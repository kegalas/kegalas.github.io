[{"content":"我们的模型并不会停留在原地不动，比如当我们在游戏中前后左右移动时，其他物体相对于我们是在平移的。又比如在游戏中移动鼠标看向不同的地方，其他物体和我们距离保持不变，但方向却改编了。\n为此，研究物体的坐标变换是十分有必要的。\n我们之前都只是简单的把物体的\\(z\\)轴坐标去掉，只用\\(x,y\\)轴坐标来画图。这导致的问题是，我们无法实现近大远小的效果，美术上也把这个称为透视原理。为此，我们还必须研究一种方法，让渲染考虑\\(z\\)轴坐标，实现对于透视的模拟。\n坐标变换 一般来说，我们主要用到平移、旋转、缩放，其他的如切变、镜像等并不是很常用到，暂时不做介绍。另外，我们最开始打算的就是在三维空间中运行，所以就不介绍更简单的二维情况了\n缩放 从最简单的缩放讲起，如果一个点是\\((x,y,z)\\)，那么把他缩放\\(k\\)倍，就是简单的\\((kx,ky,kz)\\)。这实在是过于显然的结论。用矩阵实现的话，这个变换的矩阵是\n\\[\\begin{bmatrix} k \u0026 0 \u0026 0\\\\ 0 \u0026 k \u0026 0\\\\ 0 \u0026 0 \u0026 k \\end{bmatrix} \\]\n当然，如果你想让各个轴上缩放比例不一样，例如\\(x\\)轴缩放\\(k_x\\)倍，\\(y\\)轴缩放\\(k_y\\)倍，\\(z\\)轴缩放\\(k_z\\)倍，那么\n\\[\\begin{bmatrix} k_x \u0026 0 \u0026 0\\\\ 0 \u0026 k_y \u0026 0\\\\ 0 \u0026 0 \u0026 k_z \\end{bmatrix} \\]\n其作用在某一点\\((x,y,z)^T\\)上，结果为\n\\[\\begin{bmatrix} k_x \u0026 0 \u0026 0\\\\ 0 \u0026 k_y \u0026 0\\\\ 0 \u0026 0 \u0026 k_z \\end{bmatrix} \\begin{bmatrix} x\\\\ y\\\\ z \\end{bmatrix}= \\begin{bmatrix} k_xx\\\\ k_yy\\\\ k_zz \\end{bmatrix} \\]\n写成四维（后面介绍为什么）的形式就是\n\\[\\begin{bmatrix} k_x \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 k_y \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 k_z \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} x\\\\ y\\\\ z\\\\ 1 \\end{bmatrix}= \\begin{bmatrix} k_xx\\\\ k_yy\\\\ k_zz\\\\ 1 \\end{bmatrix} \\]\n平移 事实上，三维矩阵是无法进行平移的，我们必须加入一维。\n前面提到，我们在图形学中一般最多也就用到四维坐标，我把为什么用以及如何使用四维坐标放到本章附录里。我们先讨论如何平移。\n具体而言，我们引入下面这个矩阵\n\\[\\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 t_x\\\\ 0 \u0026 1 \u0026 0 \u0026 t_y\\\\ 0 \u0026 0 \u0026 1 \u0026 t_z\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n对于任意一点\\((x,y,z,1)^T\\)应用这个变换，得到\n\\[\\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 t_x\\\\ 0 \u0026 1 \u0026 0 \u0026 t_y\\\\ 0 \u0026 0 \u0026 1 \u0026 t_z\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} x\\\\ y\\\\ z\\\\ 1 \\end{bmatrix}= \\begin{bmatrix} x+t_x\\\\ y+t_y\\\\ z+t_z\\\\ 1 \\end{bmatrix} \\]\n我们很自然地发现，这就是真正的平移，每个坐标都位移了\\(t\\)的距离。\n旋转 旋转操作有很多办法，例如欧拉角，四元数等等。这次我们先讨论欧拉角，未来可能会添加上四位数（TODO）\n在二维空间中，一个点绕原点逆时针旋转\\(\\phi\\)得到的新点为\n\\[\\begin{bmatrix} \\cos\\phi \u0026 -\\sin\\phi\\\\ \\sin\\phi \u0026 \\cos\\phi \\end{bmatrix} \\begin{bmatrix} x\\\\ y\\\\ \\end{bmatrix} \\]\n在三维空间中，这个旋转就相当于点绕\\(z\\)轴旋转，容易推出绕三个轴的旋转矩阵。\n\\[rotate-z(\\phi)= \\begin{bmatrix} cos\\phi \u0026 -sin\\phi \u0026 0\\\\ sin\\phi \u0026 cos\\phi \u0026 0\\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n\\[rotate-x(\\phi)= \\begin{bmatrix} 1 \u0026 0 \u0026 0\\\\ 0 \u0026 cos\\phi \u0026 -sin\\phi\\\\ 0 \u0026 sin\\phi \u0026 cos\\phi \\end{bmatrix} \\]\n\\[rotate-y(\\phi)= \\begin{bmatrix} cos\\phi \u0026 0 \u0026 sin\\phi\\\\ 0 \u0026 1 \u0026 0\\\\ -sin\\phi \u0026 0 \u0026 cos\\phi \\end{bmatrix} \\]\n同样的，我们也可以很方便地将其扩展为4维矩阵。\n复合变换 我们有时会对一个点进行连续的变换，例如先把他缩放50%，再把它旋转某个角度，再把它平移。设缩放矩阵为\\(M_1\\)，旋转矩阵为\\(M_2\\)，平移矩阵为\\(M_3\\)，我们的点初始为\\(P^{(0)}\\)\n首先进行的是缩放，那么\\(P^{(1)}=M_1P^{(0)}\\)，然后再进行旋转，那么\\(P^{(2)}=M_2P^{(1)}\\)，然后再平移，那么\\(P^{(3)}=M_3P^{(2)}\\)。代入展开得\n\\[P^{(3)} = M_3M_2M_1P^{(0)} \\]\n这里我想指出非常明显的一点，就是变换的顺序不可以任意交换。例如，对\\((1,0)\\)这个点，先逆时针旋转180度，再向右平移一个单位，得到\\((0,0)\\)。而先平移再旋转就得到\\((-2,0)\\)。\n体现在矩阵上也是一样的，根据线性代数知识，我们知道，矩阵乘法有结合律，但是没有交换律。也就是例如，\\(M_3M_2M_1P^{(0)}\\)和\\(M_2M_3M_1P^{(0)}\\)，在绝大部分情况下都是不相等的。\n我们计算确实是从左到右计算，但是我们观察这个式子，判断其是以什么顺序变换的，却是反过来从右到左看，先进行\\(M_1\\)变换，再进行\\(M_2\\)变换，最后再\\(M_3\\)变换\n视角变换 我们为什么需要变换视角？我们需要先介绍一下空间坐标系统\n1.png\r看这个图，我们一般会用到\\(5\\)个坐标系。\n局部空间。其指的是物体模型自己的坐标，也就是我们之前在OBJ文件里见到的那个坐标。它有自己的原点，每个不同的模型、或者相同模型的不同实例都可以有自己的原点，也就有了自己的坐标。其不需要加载到你的程序中，这个坐标就存在了。以真实世界作为类比的话，局部空间相当于你这个人的肚脐眼为原点的空间，只保存我这个人的信息。 世界空间。当你把模型加载到你的“游戏世界”，这个世界本身是有一个坐标的，以真实世界为类比，相当于宇宙的坐标系。你在这个宇宙有一个确切的坐标（如果原点确定）。这个空间存储了许多模型的信息。通过之前提到的平移、缩放、旋转矩阵，我们把物体放到世界各处。刚导入的时候，模型原点和世界原点是重叠的，所以我们只需要对局部空间的坐标应用上变换矩阵，就得到世界空间的坐标了。 观察空间。也可以叫他摄像机空间。比起局部空间，观察空间更像是把世界空间的原点和坐标轴进行位移、旋转后得到的空间，其包含了众多模型的信息。而原来世界的原点会被变换到相机的位置，坐标轴会根据相机的朝向而设定。 裁剪空间。你的摄像机并不能看到所有的东西，例如他有长宽高的限制，又例如你看不到背后的东西，再例如远处的东西太小了对你来说看不见。所以你的摄像机实际上能看到的东西只是整个观察空间中的一个很小的子集。通过投影矩阵（正交或透视投影，之后会介绍），你把能看到的东西映射到一个\\([-1,1]^3\\)的正方形盒子里。看不到的东西则在这个盒子外，也就是被剪裁了。 屏幕空间。这里是离散的，并且是\\(2\\)维的，你的屏幕（或者窗口）的分辨率是多少，屏幕空间大小就是多少。把剪裁空间里的东西真正放到屏幕上显示出来，就从剪裁空间转换到了屏幕空间。 模型变换 也就是图上的Model Matrix，其实就是之前将的缩放、平移、旋转矩阵，不需要再讲。这个矩阵记作\\(M_m\\)\n视口变换 我们先来讲最简单的视口变换，也就是图上的Viewport Transform，最后一步的矩阵。\n为了统一与便利，我们在最后一步之前，所有可见物体的\\(x,y\\)坐标都被限制在\\([-1, 1]\\)这个连续范围内。但显然，我们的图片、显示屏等都是一个像素一个像素地去描述，其坐标是在\\([0, witdh],[0,height]\\)这个离散区间内，所以我们就需要一个变换来进行转换。\n非常容易想到，先将\\([-1, 1]\\)平移变成\\([0, 2]\\)，除以\\(2\\)变成\\([0,1]\\)，再乘以宽度或高度，就有\\([0, width]\\)。写成矩阵形式如下\n\\[\\begin{bmatrix} w \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 h \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1/2 \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 1/2 \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 1\\\\ 0 \u0026 1 \u0026 0 \u0026 1\\\\ 0 \u0026 0 \u0026 1 \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} = \\begin{bmatrix} w/2 \u0026 0 \u0026 0 \u0026 w/2\\\\ 0 \u0026 h/2 \u0026 0 \u0026 h/2\\\\ 0 \u0026 0 \u0026 1 \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n其中\\(w, h\\)为图片的宽和高。我们称最后这个矩阵\\(M_{vp}\\)\n相机变换 即图上的View Matrix变换。相机变换的目的是，将世界坐标的原点变换到相机这里，从而方便计算物体对于相机的远近关系、遮挡关系等等。\n和OpenGL保持一致，我们使用右手系，并且摄像机看向的方向是\\(-z\\)方向，摄像机的头顶是\\(y\\)方向，右边是\\(x\\)方向，如下图。\n2.jpg\r我们可以把相机变换分为两步来看，首先是将原点平移到相机位置，或者更准确的说，是将相机的位置放置在\\([0,0,0]^T\\)，世界上的其他物体都平移相同的距离和方向。矩阵如下\n\\[\\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 -c_x\\\\ 0 \u0026 1 \u0026 0 \u0026 -c_y\\\\ 0 \u0026 0 \u0026 1 \u0026 -c_z\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n其中\\(\\bm c\\)是相机的世界坐标。\n第二步是将世界坐标方向旋转到和相机的坐标方向相同。其实就是线性代数里的坐标变换。\n刚才我们也说过，我们的相机看向（gaze，\\(g\\)）\\(-z\\)轴，其头上（up，\\(u\\)）的方向为\\(y\\)轴，右边（right，\\(r\\)）为\\(x\\)轴。由线性代数知识，任意基向量矩阵\\(\\times\\)某点在该基下的坐标\\(=\\)该点在自然基下的坐标。。那么，对于自然基的点\\([1, 1, 1]\\)，其相机基向量矩阵和在相机坐标系下的坐标满足\n\\[\\begin{bmatrix} r_x \u0026 u_x \u0026 -g_x \\\\ r_y \u0026 u_y \u0026 -g_y \\\\ r_z \u0026 u_z \u0026 -g_z \\end{bmatrix} \\overrightarrow{x} = [1,1,1]^T \\]\n一般情况下，我们的\\(\\bm r, \\bm u, \\bm g\\)都是单位向量。只要上式两边同乘基向量矩阵的逆矩阵，就可以计算出\\(\\bm x\\)了。而显然，这个矩阵是正交矩阵，只需要转置即可。\n综上所述，世界坐标系上的任意一点在相机坐标系下的坐标为\n\\[\\begin{bmatrix} r_x \u0026 r_y \u0026 r_z \u0026 0\\\\ u_x \u0026 u_y \u0026 u_z \u0026 0\\\\ -g_x \u0026 -g_y \u0026 -g_z \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 -c_x\\\\ 0 \u0026 1 \u0026 0 \u0026 -c_y\\\\ 0 \u0026 0 \u0026 1 \u0026 -c_z\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} x\\\\ y\\\\ z\\\\ 1 \\end{bmatrix} \\]\n合并矩阵得\n\\[\\begin{bmatrix} r_x \u0026 r_y \u0026 r_z \u0026 -c_x\\\\ u_x \u0026 u_y \u0026 u_z \u0026 -c_y\\\\ -g_x \u0026 -g_y \u0026 -g_z \u0026 -c_z\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} x\\\\ y\\\\ z\\\\ 1 \\end{bmatrix} \\]\n左边这个矩阵一般称为view矩阵，记作\\(M_v\\)\n投影变换 在倒数第二步，即Projection Matrix变换，将所有想要的点变换到标准的\\([-1, 1]^3\\)立方体内，而在这之外的点被裁剪掉，不再渲染和计算。\n投影变换分为正交投影和透视投影两个，以blender为例\n4.jpg\r3.jpg\r显然，上面的图片中，物体之间没有近大远小，而且地板的纹理都是平行的，此为正交投影。而下图中物体近大远小明显，地板纹理相较于延长线的远端，此为透视投影。\n正交投影 正交投影就很简单，将我们想要的一个长方体变换到标准立方体。和之前的视口变换有些相似。先将长方体中心移动到原点，再将其伸缩到标准立方体。假设长方体的前后是near和far（z轴），near\u0026gt;far（记住相机指向\\(-z\\)轴）。左右是left和right（x轴），right\u0026gt;left，上下是top和bottom，top\u0026gt;bottom（y轴）。则变换矩阵如下\n\\[\\begin{bmatrix} \\dfrac{2}{r-l} \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 \\dfrac{2}{t-b} \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 \\dfrac{2}{n-f} \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 -\\dfrac{r+l}{2}\\\\ 0 \u0026 1 \u0026 0 \u0026 -\\dfrac{t+b}{2}\\\\ 0 \u0026 0 \u0026 1 \u0026 -\\dfrac{n+f}{2}\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix}= \\begin{bmatrix} \\dfrac{2}{r-l} \u0026 0 \u0026 0 \u0026 -\\dfrac{r+l}{r-l}\\\\ 0 \u0026 \\dfrac{2}{t-b} \u0026 0 \u0026 -\\dfrac{t+b}{t-b}\\\\ 0 \u0026 0 \u0026 \\dfrac{2}{n-f} \u0026 -\\dfrac{n+f}{n-f}\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n记作\\(M_o\\)\n透视投影 透视投影的作用用一张图来表示\n5.jpg\r左图中的线可以看作是相机镜头（理想状态下为一个点）接收的光线。可以看到，穿过前面的小矩形（near平面）的光线，随着距离的增长覆盖到了更大的一个矩形（far平面）。而我们的任务，就是把这一个“平截头体”“拍扁”为右侧的长方体。\n这个长方体有如下性质：\nnear平面上的点坐标在投影前后不变 far平面上的点的\\(z\\)坐标在投影前后不变 far平面的中心在投影后仍然是中心 以二维为例，作图如下\n6.jpg\r如图，假设我们要对点\\((y_1, z_1)\\)进行投影，最终其\\(y\\)轴坐标会变为\\(y_2\\)，由相似三角形知识可知\n\\[y_2 = n\\dfrac{y_1}{z_1} \\]\n同理可得，三维中，除了\\(y\\)的变换，也有\n\\[x_2 = n\\dfrac{x_1}{z_1} \\]\n注意，我们的性质中没有提到截头体内部\\(z\\)的映射性质，目前还无法直接得到。\n根据齐次坐标的性质，我们可以将我们的新点定义为（老点为\\([x,y,z,1]^T\\)）\n\\[[nx, ny, ??, z]^T = [nx/z,ny/z,??,1]^T \\]\n将投影变换矩阵写出来如下\n\\[\\begin{bmatrix} n \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 n \u0026 0 \u0026 0\\\\ ? \u0026 ? \u0026 ? \u0026 ?\\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\end{bmatrix} \\begin{bmatrix} x\\\\ y\\\\ z\\\\ 1 \\end{bmatrix}= \\begin{bmatrix} nx\\\\ ny\\\\ ?\\\\ z \\end{bmatrix} \\]\n因为近平面上的点\\([x,y,n,1]^T\\)在投影前后坐标不变，又因为齐次坐标的性质\\([x,y,n,1]^T=[nx,ny,n^2,n]^T\\)，所以有\n\\[\\begin{bmatrix} n \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 n \u0026 0 \u0026 0\\\\ A \u0026 B \u0026 C \u0026 D\\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\end{bmatrix} \\begin{bmatrix} x\\\\ y\\\\ n\\\\ 1 \\end{bmatrix}= \\begin{bmatrix} nx\\\\ ny\\\\ Ax+By+Cn+D\\\\ n \\end{bmatrix}= \\begin{bmatrix} nx\\\\ ny\\\\ n^2\\\\ n \\end{bmatrix} \\]\n所以有\\(Ax+By+Cn+D=n^2\\)，即\\(A=0, B=0, Cn+D=n^2\\)\n又因为远平面中心点的坐标变换前后不变，所以有\n\\[\\begin{bmatrix} n \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 n \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 C \u0026 D\\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\end{bmatrix} \\begin{bmatrix} 0\\\\ 0\\\\ f\\\\ 1 \\end{bmatrix}= \\begin{bmatrix} 0\\\\ 0\\\\ Cf+D\\\\ f \\end{bmatrix}= \\begin{bmatrix} 0\\\\ 0\\\\ f^2\\\\ f \\end{bmatrix} \\]\n所以有\\(Cf+D=f^2\\)。\n解得\n\\[C=n+f, D=-nf \\]\n综上所述，透视投影\\(M_p\\)矩阵为\n\\[\\begin{bmatrix} n \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 n \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 n+f \u0026 -nf\\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\end{bmatrix} \\]\n注意，我们用点\\([x,y,z,1]^T\\)去算之后，得到的是\\([nx,ny,(n+f)z-nf,z]^T\\)，这并不是我们想要的数值上的结果，我们还要进行一次除以\\(z\\)（也被称作透视除法），得到\\([nx/z,ny/z,n+f-nf/z,1]^T\\)，才是我们想要的数值结果。\n综合 我们可以用透视投影将截头体变成长方体，而用正交投影则可以将长方体变为标准立方体。显而易见的，要完成整个过程，我们只需要先透视再正交即可：\n\\[M_oM_p \\]\n有些教材里会直接将其乘在一起作为\\(M_p\\)\n\\[\\begin{bmatrix} \\dfrac{2n}{r-l} \u0026 0 \u0026 \\dfrac{l+r}{l-r} \u0026 0\\\\ 0 \u0026 \\dfrac{2n}{t-b} \u0026 \\dfrac{b+t}{b-t} \u0026 0\\\\ 0 \u0026 0 \u0026 \\dfrac{f+n}{n-f} \u0026 \\dfrac{2fn}{f-n}\\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\end{bmatrix} \\]\n有些地方会比较喜欢使用无穷远的far平面，此时矩阵变为\n\\[\\begin{bmatrix} \\dfrac{2n}{r-l} \u0026 0 \u0026 \\dfrac{l+r}{l-r} \u0026 0\\\\ 0 \u0026 \\dfrac{2n}{t-b} \u0026 \\dfrac{b+t}{b-t} \u0026 0\\\\ 0 \u0026 0 \u0026 -1 \u0026 2\\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\end{bmatrix} \\]\nFOV与宽高比 我们确实是可以直接控制\\(r,l,t,b\\)四个值来控制near平面的大小，但是游戏中我们一般是通过控制fov和宽高比来控制视角范围的。现在我们来介绍一下二者如何转化。\n首先，我们需要将near平面的中心对准相机的镜头方向，这意味着\n\\[l=-r \\]\n\\[b=-t \\]\n同时，这也就意味着其和宽高比的关系为\n\\[\\dfrac{w}{h} = \\dfrac{r}{t} \\]\n7.jpg\r如上图，当\\(n, w, h\\)确定之后，我们就可以通过控制\\(\\theta\\)来控制\\(r\\)和\\(t\\)。这里的\\(\\theta\\)就是FOV。我们这里讨论的是纵向FOV，也有些地方会用横向的。显然，这几个量的关系为\n\\[\\tan\\dfrac{\\theta}{2} = \\dfrac{t}{|n|} \\]\n只要我们知道\\(n\\)和\\(\\theta\\)，那么\\(t\\)就可以推知，从而\\(r\\)也可以根据宽高比推知。\n视角变换流水线 从最开始的图可以看出来，我们需要依次经历模型变换、相机变换、投影变换、视口变换，才能得到最终的屏幕坐标，写成如下形式，对于世界坐标的点\\(p\\)，其屏幕坐标\\(p'\\)有\n\\[p' = M_{vp}M_oM_pM_vM_mp \\]\n代码 TODO\n附录 为什么要用四维坐标？其实就是因为平移他不是线性变换，三维的矩阵无法处理三维的平移。但是我们可以通过多加一维的方式来引入平移运算。\n具体而言，我们定义三维点\\((x,y,z)^T\\)扩充为四维点\\((x,y,z,1)^T\\)，定义三维向量\\((x,y,z)^T\\)扩充为四维向量\\((x,y,z,0)^T\\)。特别的，对于任意一个四维坐标\\((x,y,z,w)^T\\)，如果\\(w=0\\)，则其代表\\((x,y,z,0)^T\\)这个向量，如果\\(w\\neq 0\\)，则其代表\\((x/w,y/w,z/w,1)^T\\)这个点。\n这样做的好处是，如果两个点相减，得到的第四维为\\(0\\)，也就得到了一个向量。同理可得两个向量相减还是向量，点减去向量相当于对点进行平移，向量减去点没有意义（除非你理解为点减去向量的相反数）。\n还有一个好处，对于任意的平移变换\n\\[\\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 t_x\\\\ 0 \u0026 1 \u0026 0 \u0026 t_y\\\\ 0 \u0026 0 \u0026 1 \u0026 t_z\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n其作用在点上时，点正确的进行了平移\n\\[\\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 t_x\\\\ 0 \u0026 1 \u0026 0 \u0026 t_y\\\\ 0 \u0026 0 \u0026 1 \u0026 t_z\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} x\\\\ y\\\\ z\\\\ 1 \\end{bmatrix}= \\begin{bmatrix} x+t_x\\\\ y+t_y\\\\ z+t_z\\\\ 1 \\end{bmatrix} \\]\n而其作用在向量上时，并不会平移向量。即\n\\[\\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 t_x\\\\ 0 \u0026 1 \u0026 0 \u0026 t_y\\\\ 0 \u0026 0 \u0026 1 \u0026 t_z\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} x\\\\ y\\\\ z\\\\ 0 \\end{bmatrix}= \\begin{bmatrix} x\\\\ y\\\\ z\\\\ 0 \\end{bmatrix} \\]\n这就是数学意义上的向量，永远从原点开始。而与物理中有时讨论的矢量不同，物理中矢量有时可以让起始点在任意地方。\n另外，你可能需要经常检查你的点的第四维坐标是否为1，如果不为1，可能会产生各种奇怪的问题。在某些变换矩阵作用后，第四维可能就不为1了，并且你可能不容易发现这个问题。\n使用例 TODO\n","date":"2024-09-22T22:53:54+08:00","image":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E5%9D%90%E6%A0%87%E5%8F%98%E6%8D%A2%E4%B8%8E%E8%A7%86%E8%A7%92/cover_hudaf40032a0fd8dda1c6536765f6be1f9_238362_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E5%9D%90%E6%A0%87%E5%8F%98%E6%8D%A2%E4%B8%8E%E8%A7%86%E8%A7%92/","title":"从零开始的软渲染器 坐标变换与视角"},{"content":"原论文：https://dl.acm.org/doi/10.1145/1360612.1360639\n摘要 本文提供了一种方法来简单有效地编辑复杂的图片，用户只需要粗略选定需要调整的物体（的一部分），编辑操作就会自动扩展到整个物体和其他相似物体上。\n1.jpg\r算法 算法的任务是，将用户输入的（粗略的）编辑\\(g_i\\)和其对应的权重\\(w_i\\)，扩展到整个相似的物体上的编辑\\(e_i\\)。这些操作是对于每个像素的。最终，我们使用编辑\\(e_i\\)，将原图像\\(a_i\\)修改为新图像\\(a_i'\\)，即\\(a_i'=f(a_i;e_i)\\)。\n\\(e\\)是通过最小化如下的能量来取得的\n\\[\\sum_i\\sum_jw_jz_{ij}(e_i-g_j)^2 + \\lambda\\sum_i\\sum_jz_{ij}(e_i-e_j)^2 \\]\n\\[\\text{with}\\quad z_{ij} = \\exp(-||f_i-f_j||^2/\\sigma_a)\\exp(-||x_i-x_j||^2/\\sigma_s) \\]\n其中\\(\\sum_i,\\sum_j\\)等指的是对图片上的每一个像素遍历。这里的\\(g_j\\)即代表着我们输入的编辑操作，例如我们在LAB空间中进行提高亮度的操作，\\(g_j\\)就可以是对像素\\(j\\)增大\\(L\\)分量的值。而\\(w_j\\)是一个\\([0, 1]\\)上的权重，也是用户输入的。如果我们非常希望对于该像素，最终的修改和用户的输入保持一致，权重就取\\(1\\)。如果我们希望最终的结果可以是任意合适的编辑，那么权重就取\\(0\\)。\n这里的\\(z_{ij}\\)是一种相似性度量，用于度量图片上两个像素的相似性，从而决定要不要扩展编辑选区，扩展到同一个物体的整体，以及相似的物体上。\n\\(f\\)为该像素的特征向量，其具体含义取决于编辑的图片。例如对于LAB空间的图像，其为\\(9\\)维向量，前\\(3\\)维为该像素的LAB分量，中间\\(3\\)维为其\\(3\\times 3\\)范围的LAB分量均值，最后三维则为范围内的LAB分量标准差。对于BRDF之类的材质，该算法也可以运行，只需要设置合适的特征即可。\n\\(x\\)代表像素的空间坐标，一般图片上为二维坐标。\n上式中存在三个超参数。\\(\\lambda\\)是调整比例的参数。显然上式由两部分组成，直观上第一项是让最终的编辑尽可能和用户输入相似，而第二项则是一个平滑项：让相近的、特征相似的元素拥有相似的编辑。在文章中，作者使用\\(\\lambda=\\sum_i w_i/n\\)\n\\(\\sigma_a\\)决定了“特征相似”的重要性，与输入图像的格式有关。作者指出低动态范围的图片使用\\(500\\)，对于HDR图片和材质，使用\\(0.2\\)。而\\(\\sigma_s\\)决定了“空间距离”的重要性，和图像内容有关。如果图片中相似的物体只有一个、距离很近，则可以使用小的值如\\(0.05\\)。对于相似物体很多，距离又比较远的图片，可以使用大的值如\\(10\\)。\n最小化上述的能量等价于求解如下的线性方程\n\\[\\bigg(\\sum_j z_{ij}w_j+2\\lambda\\sum_jz_{ij}\\bigg)e_i-2\\lambda\\sum_jz_{ij}e_j = \\sum_jz_{ij}w_jg_j \\]\n写成矩阵的形式为\n\\[e = \\dfrac{1}{2\\lambda}(D-Z)^{-1}ZWg \\]\n其中\\(D,Z,W\\)都是\\(n\\times n\\)矩阵，\\(n\\)为像素数量。\\(g\\)为\\(n\\)维向量。\\(Z\\)的每一个元素\\(z_{ij}\\)的含义同前，\\(W,D\\)为对角矩阵，\\(W_{ii}=w_i, D_{ii}=d_i=\\sum_j(z_{ij}+z_{ij}w_j/(2\\lambda))\\)。\n上式的问题在于\\(D, Z, W\\)三个矩阵都是\\(n\\times n\\)大小的，这样的算法时间和空间开销过大。作者研究发现\\(Z\\)矩阵是低秩的，于是可以有一些近似算法。从\\(Z\\)中随机采样出\\(m\\)列当作列线性无关的矩阵\\(U(m\\times n)\\)，其中\\(U\\)的前\\(m\\)行记作矩阵\\(A(m\\times m)\\)。再加上逆矩阵的近似算法，最终有\n\\[e\\approx\\dfrac{1}{2\\lambda}(D^{-1}-D^{-1}U(-A+U^TD^{-1}U)^{-1}U^TD^{-1})\\cdot(UA^{-1}U^T)Wg \\]\n其中\\(D\\)和\\(W\\)都是对角矩阵容易求逆与求乘法。这样就转换成了多个小矩阵的计算，解决了复杂度的问题。\n我的实现 https://github.com/kegalas/AppProp\n优化 本文的数据规模是像素个数，可以通过一些数据结构缩小数据规模来加速。具体例如https://dl.acm.org/doi/10.1145/1618452.1618464\n","date":"2024-09-07T15:19:52+08:00","image":"https://kegalas.top/p/appprop-all-pairs-appearance-space-edit-propagation%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%E4%B8%8E%E5%A4%8D%E7%8E%B0/cover_hueda4c761f5117f950ea670cd72a10b0b_71812_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/appprop-all-pairs-appearance-space-edit-propagation%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%E4%B8%8E%E5%A4%8D%E7%8E%B0/","title":"AppProp: All-Pairs Appearance-Space Edit Propagation论文精读与复现"},{"content":"原论文：https://people.csail.mit.edu/kaiming/sig13/index.html\n摘要 拍摄全景照片的时候，因为人手在抖，所以可能拍出来的图片边界就不是一个矩形框。在本文中，作者提出了一种可以感知图片内容的弯曲（warp）算法，来将这种形状非矩形的图片转化为矩形图片。分为两步，第一步是没有mesh的，初步把一张图片弯曲成矩形。第二步就是在矩形中建立mesh，然后在其中优化图片，使得图片中的各种形状保持原样（例如直线保持直线的样子）。\n简介 同上介绍的，关于拍摄全景照片，因为手抖，无法拉出一个矩形图片。\n一个简单的解决办法是：剪裁。从这个图片中剪裁出一个矩形区域。缺点是会损失很多信息。还有一种方法就是在原来的图片边缘的外面进行图片合成，缺陷是，对于复杂的语义信息无法处理。\n作者这里提出了一种只会引入“可接受”的、“不容易注意到”的扭曲，并且保护图片原本内容的方法。\n前人工作 Image alignment and stitching\n全景照片实际上是将多张照片缝合（stitching）在一起的。通常用某种图片上的特征，来将原照片全部投影到一个相同的坐标系下。\nProjections\n众所周知，3D场景投影到2D会不可避免地导致一些折叠的扭曲。例如透视投影，虽然可以保持直线的形状，但是其他物体的形状则会被拉伸。圆柱投影和球面投影可以保持物体的形状，但会弯曲直线。\n也有研究者提出了一种在自适应流形（adaptive manifold）上进行投影和缝合的方法。不过它是适应相机的移动，而不是适应图片的内容。\n之前也有大量的工作，考虑将这些折叠后的扭曲，通过某种方式，让它们出现在不容易注意到的位置。虽然视觉上可以接受，但是无法移除固有的扭曲。\nImage retargeting and warping\nImage retargeting是一种基于图片内容的缩放图片的方式。但是它们都假设输入的图片具有矩形形状，而且其中一部分必须还要定义一个grid mesh。\nImage completion\n即前面提到的，在图片的边缘增加内容，使其变成一个矩形图片。一般的方法是把图片里面的内容，复制到需要合成的地方。但是对于需要生成语义内容来说，表现不好。\n算法 算法分为两部分，一部分是改进的Seam Carving，是一个Local Warp的步骤，其将图片初步弯曲成矩形。然后另一部分（global warp）在前一步的基础上，建立一个grid mesh，在mesh上进行优化，来保证原图的物体形状和直线形状不变。\nLocal Warp 原版的Seam Carving算法是在图片中插入水平或者垂直的接缝（seam），来穿过整张图片，然后再从接缝中水平或者垂直地扩展一个像素。作者这里想到，接缝不穿过整张图片，这样就可以改变图片边缘的形状，从而变成矩形。\n原版的算法可见https://faculty.runi.ac.il/arik/scweb/imret/index.html\n1.jpg\r如上图，其中蓝色的部分是有效的图片像素，白色的部分是需要我们填充的像素。\n首先定义boundary segment是待填充像素中的，在图片顶部/底部/左侧/右侧的一行/一列像素。例如上图。我们找到目前最长的一个boundary segment，然后从它扩展得到一个sub-image。\n这里左侧右侧的boundary segment，扩展出来的sub-image的高度保持，而宽度则等于整张图。同理，顶部和底部的boundary segment，扩展出来的sub-image的宽度保持，高度等于整张图。\n然后我们在这个sub-image上利用seam carving的方法，去进行图像扩展。方法很简单，首先根据图片颜色梯度信息，计算每一个像素的能量。然后使用动态规划，求解最短路径。\n以Figure 3(ii)为例，计算得到每个像素的能量。因为我们需要向右边填入像素，所以我们需要一个竖直方向的seam。于是我们用动态规划的方式，求底部像素到顶部像素的最短路（8邻居路径），然后所有底部像素中距离顶部像素最近的像素，及其到顶部的路径，成为我们的seam。\n注意这里使用8邻居是源于原算法的研究，另外，我们需要给待填入的像素的能量赋值为\\(10^8\\)或者更大的数，来防止seam穿过这些像素。\n填充像素的时候，我们把seam及其右边的像素都往右移动一位。原本seam的位置则求取左右两个像素的平均。\n原版算法中提到，为了防止反复在相同的位置插入seam、导致如下的情况\n2.jpg\r之前的作者建议同时采集多根seam，然后依次填入像素。\n但是这在我们这篇文章中是行不通的。我们的Local Warp要求我们每次填充完一根seam之后，都要重新计算最长的bound segment，我们不能反复对同一个sub-image填入像素。\n我这里的实现采用了一个比较trick的方法，算出seam后，对原本的seam的位置的能量设置为\\(10^5\\)这样的数，比一般的大，比非法像素的小。之后让像素和能量都右移。现在原本的seam位置的能量和其右边一个像素的能量都为\\(10^5\\)了，这样就有更少的可能会在这里再次插入seam。\n总而言之，重复以上过程，直到填充完所有像素。例如我实现的下例\n3.jpg\r其原图为\n4.jpg\r可以看到，虽然填充是填充了，但是歪歪扭扭。于是还需要下面的步骤。\nGlobal Warp Mesh Placement 首先，我们在Local Warp之后的图片的长宽上，将其分成\\((40-1)*(10-9)\\)个网格，其中\\(40*10\\)是网格的顶点数量。网格是正交的。\n在Local Warp中，我们对像素进行了移动，我们需要记录下每个像素移动的偏移量。然后，我们使用网格顶点所在像素的偏移量，将各个网格顶点移动回去，就完成了mesh placement这一步。之后local warp的图像就可以抛弃了。移动后的结果例如：\n5.jpg\rEnergy Function 这里设计能量的目的有三个，对于目前的网格与最终的网格结果之间：\n保持网格的形状尽量不变，亦即Shape Preservation 保持网格内的线段的笔直，并且与其平行的其他线段，在处理后依然平行，亦即Line Preservation 网格上下左右贴合目标矩形图像框，亦即Boundary Constraints Shape Preservation\n最终输出的mesh的顶点（vertex）集记作\\(V\\)，其中的每一个元素\\(v_i=(x_i, y_i)\\)，可以用坐标表示出来。我们进行完Mesh Placement后得到的初始mesh记作\\(\\hat V\\)\n保型的能量定义为\n\\[E_S(V) = \\dfrac{1}{N}\\sum_q||(A_q(A_q^TA_q)^{-1}A_q^T-I)V_q||^2 \\]\n这里\\(N\\)是quad的个数。其中\n\\[A_q = \\begin{bmatrix} \\hat x_0 \u0026 -\\hat y_0 \u0026 1 \u0026 0\\\\ \\hat y_0 \u0026 \\hat x_0 \u0026 0 \u0026 1\\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots\\\\ \\hat x_3 \u0026 -\\hat y_3 \u0026 1 \u0026 0\\\\ \\hat y_3 \u0026 \\hat x_3 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n\\[V_q = \\begin{bmatrix} x_0 \\\\ y_0 \\\\ \\vdots \\\\ x_3 \\\\ y_3 \\end{bmatrix} \\]\n这里也就是说第\\(q\\)个quad的四个顶点的坐标。其中\\(A_q\\)中的是初始mesh的坐标，\\(V_q\\)是目标mesh的坐标。\nLine Preservation\n我们目前计算过的东西是不包含“线段”这样的信息的。我们首先要做的事是，使用任何一种线段检测算法，来算出图片中的线段。\n根据作者的说法，我们需要将这些线段切分开来，放到mesh的各个quad里。然后将所有线段的方向角（范围\\([-\\dfrac{\\pi}{2},\\dfrac{\\pi}{2})\\)），离散化为\\(M=50\\)个角度，每个离散化角度称为一个bin。为了保持直线性和平行性，设计的能量需要让每个bin里的线段拥有同样的角度。\n给定一个线段，其方向向量\\(e\\)可以由线段的两个端点相减得到。如果我们将线段的两个端点用其所在的quad的\\(V_q\\)进行双线性插值表示，那么\\(e\\)就可以表示为\\(V_q\\)的线性函数。\n同样的\\(e\\)是我们的目标，而\\(\\hat e\\)则是最初的对应线段的方向向量。对于某一条线段，给定旋转操作的目标角度\\(\\theta_m\\)，它的能量为\n\\[||sR\\hat e-e||^2 \\]\n其中\n\\[R = \\begin{bmatrix} \\cos\\theta_m \u0026 -\\sin\\theta_m\\\\ \\sin\\theta_m \u0026 \\cos\\theta_m \\end{bmatrix} \\]\n是旋转矩阵，而\n\\[s=(\\hat e^T\\hat e)^{-1}\\hat e^TR^Te \\]\n是放缩因子。能量可以重新写为\n\\[||Ce||^2 \\]\n其中\n\\[C = R\\hat e(\\hat e^T\\hat e)^{-1}\\hat e^TR^T-I \\]\n因为\\(\\hat e\\)和\\(e\\)都可以写作\\(\\hat V_q\\)和\\(V_q\\)的线性函数，所以能量就可以写成二次函数。\n总的能量为\n\\[E_L(V, \\{\\theta_m\\}) = \\dfrac{1}{N_L}\\sum_j||C_j(\\theta_{m(j)})e_{q(j)}||^2 \\]\n这里\\(N_L\\)为线段总数。对于第\\(j\\)条线段，\\(\\theta_{m(j)}\\)代表其所属的bin中的目标旋转角度，\\(q(j)\\)代表其所属的quad。\nBoundary Constraints\n直白点说，就是把mesh的上下左右拉到图片框边缘上。\n\\[E_B(V) = \\sum_{v_i\\in L} x_i^2 + \\sum_{v_i\\in R} (x_i-w)^2 + \\sum_{v_i\\in T} y_i^2 + \\sum_{v_i\\in B} (y_i-h)^2 \\]\n\\(L/R/T/B\\)分别是左右上下边界的mesh顶点，\\(w, h\\)则是图片框的宽高。\n最终能量\n将前面的几个加和，添加权重\n\\[E(V, \\{\\theta_m\\}) = E_S(V)+\\lambda_LE_L(V, \\{\\theta_m\\}) + \\lambda_B E_B(V) \\]\n显然，我们需要图片至少能够贴合图片框，我们设置\\(\\lambda_B=10^8\\)来确保这一点。然后，关于\\(\\lambda_L\\)的选择，作者说选取\\(\u003e10\\)比较好，原文采取了\\(\\lambda_L=100\\)。\n优化算法 作者指出，可以分别优化\\(V\\)和\\(\\{\\theta_m\\}\\)。每各优化一次算迭代一次，总共迭代10次。\n固定\\(\\{\\theta_m\\}\\)优化\\(V\\)\n此时能量函数是\\(V\\)的二次函数，可以求解线性方程来计算。总共就几百个顶点，所以总体上来说，这部分的开销很小。\n这里的求解是通过最小二乘法来算的，具体见我自己的实现部分。\n固定\\(V\\)优化\\(\\{\\theta_m\\}\\)\n因为另外两项和\\(\\theta\\)无关，所以我们只用优化\\(E_L\\)这一部分。\n作者指出，可以通过牛顿迭代等方法去优化。但是，几何意义上，\\(E_L\\)的目标是找到一个\\(\\theta_m\\)，使得所有在第\\(m\\)个bin中的线段\\(e\\)和其初始线段\\(\\hat e\\)的夹角，都近似等于\\(\\theta_m\\)。所以，我们可以简单的计算所有这个夹角，然后加和，求平均，作为新的\\(\\theta_m\\)。\n防止拉伸和后处理 如果我们的目标图相框的长宽比设置的不是很好，那么我们的结果图就会被拉伸。为了减少这种拉伸问题，我们在global warping之后更新目标框。\n对于每个quad，我们计算它的\\(x\\)方向的伸缩因子为\n\\[s_x=(x_{max}-x_{min})/(\\hat x_{max}-\\hat x_{min}) \\]\n所有quad的平均伸缩因子就为\\(\\bar s_x\\)。同理可以计算出\\(\\bar s_y\\)。之后我们的目标框就设置为\\((w/\\bar s_x, h/\\bar s_y)\\)。\n之后我们再在这个新的目标框上跑一次global warping\n获得最终的mesh之后，我们就可以通过一些方法来获得最终的图像了。以图形学的思想为例，最终的mesh构成了我们要绘制的三角面。三角面空间坐标为最终mesh的坐标，uv坐标则是初始mesh的坐标。texture则是原图。\n作者指出，这样的实现有一个小问题，因为mesh不会只包住有效像素，例如\n6.jpg\r这里的quad有一部分就包含了外部的无效像素。进行纹理采样时，作者简单地将无效像素替换为最近的有效像素。\n实现细节 由于mesh是很“光滑”的，作者指出我们可以在缩小的图片上进行mesh的计算。首先将图片缩小到一个固定的大小，然后再在上面进行local/global warping。然后我们将mesh的尺度放大到原来的图片大小，再用这个mesh去进行纹理采样。\n本文局限 如果图片缺失的部分太多，那么处理结果不好\n7.jpg\r本文的算法可能会导致边缘凹进去\n8.jpg\r作者指出，可以手动添加一个透明区域，当作已知像素。\n9.jpg\r将其当作已知像素来warp，之后在本文的算法处理完之后，再在这个透明区域中使用image completion等方法。\n另外，本文无法处理未识别到的线段。这可以通过用户交互来缓解。\n最后，本文无法应对线段数量过多的情况，这是warping方式的共同挑战。\n我的实现 https://github.com/kegalas/Rectangling_Panoramic_Images\n一些细节 首先是我之前也提到过的，为了防止反复在同一个地方插入seam，我们添加了额外的一个像素类别SEAM_PIXEL，让他的能量为\\(10^5\\)。比一般的像素大，比无效像素小。\n在Global Warping主要要说明的部分则是关于如何优化能量。从\\(E_S\\)开始\n\\[E_S(V) = \\dfrac{1}{N}\\sum_q||(A_q(A_q^TA_q)^{-1}A_q^T-I)V_q||^2 \\]\n我们需要使其最小。众所周知，使向量的范数平方最小，只用使其每一维都最小即可。或者说，使向量尽可能成为零向量。\n这里的\\((A_q(A_q^TA_q)^{-1}A_q^T-I)\\)是一个\\(8\\times 8\\)矩阵（记作\\(A\\)好了），而\\(V_q\\)是一个8维向量。我们可以将所有的\\(V_q\\)收尾接在一起。如果我们的mesh是\\(40\\times 10\\)的，那么新的拼接向量\\(V_Q\\)的维度就是\\((40-1)\\times(10-1)\\times 8\\)\n\\[V_Q = \\begin{bmatrix} V_1 \\\\ V_2 \\\\ \\vdots \\\\ V_{N-1} \\\\ V_{N} \\end{bmatrix} \\]\n同理，我们也可以把\\(A\\)拼接。如下\n\\[A_Q = \\begin{bmatrix} A_1 \u0026 \u0026 \u0026 \\\\ \u0026 A_2 \u0026 \u0026 \\\\ \u0026 \u0026 \\ddots \u0026 \\\\ \u0026 \u0026 \u0026 A_N \\end{bmatrix} \\]\n我们的目标是使得\n\\[E_S(V) = \\dfrac{1}{N}A_QV_Q = \\overrightarrow{0} \\]\n这里\\(A_Q\\)是用\\(\\hat V\\)算的，而\\(V_Q\\)是我们最终mesh的坐标。也就是说我们需要解方程算出来\\(V_Q\\)。这其实就是最小二乘法。我们使用Eigen的QR分解对\\(A_Q\\)分解，然后再求解\\(V_Q\\)。这里建议使用稀疏矩阵。\n另外，每一个mesh的顶点只能有一个实例，不能单纯地把所有quad的四个顶点放进去同一列。每个顶点只能出现在\\(V_Q\\)里一次。我们直接存储\\(V_Q\\)为\\(40\\times 10\\times 2\\)维向量。即每个顶点都只存一份（包含\\(x,y\\)坐标）。然后我们去修改\\(A_Q\\)的顺序就可以在向量乘法的时候一一对应。具体见我写的代码。调整后写为\n\\[E_S(V) = \\dfrac{1}{N}AV = \\overrightarrow{0} \\]\n接下来比较简单的是\\(E_B\\)\n\\[E_B(V) = \\sum_{v_i\\in L} x_i^2 + \\sum_{v_i\\in R} (x_i-w)^2 + \\sum_{v_i\\in T} y_i^2 + \\sum_{v_i\\in B} (y_i-h)^2 \\]\n对于mesh上的一个顶点\\(v_i\\)，其有四种情况，在左侧、右侧、上部，下部。当然有四个顶点同时属于两种情况。也就是说，有一些顶点需要限制\\(x\\)坐标，有一些需要限制\\(y\\)坐标，有一些两个都需要限制，而有一些则两个都不需要限制。\n设\\(B_i\\)如下\n\\[B_i = \\begin{bmatrix} a \u0026 0 \\\\ 0 \u0026 b \\end{bmatrix} \\]\n一个点如果需要限制\\(x\\)坐标，则\\(a=1\\)，如果需要限制\\(y\\)坐标，则\\(b=1\\)。否则都等于\\(0\\)。\n例如左上角的顶点\\((x, y)\\)，我们的目标是\n\\[\\begin{bmatrix} 1 \u0026 0 \\\\ 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} x\\\\ y \\end{bmatrix} = \\begin{bmatrix} 0\\\\ 0 \\end{bmatrix} \\]\n对于右下角的顶点，目标是\n\\[\\begin{bmatrix} 1 \u0026 0 \\\\ 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} x\\\\ y \\end{bmatrix} = \\begin{bmatrix} w\\\\ h \\end{bmatrix} \\]\n对于右侧的顶点，目标是\n\\[\\begin{bmatrix} 1 \u0026 0 \\\\ 0 \u0026 0 \\end{bmatrix} \\begin{bmatrix} x\\\\ y \\end{bmatrix} = \\begin{bmatrix} w\\\\ 0 \\end{bmatrix} \\]\n对于中间的无限制顶点，目标是\n\\[\\begin{bmatrix} 0 \u0026 0 \\\\ 0 \u0026 0 \\end{bmatrix} \\begin{bmatrix} x\\\\ y \\end{bmatrix} = \\begin{bmatrix} 0\\\\ 0 \\end{bmatrix} \\]\n以此类推。\n同样的，我们把\\(v_i\\)合并成一个\\(40\\times 10\\times 2\\)向量（同前）。将\\(B_i\\)也合并。\n\\[B = \\begin{bmatrix} B_1 \u0026 \u0026 \u0026 \\\\ \u0026 B_2 \u0026 \u0026 \\\\ \u0026 \u0026 \\ddots \u0026 \\\\ \u0026 \u0026 \u0026 B_N \\end{bmatrix} \\]\n这里就不用重新调整\\(B\\)内容的顺序了。接下来合并目标\\(v_{ti}\\)\n\\[V_T = \\begin{bmatrix} v_{t1} \\\\ v_{t2} \\\\ \\vdots \\\\ v_{tn} \\end{bmatrix} \\]\n最终的目标是\n\\[E_B(V) = BV = V_T \\]\n同样，Eigen解方程可得\\(V_Q\\)。\n接下来是很复杂的\\(E_L\\)\n设原始的一条线段为\\(\\hat L=[\\hat x_{l0}, \\hat y_{l0}, \\hat x_{l1}, \\hat y_{l1}]^T\\)。根据我们前面的说法，一条线段会被mesh切割，然后放进各个quad中。我们用quad的四个顶点来进行双线性插值，来表示目标的\\(L\\)。方式如下，首先用双线性插值从\\(\\hat V_q\\)计算出\\(V_q\\)\n\\[\\begin{bmatrix} \\hat x_0 \u0026 \\hat y_0 \u0026 \\hat x_0\\hat y_0 \u0026 1 \u0026 \u0026 \u0026 \u0026\\\\ \u0026 \u0026 \u0026 \u0026 \\hat x_0 \u0026 \\hat y_0 \u0026 \\hat x_0\\hat y_0 \u0026 1\\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\vdots\\\\ \\hat x_3 \u0026 \\hat y_3 \u0026 \\hat x_3\\hat y_3 \u0026 1 \u0026 \u0026 \u0026 \u0026\\\\ \u0026 \u0026 \u0026 \u0026 \\hat x_3 \u0026 \\hat y_3 \u0026 \\hat x_3\\hat y_3 \u0026 1 \\end{bmatrix}F_L = \\begin{bmatrix} x_0\\\\ y_0\\\\ \\vdots\\\\ x_3\\\\ y_3 \\end{bmatrix} \\]\n我们把上式左边的\\(8\\times 8\\)矩阵记作\\(W\\)，上式就为\\(WF_L=V_q\\)\n然后用\\(\\hat L\\)表示\\(L\\)，有\n\\[\\begin{bmatrix} \\hat x_{l0} \u0026 \\hat y_{l0} \u0026 \\hat x_{l0}\\hat y_{l0} \u0026 1 \u0026 \u0026 \u0026 \u0026\\\\ \u0026 \u0026 \u0026 \u0026 \\hat x_{l0} \u0026 \\hat y_{l0} \u0026 \\hat x_{l0}\\hat y_{l0} \u0026 1\\\\ \\hat x_{l1} \u0026 \\hat y_{l1} \u0026 \\hat x_{l1}\\hat y_{l1} \u0026 1 \u0026 \u0026 \u0026 \u0026\\\\ \u0026 \u0026 \u0026 \u0026 \\hat x_{l1} \u0026 \\hat y_{l1} \u0026 \\hat x_{l1}\\hat y_{l1} \u0026 1 \\end{bmatrix}F_L = \\begin{bmatrix} x_{l0}\\\\ y_{l0}\\\\ x_{l1}\\\\ y_{l1} \\end{bmatrix} \\]\n上式左侧\\(4\\times 8\\)矩阵记作\\(H\\)，上式就为\\(HF_L=L\\)\n于是\n\\[L = HF_L = HW^{-1}V_q \\]\n\\(H\\)和\\(W\\)都为已知，所以\\(L\\)表示为\\(V_q\\)的线性函数。计算\\(L\\)的向量\\(e\\)使用两个端点相减，矩阵为\n\\[D = \\begin{bmatrix} -1 \u0026 0 \u0026 1 \u0026 0\\\\ 0 \u0026 -1 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n有\n\\[e = DL = \\begin{bmatrix} -1 \u0026 0 \u0026 1 \u0026 0\\\\ 0 \u0026 -1 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} x_{l0}\\\\ y_{l0}\\\\ x_{l1}\\\\ y_{l1} \\end{bmatrix}= \\begin{bmatrix} x_{l1}-x_{l0}\\\\ y_{l1}-y_{l0} \\end{bmatrix} \\]\n\\(E_L\\)中的\\(||Ce||^2\\)中的\\(e\\)最终就表示为\n\\[\\underset{(2, 1)}{e} = \\underset{(2, 4)}{D}\\underset{(4, 8)}{H}\\underset{(8,8)}{W^{-1}}\\underset{(8, 1)}{V_q} \\]\n而\n\\[C = R\\hat e(\\hat e^T\\hat e)^{-1}\\hat e^TR^T-I \\]\n其中\\(\\hat e\\)已知，\\(R\\)只和\\(\\theta_m\\)有关。可以直接算，与\\(V_q\\)无关。\n同样的，我们把所有线段的\\(e\\)和其\\(C\\)拼接（具体见代码），有\n\\[E_L(V,\\{\\theta_m\\}) = \\dfrac{1}{N_L}Ce = \\overrightarrow{0} \\]\n同样的，在优化\\(V_q\\)时，上式是\\(V_q\\)的线性函数，只需要用Eigen解方程即可。\n最终，我们的目标是使得\n\\[E = E_S+\\lambda_LE_L+\\lambda_BE_B \\]\n最小，即\n\\[\\begin{bmatrix} \\dfrac{1}{N}A\\\\ \\dfrac{\\lambda_L}{N_L}CDHW^{-1}\\\\ \\lambda_BB \\end{bmatrix}V = \\begin{bmatrix} \\overrightarrow{0}\\\\ \\overrightarrow{0}\\\\ V_T \\end{bmatrix} \\]\n用Eigen求解出V即可。注意其中的\\(CDHW^{-1}\\)指的是每一个线段的矩阵拼接后的结果，具体拼接见代码。\n","date":"2024-06-03T23:16:15+08:00","image":"https://kegalas.top/p/rectangling-panoramic-images-via-warping%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%E4%B8%8E%E5%A4%8D%E7%8E%B0/cover_hu803811e1d9d935a6e60dd50dca480090_178188_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/rectangling-panoramic-images-via-warping%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%E4%B8%8E%E5%A4%8D%E7%8E%B0/","title":"Rectangling Panoramic Images via Warping论文精读与复现"},{"content":"thread C++启动一个新线程，只要构造一个std::thread对象就可以了。使用join()方法可以等待线程汇入，使用detach()可以不等待。这里join()只能使用一次，可以用joinable()查询是否可以join\n使用方法如下\nstd::thread t(f, 1, \u0026#34;123\u0026#34;, 0.0); 其中第一个参数是一个函数对象，其后面的都是函数参数（应当使得f(args)的调用合法）。\n注意这里的参数，会被decay-copy，也就是说，如果f的形参是f(A const \u0026amp; a)之类的，用thread的构造函数传入参数的话，仍然会产生拷贝，并且不会引用原来的变量。此时需要使用std::ref来提供包装。\n注意thread的函数是不能有返回值的，只能是void。返回值可以写在参数中，通过引用或者指针来进行传递。一般会调用t.join()汇入之后再去读取这个返回值。\n可以有返回值的线程使用std::async，见后。\nmutex C++提供的互斥锁。使用方法：\nstd::mutex m; m.lock(); //... m.unlock(); 但是我们一般不会直接使用std::mutex提供的方法，而是会使用lock_guard，其提供了RAII的包装，在析构时自动解锁。\nstd::mutex m; std::lock_guard\u0026lt;std::mutex\u0026gt; lock(m); // C++17之后也可以省略模板参数 可以使用std::lock同时锁住两个（多个）锁，避免条件竞争。\nstd::mutex m1, m2; std::lock(m1, m2); std::lock_guard\u0026lt;std::mutex\u0026gt; lock_a(m1,std::adopt_lock); std::lock_guard\u0026lt;std::mutex\u0026gt; lock_b(m2,std::adopt_lock); 如果是C++17则可以使用std::scoped_lock，就不需要再来两个lock_guard了\nstd::scoped_lock lock(e1.m, e2.m); unique_lock则会更灵活一点，lock_guard只能在析构时解锁，而unique_lock不仅可以在构造的时候上锁、析构的时候解锁，还可以提前解锁和重新上锁，甚至还可以推迟上锁。\nstd::mutex m1; std::unique_lock\u0026lt;std::mutex\u0026gt; lk(m1); // 构造时上锁，析构时解锁 std::mutex m2; std::unique_lock\u0026lt;std::mutex\u0026gt; lk(m2); lk.unlock(); lk.lock(); // 可以其他解锁和重新上锁 std::unique_lock\u0026lt;std::mutex\u0026gt; lk_a(m3, std::defer_lock); std::unique_lock\u0026lt;std::mutex\u0026gt; lk_b(m4, std::defer_lock); std::lock(lk_a, lk_b); // 和之前的std::lock作用相同 避免死锁的指导 避免嵌套锁。持有一个锁，就不要再去尝试持有第二个。当需要持有多个锁时，使用std::lock 避免在持有锁时调用其他函数。因为你不知道这个其他函数会不会也尝试获取锁。 使用固定顺序获取锁。例如规定所有函数都要先获取A锁，再获取B锁。当std::lock不适用时应该考虑这种方法。 使用层次锁结构。 condition_variable 条件变量，用于线程同步。典型的使用例为生产者消费者模型\nstd::mutex mut; std::queue\u0026lt;data_chunk\u0026gt; data_queue; // 1 std::condition_variable data_cond; void data_preparation_thread() { while(more_data_to_prepare()) { data_chunk const data=prepare_data(); std::lock_guard\u0026lt;std::mutex\u0026gt; lk(mut); data_queue.push(data); // 2 data_cond.notify_one(); // 3 } } void data_processing_thread() { while(true) { std::unique_lock\u0026lt;std::mutex\u0026gt; lk(mut); // 4 data_cond.wait( lk,[]{return !data_queue.empty();}); // 5 data_chunk data=data_queue.front(); data_queue.pop(); lk.unlock(); // 6 process(data); if(is_last_chunk(data)) break; } } 其中生产者可以用notify_one和notify_all来实现通知等待的线程。消费者调用wait来等待通知，其中传入的参数首先是一个锁，然后是一个函数，作为等待的条件。wait会检查等待条件是否为真，当条件满足时，进行下一行代码。如果条件不满足，就会释放锁，等待下一次被唤醒。被唤醒时又重新获取锁，再次判断条件，以此类推。\n可以用wait_for和wait_until设置等待时间。\nfuture 前面提到，std::thread的函数对象是不能带有返回值的，如果需要有返回值，应该使用std::async\nint foo(int); void bar(); std::future\u0026lt;int\u0026gt; ans = std::async(foo, 1); bar(); std::cout\u0026lt;\u0026lt;ans.get()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; 这里的ans.get()的调用，会一直阻塞，执行foo执行完毕。我们也可以使用ans.wait()，阻塞，直到值变为可用，稍后再get值。\nasync还可以进行惰性求值\nstd::future\u0026lt;int\u0026gt; ans = std::async(std::launch::deferred, foo, 1); 具体这个foo的函数的执行时间，会推迟到wait或者get出现的时候，再去执行。\nstd::packaged_task可以将future与函数对象进行绑定。当调用packaged_task时，就会调用这个函数对象，当future状态就绪时，会存储返回值。典型的应用有线程池，见后。\nvoid task_bind() { std::packaged_task\u0026lt;int()\u0026gt; task(std::bind(f, 2, 11)); std::future\u0026lt;int\u0026gt; result = task.get_future(); task(); std::cout \u0026lt;\u0026lt; \u0026#34;task_bind:\\t\u0026#34; \u0026lt;\u0026lt; result.get() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } void task_thread() { std::packaged_task\u0026lt;int(int, int)\u0026gt; task(f); std::future\u0026lt;int\u0026gt; result = task.get_future(); std::thread task_td(std::move(task), 2, 10); task_td.join(); std::cout \u0026lt;\u0026lt; \u0026#34;task_thread:\\t\u0026#34; \u0026lt;\u0026lt; result.get() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } 如上，第一个函数是在当前线程执行任务，第二个函数则是将任务传递给别的线程。\nstd::promise提供了一种手动给future设定值的方式，例如\nvoid do_work(std::promise\u0026lt;void\u0026gt; barrier) { std::this_thread::sleep_for(std::chrono::seconds(1)); barrier.set_value(); } std::promise\u0026lt;void\u0026gt; barrier; std::future\u0026lt;void\u0026gt; barrier_future = barrier.get_future(); std::thread new_work_thread(do_work, std::move(barrier)); barrier_future.wait(); new_work_thread.join(); 当do_work执行完后，barrier会设置值，从而提醒barrier_futuer值可用，从而结束等待。也是一种线程同步的工具。\natomic C++标准库提供的原子类型，对其进行的操作是原子的。C++提供了内存序，来规定编译器进行命令重排的程度。例如\nstd::atomic_int acnt; int cnt; void f() { for (int n = 0; n \u0026lt; 10000; ++n) { ++acnt; ++cnt; } } int main() { { std::vector\u0026lt;std::jthread\u0026gt; pool; for (int n = 0; n \u0026lt; 10; ++n) pool.emplace_back(f); } std::cout \u0026lt;\u0026lt; \u0026#34;原子计数器为 \u0026#34; \u0026lt;\u0026lt; acnt \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39; \u0026lt;\u0026lt; \u0026#34;非原子计数器为 \u0026#34; \u0026lt;\u0026lt; cnt \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } C++标准库中规定了许多类型别名，例如这里的std::atomic_int就是std::atomic\u0026lt;int\u0026gt;的别名。\nC++的原子类型的内部实现有两种方法，一种是用锁实现的，另一种是无锁的原子指令。可以通过对原子类型的变量使用.is_lock_free()来查询。一个类型是否无锁取决于平台，但是atomic_flag总是无锁的。\n这里atomic_flag不是std::atomic的特化的别名，他和atomic\u0026lt;bool\u0026gt;是不一样的。它不支持赋值、运算等操作。只支持test_and_set(), test(), clear()等更基础的操作。\n虽然对atomic_int等类型直接使用+,-,++,--,+=,-=很方便，但是使用fetch_add,fetch_sub,store,load,exchange等函数可以更精细地控制内存序。\nC++有六种内存序\ntypedef enum memory_order { memory_order_relaxed, memory_order_consume, memory_order_acquire, memory_order_release, memory_order_acq_rel, memory_order_seq_cst } memory_order; relaxed，其是最宽松的，只保证对该原子类型的操作是原始的，不限制重排。 acquire，其不允许将在load该原子类型之后的命令重排到该命令之前。 release，其不允许将在store该原子类型之前的命令重排到该命令之后。 consume，类似于acquire，但是区别在于，只会限制和该原子类型相关的操作的重排。 acq_rel，即结合二者，前后的命令都不能重排。 seq_cst，最严格的，也是前后命令都不难重排，并且所有线程的语句都以全局的内存修改顺序为参照。 线程池 这里给出一个典中典极简实现：https://github.com/progschj/ThreadPool/blob/master/ThreadPool.h\n","date":"2024-05-21T23:42:42+08:00","permalink":"https://kegalas.top/inferior/c++%E5%B9%B6%E5%8F%91%E6%94%AF%E6%8C%81%E5%BA%93%E7%94%A8%E6%B3%95%E9%80%9F%E6%9F%A5/","title":"C++并发支持库用法速查"},{"content":"原论文：https://www.microsoft.com/en-us/research/publication/grabcut-interactive-foreground-extraction-using-iterated-graph-cuts/\n摘要 分离出图像的前景和背景，对于图像编辑是很重要的。经典的image segmentation实现方式有两个，一是使用纹理（颜色）信息，例如魔棒工具。另一种是使用边缘信息，例如磁力套索（Intelligent Scissors）。本文介绍使用graph-cut来进行图像分割。本文提出了三方面的改进：优化迭代、优化用户交互、border matting的处理优化\n简介 这里提到，所谓的“前景对象”的结果是一个alpha-matte，反应了前景和背景的比例。个人理解应该是，某个像素属于前景的可能性的大小和背景的可能性的比。本文想要实现保证高性能的前提下，不需要用户的过多交互，就能得到很好的效果。\n高性能指：精准分割前背景，主观上可信的alpha值，可以处理模糊、混合像素（mixed pixels）、和透明度（透明的物体），前景图片不带有背景透过来的颜色。\n用户交互的简易程度：作者举例了两个极端，一个是需要用户逐像素地点击前景，一个是只需要用户点击前景和背景的几个位置。\n之前的交互式获取matte的工作 1.jpg\r魔棒（Magic Band）\n和PS里用到的魔棒差不多，就是选择容差，选择图片中点击区域附近在容差之类的像素。但是这个容差有时不容易选择。导致结果不好。\n磁力套索（Intelligent Scissors）\n和PS里的磁力套索差不多，用户需要在前景的边缘大概地移动鼠标，选取整个前景。缺点是如果背景太复杂，用户需要的操作会很多。\nBayes matting\n对颜色概率分布进行建模，来实现一个full alpha mattes。用户要选取一个trimap。记作\\(T=\\{T_B,T_U,T_F\\}\\)，其中\\(T_B\\)标记了背景，\\(T_F\\)标记了前景。之后alpha值是在剩下的那个区域\\(T_U\\)上计算的。有时效果还是不错的，但是只有当\\(T_U\\)区域不太大，并且前背景的颜色概率分布可以很好地分开时，效果才不错。另外，需要的用户操作也不少。\nKnockout 2\n是一个PS的插件，里面用的是用户定义的trimap，总体和Bayes matting差不多。\nGraph Cut\n优化了bayes matting，同样利用了trimaps和对颜色的概率分布建模，鲁棒性很好，它甚至可以区分出环境里的迷彩服。具体在第二节才会介绍。\nLevel sets\n通过解偏微分方程来做。缺点是可能会陷入局部最优。\n作者提出的系统：grabcut 理想状态中，一个matting工具应该能够在\\(T_U\\)上计算连续的alpha值，没有强制约束的话，alpha的值可能就只会是0、1两个值。如果有连续的alpha值，那么对于烟雾、头发、树（叶）等问题应该可以自动地、近似地解决。但是作者发现，对于前景背景颜色分布容易分开的图像效果还可以，遇到迷彩这样的东西就不行。\n首先作者会在第二节和第三节介绍一个使用迭代图割（iterative graph cut）的方法来获取图像硬分割（hard segmentation）。然后在第四节border matting部分会用上通过硬分区之间的区域来计算alpha value。作者说，grabcut不处理完全透明的情况，除非是在border部分。作者建议使用matting brush来处理这种完全透明，只要没有迷彩，结果就可以很好。\n作者认为，本文的首要创新在于处理图像的分割。他们为graph cut提供了两个优化：迭代估计、不完全标记。这两个东西可观的减少了用户交互的复杂度。只需要拖拽一个矩形框柱前景。另外，也开发出了一种新的计算alpha值的机制，来用于border matting的部分。\n使用Graph Cut进行图像分割 grabcut是建立在graph cut的研究基础上的，所以有必要对此进行详细描述。\n图像分割 graph cut是用于黑白图像分割的。给定一个初始的trimap，\\(T\\)，图像是一个数组\\(z=(z_1,\\cdots,z_N)\\)，每个值都是灰度值，下标是一维的。图像的分割用一个“不透明度”的数组来表示，\\(\\underline{\\alpha}=(\\alpha_1,\\cdots,\\alpha_N)\\)表示。每个像素都有一个这种数组。一般来说\\(\\alpha_n\\)是\\([0,1]\\)上的实数，但对于硬分割来说，其取值为集合\\(\\{0,1\\}\\)。\\(0\\)代表背景，\\(1\\)代表前景。\n参数\\(\\underline{\\theta}\\)描述图像前景和背景的grey-level概率分布，也包含了灰度值的直方图。即\n\\[\\underline{\\theta} = \\{h(z;\\alpha), \\alpha=0,1\\} \\]\n其中直方图是直接用\\(T_B, T_F\\)标记的像素得来的。这里直方图进行了归一化，\\(\\int_zh(z;\\alpha)=1\\)\n图像分割的任务就是使用给定的\\(z\\)和\\(\\underline{\\theta}\\)，来推断出未知部分的不透明度数组\\(\\underline{\\alpha}\\)\n最小化能量法来进行分割 定义能量函数\\(E\\)，其值最小化的时候，得到最好的分割结果。某种意义上，这个\\(E\\)应该和前景、背景的直方图都有关，并且也和不透明度有关。反应了物体的一种稳定趋势。作者从吉布斯自由能中获得了灵感，写出了一个类似的形式：\n\\[E(\\underline{\\alpha},\\underline{\\theta},z) = U(\\underline{\\alpha},\\underline{\\theta},z)+V(\\underline{\\alpha},z) \\]\n其中，数据项\\(U\\)在给定直方图模型\\(\\underline{\\theta}\\)的情况下，评估不透明度分布\\(\\underline{\\alpha}\\)对图像\\(z\\)的拟合。定义为\n\\[U(\\underline{\\alpha},\\underline{\\theta},z) = \\sum_n-\\log h(z_n;\\alpha_n) \\]\n其中，平滑项为\n\\[V(\\underline{\\alpha},z) = \\gamma\\sum_{(m,n)\\in C}dis(m,n)^{-1}[\\alpha_n\\neq\\alpha_m]\\exp-\\beta(z_m-z_n)^2 \\]\n里面的\\([...]\\)是一个艾弗森括号。\\(C\\)是一个集合，里面的元素是邻居像素点对。\\(dis(\\cdot)\\)是邻居像素点对的欧拉距离。这种能量（指平滑项）让灰度相似的区域更加具有一致性。实践中，像素的邻居有8个。\n当常数\\(\\beta=0\\)时，平滑项就简化为著名的Ising prior（但我不知道是什么）。此时平滑项就对全图进行平滑，其程度由\\(\\gamma\\)决定。在Graph Cut的论文中指出，设置\\(\\beta\u003e0\\)更好，这可以放松对于高对比度区域的平滑，同时这里的\\(\\beta\\)可以选为\n\\[\\beta = \\bigg(2\\bigg\u003c(z_m-z_n)^2\\bigg\u003e\\bigg)^{-1} \\]\n这里\\(\u003c\\cdot\u003e\\)代表图像上样本的期望。选这个\\(\\beta\\)能够保证，平滑项可以适当的从高对比度和低对比度场景中切换。\n常数\\(\\gamma\\)取\\(50\\)，这是后面的文章通过实验得到的经验值。\n在定义完能量模型后，图像分割就可以被估计为\n\\[\\underline{\\hat{\\alpha}} = \\arg\\min_{\\underline{\\alpha}} E(\\underline{\\alpha}, \\underline{\\theta}) \\]\n这里的最小化使用最小割算法。这也是硬分割的基础。\n下一部分会介绍作者三方面的改进。首先是把黑白图像的模型，用高斯混合模型替换，从而可以用到彩色图像上。第二，执行一次最小割的算法被替换为一个迭代过程。第三，简化用户操作，只需要使用一个矩形或者一个套索来标注\\(T_B\\)\n如何用网络流为该问题建模？ 这里是GrabCut在介绍GraphCut时没有介绍到的，所以只读这篇论文我们根本不知道如何建图。\nGraphCut论文：https://ieeexplore.ieee.org/document/937505\nGraphCut的作者其实给出了更为泛用的理论，而不仅仅是黑白图像的处理。在这篇论文里，能量定义为\n\\[E(A) = \\lambda R(A)+B(A) \\]\n这里的\\(A\\)即为之前提到的\\(\\alpha\\)，是硬分割。\\(R(A)\\)是区域项，\\(B(A)\\)是边缘项。\n\\[R(A) = \\sum_{p\\in P} R_p(A_p) \\]\n\\[B(A) = \\sum_{\\{p,q\\}\\in N} B_{\\{p,q\\}}[A_p\\neq A_q] \\]\n这里的\\(P\\)是所有像素的集和。\\(N\\)是相邻像素对的集合，其中\\(\\{p,q\\}\\)是无序的。\n一般的\\(\\lambda\\geq 0\\)。\\(R(A)\\)代表着，给某个像素预测为前景和背景的惩罚。而\\(B_{\\{p, q\\}}\\geq 0\\)则是边缘差异的惩罚，两个相邻像素\\(p,q\\)，如果它们的颜色非常相近，那么\\(B_{\\{p,q\\}}\\)应该非常大；而颜色差异很大时，边缘项会非常接近\\(0\\)。\n这里只是给出了泛用的理论，具体怎么去定义这些东西，看大家的具体问题。比如GrabCut就定义了自己的两个惩罚项，本文后面也针对黑白图像定义了惩罚项。\n4.jpg\r建图是像上面一样的，其中邻居像素之间有\\(N-Links\\)，虽然它只画出来4个邻居，但是一般我们也会连上对角的邻居，作为8邻居。每个像素都和源点、汇点有一条边，称作\\(T-Links\\)。\n5.jpg\r建图如上，邻居间的\\(N-Links\\)倒是非常简单，直接就是\\(B_{\\{p, q\\}}\\)。对于\\(T-Links\\)则更难一些。\n首先要说明，求出最小割后，在源点一侧的节点是前景，在汇点一侧的节点是背景。所以，要给\\(\\{p, S\\}\\)这样的边一个误判为背景的惩罚项。图中\\(O\\)即为\\(T_F\\)，\\(B\\)即为\\(T_B\\)。如果已经由用户定义了前景和背景，那么其权值就是固定的\\(K\\)或\\(0\\)。\n在跑完最小割后，原本属于\\(T_U\\)的节点就可以根据自己属于源点部分还是汇点部分，分类到前景背景中了。\n下面我们来讨论为什么最小割可以最小化能量。割即对于图\\(G=(V,E)\\)，将点划分为\\(S\\)和\\(T=V-S\\)两个集合，其中源点\\(s\\in S\\)，汇点\\(t\\in T\\)。割的容量即为所有\\(S\\)到\\(T\\)的边的容量之和，记为\\(c(S,T)\\)。最小割即为，使得\\(c(S,T)\\)最小的割。\n首先是关于\\(N-Links\\)，显然，两个像素颜色差异越大，这里越有可能是前背景的边界，而差异大的时候边权接近\\(0\\)，所以这样的\\(N-Links\\)必然会出现在最小割中。\n然后是关于\\(T-Links\\)，一个像素如果被误判的惩罚项很大，比如前景误判为背景，那么它更有可能是前景。我们只能牺牲局部，保全大局，将误判惩罚最小的项让出去，来实现局部最优。所以这样的\\(T-Links\\)也会出现在最小割中。这里的\\(K\\)这是一样的，例如\\(\\{p,S\\}\\)中的\\(K\\)，如果一个像素已经定义为属于前景了，那么其被误判为背景的惩罚应该很大，如果一个像素已经是背景了，那么其被“误判”为背景的惩罚应该为\\(0\\)。\nGrabCut图像分割算法 这一部分也是硬分割的。\n对彩色图像数据建模 现在图像是RGB三通道的了，再像以前一样去构建灰度直方图是不切实际的（从256变成了\\(256^3=\\) 17M）。\n作者这里参考前人的工作，对前景和背景各使用一个GMM，其\\(K\\)值都等于\\(5\\)。简便起见，在优化框架框架中，添加了一个向量\\(k=\\{k_1,\\cdots,k_n,\\cdots,k_N\\}\\)，其中\\(k_n\\in\\{1,\\cdots,K\\}\\)。为每个像素分配一个不同的GMM分量，根据\\(\\alpha_n=0\\)还是\\(1\\)来确定分配前景还是背景GMM分量。\n此时，吉布斯能公式变为\n\\[E(\\underline{\\alpha},k,\\underline{\\theta},z) = U(\\underline{\\alpha},k,\\underline{\\theta},z)+V(\\underline{\\alpha},z) \\]\n现在数据项\\(U\\)变为\n\\[U(\\underline{\\alpha},k,\\underline{\\theta},z) = \\sum_nD(\\alpha_n,k_n,\\underline{\\theta},z_n) \\]\n\\[D(\\alpha_n,k_n,\\underline{\\theta},z_n) = -\\log p(z_n|\\alpha_n,k_n,\\underline{\\theta})-\\log\\pi(\\alpha_a,k_n) \\]\n其中\\(p\\)是正态分布，\\(\\pi\\)是高斯混合模型中的那个混合系数。展开有\n\\[D(\\alpha_n,k_n,\\underline{\\theta},z_n) = -\\log\\pi(\\alpha_n,k_n)+\\dfrac{1}{2}\\log\\det\\Sigma(\\alpha_n, k_n)+\\dfrac{1}{2}[z_n-\\mu(\\alpha_n, k_n)]^T\\Sigma(\\alpha_n, k_n)^{-1}[z_n-\\mu(\\alpha_n, k_n)] \\]\n此时模型的参数为\n\\[\\underline{\\theta} = \\{\\pi(\\alpha, k), \\mu(\\alpha, k), \\Sigma(\\alpha, k), \\alpha=0,1,k=1,\\cdots,K\\} \\]\n平滑项几乎没变\n\\[V(\\underline{\\alpha},z) = \\gamma\\sum_{(m,n)\\in C}[\\alpha_n\\neq\\alpha_m]\\exp-\\beta||z_m-z_n||^2 \\]\n这里的距离变成了颜色空间中的欧拉距离。\n能量最小化迭代法来进行图像分割 GrabCut使用了迭代的算法来替代Graph Cut的一次性算法。好处在于我们可以通过迭代来不断地精炼不透明度\\(\\underline{\\alpha}\\)。然后对于初始的trimap中的\\(T_U\\)部分的新标记，被用于精炼GMM的参数\\(\\underline{\\theta}\\)。算法见下图\n2.jpg\r首先是初始化部分\n用户用矩形框框选前景，那么方框外的东西就是\\(T_B\\)了，而方框内的东西都是\\(T_U\\)，即还未确定是否是\\(T_F\\) 对\\(T_B\\)内的每个像素初始化\\(\\alpha_n=0\\)，对\\(T_U\\)内的每个像素初始化\\(\\alpha_n=1\\) 然后我们就得到了属于背景的像素和属于前景的像素，这时候就可以初始化GMM的参数了。首先分别对前景和背景的像素，分别用k-means聚类为\\(K\\)类，即得到GMM中的\\(K\\)个高斯模型的元素。然后对每个高斯模型的元素计算均值、协方差，然后混合系数也可以通过计算属于第\\(k\\)个高斯模型的元素占全体元素的比例来得到。 迭代过程：\n对每个像素分配GMM中的高斯分量。\\(k_n\\)即为使得\\(D_n\\)最小的那个\\(k_n\\)，公式见上图 对于给定的图像\\(z\\)，学习优化GMM的参数。 使用最小割来进行图像分割。 重复步骤1-3直到收敛。作者指出，由于能量是一直递减的，所以一定会收敛。至少会收敛到局部最优。 应用第四节提到的border matting 用户编辑过程：\n编辑：人为地固定一些像素为背景或前景，来更新trimap，然后执行一次第3步。 重操作：（可选）重复整个迭代过程。 用户人工编辑 GrabCut是根据颜色分布和边缘来进行图像分割的，但是也有一些“不合常理”的图片。此时还是需要进行人工的编辑。\nIncomplete trimaps\n这里指的应该就是，框选前景，反过来标记背景的操作。整个迭代算法也是不对\\(T_B\\)进行retract，但是\\(T_U\\)中的像素就可以被改变为背景或前景。\nFurther user editing\n即前面描述的用户编辑过程。如果分割的图像错误地把一些东西分到了背景，则我们可以用前景刷把他们标记回来。反之亦然。\n透明度处理 一个matting的工具应该可以处理连续的\\(\\alpha\\)值。作者提出了一种机制，来使得之前的硬分隔增强为软分割，从而更好地处理物体边缘。\nBorder Matting 这个Border Matting一般是在一个闭合的曲线\\(C\\)上进行的，这条曲线一般是根据之前的硬分割的两部分的边缘组成的多边形。此时我们定义一个新的trimap\\(\\{T_B, T_U, T_F\\}\\)，这里的\\(T_U\\)定义为\\(C\\)往外扩展\\(w\\)个像素（作者使用\\(w=6\\)）。之后会使用动态规划来在\\(T_U\\)上来进行\\(\\alpha\\)值的预测。\n将曲线\\(C\\)参数化为\\(t=1,\\cdots ,T\\)，其中\\(T\\)是周期，因为\\(C\\)是闭合曲线。定义\\(t(n)\\)为\\(T_U\\)上的第\\(n\\)个像素组，这个组如下图(b)中的黑框灰色像素。\n3.jpg\r\\(\\alpha_n\\)定义为\\(\\alpha_n=g(r_n;\\Delta_{t(n)},\\sigma_{t(n)})\\)，其中\\(g\\)是一个“软”阶跃函数，见上图(c)。\\(r_n\\)是像素\\(n\\)到曲线\\(c\\)的有正负的距离，见上图(b)。\\(\\Delta,\\sigma\\)的意义见上图(c)，这里假设所有像素，如果它们的\\(t\\)相同，那么就拥有同样的\\(\\Delta, \\sigma\\)。\n\\(\\Delta, \\sigma\\)是使用动态规划来求解的。最小化如下的能量\n\\[E=\\sum_{n\\in T_U} \\widetilde{D}_n(\\alpha_n)+\\sum^T_{t=1}\\widetilde{V}(\\Delta_t,\\sigma_t,\\Delta_{t+1},\\sigma_{t+1}) \\]\n其中\\(\\widetilde{V}\\)是光滑正则项\n\\[\\widetilde{V}(\\Delta,\\sigma,\\Delta',\\sigma')=\\lambda_1(\\Delta-\\Delta')^2+\\lambda_2(\\sigma-\\sigma')^2 \\]\n它的作用是，使\\(t\\)在增加时，\\(\\alpha\\)的变化更为平滑。作者使用\\(\\lambda_1=50, \\lambda_2=10^3\\)。在DP过程中，\\(\\Delta_t\\)的值有30个levels，而\\(\\sigma_t\\)有10个levels。作者说它们的DP是线性时间的（我没看具体实现），需要两次遍历整个曲线\\(C\\)。\n数据项\\(\\widetilde{D}\\)定义为\n\\[\\widetilde{D}_n(\\alpha_n)=-\\log N(z_n;\\mu_{t(n)}(\\alpha_n), \\Sigma_{t(n)}(\\alpha_n)) \\]\n\\(N\\)即为多元高斯正态分布，其中均值和方差为\n\\[\\mu_t(\\alpha) = (1-\\alpha)\\mu_t(0)+\\alpha\\mu_t(1) \\]\n\\[\\Sigma_t(\\alpha) = (1-\\alpha)^2\\Sigma_t(0)+\\alpha^2\\Sigma_t(1) \\]\n这里的\\(\\mu_t(x),\\Sigma_t(x),x=0,1\\)是从前景和背景中的像素样本估算来的。前景\\(F_t=S_t\\cap T_F\\)，背景\\(B_t=S_t\\cap T_B\\)，这里\\(S_t\\)是一个矩形区域，即曲线\\(C\\)上的某个点\\(t\\)扩张\\(L\\)个像素得到的\\(L\\times L\\)区域，作者取\\(L=41\\)\n前景估计 作者指出，之前的Bayes matting方法，会有背景的颜色渗出到前景中的问题。作者这里通过从\\(T_F\\)中借用像素，来避免这个问题。\nBayes matting从\\(n\\in T_U\\)中预测得到一个前景色\\(\\hat f_{n}\\)。根据之前定义的\\(F_{t(n)}\\)，可知\\(\\hat f_n\\)会和借用的\\(f_n\\)很相似。\n其他思考内容 GMM换成彩色直方图会怎么样？ 以我自己的实验经验来说，\\(256^3\\)的内存空间还是放得下的，但显然不是内存的原因，才导致作者不去使用颜色直方图。我实际测试过，其效果比较差。如果你定义某个像素属于前景和背景的概率，仅仅考虑该像素颜色在直方图中的概率的话，只会有很少的像素被去除。如果你定义该概率为该像素RGB都\\(\\pm 5\\)的这个范围内的概率和，则计算量就爆炸了，而且效果也不好。\n其主要的问题在于，颜色在色彩空间中分布过于分散，计算概率的效果不好。\n彩色直方图的其他优化方法 https://mmcheng.net/zh/salobj/\n这篇文章中，作者指出，一张照片的绝大多数颜色（95%）都是相近的，可以将颜色空间简化到\\(12^3\\)，即\\(L*a*b*\\)每个通道都简化为\\(12\\)个值。然后通过进一步的统计，选择其中出现次数最多的\\(85\\)个颜色，来覆盖\\(95\\%\\)的图片色彩。\n当然，为了应对剩下的那\\(5\\%\\)，使用与其最近的颜色替代。作者也提出了一个色彩空间平滑的操作，来解决噪声问题。有机会再来精读这篇文章。\n我的实现 https://github.com/kegalas/GrabCut\n","date":"2024-05-20T11:21:12+08:00","image":"https://kegalas.top/p/grabcut-interactive-foreground-extraction-using-iterated-graph-cuts%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%E4%B8%8E%E5%A4%8D%E7%8E%B0/cover_huf62d2c95a51769be2a7aa0d894297a77_82581_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/grabcut-interactive-foreground-extraction-using-iterated-graph-cuts%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%E4%B8%8E%E5%A4%8D%E7%8E%B0/","title":"GrabCut— Interactive Foreground Extraction Using Iterated Graph Cuts论文精读与复现"},{"content":"为了应对面试官的拷打，写下此文，方便我复习这个数据库的实现方法。\nProject 1 Task 1 这一部分主要是要求实现一个LRU-K的替换算法。\nLRU是最近最少使用算法，也就是把buffer里面，上次使用时间距离现在最远的元素换出去。但是LRU的问题在于，如果有很多“偶发性”数据访问，即只访问一两次的数据，那么LRU会替换掉几乎所有元素，从而降低命中率。\nLRU-K的想法是，访问过K次及以上的数据和其他数据分开来算。显然，前者是更需要放在缓存里的，而后者是“偶发性”数据。\n这里同样定义了距离，当访问次数大于等于\\(K\\)时，该元素的距离为当前时间点减去之前的第\\(K\\)次访问的时间点。如果一个元素的访问次数不足\\(K\\)，则距离无限大。换出的规则仍然是，把距离最大的元素换出。如果有多个元素距离无限大，则把最近访问最远的那个元素换出。相当于对它们进行朴素的LRU。\n下面具体解析一下在src/include/buffer/lru_k_replacer.h里面的东西的作用\nLRUNode：这里记录我们刚刚提到的元素的信息。其中： history_记录了最近的至多\\(K\\)次访问的时间戳，表头为最远的，表尾为最近的。 k_代表累计有几次访问，最大等于LRU-K算法设定的\\(K\\)值，不能超过。 fid_代表在buffer pool中的帧号，其作用在于通过帧号找到页号，具体会用在buffer pool中。 is_evictable_，为真时代表此元素可以换出。 LRUKReplacer：这个就是具体实现LRU-K的地方。 先看看它的成员变量： node_store_，用于存储帧号对应的LRUNode。 current_timestamp_用于记录现在的时间戳，不需要用unix时间戳什么的，我们只要每次访问后将其加一即可。 curr_size_指的是目前有多少个evictable的帧。 replacer_size_指LRU-K能容纳多少Node k_即代表LRU-K中的\\(K\\)值。 latch_即我们使用的互斥锁。 再来看看成员函数： 构造析构略 Evict指换出一个帧，参数为换出的帧其帧号的指针，返回真时换出成功，否则换出失败。换出规则即之前介绍的规则。 RecordAccess记录给定帧的一次访问。每次访问都要增加current_timestamp_，如果不在node_store_中还需要新建。然后修改frame_id对应的node的数据，包括k_和history_。如果已经有\\(K\\)次访问了，还需要注意不要自增超过\\(K\\)，以及history_不要多于\\(K\\)个记录。 SetEvictable即修改给定帧的可换出属性，同时会影响curr_size_的值。 Remove即删除给定帧的访问记录。注意只有evictable的帧才能换出。同时会影响curr_size_的值。 这里面所有的frame_id的范围都在[0,replacer_size_)中，否则为非法访问。\nTask 2 这里要求实现一个磁盘调度算法。不过这个算法并不高深，就是一个简单的FIFO，使用一个并发安全的队列实现。\nsrc/include/storage/disk/disk_scheduler.h中，有：\nDiskRequest：代表一次磁盘访问的属性，包括 is_write_即是读还是写 data_一个指针。读磁盘时，指向要读入的内存数组的开头。写磁盘时，指向要写入的内存数组的开头。大小是固定的，为Page的大小，在bustub中为4096，不足的都会补0 page_id_即写入磁盘的第几页。在后面会详细介绍，我们只用知道bustub的xxx.db文件是一页一页顺着排列的就行。页号从0开始。 callback_一个线程同步的变量，后面（task 3）介绍。 DiskScheduler：即实现磁盘调度算法的部分 其成员变量有： disk_manager_磁盘调度算法要向其发送磁盘操作请求，之后介绍 request_queue_即FIFO算法所用到的队列 background_thread_即在后台不断把队列里的请求拿出来，发送给disk_manager的线程 其成员函数有： 构造函数，在构造的时候，就启动了background_thread_线程，其执行StartWorkerThread Schedule，即简单地把一个DiskRequest放入队列中 StartWorkerThread，可以看作是生产者-消费者模型中的消费者。其不断地从队列中拿出请求，向disk_manager_发送对应请求，然后将callback_赋值。无限循环直到拿出的请求是一个std::nullopt（队列中存的是std::optional\u0026lt;DiskRequest\u0026gt;） 析构函数，主要负责向队列中放入nullopt，让其停止。然后和后台的线程进行join 这个队列在这个项目里是已经提供好了的，不需要自己实现。不过为了防止被面试官拷打，我们来解析一下这个队列的实现方式。其被称作Channel，在src/include/common/channel.h。其底层是STL的queue，在此基础上加入了一个互斥锁和一个条件变量。只支持两个方法，即Put在队尾放入元素，Get取出队头元素（相当于front和pop二合一）。实现也非常经典，值得抄下来学习\nvoid Put(T element){ std::unique_lock\u0026lt;std::mutex\u0026gt; lk(m_); q_.push(std::move(element)); lk.unlock(); cv_.notify_all(); } T Get(){ std::unique_lock\u0026lt;std::mutex\u0026gt; lk(m_); cv_.wait(lk, [\u0026amp;](){return !q_.empty()}) T element = std::move(q_.front()); q_.pop(); return element; } 然后我们来看看DiskManager具体怎么访问硬盘的。抛去一些不重要的，有这些成员变量：\ndb_io_，它是一个std::fstream，至此真相大白，根本没有什么更底层的东西，只是一个STL自带的文件流而已。 file_name_，数据库文件的名字。 db_io_latch_，在硬盘读写的时候持有锁，防止冲突。 再来看看其中比较重要的几个成员函数：\n构造函数，传入文件名，打开fstream。 WritePage，传入页号，以及data的指针。前面也提到过，bustub的数据文件就是把页顺序排列，我们知道页号、知道页大小，就知道页的开头在文件中的位置。这里需要使用fstream的seekp先定位，然后再write写出数据。 ReadPage，传入页号，以及data的指针。基本上同上。只是需要注意，如果文件的最后一页不足4096，那么需要在内存中把后面全部填充0 Task 3 这里就是真正实现buffer pool的地方。buffer pool对于数据库的作用，类似于cache对于cpu的作用。cpu一般是先把内存中的东西放到cache中，然后之后读取就会更快了。基于空间局部性和时间局部性，虽然cache比内存小，但是也可以提升访问速度。而buffer pool所做的，就是把磁盘中的东西拿到内存。\nbuffer pool中的东西分为两部分，第一部分是Project 1中实现的，其只实现了基本的操作。而Project 2中实现的下半部分主要是负责更好的自动控制，不再需要手动进行Unpin等操作，解放程序员。\n还是先介绍BufferPoolManager（src/include/buffer/buffer_pool_manager.h）中的成员变量：\npool_size_，代表这个buffer pool中能容纳多少个page。LRUKReplacer的大小将会和它一致 next_page_id_，其为一个std::atomic\u0026lt;page_id_t\u0026gt;，也就是说可以并发地访问。其中page_id_t在这里定义为了uint32_t。之后创建一个新页的时候需要用到这个值。 pages_，一个数组，用于存放所有page的 disk_scheduler_，即task 2实现的东西 page_table_，通过页号找到帧号 replacer_，即我们的LRU-K算法 free_list_，其最初的大小等于pool_size_，存储了所有空闲的帧的帧号 latch_，自己的互斥量。 成员函数：\n构造函数，主要就是传入大小、\\(K\\)值，DiskManager等。这里要初始化pages_ = new Page[pool_size_]，初始化replacer_，同时把所有帧号放到free_list_里 析构函数，主要进行delete[] pages_ NewPage，分配一个新页，返回这个新页的指针，新页的页号通过参数中的指针返回。由于我们是在内存中分配新页的，所以要先找一个位置，如果有空闲的帧就直接获取一个帧号，否则换出一个帧到硬盘上（即判断是否为脏页，为脏则要向DiskManager发出一个写请求，然后从page_table_中删掉这一项。否则直接从page_table_中删掉。这里删除的时候，需要auto future = r.callback_.get_future()，然后再发送请求，然后future.wait()，这样在删除完成之前就会被阻隔，从而线程同步。），然后继续使用这个换出的帧号。在pages_数组上，直接对这个元素进行初始化。例如重置数据、分配页号、设置脏位、设置pin_count_。然后写入page_table_，并在replacer_中记录一次访问，以及设定evictable为false。这里可能所有页面都被设置为不能换出，这里要返回nullptr FetchPage，根据页号获取一个页。这个页可能已经在buffer pool里了，那么直接读这个页。否则，要去硬盘里找。同前，有空闲帧就分配、否则换出，等等操作。在之后，我们要给这个page的pin_count_加一，表明又有一个新的线程在访问这个页。以及，同样地更新page_table_、replacer_等。 UnpinPage，一个线程不再需要这个页时，需要将其unpin，也就意味着对应的pin_count_减一。同时UnpinPage的参数里会带有is_dirty，用于标注这个页的脏位。注意，如果页不在buffer pool里，或者pin_count_已经归零，就不需要进行操作了。页的这些元信息只存在于内存中，硬盘中只有data，所以pin_count_不需要从硬盘里拿出来减一。如果成功进行了减一，并且计数器归零，就可以在replacer_中把evictable设置为true了 FlushPage，给定页号，无论是否为脏页，都写回硬盘中。之后设置为非脏页。其他信息不做改动。 FlushAllPages，刷新所有页。 DeletePage，这里说的不是删掉硬盘上的页。是删掉buffer pool中的页，并标记为空闲帧。当然，如果给出的页号本来就不在buffer pool里，则什么改动都不做。删除的时候已经假定引用计数归零了，所以如果非零，则是非法操作。需要从page_table_、replacer_中删掉相应的元素。然后插入到free_list_中，把原来pages_这个位置上的页元信息重置。 AllocatePage，其实就是分配了一个新页号return next_page_id_++ DeallocatePage，这就是个空函数，bustub里根本不考虑这个。 之后我们来关注一下这个Page里面都有什么东西，在src/include/storage/page/page.h中，成员变量：\ndata_，一个指针，和读写硬盘的那个data指针类似，就是指向一个数组的头。大小固定为4096，即页大小。在构造函数中分配内存。析构中释放。 page_id_，页号。 pin_count_，表示有多少线程正在使用这个页。 is_dirty_，脏位。 rwlatch_，读写锁。实际上是用std::shared_mutex实现的，写的时候进行lock()和unlock()，读的时候进行lock_shared()和unlock_shared()。 成员函数可说的反而不多，除了一大堆getter和setter、读写上锁之外，有：\nResetMemory，就是一个memset，把data_的内容初始化。 这里面还有两个叫GetLSN和SetLSN的函数，不知道干嘛的，整个项目里倒也没用过这两个函数。\nProject 2 Task 1 在上一部分，我们实现的BufferPoolManager实现的比较底层的操作。程序员需要手动创建页、获取页、删除页、Unpin页。本部分要求我们，实现一个wrapper，能够在构造的时候获取页，析构的时候Unpin、删除页。同时，实现要求我们保证并发安全，我们也要自动地控制锁。\n首先关注src/include/storage/page/page_guard.h，其中有三个类：\nBasicPageGuard ReadPageGuard WritePageGuard 这三个类都是独占资源的类，所以类似于unique_ptr，它们的拷贝构造和拷贝赋值被禁用了。看看它们的成员变量：\nBasicPageGuard bpm_指向一个BufferPoolManager的指针 page_指向自己所管理的页的指针 is_dirty_脏位 ReadPageGuard guard_是一个BasicPageGuard。本类的成员函数的实现方式，使得本页只读，后面介绍。 WritePageGuard guard_是一个BasicPageGuard。本类的成员函数的实现方式，使得本页可读写，后面介绍。 看看它们的前几个成员函数：\nBasicPageGuard 默认构造函数，其传入bpm和page指针来初始化。 移动构造函数，把另外一个guard的page_，is_dirty_，bpm_全部都移动过来，之前的清空。 Drop，即废弃掉这个页，或者说放弃控制权。这里就需要调用bpm_中的UnpinPage了，传入自己的页号和脏位。之后再把成员变量清空。 移动赋值函数，和移动构造类似，但是要先把自己的资源Drop掉，再去考虑移动的事。 析构函数，可以直接调用Drop ReadPageGuard 默认构造函数，传入的也是bpm和page指针，其用来初始化guard_成员。其实我不是很明白这里为什么没有上读者锁（项目原版的代码），可能是因为项目里根本没有地方直接构造ReadPageGuard吧。 移动构造函数，我们只用移动guard_即可。虽然我写了先把that解锁再把this加锁，但我想了一下好像没有必要，甚至可能是错的。不过评测没有问题。 Drop，废弃页。注意如果this已经有一个页，需要先解锁，然后再Unpin。之后再把guard_的信息清空。如果弄反了，可能Unpin后页立刻换出，然后我们再解锁，解锁的就是其他页的锁了。 移动赋值函数，同前，如果需要，先考虑Drop掉自己。 析构函数，调用Drop WritePageGuard，和ReadPageGuard基本一样，只不过加锁的时候加的是写者锁。 前面也提到，一般不会直接调用ReadPageGuard和WritePageGuard的默认构造函数，我们会通过BasicPageGuard中内置的两个函数来“升级”成另外两个：\nUpgradeRead，首先给page_上读者锁，然后记录下page_和bpm_的指针，清空自己的成员变量，调用默认构造函数返回一个ReadPageGuard UpgradeWrite，同上，只不过上的是写者锁。 这三个类还有几个读取数据的成员函数\nBasicPageGuard PageId，获取page_的页号 GetData，获取page_的data_指针，一个const char *，也即不可修改内容 As，将GetData中获得的指针转化为另一个类型的指针，即const T * GetDataMut，同GetData，只不过将is_dirty_设置为true，返回char * AsMut，将GetDataMut获得的指针转为T * ReadPageGuard，只包含PageId，GetData，As WritePageGuard，包含全部五个函数。 之后我们回到src/include/buffer/buffer_pool_manager.h中，解决上个Project的遗留问题\nFetchPageBasic，首先调用自己的FetchPage获取页号，然后调用BasicPageGuard的默认构造函数构造，然后返回 FetchPageRead，调用FetchPageBasic后进行UpgradeRead，返回 FetchPageWrite，类似于上条。 NewPageGuarded，类似于第一条，使用NewPage的页号。 Task 2 从这里开始要求我们实现一个可扩哈希。我们先把可扩哈希的原理说明一下，从一张图开始\n1.jpg\r首先可以看到，它是一个三层结构。第一层是header，其大小固定。第二层是directory，其大小可以变化，从只有一项，到大小上限。而第三层是bucket。\nheader的每一项指向了一个directory（当然如果没有数据的话就指向空指针），而directory的每一项指向了一个bucket，数据实际上是存在bucket里。所以，如果我们要读写一个数据，我们要经过以下步骤：\n找到该数据对应与header中的哪一项。 从header的这一项中找到其对应的directory，然后在找到该数据对应该directory中的哪一项 从directory中的这一项找到其对应的bucket，然后在bucket中遍历（bucket可以看做是固定大小的数组），找到所需的数据位置。 具体是根据什么方法来找的呢？\n首先，我们会获得该数据的哈希值。假设我们这里得到的哈希值是一个32位无符号整数，那么，根据header的max_depth，提取出哈希值的高max_depth位。如上图，其max_depth为\\(2\\)。如果我们的哈希值是01...111，那么就要映射到header中的第1项（从0开始计数）。如果是10...111就映射到第2项，以此类推。\n接下来，我们在对应的directory里，根据其global_depth，找到哈希值的低global_depth位。例如在global_depth为\\(2\\)时，01...111就映射到directory的第3项。\n可扩哈希具体指的是哪里可扩呢？实际上指的是directory可扩。我们画个简单的情况来介绍：\n2.jpg\r如图，我们省去了header，并且现在directory的global_depth的大小为0，也就是只有第0项。我们这里假设bucket大小为\\(2\\)。这里我们有一个放了两个数据的bucket，这里用哈希值表示数据。\n整个directory有一个global_depth，主要是代表项数，也用来找哈希值对应的bucket。而每一项，有一个local_depth，代表的是，该项指向的bucket中，保证所有数据的哈希值最低的local_depth位是相同的。上图中，local_depth为0，即没有一位是保证相同的。\n如果我们要再插入一个数据（假设是...10）到其中，怎么做呢？这里显然已经插入满了，所以我们要扩容。首先，把global_depth加一，同时directory的大小也就增加了（大小为\\(1\u003c\u003c{global\\_depth}\\)），所以我们要增加directory的项数，其还是指向这个bucket。\n3.jpg\r现在，directory的global_depth是1，而两项的local_depth都是0。观察我们要插入的数据...10，其最低1位是0，所以要插入第0项。而第0项指向的bucket仍然是满的。所以我们现在要把bucket分裂。如下：\n4.jpg\r这里分裂的时候，需要按照directory的映射关系，将bucket的数据分别放到相应的新bucket中。这里，我们就可以增加local_depth了，都是1。然后我们再插入数据...10，就可以正常插入了。\n5.jpg\r再例如下图\n6.jpg\r我们插入...100，和之前一样，我们需要先扩容directory\n7.jpg\r这里global_depth变成了2，写在了上方。而local_depth都是1，写在左边。然后我们的数据...100是映射到第0项，其bucket是满的，所以要分裂bucket，再插入，如下\n8.jpg\r目前为止，插入和查询就说明白了。删除数据放到之后再说，先来看看代码，首先是src/include/storage/page/extendible_htable_header_page.h\n首先，源代码注释中给出了这个page的布局\n/** * Header page format: * --------------------------------------------------- * | DirectoryPageIds(2048) | MaxDepth (4) | Free(2044) * --------------------------------------------------- */ 这里我们也可以知道，无论是header、directory还是bucket，都是作为一个页存在硬盘上的。大小都依然是4096。\n这段注释指出，header存储的数据有两个，一个是MaxDepth，一个是表项。通过阅读后面的代码可知，这个类有两个成员变量。\npage_id_t directory_page_ids_[HTABLE_HEADER_ARRAY_SIZE]; uint32_t max_depth_; 表项是用一个数组来表示的，其类型为page_id_t，被using page_id_t = uint32_t定义。而另一个就是代表表的最大大小。因为uint32_t是4字节的，而DirectoryPageIds占2048字节，所以最多有512项。这里也说明，实现上表项不是一个指向directory的指针，而是存储了对应的页号，找到directory需要读取硬盘上的另一个页。\n接下来我们看看其中定义的三个静态变量\nstatic constexpr uint64_t HTABLE_HEADER_PAGE_METADATA_SIZE = sizeof(uint32_t); static constexpr uint64_t HTABLE_HEADER_MAX_DEPTH = 9; static constexpr uint64_t HTABLE_HEADER_ARRAY_SIZE = 1 \u0026lt;\u0026lt; HTABLE_HEADER_MAX_DEPTH; 第一个定义了元信息的大小，第二个定义了bustub默认的max_depth，第三个定义了默认的表大小。接下来我们看ExtendibleHTableHeaderPage的成员函数\n所有构造函数和析构函数都被禁用了，根据代码的注释说这样是为了保证内存安全。我水平不够暂时不了解原理。 Init，传入max_depth，让我们对header进行初始化。我们照做即可，注意表项要全部初始化为INVALID_PAGE_ID，代表没有指向任何一个directory HashToDirectoryIndex，传入32位无符号整数的哈希值，找到对应的表项。就像我们之前说的一样，找到高max_depth位就行。return hash\u0026gt;\u0026gt;(32-max_depth_);。可能要特殊处理0深度的情况。 GetDirectoryPageId，传入表项下标，返回页号。说白了就是根据数组下标返回数组元素。 SetDirectoryPageId，说白了就是根据数组下标设置元素。 MaxSize，返回表大小。 之后，我们来看src/include/storage/page/extendible_htable_directory_page.h，首先同样是看page的布局\n/** * Directory page format: * -------------------------------------------------------------------------------------- * | MaxDepth (4) | GlobalDepth (4) | LocalDepths (512) | BucketPageIds(2048) | Free(1528) * -------------------------------------------------------------------------------------- */ 存储了四种数据，首先是max_depth_，代表global_depth_的上限，然后就是global_depth_自己，用于表示directory现在的大小，以及用于映射关系。之后是local_depths_，这是一个数组，每个元素都是8位无符号整数，代表对应表项的local_depth，可知最多有512个表项。最后的bucket_page_ids_也是一个数组，类型为page_id_t的数组，存储表项对应的bucket的页号。\nstatic constexpr uint64_t HTABLE_DIRECTORY_MAX_DEPTH = 9; static constexpr uint64_t HTABLE_DIRECTORY_ARRAY_SIZE = 1 \u0026lt;\u0026lt; HTABLE_DIRECTORY_MAX_DEPTH; 静态变量和之前相似。接下来我们看看成员函数\n所有构造函数和析构函数都被禁用 Init，传入max_depth，初始化max_depth_，global_depth，以及各个表项的信息。 HashToBucketIndex，传入32位无符号哈希值，算出对应第几个表项。从前面的讨论可以得到，取hash % (1\u0026lt;\u0026lt;global_depth_)即可。 GetSplitImageIndex，传入下标，获得其镜像bucket的下标。这里的镜像bucket指的是，前面进行directory扩容时，表项会翻倍，指向同一个bucket的表项数也会翻倍。每一个旧表项都会有一个新表项与它指向同一个bucket。这两个表项互为镜像。该项的local_depth已知，则当local_depth为零时，镜像为自己。否则镜像下标为bucket_idx ^ (1\u0026lt;\u0026lt;(local_depth-1))。无非是翻转一个二进制位。 IncrGlobalDepth，我这里把扩容操作一起做进来了。具体来说，假设原来的大小是sz，那么，global_depth_++之后，新的大小变为sz*2。其中的表项有element[sz+i]=element[i]，顺着复制表项即可。 DecrGlobalDepth，这里只需要global_depth_--。因为具体的缩容操作更复杂，需要在bucket层面才能执行。这里不需要清空数组多余的部分。 CanShrink，具体怎么缩容后面再说。这里只要记住，所有的local_depth都小于global_depth，则可以缩容。 省略掉了一些简单的getter和setter。\n之后，我们来看src/include/storage/page/extendible_htable_bucket_page.h，首先同样是看page的布局\n/** * Bucket page format: * ---------------------------------------------------------------------------- * | METADATA | KEY(1) + VALUE(1) | KEY(2) + VALUE(2) | ... | KEY(n) + VALUE(n) * ---------------------------------------------------------------------------- * * Metadata format (size in byte, 8 bytes in total): * -------------------------------- * | CurrentSize (4) | MaxSize (4) * -------------------------------- */ 首先是METADATA，八个字节组成，分别是bucket的当前大小和最大大小。之后就是实际存储的键值对（KV）。每个键值对的键和值的大小不定（括号后面的是序号），具体存的什么数据，之后会介绍。\n直接来看成员函数\n所有构造函数和析构函数都被禁用 Init，负责初始化max_size_和size_ LookUp，传入key和比较key的比较函数，查找这个bucket里有没有key相等的元素，返回value。（本课程不考虑key冲突，也不考虑multimap这样的情况） Insert，传入key, value, cmp，插入到bucket中，只要key没出现过并且空间还有空闲就可以插入。 Remove，传入key, cmp，删除key对应的元素。注意，删除的时候，要把后面的所有元素往前移动一个来填补空缺。因为我们的插入是顺着插入，找到第一个空闲就插入。 省略掉其他的getter和setter，现在我们来讨论一下，它bucket里面的KV究竟是在存什么。\n在extendible_htable_bucket_page.cpp中，代码末尾有：\ntemplate class ExtendibleHTableBucketPage\u0026lt;int, int, IntComparator\u0026gt;; template class ExtendibleHTableBucketPage\u0026lt;GenericKey\u0026lt;4\u0026gt;, RID, GenericComparator\u0026lt;4\u0026gt;\u0026gt;; template class ExtendibleHTableBucketPage\u0026lt;GenericKey\u0026lt;8\u0026gt;, RID, GenericComparator\u0026lt;8\u0026gt;\u0026gt;; template class ExtendibleHTableBucketPage\u0026lt;GenericKey\u0026lt;16\u0026gt;, RID, GenericComparator\u0026lt;16\u0026gt;\u0026gt;; template class ExtendibleHTableBucketPage\u0026lt;GenericKey\u0026lt;32\u0026gt;, RID, GenericComparator\u0026lt;32\u0026gt;\u0026gt;; template class ExtendibleHTableBucketPage\u0026lt;GenericKey\u0026lt;64\u0026gt;, RID, GenericComparator\u0026lt;64\u0026gt;\u0026gt;; 这样的模板特化。首先我们知道了，KV中的V是RID（第一个除外，应该只是用来调试的）。什么是RID？实际上，又可以看做是一种指针。RID存储了两个成员变量page_id_和slot_num_，也就是说，具体的数据是存在别的页中，存在序号为slot_num_的部分。这一部分具体可以阅读src/include/common/rid.h\n然后是前面的GenericKey\u0026lt;\u0026gt;是什么？他其实是一个包装的数组，当作哈希值来使用。这个数组里面可以存我们数据库里的具体的数据（称作Tuple，以后再说），也可以直接存整数值（仅用于测试意义）。GenericKey\u0026lt;4\u0026gt;代表数组长度为4（数组类型为char[]）。具体可见src/include/storage/index/generic_key.h。\n同样的这个文件里，定义了GenericComparator\u0026lt;\u0026gt;，具体做的事就是比较GenericKey\u0026lt;\u0026gt;之间的大小关系，当然，也就是通过比较数组，或者说比较Tuple来实现的。\n","date":"2024-04-29T14:09:51+08:00","image":"https://kegalas.top/inferior/cmu154452023fall%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%84%E4%BB%B6%E5%8A%9F%E8%83%BD%E9%80%9F%E6%9F%A5/cover_hub2bee36093f48e478e5566d6bf8cc572_110686_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/cmu154452023fall%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%84%E4%BB%B6%E5%8A%9F%E8%83%BD%E9%80%9F%E6%9F%A5/","title":"CMU15445(2023 Fall)数据库组件功能速查"},{"content":"参考自https://gist.github.com/elieux/ef044468d067d68040c7\n但是他那个时候还没有ucrt64，所以我略作修改如下。\n首先是添加注册表项：\nWindows Registry Editor Version 5.00 [HKEY_CURRENT_USER\\Software\\Classes\\Directory\\Background\\shell\\MSYS here\\command] @=\u0026#34;G:\\\\Program_Files\\\\msys64\\\\msys2.exe bash\u0026#34; [HKEY_CURRENT_USER\\Software\\Classes\\Directory\\Background\\shell\\UCRT64 here\\command] @=\u0026#34;G:\\\\Program_Files\\\\msys64\\\\ucrt64.exe bash\u0026#34; [HKEY_CURRENT_USER\\Software\\Classes\\Directory\\Background\\shell\\MINGW64 here\\command] @=\u0026#34;G:\\\\Program_Files\\\\msys64\\\\mingw64.exe bash\u0026#34; [HKEY_CURRENT_USER\\Software\\Classes\\Directory\\Background\\shell\\CLANG64 here\\command] @=\u0026#34;G:\\\\Program_Files\\\\msys64\\\\clang64.exe bash\u0026#34; 这里面的路径记得改成自己的安装路径。\n然后是删除\nWindows Registry Editor Version 5.00 [-HKEY_CURRENT_USER\\Software\\Classes\\Directory\\Background\\shell\\MSYS here] [-HKEY_CURRENT_USER\\Software\\Classes\\Directory\\Background\\shell\\UCRT64 here] [-HKEY_CURRENT_USER\\Software\\Classes\\Directory\\Background\\shell\\MINGW64 here] [-HKEY_CURRENT_USER\\Software\\Classes\\Directory\\Background\\shell\\CLANG64 here] 当然，我自己觉得这样比较丑。因为右键菜单是会按照字母顺序排序的，这样这四个就不在一起了。我个人是想加一个二级菜单把它们放一起的，这个TODO。\n","date":"2024-01-15T22:40:43+08:00","permalink":"https://kegalas.top/inferior/%E6%B7%BB%E5%8A%A0msys2%E5%88%B0%E5%8F%B3%E9%94%AE%E8%8F%9C%E5%8D%95/","title":"添加msys2到右键菜单"},{"content":"概论 除了老师在课上的PPT课件，我还参考了人民邮电出版社的《操作系统导论》中的内容。本笔记也会像书中一样分为三大板块，但是也会介绍一些其他内容例如系统安全。另外本课程讲的实在过于浅显，我之后可能会专门写《操作系统导论》的笔记。\n什么是操作系统？ 对于高层应用程序的程序员来说，操作系统就是一个扩展的机器，其隐藏对于硬件的操作的具体实现，提供简单易用的API、虚拟机等给程序员使用。\n对于开发系统内核的程序员来说，它是一个资源管理器，负责管理CPU的分时复用、存储器的使用等等。协调各种程序的运行。\n对于普通使用者来说，操作系统是用户使用计算机的界面（UI）。\n比较正式地说，操作系统是控制和管理计算机硬件和软件资源、合理地组织和管理计算机的工作流程以方便用户使用的程序的集合。\n1.jpg\r2.jpg\r引入操作系统的目的 方便：给用户提供一个硬件接口，易于操作 有效：以有效的方式使用软硬件资源 改善性能：组织计算机的工作流程，改善系统性能 提供扩展能力：方便引进新的功能 现代操作系统的特征 按照《操作系统导论》来说是虚拟化、并发、持久性。下面是PPT中的，个人感觉它没涉及持久性。\n并发（concurrency） 并发指多个事件在同一时间段内发生。单个CPU核其实只能单独执行一个进程（即串行），我们可以让多个进程交替进行，只要交替得够快，宏观上就像在并发。OS就要完成这些并发过程的管理。\n程序的静态实体是可执行文件，动态实体是进程，并发是进程在并发。\n并发与并行（parallel）不同，并行是不存在交替过程的，是真正的同时进行。\n共享（sharing） 计算机中的有限资源不再为某个用户独占，而是可以多个用户共享。OS就负责管理共享的时候如何分配管理。\n有两种共享：\n互斥共享。同一时间内某个资源只能最多有一个用户使用，使用完后别的用户才能用。例：打印机 非互斥共享。同一时间内某个资源可以有多个用户“同时”使用。同时并不是并行意义上的，而是并发意义上的。例：CPU、内存。 虚拟（virtual） 在并发的时候，切换执行的进程对进程本身是不可见的，它们都以为自己完整地占用了CPU。也就是说，一个物理CPU被虚拟化成多个逻辑CPU，每个进程一个。\n虚拟分成分时复用（CPU）和分空间复用（存储器）。\n不确定性（uncertainty） 也称为异步性（asynchronism）。指多个进程并发时，执行顺序的不确定，导致结果的不确定。\n虚拟化 虚拟化主要分为虚拟化CPU和虚拟化内存。虽然虚拟化CPU会提到进程和并发的基础概念，但是这里主要讲进程调度，并发部分会主要讲锁。\n进程 基本概念 程序的并发执行使得程序的执行成为一个动态的过程。程序更像是描述一个静态的可执行文件，于是引入进程来描述动态执行的程序。\n这些并发的进程的特性为：程序执行的间断性；资源共享；独立和合作（制约）性。\n进程，直观地定义的话，就是执行中的程序。该进程可与其他进程并发执行；它是一个动态的实体，既是资源的基本分配单元，也是基本的执行单元。\n进程与程序的区别\n程序是静态的，是有序代码的集合。进程是动态的，是程序的一次执行。 程序是永久的，没有生命周期。进程是暂时的，有生命周期，会不断变化。 进程是操作系统资源分配和保护的基本单位，而程序不是。 进程与程序的结构不同 进程与程序的联系\n通过多次执行，一个程序可以对应多个进程。 通过调用，一个进程可以包括多个程序。 3.jpg\r组成成分 4.jpg\rPCB包含的信息有：进程ID、用户ID、创建时间、父子进程关系等标识信息。CPU寄存器内容等现场信息。持有句柄、进程状态、信号量、调度信息、优先级等控制信息。\n进程控制 OS对进程的控制和管理是通过操作系统内核中的原语实现的。\n原语指的是原子操作，即该操作要么完全进行了，要么根本不进行，不存在进行了一半被打断的情况。原语的原子性主要是通过屏蔽中断保证的。\n原语主要分为：进程控制原语、进程通信原语、资源管理原语、其他。常见的有：创建、撤销、阻塞、唤醒、挂起、激活等。\n进程主要有三种状态\n5.jpg\r6.jpg\r进程调度 进程调度关注的问题是：当有多个进程/线程准备就绪时，先执行哪一个？这又有两个子问题，什么时候进行这个决策？如何决策？\n可能会涉及调度的情况：\n进程生成 进程退出 用户进程调用一个用户自己定义的函数 进程在IO上被阻塞 IO中断 设计算法的时候，要同时考虑到系统和用户。对于系统来说，需要有公平性（不会有进程被饿死）和较大的吞吐量。对于用户来说，需要有及时性和较短的周转时间。\n周转时间为\n\\[T_{周转时间}=T_{完成时间}-T_{到达时间} \\]\n而响应时间为\n\\[T_{响应时间}=T_{首次运行}-T_{到达时间} \\]\n抢占式和非抢占式\n非抢占式调度意味着，一旦某个进程开始运行，那么直到该进程放弃CPU之前，操作系统只能干看着，无论后面有什么进程在等待。\n抢占式意味着，操作系统非常愿意停止一个进程，然后运行新的进程，只要它觉得有必要。\n先来先服务算法（FCFS） 也就是FIFO，也就是队列。让最早开始等待的进程占用CPU。非抢占式。\n其有公平性，但是吞吐量、及时性、周转时间都很差。\n最短任务优先（SJF） 就和小学经典的排队节水问题一样，接水最少的人最先。这里也是，执行时间最短的任务最先。\n可以证明，如果所有任务同时到达，SJF是最优的调度算法（周转意义上）。但是没有这个前提，任务随机地在某个时间点到达（贴近现实），则可能会很差。比如一个超长的任务先到达，过了一两秒后两个很短的任务到达，那么这两个任务就会等很久，造成周转时间长。\n这是一个非抢占式算法。\n但是考虑到公平性，一个进程可以反复发起短时间的占用，最终占用了长时间的CPU。所以并不公平。\n另外我们几乎不可能知道一个进程要占用多长时间。\n最短完成时间优先（STCF） 在SJF最后的问题中，可能会立刻想到一个抢占式的算法，即让完成最快的任务先进行。显然是抢占式的。\n可以证明，STCF在周转意义上是最优的。其他缺点同SJF。\n基于优先数的调度算法 其给每个进程设置一个优先级，系统在调度的时候优先选择高优先级的进程。如果有相同的优先级则按照FCFS。\n优先级有两种确定方法\n静态优先数法：进程创建时就规定好优先级，运行时不改变 动态优先数法：进程的优先级在执行过程中可以改变 PPT没说优缺点，我估计是跟优先级的选择有关。\n时间片轮转法（RR） 思想很简单，系统规定一个时间长度作为运行一个进程运行的时间，如果这段时间内进程没有运行完，则必须让出CPU然后回去排队。\n显然，其及时性很好，但是周转时间很差。\n老师的PPT还给出其公平性差，我不明白为什么，这是非常公平的算法。有其他资料印证我的想法。\n高响应比优先算法（HRRN） 综合考虑了进程的响应时间与等待时间\n对每个进程计算响应比：（等待时间+执行时间）/ 执行时间，响应比最高的进程优先获得CPU使用权\n多级反馈队列（MLFQ） MLFQ中有许多独立的队列，每个队列有不同的优先级。每个任务只能存在于一个队列之中。MLFQ总是执行优先级较高的队列中的工作。优先级相同的工作则对他们使用轮转法。具体规则为：\n如果A的优先级\u0026gt;B的优先级，运行A 如果A的优先级=B的优先级，轮转运行A和B 任务进入系统时，放在最高优先级队列 一旦任务用完了时间配额，就把它放入低一级队列 经过一段时间S，将所有工作重新加入到最高优先级队列 Windows内核采用的就是这种算法的修改版\n11.jpg\r地址重定位 当程序被装入内存时，程序的逻辑地址被转换为内存的物理地址，这一过程称为地址重定位。这一过程由MMU（Memory management unit，内存管理单元）完成。\n绝对装入/固定地址再定位 程序的地址再定位是在程序执行之前被确定的。也就是在编译连接时直接生成物理地址。在此，程序地址空间和内存地址空间是一一对应的。\n可重定位装入 程序装入时，逻辑地址和物理地址可以不一致，此时需要由逻辑地址映射到物理地址。\n静态再定位\n地址定位时修改程序的逻辑地址值，完成定位后，在程序的执行期间地址不再变化。\n特点：在程序执行前定位\n优点：容易实现，无须硬件支持\n缺点：必须分配连续的存储区域，执行期间不能在内存中移动\n动态再定位\n程序在装入内存时，不修改逻辑地址。而是在程序访问内存时，实时地转化成物理地址。\n优点：代码可以在内存中移动，代码可以不连续存放在内存中。\n缺点：需要硬件支持，实现存储管理的软件比较复杂。\n内存扩充 其实就是虚拟内存，用辅存在逻辑上扩充内存，来装入更大的程序。\n覆盖技术\n27.jpg\r优点：程序可以不必一次装入\n缺点：覆盖结构需要程序员精心安排，增加复杂度。覆盖区仍有碎片\n交换技术\n即把内存中放不下的放到外存。\n优点：程序可以不必一次全部放入；可以提供优先级服务\n缺点：换入换出增加开销。换入时的重定位问题\n28.jpg\r内存管理-分区（连续）存储管理 单一连续分区存储管理 内存中一次只装入一个用户程序，程序独占整个用户区。\n优点：简单，适合单用户、单任务的系统，不需要硬件支持\n缺点：不支持多任务和大任务。太小就浪费，太大就装不下\n固定分区管理 就像给硬盘分区，内存也可以分为几个区，然后每个区就像单一的连续分区一样管理。\n优点：利用率提高；支持多程序\n缺点：存在内碎片（即分区之间未被使用的内存），浪费。分区数固定，限制并发数。\n可变分区 不预先划分，而是在作业需要装载时向系统申请，系统从内存中挖出一块给作业。剩下的部分等待下一次使用。\n关键是如何管理这些还未分配的内存。\n这些未分配的内存块会被记录在一个线性表（通常是链表）里，表中每一项记录了该空闲块的大小以及开始地址。\n最先适应算法（first-fit）\n将所有空闲分区按照地址递增的顺序排列，从前往后找，找到第一个符合的就分给他。\n释放内存时，把前后相邻的空闲空间合并。\n优点：尽可能利用低地址的空闲区，而把高地址的空闲区留给大作业。并且释放时可以合并分区。\n缺点：查表总是从头开始，前面会有很多小空间，会查很多次。存在外碎片，即被占用内存之间的各种小空闲内存，它们无法被合并集中使用，只能放在那，谁也看不上。\n下次适应算法（next-fit，循环最先适应算法）\n与first-fit唯一的不同在于，其查找是从上次分配的区块之后查找，查找到末尾时再查开头。\n优点：空闲分区分布地更均匀，提高查找速度。\n缺点：较大的分区不易保留。\n最佳适应算法（best-fit）\n将所有的分区按容量排序，从小到大找到第一个合适的进行分配。\n释放时，在整个链表上搜索地址相邻的空闲区，合并后插入到合适的位置。\n优点：分配后剩下的空白块最小，较大的空闲分区会被保留\n缺点：空白区可能小到无法使用，形成较多碎片\n最坏适应算法（worst-fit）\n与best-fit相反。即按从大到小地找。\n优点：一次就可以匹配成功\n缺点：剩余分区会越来越小，无法运行大程序\n可再定位式分区\n又称浮动分区分配。即移动所有被分配的分区，称为一个连续区域，而留下的就是一个较大的空白区。\n内存管理-页式存储管理 分区要求作业存储时必须连续存放。这样当一个作业大于当前最大的空闲分区时，即使还有其他空闲分区，也不能利用，降低了效率。\n分页考虑把作业内内存都分割成若干大小相等的块。每一块叫做一个页，在程序逻辑空间中的叫虚页，在物理地址中的叫做实页（主页）。所有页大小都相等，常为\\(2\\)的整数幂。\n也有地方把虚页叫做页，实页叫做帧的。\n主要关注的问题是，如何把虚页号映射到实页号上。\n我们通常会使用页表（page table）来实现。可以用数组、哈希表实现，记录虚页到实页的映射关系\n29.jpg\r转换也很方便，只需要把虚拟地址的一部分当作页号，一部分当作页内偏移即可。\n30.jpg\r一般来说，页的大小会是\\(2\\)的整数次幂，就是因为这个原因。假设虚拟空间有64\\((2^6)\\)字节，按字节编址。假设页的大小为16\\((2^4)\\)字节，那么一共有4页，所以可以把地址的低4位当作页内偏移，高2位作为虚页号（VPN）\n页表也是放在内存中的，所以为了取出一个数据，要额外访问一次内存。\n优点：程序不必连续存放。没有外碎片\n缺点：程序要一次全部装入内存。页表占用空间。建立和管理页表有开销。存在内碎片。并且页面与源程序无逻辑关系，难以对源程序以模块为单位进行分配、共享、保护\n快速地址转换（TLB） 是为了缓解每次访存都要访两次的技术。简单来说，就是把页表项放在cpu的cache里，cpu中的这些页表项就组成了一个快表。由于时间局部性，这个是会提升效率的。\n内存管理-段式存储管理 其可以解决分页中不能解决的：信息共享、信息保护、动态链接、动态增长问题。\n把程序划分为大小可以不同的段，每一段按照代码逻辑单位进行划分，每一段拥有独立的逻辑空间。\n每一段都有一对基址和界限寄存器，每一段都可以独立地放入物理内存。基址意味着段从哪里开始，界限意味着段在哪里结束。当然，还会有内存增长方向的标记。\n如何把逻辑地址映射到物理地址呢？和页也有相似之处，把虚拟地址的高几位用作段的标记。\n31.jpg\r另外，段也可以有保护位，标记该段是否可以被共享。例如数据段可以被共享，而代码段、堆栈段等不能共享。\n优点：程序不必连续存放、没有内碎片、便于共享\n缺点：作业要一次装入内存，存在外碎片。\n内存管理-段页式存储管理 32.jpg\r这是一种折衷方式，把段内再进行分页。此时逻辑地址从高到低为：段号、页号、页内地址。而后两个是段内地址。\n33.jpg\r34.jpg\r访问内存3次，比分页还慢。\n虚拟存储 为了在内存空间运行超过内存总容量的大作业，或者同时运行大量作业，解决的方法是从逻辑上扩充内存容量。\n程序的局部性原理 程序部分运行是可以的。在一段时间内，程序的执行仅局限于某个部分；相应地，它所访问的存储空间也局限于某个区域内。\n程序大多数时间是顺序执行，较少跳跃 子程序调用将会使程序的执行由一部分内存区域转至另一部分区域。 程序中存在许多循环结构 程序中还包括许多对数据结构的处理，如对连续的存储空间——数组的访问，往往局限于很小的范围内。 时间局部性\n程序中存在着大量的循环操作，一条指令一旦执行，那么很有可能很快会再次执行。某个存储单元被访问，很有可能很快会再次访问。\n空间局部性\n程序是顺序执行的，所以一旦访问某个存储单元，其周围的存储单元最有可能很快被访问。\n所以，程序在装入时，就不用一次性全部装入内存的，只需要把部分装入到内存，就可以执行。在执行过程中，如果发现需要的数据不在内存里，处理器就负责通知操作系统将相应的区域调入内存，然后继续执行。\n虚拟存储器的特征 离散性。内存分配时必须离散地分配，例如分页。最基本的特征 多次性。一个作业被分成多次调入内存运行，即在作业运行时没有必要将其全部装入。最重要的特征 对换性。作业运行过程中信息在内存和外存的对换区之间换进、换出。 虚拟性。逻辑上扩充内存，使得用户看到的内存容量远大于实际容量。 虚拟内存的实现-请求页式（demand paging） 在分页系统的基础上，增加了请求调页功能、页面置换功能，从而支持形成虚拟存储系统。\n需解决：\n取页。将哪部分装入内存 置页。将调入的页放在什么地方 淘汰。内存不足时，换出哪些页 第一个问题很好回答，只有在一个页需要的时候才把它装入内存。好处是\nIO需求更少 内存需求更少 响应快 支持多用户 硬件需要做到，在无效的访问时终止。访问不在内存中的页时把页换入内存。\n页表\n要做到虚拟存储，页表需要添加一些信息\n35.jpg\r缺页中断\n另外，还需要添加一些功能。即\n产生和处理缺页中断 页面置换功能 每当需要的页不在内存时，就产生缺页中断，请求OS把页调入内存。\n与一般中断的主要区别在于：\n缺页中断机构在指令执行期间产生和处理中断信号，而一般中断在一条指令执行完后检查和处理中断信号。 缺页中断返回到该指令的开始重新执行该指令，而一般中断返回到该指令的下一条指令执行。 一条指令在执行期间，可能产生多次缺页中断。 处理缺页中断的过程：\n查找页表来确定此次地址访问是否合法 如果不合法,则中止该进程; 否则如果是发生了缺页,则需要将其调入内存 找到一个空闲物理块 启动磁盘,把该页读入内存 读磁盘结束后,修改页表以指出该页已在内存中 重新开始执行刚才发生缺页中断的指令,这时它可以访问刚才调入的页 36.jpg\r缺页的整体过程如下\n陷入OS 保存该用户寄存器和进程状态 确定该中断是一个缺页中断 检查该页面引用是合法的并确定该页在磁盘上的位置 将该页从磁盘读入一个空闲物理块 在磁盘等待队列中等待直到该请求被处理 等待设备寻道延迟 将该块从磁盘传送至内存 为了提高CPU利用率，将CPU分派给其他进程使用 磁盘I/O完成，产生中断 保存正在执行进程的现场信息（如果第6步执行了） 确定中断来自于磁盘 修改页表以示所缺的页已进入内存 等待CPU再次分派给这个进程 恢复该进程的现场信息，包括寄存器、进程状态、页表等，恢复执行 以上步骤不是在任何情况下都会发生的，主要动作为\n处理缺页中断 从磁盘读入所需的页 重新开始被中断的进程 其中磁盘IO开销最大。\n就像Cache有命中率，这里也有缺页率。\n如果作业在执行过程中总的访问内存次数为\\(A\\)，成功访问次数为\\(S\\)，缺页的次数为\\(F\\)。则\n\\[A = S+F \\]\n\\[p = F/A \\]\n然后我们就能得出有效存取时间（EAT）的概念，即访问一次内存的平均开销\n\\[EAT = (1-p)\\times 内存访问时间+p(缺页中断处理时间+换出时间+换入时间+重启程序时间) \\]\n页置换\n在可用页面不足时，找到内存中并没有使用的某个页，换出。其出发点就是希望把未来不使用或者短时间内较少使用的页调出。最终希望能有最小的缺页率。\n常见算法\n先进先出页面淘汰算法 最近最少使用（LRU）算法 最佳算法 第二次机会淘汰算法 页面缓冲算法 （感觉和Cache、TLB的替换算法一样）\n其中前两个比较重要，会考。但是在计组里面学过了，就不记了。主要讲讲LRU的实现\n计数器实现\n其中LRU的一种实现是，给每个页表项一个时间域，CPU增加一个计数器，每次访问内存就给计数器+1，然后赋值给被访问的页的时间域。\n于是最近最少使用的页就是时间域最小的页。\n栈实现\n用双向链表记录一个页号的栈。每次访问时把该页移到栈顶。于是栈底的页就是最近最少使用的。\n置换算法的好坏将直接影响系统的性能，不适当的算法可能会导致进程发生“抖动/颠簸”（Thrashing)\n抖动：刚被换出的页很快又被访问，需重新调入，导致系统频繁地交换页面，以致大部分CPU时间花费在完成页面置换的工作上\n原因为：\n页面淘汰算法不合理 分配给进程的物理页太少 常驻集指虚拟页式管理中给进程分配的物理页面数目。常驻集与缺页率的关系：\n常驻集越小，内存中能并发的进程数就越多，但是就就单个进程来说，缺页率会很高 常驻集到达一定数目后，再增加页面，缺页率不会明显下降 常驻集的大小确定方式有\n固定分配法。如平均分配法；根据程序大小按比例分配法；按优先权分配法 可变分配。性能较好，但是增加了算法开销 由于局部性原理，进程在一段时间内总是集中访问一些页面，称之为活跃页面。如果能给进程提供等于活跃页面数等大（或大于）的常驻集，那么缺页就会减少。\n对于给定的访问序列选取定长的区间，称为工作集窗口，落在工作集窗口中的页面集合称为工作集。可以用工作集来调整常驻集的大小。\nOS跟踪每个进程的工作集，并为其分配大于其工作集的物理块数。 如果还有空闲物理块，则可启动另外的进程。 如果所有进程的工作集之和超过了可用物理块的总数，则OS会选择暂停一个进程，该进程被换出，所释放的物理块可分配给其他进程。 利用工作集进行常驻集调整的策略：\n记录一个进程的工作集变化 定期从常驻集里删除不在工作集中的页面 总是让常驻集包含工作集 37.jpg\r页面调入策略\n为能使进程运行，事先需将一部分要执行的程序和数据调入内存\n预调页策略\n主动的页面调入策略，即把那些预计很快会被访问的程序或数据所在的页面，预先调入内存。 预测的准确率不高（50%），主要用于进程的首次调入。也有的系统将预调页策略用于请求调页 请求调页策略\n当进程在运行中发生缺页时，由系统将缺页调入内存 目前虚拟存储器系统大多采用此策略 在调页时须花费较大的系统开销，如需频繁启动磁盘I/O 至于从何处调入页面。虚拟存储系统中，外存被分为两部分：文件区和对换区（如linux交换空间）。对换区（连续分配）的磁盘IO速度比文件区（离散分配）要高。\n虚拟内存的实现-请求段式（demand segmentation） 课上没有内容\n并发 线程 把进程介绍放到虚拟化，把线程介绍放到并发，并不是说进程不能并发，只是《操作系统导论》中API的介绍是这样安排的。我这里也一样。\n基本概念 线程算是一种轻型的进程，是一个可执行的实体单元，是线代操作系统中处理器调度（执行）的基本单位。\n线程和进程的关系\n线程是进程的一个组成部分，线程由进程创建，一个进程中可以有多个线程。 进程是资源分配和保护的基本单位。每个进程都有自己独立的资源，而一个进程内的多个线程使用资源有很多是一样的，也即进程的资源。 所有线程的代码段和数据段是一样的，但是可以执行在不同的代码上 每个线程可独立运行也可以互相合作 每个线程的上下文是独立的，也即寄存器、栈等。 7.jpg\r线程的实现方式 用户态线程\n8.jpg\r即进程自己管理线程。\n优点：\n线程对操作系统不可见，操作系统适应性强 线程切换快 缺点：\n程序设计困难 并发度低 内核态线程\n9.jpg\r即操作系统来管理线程。\n优点：实现简单，并发度高\n缺点：执行效率低、资源消耗高\n混合模型\n10.jpg\r进程通信 进程通信简单来说就是在进程间传输数据\n除了交换数据，同步、互斥也建立在沟通通信的基础上，来传递状态和控制信息\n12.jpg\r13.jpg\r共享内存模式\n它是间接通信，是最快捷有效的方法之一。\n14.jpg\r消息传递模式\n由发送方形成，通过一定的机制传递给接收方的一组信息，它的长度可以固定，也可以变化。和客户端-服务端的形式比较像。\n消息也是分为消息头和消息体。就像HTTP请求一样。\n15.jpg\r16.jpg\r共享文件模式（管道）\nLinux的管道就是经典的例子。\n管道是一种信息流缓冲机构，基于文件系统，可以连接两个进程，以FIFO的方式单向传送数据。\n匿名管道\n匿名管道是一种未命名的、单向管道。常用在父子进程之间。匿名管道是本地的，不能用在网络之间。匿名管道如果想要双向通信，通常会创建两个单向管道。\n命名管道\n命名管道是一种有名称的，可在本地或者网络间传输，支持可靠的单向或双向通信。\n（自旋）锁 临界区：是访问共享资源的一段代码，资源通常是一个变量或数据结构 竞态条件：出现在多个执行线程大致同时进入临界区时，它们都试图更新共享资源，达到了错误的结果 不确定性：程序里面有竞态条件，就会导致程序的输出不确定。 互斥原语：即可以把临界区原子化的操作 大致上，锁是这样用的\nlock(); a = a+1; unlock(); 控制中断 即在临界区关中断，防止调度程序切换线程。\nvoid lock(){ DisableInterrupts(); } void unlock(){ EnableInterrupts(); } 缺点：\n恶意程序可以在lock之后死循环，让系统假死 不支持多处理器 导致中断丢失 效率低 测试并设置（Test-And-Set） typedef struct lock_t{ int flag; } lock_t; void init(lock_t *lock){ lock-\u0026gt;flag = 0; // 0代表未加锁，1代表加锁 } void lock(lock_t *lock){ while (TestAndSet(\u0026amp;lock-\u0026gt;flag, 1)==1) ; //自旋 } void unlock(lock_t *lock){ lock-\u0026gt;flag = 0; } 测试并设置所要做的事是，当一个进程要进入临界区时，首先测试这把锁，如果锁的值为\\(0\\)，则设置为\\(1\\)并进入临界区。否则等待直到其变为\\(0\\)\n这样一直测试直到条件满足的锁，也叫做自旋锁。和后面信号量实现的sleep-wakeup锁区分开（我没有找到sleep-wakeup锁的确切定义）。\n结果意义上，等价于设置新值，返回旧值。其等价于如下c语言代码。\nint TestAndSet(int *old_ptr, int new){ int old = *old_ptr; *old_ptr = new; return old; } 注意，不能用C语言就实现锁，必须要有硬件的支持。上述测试并设置并不是原子的，可能会在中间中断。\n幸运的是，操作系统提供这样的指令，如HSL和XCHG。\n这个锁并不保证任何的公平性，线程可能会永远自旋。\n另外，一直在自旋也会导致性能开销很大，CPU会一直处于忙等待（Busy waiting）状态\n比较并交换（compare-and-exchange（swap）） 也是需要硬件支持的。\nint CompareAndSwap(int *ptr, int expected, int new){ int actual = *ptr; if(actual == expected) *ptr = new return actual; } void lock(lock_t *lock){ while(CompareAndSwap(\u0026amp;lock-\u0026gt;flag, 0, 1)==1) ; } 如果只是实现简单的自旋锁，那么等价于测试并设置。\n链接的加载和条件式存储指令（load/store） 课上没讲\n获取并增加 课上没讲\n互斥锁vs自旋锁vsSleep-wakeup锁 简中互联网上搜到的：\n互斥锁（mutex），一种阻塞锁，是在线程试图进入临界区时，如果临界区被占用，那么该进程陷入阻塞状态，直到锁被释放。\n自旋锁（spinlock），一种非阻塞锁，在检查时，如果临界区被占用，他会通过无限循环反复检查（即自旋）是否释放。他不会进入阻塞状态从而放弃CPU，所以会消耗大量CPU时钟（称为忙等待）。\n但我个人觉得不太对。所有锁都是“互斥”的吧。也有教材、英文维基印证我的想法。我个人就倾向于分为阻塞锁和非阻塞锁。\nSleep-wakeup锁其实就是阻塞锁。\n条件变量 课堂上没讲，只需要明白使用条件变量可以避免自旋即可。\n信号量 生产者-消费者模型 也叫做有界缓冲区问题。\n假设有一个或多个生产者线程和一个或多个消费者线程。生产者把生成的数据项放入缓冲区；消费者从缓冲区取走数据项，以某种方式消费。\n如果让生产者将数据放入已满的缓冲区，或者消费者从空的缓冲区中获取数据，就会产生错误。\n这项工作由两类线程完成，一类称为生产者线程，另一类为消费者线程。\n信号量基本概念 信号量（semaphore）是一个有整数值的对象，仅可以用初始化和两个函数来操作它。POSIX标准中，这两个函数为sem_wait()和sem_post()，而在Dijkstra的荷兰语论文中称之为P()和V()\n信号量表示资源的实体，这个整数值与队列有关。\n信号量分为\n公有信号量：用于进程间的互斥，初值通常为1 私有信号量：用于进程间的同步，初值通常为0或n C语言等效代码如下，具体还是要靠硬件、或者底层同步原语（锁和条件变量）实现原子化的操作。\nint sem_wait(sem_t *s){ // 即P() s = s - 1; if(s\u0026lt;0){ // 调用进程被阻塞（sleep/wait） // 进入s的等待队列 } } int sem_post(sem_t *s){ // 即V() s = s + 1; if(s\u0026lt;=0){ // 从s的等待队列里唤醒一个进程 // 移出队列 } } 显然的，我们如果要把他当锁使用，就要给s的初值设置为1。此时，s==1代表无线程在运行。s==0代表有一个在运行。s==-n代表有n个线程在等待(n\u0026gt;0)。给临界区加锁的方式如下\nsem_wait(\u0026amp;s); // P(s) a = a + 1; sem_post(\u0026amp;s); // V(s) 这种让线程睡眠的锁叫做sleep-wakeup锁。\n如果当作条件变量使用，可能会设置s的初值为0。通常P和V会放在不同的线程中使用\n17.jpg\r信号量解决生产者-消费者问题 sem_t empty; sem_t full; sem_t mutex; void *producer(void *arg){ int i; for(int i=0;i\u0026lt;loops;i++){ sem_wait(\u0026amp;empty); sem_wait(\u0026amp;mutex); put(i); sem_post(\u0026amp;mutex); sem_post(\u0026amp;full); } } void *consumer(void *arg){ int i; for(int i=0;i\u0026lt;loops;i++){ sem_wait(\u0026amp;full); sem_wait(\u0026amp;mutex); int tmp = get(i); sem_post(\u0026amp;mutex); sem_post(\u0026amp;empty); printf(\u0026#34;%d\\n\u0026#34;, tmp); } } int main(){ //... sem_init(\u0026amp;empty, 0, MAX); //第二个参数不用管，默认为0，第三个参数为初始值，这里为缓冲区大小 sem_init(\u0026amp;full, 0, 0); sem_init(\u0026amp;mutex, 0, 1); //... } 使用注意事项\n首先，PV一定是成对出现的。互斥操作时处于同一线程中，同步操作时处于不同线程中。\n其次，PV操作的位置和次序非常重要。例如，生产者的代码不能变为\nsem_wait(\u0026amp;mutex); sem_wait(\u0026amp;empty); put(i); sem_post(\u0026amp;full); sem_post(\u0026amp;mutex); 消费者的代码同理也不能替换顺序。否则会产生死锁问题，即消费者等待full，而生产者等待mutex，二者都在等待。\n缺点\n信号量解决了同步问题，但是信号量大量分布在各个进程中不便于管理，使用不当会导致死锁。\n读者-写者模型与读写锁 这也是一个经典的Inter-Process Communication（IPC）问题。\n例如，一个数据结构可以被多个进程共享。有的进程负责修改数据，称为“写者”，有的进程只读数据，称为“读者”。规定：“读者”可以同时读取共享数据对象，“写者”不能与任何其他经常同时访问数据对象。\n可以用信号量实现如下\ntypedef struct _rwlock_t{ sem_t lock; sem_t writelock; int readers; } rwlock_t; void rwlock_init(rwlock_t *rw){ rw-\u0026gt;readers = 0; sem_init(\u0026amp;rw-\u0026gt;lock, 0, 1); sem_init(\u0026amp;rw-\u0026gt;writelock, 0, 1); } void rwlock_acquire_readlock(rwlock_t *rw){ sem_wait(\u0026amp;rw-\u0026gt;lock); rw-\u0026gt;readers++; if(rw-\u0026gt;readers==1) sem_wait(\u0026amp;rw-\u0026gt;writelock); // 即，第一个读者需要占用write锁 sem_post(\u0026amp;rw-\u0026gt;lock) } void rwlock_release_readlock(rwlock_t *rw){ sem_wait(\u0026amp;rw-\u0026gt;lock); rw-\u0026gt;readers--; if(rw-\u0026gt;readers==0) sem_post(\u0026amp;rw-\u0026gt;writelock); // 即，最后一个读者需要释放write锁 sem_post(\u0026amp;rw-\u0026gt;lock) } void rwlock_acquire_writelock(rwlock_t *rw){ sem_wait(\u0026amp;rw-\u0026gt;writelock); } void rwlock_release_writelock(rwlock_t *rw){ sem_post(\u0026amp;rw-\u0026gt;writelock); } 理发师问题 这也是一个IPC经典问题。\n理发店有一位理发师，一把理发椅和\\(n\\)把用来等候理发的椅子。如果没有顾客，理发师就在理发椅上休息。顾客来时，如果理发师空闲则理发，否则有空椅则坐等，否则离开。\ns customers = 0, barbers = 0, mutex = 1; int waiting = 0; void barber(){ while(1){ P(customers); // 检查是否有顾客 P(mutex); waiting-- V(mutex); V(barbers); // 向顾客发送信号 cut_hair(); } } void customer(){ P(mutex); if(waiting\u0026lt;MAX){ waiting++; V(mutex); V(customers); // 给理发师发送信号 P(barbers); // 接收理发师的信号 get_haircut(); } else{ V(mutex); } } 哲学家就餐问题 这也是一个IPC经典问题。\n18.jpg\r有五个哲学家和五把叉子。哲学家有时要思考，有时要就餐。哲学家只有在同时拿到左右两把叉子时，才能就餐。\n即哲学家为：\nwhile(1){ think(); getforks(); eat(); putforks(); } 我们可能会实现如下的锁：\nvoid getforks(){ sem_wait(forks[left(p)]); sem_wait(forks[right(p)]); } void putforks(){ sem_post(forks[left(p)]); sem_post(forks[right(p)]); } 但是这是有问题的，假设每个哲学家都在一开始就拿自己左手边的叉子，那么所有人都会等待右手边的叉子空闲，没有人会放下叉子，于是就死锁了。\n解决这个问题最简单的方法就是，假定某个哲学家的顺序不同，他先取右边，再取左边，这样就不会死锁了。\n管程 管程的思想为，集中和封装针对一个共享资源的所有访问，包括所需的同步操作。Dijkstra在1971提出这个概念来集中管理临界资源的同步操作，构成一个所谓的秘书进程。凡是要访问临界区的进程，都需要报告秘书，由秘书来实现诸进程对临界区的互斥使用。\n19.jpg\r基本特性\n局部于管程的数据只能被局部于管程内的函数所访问 一个进程只能通过调用管程内的函数才能访问管程内的共享数据 每次只能有一个进程在管程内执行某个函数 管程是一个语言成分，管程的互斥访问完全由编译器在编译期添加。 死锁缺陷 基本概念 之前我们也提到过死锁，就是大家都在等别人释放资源但是自己又不释放。\n正式的：在多道程序中，由于多个并发进程共享系统资源，如果使用不当可能会造成一种僵局，即当某个进程提出资源的使用请求后，是的系统中的一些进程处于无休止的阻塞状态，在无外力的作用下，这些进程将无法继续进行下去，这就是死锁。\n上面这段话可以总结出死锁产生的环境：\n多道程序设计技术 多个并发进程 资源共享和独占 没有外力可以借助 Coffman在1971年支持死锁产生的4个必要条件\n资源互斥访问。并且资源是有限的 非抢占（不可剥夺）。线程持有资源时，不能被其他线程抢占资源 持有并等待。即线程持有资源，又在等待其他资源 循环等待。即线程之间存在一个环路，环路上每个线程都持有一个资源，而这个资源又是下一个线程所需要的。 老师的PPT上还给出一个“零散请求”，我不知道什么意思。\n死锁轻则导致系统资源利用率下降，重则系统崩溃。\n与死锁相似的还有一种叫活锁，即两个线程释放资源后，又分别占用了对方释放的资源，反复释放和占用。\n置之不理——鸵鸟政策 优点：简单、简化系统设计，节约成本\n缺点：安全性低、可靠性低\n事后处理法——检查和恢复 即容忍死锁的发生，之后处理（如关机）。\n优点：灵活\n缺点：不是所有情况都可以容忍死锁的发生\n积极防御法 不让死锁发生，以积极的遏制为出发点。\n手段\n预防：破坏死锁产生的条件（代码意义上），使其不可能发生 避免：允许存在发生死锁的可能性，但是在每一步进行资源分配时灵活处理，使得其永远达不到死锁状态 积极防御法-预防 破坏互斥条件\n通常来说，代码都会存在临界区，所以破坏互斥很困难，不好用。\n破坏非抢占条件\n即允许一个进程还未执行完成时就释放已经占有的资源（被剥夺使用权）。\n缺点是实现困难，为了恢复现场需要耗费很多时间和空间。只适合CPU、存储器这样的资源。\n破坏零散请求条件\n即在进程创建时就分配所有需要的资源，然后再执行。这样运行中就没有资源申请了。运行完再释放。\n缺点是效率低，资源浪费，并发性下降。\n破坏循环等待条件\n也许是最常用、最实用的。\n给资源编号、排序，所有资源的申请必须按这个顺序申请。\n缺点是资源编号困难；资源的编号很难和进程申请资源的顺序一致。\n破坏持有并等待条件\n即把所有的锁套在一个大锁里。\n缺点是不适合封装。另外会降低并发度。\n上面这五个都是预防，以破坏必要条件为方法，由于对资源的申请加上了众多限制，因此虽然有一定限制但是利用率和效率较低。\n积极防御法-避免 通过调度避免死锁\n在分配资源之前，系统判断假若满足进程的要求是否会发生死锁，如果会就不予分配，从而保证永远不会到达死锁。\n优点：比预防更加灵活，允许更多并发，资源利用率和效率也更高。\n20.jpg\r单银行家算法（资源分配时避免死锁）\n在银行中，客户申请贷款的数量是有限的，每个客户在第一次申请贷款时要声明完成该项目所需的最大资金量，在满足所有贷款要求时，客户应及时归还。银行家在客户申请的贷款数量不超过自己拥有的最大值时，都应尽量满足客户的需要。在这样的描述中，银行家就好比操作系统，资金就是资源，客户就相当于要申请资源的进程。\n单银行家算法我不打算记笔记，因为他是多项资源银行家算法的特例，思想和算法流程完全一样。不同点在于单银行家可以使用单个整数值，而多银行家必须用上向量。\n多项资源银行家算法\n适用于一个进程申请多个资源的情况。单银行家算法就是只申请一个资源时的特例。\n假设有ABCD四种资源，有P1P2P3P4四个进程。\nAllocation矩阵表示已分配的资源，Max矩阵表示线程的总需求量，Available向量表示操作系统还剩多少资源，NEED矩阵表示线程还需要多少。当然还可以有allocation向量表示系统分出去多少资源，即Allocation矩阵的列加和向量。sum向量表示操作系统总共有多少资源。等等。\n21.jpg\r22.jpg\r安全状态前面也提到过，在该算法中，如果最终FINISH都变成true，就是安全状态，否则不安全。如果是安全的，那么算法中进行分配的顺序就是实际上操作系统进行资源分配的顺序。如果不安全，则会死锁，不进行分配。\n死锁的检测 方法是使用资源分配图\n23.jpg\r24.jpg\r25.jpg\r上图中，非阻塞即该进程并没有在等待资源释放。如T3和T4\n临时资源的死锁检测 临时性资源：即可消耗的资源。如信号、消息、邮件等。其特点是：没有固定数目；不需要释放。\n26.jpg\r对于临时性资源来讲，它有生产者，生产者会源源不断的产生资源，所以只要生产者不被阻塞，可以认为资源最终一定是充分的，可以满足各消费进程的需要。\n所以判断是否会死锁，关键在于判断生产者进程的状态。如果生产者不被阻塞，则总会产生该类资源。\n方法：\n从没有阻塞的进程入手，删除没有阻塞的进程的请求边，并使资源类中的资源数减1 重复以上步骤，直到： 图中所有请求边都删除，则不会死锁。 图中仍存在请求边，但无法化简，则死锁。 课堂上讲的一坨，也并没有找到其他资料，鉴定为不考。\n死锁的解除 重新启动\n实现简单，但会造成损失和浪费\n撤销进程\n死锁发生时，系统撤销造成死锁的进程，解除死锁。\n一次性撤销所有死锁损失较大。\n系统可以先撤销优先级低的、占有资源少的、运行时间短的。\n剥夺资源\n系统保留死锁进程，只剥夺死锁进程占有的资源，直到死锁解除。选择剥夺谁的资源同上。\n进程回退\n死锁时，系统可以根据保存的历史信息，让死锁进程退回到某种之前的状态，直到死锁解除。\n实现方法：结合检查点或回退（checkpoint/roolback）机制实现。\n系统定期保存所有进程的检查点（即某一时刻的状态）。一旦系统看到某个进程卷入了死锁，该进程就会被终止，剥夺它的资源。然后查看保存点的信息，重建状态，回到上次的检查点执行。\n目前发展比较成熟，广泛用于DBMS中。\n持久性 文件 基本概念 文件是记录在外存上的，具有符号名的，在逻辑上有完整意义的一组相关信息项的集合。\n从用户的角度看，文件是逻辑外存的最小分配单元，即数据只能以文件的形式写入外存。\n文件的符号名可以由字母、数字和其他符号组成。符号名一般包括文件名和扩展名。\n文件的优点：\n用户使用方便。只需要知道文件名即可存取 文件安全可靠。只有通过文件系统才能访问，而文件系统可以有各种安全措施 文件可备份。 文件可共享。 文件由两部分组成\n文件体：文件的真实内容 文件说明（属性）：操作系统为了管理文件所用到的信息。也是文件控制信息。文件目录就主要存放这些东西。 文件名称 文件内部标识符（inode number, inumber） 文件类型 文件位置 文件大小 访问权限 \u0026hellip; 文件的类型有很多\n按后缀分 按文件的性质和用途可以分为：系统文件、库文件、用户文件 按保护方式分：只读、读写、可执行、不保护 按保存期限：临时文件、档案文件、永久文件 文件的逻辑结构 指用户所观察到的文件组织形式，它独立于物理特性，又称为文件组织。\n分类为：\n有结构的记录式文件：由一个以上的记录构成。又分为定长记录和变长记录 无结构的流式文件：文件没有结构，由一串字符流构成 文件的物理结构 指文件在物理设备上的存放方法。\n常见的文件存储介质有磁带、光盘、磁盘\n卷\n卷是存储介质的物理单位，对应于一盘磁带、一块软盘、一个光盘、一个硬盘分区\n块\n块是存储介质上连续信息所组成的一个区域，也叫做物理记录。在磁盘上称为扇区。\n物理设备保证，对于块的读写是原子的。\n块大小\n文件的物理存储方式 连续存储\n它将逻辑上连续的文件信息依次存放在编号连续的物理块上。\n38.jpg\r链式结构\n逻辑上连续的信息在物理块上不一定连续。每个物理块有一个指向下一个物理块的指针\n39..jpg\r索引结构\n也是物理上不一定连续，系统为每个文件构建一个索引表，索引表中存放文件的逻辑块与物理块的对应关系。索引表放在一个块中。\n40.jpg\r此时，如果只用一个表，表的大小决定了文件的最大大小。\n于是我们就要想办法扩展表。\n链接文件方式\n即多个索引表用链接文件的方式串联起来。\n41.jpg\r多重索引方式\n即给索引表建立一个索引表\n42.jpg\rUNIX系统就采用了一种三级索引结构。UNIX文件系统中设置了一类特殊的索引节点，称为inode（index node，不止ext文件系统，ntfs和hfs+也有，但是fat没有）。inode包含了文件的控制信息\n43.jpg\rHash文件\n采用计算寻址结构，它由主文件和溢出文件组成。\n44.jpg\r文件的存取方式 指读写文件存储器上的一个物理块的方法。分为\n顺序读取。指对文件中的信息按顺序依次读写的方式。 随机读取： 直接存取法：允许用户随意存取文件中任意一个物理记录。 按键存取法：根据文件中各记录的某个数据项内容来存取记录的，这种数据项称之为“键”。 45.jpg\r文件系统 基本概念 文件系统是OS中负责存取和管理信息的模块，它用统一的方式管理用户和系统信息，并提供方便的操作方法。\n面向用户的功能\n文件的按名存取 文件的共享和保护 文件的操作和使用 OS需要考虑的内容\n文件目录的建立和维护 存储空间的分配和回收 数据的保护 文件目录 文件目录就是负责管理文件控制信息的地方。\n当然文件目录也是放在外存中的，文件目录中的每一条叫做文件控制块（FCB）\n文件目录结构的组织方式直接影响到文件的存取速度，关系到文件共享性和安全性，因此组织好文件的目录是设计文件系统的重要环节。\n其可以分类为\n一级目录结构\n46.jpg\r优点是简单\n缺点是：查找速度慢、不允许重名、不便于实现文件共享（单用户）\n二级目录结构\n基本上就只解决了多用户问题。不同用户可重名\n47.jpg\r多级目录结构\n类似于linux的。\n49.jpg\r48.jpg\r50.jpg\r一个目录中的信息只包含文件名和inode号，inode表另外存储。通常文件系统视目录为一个特殊的文件。因此目录也有一个inode，位于inode表中的某处。\n另外，每个目录都有一个目录文件。\n为了实现“按名存取”，UNIX会使用线性检索法，即一层层往下找。\n显然，你得假设根目录的inode号是事先约定的，才能防止为了找根目录inode号必须查询目录文件，而为了找目录文件必须进入根目录的bug。一般根目录的inode号为2\n文件目录的维护 操作系统在内存设置了一个非常精炼的文件机构，它不是外存文件管理机构的全部映象，而是存储最近正在使用文件的相关信息。\n文件打开后由内存的一套管理机构管理，关闭时退出管理机构，所以将这种文件管理机构称为打开文件机构。\n内存文件控制块\n51.jpg\r相当于一种Cache了也是。\n首先在内存中找inode，如果找不到，就在内存中分配一个空闲表项，填入外存的inode信息。\n当需要查询、修改时，直接在内存inode中进行。关闭文件时，如果内存inode被修改过，则把修改更新到外存中。\n系统打开文件表\n系统打开文件表用于记录所有打开文件的控制信息\n52.jpg\r用户打开文件表\n每一个进程都有一张打开文件表——用户打开文件表。\n53.jpg\r外存空间管理 外存和内存很像，也是多用户，需要存储、删除。\n外存空闲空间管理的数据结构通常称为磁盘分配表。常用的管理办法有\n空闲区表\n将外存空间上一个连续未分配区域称为“空闲区”。操作系统为磁盘外存上所有空闲区建立一张空闲表，每个表项对应一个空闲区，空闲表中包含序号、空闲区的第一块号、空闲块的块数等信息。\n位示图（bitmap）\n相当于一个vis数组，每一位记录对应物理块的使用情况。0代表空闲，1代表占用。\n空闲块链\n即每个空闲块有一个指针指向下一个空闲块，构成链表。头指针放在一个约定的位置中\n成组链接法\n即缝合空闲表和空闲链表。\n将空闲块分成若干组，每100个空闲块为一组。每组的第一个空闲块登记了下一组空闲块的物理盘块号和本组空闲块总数 。\n54.jpg\r其释放算法如下\n55.jpg\r分配算法如下：\n56.jpg\r（老师的ppt给的一坨，建议看https://blog.csdn.net/qq_45744501/article/details/116953538）\n文件共享 指不同用户或进程使用同一文件，实际上文件的实体只有一个。\nUNIX系统的文件名和inode分离，就有助于实现共享。\n静态共享\n一个文件同时属于多个文件目录项，但实际上文件仅仅只有一处物理存储，这种多个文件目录项对应一个文件实体的多对一的关系叫做文件链接。\n静态共享中这种关系不管文件此时是否在被使用，都存在。\n硬链接\n硬链接只是在要创建链接的目录中创建了另一个名称，其指向和原有文件相同的inode。因为inode是在特定的文件系统中的，所以不能跨分区。\n软链接/符号链接\n文件的内容为被链接文件的路径名。\n动态共享\n出现在进程共享文件时，伴随着进程的生成而存在，进程的终止而消失。\n57.jpg\rWINDOWS文件系统实例 TODO\nIO设备管理 基本概念 负责计算机与外部的输入输出(I/O)工作的设备为外部设备，简称为外设。\n进行管理的目标就是提高设备利用率，提高CPU与I/O设备之间的并行操作程度。为用户提供方便统一的界面。\nIO系统的结构 58.jpg\r59.jpg\rIO系统的控制方式 程序控制IO（直接控制方式）\n优点：简单\n缺点：CPU的大部分时间都用于对硬件进行查询，效率低下\n60.jpg\r中断驱动IO\n优点，在外设进行数据处理时，CPU不同等待，可以继续执行。提高了CPU的工作效率，并且可以和设备并行。\n缺点是，数据传输仍然要通过CPU进行。如果处理的数据量少（低速设备）还行，如果量大则会长期占用CPU。\n直接存储访问（DMA）IO\n即加个DMA控制器。CPU只用控制DMA控制器来控制IO操作的开始和结束，剩下的数据传输交给DMA控制器进行。适用于高速设备。\n通道控制方式IO\n61.jpg\r（个人感觉就是用了多个DMA）\n解决了I/O操作的独立性和各部件工作的并行性。不仅CPU和通道之间能并行，通道和通道之间也能并行，从而设备之间可以并行。\nIO设备的分类 按数据组织分类\n块设备。以数据块为单位来组织和传递信息。属于有结构设备 传输速率高 可寻址，即可随机读 通常用DMA方式，例如磁盘 字符设备。以单个字符为单位来传输数据。属于无结构设备。一般用于数据的输入和输出，例如打印机 传输速率低 不可寻址 通常用中断方式 按传输速率分类\n低速设备。如键盘鼠标麦克风 中速设备。如打印机 高速设备。如磁带、磁盘、光盘驱动器 按资源分配方式\n独占设备。即一段时间内只允许一个进程访问，大多数都很低速。如打印机。因为独占，所以要互斥地访问。 共享设备。即一段时间内可以多个进程访问。如磁盘。 虚拟设备。指通过虚拟技术将一台独占设备变换为若干台供多个用户（进程）共享的逻辑设备。 IO软件的组成 由三部分组成\nI/O交通管制程序。负责各I/O设备之间的协调工作 I/O调度程序。负责设备的分配和调度 I/O设备处理程序。负责每类设备的具体操作 其设计目标为\n设备独立性 统一命名 结构分为四层\n62.jpg\r中断处理程序\n目的：解决高速处理设备和低速输入输出设备之间的矛盾，提高系统工作效率。\n设备驱动程序\n设备驱动程序是直接同硬件打交道的软件模块。其接受自与设备无关的上层软件的抽象请求；进行与设备相关的处理。\n具体功能例如\n控制和监督各I/O控制器的正确执行 处理和设备相关的操作 缓冲区管理 设备驱动是操作系统底层中唯一知道各种设备控制细节的部分。例如磁盘驱动程序关注磁臂的运动，其他软件则根本不关注。\n与设备无关的系统软件\n是建立在设备驱动程序之上的，与具体设备无关的I/O功能的集合。\n统一命名 设备保护 提供与设备无关的逻辑块 缓冲管理 存储设备的块管理 独占设备的分配和释放 出错处理 操作故障。由驱动程序处理 非操作故障。由与设备无关的系统软件处理，并向上层返回出错信息 用户空间的I/O软件\n常见的有\nIO系统调用 Spooling系统：构成虚拟设备 63.jpg\r具有通道的设备管理 64.jpg\r通道命令（CCW）。通道又称IO处理机，具有自己的指令系统，其指令叫CCW 通道程序。用CCW编写的程序称通道程序 通道地址字（CAW）。用来存放通道程序首地址的内存单元称通道地址字 通道状态字（CSW）。是通道向操作系统报告工作情况的状态汇集 其操作过程如下\n65.jpg\rIO缓冲 缓冲区是一种交换数据的区域\n引入缓冲的主要目的：\n缓和CPU和I/O设备间速度不匹配的矛盾 提高CPU与I/O设备间并行操作的程度 减少CPU的中断频率 单缓冲技术\n只设置一个缓冲，CPU和外设轮流使用。\n双缓冲技术\n计算过程、数据输入缓冲的过程、数据传送的过程可以并行。适合于外设速度较高的情况。\n例如两个缓冲A，B。IO输入到缓冲A的时候，用户读取B的内容，之后输入到B，用户又读取A。反复交换，不需要轮流等待使用。\n环形缓冲\n66.jpg\r缓冲池\n可供多个进程共享的双向缓冲技术\n67.jpg\rUNIX设备管理实例 TODO\n磁盘 磁盘调度 影响文件系统性能的因素包括：\n存储介质 磁盘性能的好坏 磁盘调度算法的好坏 磁盘高速缓冲区的大小 磁盘是一种共享设备，为了保证信息的安全，系统每一时刻只允许一个进程启动磁盘进行I/O操作，其余的进程只能等待。因此合理的设置调度算法就十分重要。\n设置调度算法的目标：使各进程对磁盘的平均访问时间最小。\n磁盘读取一次的时间分为三个部分\n寻道时间 旋转延迟时间 数据传输时间 数据传输很难去在软件层面修改，我们只能修改寻道时间和旋转等待时间。\n于是目标就转化为：使磁盘的平均寻道时间最少\n要让其最少，就要磁头移动的磁道数平均最少\nFCFS算法\n严格按照进程请求访问磁盘的先后次序进行调度，是一种最简单的磁盘调度算法。\nSSF（最短寻道时间优先）算法\n思想：要求每次访问的磁道与当前磁头所在的磁道距离最近。\n优点：移臂次数比FCFS少\n缺点：饥饿\nSCAN（电梯调度）算法\n即保持当前磁头的移动方向，直到最远的访问，再调头。\n优点：克服了饥饿，并且总寻道时间较短。\n旋转调度算法\n研究当移动臂定位后，如何访问数据的问题。可能有如下情况\n访问同一磁道上不同编号的扇区 访问不同磁道上不同编号的扇区 访问不同磁道上相同编号的扇区 当一次移臂调度将移动臂定位到某一柱面后，还可能要进行多次旋转调度才能得到所有数据。\n信息的优化分布\n以一道例题来说明吧\n70.jpg\r假设\\(n\\)是每个磁道的块数，\\(t\\)是转一周的时间，\\(h\\)是一个记录的读取时间（有\\(h=t/n\\)），\\(p\\)是读取后的处理时间。那么顺序读写的时间为\n\\[(n-1)\\times(h+t)+h+p \\]\n基本思想是，前\\(n-1\\)个读取，都要消耗一次读取时间，而且平均都需要再转一圈才能得到下一个记录。最后一个读取则只有一次读取时间和一次读取后的处理时间。\n如果按照最佳安排顺序，即在读取后处理的时间中，根据旋转的距离，安排下一个连续记录的位置。那么总的顺序读写时间为\n\\[(n-1)\\times(\\left \\lceil \\frac{p}{h} \\right \\rceil +1)\\times h+h+p \\]\n假设安排第一个记录的区块为\\(0\\)，那么安排下一个连续区块的位置就是\\(\\left \\lceil \\frac{p}{h} \\right \\rceil+1\\)。\n在本题中，顺序存放时，顺序读写的时间为\\(8*(27+3)+3+2=245ms\\)，而最佳安排后\\(8*6+5=53ms\\)。而间隔距离\\(\\left \\lceil \\frac{2}{3} \\right \\rceil+1=2\\)，所以按照AFBGCHDIE的顺序存放。\n系统调用 不知道放哪就单独拿出来说。\n为什么引入系统调用（system call） 主要目的是为了让用户程序能与操作系统进行交互和访问底层系统资源。\n访问受限资源\n出于系统安全性和稳定性的考虑，有些计算机资源无法直接访问，可以通过系统调用访问受限资源\n提供抽象接口\n隐藏底层硬件和系统实现的复杂性\n系统功能拓展\n系统调用允许用户程序通过它来拓展操作系统的功能\n提供用户空间与内核空间之间的界限\n用户程序在用户空间运行，内核在内核空间运行，用户程序可以通过系统调用请求内核操作，可以防治用户程序对系统资源的滥用\n分布式系统 分布式计算机系统 分布式计算机系统(Distributed Computer Systems)是由多个分散的计算机经网络连接而形成的统一的计算机系统。其中各个资源单元(物理的或逻辑的)既相互协同又高度自治\n物理资源：包括处理机、输入输出接口、通信接口等。\n逻辑资源：进程，文件、数据库等。\n其特性有：\n分布性。资源在物理上是分散的 自治性。多个主机都处于平等地位，在物理上独立。 透明性。系统的分布性、操作和实现对用户完全透明， 共享性。 协同性。 其功能为：\n通信 资源共享 协同工作 其结构多种多样，如\n68.jpg\r性能衡量标准：\n基本开销：连接系统中的各个场点要多少花费。 通信开销：两个点之间的通信时间 可靠性：某台机器出现故障，剩下的机器是否能工作？ 分布式操作系统 分布式操作系统就是管理分布式系统软硬件资源，是提供具有分布式系统特征的功能和服务的软件系统。\n主要特点为：\n进程通信不能借助公共存储器，因而常采用信息传递方式 系统中的资源分布于多个场点 不失时机地协调各场点的负载 故障检测与恢复及系统重构和可靠性等问题的处理和实现都比较复杂。 远程过程调用（RPC） 允许程序调用位于其它节点机器上的过程。\n当节点A上的进程想调用节点B上的一个过程时，A上的调用进程被挂起，调用信息以参数的形式从节点A传送到节点B，在B上执行被调用过程，然后将执行的结果返回节点A。对程序员来说，他看不到消息传递过程和I/O处理过程。\n操作系统安全 概述 操作系统的不安全性主要是由于系统设计中的“破绽”所引起的。\n网络攻击破坏系统的可用性和完整性。例如网络病毒传播 隐通道破坏系统的保密性和完整性。隐通道是指系统的一个用户通过违反系统安全策略的方式传送信息给另一用户的机制。 无意和偶发性的攻击破坏操作系统的可用性和完整性。包括用户操作上的失误，计算机硬件的故障、其他软件中存在的潜在漏洞，计算机运行环境不达标以及突然断电、火灾等自然灾害 操作系统安全两个方面：\n设计安全 使用安全 实现操作系统安全的手段：\n访问控制 安全审计 内存保护等 开发安全操作系统的步骤：\n建立安全模型 进行系统设计 可信度检查 系统实现 安全机制 操作系统安全的主要目标如下：\n通过安全策略，防止用户对计算机资源的非法使用 对用户进行身份识别 监督系统运行的安全性 保证系统自身的安全性和完整性 硬件安全机制 存储安全\n访问判决基于物理页号的识别\n运行保护\n安全操作系统很重要的一点是进行分层设计，而运行域正是这样一种基于保护环（Protection）的等级式结构。运行域是进程运行的区域，在最内层、具有最小环号的环具有最高特权，而在最外层、具有最大环号的环是最小的特权环。一般的系统不少于3～4个环。\n69.jpg\rIO保护\n标识与鉴别机制 标识（Identification）就是系统要标识用户的身份，并为每个用户去一个内部名称-用户标识符，用户标识符必须是唯一的且不能被伪造。将用户标识符与用户联系的过程称为鉴别（Authentication），鉴别过程主要用以识别用户的真实身份，要求用户具有能够证明其身份的特殊信息。一般情况下，可以通过多个因素来共同鉴别用户身份的真伪。\n常用的方法有：\n基于密码的身份验证 基于令牌的身份验证 生物特征识别认证 访问控制机制 目标是防止非法用户进入系统和合法用户对系统资源的非法使用。访问控制常以 用户身份认证为前提。\n如果说用户标识与鉴别机制解决的是“你是谁？你宣称的身份是否真实？”，访问控制技术解决的就是“你能做什么？你有什么样的权限？”\n常用的策略有\n自主访问控制（DAC）。传统方法 强制访问控制（MAC）。从军事信息安全中演化出来 基于角色的访问控制（RBAC）。越来越受欢迎 最小权限管理 系统不应给用户/管理员超过执行任务所需权限以外的权限，如将超级用户的权限划分为一 组细粒度的权限，分别授予不同的系统操作员/管理员，使各种系统操作员/管理员只具有完成其任务所需的权限，从而减少由于权限用户口令丢失或错误软件、恶意软件、误操作引起的损失。\n可信路径 用户必须确实与安全核心通信，而不是与一个特洛伊木马打交道。系统必须防止特洛伊木马模仿登录过程，窃取用户的口令。可信路径提供了一种确保安全通信的方法。\n审计 审计就是对系统中有关安全的活动进行记录、检查及审核。审计作为一种事后追查的手段来保证系统的安全\nLinux的安全性实例 PAM机制 PAM即可插拔认证模块。是一种高效而且灵活便利的用户级别的认证方式。\nPAM最大的特点是实现了服务程序和认证机制的分离，它采用模块化设计和插件功能，使得我们可以轻易地在应用程序中插入新的鉴别模块或替换原先的组件，而不必对应用程序做任何修改，从而使软件的定制、维持和升级更加轻松——因为鉴别机制与应用程序之间相对独立。\n文件系统加密 较有代表性的是TCFS（Transparent Cryptographic File System）。它通过将加密服务和文件系统紧密集成，使用户感觉不到文件的加密过程。TCFS不修改文件系统的数据结构，备份与修复以及用户访问保密文件的语义也不变。\n网络监控与入侵检测 包括让Linux记录入侵企图，当攻击发生时及时通知管理员；让Linux在规定情况的攻击发生时，采取事先确定的措施；让Linux发出一些错误信息，比如模仿成其他操作系统，以增加攻击者的攻击难度。\n强制访问控制 没讲细节\n安全审计 Linux还可以进行检测、记录时间信息和网络连接情况。这些信息将被重定 向到日志中备查。\n防火墙机制 防火墙是在被保护网络和因特网之间，或者在其他网络之间限制访问的一种部件或一系列部件。Linux防火墙系统提供了如下功能：\n访问控制 审计 抗攻击 其他附属功能。如与审计相关的报警和入侵检测，与访问控制相关的身份验证、加密和认证，甚至VPN等 ","date":"2024-01-01T20:01:20+08:00","image":"https://kegalas.top/inferior/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/cover_hucd8e14c4efc19cc77fb7e62d6a8c22d5_18667_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/","title":"操作系统课程笔记"},{"content":"中英文词汇对照 因为这门课是英语试卷，有些专有名词还是得记录\n英文 中文 neurons 神经元 cortex 皮质（尤指大脑皮层） neocortex 新皮质 synapses 突触 synaptic 突触的 dopamine 多巴胺 amnesia 失忆 prefrontal cortex 额叶前皮质 lobe 脑叶 subcortical 皮质下的 hippocampus 海马区 amygdala 杏仁核 thalamus 丘脑 basal ganglia 基底核 cerebellum 小脑 occipital lobe 枕叶 temporal lobe 颞叶 frontal lobe 额叶 parietal lobe 顶叶 arousal 激励 modulatory functions 调节功能 Reinforcement Learning 强化学习 Motor Control 运动控制 Executive Function 执行功能 motor coordination 运动协调 semantic 语义的 spike dendrites 树突 axon 轴突 excitatory pyramidal neurons 兴奋性椎体神经元 inhibitory interneurons 抑制性中间神经元 white matter 白质 Likelihood function 似然函数 neurology 神经学 genetics 遗传学 认知计算绪论 大脑 在大脑新皮质上，每个神经元都有约10k个来自其他神经元的输入，通过突触连接。而大脑中总体有20billion规模的神经元。\n虽然每两个神经元之间的连接相对而言影响较小，但是通过学习机制（learning mechanisms），这些神经元们可以实现非常复杂的信息处理功能。\n大脑的学习过程并不要求单个神经元非常复杂，它其实是信息整合的一个简单形式\n准确描述神经元的反应特性 在聚合神经网络上实现复杂的信息处理 认知计算的基本问题 视觉 注意力 多巴胺与奖励机制 记忆 含义（Meaning） 任务导向行为 我们应该关注大脑的什么？ David Marr认为，我们只需要独立地关注三个层次：\n计算层次。即大脑中在进行什么计算，什么信息在被处理？ 算法层次。大脑中的计算是如何进行的，信息处理的步骤是什么？ 实现层面。硬件如何实现这些算法？ 注意独立，我们就可以抛弃实现，只研究计算和算法层次。\n这部分的研究的简明历史如下\n1960s~1990s，主要的研究是认为人脑和传统计算机差不多，所以研究主要面向逻辑和符号命题 后来，基于概率的研究变得流行，贝叶斯概率的框架使用广泛，他强调大脑在信息处理过程中的分级性质。但是贝叶斯理论对大脑在神经层面的拟合不是很好，实际上大脑不像一个通用的计算设备 神经网络 脑区域之下皮质 1.jpg\r海马区（Hippocampus） 是旧皮质，在短期记忆中有很重要的作用。\n杏仁核（Amyglada） 对情绪显著刺激（emotionally salient stimuli）很重要，并且可以向大脑的其他部分发送警报（alert）。\n它在基于奖惩机制的强化运动（和认知）动作（reinforcing motor (and cognitive) actions）中也发挥重要的作用。\n丘脑（Thalamus） 为感官信息进入大脑新皮质提供了主要通道。也可能对注意力、激励和其他调节功能很重要。它在感知和注意力以及运动控制和强化学习中发挥作用。\n基底核（Basal Ganglia） 它是下皮质的一系列区域的集合，在运动控制、强化学习和执行功能（Executive Function）中发挥关键作用\n它帮助做出最后的“GO”指令，决定是否执行大脑皮层建议的特定动作，以及决定是否更新前额叶的认知计划。\n小脑（Cerebellum） 其神经元占了脑的一半，在运动协调中有重要作用。在大部分认知任务中也处于活跃状态。\n脑区域之新皮质 2.jpg\rBrodmann根据解剖结果把大脑分为四个区域。\n枕叶（Occipital lobe） 这里包含初级的视觉皮层，在枕叶的非常末端的位置。然后包含向外辐射的高级视觉中枢。\n颞叶（Temporal lobe） 包含初级的听觉皮层，以及联系到高级听觉和语言处理的区域。\n与此同时，视觉看到的物体转换到语言、语言转换到视觉的功能也是在这里进行的。这也是我们为什么能进行阅读的原因。\n颞叶也对语义知识（semantic knowledg）很重要，也就是你对事物的深层理解。\n这里包含了我们对于他人的面容、名字，事实、事件、物体、文字的认知。\n额叶 额叶的前部，或叫前额叶，是大脑执行功能的区域。这里是所有高级shots被called的区域。\n在这里，你的所有计划被整理出来，然后受基本动机和情绪的影响后，才真正决定你会如何行动。\n这里也是处理最抽象、最有挑战性的认知形式的关键所在。\n额叶皮层的内侧和腹侧区域对于情绪和动机非常重要。\n顶叶（Parietal lobe） 这里对encoding空间位置、数字、数学、抽象关系和其他有关“智慧”的东西很重要。\n它给视觉信息指导运动动作提供了主要的通道。\n神经元 大脑神经元如此复杂，其是为了一个非常简单的整体功能“检测（detection）”服务的。\n神经元接受数以千计的输入，但其中重要且有意义的只有一些特定模式（specific pattern）的输入，这些有价值的输入被称为“spike”，这也是神经元之间交流的基础。\n神经元接受信号后，将它们与阈值比较，然后加入到总体的输出中，再用这个总体的输出和其他神经元交流。\n把神经元看作是Detector 发送神经元和接收神经元用突触连接，大部分突触都连接在接收端的树突上。这些信号通过树突进入细胞体，进行信息的处理与综合。\n输出的阈值判断发生在输出端的最开始，也就是轴突。\n突触网络的效能或者说权重，指的是发送神经元发送的信号能以多大程度影响到接收神经元。\n从计算上说，权重决定了一个神经元接受什么。权重越大，神经元对这个输入就更敏感，反之亦然。\n学习的过程就是不断地调整神经元之间连接的权重，来达到想要的输出。\n大脑新皮质的神经网络 有85%的神经元是兴奋性锥体神经元（excitatory pyramidal neurons），它们的连接跨度很广，可以跨越不同的脑区，有时候甚至可以跨越整个大脑。学习行为主要就发生在这些兴奋性神经元中；有15%是抑制性中间神经元（inhibitory interneurons），它们的连接更加局部化。某种意义上，可以理解为兴奋性神经元的散热器。\n新皮质的层级结构 新皮质具有6种不同的层，每种脑区都有这种6层结构。但是拥有不同功能的脑区，其6层结构的厚度也各有不同，暗示了层级结构的功能。\n新皮质中负责数据输入的脑区（Input Area）接收感知的输入（例如视觉；通常会经过丘脑），这些脑区的Layer 4通常会更大。这是因为来自丘脑的轴突都连接到这里。这些输入层（input layer）有一种特别的兴奋性神经元，称为星状细胞（stellate cell）。这些细胞的树突非常浓密，并且似乎尤其善于收集这一层的局部轴突输入。\n新皮质中的隐藏脑区（Hidden Area），并不直接接受感觉输入，也不直接输出运动动作。它们是这个输入和输出的中间部分。我们可以理解为，这些区域从感官输入中创建越来越复杂和抽象的类别（catagories），然后再从这些高级类别中，协助选择出正确的运动动作。这些脑区的superficial layers 2/3会更厚，包含了许多锥体神经元，并且都放在很好的位置来实现这些抽象化功能。\n新皮质中的输出脑区（Output Area），拥有直接作用于肌肉控制区的突触，发出电信号后，可以直接影响物理运动。这些输出层有更厚的deep layer 5/6，会把轴突发送给许多下皮质区域。\n新皮质中的连接模式 信息传输包含正向传播和反向传播两个过程。\n正向传播时，信息从感官信息流向大脑中更高级、更深的部分，从而形成了越来越抽象和复杂的类别（catagories）\n反向传播时，信息从隐藏层和输出层出发，回到这些区域在正向传播时的前级区域，从而支持自上而下的行为认知控制、直接注意力，并且帮助解决感官输入中的歧义。\n所以说，区域之间的连接很大程度上是双向的，发送前向信息的区域通常也会收到下级区域的信息。这种双向连接对于使网络能够跨层聚合到连贯的整体活动状态很重要，对于错误驱动（error-driven）的学习也很重要。\n类别和分布式表示（Categorization and Distributed Representations） 3.jpg\r如上，当我们看到一个人时，在最低的一层中，这里我们获得的表示只有一些最基本的特征。在下一层，我们把这些特征连起来，变成更复杂的视觉特征。在下一层，我们把面部特征全部组合了起来，形成了对于面容的认知。最后，我们把这张脸和语义上的各种东西关联起来，例如名字，性别，性格。\n这个过程可以通过fMRI来显示，不同视觉刺激的脑部活动区域高度重合。\n神经元的数学公式 一个基本的积分和激发神经元（A Basic Integrate-and-Fire Neuron）\n\\[\\tau_m\\dfrac{du(t)}{dt}=u_{res}-u(t)+R_mi(t) \\]\n其中\\(\\tau_m\\)是神经元的膜时间常数，其由通道的平均电导决定。\\(u_{res}\\)是神经元的静息电位。\\(i(t)\\)是输入电流，其由突触前神经元放电产生，并且是众多这种放电的和。\\(R_m\\)是神经元对电流的电阻。\n具体来说，\\(i(t)\\)还受到突触连接强度的影响，\n\\[i(t) = \\sum_j\\sum_{t^f_j} w_jf(t-t^f_j) \\]\n其中\\(f(\\cdot)\\)代表激活函数，\\(t\\)表示突触\\(j\\)的突触前神经元的放电时间，该时间由膜电位\\(u\\)达到阈值\\(\\theta\\)的时间决定。\n\\[u(t^f) = \\theta \\]\n模式识别绪论 模式识别是什么 模式识别是研究如何让机器观察环境，学习从环境中区分出感兴趣的物体，然后做出明智的有理由的决策。\n主要包括：目标识别（人脸识别）、语音识别、文本分类、图像视频识别等。\n模式识别的两个核心：特征提取和分类器设计。\n存在于时间和空间中可观察的物体，如果我们可以区别它们是否相同或是否相似，都可以称之为模式。\n识别的过程是从底层，逐渐抽象到高层，这样的一个过程。\n模式识别的目的：利用计算机对物体（模式）进行分类，在错误概率最小的条件下，使识别的结果尽量与客观物体相符合。\n模式识别的基本概念 样本：一类事物的一个具体体现，所研究对象的一个个体，也称模式。 样本集：若干样本的集合 类或类别：在所有样本上定义的一个子集，处于同一类的样本在我们所关心的性质上是不可区分的，即具有相同的模式，也称模式类。 特征：用于表征样本的观测信息，通常是数值表示的，有时也称为属性（attribute）；如果是高维则称为特征向量，样本的特征（向量）构成了特征空间，每个样本是特征空间中的一个点。 已知样本：事先知道类别标号的样本 未知样本（待识别的样本，测试样本）：类别标号未知但特征已知的样本 一般来说，模式识别必须经过如下的过程：模式空间-\u0026gt;特征空间-\u0026gt;类型空间\n在模式空间（等于特征空间）中每个样本模式都是一个点，点的位置由该模式在各维上的测量值确定。 模式空间中的点经过特征提取就得到了特征空间。对模式空间里的各坐标元素进行综合分析，以提取最能揭示样本属性的特征，这些特征就构成特征空间。 特征空间进行分类决策就得到了类型空间。根据适当的判决规则，把特征空间里的样本区分成不同的类型，从而把特征空间塑造成了类型空间。 模式识别的基本框架 传感器（sensing）：信号采集 分割：使图像模式互不重叠 特征提取：可判别特征、平移、旋转和尺度变换不变性特征 分类 后处理 训练和识别流程：\n83.jpg\r模式识别系统设计的五个步骤：\n收集数据 特征选择 选择模型 训练分类器 评估分类器 分类器主要有有监督学习和无监督学习。具体可以看后面传统机器学习方法。\n模式识别的方法 模板匹配 首先对每个类别建立一个或多个模板，然后对输入数据和每个类别的模板求距离或相关，根据相关性和距离大小做分类。\n优点：简单直接\n缺点：适应性差\n形变模板\n统计方法 根据训练样本，建立决策边界。这是我们课上的重点。\n统计决策理论：根据每一类总体的概率分布决定决策边界 判别式分析方法：给出带参数的决策边界，根据某种准则，由训练样本决定“最优”的参数 句法方法 许多复杂的模式可以分解为简单的子模式，这些子模式组成所谓 “基元”。每个模式都可以由基元根据一定的关系来组成。模式的相似性由句子的相似性来决定。\n优点：适合结构性强的模式\n缺点：抗噪声能力差，计算复杂度高\n神经网络 进行大规模并行计算的数学模型。具有学习、推广、自适应、容错、分布表达和计算的能力。\n优点：可以有效的解决一些复杂的非线性问题 缺点：缺少有效的学习理论 比较 82.jpg\r机器学习绪论 定义 机器学习是研究“不通过显式编程的方法让机器能够学习”的学问。\n电脑程序通过学习关于任务T的经验E，以及使用一些表现的度量方法P。\n机器学习的算法分类 主要分为两类：监督学习和无监督学习。其他还包括：强化学习、推荐系统等。\n监督学习主要包括回归和分类任务，见后。\n无监督学习主要包括聚类、概率密度估计、数据降维/可视化任务等，见后。\n神经网络基础概念 神经元及其数学模型 4.jpg\r神经元大体上由四个部分组成：细胞体、轴突、树突、突触\n在神经元的信息处理过程中，树突相当于信息的接收器，细胞体相当于加和、处理信息的东西，轴突相当于信息的发射器，突触就是信息传递的连接点。\n神经元只有当输入信息达到阈值后才会兴奋。所有这些信息都是电化学信息。学习则是突触间电化学过程效率的变化的过程。\n于是我们就可以把神经元抽象成一个数学模型（这里是M-P模型）。这其实是一个有向图，每个节点代表神经元的细胞体。每个节点一般的多个输入对应树突，一个输出（有时有多个）对应轴突。神经元的兴奋阈值在这里是节点的激活函数，而突触间的效率在这里就是边的权重。例如下图\n5.jpg\r其中一个经典的模型是感知器：\n6.jpg\r他这里的中间的两个大节点可以理解为把一个节点拆成两个部分。感知器的作用是把一系列输入分为两个类型中的一类。\n人工神经网络的特点 固有的并行结构和并行处理 容错性 自适应性 大脑分区和基础的神经网络 大脑分区和功能之前探讨过了，这里不再赘述。\n神经网络面对的问题是，对于一组历史数据\\(\\{(x_1,y_1),(x_2,y_2),\\cdots,(x_l,y_l)\\}\\)，要找出一个函数\\(f(x)=\\hat y\\)，使得对未来的数据\\(x\\)，\\(\\hat y\\)是一个良好的预测。\n单输入的神经元如下：\n7.jpg\r拓展到多输入为\n8.jpg\r\\(f\\)一般称为激活函数，典型的有：\n阶跃函数、符号函数\n\\[f(x) = step(x) \\]\n\\[f(x)=sgn(x) \\]\n线性函数\n\\[f(x)=kx+b \\]\n但是线性函数不应该被使用，因为可以通过线性组合找到一个等效的二层神经网络，多层的优势就没有了。\n分段线性函数\n89.jpg\rsigmoid函数\n\\[f(x) = \\sigma(x) = \\dfrac{1}{1+e^{-x}} \\]\n特别的，其导数为\n\\[\\sigma'(x) = \\sigma(x)(1-\\sigma(x)) \\]\n其范围为\\((0,1)\\)，输出中心为\\(0.5\\)。指数运算会比较慢，并且\\(x\\)很大时，出现梯度消失问题。\n双曲正切\n\\[f(x) = \\tanh(x)=\\dfrac{2}{1+e^{-2x}}-1 \\]\n长得和Sigmoid很像，但是其范围为\\((-1,1)\\)，输出中心为\\(0\\)。问题和sigmoid相同。\n特别的，其导数为\n\\[\\tanh'(x) = 1-\\tanh^2(x) \\]\nReLU\n\\[f(x)=\\max(0,x) \\]\n其没有指数运算，且不会梯度消失。但输入为负数时，完全失效。\nLeaky ReLU\n即在\\(x\\geq 0\\)时，\\(f(x)=x\\)，在\\(x\u003c0\\)时，\\(f(x)=ax\\)，其中\\(a\\)是一个相对于\\(1\\)很小的正常数。其对ReLU进行了微小的修正，使得在负数输入时有效。\n人工神经网络也叫做多层感知器，但是与感知器略有不同的地方就是激活函数，感知器只会用阶跃函数，而神经网络更多用sigmoid函数。这使得神经网络是可微分的。\n人工神经网络的拓扑结构 单层网络\n有了这些东西，我们就可以构造神经网络了，其中最简单的单层（Single Layer）（输入数据不被看做一层）神经网络如下。\n9.jpg\r这样的神经网络作用极其有限。只能用在线性分类任务上，大部分函数都不是线性的，或者不是线性可分的。\n多层网络\n于是就有了多层的神经网络，在上图的输入层和输出层之间添加一个或非常多个隐藏层。\n10.jpg\r这样，神经网络就能处理更多复杂的分类问题。但是，多层神经网络的问题是难以训练。\n在构成多层网络时，层间的转移函数应是非线性的，否则多层网络的计算能力并不比单层网络强。若干的线性单元层叠加还是线性单元。\n回归型网络（反馈网络）\n90.jpg\r一般来说，凡包含反馈连接的网络均称为回归型网络，或称反馈网络。\n前馈型网络(feed-forward network)\n91.jpg\r结点按照一定的层次排列； 网络是单向的，信号只能按照单一的方向，从下一层结点传递到相应的上一层结点； 上层结点与下一层所有结点相联接。 层间（Inter-field）联接 代表网络有：多层感知机、径向基函数网络。\n反馈型网络(feed-back network)\n92.jpg\r输入信号作用于神经元结点后，各个结点的输出又作为输入反馈到各结点，形成一个动态系统，当系统稳定后读取其输出； 层间（Inter-field）联接 循环联接 代表网络：Hopfield网络\n竞争学习网络(competitive learning network)\n93.jpg\r神经元结点通常排列在同一个层次上； 没有反馈联接，但是结点之间有横向的联接或相互影响； 在学习时通过神经元之间的竞争实现特定的映射。 层内（Intra-field）联接 代表网络：自组织映射(SOM)网络\n正向传播和反向传播 在感知器算法中我们实际上是在利用理想输出与实际输出之间的误差作为增量来修正权值，然而在多层感知器中，我们只能计算出输出层的误差，中间隐层由于不直接与外界连接，其误差无法估计。\n反向传播算法的出现解决了训练的问题。从后向前反向逐层传播输出层的误差，以间接计算隐层的误差。\n算法分为两个阶段\n正向过程：从输入层经隐层逐层正向计算各单元的输出； 反向过程：由输出误差逐层反向计算隐层各单元的误差，并用此误差修正前层的权值。 流程为\n选择一组训练样本，每一个样本由输入信息和期望的输出结果两部分组成。 从训练样本集中取一样本，把输入信息输入到网络中。 分别计算经神经元处理后的各层结点的输出。 计算网络的实际输出和期望输出的误差。 从输出层反向计算到第一个隐层，并按照某种能使误差向减小方向发展的原则，调整网络中各神经元的连接权值。 对训练样本集中的每一个样本重复3-5的步骤，直到对整个训练样本集的误差达到要求时为止。 机器学习课程中的符号：\\(a_i^{(j)}\\)表示，第\\(j\\)层的第\\(i\\)个神经元接受到的数据和，\\(w^{(j)}_{xy}\\)表示\\(j\\)层到下一层的连接权重，其中\\(y\\)是\\(j\\)层的神经元序号，\\(x\\)是下一层的神经元序号。\\(z_i^{(j)}\\)表示第\\(j\\)层的第\\(i\\)个神经元激活函数后的输出。例如\n\\[z^{(2)}_1 = h(a_1^{(2)}) = h(w_{10}^{(1)}x_0+w_{11}^{(1)}x_1+w_{12}^{(1)}x_2+w_{13}^{(1)}x_3) \\]\n其中\\(x\\)是输入层，其等价于\\(x_i = z^{(1)}_i\\)。一般\\(z_0^{(j)}\\)都是这一层的常数偏置。\n表示为矩阵可以为\n\\[a^{(2)} = W^{(1)}x \\]\n\\[z^{(2)} = h(a^{(2)})（算完之后还要加上偏置项） \\]\n假设本层有\\(s_j\\)个神经元（除去偏置），下一层有\\(s_{j+1}\\)个神经元，那么\\(W^{(j)}\\)的大小为\\(s_{j+1}\\times (s_j+1)\\)。\n其中输出一般记为\\(y\\)，而标签记为\\(t\\)\n这样一层一层地往下算算到输出，就是正向传播过程。\n对于回归问题\n回归问题中，输出层的激活函数是恒等函数，即该层的输入等于输出。\n一般用SSE来度量误差\n\\[ E = \\dfrac{1}{2}\\sum_{n=1}^N(y_n-t_n)^2 \\]\n其中\\(N\\)是训练集大小\n输出层的输出等于输出层的输入意味着\\(y_j=a_j\\)，也意味着\n\\[\\dfrac{\\partial E}{\\partial a_k} = y_j-t_j \\]\n对于分类问题\n分类问题中，输出层也会用sigmoid。\n机器学习课程中，对于二分类问题会用交叉熵来度量\n\\[E = -\\sum_{n=1}^N[t_n\\log y_n+(1-t_n)\\log (1-y_n)] \\]\n此时输出层只要一个输出即可，\\(y\\)代表输入属于正类的概率。\n对于多分类问题，会把标签和输出都one-hot编码成\\(K\\)维向量。此时，\\(K\\)类的交叉熵为\n\\[E = -\\sum^N_{n=1}\\sum^K_{k=1}[t_{nk}\\log y_{nk}+(1-t_{nk})ln(1-y_{nk}))] \\]\n如果所有类是互斥的，那么有\n\\[E = -\\sum^N_{n=1}\\sum^K_{k=1}t_{nk}\\log y_{nk} \\]\n通常，多分类时\\(y\\)的激活函数会用softmax，即\n\\[y_k(x,w) = \\dfrac{\\exp(a_k(x,w))}{\\sum_j \\exp(a_j(x,w))} \\]\n模式识别课程中还是用SSE来度量。\n反向传播算法（模式识别课程版）\n反向传播算法中采用梯度法修正权值，为此要求输出函数可微 。通常采用sigmoid函数作为输出函数。假设神经元\\(j\\)的期望输出是\\(t_j\\)，实际输出是\\(o_j\\)，那么误差（SSE）就是\n\\[E = \\dfrac{1}{2}\\sum_j(t_j-o_j)^2 \\]\n我们要优化的是每个连接的权重，我们就要找到每个权重对于误差的影响，偏导数\n\\[\\dfrac{\\partial E}{\\partial w_{ij}} \\]\n其中\\(w_{ij}\\)是神经元\\(i\\)到\\(j\\)的权重\n我们经常会用梯度下降法来优化权重，其迭代方向为\n\\[\\Delta w_{ij} = -\\eta\\dfrac{\\partial E}{\\partial w_{ij}} \\]\n假设上一层的输出是\\(b_i\\)，这一层的总输入为\\(\\beta_j\\)，那么有\\(\\beta_j = \\sum_i w_{ij}b_i\\)\n注意到\\(w_{ij}\\)首先影响输入值\\(\\beta_j\\)，再影响到输出值\\(o_j\\)，最后才能影响到\\(E\\)。所以\n\\[\\dfrac{\\partial E}{\\partial w_{ij}} = \\dfrac{\\partial E}{\\partial o_j}\\cdot \\dfrac{\\partial o_j}{\\partial \\beta_j}\\cdot\\dfrac{\\partial \\beta_j}{\\partial w_{ij}} \\]\n其中，显然有\\(\\dfrac{\\partial \\beta_j}{\\partial w_{ij}}=b_i\\)\n设\\(g_j = -\\dfrac{\\partial E}{\\partial o_j}\\cdot \\dfrac{\\partial o_j}{\\partial \\beta_j}\\)，如果激活函数为\\(\\sigma(x)\\)，假设神经元阈值为\\(\\theta_j\\)，则\n\\[g_j = -(t_j-o_j)\\sigma'(\\beta_j-\\theta_j) = o_j(1-o_j)(t_j-o_j) \\]\n于是更新公式为\n\\[w_{ij}\\leftarrow w_{ij}+\\Delta w_{ij} = w_{ij} + \\eta g_jb_i \\]\n综上，BP算法的迭代一次的流程为\n从前向后各层计算各单元的实际输出\\(o_j\\)。\\(\\beta_j = \\sum_i w_{ij}o_i\\)（假设上一层的输出为\\(o_i\\)），\\(o_j = \\sigma(\\beta_j)\\) 对输出层计算\\(g_j=-o_j(1-o_j)(t_j-o_j)\\)（注意这里采用了和之前稍微不同的方向，后面也会对应修改方向） 从后向前计算各隐层\\(g_j=o_j(1-o_j)\\sum_k w_{jk}g_k\\) 计算并保存各个权值修正量\\(\\Delta w_{ij} = -\\eta g_j o_i\\) 修正权值\\(w_{ij}\\leftarrow w_{ij}+\\Delta w_{ij}\\) 反向传播算法（机器学习课程版）\n反向传播分为两步走。第一步，即误差在网络中的反向传播，然后用来计算梯度。第二步，即使用梯度来调整权重。\n令人奇怪的是，他这里又不用交叉熵，改用SSE了，见前。\n这里会默认使用随机梯度降，总的误差为\n\\[E(w) = \\sum^N_{n=1}E_n(W) \\]\n计算输出层梯度时，有\n\\[\\dfrac{\\partial E_n}{\\partial w_{ji}} = \\dfrac{\\partial E_n}{\\partial a_{j}}\\dfrac{\\partial a_j}{\\partial w_{ji}} \\]\n记\n\\[\\delta_j = \\dfrac{\\partial E_n}{\\partial a_{j}} \\]\n它经常被叫做“误差”。\n因为\\(a_j = \\sum_i w_{ji}z_i\\)，所以有\n\\[\\dfrac{\\partial a_j}{\\partial w_{ji}} = z_i \\]\n所以\n\\[\\dfrac{\\partial E_n}{\\partial w_{ji}} = \\delta_jz_i \\]\n如果假设我们在输出层使用恒等函数作为激活函数，那么\n\\[\\delta_k = y_k-t_k \\]\n之后，我们计算隐藏层的梯度，用同样的方法\n\\[\\delta_j = \\dfrac{\\partial E_n}{\\partial a_j} = \\sum_k\\dfrac{\\partial E_n}{\\partial a_k}\\dfrac{\\partial a_k}{\\partial a_j} \\]\n其中\\(j\\)是隐藏层的节点，\\(k\\)是该节点连接到的输出层节点。下图是比较直观的一个过程\n115.jpg\r其中蓝色的过程是正向传播，红色的过程是反向传播。假设我们在隐藏层使用的激活函数是\\(h(\\cdot)\\)，那么有\\(\\dfrac{\\partial a_k}{\\partial a_j}=h'(a_j)w_{kj}\\)，有\n\\[\\delta_j = h'(a_j)\\sum_k w_{kj}\\delta_k \\]\n这样只要我们一层层往回推，就能推出对于输出的偏导公式。每一层的输出记为\\(z\\)的话，每一层的权重的梯度都有如下的形式\n\\[\\dfrac{\\partial E_n}{\\partial w_{ji}} = \\delta_iz_j \\]\n举一个例子\n116.jpg\r假设输出层激活函数为恒等函数，隐藏层激活函数为\\(\\tanh(a)\\)，易知其导数为\\(h'(a) = 1-h(a)^2\\)。对于每个样本，我们同样定义SSE\n\\[E_n = \\dfrac{1}{2}\\sum^K_{k=1}(y_k-t_k)^2 \\]\n对于每个样本，我们先执行正向传播过程，有\n\\[a_j = \\sum^D_{i=0}w^{(1)}_{ji}x_i \\]\n\\[z_j = \\tanh(a_j) \\]\n\\[y_k = \\sum^M_{j=0}w^{(2)}_{kj}z_j \\]\n之后，我们首先计算输出层的\\(\\delta\\)，为\n\\[\\delta_k = y_k-t_k \\]\n之后反向传播到隐藏层有\n\\[\\delta_j = (1-z_j^2)\\sum^{K}_{k=1}w_{kj}\\delta_k \\]\n最后计算出梯度为\n\\[\\dfrac{\\partial E_n}{\\partial w^{(1)}_{ji}} = \\delta_jx_i,\\quad \\dfrac{\\partial E_n}{\\partial w^{(2)}_{kj}} = \\delta_kz_j \\]\n然后就可以拿这个东西去随机梯度降了。\n反向传播算法复杂度分析\n假设网络中的所有权重有\\(W\\)个，那么对于一个样本的误差的计算，就是\\(O(W)\\)的。\n除了稀疏的网络，权重的数量会远远大于神经元的数量。大部分开销都花在了计算权重加权和上了，计算激活函数的都是少的。\n一种解决办法是，使用有限差分法（\\(\\epsilon \u003c\u003c 1\\)）\n\\[\\dfrac{\\partial E_n}{\\partial w_{ji}} = \\dfrac{E_n(w_{ji}+\\epsilon)-E_n(w_{ji})}{\\epsilon}+O(\\epsilon) \\]\n或者\n\\[\\dfrac{\\partial E_n}{\\partial w_{ji}} = \\dfrac{E_n(w_{ji}+\\epsilon)-E_n(w_{ji}-\\epsilon)}{2\\epsilon}+O(\\epsilon^2) \\]\n但是这种办法的时间复杂度甚至更差了，\\(O(W)\\)的前向传播，另外，每个权重都必须自己更新自己的，使得反向传播为\\(O(W^2)\\)\n但是这个东西也不是没用，可以检查反向传播算法实现的正确性。\n反向传播算法的优缺点\n优点：理论基础牢固，推导过程严谨，物理概念清晰，通用性好等。所以，它是目前用来训练前馈多层网络较好的算法。\n缺点：收敛慢；不能保证全局最优；推广能力有可能较差。\nLocal quadratic approximation 讲了一大串没搞明白，我看也不会考，就记住：一个驻点为最小值时，这个点的二阶偏导数大于零（对于单权重情况），或者这个点的海瑟矩阵正定（对于多权重情况）。\n正则化神经网络 给神经网络一个正则化项，以期其能拥有更好的泛化性能，在拟合不足和过拟合之间取得平衡点。通常正则化项是加载误差函数上的，最简单的是二次形式的（quadratic）：\n\\[\\tilde{E}(w) = E(w) + \\dfrac{\\lambda}{2}w^Tw \\]\n这个正则化项也被称作权重衰减（weight decay）。它的一个局限在于，与网格映射中的确定性缩放性质不相容。\n如果我们使用原始数据训练网络，和使用进行了线性变换的数据训练网络，那么相容性要求这两个网络应该是等价的。任何正则化项也应该与这个性质相容，否则模型就会偏向某个解，而忽视某个等价的解。\n简单的权重衰减项由于把所有的偏置和权重同等对待，所以不满足这个性质。\n于是我们要找一个正则化项，使得其对线性不变性不变，如\n\\[\\dfrac{\\lambda_1}{2}\\sum_{w\\in W_1} w^2+\\dfrac{\\lambda_2}{2}\\sum_{w\\in W_2}w^2 \\]\n其中\\(W_1\\)代表第一层的权重，\\(W_2\\)代表第二层的权重，其中加和中不包含偏置项的权重。该正则对应的先验为\n\\[p(w|\\alpha_1,\\alpha_2)\\approx \\exp\\bigg(-\\dfrac{\\alpha_1}{2}\\sum_{w\\in W_1} w^2-\\dfrac{\\alpha_2}{2}\\sum_{w\\in W_2}w^2\\bigg) \\]\n更一般的，对于更多层，有\n\\[p(w|\\alpha_1,\\alpha_2)\\approx \\exp\\bigg(-\\dfrac{1}{2}\\sum_{k}a_k||w||_k^2\\bigg) \\]\n其中\n\\[||w||^2_k=\\sum_{j\\in W_k}w^2 \\]\n（个人觉得课上讲的一坨，完全没介绍前置知识，照搬PRML，可能我以后会自己再做这方面的笔记吧）\n早期停止法 这也是一种防止网络过拟合的方法。\n一般，神经网络的训练对应着误差函数的迭代减小。误差函数是一个关于迭代次数的不增函数，然而，神经网络在测试集、验证集上的误差通常会首先减小，之后迭代过多达到过拟合，然后误差会增大，于是，训练过程可以在验证集误差最小的时候停止。\n117.jpg\r这种情况下，⽹络的⾏为有时可以通过⽹络的⾃由度有效数量来定量描述。⾃由度有效数量开始时很⼩，然后在训练过程中增长，对应于模型复杂度的持续增长。这样，在训练误差达到最⼩值之前停⽌训练就表⽰了⼀种限制模型复杂度的⽅式。\n在⼆次误差函数的情况下，我们可以说明这种直观的描述，并且说明早期停⽌的效果与使⽤简单的权值衰减的正则化项的效果类似。这可以下图来理解。\n118.jpg\r不变量 在许多模式识别的应⽤中，在对于输⼊变量进⾏了⼀个或者多个变换之后，预测不应该发⽣变化，或者说应该具有不变性（invariant）。例如，在⼆维图像（例如⼿写数字）的分类问题中，⼀个特定的图像的类别应该与图像的位置⽆关（平移不变性（translation invariance）），也应该与图像的⼤⼩⽆关（缩放不变性（scale invariance））。\n如果可以得到⾜够多的训练样本，那么可调节的模型（例如神经⽹络）可以学习到不变性，⾄少可以近似地学习到。\n但是，如果训练样本数受限，或者有多个不变性（变换的组合的数量随着变换的数量指数增长），那么这种⽅法就很不实⽤。一般用以下四个方法\n复制训练样本，同时对不变性进行变换。例如平移图像 为误差函数加上正则化项 在预处理阶段，在要求的不变性下做特征提取 把不变性整合进神经网络的构建中 切线传播 通过切线传播（tangent propagation）的⽅法，我们可以使⽤正则化来让模型对于输⼊的变换具有不变性（Simard et al., 1992）。\n不考，略过。\n用变换过的数据来训练 一种方法是，用原始数据集和变化过的数据集加起来当训练集来训练。\n卷积神经网络 见后\n反向传播的推广 不考\n其他常见网络 SOM网络 SOM是一种自组织（竞争型）神经网络。Kohonen认为：一个神经网络接受外界输入模式时，将会分为不同的对应区域，各区域对输入模式具有不同的响应特征，且该过程是自动完成的。\n94.jpg\r该网络由输入层和输出层组成，其中输入层的神经元个数的选取按输入网络的向量个数而定，输入神经元为一维矩阵，接收网络的输入信号，输出层则是由神经元按一定的方式排列成一个二维节点矩阵。输入层的神经元与输出层的神经元通过权值相互联结在一起。当网络接收到外部的输入信号以后，输出层的某个神经元便会“兴奋”起来。\n基本思想：网络的竞争层的各神经元竞争对输入模式响应的机会，最后仅有一个神经元成为竞争的胜者。这一获胜神经元则表示对输入模式的分类。\n学习算法：模拟生物神经元之间的兴奋、协调与抑制、竞争作用的信息处理的动力学原理来指导网络的学习与工作，而不像多层神经网络那样是以网络的误差作为算法的准则。\n竞争学习的步骤：\n向量归一化，对当前向量和全部神经元做归一化 寻找获胜神经元，依据相似度评价 网络输出与权值调整 步骤3完成后回到步骤1继续训练，直到学习率衰减到0 。学习率处于\\((0,1]\\)，一般随着学习的进展而减小，神经元（权重）趋于聚类中心。\nRBF网络 95.jpg\r径向基函数网络（RBF网络）是一种常用的前馈神经网络。（拓扑结构比较固定）\n只有一个隐层； 隐层单元采用径向基函数作为输出函数； 输入层到隐层单元间的权值固定为1； 输出结点为线性求和单元 隐层到输出结点的权值可调 这里的径向基函数是一个非线性映射，将原始空间投影到高维，从而线性可分。它是某种沿径向对称的标量函数。通常定义为空间中任意一点到某一中心之间欧氏距离的单调函数。记为\n\\[k(||x-x_i||) \\]\n其中\\(x\\)是输入向量，\\(x_i\\)是第\\(i\\)个隐节点的中心。径向基函数的作用往往是局部的，离中心越远函数值越小。常用的径向基函数是高斯函数。\n\\[k(||x-x_c||) = \\exp\\bigg(-\\dfrac{||x-x_c||^2}{2\\sigma^2}\\bigg) \\]\n可以从两个方面理解RBF网络\n函数逼近：把网络看成对未知函数\\(f(x)\\)的逼近器。一般任何函数都可以表示成一组基函数的加权和，这相当于用隐层单元的输出函数构成一组基函数来逼近\\(f(x)\\)。 线性分类：把隐层看做是对输入的非线性映射（通常将低维线性不可分的样本映射到高维空间），再用线性分类器（输出结点的输出函数是线性函数）分类。 RBF有三个参数可以调，即\\(x_c,\\sigma\\)和隐层节点到输出节点的权值。RBF学习算法分两个阶段\n确定RBF函数的中心：无师学习 训练隐层与输出节点之间的权值：有师学习 一种可能的具体训练算法步骤如下：\n对所有样本的输入进行聚类（可以采用k均值聚类算法），求得各隐层结点RBF函数的中心。 当RBF函数的中心\\(x_c\\)确定后，训练隐层与输出结点之间的权值。这是一个线性优化问题。（利用训练样本监督完成，如最小二乘法，梯度下降法） 和BP相比，其非线性映射采用了不同的输出函数，径向基函数的作用是局部的，而sigmoid函数是全局的。\n已经证明，RBF网络具有唯一最佳逼近的特性，且无局部极小，可以获得全局最优解\n但是，径向基函数、隐层结点个数难以确定（人工神经网络的公共问题），目前尚无解决方案。隐层结点RBF函数的中心难以求解，阻碍了RBF网络的广泛应用。\nBP网络 参见之前的反向传播算法。\n其解决简单感知器不能解决的疑惑问题。从本质上讲，BP算法就是以网络误差平方为目标函数、采用梯度下降法来计算目标函数的最小值。\nBP神经网络具有很强的非线性映射能力和柔性的网络结构。网络的中间层数、各层的神经元个数可根据具体情况任意设定，并且随着结构的差异其性能也有所不同。\n但是学习速度慢，容易陷入局部最优。网络层数、神经元个数的选择没有相应的理论指导；网络推广能力有限。\nHopfield网络 96.jpg\rHopfield神经网络是一种单层互相全连接的反馈型神经网络。每个神经元既是输入也是输出，网络中的每一个神经元都将自己的输出通过连接权传送给所有其它神经元，同时又都接收所有其它神经元传递过来的信息。即：网络中的神经元在t时刻的输出状态实际上间接地与自己t-1时刻的输 出状态有关。神经元之间互连接，所以得到的权重矩阵将是对称矩阵。\nHopfield神经网络成功引入能量函数的概念，使网络运行地稳定性判断有了可靠依据。基本的Hopfield神经网络是一个由非线性元件构成的全连接型单层递归系统。其状态变化可以用差分方程来表示。\n递归型网络的一个重要特点就是它具有稳定状态。当网络达到稳定状态的时候，也就是它的能量函数达到最小的时候。\n离散随机Hopfield神经网络\n每个神经元只取二元的离散值\\(0,1\\)或\\(-1,1\\)。神经元\\(i\\)和神经元\\(j\\)之间的权重由\\(w_{ij}\\)决定。神经元由当前状态\\(u_i\\)和输出\\(v_i\\)组成，也是二值。\n\\[u_{i}(t+1) = \\sum^n_{j=1}w_{ij} v_j(t)+I_i \\]\n\\[v_i(t+1) = f(u_i) = [u_i\u003e0] \\]\n其中\\(I_i\\)是神经元\\(i\\)的外部连续输入，\\(f\\)是激励函数。\n当网络更新时，如果权重矩阵与非负对角线对称，则下面这个能量函数可以保证最小化，直到系统收敛到其稳定状态之一：\n\\[E = -\\dfrac{1}{2}\\sum^n_{i=1}\\sum^n_{j=1}w_{ij}v_iv_j-\\sum^n_{i=1}I_iv_i \\]\n传统学习 贝叶斯推理和学习 传统的频率学派认为，可以用大量试验中，事件出现的频率来估计概率。\n但是贝叶斯学派不同，贝叶斯学派同时利用样本信息和先验知识。\n频率学派通过大量独立实验将概率解释为统计均值（大数定律）。贝叶斯学派则将概率解释为信念度（degree of belief）（不需要大量的实验）。\n频率学派把模型参数看做固定量，把样本看做随机变量。而贝叶斯学派则都看作随机变量。\n贝叶斯推理在如下情况时，比频率方法更为有效：\n样本数量十分有限 避免过拟合 我们有理由相信某个模型更为合适，但是这个理由不包含在样本数据里 我们更想知道某个事实有多大的可能性，而不是可能性最大的事实是什么 贝叶斯学派经常用到以下概率公式\n条件概率\n\\[P(A|B) = \\dfrac{P(AB)}{P(B)} \\]\n值得注意的是\\(P(A|B)\\neq P(B|A)\\)通常成立\n事件的积的概率\n\\(P(AB) = P(A|B)P(B)\\)\n有\\(P(AB)=P(BA)\\)\n扩展一下\n\\[P(a,b,c) = P(a|b,c)P(b,c) \\]\n全概率公式\n\\[P(A) = P(AB_1)+P(AB_2)+\\cdots+P(AB_n) \\]\n其中\\(B_1+B_2+\\cdots+B_n\\)是必然事件，它们两两互斥。\n于是再由条件概率，得到全概率公式为：\n\\[P(A)=\\sum^n_{i=1}P(A|B_i)P(B_i) \\]\n贝叶斯公式\n\\[P(B_i|A) = \\dfrac{P(A|B_i)P(B_i)}{P(A)}=\\dfrac{P(A|B_i)P(B_i)}{\\sum^n_{i=1}P(A|B_i)P(B_i)} \\]\n将贝叶斯公式写在模型中，得到\n\\[P(model|data) = \\dfrac{P(data|model)P(model)}{P(data)} \\]\n也即\n\\[P(\\theta|X)=\\dfrac{P(X|\\theta)P(\\theta)}{P(X)} \\]\n其中\\(P(\\theta|X)\\)是模型的后验概率，\\(P(X|\\theta)\\)是数据的似然函数（Likelihood Function），\\(P(\\theta)\\)是模型的先验概率，\\(P(X)\\)为证据。\n先验概率 先验概率分布即\\(P(\\theta)\\)，他的目的是，在我们得到任何样本之前，先capture我们对于\\(\\theta\\)的先验知识。\n似然函数 记为\\(L(\\theta|X)=P(X|\\theta)\\)，固定\\(X\\)时，关于参数\\(\\theta\\)的似然函数，（在数值上）等于给定参数\\(\\theta\\)后变量\\(X\\)的概率。\n后验概率 贝叶斯推断的目标就是，使用样本数据\\(X\\)，来更新我们的先验概率\\(P(\\theta)\\)，就得到了后验概率\n最大后验估计（MAP） \\[h_{MAP} = \\arg\\max_{h\\in H} P(h|D) = \\arg\\max_{h\\in H}\\dfrac{P(D|h)P(h)}{P(D)} \\]\n由于分母是常数，所以有\n\\[h_{MAP} = \\arg\\max_{h\\in H}P(D|h)P(h) \\]\n最大似然估计（MLP） \\[h_{MLP} = \\arg\\max_{h\\in H}P(D/h) \\]\n在有些时候，所有\\(H\\)的估计的先验概率是一样的（或者可以假设为一样的），就可以用最大似然估计。\n贝叶斯过程 \\[P(X|\\theta)=\\dfrac{P(\\theta|X)P(X)}{P(\\theta)} \\]\n假设你对某些特定的参数\\(\\theta\\)感兴趣，那么通用的步骤如下\n通过先验知识确定\\(P(\\theta)\\) 通过试验等办法收集\\(X\\) 用贝叶斯公式得到后验概率 后验概率作为下一次迭代的先验概率，下次迭代时要获取新的\\(X\\) 贝叶斯决策理论（贝叶斯分类器） 其是一种统计决策理论。要求：各个类别的总体概率分布 (先验概率和类条件概率密度) 是已知的；决策分类的类别数是一定的。\n常用的决策准则有：最小错误率准则、最小风险准则、黎曼皮尔逊准则、最小最大决策准则。\n下面解释一下机器学习中的各种概率的实际意义。设有\\(C\\)个类型，类型空间为\\(\\Omega = \\{\\omega_1,\\omega_2,\\cdots,\\omega_C\\}\\)，则\n先验概率\\(P(\\omega_i)\\)：代表未获得观测数据之前类别的分布（即类别占比大小） 类条件概率\\(P(x|\\omega_i)\\)：代表在\\(\\omega_i\\)类中\\(x\\)的概率分布密度 后验概率\\(P(\\omega_i|x)\\)：代表在\\(x\\)出现的条件下\\(\\omega_i\\)出现的概率 例如我们要区分鲈鱼鲑鱼，假设只捕获了这两种鱼，并且捕获的数量相等，则有\\(P(w_1)=P(w_2),P(w_1)+P(w_2)=1\\)\n以光泽度为特征，类条件概率可以为\n84.jpg\r根据贝叶斯公式，就可以得出后验概率。\n\\[P(w_i|x)=\\dfrac{P(x|w_i)P(w_i)}{\\sum P(x|w_j)P(w_j)} \\]\n后验概率的直观含义如下：\n85.jpg\r最小错误率准则（最大后验概率准则）\n于是，如果\\(P(w_1|x)\u003eP(w_2|x)\\)，那么判断为\\(w_1\\)类，否则判断为\\(w_2\\)类。（决策过程）\n此时，真实为\\(w_2\\)却被判定为\\(w_1\\)的概率误差就为\\(P(w_1|x)\\)；真实为\\(w_1\\)却被判定为\\(w_2\\)的概率误差就为\\(P(w_2|x)\\)。无论如何，概率误差为\\(P(error|x)=\\min[P(w_1|x),P(w_2|x)]\\)\n写成连续形式，有平均错误率\n\\[P(error) = \\int ^\\infty_{-\\infty} p(error, x)dx = \\int ^\\infty_{-\\infty} p(error|x)p(x)dx \\]\n总而言之，基于最小错误率的准则会最小化上面的错误率。\n其决策过程有四个等价形式（以二分类为例）\n\\(w = \\arg\\max_{w_j} P(w_j|x)\\) \\(w=\\arg\\max_{w_j}P(x|w_j)P(w_j)\\) 若\\(\\dfrac{P(x|w_1)}{P(x|w_2)}\u003e\\dfrac{P(w_2)}{P(w_1)}\\)，则\\(x\\)属于\\(w_1\\)，否则属于\\(w_2\\)。（似然比形式） 若\\(-\\ln P(x|w_1)+\\ln P(x|w_2)\u003c\\ln\\dfrac{P(w_1)}{P(w_2)}\\)，则\\(x\\)属于\\(w_1\\)，否则属于\\(w_2\\) 最小风险准则\n假设总共有\\(N\\)类，其label分别为\\(y=\\{c_1,c_2,\\cdots,c_N\\}\\)。对于某个样本，设其属于\\(c_j\\)类，其被错误归类为\\(c_i\\)时，损失大小为\\(\\lambda_{ij}\\)。或者说，做出决策\\(\\alpha_i\\)，也就是判定他为\\(c_i\\)类，而真实情况为\\(c_j\\)类的损失为\\(\\lambda(\\alpha_i, c_j)\\)\n对样本\\(x\\)做出决策\\(\\alpha_i\\)的条件风险（或期望损失）就为\n\\[R(\\alpha_i|x) = \\sum^N_{j=1}\\lambda_{ij}P(c_j|x) \\]\n我们的任务是最小化损失，即最小化（期望风险）\n\\[R(h) = E_x[R(h(x)|x)] = \\int R(h(x)|x)p(x)dx \\]\n为了最小化总体风险，我们只需要在每个样本上都选择那个能使条件风险最小的类别。即\n\\[h^*(x)=\\arg\\min_{\\alpha\\in y}R(\\alpha|x) \\]\n此时\\(h^*(x)\\)就是贝叶斯最优分类器。与之对应的总体风险\\(R(h^*)\\)称为贝叶斯风险。\n具体过程为：\n同前，先根据已知条件算出后验概率\\(P(w_i|x)\\) 利用后验概率和损失函数，计算采取每种决策的风险\\(R(c_i|x) = \\sum^N_{j=1}\\lambda_{ij}P(c_j|x)\\) 找出风险最小的决策\\(h^*(x)=\\arg\\min_{c\\in y}R(c|x)\\) 损失函数要根据具体问题具体设置，通常不是很容易，需要有关专家研讨决定。\n以二分类为例，其决策为\\(R(a_1|x)\u003c R(a_2|x)\\)时，判断为属于\\(w_1\\)，否则属于\\(w_2\\)。展开、经过运算后得到似然比形式为\n\\[\\dfrac{P(x|w_1)}{P(x|w_2)}\u003e\\dfrac{\\lambda_{12}-\\lambda_{22}}{\\lambda_{21}-\\lambda_{11}}\\times\\dfrac{P(w_2)}{P(w_1)} \\]\n此时判断属于\\(w_1\\)。\n显然，如果有\\(\\lambda_{12}-\\lambda_{22}=\\lambda_{21}-\\lambda_{11}\\)，那么其等价于最小错误率准则。\n对于多分类任务，我们的损失可以写作（此时等价于多分类最小化分类错误率）\n\\[\\lambda_{ij}\\left\\{\\begin{matrix} 0, \u0026 i=j\\\\ 1, \u0026 i\\neq j \\end{matrix}\\right. \\]\n此时条件概率可以算出来，\n\\[R(c|x) = 1-P(c|x) \\]\n于是最优分类器就为\n\\[h^*(x) = \\arg\\max_{c\\in y}P(c|x) \\]\n即对每个样本\\(x\\)，都选择能使其后验概率最大的类别\\(c\\)\n对于\\(P(c|x)\\)怎样得出，判别式模型对于给定的\\(x\\)，通过直接建模\\(P(c|x)\\)来预测\\(c\\)。而生成式模型，先对联合概率\\(P(x,c)\\)建模，再通过贝叶斯公式得到\\(P(c|x)\\)\n\\[P(c|x)=\\dfrac{P(x,c)}{P(x)} = \\dfrac{P(c)P(x|c)}{P(x)} \\]\n判别函数和决策面、分类器设计 用于表示决策规则的某些函数\\(g_i(x)\\)称为判别函数，每个类别分别对应一个判别函数。\n判别函数与决策面方程密切相关，且都由相应的决策规则所确定。\n对于\\(c\\)类分类问题，按照决策规则可以把\\(d\\)维特征空间分成\\(c\\)个决策域，将划分决策域的边界面称为决策面，在数学上用解析形式可以表示成决策面方程。\n判决区域\\(R_i\\)是特征空间中的一个子空间，所有落入\\(R_i\\)的样本都会被判断为类别\\(w_i\\)\n在判决边界上，通常有两类或多类的判别函数值相等。\n分类器设计就是设计判别函数，求出判定面方程\\(g(x)\\)\n分类器最常用的表述方式为判别函数\\(g_i(x),i=1,2,\\cdots,c\\)\n基于判别函数的判定方法为：\\(w_i = \\arg\\max_i g_i(x)\\)。决策面方程就为\\(g_i(x)=g_j(x)\\)\n基于最小错误率的判决函数就是\\(g_i(x)=P(w_i|x)\\)，基于最小风险的判决函数就是\\(g_i(x)=-R(a_i|x)\\)。\n特别的，对于两分类问题，可以只用一个判别函数\\(g(x)=g_1(x)-g_2(x)\\)。如果\\(g(x)\u003e0\\)，则为\\(w_1\\)，否则为\\(w_2\\)。此时决策面为\\(g(x)=0\\)\n朴素贝叶斯分类器 之前的贝叶斯公式的问题是\\(P(x|c)\\)是一个联合概率，其并不方便直接从训练样本里面得出。朴素贝叶斯假设属性条件独立，那么有\n\\[P(c|x)=\\dfrac{P(c)P(x|c)}{P(x)}=\\dfrac{P(c)}{P(x)}\\prod^d_{i=1}P(x_i|c) \\]\n其中\\(d\\)为属性数目，\\(x_i\\)为\\(x\\)在第\\(i\\)个属性上的取值。\n于是朴素贝叶斯分类器就为\n\\[h_{nb} = \\arg\\max_{c\\in y} P(c)\\prod^d_{i=1}P(x_i|c) \\]\n若有充足的独立同分布样本，则可容易地估计出类先验概率\n\\[P(c) = \\dfrac{|D_c|}{|D|} \\]\n即类\\(c\\)的个数在所有样本个数中的占比。\n对于离散属性，条件概率可以估计为\n\\[P(x_i|c)=\\dfrac{|D_{c,x_i}|}{|D_c|} \\]\n\\(D_{c,x_i}\\)指的是，\\(D_c\\)中，在第\\(i\\)个属性上取值为\\(x_i\\)的样本组成的集合。\n对于连续属性，可以考虑概率密度函数，例如\\(P(x_i|c)\\sim N(\\mu_{c,i},\\sigma^2_{c,i})\\)，其中\\(\\mu_{c,i},\\sigma^2_{c,i}\\)是第\\(c\\)类样本在第\\(i\\)个属性上取值的均值和方差。\n贝叶斯线性回归 最大似然函数和最小二乘法\n119.jpg\r我们通过通常的线性回归后得到红色的这条拟合线。可以看到，实际的数据点分布在这条线的周围，对于这种偏差，我们可以把它看做是一种噪声，一般是一种高斯分布的随机变量，可以把实际值记为\n\\[t = y(x,w)+\\epsilon \\]\n其中\\(y(x,w)=w^Tx\\)是拟合出来的线性模型，\\(\\epsilon\\)符合均值为\\(0\\)的高斯分布，其精确度为\\(\\beta\\)。精确度即为方差的倒数。显然，可以知道\\(E(t)=E(y)=w^Tx, Var(t)=Var(\\epsilon)=\\sigma^2=\\beta^{-1}\\)，我们可以记作\n\\[p(t|x,w,\\beta) = \\mathcal{N}(t|y(x,w),\\beta^{-1}) \\]\n接着我们就可以通过最大似然估计来求解\\(w\\)，首先，对于样本量\\(N\\)，似然函数为\n\\[p(t|X,w,\\beta) = \\prod^N_{n=1} \\mathcal{N}(t_n|y(x_n,w),\\beta^{-1}) \\]\n取对数似然函数，有\n\\[\\ln p(t|w,\\beta) = \\sum^N_{n=1} \\ln\\mathcal{N}(t_n|y(x_n,w),\\beta^{-1}) = \\dfrac{N}{2}\\ln\\beta-\\dfrac{N}{2}\\ln(2\\pi)-\\beta E_D(w) \\]\n其中\n\\[E_D(w) = \\dfrac{1}{2}\\sum^N_{n=1}[t_n-y(x_n,w)]^2 = \\dfrac{1}{2}\\sum^N_{n=1}[t_n-w^T\\phi(x_n)]^2 \\]\n其实就是个SSE，称为平方和的损失函数。\n偏差和方差的分解\n有了平方损失函数，最优预测（最优模型）就是下面的条件期望（不懂老师在说什么鸟语，感觉不如周志华，见后）\n\\[h(x) = E[t|x]=\\int t\\cdot p(t|x)dt \\]\n平方误差的期望为\n\\[E[L] = \\int[y(x)-h(x)]^2p(x)dx + \\iint [h(x)-t]^2p(x,t)dxdt \\]\n上式的第二部分，与\\(y(x)\\)无关，是数据集固有的噪声，它代表了最小的可达到的期望误差。\n第一部分是我们优化的目标。如果有无数多样本，那我们可以以任意精度得到\\(h(x)\\)，从而得到\\(y(x)\\)的最优解。但是实践中我们只有有限数量的样本。如果我们在样本集\\(D\\)中对第一项进行一些处理\n\\[[y(x;D)-E_{D}[y(x;D)]+E_D[y(x;D)]-h(x)]^2 \\]\n展开得\n\\[[y(x;D)-E_{D}[y(x;D)]]^2 + [E_{D}[y(x;D)]-y(x;D)]^2 + 2 [y(x;D)-E_{D}[y(x;D)]] [E_{D}[y(x;D)]-y(x;D)] \\]\n那么有\n\\[E_D[y(x;D)-h(x)]^2 = [E_D[y(x;D)]-h(x)]^2 + E_D[y(x;D)-E_D[y(x;D)]]^2 \\]\n其中第一项称为平方偏差\\((bias)^2\\)，第二项称为方差variance。带回\\(E(L)\\)时，有\n\\[\\text{expected loss} = (\\text{bias})^2+\\text{variance} +\\text{noise} \\]\n\\[(\\text{bias})^2 = \\int[E_D[y(x;D)]-h(x)]^2 p(x)dx \\]\n\\[\\text{variance}=\\int E_D\\bigg[[y(x;D)-E_D[y(x;D)]]^2\\bigg] p(x)dx \\]\n\\[\\text{noise} = \\iint [h(x)-t]^2p(x,t)dxdt \\]\n我们的⽬标是最⼩化期望损失，它可以分解为（平⽅）偏差、⽅差和⼀个常数噪声项的和。这里噪声是常数，所以只能调整前两个。我们通常只能二者选其一，要么偏差大方差小，要么方差大偏差小。\n按照周志华的讲法，\\(y(x;D)\\)在这里是模型\\(y\\)在数据集\\(D\\)上训练，对\\(x\\)的预测。而\\(E_D[y(x;D)]\\)则为期望预测。而\\(h(x)\\)则为数据集中的标签（可能存在标错了的情况，或者说，因为噪声的存在，导致标记值和真实值不同）。看起来\\(t\\)是样本的真实标签（即没有错的标签）。\n周志华的符号依次为模型\\(f(x;D)\\)，模型预测期望\\(\\bar f(x)\\)，数据集标记\\(y_D\\)，真实标记\\(y_D\\)。方差为\\(E_D[(f(x;D)-\\bar f(x))^2]\\)，噪声为\\(\\epsilon^2 = E_D[(y_D-y)^2]\\)，偏差为\\(bias^2(x)=(\\bar f(x)-y)^2\\)，偏差-方差分解如下\n147.jpg\r其中式2.37指\\(\\bar f(x)=E_D[f(x;D)]\\)\n参数分布\n假设噪声精度\\(\\beta\\)已知，那么\n\\[p(t|w)=\\prod ^N_{n=1}\\mathcal{N}(t_n|w^T\\phi(x_n),\\beta^{-1}) \\]\n取共轭先验，有\n\\[p(w) = \\mathcal{N}(w|m_0, S_0) \\]\n则后验为\n\\[p(w|t) = \\mathcal{N}(w|m_N, S_N) \\]\n其中\n\\[m_N = S_N(S^{-1}_0m_0+\\beta \\Phi^Tt) \\]\n\\[S^{-1}_N = S^{-1}_0+\\beta\\Phi^T\\Phi \\]\n120.jpg\r其中\\(\\phi\\)都是进行变换的基函数。\n最大后验概率的权重向量为\\(w_{MAP}=m_N\\)\n简单起见，考虑先验为\n\\[p(w|\\alpha) = \\mathcal{N}(w|0, \\alpha^{-1}I) \\]\n则后验变为\n\\[m_N = \\beta S_N\\Phi^Tt \\]\n\\[S^{-1}_N = \\alpha I+\\beta\\Phi^T\\Phi \\]\n考虑当\\(S_0=\\alpha^{-1}I\\)中的\\(\\alpha\\to 0\\)，此时，\\(m_N\\)就是最大似然估计（MLP）的结果\n对后验概率求\\(\\log\\)有\n\\[\\ln p(w|t) = -\\dfrac{\\beta}{2}\\sum^N_{n=1}[t_n-w^T\\phi(x_n)]^2-\\dfrac{\\alpha}{2}w^Tw+const \\]\n最大化这个后验概率局等价于最小化用\\(\\lambda=\\alpha/\\beta\\)正则化的平方和误差函数。\n预测分布\n\\[p(t'|t,\\alpha,\\beta) = \\int p(t'|w,\\beta)p(w|t,\\alpha,\\beta)dw \\]\n\\[p(t'|x,t,\\alpha,\\beta) = \\mathcal{N}(t|m_N^T\\phi(x),\\sigma^2_N(x)) \\]\n\\[\\sigma^2_{N} = \\dfrac{1}{\\beta}+\\Phi(x)^TS_N\\Phi(x) \\]\n我的评价\n老师像在炫技一样做PPT，符号完全没有介绍，前后文不连贯。完全就是从PRML里面挑着东西复制粘贴到PPT上。\n贝叶斯逻辑回归 因为后验概率不再是高斯分布，那么我们就不能精确地对权重\\(w\\)求积分。因此，有必要介绍一种近似方法，即拉普拉斯近似。它的目标是找到定义在一组连续变量上的概率密度的高斯近似。\n拉普拉斯近似是通过找到后验分布的众数（mode）来得到的，然后拟合以该众数为中心的高斯分布。 这需要计算对数后验的二阶导数，也就等价于找海瑟矩阵 首先考虑一个单一的连续变量\\(z\\)，假设其分布为\n\\[p(z) = \\dfrac{1}{Z}f(z) \\]\n其中\\(Z=\\int f(z)dz\\)，是归一化系数，但是其值未知。拉普拉斯方法的目的是找到一个高斯近似\\(q(z)\\)，其中心位于\\(p(z)\\)的众数上。\n第一步，找到\\(p(z)\\)的众数，也就是找到\\(z_0\\)使得\\(p'(z_0)=0\\)，等价地，有\n\\[\\dfrac{df(z)}{dz}\\bigg|_{z=z_0}=0 \\]\n将\\(\\ln f(z)\\)在\\(z_0\\)处泰勒展开，有\n\\[\\ln f(z) \\approx \\ln f(z_0)-\\dfrac{1}{2}A(z-z_0)^2 \\]\n其中\n\\[A = -\\dfrac{d^2}{dz^2}\\ln f(z)\\bigg |_{z=z_0} \\]\n那么\n\\[f(z)\\approx f(z_0)\\exp\\bigg\\{-\\dfrac{A}{2}(z-z_0)^2\\bigg\\} \\]\n之后，我们可以取一个归一化分布\n\\[q(z) = \\bigg(\\dfrac{A}{2\\pi}\\bigg)^{1/2}\\exp\\bigg\\{-\\dfrac{A}{2}(z-z_0)^2\\bigg\\} \\]\n注意，高斯近似只有在\\(A\u003e0\\)的时候才定义良好。此时驻点\\(z_0\\)一定取得局部最大值，而这个点的二阶导数一定为负数。\n这之后，可以得到\n\\[Z = \\int f(z)dz \\approx f(z_0)\\int \\exp\\bigg\\{-\\dfrac{1}{2}A(z-z_0)^2\\bigg\\}dz \\]\n即\n\\[Z = f(z_0)\\dfrac{(2\\pi)^{1/2}}{|A|^{1/2}} \\]\n模型比较\n设数据集\\(D\\)，各种模型的集合\\(\\{M_i\\}\\)，每个模型的参数为\\(\\theta_i\\)，对于每个模型都定义一个似然函数\\(p(D|\\theta_i, M_i)\\)。如果我们引入先验分布\\(p(\\theta_i|M_i)\\)，那么我们关注计算模型的证据\\(p(D|M_i)\\)\n有\n\\[p(D) = \\int p(D|\\theta)p(\\theta)d\\theta \\]\n令\\(f(\\theta)=p(D|\\theta)p(\\theta)\\)和\\(Z=p(D)\\)，那么\n\\[\\ln p(D)\\approx \\ln p(D|\\theta_{MAP})+\\ln p(\\theta_{MAP}) + \\dfrac{M}{2}\\ln(2\\pi)-\\dfrac{1}{2}\\ln|A| \\]\n其中，最后三项叫做Occam，其中\n\\[A = -\\nabla\\nabla \\ln p(D|\\theta_{MAP})p(\\theta_{MAP}) = -\\nabla\\nabla\\ln p(\\theta_{MAP}|D) \\]\n如果假设高斯分布比较宽，而且海瑟矩阵是满秩的，那么可以非常粗略的近似\n\\[\\ln p(D)\\approx \\ln p(D|\\theta_{MAP})-\\dfrac{1}{2}M\\ln N \\]\n其中\\(N\\)为数据集大小。这也被叫做Bayesian Information Criterion（BIC），贝叶斯信息准则。\nTODO，剩下一大坨，老师介绍了半天不知道有什么用。\n贝叶斯网络 见概率图模型。\n正态分布下的统计决策 单变量正态分布\n\\[p(x) = \\dfrac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\bigg\\{-\\dfrac{1}{2}\\bigg(\\dfrac{x-\\mu}{\\sigma}\\bigg)^2\\bigg\\} \\]\n记作\\(N(\\mu,\\sigma)\\)，其中\\(\\mu=Ex=\\int xp(x)dx,\\sigma^2=Dx=E(x-\\mu)^2=\\int (x-\\mu)^2p(x)dx\\)\n多元正态分布函数\n设\\(x\\)是\\(d\\)维向量\n\\[p(x) = \\dfrac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}}\\exp\\bigg(-\\dfrac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\bigg) \\]\n其中\\(\\mu\\)是均值向量\\((\\mu_1,\\mu_2,\\cdots,\\mu_d)^T\\)，\n\\(\\Sigma\\)是协方差矩阵即\\(E((x-\\mu)(x-\\mu)^T)=[\\sigma_{ij}]_{d\\times d}\\)，其中每个元素为\\(\\sigma_{ij}=E((x_i-E(x_i))(x_j-E(x_j)))\\)。协方差矩阵是对称非负定矩阵。\n一个多元正态分布函数共有\\(d+d(d+1)/2\\)个参数，其中\\(d\\)个参数是均值向量，剩下的\\(d(d+1)/2\\)是协方差矩阵。\n该概率密度函数中等密度点的轨迹为一超椭球面。如果要使\\(p(x)\\)值不变，只需要保证\\(\\exp\\)内的参数为常数。\n102.jpg\r线性变换与正态分布\n假设\\(x\\in R_d, A\\in R_{d\\times k}, y = A^Tx\\in R_k\\)，如果有\\(x\\sim N(\\mu,\\sigma)\\)，那么有\n\\[y\\sim N(A^T\\mu, A^T\\Sigma A) \\]\n特别的，有白化变换（whitening transform）\n\\[A_w = \\Phi\\Lambda^{-1/2} \\]\n其中\\(\\Phi\\)是一个矩阵，每一列都是\\(\\Sigma\\)的正交特征向量，\\(\\Lambda\\)是对角阵，元素为对应的特征值。这个白化变换，给出了一个等于单位矩阵的协方差矩阵。\n马氏距离（的平方）\n\\[\\gamma^2 = (x-\\mu)^T\\Sigma^{-1}(x-\\mu) = \\sum^n_{i=1}\\sum^n_{j=1}p_{ij}(x_i-\\mu_i)(x_j-\\mu_j)\\geq 0 \\]\n与欧氏距离（的平方）\\((x-\\mu)^T(x-\\mu)\\)相比，马氏距离考虑数据各个维度间的相关性，\\(x\\)到\\(\\mu\\)的马氏距离为常数时，所组成的超椭球面为等密度点 。\n判别函数\n根据最小错误率贝叶斯判别函数，在多元正态概型\\((p(x|w_i)\\sim N(\\mu_i, \\sigma_i), i=1,\\cdots,c)\\)下就可以立即写出其相应的表达式。\n因为\n\\[p(x|w_i) = \\dfrac{1}{(2\\pi)^{d/2}|\\Sigma_i|^{1/2}}\\exp\\bigg(-\\dfrac{1}{2}(x-\\mu_i)^T\\Sigma^{-1}_i(x-\\mu_i)\\bigg) \\]\n之前我们得出最小错误率的判决函数就是\\(g_i(x)=P(w_i|x)\\)，也就等价于\\(g_i(x)=P(x|w_i)P(w_i)\\)（分母为无关项）。我们判断是选取判决函数最大的作为预测类，也就等价于最大的\\(g_i(x)=\\ln P(x|w_i)+\\ln P(w_i)\\)。于是，代入多元正态，得到最终的判别函数为\n\\[g_i(x) = -\\dfrac{1}{2}(x-\\mu_i)^T\\Sigma^{-1}_i(x-\\mu_i)-\\dfrac{d}{2}\\ln 2\\pi-\\dfrac{1}{2}\\ln|\\Sigma_i|+\\ln P(w_i) \\]\n决策面方程为\\(g_i(x)-g_j(x)=0\\)，即\n\\[-\\dfrac{1}{2}[(x-\\mu_i)^T\\Sigma^{-1}_i(x-\\mu_i)-(x-\\mu_j)^T\\Sigma^{-1}_j(x-\\mu_j)] - \\dfrac{1}{2}\\ln\\dfrac{|\\Sigma_i|}{|\\Sigma_j|}+\\ln\\dfrac{P(w_i)}{P(w_j)} = 0 \\]\n情况1\n若\\(\\Sigma_1=\\cdots=\\Sigma_c=\\sigma^2 I\\)，则有\\(\\Sigma^{-1}_i=\\dfrac{1}{\\sigma^2} I, |\\Sigma_i|=\\sigma^{2d}\\)，代入、展开、去除与\\(i\\)无关的项得到判决函数为\n\\[g_i(x) = \\dfrac{1}{\\sigma^2}\\mu_i^Tx-\\dfrac{1}{2\\sigma^2}\\mu^T_i\\mu_i+\\ln P(w_i)=w^T_{i1}x+w_{i0} \\]\n等价于一个线性判别函数。其决策面为\\(g_i(x)=g_j(x)\\)，等价于\\(w^T(x-x_0)=0\\)。其中\n\\[w = \\mu_i-\\mu_j \\]\n\\[x_0 = \\dfrac{1}{2}(\\mu_i+\\mu_j)-\\dfrac{\\sigma^2}{||\\mu_i-\\mu_j||^2}\\ln\\dfrac{P(w_i)}{P(w_j)}(\\mu_i-\\mu_j) \\]\n直观来说，如果\\(P(w_i)=P(w_j)\\)，则\\(x_0\\)位于两中心的终点。否则更靠近先验概率小的方向。\n在先验概率相等的情况下，最优判决的规则为：为将某特征向量\\(x\\)归类，通过测量\\(x\\)到\\(c\\)个均值向量中心的欧氏距离，并将\\(x\\)归为离它最近的那一类。这样的分类器称为“最小距离分类器”。\n形式化的说，所有\\(P(w_i)\\)都相等，那么\\(w = \\arg\\min_{w_i}||x-\\mu_i||\\)\n103.jpg\r104.jpg\r情况2\n若\\(\\Sigma_1=\\cdots=\\Sigma_c=\\Sigma\\)，在几何上，相当于各类样本集中在以该类均值为中心的同样大小和形状的超椭球内。\n去除无关项，得到判决函数为\n\\[g_i(x) = -\\dfrac{1}{2}(x-\\mu_i)^T\\Sigma^{-1}(x-\\mu_i)+\\ln P(w_i) \\]\n特例，如果\\(P(w_i)=P\\)为固定值，那么判决函数就可以进一步简化为\\(g_i(x)=\\gamma^2\\)，即马氏距离的平方。\n把上式展开，去除与\\(i\\)无关的项，可以得到\n\\[g_i(x) = \\mu_i^T\\Sigma^{-1}x-\\dfrac{1}{2}\\mu_i^T\\Sigma^{-1}\\mu_i+\\ln P(w_i)=w^T_{i1}x+w_{i0} \\]\n等价于一个线性判别函数。其决策面为\\(g_i(x)=g_j(x)\\)，等价于\\(w^T(x-x_0)=0\\)。其中\n\\[w = \\Sigma^{-1}(\\mu_i-\\mu_j) \\]\n\\[x_0 = \\dfrac{1}{2}(\\mu_i+\\mu_j)-\\dfrac{1}{(\\mu_i-\\mu_j)^T\\Sigma^{-1}(\\mu_i-\\mu_j)}\\ln\\dfrac{P(w_i)}{P(w_j)}(\\mu_i-\\mu_j) \\]\n由于\\(w\\)并非沿着\\(\\mu_i-\\mu_j\\)方向，因此分界面并非与均值间的连线垂直正交。\n105.jpg\r106.jpg\r情况3\n即任意的\\(\\Sigma_i\\)\n\\[g_i(x) = -\\dfrac{1}{2}(x-\\mu_i)^T\\Sigma^{-1}_i(x-\\mu_i)-\\dfrac{1}{2}\\ln|\\Sigma_i|+\\ln P(w_i) \\]\n可以写为\n\\[g_i(x) = x^Tw_{i2}x+w_{i1}^Tx+w_{i0} \\]\n其中\n\\[w_{i2} = -\\dfrac{1}{2}\\Sigma_i^{-1} \\]\n\\[w_{i1} = \\Sigma_i^{-1}\\mu_i \\]\n\\[w_{i0} = -\\dfrac{1}{2}\\mu_i^T\\Sigma_i^{-1}\\mu_i - \\ln|\\Sigma_i| + \\ln P(w_i) \\]\n这样的二次型形式。决策面\\(g_i(x)=g_j(x)\\)为\n\\[x^T(W_i-W_j)x+(w_i-w_j)^Tx+w_{i0}-w_{j0}=0 \\]\n由上式所决定的决策面为超二次曲面随着参数的不同而呈现为某种超二次曲面，即超球面、超椭球面、超抛物面、超双曲面或超平面。\n错误率\n对于两类，假设\\(w_1\\)的决策空间为\\(R_1\\)，\\(w_2\\)的的决策空间为\\(R_2\\)，那么两分类的错误率为\n\\[P(error) = P(x\\in R_2, w_1)+P(x\\in R_1, w_2) = P(x\\in R_2|w_1)P(w_1)+P(x\\in R_1| w_2)P(w_2) \\]\n写作积分，则为\n\\[P(error) = \\int_{R_2}p(x|w_1)P(w_1)dx + \\int_{R_1}p(x|w_2)P(w_2)dx \\]\n对于多类，则有\n\\[P(error) = 1-P(correct) = 1-\\sum^C_{i=1}P(x\\in R_{i}, w_i) = 1-\\sum^C_{i=1}P(x\\in R_{i}|w_i) P(w_i) \\]\n写成积分为\n\\[P(error) = 1-\\sum^C_{i=1}\\int _{R_i} p(x|w_i)P(w_i)dx \\]\n受试者工作特征曲线（ROC，Receiver Operating Characteristics）\n这是一种经常与二分类一起使用的工具，假设\\(C_1\\)类是正类，\\(C_2\\)类是负类，那么有混淆矩阵如下\n121.jpg\r其中mis-detection也叫做假阴性或者第二类错误，false alarm也叫做假阳性或者第一类错误。\n如果以correct detection占总的比例作为纵轴，false alarm作为横轴，绘制的曲线就叫ROC。一个模型不同超参数的ROC曲线如下\n122.jpg\r越左上角越好。\n生成式模型和判别式模型 有三种办法来解决决策的问题\n显式或隐式地对输入和输出的分布建模，称为生成式模型 对后验概率直接建模的方式称为判别式模型 直接找到一个判别函数，这之中概率没有发挥作用。 构造生成式模型\n对类条件概率\\(p(x|w_i)\\)建模 对类概率\\(p(w_i)\\)建模 通过贝叶斯公式计算后验概率\\(p(w_i|x)\\) 对于二分类有\n\\[p(w_1|x) = \\dfrac{p(x|w_1)p(w_1)}{p(x|w_1)p(w_1)+p(x|w_2)p(w_2)} = \\dfrac{1}{1+\\exp(-a)} = \\sigma(a) \\]\n其中\n\\[a = \\ln\\dfrac{p(x|w_1)p(w_1)}{p(x|w_2)p(w_2)} \\]\n对于多分类有\n\\[p(w_k|x) = \\dfrac{p(x|w_k)p(w_k)}{\\sum_jp(x|w_j)p(w_j)} = \\dfrac{\\exp(-a_k)}{\\sum_j\\exp(-a_j)} \\]\n这也叫做softmax函数，其中\n\\[a_k = \\ln p(x|w_k)p(w_k) \\]\n构造判别式式模型\n直接最大化由\\(p(w_i|x)\\)定义的似然函数\n优点是，通常将有更少的自适应参数要确定。它还可能提高预测性能，特别是当类条件密度假设对真实分布的近似度较差时。\n贝叶斯vs其他判别 我们的贝叶斯理论都基于后验概率，所以要先知道先验概率和类条件概率。实际情况下并不一定知道类条件概率，如果样本充足，则可以用估计的办法估计类条件概率。有时候样本不够多，样本维数又比较高，此时估计就会不准确。更适合采用别的方法，例如线性判别。\n线性判别直接假设判别函数，用样本来估计判别函数的参数，而免去估计类条件概率。非贝叶斯的算法基本上都采用这种方式。判别函数最简单的形式是线性函数，决策面是超平面，此时也叫做线性判别。其包含参数\\(w,w_0\\)\n然而，在贝叶斯决策中，判别函数为最小错误率和最小风险。使用这种判别函数的分类器是所有分类器中的最优分类器。其他判别函数下的分类器都只能称为次优分类器。\n后面介绍的准则函数，都只是在给定准则下的最优解，而不是整个问题的最优解。次优解的好处是代价小。\n有监督学习 即训练集除了属性，还有标签。\n其训练、验证、预测程序框架如下\n12.jpg\r一般来说，其有如下步骤\n决定数据集的类型 获取数据集 决定学习的模型，以及学习的算法 完成程序设计，在训练集上跑 评估正确率等指标，然后选择继续修正参数再次训练或者结束。 有监督学习的任务主要分为两个：回归、分类。回归就是对输入给出预测的输出，例如预测未来某一天的温度；分类则是对样本进行划分，使其属于某一个类别。\n常见的算法有：决策树、随机森林、支持向量机、逻辑回归、人工神经网络、K近邻、贝叶斯等\n回归任务 一般预测的输出为连续变量。\n其一般如下。设样本为\\(\\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\cdots, (x^{(m)}, y^{(m)})\\}\\)。程序对于\\(x\\)给出的预测是\\(h_\\theta(x)=\\hat y\\)，其中\\(h_\\theta\\)就是我们的预测函数，或者说模型，而\\(\\theta\\)是模型参数。我们的目标是求出\n\\[\\theta^* = \\arg\\min_{\\theta}\\sum^m_{i=1}(\\hat y^{(i)}-y^{(i)})^2=\\arg\\min_\\theta J(\\theta) \\]\n至于如何求出，一般会使用数值最优化方法，例如梯度下降。搜索方向即是\\(-\\eta\\nabla J(\\theta)\\)\n分类任务 一般预测的输出为离散变量。\n总体来说和回归任务形式上还是挺相似的。只是样本的\\(y\\)记录的是样本的类别标签。给出的预测也是预测标签。通常目标也是最小化损失函数。\n前面在贝叶斯分类器中提到过，生成式模型（Generative Algorithms）和判别式模型（Discriminative Algorithms）的区别。\n判别式模型直接对\\(P(Y|X)\\)建模。例子：通过人脸识别来判断性别。典型算法有：逻辑回归、SVM、神经网络等。\n而生成式模型通过对\\(P(X|Y)\\)和\\(P(Y)\\)建模，通过贝叶斯公式来算\\(P(Y|X)\\)。例子：你收到电子邮件（观察结果，the observation），你想推断邮件是否是垃圾邮件（原因，the cause）。典型算法有：朴素贝叶斯、贝叶斯网络。\n线性回归模型 单变量的模型为\n\\[h_w(x) = w_0+w_1x \\]\n包含两个参数。其代价函数为（也称为均方误差MSE）\n\\[J(w_0,w_1)=\\dfrac{1}{2m}\\sum^m_{i=1}(h_w(x^{(i)})-y^{(i)})^2 \\]\n其中\\(m\\)为样本集大小，前面的常数系数个人觉得是多少都行，并不会影响求解过程，有个\\(2\\)只是方便求导。\n我们的目标即为\n\\[\\arg\\min_{w_0,w_1} J(w_0,w_1) \\]\n求解的方法一般会用梯度下降法。见最优化理论学习笔记\n这边，更新公式就为\n\\[w_j := w_j - \\alpha\\dfrac{\\partial}{\\partial w_j}J(w_0, w_1) \\]\n注意，需要把新值\\(w_0', w_1'\\)存下来，等两个新值都计算完后，在赋值给变量。不能计算一个，马上就赋值一个。本次更新的信息都必须来自上次。\n扩展到多变量也很方便，模型变为\n\\[h_w(x) = w_0+w_1x_1+w_2x_2+\\cdots+w_nx_n = w^Tx \\]\n其中\\(w\\)和\\(x\\)都是\\(n+1\\)维向量，默认\\(x_0=1\\)。样本特征仍然是\\(n\\)维的。\n代价函数没多大变化\n\\[J(w) = \\dfrac{1}{2m}\\sum^m_{i=1}(h_w(x^{(i)})-y^{(i)})^2 \\]\n\\[\\arg\\min_{w} J(w) \\]\n\\[w_j := w_j - \\alpha\\dfrac{\\partial}{\\partial w_j}J(w) \\]\n其中梯度为\n\\[\\dfrac{\\partial}{\\partial w_j}J(w) = \\dfrac{1}{m}\\sum^m_{i=1}(h_w(x^{(i)})-y^{(i)})x_j^{(i)} \\]\n我们也不一定要用梯度下降法才能求出最优参数，线性回归方程有闭式解\n\\[w^\\ast = (X^TX)^{-1}X^Ty \\]\n其中\\(X\\)是一个\\(m\\)行\\(n+1\\)列的矩阵。每一行的矩阵代表一个样本。于是\\(X^TX\\)是一个\\((n+1)\\times(n+1)\\)的矩阵，\\(X^Ty\\)是一个\\(n+1\\)行的列向量。\n广义线性模型\n和之后提到的广义线性判别分析一样，我们也可以通过加高维数的方法使得多项式变成线性。这里不再赘述。\n正则化\n给代价函数加上一项\n\\[J(w) = \\dfrac{1}{2m}\\bigg[\\sum^m_{i=1}(h_w(x^{(i)})-y^{(i)})^2+\\lambda \\sum^n_{j=1}w_j^2\\bigg] \\]\n注意加上的不包含\\(\\lambda w_0\\)，求导的时候要注意。\n这也叫做Tikhonov正则化、岭回归。此时，学习算法不仅要拟合数据，还要使模型权重尽可能小。\n\\(\\lambda\\)等于零时等价于线性回归， \\(\\lambda\\)很大时，会使曲线趋于平缓，不至于过拟合。平缓时，可以减小方差，但是会增加偏差。\n另外使用正则化需要缩放数据，因为其对输入特征的缩放很敏感。\n闭式解为\n\\[w = (X^TX+\\lambda A)^{-1}X^Ty \\]\n其中\\(A\\)是一个\\((n+1)\\times(n+1)\\)的单位矩阵，然后再设置最左上角的元素为\\(0\\)\n线性分类模型 先看二分类问题，模型为\n\\[y(x) = w^Tx+w_0 \\]\n\\(w\\)是权重向量，\\(w_0\\)为偏置项。当\\(y(x)\\geq 0\\)时分为第一类，否则分为第二类。于是决策面就为\\(y(x)=0\\)，对于\\(D\\)维特征样本，决策面是\\(D-1\\)维超平面\n假设\\(x_a,x_b\\)在决策面上，那么有\\(w^T(x_a-x_b)=0\\)，即权重向量\\(w\\)和所有决策面上的向量正交。所以\\(w\\)是决策面的法向量方向。\n任意一点到决策面的距离为\n\\[\\dfrac{|y(x)|}{||w||} \\]\n现在考虑多分类（K类）问题，我们可以训练\\(K\\)个一对多二分类器，也可以训练\\(K(K-1)/2\\)个一对一二分类器，然后通过投票的方式选出得票最多的。但是，我们会遇到投票数相等的情况，例如\n112..jpg\r113.jpg\r有些时候这个方法还是有用的，但是作为一般的讨论，我们要找到一种更好的方法来避免出现这种ambiguous regions。\n我们升级模型为\n\\[y_k(x) = w_k^Tx+w_{k0} \\]\n其中\\(k=1,\\cdots,K\\)。如果对于所有的\\(j\\neq k\\)，有\\(y_k(x)\u003ey_j(x)\\)，那么把\\(x\\)归类为\\(C_k\\)类。\n此时，\\(k\\)类和\\(j\\)类的判决面就是\\(y_k(x)=y_j(x)\\)，也即\n\\[(w_k-w_j)^Tx+(w_{k0}-w_{j0}) = 0 \\]\n114.jpg\r线段\\(x_ax_b\\)上的点都可以表示为\\(\\hat x = \\lambda x_a+(1-\\lambda)x_b\\)，其中\\(0\\leq\\lambda\\leq 1\\)。于是，根据线性性，我们就得到\\(y_k(\\hat x)=\\lambda y_k(x_a)+(1-\\lambda)y_k(x_b)\\)，并且因为\\(y_k(x_a)\u003ey_j(x_a)\\)且\\(y_k(x_n)\u003ey_j(x_n)\\)，可以得出\\(y_k(\\hat x)\u003ey_j(\\hat x)\\)，以及\\(\\hat x\\)属于\\(C_k\\)。\n所以说，判决区域是单连通的，并且是凸的。\n为了便于表示，我们可以把\\(K\\)个模型合并起来，得到\n\\[y(x)=\\tilde{W}^T\\tilde{x} \\]\n其中\\(\\tilde{W}\\)是一个\\(K\\)列矩阵，每一列是\\(D+1\\)维列向量。即\\(\\tilde{w}_k=[w_{k0}, w_k^T]^T\\)。相应的有，\\(\\tilde{x}=[1,x^T]^T\\)\n求取参数矩阵的最小二乘解（least-squares solutions），我们的损失函数称作误差平方和（SSE，和均方误差的区别在于前面的系数），即\n\\[E_D(\\tilde{W}) = \\dfrac{1}{2}tr\\{(\\tilde{X}\\tilde{W}-T)^T(\\tilde{X}\\tilde{W}-T)\\} \\]\n其中\\(\\tilde{W}\\)同前，而\\(\\tilde{X}\\)的每一行都代表一个\\(\\tilde{x}^T\\)，共\\(N\\)行，即训练集大小。而\\(\\tilde{T}\\)也是\\(N\\)行矩阵，每一行都是一个向量\\(t^T\\)，代表训练集的标记。虽然老师没说，但我感觉是one-hot编码的标记。\n于是有闭式解为\n\\[\\tilde W = (\\tilde X^T\\tilde X)^{-1}\\tilde XT=\\tilde X^\\dagger T \\]\n其中\\(\\dagger\\)表示伪逆（pseudo-inverse）矩阵\n这样的最小二乘解有一个性质，如果对一对固定的\\(a,b\\)，每个训练样本的标记都满足\n\\[a^Tt+b = 0 \\]\n那么模型也会满足\n\\[a^Ty(x)+b=0 \\]\n因此，使用one-hot编码的标记，对任意样本\\(x\\)进行预测得到\\(y(x)\\)，预测结果的每一项加起来等于\\(1\\)\n然而，并不能用这个来表示样本属于类各类的概率，因为每一项并不限制在\\((0,1)\\)之间\n另外，最小二乘解对极端值没有鲁棒性。\nFisher线性判别 对于两类问题，线性判别函数为\n\\[g(x) = w^Tx+w_0 \\]\n判决面方程为\\(g(x)=0\\)\n决策规则为：令\\(g(x)=g_1(x)-g_2(x)\\)，如果\\(g(x)\u003e0\\)，则判断为\\(w_1\\)，若\\(g(x)\u003c0\\)，则判断为\\(w_2\\)，如果\\(g(x)=0\\)，则可以拒判或者任意分。\n至于如何取得参数，我们需要一个准则函数\\(J\\)，其是\\(x,w,w_0\\)的函数，它的极值对应于“最优”的决策。我们用最优化方法求取\\(J\\)的极值，就可以得到最优参数。\nFisher判别分析考虑把\\(d\\)维特征投影到一条直线上，形成一维空间，并且保持较好的性能。\n只要给每个样本\\(x\\)乘以向量\\(w^T\\)就可得到一个标量\\(y=w^Tx\\)，也就是投影到了一条直线上。其中\\(w\\)就是投影到的直线。其方向重要而长度不重要。\n如何保持较好的性能呢？Fisher法希望两类样本在该直线上的距离尽可能远，而类内的距离尽可能近。\n假设有\\(m\\)个\\(n\\)维样本\\(\\{x_1,x_2,\\cdots,x_m\\}\\)，第一类集合为\\(D_1\\)，规模为\\(N_1\\)，第二类集合为\\(D_2\\)，规模为\\(N_2\\)\n在\\(n\\)维\\(X\\)空间中\n各类均值向量为\n\\[\\mu_i = \\dfrac{1}{N_i}\\sum_{x_j\\in D_i}x_j \\]\n类\\(i\\)的类内离散度为\n\\[S_i = \\sum_{x_j\\in D_i}(x_j-\\mu_i)(x_j-\\mu_i)^T \\]\n总类内离散度就为\n\\[S_w = S_1+S_2 \\]\n其是对称半正定矩阵，当\\(m\u003en\\)时通常是非奇异的\n类间离散度为\n\\[S_b = (\\mu_1-\\mu_2)(\\mu_1-\\mu_2)^T \\]\n其是对称半正定矩阵。\n在\\(1\\)维\\(Y\\)空间中\n各类均值向量为\n\\[\\bar\\mu_i = \\dfrac{1}{N_i}\\sum_{y_j\\in D_i}y_j \\]\n类\\(i\\)的类内离散度为\n\\[\\bar S_i^2 = \\sum_{x_j\\in D_i}(y_j-\\bar\\mu_i)^2 \\]\n总类内离散度就为\n\\[\\bar S_w = \\bar S_1^2+\\bar S_2^2 \\]\n类间离散度为\n\\[\\bar S_b = (\\bar\\mu_1-\\bar\\mu_2)^2 \\]\n于是Fisher的最佳投影方向的准则函数就为\n\\[J(w) = \\dfrac{\\bar S_b}{\\bar S_w} \\]\n最优参数就是\n\\[w^\\ast = \\arg\\max_w J(w) \\]\n把\\(y_j\\)用\\(w^Tx\\)代入，展开可以得到\n\\[\\bar S_b = w^T S_b w \\]\n\\[\\bar S_w = w^TS_ww \\]\n所以有\n\\[J(w) = \\dfrac{w^TS_bw}{w^TS_ww} \\]\n假定分母是非零常数，则可以用拉格朗日乘数法算出\n\\[w^* = S^{-1}_w(\\mu_1-\\mu_2) \\]\n于是用这个参数，我们把所有样本\\(x\\)降维为\\(y=w^{*T}x\\)。\n分类规则为，\\(y\u003ew_0\\)时属于\\(\\omega_1\\)类，否则属于\\(\\omega_2\\)类。其中\\(w_0\\)可以用多种取法。最常用的有\n86.jpg\r逻辑回归（Logistic Regression） 逻辑回归是一种线性分类算法，其通常是二分类，并且给出确定结果（而不是属于某一类的概率）。当输出为1时，预判为正类，输出为0时，预判为负类。\n线性回归的模型如下，其一般用于回归问题\n\\[h_\\theta(x)=\\theta_0+\\theta_1x_1+\\theta_2x_2+\\cdots+\\theta_nx_n = \\theta^Tx+\\theta_0 \\]\n想把它转化到分类问题上时，我们给他套上一个sigmoid函数，即\\(\\sigma(x)=\\dfrac{1}{1+e^{-z}}\\)\n得到逻辑回归的模型如下\n\\[h_\\theta(x) = \\dfrac{1}{1+e^{-(\\theta^Tx+\\theta_0)}} \\]\n之后我们有\n\\[\\ln\\dfrac{h_\\theta(x)}{1-h_\\theta(x)} = \\theta^Tx+\\theta_0 \\]\n因为逻辑回归的输出只有\\(0,1\\)，当\\(h_\\theta(x)=0\\)时，\\(\\theta^Tx+\\theta_0=-\\infty\\)，当\\(h_\\theta(x)=1\\)时，\\(\\theta^Tx+\\theta_0=\\infty\\)\n所以我们的判别方法为：当\\(\\theta^Tx+\\theta_0\u003c0\\)时，判断为负类（0）。当当\\(\\theta^Tx+\\theta_0\u003e0\\)时，判断为正类（1）。\n关于如何训练，我们得到的损失函数如下\n\\[J(\\theta) = \\dfrac{1}{m}\\sum^m_{i=1}[-y^{(i)}\\log(h_\\theta(x^{(i)}))-(1-y^{(i)})\\log(1-h_\\theta(x^{(i)}))] \\]\n其中\\(m\\)是样本数量，\\(y\\)的取值为\\(\\{0,1\\}\\)。目标就是最小化损失函数，可以利用梯度下降法等办法。\n梯度为\n\\[\\dfrac{\\partial}{\\partial \\theta_j} J(\\theta) = \\dfrac{1}{m}\\sum^m_{i=1}(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)} \\]\n另外，还是有可能算出属于某个类的概率的，即\\(p(y|x;\\theta)=(h_\\theta(x))^y(1-h_\\theta(x))^{1-y}\\)，或者说\\(h_\\theta(x)\\)表示\\(x\\)属于正类的概率。\n非线性可分时，仍然可以使用广义线性模型来升维解决。\n感知准则函数与感知器算法 线性可分性\n如果存在一个向量\\(a\\)使得，对于所有的\\(x\\in w_1\\)，有\\(a^Tx\u003e0\\)，对于所有的\\(x\\in w_2\\)，有\\(a^Tx\u003c0\\)，那么样本集是线性可分的。否则是线性不可分的。\n样本规范化\n对于线性可分的样本集，令\n\\[x_i' = \\left\\{\\begin{matrix} x_i ,\u0026\\quad x_i\\in w_1\\\\ -x_i ,\u0026\\quad x_i\\in w_2 \\end{matrix}\\right. \\]\n那么线性可分条件就可以改写为\\(a^T x'_i\u003e0\\)\n上述过程称为样本的规范化。\\(x'_i\\)称为规范化增广样本向量。本部分的后续内容都是规范化的，简记为\\(x_i\\)\n解向量和解区\n对于线性可分的一组规范化样本\\(\\{x_1,x_2,\\cdots,x_m\\}\\)，若存在一个权向量\\(a^*\\)满足\n\\[a^{*T}x_i\u003e0 \\]\n则称\\(a^*\\)为一个解向量，在权值空间中所有解向量组成的区域称为解区。\n对解区的限制\n解向量不唯一，我们可以通过加入限制得到更好的选择。一般认为，越靠近解区中间的解向量，似乎越能对新的样本正确分类。\n我们可以选找一个单位长度的解向量使之最大化样本到分界面的距离\n也可以引用一个余量\\(b\u003e0\\)，寻找对所有样本\\(x_i\\)满足\n\\[a^Tx_i \u003e b \\]\n的最小长度的向量。新的解区位于原解区之中，而且他的边界到原解区边界的距离为\\(b/||x_i||\\)\n感知器算法\n感知器算法也是个二分类算法。\n通常首先要使用一个固定的非线性转换把输入向量\\(x\\)转换成特征向量\\(\\phi(x)\\)。这个特征向量之后要被用作构建一个广义线性模型\n\\[y(x) = f(w^T\\phi(x)) \\]\n其中\\(f(\\cdot)\\)是一个非线性激活函数，通常会用如下形式的阶跃函数\n\\[f(a)\\begin{cases} +1, \u0026 a\\geq 0 \\\\ -1, \u0026 a \u003c 0 \\end{cases} \\]\n另外，像之前一样，有\\(\\phi_0(x)=1\\)。注意我们之前可能把二分类标记为\\(\\{0,1\\}\\)，这里我们标记为\\(t\\in\\{-1,1\\}\\)，因为可以比较方便地样本规范化。\n\\[w^T\\phi(x_n)t_n \u003e 0 \\]\n对于线性可分的（规范化）样本，满足\\(w^T\\phi(x_n)t_n \u003e 0\\)。在训练时，对于某个迭代中的权向量\\(w\\)，如果某个样本被错误分类，则\\(w^T \\phi(x_k)t_k\\leq 0\\)。我们对所有错分样本的惩罚函数，即感知器准则函数定义如下\n\\[E_P(w)=J_P(w) = -\\sum_{k\\in M}(w^T\\phi(x_k)t_k) \\]\n其中\\(M\\)是错分样本的下标集。\n当且仅当函数取得最小值\\(0\\)时，有最优的\\(w^*\\)。求解过程可以用梯度下降法。见最优化理论学习笔记\n机器学习课上，使用了随机梯度降，\n\\[w^{(t+1)} = w^{(t)} - \\eta \\nabla E_P(w) = w^{(t)} + \\eta\\phi_nt_n \\]\n不具一般性的，如果把\\(w\\)乘上一个常数，那么预测\\(y(x,w)\\)是不改变的，所以可以把\\(\\eta\\)设置为\\(1\\)。\n但是，一般来说，\\(w\\)改变的同时，错分的集合也会变。\n我们训练的时候是每次迭代，对每个样本都跑一次这个梯度降，如果分类正确了，就保持\\(w\\)不动，如果分类错误，则加上这个样本对应的\\(\\eta\\phi_n t_n\\)\n如果我们关注单个错分样本的训练过程，\n\\[-w^{(t+1)T}\\phi_nt_n = -w^{(t)T}\\phi_nt_n-(\\phi_nt_n)^T(\\phi_nt_n) \u003c -w^{(t)T}\\phi_nt_n \\]\n其是减小误差值的，但是由于每个样本的训练是分开的，他减小的时候可能会导致别人的增大。所以，感知器算法并不保证在每个状态中，总体误差都会更小。\n但是，感知器算法可以保证，如果样本线性可分，那么一定会在有限步内收敛到一个确切的解。（线性不可分则一定不会收敛）\n但是的但是，虽然有限步，可能还是会很大。另外，即使样本线性可分，可能也会存在多个解，感知器达到哪个解，要看他的初始情况和数据的表示方法。\n模式识别课上，感知器算法的更新公式如下（这里没有进行投影变换，以及是原始版本的规范化）：\n\\[w^{(k+1)} = \\left\\{\\begin{matrix} w^{(k)}, \u0026\\ w^{(k)T}x_i\u003e0\\\\ w^{(k)}+Cx_i \u0026\\ w^{(k)T}x_i\\leq 0 \\end{matrix}\\right. \\]\n其中\\(C\\)是一个校正增量。对正确分类的模式则“赏”，实际上是“不罚”，即权向量不变。对错误分类的模式则“罚”，使\\(w^{(k)}\\)加上一个正比于\\(x_i\\)的分量。如此反复直到所有样本都可以被正确分类。\n如果线性可分，那么参数一定会收敛。否则一定无法收敛，会一直迭代。\n这个算法必须要有代表性的正确的训练数据，其对噪声很敏感，解不够鲁棒。\n如果要有比较好的训练效果，以及时间不是开销太大。一般样本数为\\(C=2(k+1)\\)的\\(10\\sim 20\\)倍，其中\\(k\\)为特征维数。\n广义线性判别分析 对于非线性问题，线性判别函数难以正确分类，而且设计非线性判别函数比较复杂。\n此时，常用的方法是将原特征空间映射到一个高维空间，将低维空间中的非线性问题转化为高维空间中的线性问题，从而降低模式分类的难度。\n例如对于二次判别函数\\(g(x)=c_0+c_1x+c_2x^2\\)。我们就可以令\\(y=[1,x,x^2],a=[c_0,c_1,c_2]\\)。则\\(g(x)=a^Ty\\)就是\\(y\\)的线性函数。\n此时称\\(g(y)\\)为广义线性判别函数，\\(a\\)叫做广义权向量。\n如此做的副作用是，增加了特征的维数，如上例就是一维变三维。可以证明，如果特征数有限，那么一定存在一个高维特征空间使得样本线性可分。\n判别函数的一般形式是\n\\[g(x) = w_1f_1(x)+w_2f_2(x)+\\cdots+w_kf_k(x)+w_0 \\]\n其中\\(f_i\\)是单值函数。将函数从\\(x\\)空间变换到\\(y\\)空间后，在新空间中是线性函数。\n87.jpg\r支持向量机 理论基础\n传统的统计模式识别方法只有在样本趋向无穷大时，其性能才有理论的保证。这就是经验风险最 小化理论，比如人工神经网络。统计学习理论（STL）研究有限样本情况下的机器学习问题。SVM 的理论基础就是统计学习理论。\n传统的统计模式识别方法在进行机器学习时，强调经验风险最小化。而单纯的经验风险最小化会产生“过学习问题”（过拟合），其推广能力较差。\n根据统计学习理论，学习机器的实际风险由经验风险值和置信范围值两部分组成。而基于经验风险最小化准则的学习方法只强调了训练样本的经验风险最小误差，没有最小化置信范围值，因此其推广能力较差。\nSVM则是以训练误差（经验风险最小）作为优化问题的约束条件，以置信范围值最小化（推广能力）作为优化目标，即SVM是一种基于结构风险最小化准则的学习方法，其推广能力明显优于一些传统的学习方法。\nSVM的优化最终可以规约为二次规划问题，由于目标和约束都是凸函数，所以SVM的解是全局唯一的最优解。\nSVM在解决小样本、非线性及高维模式识别问题中表现出许多特有的优势，它能够获取全局最优解，并能够推广应用到函数拟合等其他机器学习问题中。\n线性判别函数和判别面\n线性判别函数是由\\(x\\)的各个分量的线性组合而成的函数\n\\[g(x) = w^Tx+w_0 \\]\n支持向量机通常是是二分类分类器。\n97.jpg\r判别面则是方程\\(g(x)=0\\)，也即上面那张图中的直线。\n如果两个点\\(x_1,x_2\\)都在判定面上，那么有\\(w^Tx_1+w_0=w^Tx_2+w_0\\)，即\\(w^T(x_1-x_2)=0\\)。即\\(w\\)与判别面上的任意向量正交，称\\(w\\)为判别面的法向量。\n广义线性判别函数\n和之前说到的广义线性判别分析中的一样，见前即可。\n最优分类超平面\nSVM其基本思想是找到一个分类面（或者是线，或者是超平面），把样本分成两类。但是这样的划分面可能有很多个\n13.jpg\r（注意，样本虽然形式上和逻辑回归相似，都是\\(\\{(x_1,y_1),(x_2,y_2),\\cdots,(x_1,y_1),(x_m,y_m)\\}\\)，并且都是二分类，但是支持向量机这里，\\(y\\in\\{-1,1\\}\\)，\\(1\\)代表正类，\\(-1\\)代表负类）\n直觉上来说，我们应该选择那条加粗的线。因为它对样本的局部扰动容忍性最好。换言之，这个划分超平面所产生的分类结果是最鲁棒的，对未见实例的泛化能力最强.\n这个划分面也叫做最优分类超平面。即一个超平面能够将训练样本没有错误的分开，而且两类训练样本中离超平面最近的样本与超平面之间的距离之和最大。这个距离之和也叫做分类间隔（margin）\n形式地说，划分的超平面的形式如下\n\\[w^Tx+b=0 \\]\n其中\\(w=(w1,w2,\\cdots,w_d)\\)是法向量，决定超平面的方向，\\(b\\)是位移项，决定超平面和原点的距离。我们将其记为\\((w,b)\\)，样本空间中任意一个点\\(x\\)到该超平面的距离为\n\\[r = \\dfrac{|w^Tx+b|}{||w||} \\]\n假设超平面能将训练样本正确分类，即对于\\((x_i,y_i)\\in D\\)，若\\(y_i=1\\)，则有\\(w^Tx_i+b\u003e0\\)，若\\(y_i=-1\\)，则有\\(w^Tx_i+b\u003c0\\)，令\n\\[\\left\\{\\begin{matrix} w^Tx_i+b\\geq +1, \u0026 y=+1\\\\ w^Tx_i+b\\leq -1, \u0026 y=-1 \\end{matrix}\\right. \\]\n如下图\n14.jpg\r距离超平面最近的几个训练样本使得上式的等号成立，这些训练样本被称为支持向量。两个异类支持向量到超平面的距离之和为\n\\[\\gamma = \\dfrac{2}{||w||} \\]\n这也被称为间隔。\n支持向量机的训练目标就是最大化间隔（或者是求最优超平面）。也就是如下的最优化问题\n\\[\\begin{align*} \\max_{w,b} \u0026\\quad \\dfrac{2}{||w||}\\\\ \\text{s.t.} \u0026\\quad y_i(w^Tx_i+b)\\geq 1,\\quad i=1,2,\\cdots,m \\end{align*} \\]\n其中目标函数等价于最小化问题\n\\[\\begin{align*} \\min_{w,b} \u0026\\quad \\dfrac{1}{2}||w||^2\\\\ \\text{s.t.} \u0026\\quad y_i(w^Tx_i+b)\\geq 1,\\quad i=1,2,\\cdots,m \\end{align*} \\]\n上式是一个凸二次规划问题，拉格朗日法得出其对偶问题是\n\\[\\begin{align*} \\max_{\\alpha} \u0026\\quad \\sum^m_{i=1}\\alpha_i-\\dfrac{1}{2}\\sum^m_{i=1}\\sum^m_{j=1}\\alpha_i\\alpha_jy_iy_jx_i^Tx_j\\\\ \\text{s.t.} \u0026\\quad \\sum^m_{i=1}\\alpha_iy_i=0\\\\ \u0026\\quad \\alpha_i\\geq 0,\\quad i = 1,2,\\cdots,m \\end{align*} \\]\n求出\\(\\alpha\\)后，即可算出模型\n\\[f(x)=w^Tx+b=\\bigg(\\sum^m_{i=1}\\alpha_iy_ix_i^T\\bigg)x+b=\\sum^m_{i=1}\\alpha_iy_ix_i^Tx+b \\]\n当然，输出是\\(\\pm 1\\)的话，可以写作\\(f(x) = \\text{sgn}\\bigg\\{\\sum^m_{i=1}\\alpha_iy_ix_i^Tx+b\\bigg\\}\\)。\n其中\\(\\alpha_i\\)是支持向量系数，最优超平面的权重向量等于训练样本以一定的系数加权后进行线性组合。只有满足优化式等号成立的样本对应\\(\\alpha_i\\)的才大于\\(0\\)，其他样本都等于\\(0\\)。求和只对少数支持向量进行。\n当样本集不是线性可分时，存在一些样本使得\\(y_i(w^Tx_i+b)\u003c1\\)。对于这个样本，我们总可以找到一个整数\\(\\xi\\)使得对于该样本有\\(y_i(w^Tx_i+b)+\\xi\\geq 1\\)。对于众多这样的样本，优化目标函数就变为\n\\[\\min_{w}\\dfrac{1}{2}||w||^2+C\\sum\\xi_i \\]\n其中\\(\\xi_i\\)是松弛因子，其和越大，错分的样本越多。此时的目标变成一方面让分类间隔尽可能的大，另一方面让错分的样本尽可能的少且错误率尽可能的低。\n核函数\n到目前为止，我们能分类的样本都只能是线性可分的。如果是对于异或问题等非线性可分的问题，我们引入核函数，将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分。\n15.jpg\r可以证明，如果原始空间是有限维，即属性数有限，那么一定存在一个高维特征空间使样本可分.\n令\\(\\phi(x)\\)表示将\\(x\\)映射后的特征向量（显然\\(\\phi(x)\\)不会是线性变换），于是，在特征空间中划分超平面所对应的模型可表示为\n\\[g(x) = w^T\\phi(x)+b \\]\n其对偶问题是\n\\[\\begin{align*} \\max_{\\alpha} \u0026\\quad \\sum^m_{i=1}\\alpha_i-\\dfrac{1}{2}\\sum^m_{i=1}\\sum^m_{j=1}\\alpha_i\\alpha_jy_iy_j\\phi(x_i)^T\\phi(x_j)\\\\ \\text{s.t.} \u0026\\quad \\sum^m_{i=1}\\alpha_iy_i=0\\\\ \u0026\\quad \\alpha_i\\geq 0,\\quad i = 1,2,\\cdots,m \\end{align*} \\]\n其解为\\(f(x) = \\text{sgn}\\bigg\\{\\sum^m_{i=1}\\alpha_iy_i\\phi(x_i)^T\\phi(x)+b\\bigg\\}\\)\n其中\\(\\phi(x_i)^T\\phi(x_j)\\)是样本映射到特征空间之后的内积。由于特征空间维数可能很高，甚至可能是无穷维，因此直接计算\\(\\phi(x_i)^T\\phi(x_j)\\)通常是困难的。为了避开这个障碍，可以设想这样一个函数：\n\\[\\kappa(x_i,x_j)=\u003c\\phi(x_i),\\phi(x_j)\u003e=\\phi(x_i)^T\\phi(x_j) \\]\n即\\(x_i\\)与\\(x_j\\)在特征空间的内积等于它们在原始样本空间中通过函数\\(\\kappa(x_i,x_j)\\)计算的结果。这里的这个函数就是核函数。\n从计算角度，不论\\(\\phi(x)\\)所生成的变换空间维数有多高，这个空间里的线性支持矢量机求解都可以在原空间通过核函数\\(\\kappa(x_i,x_j)\\)进行，这样就避免了高维空间里的计算，而且计算核函数的复杂度与计算内积并没有实质性增加。\n解出来的模型就是\n\\[f(x)=\\text{sgn}\\bigg\\{\\sum^m_{i=1}\\alpha_iy_i\\kappa(x_i,x)+b\\bigg\\} \\]\n根据泛函的有关理论，只要一种核函数满足Mercer条件，它就对应某一变换空间中的内积。因此，在最优分类面中采用适当的内积函数就可以实现某一非线性变换后的线性分类。现在我们可以说正式得到了完全体的SVM。\n核函数具体形式有许多，在实际问题中，通常是直接给出核函数。常见的有\n线性核函数\\(\\kappa(x_i,x_j)=x_i^Tx_j\\) 多项式核函数\\((x_i^Tx_j)^d\\)，其中\\(d\\geq 1\\)为多项式的次数。也有写作\\((sx_i^Tx_j+c)^d\\)的。 径向基核函数\\(\\exp(-\\gamma||x_i-x_j||^2)\\)。\\(\\gamma=1/2\\sigma^2\\)时称为高斯核，\\(\\gamma=1/\\sigma\\)时称为拉普拉斯核 sigmoid核\\(\\tanh(\\beta x_i^Tx_j+\\theta)\\)，其中\\(\\beta\u003e0,\\theta\u003c0\\) 训练方式\n对于线性情况，我们通过数值最优化办法求出对偶问题的\\(\\alpha\\)，然后显然有\\(w=\\sum \\alpha_iy_ix_i\\)。利用KKT条件可以算出\\(b=\\dfrac{1}{|S|}\\sum_{i\\in S}(y_i-\\sum \\alpha_jy_jx_j^Tx_i)\\)，其中\\(S\\)是所有支持向量的下标集。\n非线性情况，同样地有\\(w=\\sum a_iy_i\\phi(x_i)\\)，\\(b\\)类似。当然我们可能不关注\\(w^Tx\\)而直接关注\\(\\sum^m_{i=1}\\alpha_iy_i\\kappa(x_i,x)\\)\n多分类SVM\nSVM单独一般只能做二分类，但是我们可以训练多个SVM实现多分类。\nOne-against-all方法，把\\(k\\)类问题分解成\\(k\\)个两类问题，例如区分A与非A，B与非B，C与非C三个; One-against-one方法，把\\(k\\)类问题分解成\\(k(k-1)/2\\)个两类问题，例如区分AB，区分BC，区分AC三个; 其他的整体算法(Weston,Bredensteiner, 和Guermeur) 特点\n专门针对有限样本的情况的最优解，而不是无限样本假设的最优解 全局最优解而非局部 推广能力好，避免维数灾难。 较强的非线性处理能力 支持向量是SVM的训练结果，在SVM分类决策中起决定作用的是支持向量。 SVM的最终决策函数只由少数的支持向量所确定，计算的复杂性取决于支持向量的数目，而不是样本空间的维数，这在某种意义上避免了“维数灾难”。 少数支持向量决定了最终结果，这不但可以帮助我们抓住关键样本、“剔除”大量冗余样本,而且注定了该方法不但算法简单，而且具有较好的“鲁棒”性。 增、删非支持向量样本对模型没有影响 支持向量样本集具有一定的鲁棒性 有些成功的应用中，SVM方法对核的选取不敏感 最近邻 近邻法（NN和KNN）在原理上属于模板匹配，并且它没有训练过程。它将训练样本集中的每个样本都作为模板，用测试样本与每个模板做比较，看与哪个模板最相似(即为近邻)，就按最近似的模板的类别作为自己的类别。\n近邻法的共同缺点是计算量大，存储量也大。它也不考虑决策风险。另外有限样本的分析难以进行。\n但是在模板数量很大时其错误率指标还是相当不错的。该方法普适性比较好。常用来作为一个基准算法。\n最近邻就是将与测试样本最近邻样本的类别作为决策的方法。\n对于一个\\(C\\)类别问题，每类有\\(N_i\\)个样本，则第\\(i\\)类的判别函数为\n\\[g_i(x) = \\min_k||x-x_i^k|| \\]\n其中\\(x^k_i\\)表示\\(w_i\\)类中的第\\(k\\)个样本。距离可以有很多种，用的比较多的是欧氏距离。\n决策规则为，\\(w = \\arg\\min_w g_i(x)\\)。\n最近邻法的错误率会有偶然性，也就是指与具体的训练样本集有关。计算错误率的偶然性会因训练样本数量的增大而减小。随着训练样本的增加，准确率会有所提高。\n最近邻的错误率比贝叶斯错误率要大，但是在无限样本的情况下，错误率不会超过两倍贝叶斯错误率。\nNN的错误概率为\n\\[P(err)=1-\\sum_{c\\in Y}P(c|x)P(c|z) \\]\n其中\\(x\\)是测试样本，\\(z\\)是其最邻近样本。\n在无限大样本时，有\n\\[P(err)\\approx 1 - \\sum_{c\\in Y}P^2(c|x)\\leq 1-P^2(c^*|x)=(1+P(c^*|x))(1-P(c^*|x))\\leq 2\\times(1-P(c^*|x)) \\]\nKNN KNN的思想很简单，挑选出距离该样本最近的\\(k\\)个样本，这\\(k\\)个样本中最多的类别决定为预测类别。\\(k\\)一般为奇数。一般比较小，如几或几十，通常可以用交叉验证来确定最优的\\(k\\)。\n在无穷多样本的情况下，KNN错误率要低于NN。也仍然是在一倍到两边贝叶斯错误率之间。\n决策树 78.jpg\r决策树比较适合离散属性的分类问题。他是一种多级分类器，综合采用多个决策规则，逐步把复杂的多类别分类问题转化为若干个简单的分类问题。\n决策树是一个树形的决策帮助数据结构工具。一般的，一棵决策树包含一个根结点、若干个内部结点和若干个叶结点；叶结点对应于决策结果，其他每个结点则对应于一个属性测试；每个结点包含的样本集合根据属性测试的结果被划分到子结点中；根结点包含样本全集。从 根结点到每个叶结点的路径对应了一个判定测试序列.\n二叉决策树是一个特例，把复杂的多分类任务转化成多级两分类任务。\n对噪声数据有很好的健壮性且能学习析取表达式，之前的线性判别函数中的感知器函数对噪声特别敏感，决策树对噪声鲁棒性较好。\n构造好的决策树的关键在于如何选择好的逻辑判断或属性。人们研究出，一般情况下或具有较大概率地说，树越小则树的预测能力越强。要构造尽可能小的决策树，关键在于选择恰当的逻辑判断或属性。\n若某一个子集上样本很少，还有分支，这说明属性不是很好，只对某些很少的样本有作用（过拟合）\n决策树的适用条件：\n有一个决策者期望实现的明确目标。 决策者有多于两种可行的选项 有多于两个不确定的因素超过了决策者的控制范围 决策者可以估计不确定因素的发生概率 可以计算不同方案在不同因素下的收益或损失 优点：可以生成可以理解的规则，比较直观；计算量不太大；可以处理连续和离散字段；可以清晰地在树的构造过程中显示哪些字段比较重要\n缺点：对于连续性的字段比较难预测；类别太多时，错误率可能会增加的比较快；一般的算法分类时，只是根据一个属性来分类；不是全局最优。\n生成决策树有三种算法：ID3（处理离散）、C4.5（处理连续）、CART（处理属性缺失）。\n信息增益\n信息增益Information Gain，指知道一个特征后，不确定性的减少程度。也就是知道前后的信息熵的变化程度。记作\\(g(D,A)\\)，其中\\(D\\)是训练集，\\(A\\)是其中的一个特征，有\n\\[g(D,A) = H(D) - H(D|A) \\]\n其中\n\\[H(D) = -\\sum_i\\dfrac{|C_i|}{|D|}\\log\\dfrac{|C_i|}{|D|} \\]\n\\[H(D|A) = \\sum^K_{k=1}\\dfrac{|D_k|}{|D|}H(D_k) \\]\n其中\\(D_k\\)指的是，离散属性\\(A\\)将当前样本集划分成\\(n\\)个分支节点，每个分支构成了一个新样本集\\(D_k\\)。其中\\(C_i\\)是指分类目标有几类，其中\\(D\\)所有样本中属于第\\(i\\)类的集合。例如分为正类和负类，\\(C_0\\)就是\\(D\\)中所有负类的集合，\\(C_1\\)就是\\(D\\)中所有正类的集合。\n样本数越多的分支结点的影响越大，信息增益越大，则意味着使用属性\\(A\\)来进行划分所获得的“纯度提升”越大。因此，我们可用信息增益来进行决策树的划分属性选择。\nID3选择这个值来选择最优划分属性。\n信息增益率\n实际上，信息增益准则对可取值数目较多的属性有所偏好，为减少这种偏好可能带来的不利影响，C4.5选择使用增益率来替代。\n\\[g_R(D,A) = \\dfrac{g(D,A)}{H_A(D)} \\]\n\\[H_A(D) = -\\sum^K_{k=1}\\dfrac{|D_k|}{|D|}\\log\\dfrac{|D_k|}{|D|} \\]\n属性\\(A\\)的可能取值越多，通常\\(H_A\\)会越大。\n但是C4.5也不是直接使用增益率，增益率准则对可取值数目较少的属性有所偏好。它使用一种启发式的算法，先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。\n基尼指数\nCART选择使用基尼不纯度来选择划分属性，数据集的纯度可以用基尼值来度量\n\\[Gini(D) = \\sum^{|Y|}_{k=1}\\sum_{k'\\neq k}p_kp_{k'} = 1 - \\sum^{|Y|}_{k=1}p_k^2 \\]\n直观来说，\\(Gini(P)\\)反映了从数据集\\(D\\)中随机抽取两个样本，其类别标记不一致的概率。因此，\\(Gini(D)\\)越小，则数据集\\(D\\)的纯度越高。基尼指数定义为\n\\[Gini\\_index(D,A) = \\sum^K_{k=1}\\dfrac{|D_k|}{|D|}Gini(D_k) \\]\n于是最优属性为\\(a^*=\\arg\\min_{a\\in A} Gini\\_index(D,A)\\)\n决策树的算法流程如下\n79.jpg\r剪枝（pruning）\n剪枝是决策树学习算法对付“过拟合”的主要手段。在决策树学习中，为了尽可能正确分类训练样本，结点划分过程将不断重复，有时会造成决策树分支过多，这时就可能因训练样本学得“太好” 了，以致于把训练集自身的一些特点当作所有数据都具有的一般性质而导致过拟合。因此，可通过主动去掉一些分支来降低过拟合的风险.\n决策树剪枝的基本策略有 “预剪枝”(prepruning)和 “后剪枝 \u0026quot; (post-pruning)两种。预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点；后剪枝则是先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点.\n随机森林 在讲随机森林前要先讲集成学习，见后。\n决策树对于训练集的数据很敏感，如果训练集太小，则预测结果会不好，如果训练集太大，则容易过拟合。所以要引入随机森林。\n另外，像CART这样的算法，是贪心的，即使使用bagging，所有的决策树结构上还是相似的，并且预测是相关的。如果来自子模型的预测是不相关的，或者至少是弱相关的，那么集合方法就能工作得更好。\n随机森林是决策树的集成，通常使用bagging。随机森林的算法略微调整bagging，使得决策树的训练的数据的特征，被限制在了一些随机采样出来的特征中，从而解决相关性的问题。\n设训练集的大小是\\(n\\)，利用采样，可放回地对训练集采样\\(n\\)次，得到一个大小同样为\\(n\\)的数据集。重复这个操作，得到\\(m\\)个大小为\\(n\\)采样集。（可以算出每个采样集中有原始数据集的\\(63.2\\%\\)的样本）（也就相当于使用\\(m\\)次bootstrapping） 我们在这\\(m\\)个采样集上，分别训练\\(m\\)个决策树。 用这\\(m\\)个决策树同时预测一个数据，通过投票结果，给出最后的判断。 传统的决策树是，从当前的\\(d\\)个特征中选择最优的特征。随机森林中的决策树，是随机选取\\(d\\)个特征中的\\(k\\)个特征。在从\\(k\\)个特征中选出最优的那个特征。\n通常，对于分类任务，可以选择\\(k=\\sqrt{d}\\)，对于回归任务，可以选择\\(k=d/3\\)\n优点\n作为最流行的一种bagging算法，它综合几个弱学习器来形成一个强学习器，提高准确度的同时降低方差，并且还消除了过拟合。\n缺点\n引入了模型可解释性的损失。当没有进行适当的步骤时，可能会给结果模型引入很多偏差。计算复杂度可能提升。\n无监督学习 和有监督学习相比，无监督学习就是样本没有打上label。\n训练集一般就没有\\(y\\)，为\\(\\{x^{(1)}, x^{(2)}, \\cdots, x^{(m)}\\}\\)。常见的应用有：网络搜索、认知科学、神经学、遗传学。\n高斯混合模型 统计学习模型可以分为两类，一类是概率模型，另一类是非概率模型。\n概率模型的形式是\\(P(Y|X)\\)。如果输入是\\(X\\)，输出是\\(Y\\)，训练后模型得到的输出不是一个具体 的值，而是一系列的概率值。对于聚类问题来说，就是输入\\(X\\)对应于各个不同聚类簇\\(Y\\)的概率，称作软聚类。\n非概率模型的形式是一个决策函数\\(Y=f(X)\\)，如果输入是\\(X\\)，输出是\\(Y\\)，训练后模型得到的 输出是一个具体的值。对于聚类问题来说，输入数据\\(X\\)后就可以通过模型映射得到唯一的判决结果\\(Y\\)，在无监督学习中称作硬聚类。\n高斯混合模型（GMM）是一种典型的概率模型。假设所有数据点都是由具有未知参数的有限个高斯分布混合产生的。\n高斯混合模型是用于估计样本的概率密度分布的方法，其估计采用的模型是几个在训练前就已经建立好的高斯模型的加权和。高斯模型的数目是一个超参数，在模型建立前给定，每个聚类簇都对应于一个高斯分布。\n理论上，高斯混合模型可用于近似任何概率分布。\n单高斯模型的基本定义和之前提到的正态分布下的统计决策一致。即用一个一维正态分布或者一个多维正态分布就可以描述样本\\(x\\)，将\\(x\\)代入概率密度函数，当概率值大于给定阈值时，就认为该样本属于\\(C\\)类。\n单高斯分布模型可以拟合数据接近高斯分布的情况，但实际应用中，数据的分布情况往往不满足高斯分布，这就引入了高斯混合模型。\n高斯混合模型假定样本数据分布服从几个高斯分布的加权和的形式。\n\\[\\Pr(x) = \\sum^K_{k=1}\\pi_kN(x;\\mu_k,\\Sigma_k) \\]\n其中任意的一个高斯分布称为这个模型的一个分量。\\(0\\leq \\pi_k\\leq 1\\)是混合系数，表示每个分量的权重 。满足\\(\\sum \\pi_k=1\\)\n107.jpg\r将高斯混合模型用于聚类\n先假设数据服从混合高斯分布，再根据数据推出高斯混合模型的概率分布就可以进一步求出各个样本属于每个聚类的概率。\n高斯混合模型的\\(K\\)个高斯模型实际上对应\\(K\\)个聚类簇。\n高斯混合模型参数的求解，就是在只有样本数据，而不知道样本分类的情况下，计算出模型的隐含参数\\(\\pi_k,\\mu,\\Sigma\\)。可以使用期望最大化（EM）算法来求解。\n求解完后聚类的具体步骤为\n以\\(\\pi_k\\)为概率随机选择\\(K\\)个高斯分布分量中的一个（个人猜测类似于轮盘赌） 把样本数据代入第一步中选中的高斯分布，判断输出概率是否大于阈值，如果不是则返回第一步重新选择。 如何求解模型？如果样本分类已知，就是有监督学习，可以用最大似然估计\n\\[\\pi_k = \\dfrac{N_k}{N} \\]\n\\[\\mu_k = \\dfrac{1}{N_k}\\sum_{x\\in L(k)}x \\]\n\\[\\Sigma_k=\\dfrac{1}{N_k}\\sum_{x\\in L(k)}(x-\\mu_k)(x-\\mu_k)^T \\]\n其中\\(N\\)是总样本数，\\(N_k\\)是属于\\(k\\)类的样本数，\\(L(k)\\)是\\(k\\)类的样本集合。\n如果样本分类未知，就是无监督学习。假设有\\(N\\)个数据点，其服从某种分布\\(Pr(x;\\theta)\\)，我们的目标是找到一组这种分布的参数\\(\\theta\\)，使得在这种分布下生成这些数据点的概率最大，也就是似然函数最大。似然函数表示为\n\\[\\prod^N_{i=1} \\Pr(x_i;\\theta) \\]\n在实际应用中，往往单个点分布的概率都很小，为了便于求解， 一般对似然函数取对数 ，得到对数似然函数。对高斯混合模型求对数似然函数\n\\[\\sum^N_{i=1}\\log\\bigg[\\sum^K_{k=1}\\pi_k N(x_i;\\mu_k,\\Sigma_k)\\bigg] \\]\n我们的目标是要找到一组最佳的模型参数，使得上式所示的期望最大，期望最大化算法（EM）的名字就由此而来。\nEM算法\n在统计模型中，EM算法是一种求参数的最大似然或最大后验概率(MAP)估计的迭代方法，其模型依赖于未观测到的隐含变量。\nEM算法迭代地交替执行期望(E)步和最大化(M)步 E步使用参数的当前估计计算的对数似然的期望值创建函数 M步计算最大化在E步上找到的期望对数似然的参数。然后用这些参数估计来确定下一步中隐含变量的分布。 EM求解的问题的一般形式是\n\\[\\theta^* = \\arg\\max_{\\theta}\\prod^{|X|}_{j=1}\\sum_{y\\in Y}\\Pr(X=x_j,Y=y;\\theta) \\]\n其中\\(Y\\)是隐含变量。其基本思路是：随机初始化一组模型参数\\(\\theta^{(0)}\\)，并根据后验概率更新\\(Y\\)的预期\\(E(Y)\\)，然后用\\(E(Y)\\)代替\\(Y\\)求出新的模型参数\\(\\theta^{(1)}\\)。如此迭代直到\\(\\theta\\)收敛。\n定义分类数目\\(K\\)，对每个分量\\(k\\)设置\\(\\pi_k,\\mu_k,\\Sigma_k\\)的初始值，然后计算对数似然函数 E步，引入隐含变量\\(\\gamma\\)，其在高斯混合模型中表示数据点由各个分量生成的概率 \\[\\gamma(i,k) = \\dfrac{\\pi_kN(x_i;\\mu_k,\\Sigma_k)}{\\sum^K_{j=1}\\pi_jN(x_i;\\mu_j,\\Sigma_j)} \\]\nM步，通过最大似然估计来求解模型参数，现在我们认为上一步求出\\(\\gamma(i,k)\\)的就是“数据点\\(x_i\\)由分量\\(k\\)生成的概率。仿照之前的有类别标记的估计法，有 \\[N_k = \\sum^N_{i=1}\\gamma(i,k) \\]\n\\[\\pi_k = \\dfrac{N_k}{N} \\]\n\\[\\mu_k = \\dfrac{1}{N_k}\\sum^N_{i=1}\\gamma(i,k)x_i \\]\n\\[\\Sigma_k = \\dfrac{1}{N_k}\\sum^N_{i=1}\\gamma(i,k)(x_i-\\mu_k)(x_i-\\mu_k)^T \\]\n计算对数似然函数\\(\\sum^N_{i=1}\\log\\bigg[\\sum^K_{k=1}\\pi_k N(x_i;\\mu_k,\\Sigma_k)\\bigg]\\) 检查参数是否收敛，或者对数似然函数是否收敛，不收敛则返回2 K-means聚类算法 K-means是一种基于样本间相似性度量的聚类方法，这类方法的目标是类内样本相似性高，类间样本相似性低。基于样本间相似性度量的聚类方法可以分为动态聚类法和层次聚类法，K-means是动态聚类法。\n动态聚类的关键点是\n选取一定的距离度量方法作为样本间的相似性度量准则。 确定样本的合理初始划分，包括代表点的选择，初始分类方法的选择等。 确定评价聚类结果质量的准则函数，对初始分类进行调整，使其达到该准则函数的极值。 K-means算法把\\(n\\)个样本分成\\(k\\)类，每一个样本和与它最近的类型中心分为一类。这里可以是各种距离，包括欧几里得距离、海明距离、曼哈顿距离等。\n假设样本集为\\(D=\\{x_1,x_2,\\cdots,x_m\\}\\)，要把他们分为\\(k\\)类，\\(C=\\{C_1,C_2,\\cdots,C_k\\}\\)。K-means的优化目标是，最小化：\n\\[J = \\sum^k_{i=1}\\sum_{x\\in C_i}||x-\\mu_i||^2_2 \\]\n其中\\(\\mu_i\\)是每一类的聚类中心，\n\\[\\mu_i = \\dfrac{1}{|C_i|}\\sum_{x\\in C_i}x \\]\n\\(J\\)越小，代表着各类的样本和样本重心的紧密度（closeness degree）越高，代表着聚类效果越好。\n算法流程如下：\n随机选取\\(k\\)个聚类中心\\(\\mu_i\\)，可以指定坐标，也可以直接从样本点中随机选。 把每个点划分进最近的聚类中心的那一类。 计算新的聚类中心。即使用\\(\\mu_i = \\dfrac{1}{|C_i|}\\sum_{x\\in C_i}x\\) 重复2-3，直到迭代次数足够，或聚类中心不再改变（两次迭代的距离差距极小） 优点：简单、快速；处理大数据集，该算法是相对可伸缩和高效率的；当类密集，且类与类之间区别明显（比如球型聚集）时，聚类效果很好；\n缺点：结果与初始聚类中心有关；必须预先给出类别数\\(k\\)；对噪声和孤立点敏感；不适合发现非凸面形状的聚类\n对于初值选择问题，可以多设置一些不同的初值，对比最后的结果，直到稳定。\n对于聚类数未知情况下的聚类问题：聚类分裂、合并确定聚类数；可以通过其他的算法来估计\\(k\\)\n模糊聚类（FCM） 前置知识为人工智能概论笔记\n这里只用到\\(\\mu_A(x)\\)表示\\(x\\)属于集合\\(A\\)的程度。\n在模糊模式识别中，用模糊子集代替确定子集，而得到模糊的分类结果，即分类结果的模糊化，其中，一个样本以不同的程度属于各个类别，而不再属于某个确定的类别。也就是软聚类。\n优点是：可以反映出分类过程中的不确定性, 有利于用户根据结果进行决策。模糊化的分类结果比明确的分类结果中包含更多的信息, 有利于进一步决策。\n相较于Kmeans的准则函数，FCM的准则函数添加了隶属度部分（有\\(N\\)个样本，共\\(C\\)类）\n\\[J_f = \\sum^C_{j=1}\\sum^N_{i=1}[\\mu_j(x_i)]^b||x_i-m_j||^2 \\]\n其中\\(b \u003e1\\)是一个可以控制聚类结果的模糊程度的超参数，\\(m_j\\)是\\(j\\)类的聚类中心。约束条件为\n\\[\\sum^C_{j=1}\\mu_j(x_i)=1 \\]\n在此\\(N\\)个约束条件下，对\\(J_f\\)使用拉格朗日乘数法，可得\n\\[m_j = \\dfrac{\\sum^N_{i=1}[\\mu_j(x_i)]^bx_i}{\\sum^N_{i=1}[\\mu_j(x_i)]^b} \\]\n\\[\\mu_j(x_i) = \\dfrac{(1/||x_i-m_j||^2)^{1/(b-1)}}{\\sum^C_{l=1}(1/||x_i-m_l||^2)^{1/(b-1)}} \\]\n算法步骤为：\n设定聚类数目\\(C\\)，参数\\(b\\)（通常为\\(2\\sim 5\\)），和一个\\(\\varepsilon \u003e0\\) 初始化聚类中心 根据上式更新\\(\\mu_j(x_i)\\) 根据新的隶属度函数更新新的聚类中心 如果两次迭代的聚类中心不变动（变动距离小于\\(\\varepsilon\\)），则停止。否则返回3 最后的输出可以输出隶属度，也可以输出隶属度最大的类。\nFCM算法速度较快，对于满足正态分布的数据聚类效果会很好。但是也会对孤立点敏感，并且也对初始化关系大，且需要提前给出类别数。\n层次聚类算法 基于划分的聚类算法可以将数据集划分为指定数量的聚类簇，但在某些情况下，数据集需要在不同的级别进行划分。\n并且，基于划分的算法需要给出聚类的数目\\(K\\)，实际应用中经常不能确定类的数目。有时，数据集划分为两类四类八类都是合理的。因此，特定数据集应该聚成多少个簇通常取决于我们研究该数据集的尺度。\n层次聚类算法主要分为分裂的和凝聚的两类，具体决于其层次结构是“自上而下”还是“自下而上”的。\n分裂方法：自上而下，首先把所有样本数据归为同一个聚类簇。然后递归地把这些聚类簇划 分成更小的子聚类簇，直到每一个样本都单独作为一个聚类簇，或满足某个终止条件。常见的基于分裂方的的算法有层次K-均值算法。\n凝聚方法：自下而上，数据集中的每个样本首先被视为一个聚类簇，然后迭代地将这些较小 的簇合并为更大的聚类簇。直到最后所有样本被归为一个大聚类簇，或满足某个终止条件。\n层次K均值\n把所有样本数据归到一个簇\\(C\\)中，即为层次结构的根 使用Kmeans把簇\\(C\\)划分成指定的\\(K\\)个子簇 对于2中的\\(K\\)个簇，分别使用Kmeans划分为更小的簇，递归地只到无法划分或者满足终止条件。 缺点：一旦两个样本在开始时被分成不同的簇，即使两点之间的距离非常接近，它们也不会在以后的聚类过程中聚在一起。\n凝聚方法\n把每个样本都看做一个簇，共\\(n\\)个，每个簇只含一个样本 重复以下步骤，只到所有样本被聚类到同一个簇或者满足停止条件 从\\(C\\)中找到两个距离最近的簇 合并这两个簇 从\\(C\\)中删除原来的两个簇，添加新簇 关于簇间的距离。单连锁方式：两个簇中相距最近的点作为簇间距离。全连锁方式：按照两个簇中相距最远的两个点之间的距离作为簇间距离。平均连锁：把两个簇之间两两点之间的距离的平均值作为簇间距离。\n主成分分析（Principal Component Analysis(PCA)） 主成分分析更多地用作一种降维手段，它主要涉及识别数据中的相关性。\n考虑在正交属性空间中的样本点，如何用一个超平面（直线的高维推广）对所有样本进行恰当的表达？\n显然这个超平面如果存在，就要\n最近重构性（Recent reconfigurability）：样本点到这个超平面的距离都足够近。 最大可分性（Maximum separability）：样本点在这个超平面上的投影能尽可能分开。 在这个超平面子空间（\\(d'\\)维）中，目标是使得\\(x_1,\\cdots,x_n\\in R_d\\)的重构误差最小。重构误差的判决函数在最小二乘意义上如下\n\\[J_{d'} = \\sum^n_{i=1}\\bigg|\\bigg|\\sum^{d'}_{k=1}y_{ik}e_k-x_i\\bigg|\\bigg|^2 \\]\n其中\\(e_1,\\cdots,e_{d'}\\)是子空间的基（是吗？写的有问题吧，明明\\(e\\)的维度是\\(d\\)），也就是投影矩阵\\(A\\)的列向量，\\(y_i = A^Tx_i\\)\n最小化重构误差（老师的PPT一坨史，前后文有关系吗？）：\n\\[J = \\dfrac{1}{N}\\sum^N_{n=1} ||x_n-\\tilde{x}_n||^2 \\]\n设\\(\\{u_i\\},i=1,\\cdots,D\\)是原空间的正交基向量，而\\(u_i^Tu_j=\\delta_{ij}\\)。然后这个量再也没有用过，老师可能缝合了六七个PPT，变量乱窜，前文没有后文，后文没有前文，我决定不学，改为学周志华的《机器学习》。\n假设数据样本进行了中心化，即\\(\\sum_i x_i=0\\)。投影变换后得到的新坐标系为\\(\\{w_1,w_2,\\cdots,w_{d'}\\}\\)，其中\\(w_i\\)是标准正交基向量，\\(||w_i||_2=1\\)。此时，样本点\\(x_i\\)在低维坐标中的投影是\\(z_i=(z_{i1},z_{i2},\\cdots,z_{id'})\\)，其中\\(z_{ij} = w_j^Tx_i\\)（或者说，\\(z_i=W^Tx_i\\)）。如果基于\\(z_i\\)来重构\\(x_i\\)，则有\\(\\hat x_i = \\sum^{d'}_{j=1}z_{ij}w_j\\)。\n考虑整个训练集，原样本点\\(x_i\\)与基于投影重构的样本点\\(\\hat x_i\\)之间的距离为\n\\[\\sum^m_{i=1}\\bigg|\\bigg|\\sum^{d'}_{j=1}z_{ij}w_j-x_i\\bigg|\\bigg|^2 = -tr\\bigg(W^T\\bigg(\\sum^m_{i=1}x_ix_i^T\\bigg)W\\bigg) \\]\n基于最近重构性，上式应该被最小化，\n\\[\\begin{align*} \\min_W\\quad \u0026 -tr(W^TXX^TW)\\\\ s.t.\\quad \u0026 W^TW=I \\end{align*} \\]\n这就是主成分分析的优化目标。即最小化重构误差。\n主成分分析还有另一种解释，即最大化方差，方差为\\(\\sum_iW^Tx_ix_i^TW\\)，于是优化目标变为\n\\[\\begin{align*} \\max_W\\quad \u0026 tr(W^TXX^TW)\\\\ s.t.\\quad \u0026 W^TW=I \\end{align*} \\]\n易见二者是等价的。\n算法流程如下，设样本集是\\(D=\\{x_1,x_2,\\cdots,x_m\\}\\)，要将他降维至\\(d'\\)维。\n对所有样本进行中心化：\\(x_i\\rightarrow x_i-\\dfrac{1}{m}\\sum^m_{i=1}x_i\\)，即最后使得\\(\\sum_i x_i=0\\) 计算样本的协方差矩阵\\(XX^T\\) 对协方差矩阵\\(XX^T\\)做特征值分解（常见的其实会用SVD分解，分解成\\(U\\Sigma V^T\\)，这里的\\(V\\)，每一列向量都是样本的主成分，也是特征值） 取\\(V^T\\)中的前\\(d'\\)个列向量\\(w_1,w_2,\\cdots,w_{d'}\\) 输出\\(W=[w_1,w_2,\\cdots,w_{d'}]\\) 此时，样本点\\(x_i\\)在低维坐标中的投影是\\(z_i=(z_{i1},z_{i2},\\cdots,z_{id'})\\)，其中\\(z_{ij} = w_j^Tx_i\\)（或者说，\\(z_i=W^Tx_i\\)）。\n至于如何选择\\(d'\\)，则可以使用交叉验证，使用KNN验证不同的\\(d'\\)的效果。\n对PCA，还可从重构的角度设置一个重构阈值，例如\\(t = 95\\%\\)，然后选取使下式成立的最小\\(d'\\)值：\n\\[\\dfrac{\\sum^{d'}_{i=1}\\lambda_i}{\\sum^{d}_{i=1}\\lambda_i}\\geq t \\]\n其中\\(\\lambda_i\\)是特征值，并且特征值从大到小排序。\n概率的PCA\n目标是使用隐变量\\(z_i\\in R_{d'}\\)下表示每个\\(x_i\\)，假设隐变量的分布为\n\\[p(z) = N(z|0,I) \\]\n通过投影，生成相应的数据点\n\\[p(x|z) = N(x|Wz+\\mu, \\sigma^2I) \\]\n其中\\(W\\in R_{d\\times d'}\\)称为主轴，于是，从生成的角度来看，概率PCA模型就是\n\\[x = Wz+\\mu+\\epsilon \\]\n假设我们要用最大似然函数来获取这些参数，那么\n\\[p(x) = \\int p(x|z)p(z)dz = N(x|\\mu, C) \\]\n其中协方差矩阵\\(C\\in R_{d\\times d}\\)为\n\\[C = WW^T+\\sigma^2I \\]\n其逆矩阵为\n\\[C^{-1} = \\sigma^{-2}I - \\sigma^{-2}WM^{-1}W^T \\]\n其中\n\\[M = W^TW+\\sigma^2I\\in R_{d'\\times d'} \\]\n于是后验概率为\n\\[p(z|x) = N(z|M^{-1}W^T(x-\\mu), \\sigma^{-2}M) \\]\n核PCA\n即在非线性空间中使用的PCA。\n独立成分分析（Independent Component Analysis(ICA)） ICA是一种统计学原理的计算方法，是一种线性变换。这个变幻把数据或信号分为统计学意义上独立的非高斯源的线性组合。其最重要的假设是，假设信号在统计学意义上是独立的。\n经典问题是鸡尾酒会问题（cocktail party problem）。\n17.jpg\r在派对中，可能会有很多人说话，这些声音嘈杂在一起，但是人可以从其中专注于单一的说话者。ICA就是用于解决这种分离问题的。图上的\\(W\\)是分离矩阵。\n生成对抗网络（Generative Adversarial Network(GAN)） GAN由一个生成网络（generation network）和一个判别网络（discriminant network）组成。\n具体而言，生成网络从潜在空间（potential space，latent space）中随机采样来作为输入（通常会用随机分布作为输入，并且通常用高斯分布），其输出需要尽可能模拟训练集中的真实样本。\n判别网络的输入是真实样本和生成网络的输出，目的就是尽可能将生成网络生成的东西和真实的东西区分开来。\n两个网络相互对抗，并不断调整参数，最终目标是使判别网络无法很好地区分生成网络生成的数据和真实样本的数据。\n其公式如下\n\\[\\min_G\\max_D V(D,G)=E_{x\\sim p_{data}(x)}[\\log D(x)] + E_{z\\sim p_z(z)}[\\log(1-D(G(z)))] \\]\n其中\\(E_{x\\sim p}[\\log Q(x)]\\)这种形式的东西是交叉熵，见附录。\n\\(E_{x\\sim p_{data}(x)}[\\log D(x)]\\)描述的是真实数据的交叉熵，其中\\(x\\)是真实数据。而\\(E_{z\\sim p_z(z)}[\\log(1-D(G(z)))]\\)是从潜在空间中生成的东西的交叉熵，其中\\(G(z)\\)是从该空间中生成的东西。\n\\(V(D,G)\\)相当于表示真实样本和生成样本的差异程度，其中G是生成器，D是判别器。\\(min_G\\max_D\\)代表，首先固定\\(G\\)，最大化判别器的判别效果。然后最大化判别器之后将其固定，要求最小化生成器生成的东西和真实数据的差异。\n半监督学习 通用理论 如果训练集里面一部分是有标签的，而另一部分是无标签的，那么在此上训练的就是半监督学习算法。\n虽然什么比例都可以，但通常情况下是，有标签的只占一小部分，大部分仍是无标签。大部分的半监督学习算法也是结合了有监督学习和无监督学习，例如深度置信网络（Deep Belief Networks(DBNS)），他是一个以无监督学习为基础的受限玻尔兹曼机（Restricted Boltzmann Machine(RBMS)），但是整个系统却是建立在有监督学习技术上的。\n实际上，未标记样本虽然没有直接含有类别标记信息，但如果它们和有标记样本是从相同的数据中独立同分布采样得到的，则它们包含的有关数据分布的信息对学习模型有很大帮助。\n如何让学习过程不依赖外界的咨询交互，自动利用未标记样本所含信息来提高模型性能便是本专题所要介绍的内容，即半监督学习(Semi-Supervised Learning，SSL)。\n形式化地来说，有标记的样本集记为\\(D_l=\\{(x_1,y_1),(x_2,y_2),\\cdots,(x_l,y_l)\\}\\)，未标记的样本集为\\(D_u=\\{x_{l+1},x_{l+2},\\cdots,x_{l+u}\\}\\)。其中通常会有\\(l \u003c\u003c u\\)\n面对这样的问题，我们可能会有如下的思路。\n思路1\n只使用\\(D_l\\)来训练。其问题是样本过少，完全舍弃非标记样本的信息，训练量不足\n思路2\n把\\(D_u\\)打上标记。这其实就转化为有监督学习了，缺点是消耗大量时间。\n思路3\n先利用\\(D_l\\)学出一个模型，然后利用这个模型，从\\(D_u\\)中挑出一个样本，对这个样本的标签进行预测（查询），把这个获得标签的样本作为新的标记样本加入\\(D_l\\)中重新学习得到一个模型。反复重复直到\\(D_u\\)全部被给予标记并被放入\\(D_l\\)中。\n这样的学习方式被称为主动学习（Active Learning）。其目标是希望尽可能少的查询标签来获得尽量好的模型性能。\n缺点是，显然主动学习引入了额外的专家知识，仍然需要与外界产生交互来将部分未标记样本转变为有标记样本。\n思路4\n利用未标记样本提供的数据分布的信息。这样的学习方式被称为半监督学习。让学习器不依赖外界交互、自动的利用未标记样本来提升学习性能，就是半监督学习（Semi-Supervised Learning，SSL）。即训练集中同时包含有标记样本数据和未标记样本数据。\n半监督学习需要预设两个假设前提\n聚类假设（Cluster Assumption）：假设数据存在簇结构，同一个簇的样本属于同一个类别。 流形假设（Manifold Assumption）：假设数据分布在一个流形结构上，邻近的样本拥有相似的输出值。 更一般地假设，如果两个样本相似，那么他们具有相似的输出。\n99.jpg\r半监督分类 生成式模型\n给定样本\\(x\\)，类别标记为\\(y\\in Y=\\{1,2,\\cdots,N\\}\\)。假设样本是由高斯混合模型生成的。且每一个类别都对应一个高斯混合成分，数据是由如下概率密度生成\n\\[p(x) = \\sum^N_{i=1}\\alpha_i\\cdot p(x;\\mu_i,\\Sigma_i) \\]\n其中\\(a_i\\geq 0, \\sum a_i=1\\)\n用\\(f(x)\\in Y\\)表示模型\\(f\\)对样本的预测值，\\(\\Theta\\in\\{1,2,\\cdots,N\\}\\)是样本\\(x\\)隶属的高斯混合成分。最大化后验概率得\n\\[\\begin{align*} f(x) \u0026 = \\arg\\max_{j\\in Y}p(y=j|x) \\\\ \u0026 = \\arg\\max_{j\\in Y}\\sum^N_{i=1}p(y=j,\\Theta=i|x)\\\\ \u0026 = \\arg\\max_{j\\in Y}\\sum^N_{i=1}p(y=j|\\Theta=i,x)\\cdot p(\\Theta=i|x)\\\\ \u0026 \\end{align*} \\]\n其中\\(p(y=j,\\Theta=i,x)\\)是第\\(i\\)个高斯混合成分生成，且类别为\\(j\\)的概率\n\\[p(\\Theta=i|x) = \\dfrac{\\alpha_i\\cdot p(x;\\mu_i,\\Sigma_i)}{\\sum^N_{j=1}\\alpha_j\\cdot p(x;\\mu_j,\\Sigma_j)} \\]\n是样本\\(x\\)由第\\(i\\)个高斯混合成分生成的后验概率。\n这里面，\\(p(y=j|\\Theta=i,x)\\cdot p(\\Theta=i|x)\\)的前半部分要知道标记\\(y\\)，也就是有标记样本，而后半部分不需要知道，于是我们就可以同时利用有标记和未标记样本。\n参数求解过程如下：\n假定给了有标记数据集\\(D_l\\)和未标记数据集\\(D_u\\) 假设所有样本独立同分布且由同一个高斯混合模型生成 使用极大似然估计得到高斯混合模型的参数\\(\\alpha_i,\\mu_i,\\Sigma_i\\) 使用EM算法对其参数进行求解 其中，极大似然函数可以写作\n\\[LL(D_l\\cup D_u) = \\sum_{(x_j,y_j)\\in D_l}\\ln\\bigg(\\sum^N_{i=1}\\alpha_i\\cdot p(x_j;\\mu_i,\\Sigma_i)\\cdot p(y_j|\\Theta=i,x_j)\\bigg) + \\sum_{x_j\\in D_u}\\ln\\bigg(\\sum^N_{i=1}\\alpha_i\\cdot p(x_j;\\mu_i,\\Sigma_i)\\bigg) \\]\nEM算法如下\n110.jpg\r111.jpg\r半监督SVM\n其中使用最广泛的是TSVM。使用转导推理（Transductive Inference）方法，通过观察特定的训练样本，进而预测特定的测试样本。\nTSVM也是针对二分类问题，tsvm的目标是给出\\(D_u\\)的预测标记\\(\\hat y=\\{y_{l+1},y_{l+2}+\\cdots+y_{l+u}\\}\\)，使得划分超平面具有最大边界。即\n\\[\\begin{align*} \\min_{w,b,\\hat y,\\xi} \u0026\\quad \\dfrac{1}{2}||w||^2+C_l\\sum^{l}_{i=1}\\xi_i+C_u\\sum_{i=1}^{u}\\xi_{l+i} \u0026 \\\\ \\text{s.t.} \u0026\\quad y_i(w^Tx_i+b)+\\xi_i\\geq 1, \u0026 \\quad i=1,2,\\cdots,l\\\\ \u0026\\quad \\hat y_{l+i}(w^Tx_{l+i}+b)+\\xi_{l+i}\\geq 1, \u0026 i=1,2,\\cdots,u\\\\ \u0026\\quad \\xi_i\\geq 0 \u0026 i=1,2,\\cdots,u+l \\end{align*} \\]\n其中\\(C_l,C_u\\)是用户自定义参数，用来决定有标记样本和未标记样本的重要程度。\nTSVM是一个时间和计算复杂度都十分高的算法。因此，半监督SVM需要重点研究如何设计出高效的优化策略。\n基于图的半监督学习\n对于一个样本集，我们可以把其样本之间的关系用一个图来表示，其中每个样本对应图中的一个节点。如果两个样本直接的相关性很高，则对应的两个结点之间会存在一条边并且边的权重和样本之间的相似度成正比。\n代表算法：一种多分类标记传播算法。\n首先用\\(D_l\\cup D_u\\)建立一个图\\(G=(V,E)\\)，其中\\(V=\\{x_1,x_2,\\cdots,x_{l+u}\\}\\)，图是满图，边权用高斯函数如下定义\n\\[w_{ij} = \\begin{cases} \\exp\\bigg(\\dfrac{-||x_i-x_j||_2^2}{2\\sigma^2}\\bigg), \u0026 i\\neq j\\\\ 0 ,\u0026 i=j \\end{cases} \\]\n定义对角矩阵\\(D=diag(d_1,d_2,\\cdots,d_{l+u})\\)，其中\\(d_i=\\sum_{j=1}^{l+u}w_{ij}\\)。\n设标签\\(y\\in \\Psi\\)，定义一个大小为\\((l+u)\\times |\\Psi|\\)的非负标记矩阵\\(F=(F_1^T,F_2^T,\\cdots,F_{l+u}^T)^T\\)，其中\\(F_i=(F_{i1},F_{i2},\\cdots,F_{i|\\Psi|})\\)为样本\\(x_i\\)的标记向量，其分类准则为\\(y_i=\\arg\\max_{j}F_{ij}\\)。矩阵初始化为\n\\[F^{(0)}_{ij}=\\begin{cases} 1, \u0026 (1\\leq i\\leq l)\\wedge(y_i=j)\\\\ 0, \u0026 \\text{otherwise} \\end{cases} \\]\n根据矩阵边矩阵\\(W\\)建立一个标记传播矩阵\\(S = D^{-1/2}WD^{-1/2}\\)。其中\\(D^{-1/2}=diag(\\dfrac{1}{\\sqrt{d_1}}, \\dfrac{1}{\\sqrt{d_2}}, \\cdots, \\dfrac{1}{\\sqrt{d_{l+u}}})\\)，于是我们得到迭代公式\n\\[F^{(t+1)} = \\alpha SF^{(t)}+(1-\\alpha)Y \\]\n其中\\(Y=F^{(0)}\\)，\\(\\alpha\\in(0,1)\\)是由用户控制的参数。上式迭代收敛到\n\\[F^* = \\lim_{t\\to\\infty}F^{(t)}=(1-\\alpha)(I-\\alpha S)^{-1}Y \\]\n100.jpg\r算法复杂度上存在较大的不足，很难处理大规模数据。\n在构建图的过程中，只考虑到训练样本集，很难判断新的样本在图中的位置。在出现新的样本时，需要将新样本加入到原样本集对图进行重建且进行标记传播。\n基于分歧的方法\n使用两个学习器来“协同训练”，在训练过程中，两个分类器挑选置信度较高的已标记和未标记样本交给对方学习，直到达到某个终止条件。\n一个样本往往拥有多个属性，每个属性在这里被称为一个“视图”。给出样本空间\\(X=X_1\\times X_2\\)，其中\\(X_1,X_2\\)对应一个样本的两种不同视图。在此基础上，每个样本\\(x\\)可以用一对\\((x_1,x_2)\\)来表示。\n使用这个方法对于数据有前提假设：每个视图条件独立；每个视图本身就足以进行正确的分类，即\\(f(x)=f(x_1)=f(x_2)=y\\)。满足该假设的不同的视图具有相容性，即它们包含的关于输出类别的信息是一致的。\n算法框架如下\n假设\\(x\\)拥有两个条件独立且充分的两个视图\\(x_1\\)和\\(x_2\\) 利用每个视图基于有标记样本分别训练得到一个分类器，然后让每个分类器各自去选择自己“最信任的”的未标记样本赋值一个伪标记，并且把这个伪标记的样本作为一个有标记样本提供给另外一个分类器进行训练更新。 这个“互相学习”的过程不断的进行迭代，直到达到迭代的终止条件为止。 101.jpg\r实际问题中，满足这两个假设的样本集是很少的。2000年有一种新的协同训练方法可以不要求两个假设。2007年的Tri-training使用三个分类器协同训练，对样本集没有苛刻的要求。特点为：\n对于每一个分类器，将剩余的两个分类器作为其辅助分类器来对未标记样本进行分类，标记相同的未标记样本就会被作为置信度较高的样本。 主分类器会随机从中选取一些伪标记样本添加到标记样本集中进行训练。 每一次被挑选出来的未标记样本在参与完本轮的迭代后，仍然作为未标记样本保留在未标记数据集中。 框架如下：\n首先对有标记样本集进行可重复抽样(bootstrapping)来获得三个有标记训练集进行初始分类器的训练。 在迭代过程中，每个分类器轮流作为主分类器，其余两个作为辅助分类器来为主分类器提供新的无标记数据用来训练。 在进行样本预测时，使用三个分类器的结果进行投票得到最终的分类标记。 半监督聚类 聚类本来是无监督的，但是利用少量的标记样本可以对聚类算法进行辅助。\n标记可以分为：数据对是否属于同一类别的约束关系、类别标记。\n基于距离的半监督聚类算法\n传统聚类大多采用基于距离的度量准则来描述相似性，但是选择何种距离没有统一答案。半监督时，根据约束或者类别信息来构造某种距离度量，然后在该距离度量的基础上进行聚类。\n基于约束的半监督聚类算法\n利用监督信息对聚类的搜索过程进行约束。例如Constrained-K-means算法和Seeded-K-means算法。\n在K-means算法的基础上，引入了由少量标记样本组成的Seed集合，含有全部的\\(K\\)个聚类簇，每种类别最少有一个样本。 对Seed进行划分得到K个聚类并且基于此来进行初始化，即初始的聚类中心。 利用EM算法来进行优化步骤。 在Seeded-K-means算法中，Seed集的标记是可以发生改变的，而在Constrained-K-means算法中，Seed集的样本标记是固定的。\n在不含噪声的情况下，Constrained-K-means算法的性能较好，而在Seed集中含有噪声的情况下，Seeded-K-means的性能明显更优。\n集成学习/组合分类器 16.jpg\r如上，基本思想是先产生一组个体学习器，再用某种策略将它们结合起来，以获得一个更好的性能\n个体学习器通常由一个现有的学习算法从训练数据产生，\n根据个体学习器的生成方式，目前的集成学习方法大致可分为两大类：\n个体学习器间存在强依赖关系、必须串行生成的序列化方法。训练集不独立 以及个体学习器间不存在强依赖关系、可同时生成的并行化方法。训练集独立 前者的代表是Boosting，后者的代表是Bagging和随机森林（见前）。\nBagging要求每个预测器的算法相同（也称为基学习器的基学习算法），但是在不同的随机训练子集上训练。Bagging要去取样时样本放回，如果取样时样本不放回的叫pasting。\n在大多数数据集中，boosting的准确性比bagging高。在有些数据集中，boosting会引起退化（过拟合）。\n一旦这些基学习器训练完成，集成就可以通过简单地聚合所有预测器的预测来对新实例做出预测。对于分类，聚合函数通常是统计法（即投票，简单多数），而回归问题则通常用平均法。\nBagging 如前所述，要求每个预测器的学习算法相同。每次学习中，某个个体学习器的训练集都是bootstrapping得来的。分类问题采用投票，回归问题采用平均。\nBagging比较适合“不稳定”的分类算法，例如决策树、神经网络。不稳定指的是数据集的小的变动能够使得分类结果的显著的变动。\n只有弱学习算法不稳定时，采用Bagging来集成，才能提升预测准确率。其对稳定的学习算法效果不明显，甚至有副作用。\nBoosting Boosting是一族可将弱学习器提升为强学习器的算法。这族算法的工作机制类似：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注（加大权重），然后基于调整后的样本分布来训练下一个基学习器；如此重复进行，直至基学习器数目达到事先指定的值T，最终将这T个基学习器进行加权结合。\n80.jpg\r如上图，训练过程是阶梯式的，基学习器按照顺序学习，最后加权综合。\n每次迭代过程分为两步：在一定的权重条件下训练数据，得出分类器；根据分类器的错误率调整权重\n有两个关键问题：如何更改每个训练样本的权重？如何把弱学习器组合成强学习器？\nBoost用途广泛，例如计算机视觉的对象分类任务、二分类加速等等。\nBoosting易受到噪音的影响； AdaBoost可以用来鉴别异常；经过多轮后，具有最高权重的样本即为异常。 应用Boosting，不需寻找很难获得的预测精度很高的强学习算法，只需找出精度稍好于随机预测的弱学习算法即可。 但是同时也有可能使集成过分偏向于某几个特别困难的示例。因此，该方法不太稳定，有时能起到很好的作用，有时却没有效果。 AdaBoost\nAdaBoost可能是Boost中最著名的。对于两个关键问题，它的回答是\n增加前一轮中被错误分类的样本的权重，减少正确分类的样本的权重 使用一个加权的投票方法来组合 有很多种推导AdaBoost的方法，比较容易理解的是加性模型，即基学习器的线性组合\n\\[H(x) = \\sum^T_{t=1}\\alpha_th_t(x) \\]\n来最小化指数损失函数\n\\[l_{exp}(H|D) = E_{x\\sim D}[e^{-f(x)H(x)}] \\]\n其中\\(f(x)\\)是真实函数。数据集的\\(y\\in\\{-1,1\\}\\)（预测器的输出也应该是\\(h\\in \\{-1,1\\}\\)）\n训练算法如下\n81.jpg\rXGBoost\n一种对多个回归树进行集成的方法，构造出的多个回归树通过优化使得树群的预测值尽可能接近真实值且具有泛化能力\n非监督集成学习 非监督集成(Unsupervised ensemble)也称聚类集成，被认为在许多方面都能超越单个聚类算法，如：鲁棒性，稳定性和一致性估计以及并行性和可量测性\n特征选择 基本概念 对分类器设计来说，使用什么样的特征描述事物，也就是说使用什么样的特征空间是个很重要的问题。\n对特征空间的改造、优化，主要的目的是降维，即把维数高的特征空间改成维数低的特征空间，降维主要有两种途径。\n筛选掉次要特征。关键在于如何确定特征的重要性，以及如何筛选 通过线性变换来降维。 88.jpg\r这些特征中对于训练有帮助的叫做相关特征（relevant features），无帮助的叫做无关特征。\n三大类特征\n三大类特征：物理、结构和数字的\n物理和结构特征：易于为人的直觉感知，但有时难于定量描述，因而不易用于机器判别。 数字特征：易于用机器定量描述和判别，如基于统计的特征。 特征空间的优化\n对初始的特征空间进行优化是为了降维。即初始的特征空间维数较高。能否改成一个维数较低的空间，称为优化。有两种方法\n特征选择。从原有的的\\(D\\)维特征空间，删去一些特征描述量，从而得到精简后的特征空间。新空间的维数\\(d \u003c D\\)，并且，其是原空间的一个子集，每个分量都必然能在原空间中找到对应的分量。 特征提取。找到一个映射关系\\(A:Y\\to X\\)，使得新样本特征描述维数比原维数降低。其中每个分量\\(x_i\\)是原特征向量各分量的函数，即\\(x_i=W^T y_i\\) 一般人常想，只要逐个分析每个特征，判断它对分类的价值，然后根据其价值删去或保留，但是这种方法并不能保证特征空间的最优组合优化，因此本节仅讨论一些原理上更好的方法。\n特征选择要从原始特征中挑选出一些最有代表性、分类性能最好的特征进行分类。\n要解决两个问题：\n选择的标准，如可分离性判据 快速特征子集搜索算法 另外，从\\(D\\)中选\\(d\\)个，或者从\\(D\\)中选出不定大小的子集，是典型的组合优化问题。\n特征选择的方法：\n是否直接考虑分类器性能？ Filter方法。根据独立于分类器的指标\\(J\\)来评价所选择的特征子集\\(S\\)，在所有可能的特征子集中搜索出使得\\(J\\)最大的特征子集作为最优特征子集。不考虑所使用的学习算法。 Wrapper方法。将特征选择和分类器结合在一起，在分类过程中表现优异的的特征子集会被选中。 选择特征的顺序 自下而上：特征数从零逐步增加到d。 自上而下：特征数从D开始逐步减少到d。 类别可分离性判据 用以定量检验分类性能的准则称为类别可分性准则\\(J_{ij}\\)，需要满足以下几点：\n与错误概率有单调关系。这样，准则取最大值时的，错误概率也更小 特征独立时具有可加性 度量特性 \\(J_{ij}\u003e0\\)，\\(i\\neq j\\)时 \\(J_{ij}=0\\)，\\(i=j\\)时 \\(J_{ij}=J_{ji}\\) 这里\\(J_{ij}\\)是第\\(i\\)类和第\\(j\\)类的可分性准则函数，\\(J_{ij}\\)越大，两类的分离程度就越大。\n单调性，即加入新的特征时，准则函数不减小。 基于距离的可分离性判据 基于距离的可分性判据的实质是Fisher准则的延伸。各类样本之间的距离越大，则类别可分性越大。因此，可以用各类样本之间的距离的平均值作为可分性准则\n\\[J_d(x) = \\dfrac{1}{2}\\sum^C_{i=1}P_i\\sum^{C}_{j=1}P_j\\dfrac{1}{n_in_j}\\sum^{n_i}_{k=1}\\sum^{n_j}_{l=1}\\delta(x^{(i)}_k, x^{(j)}_l) \\]\n其中\\(c\\)是类别数，\\(P_i,P_j\\)是相应类别的先验概率，\\(\\delta(x^{(i)}_k, x^{(j)}_l)\\)是两个向量之间的距离，通常用欧氏距离。\n如果记均值向量和总平均向量为\n\\[m_i=\\dfrac{1}{n_i}\\sum^{n_i}_{k=1} x^{(i)}_k,\\quad m = \\sum^C_{i=1}P_im_i \\]\n那么等价为\n\\[J_d(x) = \\sum^C_{i=1}P_i\\bigg[\\dfrac{1}{n_i}\\sum^{n_i}_{k=1} \\delta(x^{(i)}_k, m_i)+\\delta(m_i,m)\\bigg] \\]\n其中方括号中的前半为样本到质心的平方距离，后半为某类均值向量到总体样本向量之间的平方距离。如果乘进去，则有类间离散度\\(\\tilde{S}_b\\)和类内离散度\\(\\tilde{S}_w\\)为\n\\[\\tilde{S}_w = \\sum^C_{i=1}P_i\\dfrac{1}{n_i}\\sum^{n_i}_{k=1}(x^{(i)}_k-m_i)(x^{(i)}_k-m_i)^T \\]\n\\[\\tilde{S}_b = \\sum^C_{i=1}P_i(m_i-m)(m_i-m)^T \\]\n此时\n\\[J_d(x) = tr(\\tilde{S}_w+\\tilde{S}_b) \\]\n其他表达形式如下。\n108.jpg\r基于距离的准则概念直观，计算方便。但没有直接考虑样本的分布情况，与错误率没有直接关系；而且两类样本的分布有重叠时，这些判据不能反映重叠的情况。\n基于概率的可分性判据 基于距离的可分性判据原理直观，计算简便。但是这种原理没有考虑概率分布，因此当不同类样本中有部分在特征空间中交迭分布时，简单地按距离划分，无法表明与错误概率之间的联系。\n109.jpg\r显然不同类别在特征空间\\(x\\)中的分布要尽可能不一样，则分类就比较容易，通俗的讲，则不同类别在特征空间的不同区域聚集，则分类就容易，它们重迭的程度越低，越有别于分类。\n分布密度的交叠程度可用\\(p(X|w_1)\\)及\\(p(X|w_2)\\)这两个分布密度函数之间的距离\\(J_p\\)来度量，距离\\(J_p\\)有以下几个共同点：\n\\(J_p\\)是非负的 当两类完全不交叠时，\\(J_p\\)达到其最大值 当两类分布密度相同时，\\(J_p=0\\) 常用的有巴氏距离、切诺夫界限、散度等\nBhattacharyya距离\n\\[J_B = -\\ln\\int[p(x|w_1)p(x|w_2)]^{1/2}dx \\]\n不交叠时为无穷大，相同时为\\(0\\)。巴氏距离与错误率的上界有直接关系，因此\\(J_B\\)不仅用来对特征空间进行降维优化，而且也用来对分类器的错误率作出估计。\nChernoff界限\n\\[J_C = -\\ln\\int p^s(x|w_1)p^{1-s}(x|w_2)dx \\]\n其中\\(s\\in[0,1]\\)，当\\(s=0.5\\)时其等价于巴氏距离、\n散度\n散度是区分\\(i,j\\)两类总的平均信息\n\\[l_{ij}(x) = \\dfrac{p(x|w_i)}{p(x|w_j)} \\]\n\\[I_{ij}(x) = \\int_x p(x|w_i)\\ln\\dfrac{p(x|w_i)}{p(x|w_j)}dx \\]\n\\[I_{ji}(x) = \\int_x p(x|w_j)\\ln\\dfrac{p(x|w_j)}{p(x|w_i)}dx \\]\n\\[J_D(x) = I_{ij}+I_{ji} \\]\n如果两类样本服从正态分布，且协方差矩阵相等，那么散度就是马氏距离。\n基于熵的可分性依据 特征对分类的有效性也可以从后验概率角度来考虑。后验概率越集中，错误概率就越小，反之后验概率分布越平缓，即接近均匀分布，则分类错误概率就越大。\n熵函数记作\n\\[H = J_c[P(w_1|x),\\cdots,P(w_c|x)] \\]\n其中，香农熵为\n\\[J_c^1 = -\\sum^c_{i=1}P(w_i|x)\\log_2 P(w_i|x) \\]\n平方熵为\n\\[J_c^2 = 2\\bigg[1-\\sum^c_{i=1}P^2(w_i|x)\\bigg] \\]\n熵函数期望表征类别的分离程度：\n\\[J(\\cdot)=E\\{J_c[P(w_1|x),\\cdots,P(w_c|x)]\\} \\]\n子集评估（机器学习课程） 信息增益 和决策树中的信息增益一样。不再介绍。\n特征子集的搜索策略 112.png\r穷举搜索（exhaustive search） 即完全搜索所有特征子集。\n分支定界法 比穷举好一点，只有所有子集的一部分需要被枚举。说人话就是剪枝。\n单独最优特征组合 机器学习中叫（best individual feature）\n计算各特征单独使用时的可分性判据\\(J\\)并加以排序，取前\\(d\\)个作为选择结果。\n问题是组合起来不一定是最优结果，只有当可分性判据对各特征具有（广义）可加性时，才可以选出一组最优特征。例如：各类具有正态分布；各特征统计独立；可分性判据基于Mahalanobis距离\n顺序前进法（SFS） （机器学习课程中也叫sequencial subset search，序列子集搜索）\n自下而上\n每次从未入选的特征中选择一个特征，使得它与已入选的特征组合在一起时所得的可分性或分类识别率为最大，直到加入的特征数达到\\(d\\)\n优点是考虑了所选特征与已入选特征之间的相关性。比单独最优特征组合效果好。\n缺点是，一旦某特征入选，后面无论加入什么，也无法去除它。\n广义顺序前进法（GSFS） 每次从未入选的选出\\(r\\)个，使得\\(r\\)个特征加入后\\(J\\)最大\nSFS每次只加一个，未考虑新加特征之间的统计相关性。GSFS更好，但计算量更大，且还是无法拿出之前的。\n顺序后退法（SBS） 自上而下\n从全体特征开始，每次剔除一个特征，使得保留的特征集合具有最大的可分性或分类识别率。依次迭代，直到可分性或识别率开始下降。\n特点是，计算过程中可以估计每次去掉一个特征所造成的可分性的降低。计算量比前进法大。同样的，一旦被删除就无法再加入。\n也有广义顺序后退法。\n增l减r法 （机器学习课程中也叫bidirectional search，双向搜索）\n为了避免一加入就无法剔除，一剔除就无法加入的问题。引入局部回溯手段。\n在第\\(k\\)步先用SFS一个个加入特征到\\(k+l\\)个，再用SBS一个个剔除\\(r\\)个特征。反复进行直到满足\\(d\\)个特征。此时\\(l\u003er\\)，自下而上，起始时有\\(0\\)个特征。\n如果\\(l\u003c r\\)，则要先剔除，再增加。自上而下，起始时有\\(D\\)个特征。\n也有其推广。即把上面每一步的SFS和SBS换成GSFS和GSBS。\n顺序前进浮动和顺序后退浮动 Sequencial forward floating search（SFFS），Sequencial backward floating search（SBFS），\n是增l减r法的一个推广，其中\\(l\\)和\\(r\\)的值在算法过程中是自动动态更新的。\n遗传算法 从生物进化论得到启迪。遗传，变异，自然选择。基于该思想发展了遗传优化算法。\n基因链码：待解问题的解的编码，每个基因链码也称为一个个体。对于特征选择，可用一个\\(D\\)位的0/1构成的串表示一种特征组合。 群体：若干个个体的集合，即问题的一些解的集合。 交叉：由当前两个个体的链码交叉产生新一代的两个个体。 变异：由一个链码随机选取某基因使其翻转。 适应度：对于每个解，以给定的优化准则来判断其性能的优劣，作为其适应度，即函数\\(f_i\\)的值，个体\\(x_i\\)越好，\\(f_i\\)越大。新一代群体对环境的平均适应度比父代高。 基本步骤如下：\n令进化代数\\(t=0\\) 给出初始化群体\\(P(t)\\)，令\\(x_g\\)为其中任一个体 对\\(P(t)\\)中每个个体估值，并将群体中的最优解\\(x'\\)与\\(x_g\\)比价， 如果比\\(x_g\\)更优，则\\(x_g=x'\\) 如果终止条件满足，则算法结束，\\(x_g\\)作为输出。否则继续 从\\(P(t)\\)中选择个体并进行交叉和变异操作，得到新一代群体\\(P(t+1)\\)，令\\(t=t+1\\)，转第3步。 其中交叉操作仅对非最优个体进行，而且交叉后的个体应该适应度比父代大，如果不满足就要反复交叉直到满足或者无法交叉。\n变异操作是对交叉后还不满足条件的进行的。如果某个类中有一半以上交叉的后代个体不大于父代，则全变异。\n轮盘赌选择法\n依据个体的适应度值计算每个个体在子代中出现的概率，并按照此概率随机选择个体构成子代种群。\n轮盘赌选择策略的出发点是适应度值越好的个体被选择的概率越大。因此，在求解最大化问题的时候，我们可以直接采用适应度值来进行选择。\n将种群中个体的适应度值叠加，得到总适应度值 每个个体的适应度值除以总适应度值得到个体被选择的概率 计算个体的累积概率以构造一个轮盘 轮盘选择：产生一个\\([0,1]\\)区间内的随机数，若该随机数小于或等于个体\\(a\\)的累积概率且大于个体\\(b\\)的累积概率，选择个体\\(a\\)进入子代种群。重复步骤(4)多次次，得到的个体构成新一代种群。 特征选择算法（机器学习课程） 通过结合子集搜索和子集评估的算法，我们可以构建特征选择的算法。\n这些算法显式或隐式地组合了一个或数个子集搜索和子集评估，分为Filter方法和Wrapper方法\nFilter 这个方法中，特征选择是在训练学习器之前。也就是说，特征选择与训练过程无关。\n其使用Relief来设计了一种相关性的统计数据（relevant statistics），来测量特征的重要性。这个统计数据是一个向量，每个元素对应一个特征。\n每个特征子集的重要性，都由这个统计数据的元素和所测量。所以我们可以使用一个阈值\\(\\tau\\)去选择统计数据高于\\(\\tau\\)的特征。或者给定\\(k\\)个特征，选择\\(k\\)个统计数据最大的特征。\n对于任意一个特征\\(x_i\\)，找到与它同类型的最近邻居\\(x_{i,nh}\\)，叫他near-hit。然后找到与它不同类型的最近邻居\\(x_{i,nm}\\)，叫他near-miss\n那么这个相关统计数据，对于特征\\(j\\)来说，就是\n\\[\\delta^j = \\sum_i-diff(x^j_i, x^j_{i,nh})^2 + diff(x^j_{i}, x^j_{i,nm})^2 \\]\n如果这个样本，和near-hit的距离比和near-miss的距离短，那么他是有用的特征。否则，它甚至有副作用。\nWrapper 与filter不同，wrapper使用学习器的表现来度量子集。如果从提升学习器的表现的角度来看，wrapper是更好的方法。\n但是，因为要反复对学习器进行训练，所以wrapper方法的时间开销要大得多。\nLas Vegas Wrapper\n123.jpg\r一句话：反复选择特征子集，使得交叉验证误差最小。交叉验证误差一样时，选择维数更低的子集。\n稀疏表示（sparse representation，机器学习课程） 嵌入L1正则化项 在filters和wrappers中，特征选择都是在训练过程之外的。\n而嵌入特征选择，将特征选择和模型训练整合成了一个，并且在同一个数值最优化过程中进行这两个环节。也就是训练的过程中，自动地进行特征选择。\n线性回归中正则化长这样\n\\[J(w) = \\sum(y^{(i)}-y(x^{(i)},w))^2+\\lambda ||w||^2_2 \\]\n我们把\\(\\ell_2\\)换成\\(\\ell_1\\)（即欧拉距离换成曼哈顿距离），得到LASSO\n\\[J(w) = \\sum(y^{(i)}-y(x^{(i)},w))^2+\\lambda ||w||_1 \\]\n特点是倾向于得到一个更稀疏（sparse）的解，例如\\(w\\)中的非零项将减少。通常也是由梯度下降来优化的。\n字典学习 把数据集\\(D\\)当作矩阵，每一行是一个样本，每一列则是一种特征。\n特征选择中，特征被认为是稀疏的。例如，很多列对于学习任务是没有关联的。\n我们考虑另一种稀疏：\\(D\\)的矩阵中有很多的零，但是这些零并不有规律地分布在一列列或者一行行中。\n我们需要找到一个恰当的字典，使这些样本被变换到某些稀疏表示上，从而使得学习过程简化。\n假设有\\(m\\)个样本，那么最简单的字典学习是\n\\[\\min_{B,\\alpha_i}\\sum^m_{i=1}||x_i-B\\alpha_i||_2^2 + \\lambda\\sum^m_{i=1}||\\alpha_i||_1 \\]\n其中\\(B\\in R_{d\\times k}\\)是字典矩阵，\\(\\alpha_i\\in R_k\\)是对应的\\(x_i\\in R_d\\)的稀疏表示。上式的第一项使得这个构造更好，而第二项约束\\(\\alpha_i\\)，使得模型足够稀疏。\n降维和度量学习（机器学习课程） 在实践上，有些时候，添加新的特征可能不会改善表现，甚至更差。这也称为维度的诅咒（curse of dimensionality）。\n增加特征数量，可能导致：\n分类正确率下降 分类器的复杂度上升 分类正确率的下降可能是因为：\n对于模型选择的错误假设 过拟合 潜在的解决方法：\n减少维度 简化对于误差的估计 维度可以通过以下办法降低：\n重新设计（要选取什么）特征 选取目前所有特征的一个子集 把一些特征组合起来 误差估计可以通过以下方法简化：\n假设所有类的协方差相同 用正则化 使用先验知识和贝叶斯估计 使用启发式方法，例如条件独立 常见的分类器都会遭受维度诅咒的影响，在实践上，一般使用的每一类的样本数量要是特征数的十倍以上。\n降维 降维即是之前提到的，把一些特征组合起来的方法。\n降维需要关注：\n线性和非线性变换的选择 是否使用类标记信息（这也取决于样本是否有标记） 训练目标 最小化分类误差（判别训练，discriminative training） 最小化重建误差（reconstruction error）（PCA） 最大化类型分离度（LDA） 保留interesting方向（投影追踪法） 使特征尽可能独立（ICA） 嵌入到低维流形（Isomap，LLE） 线性组合 线性组合计算和分析都较为简单。\n线性组合方法就是把高维特征投影到低维空间上。\n优点：\n简化了估计和分类的复杂性 方便可视化检查效果，尤其是投影到二维和三维的时候 形式化地来说，有原始特征\\(x\\in R_d\\)，目标就是找到线性变换\\(A\\)使得\\(y=A^Tx\\in R_{d'}\\)，其中\\(d' \u003c d\\)\n这有两种方法：主成分分析（PCA）和线性判别分析（LDA）。两种方法的目标都是找到最优的线性变换。PCA是找到一个投影，使得其能在最小二乘意义上最好地表达数据。LDA是找到一个投影，使得其能够在最小二乘意义上最好地分离数据。\nPCA\n见前无监督学习部分。\n自动编码器神经网络\n啥也没讲\n线性判别分析\n见fisher线性判别分析\n流形学习 等度量映射（Isometric Mapping，Isomap）\n其认为，低维流形在嵌入高维空间之后，直接在高维空间中计算直线距离具有误导性，因为高维空间中的直线距离对于低维流形上是不可达的。就像圆柱体上的蚂蚁，两点间的距离是直线距离，而蚂蚁走的距离叫做“测地线”（geodesic）距离。\n如何计算测地线距离？流形在局部上与欧式空间同胚，所以可以找近邻点建图。图中的近邻点之间有边，非近邻点之间没有边。边权为高维空间直线距离。于是两点的测地线距离就等于近邻连接图上两点的最短路径问题，可以用Dijkstra等算法解决。\n得到两点间的距离，就可以用MDS方法来获得样本在低维空间中的坐标\n局部线性嵌入（LLE）\n与Isomap试图保持近邻样本之间的距离不同，局部线性嵌入试图保持邻域内样本之间的线性关系。\n假设样本点可以通过它邻域的样本组合出来，LLE之后，希望这个线性组合的关系保持。\n优点：\n全局最小 只有一个自由变量（即近邻点的个数K） 线性代数计算中只有稀疏矩阵 缺点：\n对噪声敏感 没有理论担保 随机邻域嵌入（SNE）\n其给近邻点一个概率，每个点不再是“硬”地成为近邻点，而是以一定概率属于近邻点。\n度量学习 寻找合适的空间，实际上就是在寻找一个合适的距离度量。\n对于\\(d\\)维样本\\(x_i,x_j\\)，它们之间的平方欧氏距离为\n\\[dist^2_{ed}(x_i,x_j) = ||x_i-x_j||^2_2 = dist^2_{ij, 1} + dist^2_{ij,2}+\\cdots+dist^2_{ij,d} \\]\n如果引入权重，则有\n\\[dist^2_{wed}(x_i,x_j) = w_1dist^2_{ij, 1} + w_2dist^2_{ij,2}+\\cdots+w_ddist^2_{ij,d} = (x_i-x_j)^TW(x_i-x_j) \\]\n其中\\(w_i\\geq 0\\)而\\(W\\)是一个对角矩阵。\n如果再往前走一步，\\(W\\)不只是对角矩阵，把各个属性之间关联起来，\\(W\\)成为一个半正定对称矩阵\\(M\\)，则得到马氏距离\n\\[dist^2_{mah}(x_i,x_j) = ||x_i-x_j||^2_M = (x_i-x_j)^TM(x_i-x_j) \\]\n\\(M\\)也称为度量矩阵，度量学习就是对\\(M\\)进行学习。\\(M\\)是半正定对称矩阵，那么一定有正交基\\(P\\)使得\\(M = PP^T\\)\n假设我们用\\(M\\)提高近邻分类器的性能。我们把近邻分类器的投票法变为概率投票法，则对于任意样本\\(x_j\\)，其对\\(x_i\\)的分类结果影响的概率为\n\\[p_{ij} = \\dfrac{\\exp(-||x_i-x_j||^2_M)}{\\sum_l\\exp(-||x_i-x_l||^2_M)} \\]\n如果以留一法正确率的最大化为目标，则可计算\\(x_i\\)的留一法正确率，即它被自身以外的所有样本分类正确的概率为\n\\[p_i = \\sum_{j\\in \\Omega_i}p_{ij} \\]\n其中\\(\\Omega_i\\)是与\\(i\\)同类型的下标集。于是整个样本集上留一法的正确率为\n\\[\\sum^m_{i=1}p_{i} = \\sum^m_{i=1}\\sum_{j\\in \\Omega_i}p_{ij} \\]\n将\\(p_{ij}\\)代入，考虑到\\(M=PP^T\\)，那么优化目标为\n\\[\\min_P\\quad 1-\\sum^m_{i=1}\\sum_{j\\in \\Omega_i}\\dfrac{\\exp(-||P^Tx_i-P^Tx_j||^2_2)}{\\sum_l\\exp(-||P^Tx_i-P^Tx_l||^2_2)} \\]\n模型评估与选择 经验误差（empirical errors） 错误率\n即错分样本在总样本中的比例\n正确率\n即\\(1-错误率\\)\n经验误差\n通常来说，输出和标签之间的不同就是误差。\n学习器在训练集上训练时的误差叫做训练误差或者经验误差\n而学习器在新样本（实践中的样本），上的误差叫做泛化误差（generalization error）\n显然，我们的目的是减小泛化误差，但是我们不能使用未来的新样本，只能尝试去最小化经验误差。\n过拟合和欠拟合\n有许多方法可以处理过拟合，但是过拟合不可完全避免。\n机器学习问题通常是NP-hard的 高效的学习算法应该在多项式时间之内 如果我们能完全避免过拟合，那么\\(P=NP\\) 如果\\(P\\neq NP\\)，那么过拟合是不可避免的 评估方法 对于模型的集合\\(\\mathcal{M}=\\{M_1, M_2,\\cdots, M_R\\}\\)，选择一个模型，具有最小的泛化误差。\n这个集合里面可以有\n同一模型，但具有不同超参数 不同的模型 我们可以通过实验来估计泛化误差。为此，我们要建立一个测试集，让算法在测试集上计算测试误差，从而近似得到泛化误差。\n通常，测试集是从真实样本的分布中取样得到的。\n注意，测试集和训练集不能有重叠元素。\nhold-out 把数据集直接分成两个不相交的子集，一个作为训练集，一个作为测试集。\n注意：\n分完之后，两个集合中，各类型的比例应该保持和原数据集一致。 保持比例可以通过分层抽样来完成 但是即使如此也有多种分法。不同的训练集和测试集大小的比例会导致不同的评估结果 当使用hold-out时，重复随机地进行划分是需要的，最终求平均结果 一般我们会划分\\(2/3\\sim 4/5\\)给训练集，剩下的给测试集 交叉验证（k-fold） 把\\(D\\)划分成\\(k\\)个不相交子集，每个子集的大小相等，每次训练时，\\(k-1\\)个子集作为训练集，剩下的一个作为测试集。总共训练\\(k\\)次，每次的测试集顺着来换。\n交叉验证（leave-one-out，LOO，留一法） 简单来说，就是让k-fold中，每个子集的大小为\\(1\\)，或者说\\(k\\)等于数据集大小。\n好在，分子集的时候没有引入随机，因为只有一种分法。因为训练集就只差一个样本，所以大多数情况下，模型在测试集上的误差非常接近在训练集上的误差。\n缺点是，时间复杂度巨大。\nbootstrapping hold-out和k-fold中的训练集大小比起整个数据集来说较小，而LOO虽然大小差不多，但是复杂度太高。\nbootstrapping通过可放回地从数据集中抽样\\(m\\)次，得到大小为\\(m\\)的训练集。可以算出，大概有\\(36.8\\%\\)的数据从未出现在训练集中，那么就可以把这些数据用作测试集。这个结果被叫做包外评估（out-of-bag estimate）\n如果不放回，变量的后续选择始终取决于先前的选择，这会使得预判准则不随机。\n参数调整（parameter tuning） 我觉得他想说的是超参数。很多算法中都有手动设置的超参数，不同的超参数可以导致不同的效果。\n用于模型评估和选择的测试集叫做验证集（validation set）。而训练集不必多说，测试集是用来估算学习器的泛化误差的。\n网格搜索 其实就是爆搜，和手调超参的区别是，它可以自动地并行地执行。遍历给出的超参的范围（离散值），找到最好的超参。\n一般只适用于低维，如一两个超参，多了复杂度太高。\n随机搜索 可能类似于模拟退火这样的算法。\n好处是，比起网格搜索更高效，因为不是所有超参数都是同等重要的。\n性能度量（performance measure） 对学习器的泛化性能进行评估，不仅需要有效可行的实验估计方法，还需要有衡量模型泛化能力的评价标准，这就是性能度量。\n性能度量和任务需求有关，使用不同的性能度量时，可能会得出不同的模型结果。也就是说模型的“好坏”是相对的。\n在回归任务中，最常用到的性能度量是“均方误差”（MSE）\n\\[E(f;D) = \\dfrac{1}{m}\\sum^m_{i=1}(f(x_i)-y_i)^2 \\]\n对于概率分布情况，\n\\[E(f;D) = \\int _{x\\sim D}(f(x)-y)^2p(x)dx \\]\n分类任务中常用错误率和精度。\n\\[E(f;D) = \\dfrac{1}{m}\\sum^m_{i=1}[f(x_i)\\neq y_i] \\]\n\\[acc(f;D) = \\dfrac{1}{m}\\sum^m_{i=1}[f(x_i)= y_i] = 1-E(f;D) \\]\n\\[E(f;D) = \\int_{x\\sim D}[f(x_i)\\neq y_i]p(x)dx \\]\n\\[acc(f;D) = \\int_{x\\sim D}[f(x_i)= y_i]p(x)dx = 1-E(f;D) \\]\n分类任务中这两个数据并不能完全满足需求，我们还需要精度（precision）和召回率（recall）来度量。\n对于二分类问题，\n124.jpg\r精度\\(P\\)和召回率\\(R\\)为\n\\[P = \\dfrac{TP}{TP+FP} \\]\n\\[R = \\dfrac{TP}{TP+FN} \\]\n这两个数据是矛盾的数据，召回率高时往往精度低，精度高时往往召回率低。\n在很多情形下，我们可根据学习器的预测结果对样例进行排序，排在前面的是学习器认为“最可能”是正例的样本，排在最后的则是学习器认为“最不可能”是正例的样本。按此顺序逐个把样本作为正例进行预测，则每次可以计算出当前的精度、召回率。以精度为纵轴、召回率为横轴作图，就得到了精度-召回率曲线，简称“P-R曲线\u0026quot;\n125.jpg\r这其中的平衡点简称BEP，此时精度等于召回率。平衡点越往右上角，模型越好，但是最好还是要整根曲线包住另一根，才能说更好。但是这个还是过于简化，通常用\\(F1\\)度量\n\\[F1 = \\dfrac{2PR}{P+R} = \\dfrac{2\\times TP}{样例总数+TP-TN} \\]\n实际上\\(F1\\)是\\(P,R\\)的调和平均。更近一步\n\\[F_\\beta = \\dfrac{(1+\\beta^2)PR}{\\beta^2P+R} \\]\n之后我们还有真正率和假正率的的概念和ROC曲线，见前，前面说的一坨史（我真不知道为什么老是的PPT可以自相矛盾的），实际上纵轴是真正率（TPR），横轴是假正率（FPR）。\n\\[TPR=\\dfrac{TP}{TP+FN},\\quad FPR = \\dfrac{FP}{TN+FP} \\]\n越往左上角越好。最好是好的曲线包住另一根，这样才能说更好。如果没有包住，则引入AUC，计算ROC曲线下各部分的面积和。\n\\[AUC = \\dfrac{1}{2}\\sum^{m-1}_{i=1}(x_{i+1}-x_i)(y_i+y_{i+1}) \\]\n实际中ROC不能绘制出连续曲线，我们给定\\(m^+\\)个正例和\\(m^-\\)个负例，根据学习器预测结果对样例排序，然后把分类阈值设为最大，此时真正率和假正率都为0，于是在坐标轴原点标记一个点。然后分类阈值依次设置为每个样本的预测值。前一个标记点坐标记为\\((x,y)\\)，当前若为真正类，则标记\\((x,y+\\dfrac{1}{m^+})\\)，否则标记\\((x+\\dfrac{1}{m^-},y)\\)\n概率图模型 图 图是由顶点和边组成的。顶点代表一个随机变量，而边权表示两个随机变量之间的概率关系。\n如果图是有向图，则称之为贝叶斯网络，如果为无向图，则称之为马尔科夫随机场。\n贝叶斯网络 贝叶斯网络是一个有向无环图。其中节点代表随机变量\\(\\{X_1,X_2,\\cdots,X_n\\}\\)。如果两个节点之间有因果关系，那么用一条有向边连接，起点是原因，终点是结果。起点是父节点，终点是子节点。\n这个因果关系由参数\\(\\theta\\)描述，所以贝叶斯网络可以表述为一个图\\(G\\)和参数\\(\\theta\\)，即\\(B=\u003c G,\\theta \u003e\\)。假设属性\\(x_i\\)在图中的父节点为\\(\\pi_i\\)（注意可以有多个父节点），则\\(\\theta_{x_i|\\pi_i}=P_B(x_i|\\pi_i)\\)\n贝叶斯网假设每个属性与它的非后裔属性独立，于是有\n\\[P_B(x_1,x_2,\\cdots,x_d) = \\prod^d_{i=1}P_B(x_i|\\pi_i) = \\prod^d_{i=1}\\theta_{x_i|\\pi_i} \\]\n例如，下图中所有点的联合概率分布可以表示为\n11.jpg\r这个式子也揭示了联合概率分布的因式分解性质。\n注意，这种图必须要是有向无环图（DAG）\n下面是多项式回归的例子\n126.jpg\r条件独立 如果\n\\[p(a|b,c)=p(a|c) \\]\n那么说，\\(a\\)在给定\\(c\\)的情况下与\\(b\\)条件独立，下式可以得出一样的结论\n\\[p(a,b|c) = p(a|b,c)p(b|c)=p(a|c)p(b|c) \\]\n我们可以记作\\(a\\perp b|c\\)\n我们可以用贝叶斯网络来判断条件独立\n127.jpg\r上图有\n\\[p(a,b,c)=p(a|c)p(b|c)p(c) \\]\n如果三个点的分布都未知，那么检验\n\\[p(a,b) = \\sum_c p(a|c)p(b|c)p(c)\\neq p(a)p(b) \\]\n所以\\(a\\not\\perp b|\\emptyset\\)\n如果\\(p(c)\\)分布已知，那么\n\\[p(a,b|c) = \\dfrac{p(a,b,c)}{p(c)} = p(a|c)p(b|c) \\]\n所以\\(a\\perp b|c\\)\n128.jpg\r一道例题\n129.jpg\r130.jpg\r131.jpg\r132.jpg\r为了分析有向图中变量间的条件独立性，可以使用有向分离（D-separation）。先把有向图转为无向图\n找出有向图中所有V型结构，在V型结构中的两个父节点中加上一条无向边 所有有向边改为无向边 这样的无向图称为道德图。此时，给出两个点\\(x,y\\)和一个点的集合\\(z\\)，如果在道德图上把\\(z\\)中的节点和所有相连边去除，\\(x,y\\)不再连通，则\\(x\\perp y|z\\)\n马尔科夫随机场 也叫做马尔科夫网络或者无向图模型。每个节点代表一个变量或者一组变量，\n对于下图\n133.jpg\r若从节点集\\(A\\)中的节点到\\(B\\)中的节点都必须经过节点集\\(C\\)，那么\\(C\\)称为分离集，节点集\\(A,B\\)被\\(C\\)分离，有\n\\[A\\perp B|C \\]\n如果两个点间没有边，那么这两个点被所有其他点分离。\n对于图中节点的一个子集，如果子集中任意两个节点之间都有边，那么该子集称为一个团（clique）。如果加入另外任何的节点，该子集都不成团，则该团为极大团\n记一个团为\\(C\\)，其中的点为\\(x_C\\)。则所有点的联合概率为\n\\[p(x) = \\dfrac{1}{Z}\\prod_C\\psi_C(x_C) \\]\n其中\\(\\psi_C\\)为\\(C\\)对应的势函数，用于对\\(C\\)中的变量关系建模，\\(Z=\\sum_x\\prod_C\\psi_C(x_C)\\)。\n因为势函数总是严格为正，所以可以简化为一个期望\n\\[\\psi_C(x_C) = \\exp[-E(x_C)] \\]\n\\(E(x_C)\\)叫做能量函数，而整个东西叫做玻尔兹曼分布。\n卷积神经网络 卷积层独立地处理图像上的局部区域，但是使用的参数可以在整张图上分享。\n比起全连接网络，其使用的参数更少。其可以利用周围像素的学习结果，而不用对每个像素都学习一整张图。\n使用卷积层的网络就叫卷积神经网络。\n不变性与等变性 一个函数\\(f(x)\\)对于变换\\(t(x)\\)是不变的，当\n\\[f(t(x)) = f(x) \\]\n\\(f(x)\\)对变换\\(t(x)\\)是等变的，当\n\\[f(t(x)) = t(f(x)) \\]\n一维卷积 134.jpg\r135.jpg\r可以知道，\\(z\\)是等变的，即给\\(x\\)施加变换，等价于给\\(z\\)施加相同的变换。\nzero padding\n136.jpg\r“Valid” convolutions\n137.jpg\rStride, kernel size, dilation\n138.jpg\rkernel size不必多解释。stride意味着，卷积核每次移动多远。dilation意味着，卷积项之间的间隔。\n卷积层 139.jpg\r卷积层第\\(i\\)个神经元的输出如上，其中\\(a\\)是激活函数。下面展示了全连接网络。\n通道 140.jpg\r141.jpg\r142.jpg\r感受野 隐藏层的感受野，指的是其受到哪些输入层单元的影响。\n143.jpg\r如上，感受野（左侧）大小为3\n144.jpg\r如上，第四层隐藏层的感受野大小为11\n计算学习理论 计算学习理论研究的是关于通过“计算”来进行“学习”的理论，即关于机器学习的理论基础，其目的是分析学习任务的困难本质，为学习算法提供理论保证，并根据分析结果指导算法设计。\n支持向量机就很大程度上受到它的影响。计算学习理论起源于概率近似正确（PAC）学习框架。\n近似正确\n算法必须学习到一个函数，该函数与真实函数尽可能接近。时间中，用误差参数\\(\\epsilon\\)代表近似正确的程度。\n概率\n学习算法应该有很高的概率，学习到一个近似正确的函数。概率用\\(\\delta\\)代表有多高。\n样本复杂度 要有多少样本才足以学习目标概念？有三种情况\n学习者提供实例，向老师查询。即学习者提供\\(x\\)，老师提供\\(f(x)\\) 老师生成训练样本。即生成\\(\\{(x^1,f(x^1)),\\cdots,(x^n, f(x^n))\\}\\) 随机生成（例如自然生成）一些实例，老师提供标签。实例根据\\(P(X)\\)生成 记实例集为\\(X\\)，假设集为\\(H=\\{h:X\\to\\{0,1\\}\\}\\)，可能的目标函数集为\\(C=\\{c:X\\to\\{0,1\\}\\}\\)，用\\(P(X)\\)生成的实例，老师打上的无噪声标签为\\(c(x)\\)\n学习者要给出一个假设\\(h\\in H\\)，使得\n\\[h = \\arg\\min_{h\\in H}error_{train}(h) \\]\n举例，决策树为\n145.jpg\r假设的真错误（True Error of a Hypothesis） \\(h\\)的真错误为，它错误分类的概率\n\\[error_{true}(h) = Pr[h(x)\\neq c(x)] \\]\n对于实际中的实例集\\(D\\)\n\\[error_{true}(h) = Pr_{x\\in D}[h(x)\\neq c(x)] = \\dfrac{1}{|D|}\\sum_{x\\in D}\\delta(h(x)\\neq c(x)) \\]\n对于分布\\(P(X)\\)\n\\[error_{true}(h) = Pr_{x\\sim P(X)}[h(x)\\neq c(x)] \\]\n过拟合 考虑在训练集上的错误率\\(error_{train}(h)\\)和在整个数据集上的真错误率为\\(error_{true}(h)\\)。如果\\(h\\)过拟合，那么有\n\\[error_{true}(h)\u003eerror_{train}(h) \\]\n过拟合的大小为\n\\[error_{true}(h)-error_{train}(h) \\]\nVC维 假设空间\\(H\\)的VC维是能被H打散的最大实例集的大小\n即\n\\[VC(H) = \\max\\{m:\\Pi_H(m)=2^m\\} \\]\n146.jpg\r强化学习 概论 在强化学习中，软件智能体在环境中进行观察并采取行动，作为回报，它会获得奖励。\n也就是说，强化学习的数据是很多对“状态-动作”，每采取一个动作，到达一个新的状态，然后获得奖励（或惩罚）。而其目标是，学会以一种可以随时间推移最大化其预期回报的方式来采取行动。\n假设每一步行动\\(a_t\\)后，状态从\\(S_t\\)转移到\\(S_{t+1}\\)，获得\\(r_t\\)的回报，那么从\\(t\\)开始的总回报为（注意和后面区分）\n\\[R_t = \\sum^\\infty_{i=t} r_i \\]\n需注意“机器”与“环境”的界限，在环境中状态的转移（指采取动作后的转移方向）、奖赏的返回是不受机器控制的，机器只能通过选择要执行的动作来影响环境，也只能通过观察转移后的状态和返回的奖赏来感知环境.\n马尔科夫决策过程（Markov Decision Processes） 我们可以使用马尔科夫决策过程来描述一个强化学习任务。\n机器处于环境\\(E\\)中，状态空间为\\(X\\)，每个状态\\(x\\in X\\)是机器感知到的环境的描述。机器能采取的动作构成的动作空间为\\(A\\)，若某个动作\\(a\\in A\\)作用在当前的状态\\(x\\)上，则（潜在的）转移函数\\(P\\)将使得环境从当前状态按某种概率转移到另一个状态。在转移到另一个状态的同时，环境会根据（潜在的）奖赏函数\\(R\\)反馈给机器一个奖赏。\n综合起来，强化学习任务对应了四元组\\(E=\u003c X,A,P,R \u003e\\)，其中\\(P:X\\times A\\times X\\rightarrow \\mathbb{R}\\)指定了状态转移的概率，\\(R:X\\times A\\times X\\rightarrow \\mathbb{R}\\)指定了奖赏。在有些时候奖赏函数只和状态转移有关，即\\(R:X\\times X\\rightarrow \\mathbb{R}\\)。如下是用有向图表示的一个例子\n18.jpg\r一个状态转移如果是马尔科夫的，则必须要符合马尔科夫性质。也就是说，状态转移只取决于当前的状态，而与过去的状态无关（独立）。公式表述如下\n\\[P[x_{t+1}|x_t] = P[x_{t+1}|x_1,x_2,\\cdots,x_t] \\]\n当然，马尔科夫决策过程中的所有状态转移都要是马尔科夫的。\n当然，有些地方马尔科夫决策过程是五元组，还要多一元\\(\\gamma\\)，其是折扣因子（discount factor），其取值范围为\\([0,1]\\)，此时，从\\(t\\)开始的奖赏（称为\\(\\gamma\\)折扣累计奖赏）为\n\\[R_t = \\sum^\\infty_{i=0}\\gamma^i r_{i+t} \\]\n如果不使用折扣因子，则可以使用\\(T\\)步累计奖赏（注意和前面区分）\n\\[R_t = \\dfrac{1}{T}\\sum^T_{t=1}r_t \\]\n如果转移不是确定的，那么就要使用\\(E[\\sum^\\infty_{i=0}\\gamma^i r_{i+t}]\\)和\\(E(\\dfrac{1}{T}\\sum^T_{t=1}r_t)\\)，对所有的随机变量求期望，来求期望奖赏。\n机器在这样一个马尔科夫决策过程中，要做的是通过在环境中不断地尝试而学得一个“策略”（policy）\\(\\pi\\)，根据这个策略，在状态\\(x\\)下就能得知要执行的动作\\(a=\\pi(x)\\)。策略有两种表示方法\n\\(\\pi :X\\to A\\)，用于确定性的策略 \\(\\pi:X\\times A\\to \\mathbb{R}\\)，用于表示概率、随机性的策略，此时用\\(\\pi(x,a)\\)（或者\\(\\pi(a|x)\\)）表示状态\\(x\\)下选择动作\\(a\\)的概率。注意必须有\\(\\sum_a \\pi(x,a)=1\\)。 此时，在策略\\(\\pi\\)下，状态\\(x\\)的奖励就为（假设第\\(t\\)步进行到\\(x\\)）\n\\[R_x=E_\\pi[R_{t+1}|X_t=x] \\]\n把从此时开始的总折扣奖励记为\n\\[G_t = R_{t+1}+\\gamma R_{t+2}+\\cdots = \\sum^\\infty_{k=0}\\gamma^kR_{t+k+1} \\]\n也可以用\\(T\\)步累计奖赏。策略的优劣取决于长期执行这一策略后得到的累计奖赏。\n在模型已知时，对任意策略\\(\\pi\\)能估计出该策略带来的期望累积奖赏。用这个期望累积奖赏来评估策略。\n假设回报只和状态转移有关，那么从此时开始的状态值函数（Value Function）记为\n\\[V_\\pi(x) = E_\\pi[G_t|X_t=x] \\]\n区分两种累计奖赏，以\\(0\\)为开始行动步骤，则有\n\\[\\left\\{\\begin{matrix} V^\\pi_T(x) = E_\\pi[\\frac{1}{T}\\sum^T_{t=1}r_t|x_0=x],\u0026 T步累积奖赏\\\\ V^\\pi_\\gamma(x)=E_\\pi[\\sum^{+\\infty}_{t=0}\\gamma^t r_{t+1}|x_0=x], \u0026 \\gamma 折扣累积奖赏 \\end{matrix}\\right. \\]\n如果回报和状态转移和采取的动作都有关，那么状态-动作值函数记为\n\\[Q_\\pi(x,a) = E_\\pi[G_t|X_t=x, A_t=a] \\]\n区分有\n\\[\\left\\{\\begin{matrix} Q^\\pi_T(x,a) = E_\\pi[\\frac{1}{T}\\sum^T_{t=1}r_t|x_0=x,a_0=a],\u0026 T步累积奖赏\\\\ Q^\\pi_\\gamma(x,a)=E_\\pi[\\sum^{+\\infty}_{t=0}\\gamma^t r_{t+1}|x_0=x,a_0=a], \u0026 \\gamma 折扣累积奖赏 \\end{matrix}\\right. \\]\n于是我们的优化目标就是选出最优策略\n\\[\\pi^\\ast(x) = \\arg\\max_a Q^\\ast(x,a) \\]\n有模型学习 考虑多步强化学习任务，暂且假定任务对应的马尔科夫决策过程的四元组\\(E=\u003c X,A,P,R \u003e\\)均为已知，这样的情形称为“模型已知”，即及其已对环境进行了建模，能在机器内部模拟出与环境相同或近似的状况.在已知模型的环境中学习称为“有模型学习\u0026quot; (model-based learning)。\n此时，对于任意的状态\\(x,x'\\)和动作\\(a\\)，在\\(x\\)状态下执行动作\\(a\\)转移到\\(x'\\)状态的概率\\(P^a_{x\\to x'}=P[X_{t+1}=x'|X_t=x,A_t=a]\\)是已知的，其带来的奖赏\\(R^a_{x\\to x'}\\)也是已知的。\n动态规划 众所周知，动态规划是非常通用的方法，只要满足：\n最优子结构 重叠子问题 即可使用。\n在强化学习中，DP需要知道整个环境，并且\\(V_\\pi(x)\\)需要是递归的。另外，\\(V(x)\\)的估计是自助的（bootstrapping）\n在强化学习中使用DP的主要想法是：使用值函数来构建搜索最优策略的方式；需要一个对于环境的完美模型。主要由两步构成：从任意的策略开始；重复评估/改进直到收敛。评估/改进则是：计算\\(\\pi\\)的\\(V_\\pi(x)\\)，然后用\\(V_\\pi(x)\\)来改进\\(\\pi\\)\n通过\\(\\pi\\)来计算\\(V_\\pi(x)\\)是一个递归的过程，以\\(\\gamma\\)为例，有\n\\[V^\\pi_\\gamma(x) = \\sum_{a\\in A}\\pi(x,a)\\sum_{x'\\in X}P^a_{x\\to x'}(R^a_{x\\to x'}+\\gamma V^\\pi_{\\gamma}(x')) \\]\n这个递归等式也称为Bellman等式（推导过程可以去周志华《机器学习》查阅，主要是因为满足马尔科夫性质，并且已知\\(P\\)和\\(R\\)，做全概率展开，才能推导）。显然的，利用动态规划，我们可以从\\(0\\)开始，从低到高计算，这样只需要计算\\(T\\)次即可到达现在的值函数（对于T步奖赏来说，对于\\(\\gamma\\)来说，可以设定一个停止准则\\(\\max_x\\in X|V(x)-V'(x)|\u003c \\theta\\)）。\n通过\\(V_\\pi(x)\\)来更新\\(\\pi\\)，则是\n\\[\\pi'(x) = \\arg\\max_{a\\in A}Q_\\pi(x,a) = \\arg\\max_{a\\in A}\\sum_{x'\\in X}P^{a}_{x\\to x'}[R^a_{x\\to x'}+\\gamma V_\\pi(x')] \\]\n注意上式是通过用\\(V_\\pi\\)来表示\\(Q_\\pi\\)来实现，具体公式推导可以去周志华《机器学习》查阅。\n此时\\(\\pi'\\)要么严格好于\\(\\pi\\)，要么\\(\\pi'\\)已经是最优的了。\n重复执行上述更新过程，我们有两种停止更新的策略\n策略迭代。即真的用\\(\\pi_0\\)计算\\(V_{\\pi_0}\\)，再用其更新出\\(\\pi_1\\)，再计算\\(V_{\\pi_1}\\)，直到\\(\\pi\\)收敛。输出\\(\\pi^*\\)他要用两次嵌套迭代，在每次改进策略后都需重新进行策略评估。但是不需要收敛到\\(V_{\\pi_k}\\)（我实在不明白老师PPT里这句话指的是什么意思） 值迭代。即使用\\(V_{k+1}(x) = \\max_{a\\in A}\\sum_{x'\\in X}P^a_{x\\to x'}(R^a_{x\\to x'}+\\gamma V_k(x'))\\)来迭代。需要收敛到\\(V^*\\)（我实在不明白老师PPT里这句话指的是什么意思） 两个算法的伪代码如下（虽然是基于\\(T\\)步奖赏的，但是修改不难）\n19.jpg\r20.jpg\r免模型学习 在现实的强化学习任务中，环境的转移概率、奖赏函数往往很难得知，甚至有多少状态都很难得知，往往只有一些经验和模拟经验。如果学习算法不依赖于环境建模，则称为免模型学习。\n蒙特卡罗方法（MC） 对比有模型学习的方法，策略迭代算法在没有模型的时候，首先就没有办法评估策略，因为未知\\(P,R\\)而无法做到全概率展开。另一方面，策略迭代算法估计的是状态值函数\\(V\\)，而最终的策略则是通过状态-动作值函数\\(Q\\)来获得。当模型已知时，\\(V\\)到\\(Q\\)很容易，但未知时则很困难。另外，模型已知的时候，我们可以从起始状态动态规划地得到所有状态。而没有模型时则不行，只能在探索的过程中逐渐发现各个状态。\n一种直接的策略评估替代方法是多次“采样”，然后求取平均累积奖赏来作为期望累积奖赏的近似，这称为蒙特卡罗强化学习.由于采样必须为有限次数，因此该方法更适合于使用\\(T\\)步累积奖赏的强化学习任务.\n策略评估\n目标：获取\\(V_\\pi(x)\\)\n提供的数据：在\\(E\\)中执行策略\\(\\pi\\)，产生的轨迹（episode）\\(\u003c x_0,a_0,r_1,x_1,a_1,r_2,\\cdots,x_{T-1},a_{T-1},r_T,x_T \u003e\\),\n其思想是，只要多次采样，求平均，就能近似得到期望累积奖赏。\n\\[V\\pi\\approx avg(G_t),\\quad s.t.\\quad X_t=x \\]\n这里有两种平均的方式\nEvery-Visit MC。当每次轨迹访问到\\(x\\)时，就更新这个均值 First-visit MC。只有第一次访问到\\(x\\)时，才会更新这个均值。 这两种方法都会近似地收敛。\n具体上，每次迭代：\n\\(N(X_t)\\leftarrow N(X_t)+1\\) \\(V(X_t)=V(X_t)+\\dfrac{1}{N(X_t)}(G_t-V(X_t))\\) 只要迭代的次数够多，那么有\n\\[V(X_t)\\to V_\\pi(X_t),N(X_t)\\to\\infty \\]\nFirst-visit MC的伪代码如下\n21.jpg\r估计状态-动作值函数\n更新公式如下\n\\[Q(X_t, A_t) = Q(X_t, A_t) + \\dfrac{1}{N(X_t)}(G_t-Q(X_t,A_t)) \\]\n于是我们就可以得到蒙特卡罗版本的策略迭代算法：\n22.jpg\r（我不明白为什么上面的\\(Q\\)不大写）\n其中\\(E\\)是一次蒙特卡罗版本的策略评估，\\(I\\)是一次策略优化（贪心地，可以对状态值函数贪心，也可以对动作-状态值函数贪心）。伪代码如下\n23.jpg\r时序差分学习（Temporal Difference） 相比于蒙特卡罗算法需要在完成一个采样轨迹后再更新策略的值估计，基于动态规划的策略迭代和值迭代算法在执行每一步策略后就进行值函数更新。这样看下来，蒙特卡罗算法效率就很低，这是因为蒙特卡罗算法没有用上马尔科夫性质（MDP）。而时序差分学习就参考了蒙特卡罗算法的思想，直接从经验学习而不用模型，也参考了动态规划的思想，从后继节点学习。对于连续的任务能work，通常比纯蒙特卡罗快。\n蒙特卡罗算法在一个完整的采样轨迹完成后再对所有的状态-动作对进行更新，但是这个过程实际上是可以增量式地进行的。更新公式如下\n\\[V(X_t)\\leftarrow V(X_t)+\\alpha(R^{a}_{X_t\\to X_{t+1}}+\\gamma V(X_{t+1})-V(X_t)) \\]\n\\(R^{a}_{X_t\\to X_{t+1}}+\\gamma V(X_{t+1})\\)称为TD目标，而\\(R^{a}_{X_t\\to X_{t+1}}+\\gamma V(X_{t+1})-V(X_t)\\)这样的差分形式就是为什么它叫做时序差分算法。\n优势总结：\nTD可以在最终结果出来之前学习，而MC不能。或者说TD可以从不完整的轨迹中学习，而MC不能。 TD运行在连续（无中断）的环境中（即在线算法），而MC每次迭代都要中断（即离线算法）。 内存消耗低 峰值计算少 在线学习\n无模拟器（simulator），直接与环境交互 智慧体在每个动作后直接接受奖励/开销（Rewards/costs） 主要的挑战是：\n探索/利用的权衡（Exploration/exploitation tradeoff），即每一步行动应该是专注于最大化立即的奖励，还是专注于获得更多的信息？ 对于每一步动作的实时计算，效率问题。 因为每次都要与环境交互才能获取信息，所以学习时信息相对有限。 离线学习\n智慧体可以与模拟器交互 奖励/开销不重要（于是也就没有探索/利用的权衡问题） 由于不是实时计算，所以两次动作之间的计算时间不是关键问题。 模拟器可以造出重组的信息供智慧体学习。 主要的挑战是：\n如何优化使得收敛到最优策略的事件开销最小。 TD版策略评估\n即使用之前提到的\n\\[V(X_t)\\leftarrow V(X_t)+\\alpha(R^{a}_{X_t\\to X_{t+1}}+\\gamma V(X_{t+1})-V(X_t)) \\]\n伪代码如下\n24.jpg\rSara算法\n因为Sara算法的评估与改进过程用的是同一个策略，所以也叫做同策略（On-Policy）算法，其\\(Q\\)值更新策略为：\n\\[Q(X_t, A_t)\\leftarrow Q(X_t, A_t)+\\alpha(R^{a}_{X_t\\to X_{t+1}}+\\gamma Q(X_{t+1}, A_{t+1})-Q(X_t, A_t)) \\]\n直观上来说，就是本次状态的\\(Q\\)值，使用下个状态奖励和\\(Q\\)值来更新。伪代码如下\n25.jpg\rQ-学习\n它是异策略（Off-Policy）算法。其更新公式为\n\\[Q(X_t, A_t)\\leftarrow Q(X_t, A_t)+\\alpha(R^{a}_{X_t\\to X_{t+1}}+\\gamma \\max_a Q(X_{t+1}, a)-Q(X_t, A_t)) \\]\n直观上来说，它不仅仅用轨迹中的下一个点来更新，它把所有下一个动作达到的状态的最大\\(Q\\)值拿来更新。\n26.jpg\rn-步TD 之前提到的TD，每进行一个动作就更新一次，而n-步TD扩展了这个过程。可以每进行\\(n\\)个动作，才进行一次更新。如下图\n28.jpg\r其中\\(n\\to \\infty\\)时，TD就是蒙特卡罗算法。各个更新公式为\n\\[\\begin{align*} \u0026 n=1(TD), \u0026 \\quad G^{(1)}_t=R_{t+1}+\\gamma V(X_{t+1})\\\\ \u0026 n=2, \u0026 \\quad G^{(2)}_t=R_{t+1}+\\gamma R_{t+2}+\\gamma^2 V(X_{t+2})\\\\ \u0026 \\vdots \u0026 \\\\ \u0026 n \u0026 G^{(n)}_t = R_{t+1}+\\gamma R_{t+2}+\\cdots+\\gamma^{n-1} V(X_{t+n}) \\end{align*} \\]\n\\(V\\)值更新方式如下\n\\[V(X_t) = V(X_t)+\\alpha(G^{(n)}_t-V(X_t)) \\]\nTD(\\(\\lambda\\)) 首先定义\\(G_t^\\lambda\\)（\\(\\lambda\\)-return），其利用权重\\((1-\\lambda)\\lambda^{k-1}\\)，综合了所有n-步TD的信息，\n\\[G^\\lambda_{t} = (1-\\lambda)\\sum^\\infty_{k=1}\\lambda^{k-1}G^{(k)}_t \\]\n直观来看如下\n29.jpg\r前向视角\n更新公式为\n\\[V(X_t) = V(X_t) + \\alpha(G^\\lambda_{t}-V(X_t)) \\]\n利用\\(\\lambda\\)-return来更新。其通过观测（最遥远的）未来，来计算\\(G^\\lambda_t\\)，就像MC一样，必须要获得完整的轨迹才能进行更新，也即离线算法。\n资格迹（Eligibility Traces）\n假设下面这样一个问题（Credit assignment问题）\n30.jpg\r智慧体接收到三个铃铛响和一个光照，最后智慧体发生了一个shock。那么铃铛响和光照中谁导致了这个shock？有两种启发式想法\n频率启发：给发生频率最高的时间assign credit 最近启发：给最近的事件assign credit 而资格迹综合了这两个启发\n\\[E_0(x) = 0 \\]\n\\[E_t(x)=\\gamma\\lambda E_{t-1}(x)+1,(X_t=x) \\]\n反向视角\n每次更新时都记录其资格迹，用如下公式更新当前的\\(V(x)\\)\n\\[\\delta_t = R_{t+1}+\\gamma V(X_{t+1})-V(X_t) \\]\n\\[V(x) = V(x)+\\alpha\\delta_tE_t(x) \\]\n其中\\(\\delta_t\\)称为TD-error。（老师的PPT中第一个等式的第三项的符号打反了，打了个\\(+\\)号）\nTD(\\(\\lambda\\))和TD(0)、MC的关系\n当\\(\\lambda=0\\)时，\\(E_t=1\\)，此时TD(\\(\\lambda\\))就是TD(0)（也就是最原始版本的TD）。\n当\\(\\lambda=1\\)时，大致上等价于every-visit的MC。因为它的误差更新是在线的，一步一步的。如果只在最后才更新值函数，也就是离线的，那么等价于MC。\n强化学习中的自助法（Bootstrapping）和采样（Sampling） 自助法\n更新时包括估计\nMC不包含，DP包含，TD包含。\n采样\n更新时采样期望。\nMC采样，DP不采样，TD采样。\n27.jpg\r值函数近似 前面我们一直假定强化学习任务是在有限状态空间上进行，每个状态可用一个编号来指代。之前我们的\\(V(x)\\)和\\(Q(x,a)\\)都是通过记录、查询数组（或者其他数据结构）得到的。\n但是现实中的强化学习任务，往往状态空间不是离散而是连续的，并且状态可能是无穷多的。我们引入值函数近似来处理这个问题\n\\[V(x,w)\\approx V_\\pi(x) \\]\n\\[Q(x,a,w)\\approx Q_\\pi(x,a) \\]\n从已经见过的状态中推广到未来的状态中，通过MC或者TD来更新这个\\(w\\)\n我们主要考虑可微的值函数的近似，例如：特征的线性组合、神经网络。另外，我们需要一种训练方法，适合处理非固定的数据。此时我们可以用梯度下降法来更新\n\\[J(w)=E[(V_\\pi(x)-V(x,w))^2] \\]\n方向为\n\\[\\Delta w = -\\dfrac{1}{2}\\alpha\\nabla_wJ(w) \\]\n随机梯度降的方向为\n\\[\\Delta w = \\alpha(V_\\pi(x)-V(x,w))\\nabla_w V(x,w) \\]\nActor-Critic方法 31.jpg\r值函数和策略是隐式表示的 只需要最小的计算就可以选择下一步行动 可以学习到隐式随机的策略 可以给策略加上限制条件 作为心理和神经模型而吸引人 强化学习还存在的问题 状态值函数，动作-状态值函数，后状态值函数，应该估算哪一个？ 探索/利用权衡问题 同步/异步更新的问题 智慧体应该从真实环境中获取信息还是应该从模拟环境中获取信息？ 更新时间点的问题。更新应该作为选择操作的一部分进行，还是在选择之后进行？ 更新时内存的使用问题。更新过的值应当在内存中留存多长时间？ 序列模型（Sequence Model）：RNN、LSTM、注意力机制 什么是序列数据（sequence data）？\n32.jpg\r以上图为例。上面的不是序列数据，而下面的是。并且下面的是时间上的序列数据，其是对于一个特定的东西或者现象，在一段时间内的记录。\n当然并不一定需要是时间上相关的，例如自然语言，其就是前后语义相关的。总而言之，以串数据，前后两个数据之间要有相关性，才能成为序列数据。\n以下是一些常见例子：\n语音识别 AI编曲 情感分类 DNA序列分析 机器翻译 视频人物动作分析 命名实体（Name Entity）识别 以命名实体识别为例\n33.jpg\r为什么这个问题不便于用如下的传统的神经网络呢？\n34.jpg\r问题在于：\n不同的样本，其输入长度和输出长度都可能不同。 在文章中不同的地方，学习到的东西不能共享。 为此我们需要引入一些新的方法。\n循环神经网络（RNN） 在之前，我们主要只关注了前馈神经网络，即激活仅在一个方向上流动，从输入层到输出层。而RNN在前馈神经网络的基础上，还具有反向的连接，最简单的例子如下\n35.jpg\r一个神经元添加了一个输出到自身的连接。在每个时间步长\\(t\\)（也称为帧），该循环神经元接受输入\\(x_t\\)和前一个时间步长\\(y_{t-1}\\)的输出（第一个时间步长时，前一个步长的输出定义为\\(0\\)）。上图的右侧代表了按时间展开该网络。\n很容易可以扩展到一整层\n36.jpg\r此时，一层的输入\\(y\\)和一层的输出\\(x\\)都是向量。此时，每个循环神经元都有两个权重，\\(w_x\\)和\\(w_y\\)，前者用于输入\\(x_t\\)，后者用于输出\\(y_{t-1}\\)。对于一层来说，则是两个权重矩阵\\(W_x,W_y\\)。此时一层的输出为\n\\[y_t = \\phi(W^T_xx_t+W^T_yy_{t-1}+b) \\]\n记忆单元 由于在时间步长\\(t\\)时递归神经元的输出是先前时间步长中所有输入的函数，因此你可以说它具有记忆的形式。在时间步长上保留某些状态的神经网络的一部分称为记忆单元（或简称为单元）。\n37.jpg\r其中\\(a_1,a_2\\)（有些地方会是\\(h_1,h_2\\)），就是记忆单元。\n此时，循环神经元和其按时间展开的形式如下\n38.jpg\r单个或单层的循环神经网络非常基础，通常只能学习短模式（通常约10个步长）。\n不同类型的RNN 39.jpg\r多到多的RNN（我自己叫他同时的多到多）\n之前介绍的，都是多到多的RNN，如下\n40.jpg\r其代表性的例子就是命名实体识别任务。\n多到一的RNN\n41.jpg\r另一种多到多的RNN（我自己叫他非同时的多到多）\n42.jpg\r一到多的RNN\n43.jpg\r多层RNN\n44.jpg\r双向RNN\n45.jpg\r注意上图的下面两行的意思是，有两种记忆单元，一种在时间上往前传播，一种往后传播。\n例如在完型填空中，I am __ hungry now. 填的词根前面和后面的文章都有关，需要双向RNN。\n金字塔型RNN\n46.jpg\rRNN的训练 训练RNN，诀窍是将其按时间展开，然后利用常规的前向传播和反向传播即可。\n前向传播过程\n\\[a^{\u003c t \u003e} = \\phi(W_{ax} x^{\u003c t \u003e}+W_{aa} a^{\u003c t-1 \u003e}+b_a) \\]\n\\[\\hat y^{\u003c t \u003e} = g(W_{ya} a^{\u003c t \u003e}+b_y) \\]\n\\[L^{\u003c t \u003e} = CrossEntropy(\\hat y^{\u003c t \u003e}, y^{\u003c t \u003e}) \\]\n\\[L = \\sum^{T_y}_{t=1} L^{\u003c t \u003e} \\]\n其中\\(\\phi\\)（可能）通常会使用\\(\\tanh\\)\n反向传播过程\n这也称作时间反向传播（BPTT (back propagation through time)）\n\\[\\dfrac{\\partial L}{\\partial b_y} = \\sum^{T_y}_{t=1}\\bigg(\\dfrac{\\partial L^{\u003c t \u003e}}{\\partial y^{\u003c t \u003e}}\\bigg)\\bigg(\\dfrac{\\partial y^{\u003c t \u003e}}{\\partial b_y}\\bigg) \\]\n\\[\\dfrac{\\partial L}{\\partial a^{\u003c 1 \u003e}} = \\sum^{T_y}_{t=1}\\bigg(\\dfrac{\\partial L^{\u003c t \u003e}}{\\partial y^{\u003c t \u003e}}\\bigg)\\bigg(\\dfrac{\\partial y^{\u003c t \u003e}}{\\partial a^{\u003c 1 \u003e}}\\bigg) = \\sum^{T_y}_{t=1}\\bigg(\\dfrac{\\partial L^{\u003c t \u003e}}{\\partial y^{\u003c t \u003e}}\\bigg)\\bigg(\\dfrac{\\partial y^{\u003c t \u003e}}{\\partial a^{\u003c t \u003e}}\\bigg)\\bigg(\\dfrac{\\partial a^{\u003c t \u003e}}{\\partial a^{\u003c t-1 \u003e}}\\bigg)\\cdots\\bigg(\\dfrac{\\partial a^{\u003c 2 \u003e}}{\\partial a^{\u003c 1 \u003e}}\\bigg) \\]\n梯度消失问题（The Vanishing Gradient Problem） 反向传播过程有一长串相乘的梯度，其中大部分展开后都有\\(W_{aa}\\)矩阵。这导致，在长序列的训练中，如果\\(W_{aa}\\)太大，就会梯度爆炸，如果\\(W_{aa}\\)太小，就会梯度消失。\n误差平面非常粗糙的问题 47.jpg\r长短期记忆（LSTM(Long Short-term Memory)） 前面也提到，很简单的RNN基本单元可能只能处理很短的时间序列，所以我们引入LSTM。\n48.jpg\r假设我们不关注内部的结构，它的外部结构和基本的单元还是很相似的。只不过，原来的\\(a^{ \u003c t \u003e }\\)被分成了两个部分\\(c^{\u003c t \u003e}\\)和\\(h^{\u003c t \u003e}\\)。可以理解为\\(h\\)是短期记忆，\\(c\\)是长期记忆。\n关键的思想是网络可以学习长期状态下存储的内容、丢弃的内容以及从中读取的内容。\n当长期状态\\(c_{(t-1)}\\)从左到右遍历网络时，它首先经过一个遗忘门，丢掉了一些记忆，然后通过加法操作添加了一些新的记忆（由输入门选择的记忆）。结果\\(c_{(t)}\\)直接送出来，无须任何进一步的转换。因此，在每个时间步长中，都会丢掉一些记忆，并添加一些记忆。\n此外，在加法运算之后，长期状态被复制并通过\\(\\tanh\\)函数传输，然后结果被输出门滤波。这将产生短期状态\\(h_{(t)}\\)（等于该时间步长的单元输出\\(y_{(t)}\\)）。\n对于输入的部分：首先，将当前输入向量\\(x_{(t)}\\)和先前的短期状态\\(h_{(t-1)}\\)馈入四个不 同的全连接层。它们都有不同的目的：\n主要层是输出\\(g_{(t)}\\)的层。它通常的作用是分析\\(x_{(t)}\\)短期状态\\(h_{(t-1)}\\)。在基本单元中，除了这一层，没有其他东西，它的输出直接到\\(y_{(t)}\\)和\\(h_{(t)}\\)。相比之下，在LSTM单元中，该层的输出并非直接输出，而是将其最重要的部分存储在长期状态中（其余部分则丢弃）。这个层的设计，只有很少部分的信息被修改，方便信息在未被修改的情况下直接通到后面的层。 其他三层是门控制器。由于它们使用逻辑激活函数，因此它们的输出范围是\\(0\\)到\\(1\\)。如你所见，它们的输出被馈送到逐元素乘法运算，因此，如果它们输出\\(0\\)，则关闭门；如果它们输出\\(1\\)，则将门打开。 遗忘门\\(f_{(t)}\\)，控制长期状态中哪些应该被删除。其维数和\\(c_{(t-1)}\\)相同，乘法是元素相乘。 输入门\\(i_{(t)}\\)，控制\\(g_{(t)}\\)中的哪些部分应该添加到长期状态中 输出门\\(o_{(t)}\\)，控制应在此时间步长读取长期状态的哪些部分并输出到\\(h_{(t)}\\)和\\(y_{(t)}\\) 注：基本单元的RNN相当于：\n49.jpg\r还有一个老师给出的更一般化的模型：\n50.jpg\rLSTM的计算公式如下\n\\[i_{(t)} = \\sigma(W_{xi}^T x_{(t)}+W_{hi}^T h_{(t-1)}+b_i) \\]\n\\[f_{(t)} = \\sigma(W_{xf}^T x_{(t)}+W_{hf}^T h_{(t-1)}+b_f) \\]\n\\[o_{(t)} = \\sigma(W_{xo}^T x_{(t)}+W_{ho}^T h_{(t-1)}+b_o) \\]\n\\[g_{(t)} = \\tanh(W_{xg}^T x_{(t)}+W_{hg}^T h_{(t-1)}+b_g) \\]\n\\[c_{(t)} = f_{(t)}\\otimes c_{(t-1)}+i_{(t)}\\otimes g_{(t)} \\]\n\\[y_{(t)} = h_{(t)} = o_{(t)}\\otimes \\tanh(c_{(t)}) \\]\n有些地方会把\\(g_{(t)}\\)记作\\(\\tilde{C}_{(t)}\\)\n窥视孔连接（Peephole） 常规LSTM中，门控制器只能查看短期状态和输入。窥视孔连接允许它们也查看长期状态。\n51.jpg\r联合遗忘和输入门 常规LSTM中，决定遗忘什么和决定添加什么是分开的。有时可以将这些决定一起做，我们只忘记那些，正好被新记忆替代的记忆。\n52.jpg\r门控循环单元（Gated Recurrent Unit(GRU)） GRU单元是LSTM单元的简化版，它的性能似乎也不错\n53.jpg\r它将两个状态向量合并为一个\\(h_{(t)}\\) 和前面一样的，把遗忘和添加的门合成一个\\(z_{(t)}\\) 没有输出门，在每个时间步长都输出完整的状态向量。但是有一个新的门\\(r_{(t)}\\)限制先前状态的哪一个部分将显示给主要层\\(g_{(t)}\\) 公式如下\n\\[z_{(t)} = \\sigma(W_{xz}^T x_{(t)},W_{hz}^T h_{(t-1)}+b_z) \\]\n\\[r_{(t)} = \\sigma(W_{xr}^T x_{(t)},W_{hr}^T h_{(t-1)}+b_r) \\]\n\\[g_{(t)} = \\tanh(W_{xg}^T x_{(t)},W_{hg}^T (r_{(t)}\\otimes h_{(t-1)})+b_g) \\]\n\\[h_{(t)} = z_{(t)}\\otimes h_{(t-1)} + (1-z_{(t)})\\otimes g_{(t)} \\]\n老师的PPT给出的形式如下，我觉得完全等价，只是翻转一下\\(z_{(t)}\\)的语义。\n54.jpg\rRNN条件生成 例如通过莎士比亚的作品进行学习，然后用RNN生成一段新的文章。\n这种方式把每一个字符当作输入，然后让RNN根据前文输出下一个字符。一个字符一个字符地，最后得到了最终的文本。\n例如图像生成，这种可以把图像拆成一个一个像素，然后像生成文字一样生成图片。\n显然，这些东西都不是随机生成的，我们给AI一些前提条件，让AI脑补补完。\n55.jpg\r另外，基于神经网络的机器翻译和Chat-bot（包括GPT）也是用到了RNN的条件生成，主要用到了编码器-解码器网络。\n词嵌入（Word Embedding） 现有的机器学习方法往往无法直接处理文本数据，因此需要找到合适的方法，将文本数据转换为数值型数据，由此引出了Word Embedding（词嵌入）的概念。\n具有相同含义的单词具有相似表示。\n使用词嵌入的好处是\n大多数神经网络工具不适合处理高维、稀疏向量（应该是说one-hot的缺点，而词嵌入比较密集） 密集表示，所以泛化能力强 Bag of Words\n148.jpg\rword2vec\n即将词汇向量化。老师介绍的不是很清楚。\n编码器-解码器网络 56.jpg\r上图是一个简单的神经机器翻译模型，把英语翻译成法语。\n简而言之，英语句子被送入到编码器，解码器输出法语翻译。注意，法语翻译也用作解码器的输入，但是向后偏移了一步。换句话说，给解码器的输入是在上一个步长应该输出的单词。对于第一个单词，解码器的输入是序列开始（SOS）令牌。解码器希望以序列结尾（EOS）令牌来结束句子。\n注意英语句子是反转单词顺序的，这确保英语句子的开头最后被馈送到编码器。这是有用的，因为通常这是编码器需要翻译的第一个内容。\n每个单词最初都由其ID表示， 接下来，embedding层返回词嵌入，然后将词嵌入馈送到编码器和解码器。\n在每个步长中，解码器为在（法语）词汇表中的每个单词输出一个分数，然后softmax层将这些分数转换为概率。概率最高的词将会被输出。\n注意力机制 考虑神经机器翻译模型中“milk”到“lait”的路径，它非常长，这意味着这个单词的表征在实际使用之前需要进行许多步骤。\n另外，输入\\(X\\)被压缩为固定长度的向量\\(c\\)。最后一个隐藏状态跟最后一个输入非常相关，当输入很长时，该模型表现骤然变差。\n每个输入都是按同样的权重给予的，这在很多情况下是不符合直觉的。\n编码器的输入是按顺序一个一个单词来的，所以隐藏的状态中就包含了顺序信息，会导致解码器也会受到这个顺序的影响。但是我们希望结果并不会受到这样的影响。\n注意力机制允许解码器在每个时间步长中专注于适当的单词（由编码器编码）。例如，要输出“lait”时，会把注意力集中在单词“milk”上，这意味着从输入单词到其翻译的路径变短了，因此RNN的短期记忆限制的影响变小了。这一技术彻底改变了神经机器翻译（一般来说是NLP），特别是对于长句子。\n57.jpg\r（左下角应该是编码器）\n注意力机制不像之前一样，编码器到解码器只有一个固定语义的输出。事实上，注意力机制允许有多个语义的输出，然后每个语义的输出还有各自的权重。\n在每个时间步长，解码器的记忆单元都会计算所有这些编码器的输出的加权总和：这确定了该步长会把终点关注在哪个单词。权重\\(\\alpha_{(t,i)}\\)表示在第\\(t\\)个解码器时间步长处的第\\(i\\)个编码器输出的权重。谁的权重更大，解码器就会更注重它。解码器的其他部分的工作方式和之前类似，在每个步长，记忆单元都会接收我们刚刚说的输入，再加上前一个时间步长的隐藏状态，最后它接收前一个时间步长中的目标单词（虽然图中没画出来。在推断时，则接收前一个时间步长的输出）。\n这些权重从何而来？它们由一种称为对齐模型（或注意力层）的小型神经网络生成，该网络与其余的编码器-解码器模型一起训练。它始于有单个神经元的时间分布Dense层，该层接收所有编码器的输出作为输入，与解码器先前的隐藏状态（如\\(h_{(2)}\\)）合并，然后为每个输入输出一个分数。然后分数经过softmax层，变成最终权重。\n注意力机制的公式如下：\n条件概率\\(p\\)为\n\\[p(y'_i|y_1',\\cdots,y_{i-1}',x)=g(y_{i-1}', h_{(i-1)},c_i) \\]\n其中\\(h_{i}\\)是解码器RNN的隐藏状态\n\\[h_i = f(h_{i-1}, y_{i-1}',c_i) \\]\n其中\\(c_i\\)是加权处理过的输出\n\\[c_i = \\sum^{T_x}_{j=1}\\alpha_{ij}y_j \\]\n其中\\(y_j\\)是编码器的隐藏状态兼输出。\\(a_{ij}\\)中\\(i\\)代表的是解码器的时间\\(t\\)，\\(j\\)代表的是编码器的第\\(j\\)个输出。\n\\[a_{ij} = \\dfrac{\\exp(e_{ij})}{\\sum^{T_x}_{k=1}\\exp(e_{ik})} \\]\n\\(e_{ij}\\)有三种公式\n\\[e_{ij} = \\left\\{\\begin{matrix} h^T_{(t)}y_{(i)} \u0026 点\\\\ h^T_{(t)}Wy_{(i)} \u0026 通用\\\\ v^T\\tanh(W[h_{(t)};y_{(i)}]) \u0026 合并 \\end{matrix}\\right. \\]\n详细的算法步骤是：\n首先准备编码器和解码器的隐藏状态 为每一个编码器的状态给出一个score 把所有score送到softmax层 把所有经过softmax后的score乘以对应的编码器的隐藏状态，得到一些向量 把所有这些向量对齐相加 把得到的结果发送给解码器 注意力机制分类 软注意力和硬注意力\n58.jpg\r硬注意力关注更小的部分，而软注意力关注点比较模糊、泛化。\n全局注意力和局部注意力\n全局注意力和之前提到的一样，所有隐藏状态都被用来计算输出权重。\n局部注意力可以看作是软注意力和硬注意力的混合，计算复杂度更低（比全局和软注意力），并且可微、方便训练（对比硬注意力）。\n注意力机制的应用 机器翻译 语音识别 图像描述生成 情感分析 几个研究领域 情感分类 老师的课上只介绍了一种理论：情绪轮理论\n其将情绪分解为8种基本情绪，根据强弱分为三个等级。复合情绪由基本情绪叠加得来。\n59.jpg\r文本情感分析 社交媒体上存在大量包含用户情感的文本，每一句留言都很可能包含了发布者的情感。有很多分析方法。\n基于词典的规则方法\n这是很传统、很早期的方法。主要围绕主客观判定和情感极性判定两方面展开。主要是从文档中提取与特定主体的正面或负面相关的情绪，通过使用语法分析器和情感词典进行语义分析。\n基于统计机器学习的方法\n机器学习方法主要是采用有监督的学习方式，在有标注的训练预料上训练一个情感分类器，然后用于未标注数据的情感极性预测。当然，他需要人工提取特征，并且很依赖标注数据。\n基于深度学习的方法\n基于深度学习的方法文本特征是自动提取的，通过神经网络学习文本中所蕴含的语义信息，达到情感分析的目的。可以利用大量无标注数据进行预训练，减少对标注数据的需求。解决传统方法的稀疏性问题。自动学习特征表示，更灵活。\n声音情感分析 主要是关于录音的特征分析。\n图像情感分析 主要是基于人脸特征点的分析。\n简介 通常，我们研究的情绪识别任务，会从人们脸上的表情来进行分析。\n通常，我们假设人的情感状态是可以从脸部的运动推断出来的。通常，这也叫emotional expressions或facial expressions。\n但是，实际上更为复杂。仅仅从简单的一些脸部运动来推断人的感受，并不是可靠的，例如\n60.jpg\r如果只靠表情分析，这可能甚至会有误导性的效果。\n这是一个反向推理的过程，即从特定的表情，推断到特定的情绪。一个鲁棒性好的（robust）的推理应该满足四个准则：可靠性、特异性、可推广性、有效性（Reliability, specificity, generalizability, and validity.）\n只有一个人的面部运动非常符合这四个准则时，我们才可以很好地反向推理出他的情绪。\n虽然研究确实证明了，面部表情和情绪并没有因果性，但是面部移动也不是毫无意义和不含信息的。\n情感分析的相关研究 1967年，Mehrabian认为，人的情绪由55%的面部表情、38%的supporting language和7%的oral language组成。\n1971年，Ekman和Friesen把情感分为六种基本情感。\n面部参数化（Facial Parameterization） FACS\n1977年，Ekman和Friesen建立了面部动作编码系统（Facial Action Coding System (FACS)）。这是一个基于面部肌肉的方法。\n61.jpg\r这个系统识别单独或成组的、引起面部表现变化的各种面部肌肉。这些面部的改变和导致它改变的肌肉，叫做一组Action Units（AU）。人脸由许多这样的AU组成。\nAU有些是additive的，有些是non-additive的。每一种表情都可以表述为一个或多个additive或non-additive的AU的组合。（既然可以组合，那我就不明白它哪里non-additive了，这ppt也真是写的不明不白）\nFAPs\n面部动画参数（Facial Animation parameters(FAPs)）是MPEG-4 SNHC标准的一部分。\nFAPs是一整套面部动作的参数，包括头部运动、舌头、眼睛、嘴巴控制。FAPs和AU都很关注肌肉运动。\n每个FAP，都是一个面部动作，这个动作使得脸从中性状态中变形。\nFAP值表示FAP的大小，也就代表了这个从中性状态变形的大小程度。例如：微笑和大笑。\n人脸检测方法 Kanade-Lucas-Tomasi跟踪器\n该方法将过去和当前帧中固定大小的特征窗口之间的匹配度量定义为窗口上强度差的平方和。\n62.jpg\r比率模板跟踪器（Ratio Template Tracker）\n比例模板包含了16个区域和23个关系。\n63.jpg\r左边的比例模板套在右边的人脸上如图。\n特征空间（Eigenspace）方法\n64.jpg\r模块化特征空间描述符用于识别具有显著特征的人脸图像。\n本征面定义了样本图像的子空间，称为“面空间（face space）”。\nPersonSpotter系统\n首先通过图像的差异来定位包含运动物体的区域。然后使用皮肤检测器和凸检测器来识别和跟踪面部。这个方法对于背景有很好的鲁棒性。\n65.jpg\rPBVD\n它的跟踪器使用了一个三维的线模型（使用贝赛尔曲线）。这个PBVD模型也可以用于分析面部动作。\n66.jpg\rCandide face model\n使用三角面搭建模型。\nAdaBoost方法\nAdaBoost其实是个集成学习方法，也会提高准确度并且不会提升多少时间复杂度。用在人脸检测上，识别脸和分离背景的速度很快。\nAdaBoost级联了分类器，一个分类器的输出接到下一个分类器的输入\n67.jpg\r缺点是对噪声和异常数据比较敏感。\n空间比例模板（Spatial Ratio Template）方法\n相比于比例模板，其融入了黄金比，在不同的光照条件下表现更好。\nHaar分类器方法\nHaar分类器在实时环境中有鲁棒性，缩放容易、选取正确率高。Haar特征主要考虑提取脸的边缘、线条、动作和肤色。\n68.jpg\rContours（轮廓）方法\n基于人脸轮廓的识别方法，并且可以用在视频序列上（实时计算）。\n69.jpg\r自适应肤色方法\n肤色是很有用的特征。虽然RGB和CMY、YUV等颜色格式用的很多，但是在这里，用的更多的是YIQ和YUV\n人脸特征提取技术-基于几何的方法 基于几何的方法关注永久的特征。例如眼镜、额头、鼻子、嘴巴。算法用预定的几何位置描述这些东西的形状、位置等。\n面部组成部分的（空间）关系向量化后就可以用于训练。可以通过测量重要部分的位移来识别面部表情。\nASM\n70.jpg\rAAM\nAAM的作用是，当形状和纹理和训练结果相比出现变化时，及时调整形状和纹理模型。\n为了识别面部表情，AAM从FACS中提取先验知识。\n72.jpg\r尺度不变特征变换（scale invariant featuretransform(SIFT)）\n基于部位的SIFT，使用固定尺寸和方向的SIFT描述符来描述面部部位。\n这种表述继承了SIFT特征对于光照条件的容忍性，并且计算很简单。\n特征点追踪\n这可能是使用频率最高的方法。\n通过把人脸的特征点直接写到xy坐标上来表述人脸。当中性人脸存在时，这个方法可以用来减少识别误差。但是它对光照变化比较敏感。\n人脸特征提取技术-基于外观（Appearance）的方法 外观特征（Appearance Feature）通常是从脸的全局或者是从包含不同信息的不同人脸区域中提取的。\n基于外观的算法通常关注瞬态特征（例如皱眉、鼓气），这些特征描述脸上的材质、（光照）强度、直方图和像素值。\n外观信息对于噪声更不敏感，能检测更多种类的面部表情，对于微小的表情的检测更为重要。\n这些特征提取技术适用于RGB和热模态（thermal modalities），但是不适用于3D信息，因为它不传达外观信息。\n本地二进制模式（Local Binary Pattern(LBP)）\n在LBP中，人脸被切分为多个小方块，每个小方块的二进制信息都会被计算直方图（histogram）。最后这些小直方图会被连接起来用作全局特征\n73.jpg\rGabor-小波（wavelet）\n这个方法对波浪状结构的图片敏感，例如皱纹、脸上的凸起等。\n但是，分析的结果的维度会非常大，对于实时计算来说是困难的。\n74.jpg\rHappy等人对LBP的改进型\n它们借鉴LBP，但是块大小是不同的，然后依然计算直方图作为特征向量。这些特征向量导入主成分分析中进行分类。\n梯度HoG直方图（Histogram of Gradients HoG）\nHoG通过图像所包含的（人脸）边缘的方向来表示图像。HoG通过在图像上应用梯度算子。并根据梯度大小和方向来编码输出，从而提取局部特征。\n首先，还是像LBP一样分成小格子（cell）。然后直方图绘制这些小格子的（梯度）大小和方向的数据。然后在更大的块（block）中，组合这些小格子。如果有重叠，那么维度会增加。\nGhimire等人的研究\n实际上，并不一定总是要关注全局，不同的脸部的区域有不同程度的重要性。例如眼睛和嘴巴能提供的信息比额头和脸颊要多。\nGhimire等人就把脸部分成了域特定（domain-specific）的局部区域，然后再从这些地方提取区域特定的外观特征。\n其中比较重要的局部区域，考虑使用增量搜索方法（incremental search approach），通常可以降维，也可以提高识别准确率。\n75.jpg\r红外图像（infrared images）方法\n一些研究者试图研究红外图像的人脸识别，而不是可见光图像。\nShenetal等人，使用红外图像，从人脸的局部区域中，提取横向和纵向的温度变化信息。他们的分类算法是使用了AdaBoost的K近邻。\n分类器 SVM\n人脸识别这一块，使用一对一的、包含径向基（RBF）核函数的SVM。当然，就只能做二分类，识别一个样本属不属于该类型。做多分类要用组合多个分类器的方法。\n最近邻\n最近邻是最简单的非参数算法，决策域是整个训练集。\nNB/TAN分类器\n如果最近邻（NB）的训练集比较小，那么就存在准确率和最大分类误差的折衷。\n研究者发明了一种更好的分类器：树增广朴素贝叶斯（Tree Augmented Naive Bayes (TAN)）\n作为一个一般的经验法则，数据不足时使用NB，如果有足够的数据可用时，则用TAN。（我就不明白了，前面说NB的训练集较小的时候有问题，现在又说数据不足时用NB？）\nDRML 深度区域和多标签学习（Deep region and multi-label learning）是一个区域层（region layer）。使用前馈函数来诱导重要的面部区域，强制学习的权重去获取脸部的结构信息。\n整一个网络是一个可以端到端训练的。并且自动学习对局部区域内固有变化具有鲁棒性的表示。\n对于静态图片的深度面部表情识别网络（Deep FER networks for static images） 预训练和微调（Pre-training and fine-tuning） 一个多级的微调策略可以实现更好的性能表现。\n第一层的微调，是在预训练模型上使用FER2013.\n第二层的微调基于目标集（例如EmotiW）的训练部分，用于细化模型去适应更具体的数据集（例如目标机集本身）。\n虽然预训练和微调可以解决过拟合问题，但是可能会削弱对应情感的表示能力。为了消除这个影响，一个两层的训练算法——FaceNet2ExpNet被提出。\n多样化网络输入 只使用一整章对齐的脸的RGB图像来作为网络的输入，学习用到的特征可能会丢失一些重要信息。例如：均匀或规则的纹理信息；图像缩放、旋转、遮挡和关照方面的不变性，这可能代表了FER的混杂因素。\n76.jpg\r辅助（Auxiliary）块和层 许多研究都建议添加一些良好设计的辅助块或层，从而加强对于情感相关的特征的表示能力。通常基于CNN的架构。\n77.jpg\rHu等人嵌入了三种不同的监督块。SS块浅层监督，IS块中间层监督，DS块深层监督。\nCai等人提出用Island loss层。island loss在特征提取层中计算，softmax loss在决策层中计算，然后被用于监督CNN的训练。\nLiu等人提出用(N+M)-tuple clusters loss层。\n网络集成 在特征层的集成，最常用的策略师把几个不同的网络学习到的特征连在一起，作为一个单独的特征向量。\n在决策层的集成，最常用的有三种方法：投票多数、简单平均、加权平均。有研究者甚至提出了一种三层委员会架构，使用混合决策来获取更多样化的决策。\n多任务网络 许多现有的FER网络只关注单任务，并且学习的特征都是对表情敏感的，而不考虑其他潜在因素的相互作用。\n然而在现实世界中，面部表情被许多因素影响，例如头的姿势，光照和受试者身份（面部形态）。\n为了解决这个问题，多任务学习被引入，来转换其他相关任务的知识和理清妨害因素。\n在MSCNN中，一对图像被送到MSCNN来训练。\n将具有交叉熵损失的表情识别任务和具有对比损失的人脸验证任务相结合来训练MSCNN，前者学习表情间变化较大的特征，后者减少表情内特征的变化。\n数据集 在FER领域，有许多数据集被用在广泛的实验中。\n传统意义上，人脸表情数据通常都是在2D静态图片或者2D视频上获取的。但是基于2D的数据比较难以处理较大的姿势变化和较微小的面部动作。而3D的面部表情分析将有助于检查细微的表情变化。\nThe Japanese Female Facial Expression (JAFFE)\n213张图片，7种（6种基础表情+1种中性表情）。总共有10个日本女性作为模型。每个图像是\\(256\\times 256\\)\nThe Karolinska Directed Emotional Face (KDEF)\n4900张人类表情的图，总共有70个人，每个人都包含7种表情，每个表情有5个不同的角度。大小为\\(562\\times 762\\)\nFER2013\n一个由谷歌图像搜索API自动收集的大型无约束数据库。所有图像都缩放到了\\(48\\times 48\\)。28709的训练集，3589的验证集，3589的测试集。标签有7种表情。\nCompound Emotion (CE)\n5060张图，22种基础、组合表情，总共来自230个人，130女性，100男性，年龄平均23.\n还有很多，但是我觉得对于复习意义不大，不记录了。\n未来工作的挑战 光照 变化的光照会影响特征的提取任务。也有些预处理技术被用来处理光照问题，但是，我们仍然需要一种鲁棒的方法来克服这些困难。\n遮挡 在真实情况中，有很大可能性，脸面前会有遮挡物，例如眼镜（或许还有口罩）。这些遮挡会导致分类不精确，因为很难从非遮挡区域中识别出主要的视觉特征。\n面部遮挡有几个显著的特征，使其特别难以处理：\n遮挡的类型可能会取决于面部出现的情况 遮挡有很多类型，并且可能同时存在 大多数类型的遮挡通常还不会固定在脸上的特定位置 不同类型的遮挡可能有不同的持续时间 由于导致遮挡的对象的可变性，导致遮挡的视觉特性（例如形状、外观和大小）通常是不可预测的；例如太阳镜、3D眼镜、护目镜是不同的。 未来的工作包括：\n全面的基准数据集，包括各种类型的频繁自然面部遮挡 致力于设计面部遮挡检测技术，以可靠地确定面部遮挡的具体参数，如类型和位置 利用多种模式之间的时间相关性并结合多种模式的融合特征来对抗面部遮挡的研究 在多个真实数据集上深入研究面部遮挡对非原型自发情绪表现的影响 姿势变化 头部的姿势变化可能会导致“自遮挡”。现在大多数研究都是针对脸部的正面视角，只有一小部分关注到了多姿势的表情识别，导致整体效果不佳。\n数据集偏差 数据偏差和不一致的标记在不同的面部表情数据集之间非常常见。比如数据采集的条件不同，打标记的人有主观性，可能会错误区分anger和disgust等。\n未来的工作是：消除这种混淆；同样准确的识别所有表情\n自发表情（Spontaneous expressions） 人的表情有时候是故意非常夸张的，看起来很做作。有些研究正在将重点转移到研究这些自发表情上，通常会通过一些视频和电影来引发情绪。\n引发开心的表情很容易，但是引发恐惧和愤怒却很难。另外，研究人员不能拿自己的脸来当数据，因为他们知道自己会用数据来干什么，就像医疗需要双盲试验一样，获取数据也应该双盲或者单盲。研究者还要从不同的光照和遮挡下采集数据。\n未来的工作：找到捕获愤怒和恐惧表情的特征的方法。找到能引发恐惧和愤怒的影片。\n多模式感情识别（Multimodal affect recognition） 例如和肢体语言的情绪、情绪的光谱图结合，构成一个更高层次的框架。从而提供补充的信息，具有更好的鲁棒性。\n由于面部表情的互补性，模态融合正成为一个研究方向。\n红外图像。 来自3D人脸模型和生理数据的深度信息。 附录 熵 https://zhuanlan.zhihu.com/p/149186719\n具体可以看上文。信息论中的熵是指：无损编码事件信息的最小平均编码长度。假设所要表述的信息有\\(N\\)种可能性，每种可能性\\(i\\)出现的概率为\\(P(i)\\)，那么，熵为\n\\[-\\sum_i P(i)\\log_2 P(i) \\]\n这个东西可以理解为，\\(-\\log_2 P(i)\\)的期望，记作\\(H(P)\\)，那么有\n\\[H(P) = E_{x\\sim P}[-\\log P(x)] = -\\sum_i P(i)\\log_2 P(i) \\]\n如何理解\\(-\\log P(i)\\)？注意当每种情况等可能时，编码的长度就需要至少（并且足够）\\(\\log N\\)，而\\(\\log N = -\\log\\dfrac{1}{N} = -\\log P\\)。上式只是拓展到不同概率的事件的情况。所以\\(-\\log P(i)\\)可以理解为该事件的平均编码长度。所有事件的平均编码长度就是概率的加权平均，也就是熵了。\n对于某个特定的数据集，我们用试验频率代替概率，得到熵为\n\\[H(D) = -\\sum^K_{k=1}\\dfrac{|C_k|}{|D|}\\log\\dfrac{|C_k|}{|D|} \\]\n交叉熵 熵是假设了我们知道每种可能性的概率分布，但是我们在实践中通常不知道概率分布，只有一个预估的概率分布\\(Q\\)。于是我们就只有一个预估的熵\n\\[E_{x\\sim Q}[-\\log Q(x)] \\]\n我们希望这个熵尽可能接近理论上的熵，于是我们引入了交叉熵\n\\[H(P,Q) = E_{x\\sim P}[-\\log Q(x)] \\]\n这个\\(P\\)可能是建模得到的，也可能是大量统计观测得到的。在机器学习中可能就是样本集的，而\\(Q\\)则是预测器给出的。\n可以证明\\(H(P,Q)\\geq H(P)\\)，我们的训练目标就是使得交叉熵尽可能的接近真实的熵。所以可以把交叉熵用作损失函数。\n假设五分类任务，训练集用one-hot方式编码，即第一类编码为\\([1,0,0,0,0]\\)，第二类编码为\\([0,1,0,0,0]\\)，以此类推。即每一个样本都确定地属于一个类（可以算出熵都为\\(0\\)）。\n假设分类器A给出的预测是\\([0.4,0.3,0.1,0.1,0.1]\\)，分类器B给出的预测是\\([0.9,0.1,0,0,0]\\)。那么\n\\[\\begin{align*} H(P,Q_A) \u0026 = -\\sum_i P(i)\\log Q_A(i) \\\\ \u0026 = -(1\\log 0.4+0\\log 0.3+0\\log 0.1+0\\log 0.1+0\\log 0.1)\\\\ \u0026 = 0.916 \\end{align*} \\]\n\\[\\begin{align*} H(P,Q_B) \u0026 = -\\sum_i P(i)\\log Q_A(i) \\\\ \u0026 = -(1\\log 0.9+0\\log 0.1+0\\log 0.1+0\\log 0.1+0\\log 0.1)\\\\ \u0026 = 0.152 \\end{align*} \\]\n显然分类器B的交叉熵更低，实际上预测结果也更好。\n特别的，对于二分类问题，其交叉熵就为\n\\[-P\\log Q - (1-P)\\log(1-Q) \\]\n机器学习中，一般把标签作为\\(P\\)，预测作为\\(Q\\)，于是就有\n\\[-y\\log h_\\theta(x) - (1-y)\\log (1-h_\\theta(x)) \\]\n矩阵/向量求导技术 向量变量与标量函数 定义\\(f(x), x=[x_1,x_2,\\cdots,x_n]^T\\)，即变量是向量，而函数值是标量，则其导数为\n\\[\\dfrac{\\partial f(x)}{\\partial x} = \\bigg[\\dfrac{\\partial f}{\\partial x_1},\\dfrac{\\partial f}{\\partial x_2},\\cdots,\\dfrac{\\partial f}{\\partial x_n}\\bigg]^T \\]\n其求导满足普通的线性、乘法、除法法则。下面给出几个常用公式\n\\[\\dfrac{\\partial c}{\\partial x} = \\vec{0},\\ c是常数 \\]\n\\[\\dfrac{\\partial x^Ta}{\\partial x} = \\dfrac{\\partial a^Tx}{\\partial x} = a,\\ a是常数向量 \\]\n\\[\\dfrac{\\partial x^Tx}{\\partial x} = 2x \\]\n\\[\\dfrac{\\partial x^T Ax}{\\partial x} = Ax+A^Tx,\\ A是常数矩阵 \\]\n\\[\\dfrac{\\partial a^Txx^Tb}{\\partial x} = ab^Tx+ba^Tx,\\ a,b是常数向量 \\]\n矩阵变量与标量函数 定义\\(f(X),X_{m\\times n}\\)，其导数定义为\n\\[\\dfrac{\\partial f}{\\partial X}= \\begin{bmatrix} \\dfrac{\\partial f}{\\partial x_{11}} \u0026 \\dfrac{\\partial f}{\\partial x_{12}} \u0026 \\cdots \u0026 \\dfrac{\\partial f}{\\partial x_{1n}}\\\\ \\dfrac{\\partial f}{\\partial x_{21}} \u0026 \\dfrac{\\partial f}{\\partial x_{22}} \u0026 \\cdots \u0026 \\dfrac{\\partial f}{\\partial x_{2n}}\\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots\\\\ \\dfrac{\\partial f}{\\partial x_{m1}} \u0026 \\dfrac{\\partial f}{\\partial x_{m2}} \u0026 \\cdots \u0026 \\dfrac{\\partial f}{\\partial x_{mn}} \\end{bmatrix} \\]\n其同样满足线性、乘法、除法运算法则。常用公式如下\n\\[\\dfrac{\\partial c}{\\partial X} = 0_{m\\times n},\\ c是常数 \\]\n\\[\\dfrac{\\partial a^TXb}{\\partial X} = ab^T \\]\n\\[\\dfrac{\\partial a^TX^Tb}{\\partial X} = ba^T \\]\n\\[\\dfrac{\\partial a^TXX^Tb}{\\partial X} = ab^TX+ba^TX \\]\n\\[\\dfrac{\\partial a^TX^TXb}{\\partial X} = Xba^T+Xab^T \\]\n","date":"2023-11-28T10:21:26+08:00","image":"https://kegalas.top/inferior/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E8%AE%A4%E7%9F%A5%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/cover_hudfaf5e1d7526a380ad7b29f8ee060abf_123913_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E8%AE%A4%E7%9F%A5%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"机器学习+模式识别+认知计算综合学习笔记"},{"content":"绪论 1.jpg\r2.jpg\r数制与码制 在计组、数电中已经学过这部分内容，这里着重讨论硬件的操作。\n有符号数加减运算的溢出 设次高位向最高位的进位标志为\\(C_p\\)，最高位和次高位进位相加的进位标志为\\(C_s\\)，则当且仅当\\(C_p\\oplus C_s=1\\)时，计算溢出。\n8086CPU中PSW的OF标志位表示有符号数运算是否溢出。\nCPU的结构和功能 外部结构 3.jpg\r微处理器的外部结构表现为数量有限的输入输出引脚（共40个），这些引脚构成了微处理器级总线\n这些引脚用来与存储器、IO设备交换信息，以及输入输出必要的信号。\n通过分时复用技术，实现了引脚的复用。对于存储器，总共地址线为20条，寻址范围1M。对于IO设备则只有16条地址线。采用了独立编址的方式。控制线和数据线分别只有16条。也就是最大表示范围为\\(0\\sim 2^{16}-1\\)\n内部结构 4.jpg\r功能结构 5.jpg\r寄存器组织 通用寄存器 8086一共有8个通用寄存器，虽然通用并不意味着可以随便交换使用，还是有些操作只能用某个寄存器实现。\n数据寄存器\n一共有4个，分别叫AX，BX，CX，DX。每个都是16位大小的，但也可以拆成两个8位的使用。例如AH、AL分别表示AX的高8位、低8位。BH、BL表示BX的。\nA的意思是Accumulator，即累加器。A在以前是8位寄存器，X代表miX，AX就为16位，而之后的EAX的E是Extend，为32位。再之后的RAX是64位。这些寄存器一般用来做运算操作。\nB的意思是Base Register，基址寄存器，用于表示数据段的段内地址。\nC的意思是Count Register，计数器，用于表示循环计数。\nD的意思是Data Register，数据寄存器，用于表示IO端口的地址。\n地址指针与变址寄存器\n总共有4个，SP、BP、SI、DI。都是16位。前两个是地址指针\nSP为Stack Pointer，堆栈指针，用于保存堆栈段的段内偏移地址。\nBP为Base Pointer，基址指针，用于表示段内偏移地址，默认段地址由SS提供。\nSI为Source Index，源变址寄存器。\nDI为Destination Index，目的变址寄存器。\n这两个寄存器用于字符串操作中，源操作数和目的操作数的段内偏移地址。\n段寄存器 总共有4个，CS、DS、ES、SS。都是16位。\nCS为Code Segment，代码段寄存器。用于保存当前执行程序的段地址，不能做被用户操作。\nDS为Data Segment，数据段寄存器。用于保存数据段的段地址。\nES为Extra Segment，附加数据段寄存器。用于保存附加数据段的段地址。\nSS为Stack Segment，堆栈段寄存器。用于保存堆栈段的段地址。\n控制寄存器 总共有2个，IP、PSW。都是16位。\nIP为Instruction Pointer，指令指针寄存器。始终指向下一条要执行的指令的偏移地址（段地址由CS提供）。相当于一般讨论中的程序计数器PC。IP的值不能被用户更改。\nPSW为微处理器状态字。虽然有16位但是有用的只有其中9位。\n6.jpg\r其中CF、PF、AF、ZF、SF、OF这6个是状态标志，反应ALU运算后的结果状态。\nTF、IF、DF这3个是控制标志，用来控制CPU的运行状态。\nCF表示最高位有无进/借位标志，有进位为1。\nPF表示低8位含有1的个数，偶数个为1，奇数个为0。\nAF表示D3位有无进/借位，有则为1。D3为即为8位二进制的第3位（从0位开始算）\nZF表示运算结果是否为0，是则为1。\nSF为符号位，和数字的符号位一致。即等于D7或者等于D15。\nOF之前介绍过，表示是否溢出，是则为1。\nDF为方向标志，在进行字符串操作时，CPU每执行一条串操作指令，对源或(与)目的操作数的地址会自动进行一次调整。当DF为0时，SI/DI自动递增；DF为1时，SI/DI自动递减。在汇编中CLD指令把DF置0，STD指令把DF置1。\nIF为外部中断允许标志，IF为1时，CPU能响应外部可屏蔽中断，即开中断状态。IF为0时为关中断状态。显然可以推知，对内部中断和外部不可屏蔽中断不起作用。STI指令置1，CLI指令置0。\nTF为陷阱标志。当TF=1时，CPU每执行完一条指令便自动产生一个内部中断(类型为1)，转去执行一个中断服务程序，用户可以借助中断服务程序来检查每条指令执行的情况，称为单步工作方式，常用于程序的调试(Debug)。没有专门的设置指令。\n存储器和IO组织 8086有20条地址线。\n对于存储器用了全部的20条，寻址范围为1M，最小单位为字节，所以总共的空间为1MB。地址范围为00000H~FFFFFH。\n对于IO端口则只使用低16条，寻址范围为64K。\n由于寄存器全都是16位的，要表述20位的地址，就要用到两个寄存器。这两个寄存器加起来可以有32位，所以所有地址都可以有多重表示方式。之后会介绍。\n数据在存储器中的存储 字节型数据\n例如指令DB 5, -12, 'a'，存放三个字节型数据，它们顺序存放在内存中。\n7.jpg\r字型数据\n字是16位，即两个字节。其低8位放在低地址，高8位放在高地址。例如1234H放在内存中，指令为DW 1234H，内存中就是34，12。这也叫做小端序。\n整个字型数据的地址是低字节的地址。8086字的地址可以从任何地方开始。当地址为偶地址时，称为对准的；地址为奇地址时，称为未对准的。\n8.jpg\r8086的数据总线为16位，所以存取一个字节只需要1个周期。而对于字，对准的需要1个周期，未对准的需要2个周期。\n存储器的分段 由于寄存器全都是16位的，要表述20位的地址，就要用到两个寄存器。8086采用分段的方式，把地址空间分为若干个逻辑段。即20位地址表示为5位16进制数，例如12345H，1234H表示段地址，5H表示段内偏移。即高16位表示段地址，且每个段的起始地址可以被16整除（即XXXX0H可以被16整除）。\n更具体的说，由于用两个寄存器表示，就可以写作1234H:0005H，前面的为段地址的寄存器，后面位段内偏移的寄存器。\n显然的，这样操作，1MB的空间最多可以分为64K个段。每个段也最多可以有64KB的大小。但是我们最多也就1MB内存的大小，而不是64KB*64K这么大的空间。我们几乎可以立即得到，段是可以重叠的，地址可以有多重表示方式。\n事实上、\\(物理地址=段地址 \\times 10H+偏移地址\\)。这样，00100H就可以表示为0000H:0100H和0010H:0000H，等等。\n在硬件实现上，把段地址的寄存器（如CS、DS、ES、SS）的内容左移4位，加上偏移寄存器（如BX、BP、SP、SI、DI）中的内容，形成20位地址。\n程序的分段存储 每个程序使用的内存可以分为三个段，即代码段、数据段、堆栈段。\n9.jpg\r其中代码段的物理地址由CS:IP表示，数据段由DS/ES:BX/SI/DI表示，堆栈段由SS:SP/BP表示。\n8086汇编 语句类型 指令\n每条指令都对应一条CPU能执行的语句，即对应一条机器语言。\n伪指令\n不对应机器语言的代码，CPU无法进行操作。只是给汇编器看的，告诉汇编器如何汇编。\n宏指令\n用户自定义的一条能完成某一特定功能的新指令，由指令和伪指令组成，在程序汇编时展开，用指令和伪指令替代宏指令\n语句格式 [名称:] 助记符 [操作数] [;注释]\n其中名称有点像C/C++里面的label，给goto用的那个label。为可选项。\n助记符就是指令、伪指令、宏指令的名字。必选项。\n操作数，具体要看助记符要使用什么操作。有时候没有操作数，算是可选项。\n注释用;开头，可选项。\n常数和表达式 常数分为数值常数和字符（串）常数。\n二进制数以B结尾，八进制数以O结尾，十六进制数以0开头，H结尾。\n字符串用单引号括住。\n表达式用的符号有算术、逻辑、关系等\n+,-,*,/,MOD是算术操作\nAND, OR, XOR, NOT是逻辑操作（其实是按位运算，不是逻辑与或）\nEQ, NE, LT, GT, LE, GE是关系操作\n这些运算符只能给常量使用，不能给寄存器使用。变量名使用是把变量名当作其偏移地址常数使用。\n另外，关系判断中，如果为真，则所有位全取1，为假则全取0.\n名称（标号） 前面提到，名称和goto里使用的label差不多。以冒号结尾，其后半部分的语句可以在下一行也可以在同一行。\n标号还有一些属性，例如可以代表标号所在段的段地址，在段内的偏移，以及其类型。其分为两类，如果标号只在本段内使用，则其为NEAR型，如果在段间使用，则为FAR型。\n变量 变量是用伪指令来表达的。分为五种类型\nDB，1字节变量 DW，字，即2字节变量 DD，双字，即4字节变量 DQ，长字，即8字节变量 DT，10字节变量。 变量可以有名称，但是名称不需要冒号。一个伪指令可以包含多个数值，用逗号分隔。例如\nVAR1 DB 12H, 0A5H, 18+20, 50/3, 0, -1 它是单字节的，在内存中存储如下（注意这里内存+1不像C语言的指针+1是偏移一整个类型，这里就是偏移一个字节）\n地址 内容 VAR1 12H VAR1+1 A5H VAR1+2 26H VAR1+3 10H VAR1+4 0 VAR1+5 FFH 由于x86是小端序，在2字节存储时\nVAR2 DW 12H,$+1 其在内存中为\n地址 内容 VAR2 12H VAR2+1 00H VAR2+2 09H VAR2+3 00H 此处$表示当前汇编语句的偏移地址（假设前面已经定义VAR1），可以看到，逗号分隔的前面的数值算做了2个字节的偏移。再加上前面的6个字节，$表示8，那么8+1=9；另外$的长度为字形\n另外，可以用?表示保留空间，但不预先赋值\nVAR3 DB ?, ? 利用DUP，可以表示重复的声明\nVAR4 DB 3 DUP(?) ; 这一句保留了3个未赋值的DB VAR5 DB 4 DUP(0FFH, ?) ; 而且内部参数是可以有多个的，就保存了四个0FFH, ?的数据 VAR6 DB 3 DUP(55H,2 DUP(77H)) ; 而且还可以嵌套 表达字符串时，只能用DB和DW\nVAR7 DB \u0026#39;ABCD\u0026#39; ; 其等价于DB \u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;或者DB \u0026#39;ABC\u0026#39;, \u0026#39;D\u0026#39;等 VAR8 DW \u0026#39;AB\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39; ; DW型保存字符时，要么两个字符，要么一个字符，不能多 ; 其仍然遵循小端序，即B在低位，A在高位。或者C在低位，00H填充高位 变量也有类型：段地址、段内偏移、类型、长度、大小。长度为第一个DUP前的系数（没有DUP则为1），大小不是占用空间大小，是类型乘以长度。类型即为变量字节数（1/2/4/8/10）。可以用伪代码获取这些属性，获取的都是立即数常数。\nMOV AX, SEG VAR1 ; 获取段地址 MOV AX, OFFSET VAR1 ; 获取段内偏移 MOV AL, TYPE VAR1 ; 获取类型 MOV AX, LENGTH VAR1 ; 获取长度 MOV AL, SIZE VAR1 ; 获取大小 PTR操作符 相当于汇编的强制类型转换。\n类型 PTR 表达式 例如\nWORD PTR [BX] 其将BX指向的内存的大小当作字。避免运算过程中类型不确定的问题。\n数据寻址操作 即MOV命令。其格式如下\nMOV DST, SRC 把SRC里的东西放到DST里。根据DST和SRC的不同可以有很多种MOV操作。\n立即数寻址 MOV AX, 1200H 即源操作数为立即数。\n寄存器寻址 MOV AX, BX 两个寄存器的大小要匹配。另外CS不能作为目的操作数。\n直接寻址 MOV AX, [1200H] 其中[]括起来的东西代表偏移地址，其加上段寄存器（默认为DS）的段地址得到物理地址，再把物理地址里的东西给AX。\n可以指定段寄存器\nMOV AX, ES:[1200H] SRC可以是变量\nMOV AX, VAR1+5 其中是把VAR1+5对应的地址开始的一个字给AX\n还可以把立即数给变量\nMOV VAR1, 2500 寄存器间接寻址 MOV AX,[SI] 把SI中的数据当作段内偏移，加上段地址（默认为DS）得到物理地址，再把物理地址里的东西赋值给AX。\n但是，[]中的寄存器只能是BX、SI、DI这三个\n也可以反过来进行\nMOV ES:[SI], AL 即把寄存器里的东西放到内存里。\n注意：\n不能DST和SRC都表示内存单元 不能直接把立即数当作SRC，内存当作DST，因为没有指定类型，应当： MOV WORD PTR [DI], 12H ; 而不是 MOV [DI], 12H 寄存器相对寻址 和上面的寄存器间接寻址相比，其就是增加了常数偏移。形式为\n\\[[REG\\pm 常数],常数[REG],变量名[REG],变量名[REG\\pm 常数] \\]\n其中REG可以为BX、BP、SI、DI，相比间接寻址多了BP。\n当偏移为常数时，段地址为段寄存器，BX、SI、DI默认为DS段，BP默认为SS段。\n偏移有变量名时，段地址取变量的段地址。\n例如\nMOV BX, [SI+5] MOV BX, 5[SI] ; 和上一行等同 MOV CX, VAR1[BX] ; 变量名意味着段地址以变量为准 MOV AL, VAR2[DI-15] 基址变址寻址 MOV DX, [BX][SI] 如上例，操作数在存储器中，其地址为一个基址寄存器和一个变址寄存器之和，即((BX)+(SI))为其内容。\n其中基址寄存器可以是BX和BP，变址寄存器可以为SI和DI。当BX时，默认为DS段，BP时，默认为SS段。\n基址变址且相对寻址 把上面的基址变址缝上相对寻址，即加上偏移\n\\[[BX/BP\\pm 常数][SI/DI\\pm 常数],常数[BX/BP][SI/DI] \\]\n\\[变量名[BX/BP][SI/DI],变量名[BX/BP\\pm 常数][SI/DI\\pm 常数] \\]\n有变量名时段由变量决定。\n隐含寻址 即操作码本身隐含（提前规定）了操作数地址。例如乘除、字符串操作指令\nMUL BL ; AX \u0026lt;- AL x BL MOVSB ; (ES:DI) \u0026lt;- (DS:SI), SI+-1, DI+-1 一般化的要求 CS不能做DST 立即数不能直接给段寄存器 存储单元不能直接到存储单元 段寄存器不能直接到段寄存器 立即数不能作为DST 源和目的至少有一个类型明确 源和目的都有类型时，类型必须一致 转移地址寻址操作 CPU要执行的指令的地址由CS:IP决定，即IP指向下一条要执行（取）的指令。CPU每执行一 条指令，IP自动增加，使之指向下一条指令。IP增加的值为当前指令的指令长度。\n可以通过改变CS：IP的内容实现程序的跳转 。\n如果程序转移后只有IP发生改变，则称为段内转移（近程、NEAR转移）。如果CS也改变，则称为段间转移（远程、FAR转移）。\n两种转移都有间接和直接寻址。\n段内直接寻址 JMP LABEL 直接用标号给出地址（是16位大小的偏移地址），且标号应与该指令在同一个段。也可以直接给出偏移地址，例如用常数。但是不能用变量，变量算地址保存在存储器中。\n实际汇编后，其会把IP修改为，JMP指令的下一条指令的IP+16位偏移的形式。16位偏移是汇编器直接在编译期转化为常数的。\n但是，段内偏移和JMP指令的偏移是不同的，段内偏移就是内存物理地址中的那个段内偏移，我们明文写给JMP的地址是这个，但是JMP生成的机器码，其偏移是下一行指令的地址加上的一个偏移，可正可负。\n段内间接寻址 JMP BX JMP VAR1 ; VAR1为字型变量 JMP VAR1[SI] 诸如此类，16位偏移地址保存在寄存器或存储单元里。之前介绍的各种存储器寻址方式都可以在这里使用。\n同前，我们写的16位偏移是段内偏移，但是JMP对应的机器码是相对于下一行指令地址的偏移。\n段间直接寻址 JMP LABEL 其中LABEL和当前指令不在一个段。LABEL给出了16位段地址和16位段内偏移。\n段间间接寻址 JMP VAR3 ; VAR3是双字变量，第一个字为段内偏移，第二个字为段地址 JMP VAR3[SI] ; 有效地址为(SI)+VAR3 也可以采用之前的存储器寻址方式。\n转移指令 无条件转移：JMP、CALL、RET、IRET\n条件转移：JZ、JC、JCXZ、LOOP等\n程序结构 段定义伪指令 \u0026lt;段名\u0026gt; SEGMENT (定位类型)(组合类型)(类别) ... 段体 ... \u0026lt;段名\u0026gt; ENDS 段名和普通的名称一致，具有段地址、偏移地址、定位类型、组合类型、类别五个属性\n定位类型\n定位类型 段起始地址（2进制） 段起始地址（16进制） 特性 含义 PAGE(页) xxxx xxxx xxxx 0000 0000 xxx00H 可以被256整除 本段从页的边界开始 PARA(节，默认) xxxx xxxx xxxx xxxx 0000 xxxx0H 可以被16整除 本段从段的边界开始 PAGE(页) xxxx xxxx xxxx xxxx xxx0 / 可以被2整除 本段从偶地址开始 PAGE(页) xxxx xxxx xxxx xxxx xxxx xxxxxH 起始为任意地址 起始为任意地址 组合类型\nNONE：表示本段与其他段不发生任何关系，该段有自己的段基址，是默认的组合关系。\nPUBLIC：在满足定位类型的前提下与其他模块的同名段连接在一起，形成一个新的逻辑段，共用一个段基址。\nCOMMON：表示产生一个覆盖段。连接时，把本段与其他同名段置成相同的起始地址，重叠在一起，共享相同的存储区，其段长度由最长的段确定。\nSTACK：在每个汇编程序中，只能且必须有一个堆栈段，连接时，将本段与其同名段连接成一个连续的STACK段，汇编程序自动初始化SS和SP寄存器，使SS的内容为该连续段的段基址，SP指向堆栈底部加1的存储单元。\nMEMORY： 表示本段在存储器中应定位在所有其他段的最高地址。\nAT\u0026lt;表达式\u0026gt;：表示本段从表达式指定的地址处开始装入，这样，在程序中用户就可以直接定义段地址，这种方式不适用于代码段。\n类别\n如代码段（\u0026lsquo;CODE\u0026rsquo;）、数据段（\u0026lsquo;DATA\u0026rsquo;）、堆栈段（\u0026lsquo;STACK\u0026rsquo;），注意包括单引号，其本质是字符串。也允许自定义类别，方便连接同类别的段。\nASSUME伪指令 ASSUME 段寄存器:段名[, 段寄存器2:段名2, ...] 通知寄存器把哪个段寄存器当作哪个段的寄存器，例如\nCODE SEGMENT ASSUME CS:CODE, DS:DATA, SS:STACK 注意：当程序运行时，DOS的程序加载器(Loader)负责把CS、IP、SS、SP初始化成正确的段地址和段内偏移地址（如果设定了合适的组合类型），因此用户在程序中就不必设置。但是，在用户程序中必须用两条指令对DS和ES进行初始化，以装入用户的数据段段地址。\nCODE SEGMENT ASSUME CS:CODE, DS:DATA, SS:STACK MOV AX, DATA ; DATA为段名，为立即数寻址 MOV DS, AX END伪指令 END 表达式 该伪指令表示整个源程序的结束，其表达式的值为该程序运行时的启动地址，它通常是第一条可执行语句的标号（例如START:）。\nPAGE伪指令 PAGE 参数1, 参数2 该伪指令可以为汇编过程产生的列表文件指定每页的行数“参数 1”和每行的字符数“参数 2”。\nTITLE伪指令 TITLE 正文 该伪指令可以为汇编过程产生的列表文件指定一个标题“正文”，它不能超过 60 个字符。在列表文件的每一页的第一行将打印出这个标题。\nLABEL伪指令 名称 LABEL 类型 该伪指令用来定义变量或标号的类型，它具有段地址与偏移地址的属性，但它并不占用内存单元。\n如果名称为变量名，其类型主要有三种：BYTE、WORD、DWORD\n如果名词为标号，其类型主要有两种：NEAR、FAR\nEQU伪指令和“=”伪指令 名称 EQU 表达式 很类似C语言的#define，即给表达式一个名称，可以在程序里随地替换。\n但是EQU定义的名称不能重复。而\n名称=数值 可以重复定义，值为最近一次定义的值\nORG伪指令 ORG 表达式 该伪指令用于为后续指令指定段内偏移地址，可以方便地将程序存入适当的地址，这一点对中断设计非常有用。\n程序的加载和运行 当用户编写的程序在必须加载到内存中从才能运行，这是由操作系统的程序加载器（Loader）实现的，其具体工作包括：\n决定使用存储器哪一部分的内存 初始化SS:SP和CS:IP(程序的第1条指令的位置) 当加载到内存的程序在计算机中运行时，计算机的控制由操作系统（OS）交给用户程序，当用户程序运行结束后，应再将控制权交回操作系统，可由系统中断程序中INT 21H的4C号程序实现。\n用户程序的代码前一定有100个字节的程序段前缀(Program Segment Prefix, 简称PSP)，PSP给 出了用户的可执行文件(.EXE)的若干控制信息。\n数据传送指令 数据传送指令被用来在寄存器、存储单元之间进行数据的传输。包含有：MOV、LEA、LDS、LES、LAHF、SAHF、XCHG、XLAT、PUSH、POP、PUSHF和POPF\n共同点有\n除了SAHF、 POPF，其他操作不影响PSW 有两个操作数时，第一个为目的，第二个为源 目的操作数的寻址不能是立即数和段寄存器CS MOV MOV DST, SRC 将SRC中的一个字节或一个字传送到DST。可以在立即数、存储单元、寄存器、段寄存器之间传送数据。\n注意事项如下\n操作数至少有一个类型是确定的 两个类型都确定时，类型要一致 不允许MOV [xxx], [xxx]，即内存-\u0026gt;内存 不运行段寄存器-\u0026gt;段寄存器 不允许立即数-\u0026gt;段寄存器 IP不能作SRC或DST CS不能作DST 立即数不能作DST 对于类型\n立即数是无类型的 不含变量名的直接寻址、寄存器间接寻址、寄存器相对寻址、基址变址寻址、基址变址且相对寻址的操作数也是无类型的(存储器寻址) 利用PTR操作符可指定或暂时改变存储单元的类型 立即数分为\n常数和常数表达式 所有由属性操作符得到的标号或变量的属性 前面提到一些不能进行的操作，指的是不能直接进行，但是我们可以间接进行\n内存-\u0026gt;内存不行，但是内存-\u0026gt;通用寄存器-\u0026gt;内存可以 立即数-\u0026gt;段寄存器不行，但是立即数-\u0026gt;通用寄存器-\u0026gt;段寄存器可以 段寄存器-\u0026gt;段寄存器不行，但是段寄存器-\u0026gt;通用寄存器-\u0026gt;段寄存器可以 CS和IP不能用MOV改变，但是可以通过跳转指令改变 LEA LEA REG16, MEM 取有效地址指令，即把MEM的16位段内偏移赋值给REG16。SRC是直接寻址，DST是寄存器寻址，用通用寄存器，一般用BX、BP、DI、SI\n其相当于\nMOV REG16, OFFSET MEM LDS/LES LDS REG16, MEM LES REG16, MEM 取地址指针指令。\nLDS把MEM的物理地址的高16位送入DS，低16位送入指定的REG16.\nLES把MEM的物理地址的高16位送入ES，低16位送入指定的REG16.\nLAHF/SAHF LAHF SAHF 标志传送指令。其没有操作数，也就是隐含寻址。LAHF把PSW的低8位赋值给AH，SAHF把AH赋值给PSW的低8位。\nXCHG XCHG DST, SRC 数据交换指令。该命令完成寄存器之间，或者寄存器与内存之间的内容交换（立即数不行）。即把DST和SRC的内容交换。\n但是寄存器不能是段寄存器，数据可以是字也可以是字节（但是类型要一致）。\nXLAT XLAT 字节交换指令。隐含寻址。将有效地址为(BX)+(AL)的内存的内容送进AL，常用来查表。\nPUSH/PUSHF PUSH SRC PUSHF 压栈指令。PUSH指令把SRC压入堆栈，即SP\u0026lt;-SP-2, (SP)\u0026lt;-(SRC)。PUSHF则把PSW压入栈。这里SRC必须是字型的，可以是通用、段寄存器，也可以是某种寻址的内存，但是不能是立即数。\nPOP/POPF POP DST POPF 弹栈指令。POP指令把栈顶弹出，赋给DST，即(DST)\u0026lt;-(SP), SP\u0026lt;-SP+2。POPF则是栈顶弹出给PSW。\n这里的DST和之前的SRC要求相同。但是DS不能作DST。\n堆栈注意事项 PUSH和POP成对使用 8086不会检测栈溢出，所以交给程序员自己检查 分配堆栈空间时要留有余量（20%以上） 算术运算指令 算术运算指令可以完成两个操作数的各种算术运算，例如加减乘除取余，以及其BCD数运算的调整运算。包括有：ADD、ADC、SUB、SBB、NEG、CMP、INC、DEC、MUL、IMUL、DIV、IDIV、CBW、CWD、AAA、DAA、AAS、DAS、AAM、AAD。\n它们可以分为6类\n加减法指令 比较指令 增量减量指令 乘除法指令 符号扩展指令 BCD数运算调整指令 一般情况下：\n涉及ALU的运算，不能使用段REG 设计ALU的运算，运算结果一般会影响PSW的6个状态位：OF、SF、ZF、AF、PF、CF 一般支持字节或字型数据 ADD/ADC ADD DST, SRC ADC DST, SRC 加法指令。ADD是把DST和SRC的值加起来再给DST；而ADC是把DST和SRC加起来，再加上CF（即PSW进位标志的值），再给DST。\nSRC可以取立即数、通用寄存器、内存（存储单元）。DST可以取通用寄存器和内存。但是SRC和DST不能同时为内存，并且两者类型要一致。\n只能处理字节或字，其他位宽的数据要分开来加。\n比如双字，可以先利用ADD完成低字的加法，再利用ADC完成高字和进位的加法。\nSUB/SBB SUB DST, SRC SBB DST, SRC 减法指令。SUB是(DST)\u0026lt;-(DST)-(SRC)，SBB是(DST)\u0026lt;-(DST)-(SRC)-(CF)\n指令的要求和ADD/ADC一样。\nNEG NEG DST 取负指令。即把DST的相反数传递给DST。\nDST可以取通用寄存器和内存，也会影响6个PSW位。其实质上是一个特殊的减法运算，即0-(DST)\nCMP CMP DST, SRC 比较指令。其完成DST-SRC，然后根据结果设置PSW的标志位，但结果不保存到DST。\n如果DST和SRC都是无符号数，如果DST\u0026gt;=SRC，则CF=0。若DST\u0026lt; SRC，则CF=1。\n如果都是有符号数，则两个数的大小由OF和SF共同决定。\n不溢出时，OF=0，差是正确的，则SF=0代表DST\u0026gt;=SRC，SF=1代表DST\u0026lt; SRC\n溢出时，OF=1，差是错误的，则SF=0代表DST\u0026lt;SRC，SF=1代表DST\u0026gt;= SRC\n简单记为，\\(OF\\oplus SF=0\\Rightarrow DST\\geq SRC\\)，\\(OF\\oplus SF=1\\Rightarrow DST\u003c SRC\\)\nINC/DEC INC DST DEC DST 增量减量指令。INC相当于DST++，DEC相当于DST\u0026ndash;。\nDST可以取通用寄存器和内存。INC和DEC只会影响AF、OF、SF、ZF、PF，但是不会影响CF。\nMUL/IMUL MUL SRC IMUL SRC 乘法指令。其中MUL对应无符号，IMUL对应有符号。目的操作数隐含在AX或AL中，SRC可以是通用寄存器和内存（不能是立即数），但是必须有确定的类型，而且只能是字节或字。\nSRC为字节时，AL和SRC相乘，其结果存在AX中。SRC为字时，AX和SRC相乘，其结果的高16位保存在DX，低16位保存在AX。\n这两个指令只对CF和OF有影响。如果字运算结果的DX为0，那么CF=0，OF=0，表示结果也为一个字。如果字节运算结果的AH为0，那么CF=0，OF=0，表示结果也为一个字节。否则CF=1且OF=1。\nDIV/IDIV DIV SRC IDIV SRC 除法指令。其中DIV对应无符号，IDIV对应有符号。总体上和乘法指令类似。\n当SRC为字节时，将AX中的16位二进制数除以8为二进制数（SRC），其结果的商保存在AL中，余数保存在AH中。\n当SRC为字时，DX与AX联合成为32位被除数，SRC作为16为除数。其结果的商存在AX中，余数存在DX中。\n商的正负性不用多说，讨论余数的正负性：余数的正负永远和被除数的正负相同（和数学上定义不一样）。\n这两个指令不影响PSW的标志位，但是不允许出现除数为0或者除法溢出。如果出现这两种情况，则没有意义，并且会引发中断。\nCBW/CWD CBW CWD 符号扩展指令。CBW将AL的符号扩展到AH中，形成一个字AX。CWD将AX的符号扩展到DX中，形成双字。\n即当D7=0时，扩展为AH=00H，D7=1时，扩展为AH=FFH。扩展双字同理。\nBCD数运算调整指令 在8086这里BCD码可以分为两类。\n分离BCD码，8位的寄存器中只包含一位BCD码，即D0~D3 组合BCD码，8位的寄存器中包含了两位BCD码。 BCD调整指令一共有6条\n助记符 功能 AAA 加法分离BCD调整 DAA 加法组合BCD调整 AAS 减法分离BCD调整 DAS 减法组合BCD调整 AAM 乘法分离BCD调整 AAD 除法分离BCD调整 加法调整指令\n众所周知，BCD码用4位空间表示0~9十个数字，就有6个信息位没用上。所以每一个BCD数字相加时，可能会溢出到这六个没用上的信息位上，此时要整体+6、进位来修正。具体可见计组和数电。\nAAA为分离BCD码加法运算后的调整指令，它会自己判断相加的结果（即AL）需不需要进行加6修正，如果需要则修正，否则不动。根据运算结果及修正结果的AF有无进位，进行下列操作：\nAF有进位，则AH=AH+1，CF=1，AF=1 AF无进位，则CF=0，AF=0 并清除AL中的高4位。\nDAA为组合BCD码的加法调整，表示对相加结果AL的低4位和高4位分别进行加6修正（如有必要）。DAA对AF、CF、SF、ZF、PF都有影响，其效果等同于ADD指令。\n例如\nMOV AH, 0 MOV AL, \u0026#39;4\u0026#39; MOV BL, \u0026#39;8\u0026#39; ; 这两个是因为，ASCII的数字，高4位都是0011，而低4位从0开始。而分离BCD码高4位无效，所以不需要清除高4位。 ADD AL, BL AAA 在AAA之前，(AL)=6CH，AAA调整后，(AX)=0102H，CF=1，AF=1\n这说明4+8=12\n又例如\nMOV AL, 34H MOV BL, 28H ADD AL, BL DAA 执行DAA前，(AL)=5CH，执行之后，(AL)=62H，CF=0，AF=1，SF=0，PF=0，ZF=0。这说明34+28=62。\n而\nMOV AL, 56H MOV BL, 73H ADD AL, BL DAA DAA前，(AL)=C9H，DAA后，(AL)=29H，CF=1，AF=0，SF=0，PF=0，ZF=0。这说明56+73=129。也就是说CF标志位成为了百位数。\n减法调整指令\n与加法正好相反，如果一位溢出时，要进行减6修正。\nAAS根据运算结果及修正结果的AF有无借位，进行下列操作\nAF有借位，则CF=1，AF=1 AF无借位，则CF=0，AF=0 并清除AL的高4位。\n而DAS则会对AF、CF、SF、ZF、PF都有影响，其效果等同于SUB指令。\n逻辑运算指令 总共有五种逻辑运算指令：AND、OR、XOR、TEST、NOT，格式分别为\nAND DST, SRC OR DST, SRC XOR DST, SRC TEST DST, SRC NOT DST 都是按位计算，其中TEST的功能和AND完全相同，但是不改变任何操作数，只改变PSW。\n逻辑运算指令的对象是字节或字。其中NOT指令对PSW无影响，其他指令使得CF=OF=0，ZF、SF、PF根据结果改变。AF无关。\nDST可以为通用寄存器、内存，SRC可以为通用寄存器、内存、立即数。但是二者不能同时为内存。\n移位指令 移位指令的共同特点为：正常影响PSW的SF、PF、ZF、CF和OF标志位，其中CF表示指令所移出的一位，OF=1表示移位前后符号位发生了变化。\n移位指令一般形式如下\nSHR DST, CNT 其中DST为通用存储器或内存，而CNT一般为常数01H或者寄存器CL\n逻辑移位 左移为SHL、右移为SHR。空位用0填补，移出的位放入CF（移出多位时，最后一个移出的放入CF）。\n算术移位 左移位SAL、右移为SAR。SAL与SHL完全相同，SAR则是空位由符号位补充，移出的位也是放入CF。\n循环移位指令 不带CF的循环移位，左移为ROL，右移为ROR。\n10.jpg\r带CF的循环移位，左移为RCL，右移为RCR。\n11.jpg\r标志位操作指令 用这些指令可以手动设置PSW里的位。\n指令 功能 CLC CF置0 STC CF置1 CMC CF取反 CLD DF置0 STD DF置1 CLI IF置0，关闭中断 STI IF置1，打开中断 转移指令 8086汇编中转移指令有两大类：无条件转移指令（如JMP、CALL、RET、IRET），条件转移指令（如JZ，JC，JCXZ，LOOP）\nJMP（无条件） JMP LABEL ; 段内或段间直接寻址，跳转到LABEL标号处 JMP REG16 ; 段内间接寻址，跳转到REG指定的段内偏移 JMP MEM ; 字单元段内转移，双字单元段间转移，跳转到MEM指定的位置 其中JMP LABEL不需要指明是Near还是Far。如果LABEL与该指令在同一个段内，则为段内直接转移，转移后CS不变，(IP)\u0026lt;-(IP)+DISP16。其中DISP16表示转移目的地址与JMP转移指令之间的16位偏移量（可正可负），这时也叫近程转移。如果偏移量可以用8位表示，那么(IP)\u0026lt;-(IP)+DISP8，这时称为短转移。如果LABEL和JMP在不同的段，则表示段间直接转移，转移后(CS)\u0026lt;-SEG LABEL，(IP)\u0026lt;-OFFSET LABEL，这时称为远程转移。\n而段内间接寻址则不是这么玩的，例如JMP BX他直接把BX内容赋值给IP，而没有什么偏移。\n段间间接寻址是用双字内存来实现的，第一个字是OFFSET，第二个字是SEG。\n有条件转移指令 只有当给定的条件满足时，才会转移到指定的地址。条件是看PSW中的标志位，由上一条指令产生。\n有条件转移的寻址方式只有段内直接转移一种，而且是短转移，即偏移只能有8位有符号数。\n指令 测试条件 功能 JC LABEL CF=1 有进/借位 JNC LABEL CF=0 无进/借位 JE/JZ LABEL ZF=1 相等 JNE/JNZ LABEL ZF=0 不相等 JS LABEL SF=1 负数 JNS LABEL SF=0 非负数 JO LABEL OF=1 有溢出 JNO LABEL OF=0 无溢出 JP/JPE LABEL PF=1 有偶数个1 JNP/JPO LABEL PF=0 有奇数个1 JA/JNBE LABEL (CF=0)且(ZF=0) 大于（无符号） JAE/JNB LABEL CF=0 大于等于（无符号） JB/JNAE LABEL CF=1 小于（无符号） JBE/JNA LABEL (CF=1)或(ZF=1) 小于等于（无符号） JG/JNLE LABEL \\((OF\\oplus SF)\\wedge ZF=0\\) 大于（有符号） JGE/JNL LABEL \\(OF\\oplus SF=0\\) 大于等于（有符号） JL/JNGE LABEL \\(OF\\oplus SF=1\\) 小于（有符号） JLE/JNG LABEL \\((OF\\oplus SF)\\vee ZF=1\\) 小于等于（有符号） 由于有条件转移的范围很小，所以可以把他搭配无条件转移来使用。\n循环指令 LOOP LABEL ; (CX)\u0026lt;-(CX)-1, CX!=0时转LABEL LOOPZ/LOOPE LABEL ; CX!=0且ZF=1时转LABEL LOOPNZ/LOOPNE LABEL ; CX!=0且ZF=0时转LABEL JCXZ LABEL ; CX=0时转LABEL 都是段内直接转移，且为短转移。\n字符串操作指令 8086有5类字符串操作，分别为字符串传送（MOVS）、比较（CMPS）、扫描（SCAS）、装入（LODS）、存储（STOS）\n字符串处理既可以按字操作，也可以按字节操作，每次处理一个单元。SRC和DST都是隐含寻址。约定如下：\n如操作数在存储器中，则SRC由DS:SI确定，DST由ES:DI确定；如果操作数在寄存器中，则使用AL（字节型），AX（字型） CPU执行操作后，SI和DI会自动修改，当DF=0时增加，DF=1时减小。字节操作时修改1，字操作时修改2。 字符串传送 MOVSB ; 字节传送 (ES:DI)\u0026lt;-(DS:SI) MOVSW ; 字传送 (ES:DI)\u0026lt;-(DS:SI) MOVS DST, SRC ; 使用变量名，字节或字传送，但是是隐含寻址 字符串传送对PSW无影响。\n注意MOVS的DST和SRC不是寻址，操作数仍然是隐含寻址的ES:DI和DS:SI。当DST和SRC都是字型时等同于MOVSW，都是字节型时等同于MOVSB。\n字符串比较 CMPSB CMPSW CMPS DST, SRC 三个操作都是(DS:SI)-(ES:DI)，然后设置PSW标志位。DST和SRC仍然是只标记大小，并不是寻址。\n字符串扫描 SCASB SCASW SCAS DST 字节扫描时，(AL)-(ES:DI)设置PSW。字扫描时，(AX)-(ES:DI)设置PSW。源操作数固定为AX或AL，目的操作数固定为ES:DI。\n字符串装入 LODSB LODSW LODS SRC 字节操作时，把(DS:SI)放入AL。字操作时，把(DS:SI)放入AX。源操作数固定位DS:SI，目的固定为AL或AX。不影响PSW。\n字符串存储 STOSB STOSW STOS DST 把AL或者AX放入(ES:DI)，操作数固定。不影响PSW。常用作对指定区域清零或者赋初值。\n重复前缀 实际应用中经常需要对整个字符串进行操作，此时需要重复指令。\nREP\nREP STR_OP ; 当CX!=0时，重复执行STR_OP。CX\u0026lt;-CX-1。例如REP STOSB REPZ/REPE\nREPZ STR_OP ; 当CX!=0且ZF=1，重复执行STR_OP。CX\u0026lt;-CX-1。例如REP CMPSB比较直到不相同 REPNZ/REPNE\nREPNZ STR_OP ; 当CX!=0且ZF=1，重复执行STR_OP。CX\u0026lt;-CX-1。例如REP CMPSB比较直到相同 子程序 子程序是一种汇编语言的封装，在和C语言中的函数是类似的。子程序通过修改CS和/或IP来实现调用，一般通过CALL指令。CALL好处在可以保存CS和IP，方便之后用RET指令返回。\nCALL CALL LABEL 如果LABEL可以用短转移。则IP入栈，(IP)\u0026lt;-(IP)+DISP8。如果只能用16位的近程转移，那么IP入栈，(IP)\u0026lt;-(IP)+DISP16。如果只能用远程转移，那么CS先入栈，IP再入栈。再把IP赋值OFFSET，CS赋值SEG。\nCALL OPR 如果OPR为REG16，IP入栈，(IP)\u0026lt;-(REG16)\n如果OPR为16位RAM，IP入栈，(IP)\u0026lt;-(MEM)\n如果OPR为32位RAM，CS入栈，IP入栈，(IP)\u0026lt;-(MEM)，(CS)\u0026lt;-(MEM+2)\nRET RET ; 用于段内返回，使得(IP)\u0026lt;-(SP)，弹栈 RETF ; 用于段间返回，先IP出栈，后CS出栈 RET n ; 完成RET（或RETF）后，(SP)\u0026lt;-(SP)+n 子程序伪指令 过程名 PROC [类型] ... ... RET 过程名 ENDP 其中PROC和ENDP是伪指令。过程名相当于C语言的函数名，给子程序取的名字。它可以看作标号。类型可以是Near也可以是Far，默认为Near。\n但是过程名没有命名空间，也不能嵌套声明（可以嵌套调用）。\n中断 8086有三种中断\n内部中断。包括除法错误（0号中断），单步执行（1号），断点中断（3），INTO指令中断（4），INT n中断（n） 外部非可屏蔽中断NMI（2）。包含存储器错误和关机等。 外部可屏蔽中断INTR。 中断处理程序是放在存储器中的。于是我们获取到中断编号后，就要从内存中获取该编号对应的中断处理程序的地址（包括CS和IP）。\n中断处理程序的地址的地址，为段地址0000H，偏移地址\\(中断类型号\\times 4\\)。于是有四个字节或者两个字，第一个字为IP，第二个字为CS。CS:IP给出了中断处理程序的地址。\n中断类型范围为0~255\nINT INT n 表示调用第n号中断，其值为0~255，其会进行如下操作\n12.jpg\rIRET 中断返回指令。执行时会IP、CS、PSW的顺序出栈。\nDOS提供的系统功能调用 13.jpg\r其中INT21的功能号对应的功能为\n14.jpg\rIO操作 8086是独立编址的，进行IO操作需要特别的指令。\nIN IN DST, SRC 从端口输入数据。其中SRC一般为DX或者立即数，表示设备端口的地址。但是立即数只能是8位，而DX可以用16位也可以用8位。DST例如用AX表示读一个字，用AL则表示读一个字节。\nOUT OUT DST, SRC 和IN的DST和SRC的要求换一下即可。\n处理器控制指令 NOP 空操作指令。表示什么也不做，但要占用机器的三个时钟周期。\nHLT 暂停指令，使CPU进入暂停状态，退出暂停的条件有：\nRESET信号有效，即CPU进行复位操作 NMI（非屏蔽中断请求）信号有效，即系统收到了非屏蔽中断，必须处理 INTR（可屏蔽中断请求）有效，且IF=1，此时要求系统响应该请求 WAIT 等待指令，使CPU处于等待状态。这是，CPU会定期检测8086芯片的\\(\\overline{TEST}\\)引脚。为高电平时继续等待，并且每五个时钟周期再检查一次，直到低电平，之后退出等待执行下一条指令。\nLOCK 总线锁定指令\nLOCK \u0026lt;其他指令\u0026gt; 可以保持总线的使用权，表示在使用这组指令期间，别的设备不能使用外部总线\nESC ESC CODE, DATA 换码指令，完成多处理器之间的指令和数据交换。\n例如8086cpu可以利用该指令把任务分配给8087。CODE是一个事先规定的6位指令码（立即数表示），DATA表示要送的数据（使用寄存器或存储器寻址）\n宏指令 宏指令是用户自己定义的指令，它是由指令和伪指令构成的程序段。用户使用宏指令时必须先定义后调用。\n宏指令用标识符（宏指令名）来表示一段程序，在程序汇编时，调用的宏指令会被展开成相应的程序段（宏展开）。所以宏指令并没有相对应的指令代码，类似于EQU这样的标识符。\n宏指令名 MARCO \u0026lt;形式参数\u0026gt; ... ; 宏体 ENDM 形式参数就像C的函数的参数，不过应该是传引用，例如\n15.jpg\r16.jpg\r总线及其形成 基础概念 一组共用的导线，计算机中各种信息沟通的公共通道\n按照连接对象分类为：内总线、外总线 传输信息的种类：数据总线、地址总线、控制总线 握手技术和联络方式：同步传输总线、异步传输总线 功能层次：片内总线、元件级总线、系统总线、通信总线 微处理器级总线： 微处理器外部结构中的数量有限的输入输出引脚\n系统级总线：微处理器级总线和其他逻辑电路连接组成的主机板系统\n集中常用芯片 三态门 典型芯片74LS244\n17.jpg\r其中Z为高阻态。上图应该G是\\(\\bar G=1\\)时高阻\n18.jpg\r双向三态门 典型芯片74LS245\n19.jpg\r20.jpg\r带有三态门输出的锁存器 典型芯片74LS373\n21.jpg\r22.jpg\r8086的引脚功能及时序 23.jpg\r总线周期 T1状态：表示CPU准备输出存储器地址或I/O地址。 T2状态：用于输出控制信号。 T3/Tw状态：在这个状态下，CPU会等待存储器或I/O端口准备好数据传输。 T4状态：这是数据传输完成的确认阶段。 最小方式 引脚功能TODO\n24.jpg\r最大方式 引脚功能TODO\n25.jpg\r系统总线的形成 最小方式 26.jpg\r最大方式 27.jpg\r28.jpg\r8086与8088的差异 在 CPU 内部，8086 CPU 的指令队列寄存器由 6 字节组成，而 8088 CPU 的指令队列寄存器由 4 字节组成。 在 CPU 外部 8088只有8位数据线即D0-D7 8088中为\\(IO/\\bar M\\)，而8086中为\\(M/\\overline{IO}\\) 8086中的\\(\\overline{BHE}/S_7\\)在8088中为\\(\\overline{SS_0}\\)仅用于在最小方式中提供状态信息，在最大方式中始终为高电平。 PC/XT 总线 29.jpg\r引脚功能todo\n30.jpg\r存储器设计 存储器分类和主要技术指标 P190\n几种常用存储器芯片介绍 6264和2114是SRAM，而2764是EPROM\n31.jpg\r32.jpg\r33.jpg\r扩展存储器设计 P201\n存储器地址译码电路设计 P207\n34.jpg\r35.jpg\r36.jpg\r37.jpg\r38.jpg\r存储器与CPU的连接 P209\n本章后面的疑似不用学\n常用芯片的接口技术 I/O 接口概述 P224\n外设接口的编址方式 P226\n输入/输出的基本方式 P228\n常用芯片的接口技术 P232\n本章后面的疑似不用学\n中断系统与可编程中断控制器 8259A 中断的基本概念 P256\n8086 的中断系统 P260\n可编程中断控制器 8259A 及其应用 P264\n39.jpg\r40.jpg\r定时/计数器 8253 应用设计 8253的引脚功能及特点 P273\n8253的原理结构及工作原理 P273\n41.jpg\r8253的控制字及工作方式 P275\n42.jpg\r43.jpg\r8253与系统总线的接口方法 P287\n8253的应用设计 P300\n并行接口芯片8255A应用设计 8255A的引脚功能及特点 P316\n8255A的原理结构及工作原理 P316\n44.jpg\r8255A的控制字及工作方式 P317\n45.jpg\r46.jpg\r8255A与系统总线的接口方法 P323\n8255A的应用设计 P325\n","date":"2023-11-08T08:23:07+08:00","image":"https://kegalas.top/inferior/%E5%BE%AE%E6%9C%BA%E5%8E%9F%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/cover_hu9ed3e3d7509314fb7a01cf1769564f25_44442_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E5%BE%AE%E6%9C%BA%E5%8E%9F%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"微机原理学习笔记"},{"content":"可能是因为我安装了Debian子系统，VBox突然就打不开了。当然时间久远，一直没有解决，是不是这个原因暂且按下不表。\n报错信息大致是\n... Error relaunching VirtualBox VM process: 5 ... 5 VERR_INVALID_NAME (-104) -Invalid (malformed) file/path name. 这样的。\n我知道很长一段时间内，Hyper-v和VirtualBox、VMWare是不兼容的。但是现在VBox都已经7.0版本了，甚至都支持半虚拟化用Hyper-v了，再用hyper-v和virtualbox不兼容来解释就有点说不过去了。\n经过一番搜索，我的方法如下：\n在VBox的安装目录下找到\\drivers\\vboxsup，选中VBoxSup.inf右键安装。 打开regedit.exe，找到计算机\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\VBoxSup，把Start改成2 重启 竟然奇迹般的好了。\n很多人也通过别的方法解决了，例如关闭杀毒软件、关闭Hyper-V等等。我个人觉得这个错误的原因很多，可能需要自己多看几篇文章，反复尝试。\n","date":"2023-10-22T22:33:16+08:00","permalink":"https://kegalas.top/inferior/virtualbox%E6%89%93%E5%BC%80%E8%99%9A%E6%8B%9F%E6%9C%BAverr_invalid_name-104%E9%94%99%E8%AF%AF%E7%9A%84%E8%A7%A3%E5%86%B3/","title":"VirtualBox打开虚拟机VERR_INVALID_NAME(-104)错误的解决"},{"content":"众所周知，学校校园网是一个巨大的局域网。你在教室里面连上校园网的WiFi，就可以访问用有线网（或者WiFi）连接到校园网的宿舍电脑。这给了我们使用SSH在学校的任意地点访问宿舍电脑的可能。\nWindows配置 客户端配置 软件安装 Win11下，我们在设置-应用-可选功能-添加可选功能（查看功能）中搜索ssh，安装OpenSSH客户端。\n密码连接方式 这样就已经可以使用ssh登陆服务器了，当然现在你只能使用用户名和密码登陆。方法如下\nssh username@ip 我们一般局域网都是直接访问ip的，username就是你windows的用户名。密码不是PIN，是你微软账号的密码。如果是本地用户就是用户的密码。\n当然如果你要登陆的用户是管理员，现在可能还登不上，会显示Permission Denied\n密钥连接方式 如果不想输入密码，就要用到ssh的密钥文件。如何生成密钥文件我推荐你参考https://docs.github.com/zh/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent\n生成完之后记得要ssh-add，把密钥添加到ssh-agent里，这也在这篇文章中讲到怎么做了。通常，我也会建议你把ssh-agent服务设置为自动。注意在services.msc中这个服务叫OpenSSH Authentication Agent，在任务管理器中这个服务叫ssh-agent\n服务端配置 软件安装 类似于客户端，这次我们添加的功能叫做OpenSSH服务端。\n安装完成后，启动服务。在services.msc中这个服务叫OpenSSH SSH Server，在任务管理器中叫sshd。建议设置为自动。\n服务器参数配置 一般来说，开启服务之后，会自动在C:\\ProgramData\\ssh\\下生成一大堆文件。其中包括服务器的配置文件，和服务器自己的密钥等等。\n我们修改这个目录下的sshd_config文件，以下内容取消注释\nPermitRootLogin prohibit-password PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys PasswordAuthentication yes 然后，把PermitRootLogin prohibit-password改为PermitRootLogin no；把PasswordAuthentication yes改为PasswordAuthentication no\n最后，再注释掉：\n# Match Group administrators # AuthorizedKeysFile __PROGRAMDATA__/ssh/administrators_authorized_keys 这样，我们就只能用密钥登陆了。可能提升了些微的安全性。注意PermitRootLogin对Windows是无用的，我这样只是方便跟linux统一。\n修改完后重启sshd服务。\n服务器配置密钥连接方式 我们要把客户端的公钥上传服务器，这样我们才能让客户端正常登陆。为此我们要修改服务器用户的~\\.ssh\\authorized_keys文件（没有就创建一个），然后把客户端用户的公钥直接复制粘贴到authorized_keys中。公钥都是一行的，所以如果有多个公钥，每行一个即可。\n更换默认命令行 你可能发现ssh连进去，打开的是cmd命令行，而你更想要PowerShell，参照https://learn.microsoft.com/zh-cn/windows-server/administration/openssh/openssh_server_configuration#configuring-the-default-shell-for-openssh-in-windows\n我的版本如下，修改了我自己的PowerShell7的位置。\nNew-ItemProperty -Path \u0026#34;HKLM:\\SOFTWARE\\OpenSSH\u0026#34; -Name DefaultShell -Value \u0026#34;G:\\Program_Files\\PowerShell\\7\\pwsh.exe\u0026#34; -PropertyType String -Force 后记\npowershell 7在更新的时候可能会把你安装的位置强行迁移到C盘Program Files下，我建议不要换默认安装位置，防止自己搞不清状况又要重新配置。\n注意事项 注意，authorized_keys需要注意权限和所有权的问题。如果假如说，你创建了一个用户2，作为没有管理员权限的用户，用户1是拥有管理员权限的用户。它们两个在服务端。那么你需要确保用户2的~\\.ssh是由用户2自己创建的，并且自己有完全控制的权限。authorized_keys文件同理。这样才能让用户2正常读取文件信息。\n假设你为了方便用用户1为用户2创建文件、写入信息。那么你很有可能会登陆失败，显示Permission Denied。本人曾经踩过这个坑。\nLinux 使用例 Hugo Hugo是可以开启本地服务器的，其使用方法为hugo server，之后我们就可以在localhost:1313访问我们的博客了。\n1.jpg\r但是注意到，他开在127.0.0.1这个回环地址上。也就是说，只有本机才能访问，而内网的其他设备是无法访问的。\n在此我们要区分一下几个ip。localhost、127.0.0.1、192.168.x.x，10.x.x.x。\nlocalhost\n这个其实是个域名，和baidu.com没有本质区别，它一般会被映射到127.0.0.1。我们可以通过修改hosts更改它的映射。\n127.0.0.1\n这个叫回环地址，本机发出的所有信息都会兜一圈再发回给本机，并且这个兜一圈只在本机内部。外部设备是无法连接到这个地址的。\n192.168.x.x\n一般路由器会分配给电脑这个内网地址，同一路由器所连的设备地址都会是这个样子，只是最后几位不同。这些设备可以用它们的这个地址互相访问。\n10.x.x.x\n如果你在用校园网的话，路由器wan口的地址一般会是这个。但是这不是公网地址，这是校内局域网的地址。我们在别处使用校园网的话，就可以用这个地址访问宿舍内的设备。\n综上所述，如果你要让外部的设备访问到Hugo页面，你就不能把他开到127.0.0.1上，你应该开到192.168.x.x上。但是这样的话你本机访问localhost或者127.0.0.1又不能连上了。幸好我们有一种办法可以让两个同时可以访问，就是把服务器开在0.0.0.0上。开在这个ip上的服务器会自动探测本机的所有ip，让他们都能访问（不过0.0.0.0本身是不能访问的）。\nHugo本身的用法是hugo server --bind 0.0.0.0\n到此为止，你已经可以用本机的各种地址访问了，但是还不能用校园网内的其他设备访问10.x.x.x这个地址，因为这个地址是你宿舍路由器的wan口地址（你直接拨号上网除外）。你需要把192.168.x.x:1313映射到10.x.x.x:1313，需要用到的技术叫做端口映射，一般可以在路由器内设置。例如openwrt：\n2.jpg\r之后我们就可以真正在学校任意一个有网的地方访问10.x.x.x:1313来连接博客了。\nAnaconda 假设这样一个场景：你宿舍、实验室的机器显卡很强，可以用来训练AI，但是笔记本不太行。所以你想要在课堂上、图书馆训练AI是不可能的。这时候ssh就派上用场了，直接连到远程机器进行训练即可。\n你可能比较熟悉Anaconda的图形化界面，它启动特定的环境比较方便，只要按几个按钮即可。但是ssh只有命令行，命令行稍微困难点。\n在Anaconda的安装目录下，有一个condabin文件夹，里面的conda.bat可以帮助我们启动环境。\n你可以先使用.\\conda info -e查看你有哪些环境：\n3.jpg\r启动环境的方法是\n.\\conda activate base 你在powershell里输入会发现毫无变化。这其实是因为anaconda只支持cmd，我们要先输入cmd切换到cmd，之后再启动环境，即可。\n4.jpg\r与Hugo类似的，我们也可以通过校园网访问Jupyter Notebook。只要设定其ip即可\njupyter notebook --ip=0.0.0.0 同样，你也需要去开启路由器8888端口的映射。\n","date":"2023-10-20T15:33:36+08:00","permalink":"https://kegalas.top/p/%E5%9C%A8%E6%A0%A1%E5%9B%AD%E7%BD%91%E4%B8%AD%E7%94%A8ssh%E8%BF%9E%E6%8E%A5%E5%AE%BF%E8%88%8D%E7%94%B5%E8%84%91/","title":"在校园网中用ssh连接宿舍电脑"},{"content":"Windows 音频软件 软件名 简介 Audacity 编辑、录制（开源免费） Adobe Audition 编辑、录制 GoldWave 编辑、音频分析 foobar2000 播放器（免费） Audacious 播放器（开源） clementine 播放器（开源） LMMS 编曲（开源免费，但是质量不高） cakewalk 编曲（免费） reaper 编曲 studio one 编曲 ableton live 编曲 cubase 编曲 fl studio 编曲 musescore4 打谱（开源免费） 视频软件 软件名 简介 Davinci Resolve 编辑、特效、调色（免费） Adobe Premiere 编辑 Adobe After Effects 特效 olive 编辑（开源免费） Natron 特效（开源免费） OBS 录制（开源免费） bandicam 录制 MediaInfo 视频信息查看（开源免费） 完美解码 播放器、解码器（免费） VLC 播放器（开源免费） ShanaEncoder 转码（免费） handbrake 转码（开源免费） Arctime 字幕（免费） 图像软件 软件名 简介 GIMP 编辑（开源免费） Adobe Photoshop 编辑 Mine-imator mc特化的c4d（免费） Honeyview 看图软件（免费） Krita 绘画（开源免费） RawTherapee 调色（开源免费） Adobe Illustrator 矢量图 inkscape 矢量图（开源免费） snipaste 截图软件（部分免费） 网络软件 软件名 简介 firefox 浏览器（开源免费） thunderbird 邮件（开源免费） IDM http下载器 XDM http下载器（免费），但是中文文件名支持有些问题 FDM http下载器（开源免费） ，感觉比很久以前好用了 aria2（及其网页gui ariaNG） 下载器（开源免费） qbittorrent bt下载器（开源免费） motrix 下载器（开源免费） uget 下载器（开源免费） Z2VwaA== Y2xvdWRmbGFyZSB3YXJw dG9yIGJyb3dzZXI= zerotier 组局域网（开源，部分免费），路由器可以支持 ToDesk 远程控制（部分免费） 蒲公英游戏版 组局域网（部分免费），国内低延迟、小数量联机首选 文本编辑 软件名 简介 vim 开源免费 emacs 开源免费 notepad3 可以完全替代windows自带的记事本（开源免费） obsidian markdown编辑（开源免费） 更多的，IDE级别的，可见Windows开发环境配置合集（长期更新）\n开发环境 见Windows开发环境配置合集（长期更新）\n音源 音源名 链接 类型 备注 Ample Bass www.pluginboutique.com 贝斯 Ample Guitar www.pluginboutique.com 吉他 BBC Symphony Orchestra www.spitfireaudio.com 管弦乐 用Spitfire Audio软件下载 CollaB3 https://sampleson.com/collab3-free-tonewheel-organ.html 管风琴 已存百度云 ExaktLite https://www.sonicbits.com/exakt-lite.html 合成器 Iris2 https://www.izotope.com/ 合成器 用izotope软件下载（其中也有本列表未列出音源） KeyzoneClassic https://vst4free.com/plugin/2848/ 钢琴 kHs One https://kilohearts.com/products/one 合成器 用kilohearts的软件下载 synth1 http://daichilab.com/synth1/ 合成器 Native-Instruments https://www.native-instruments.com/ 音源库 其他音源的前置(包含很多没有在此表中的音源) LABS www.spitfireaudio.com 各种乐器 用Spitfire Audio软件下载 MSoundFactory www.meldaproduction.com 音源库 Sonatina Orchestra https://vst4free.com/plugin/2541/ 管弦乐 Vital https://vital.audio/ 合成器 MonasteryGrand https://www.meldaproduction.com/MonasteryGrand 钢琴 安装后用MSoundFactory启动 DrumMic\u0026rsquo;a https://en-au.sennheiser.com/drummica 鼓 安装后用NI启动，百度云里有 The Free Orchestra https://projectsam.com/libraries/the-free-orchestra/ 管弦乐 用NI启动，百度云有 Surrealistic MG-1 Plus https://store.cherryaudio.com/ 合成器 Reverb Drum Machines https://reverb.com/software/samples-and-loops/reverb/3514-reverb-drum-machines-the-complete-collection# 鼓机 百度云有 VSCO2 Rompler https://vst4free.com/plugin/2734/ 管弦乐 Palette – Primary Colors https://redroomaudio.com/product/palette-primary-colors/ 管弦乐 需要完整版kontakt，下载用pulse Xfer OTT https://xferrecords.com/freeware 压缩器 Layers https://www.orchestraltools.com/store/collections/45 管弦乐 ZODIAC https://cymatics.fm/pages/zodiac-beta-pack loop 百度云有 French Violin https://www.samplescience.info/2021/07/french-violin.html 小提琴 https://samplescience.gumroad.com/l/kVTQI 上面的那个的下载链接 swatches https://www.applied-acoustics.com/swatches/ 一堆物理建模的音源 Art Deco Piano https://cn.ikmultimedia.com/userarea/my-products/ 钢琴 在IK软件中下载\n网盘有 SampleTank 4 CS https://cn.ikmultimedia.com/userarea/my-products/ 综合 在IK软件中下载 Decent Sampler https://www.decentsamples.com/ 各种音源 其中音源要在Decent Sampler这个软件中下载，百度云有 Korg Volca Keys https://www.decentsamples.com/ 合成器 免费版本要完整版knotakt，也有sfz的版本，百度云有 Lewis E Pyle Violin Lite https://www.decentsamples.com/ 小提琴 同上 DSK Harmonica https://plugins4free.com/plugin/353/ 口风琴 百度云有 SamsaraCycleAudio Harmonica https://plugins4free.com/plugin/1831/ 口风琴 百度云有 K1v https://www.nilsschneider.de/wp/nils-k1v/ 合成器预设 百度云有 Downtown Colors https://zaksound.com/products/ 合成器预设 百度云有 上一行的链接中还有raizes series、Infinite Space Piano、Retro Keys VII等免费音源，第一个暂未下载（软件下载地址404） Syntronik 2 V-80 https://cn.ikmultimedia.com/userarea/my-products/ 合成器 在IK中下载 百度云有 IMPACT S1 \u0026amp; Prod. Secrets SAMPLE PACK https://prodsecrets.com/pages/free-s1-sample-pack 采样包 百度云有 NumaPlayer https://www.studiologic-music.com/products/numaplayer/ 键盘、管弦音源 百度云有 Atmos 2 https://electroniksoundlab.com/free-stuff/ 氛围钢琴 百度云有 cinematic-soundfx-2 https://www.ghosthack.de/cinematic-soundfx-2/ 影视采样包 百度云有 the-88e https://impactsoundworks.com/product/the-88e/ 88个E的特制钢琴 NI中下载 foundations-piano https://heavyocity.com/product/foundations-piano/ 氛围钢琴 要用heavyocity下载，在NI中定位激活 The Felt Seiler - Free Edition https://www.strezov-sampling.com/products/view/the-felt-seiler-free-edition.html 钢琴 虽然可以用他自己的软件或者直接网站下载（有次数限制），不过要梯子，更建议在NI中下载 Augmented Strings Intro https://www.arturia.com/support/augmented-strings-intro-gift# 特制弦乐采样 在aturia软件中下载 PA Soundwide Welcome Bundle https://www.plugin-alliance.com/en/products/pa-soundwide-bundle.html 效果器 在该网站提供的下载器中下载 DSK Dynamic Guitars https://www.pluginboutique.com/ 吉他 在用户免费product中，百度云有 Autoformer https://www.unitedplugins.com/Autoformer/ 效果器 百度云有 foundations-staccato-strings https://heavyocity.com/product/foundations-staccato-strings/ 弦乐（断奏） 要用heavyocity下载，在NI中定位激活 Lounge Lizard Session 4 https://www.applied-acoustics.com/portal/products/ 吉他 百度云有 Strum Session 2 https://www.applied-acoustics.com/portal/products/ 复古合成器 百度云有 Ultra Analog Session 2 https://www.applied-acoustics.com/portal/products/ 电吉他 百度云有 Music Boxes https://www.soniccouture.com/en/account/downloads/#free-products 小品音源 在Kontakt中使用，需要定位音源库，百度云有 RMI Rocksichord https://www.soniccouture.com/en/account/downloads/#free-products 小品音源 在Kontakt中使用，需要定位音源库，百度云有 Tape Choir https://www.soniccouture.com/en/account/downloads/#free-products 小品音源 在Kontakt中使用，需要定位音源库，百度云有 Thunder Drum https://www.soniccouture.com/en/account/downloads/#free-products 小品音源 在Kontakt中使用，需要定位音源库，百度云有 Vienna的众多免费管弦音源 https://www.vsl.co.at/ 管弦 用其自己的软件下载 Podolski https://u-he.com/products/podolski/ 合成器 百度云有 TripleCheese https://u-he.com/products/triplecheese/ 合成器 百度云有 TyrellN6 https://u-he.com/products/tyrelln6/ 合成器 百度云有 Diamond Jazz Trio https://www.strezov-sampling.com/products/view/Diamond-jazz-trio.html 爵士三重奏 NI中下载 Analog Lab Intro https://audioplugin.deals/analog-lab-intro-by-arturia/ 合成音色 需要在arturia的软件中下载 Roland Concerto https://www.roland.com/us/products/rc_roland_cloud_manager/?lang=en-US 各种 需要在roland云里下载 foundations-nylon-guitar https://heavyocity.com/product/foundations-nylon-guitar/ 尼龙吉他 要用heavyocity下载，在NI中定位激活 GrandPianoXXL Win VST https://www.audiolatry.com/ 大钢琴 百度云有 Contemporary Bass: Freebie https://sonixinema.com/collections/freebies/products/contemporary-bass-freebie 倍大提琴拨奏 在NI中下载即可 foundations-synth-bass https://heavyocity.com/product/foundations-synth-bass/ 合成器贝斯 要用heavyocity下载，在NI中定位激活 Hammersmith Free https://www.soniccouture.com/en/account/downloads/#free-products 钢琴 直接在NI中下载即可 prime 8+ https://www.uvi.net/en/vintage-synth/prime-8-plus.html 鼓机 在UVI的软件中下载 Hypha https://www.native-instruments.com/zh/specials/holiday-gift-2022/ 混合电声与原声的音色 在NI中下载 vivace-legacy https://www.sonokinetic.net/products/instruments/vivace-legacy 管弦 下载后（使用其管理软件）在NI中加载 cinesamples的五款小品音源 https://cinesamples.com/my-products 各种 在NI中下载 indie-melodica https://www.orangetreesamples.com/account/downloads/indie-melodica 口风琴 在网页中下载，去ni中定位 Minimalist Violins Legato Freebie https://www.strezov-sampling.com/products/view/afflatus-freebie.html 小提琴 网页下载NI定位 Usynth Core https://www.pluginboutique.com/products/8862-Usynth-Core 合成器 也可以去ujam官网下载其APP然后安装音源 Super 8 https://www.pluginboutique.com/myaccount 合成器 是NI的产品之一，直接去NI下载 Miroslav Philharmonik 2 CE https://cn.ikmultimedia.com/userarea/my-products/ 管弦 IK下载 Bell\u0026amp;Bone https://librewave.com/my-account/downloads/ 铜管 用提供的Rhapsody下载。有下载限制，存百度云。 其他 软件名 简介 SumatraPDF PDF查看，也可以打开epub等电子书（开源免费） okular PDF查看（开源免费） PDF24 大量PDF相关的小工具（免费） calibre 电子书（开源免费） 7zip 解压缩（开源免费） peazip 解压缩（开源免费） freeplane 思维导图（开源免费） Daemon Tools 虚拟光驱（部分免费） iLok License Manager 音源加密狗（免费） Playnite 游戏进度管理（免费） wiztree 磁盘占用数据分析（免费） spacesniffer 磁盘占用数据分析（免费，但感觉不如上一个） Everything 文件搜索（免费） geogebra 数学绘图工具（开源免费） zotero 文献管理（开源免费） U盘工具箱 软件名 简介 图吧工具箱 电脑信息综合（免费） dism++ 电脑维护综合（免费） Everything 同前 wiztree 同前 rufus 刻录安装镜像（开源免费） ventoy 可以让u盘有多个启动镜像，一定程度上比上面那个好得多（免费） equalizer apo 音频相关（免费） voice meeter 音频相关（免费） Linux 部分Windows软件也有Linux版，这里只介绍我只会用在Linux中的。\n软件名 简介 efibootmgr 管理efi启动项 AppImageLauncher 管理appimage格式的软件 kate kde下不错的轻量文本编辑器 sddm 登陆管理器 kalzium 元素周期表软件 kmplot 数学绘图 fcitx 输入法 dolphin 资源管理器 yakuake 下拉式terminal ark 解压缩 ","date":"2023-10-13T21:20:54+08:00","permalink":"https://kegalas.top/inferior/%E4%B8%AA%E4%BA%BA%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%88%97%E8%A1%A8/","title":"个人常用软件列表"},{"content":"编辑器/IDE Emacs https://mirrors.tuna.tsinghua.edu.cn/gnu/emacs/windows/，在清华源下载安装，可以更改的只有安装目录。\n我的.emacs.d可见https://github.com/kegalas/dotfiles\n现在emacs29自带use-package，直接打开就可以，不需要手动安装。\nall-the-icons很奇怪，不会被use-package安装，我们M-x package-install all-the-icons安装重启即可。\n另外，我安装了lsp-pyright来提供python的补全，python里面也要用pip安装pyright才能运行。\n此时，用GUI版本的Emacs已经可以了，但是如果想在命令行里用Emacs，则需要添加环境变量。出于对环境变量冲突的恐惧，我没有直接将Emacs的bin添加进PATH，我选择了照抄Vim的bat文件。如下\n@echo off rem -- Run Emacs -- setlocal set EMACS_EXE_DIR=D:\\Program_Files\\Emacs\\emacs-29.1\\bin if exist \u0026#34;%EMACS%\\emacs-29.1\\bin\\emacs.exe\u0026#34; set EMACS_EXE_DIR=%EMACS%\\emacs-29.1\\bin if exist \u0026#34;%EMACSRUNTIME%\\emacs.exe\u0026#34; set EMACS_EXE_DIR=%EMACSRUNTIME% if not exist \u0026#34;%EMACS_EXE_DIR%\\emacs.exe\u0026#34; ( echo \u0026#34;%EMACS_EXE_DIR%\\emacs.exe\u0026#34; not found goto :eof ) \u0026#34;%EMACS_EXE_DIR%\\emacs.exe\u0026#34; %* 把这个文件保存为emacs.bat，然后找一个文件夹放进去，例如我放在了xxx\\myExec下，然后把这个文件夹添加到PATH的末尾。\nIDEA https://www.jetbrains.com/idea/download/?section=windows，官网下载，我现在主要用Community版本，免费，而且其是可商用的，这点和其他很多软件的社区版不同。\n我这里没有选择添加进PATH，并且把所有文件关联都勾选上了。主要是考虑到防止PATH里面东西太多，干扰运行。\n2.jpg\rPycharm https://www.jetbrains.com/pycharm/download/?section=windows，和IDEA一样。\nQT Creator TODO\n（如果设置Android SDK会导致奇怪的卡顿）\nAndroid Studio https://developer.android.google.cn/studio，官网下载。\n勾上AVD，这个是安卓虚拟机，很显然是必要的。\n10.jpg\rAVD设置TODO（包括用软连接把安装目录转移等）\nObsidian https://obsidian.md/，官网下载，不需要设置环境变量。\n其软件设置，我一般会加上Completr插件来为Latex提供补全，安装Solarized主题。设置严格换行，显示行号，tab功能替换为4个空格而非制表符等。\n另外Obsidian自带的PDF导出并不能导出目录，我会安装https://github.com/l1xnan/obsidian-better-export-pdf来解决。\nCP Editor https://cpeditor.org下载，\n建议选择64位版，不带mingw和llvm的版本，因为我们已经在msys里安装过了。\n这里没有选择all users安装，其他就只有目录可以修改。\nTexStudio 见后\n字体 Jetbrains Mono https://www.jetbrains.com/lp/mono/，下载解压，得到一大堆ttf格式的文件。虽然你可以一个一个双击安装，但是太慢了，我推荐你把它们全部选中，拖入到C:\\Windows\\Fonts文件夹中，可以批量安装。\nNoto TODO\nGit Git for Windows 18.jpg\r我这里除了创建桌面图标都勾选了。\n19.jpg\r这里选择了vim当作默认编辑器。\n20.jpg\r这里选择第一个，因为我还有一些库是用master作为默认分支的。\n21.jpg\r这里思虑再三我还是选择第二个。如果选第一个，更小心的避免PATH冲突，可以用和Emacs一样的手法：\n@echo off rem -- Run GIT -- setlocal set GIT_EXE_DIR=D:\\Program_Files\\Git\\bin if exist \u0026#34;%GIT%\\bin\\git.exe\u0026#34; set GIT_EXE_DIR=%GIT%\\bin if exist \u0026#34;%GITRUNTIME%\\git.exe\u0026#34; set GIT_EXE_DIR=%GITRUNTIME% if not exist \u0026#34;%GIT_EXE_DIR%\\git.exe\u0026#34; ( echo \u0026#34;%GIT_EXE_DIR%\\git.exe\u0026#34; not found goto :eof ) \u0026#34;%GIT_EXE_DIR%\\git.exe\u0026#34; %* 但是，这样做许多软件就识别不到git，例如jetbrains家的IDE。所以我还是选择第二个好了。\n但是会不会和msys2中的软件冲突，还有待观察。目前我把他的环境变量顺序放到msys2以下。\n22.jpg\r23.jpg\r选第一个，感觉影响不大。\n24.jpg\r跨平台，就选第二个吧。\n25.jpg\r第一个，一直都是用第一个。\n26.jpg\r关于合并的操作，一直都是用的第一个。\n27.jpg\r这个不太懂，选默认的。\n28.jpg\r都勾选，有用。\n29.jpg\r两个实验功能就不勾选了。\nGithub Desktop https://desktop.github.com/，可说的不多，甚至不需要安装，双击就打开安装完毕了，也没有环境变量需要配置（自动配置在User的PATH里了）。\n终端模拟器 Terminal 主题 tabby alacritty C/C++相关 GCC 这里使用的是MSYS2，https://www.msys2.org/，下载安装包。\n打开安装包，其中只有安装目录是能修改的。\n安装完成后勾选立即打开，打开的是ucrt64，我们首先更换软件源。\n进入xxx\\msys64\\etc\\pacman.d，参照https://developer.aliyun.com/mirror/msys2进行修改，这里我们全都修改一下。\n在文件中搜索ali\n11.jpg\r把阿里云的这一行复制到第一行。对所有文件都进行这个操作。\n之后在ucrt64的命令行中执行pacman -Sy\n之后安装pacman -S mingw-w64-ucrt-x86_64-gcc，当然，也可以使用pacman -S mingw-w64-ucrt-x86_64-toolchain。前者是目前官网的安装示例里的，后者则是以前的示例里的。\n环境变量我们只设置ucrt64、clang64和msys的，全部设置可能会加大冲突风险。\n12.jpg\r注意顺序，不能颠倒。\n之后我们打开MSYS的命令行，安装pacman -S gcc，这一步的目的是，我们使用MSYS提供的虚拟Linux的POSIX，方便我们在windows上进行Linux系统调用，这两个gcc的区别可见MSYS2,MinGW64,Cygwin的使用区别浅谈\n另外，还可以把msys2添加到右键菜单，见添加msys2到右键菜单\nClang 我们不去安装LLVM官方给Windows的二进制包了，我们直接在clang64里安装。\npacman -S mingw-w64-clang-x86_64-toolchain 安装了clang，clangd等工具。安装完之后不用进行任何环境变量配置。\n注意：不能只安装clang、clang-tools-extra等，否则clangd可能会出现找不到iostream库的问题。\nMSVC TODO\nMake/Cmake/Ninja 在UCRT64的terminal里面，输入\npacman -S mingw-w64-ucrt-x86_64-cmake mingw-w64-ucrt-x86_64-cmake-gui mingw-w64-ucrt-x86_64-ninja mingw-w64-ucrt-x86_64-make 安装cmake官网的windows版本会不会更优有待考察TODO。\n另外，直接安装make后，并不能在powershell里直接使用，见MSYS2中的make工具安装方法\n要让clangd能够检测Cmake项目，还需要进行https://clangd.llvm.org/installation#project-setup里提到的操作，简单来说\n在cmake进行configure的时候添加参数-DCMAKE_EXPORT_COMPILE_COMMANDS=1 把configure后build目录里生成的compile_commands.json软连接到项目根目录 Lua TODO\nRust相关 TODO\nGO相关 TODO\nJava相关 JRE和JDK Java8运行时 很多软件（例如Minecraft），都还建立在Java8之上，所以安装JRE8是理所当然的。\nhttps://www.java.com/en/download/，java官网目前首选的下载也是Java8。安装过程没什么可说的，只有安装位置可以更改。\n环境变量他也会自动配置好。\nJDK11和JDK17 因为有许多库，其在JDK11上运行最稳定，所以JDK11是要安装的，而想用新特性，最好安装一下JDK17。JDK11和17是LTS版本，更新的有需要再安装。如果你不可避免的要用JDK8 LTS，那么也可以去安装。\n我这里安装的都是Adoptium Eclipse Temurin的JDK，见https://adoptium.net/zh-CN/temurin/releases/?version=17\n以JDK17为例\n5.jpg\r我这里全都勾选了，但是PATH和JAVA_HOME其实可以不用勾选，因为很多IDE（如IDEA，Android Studio）都支持搜索所有JDK，并且手动选择JDK版本，所以这个其实不是很必要。\n另外，如果你加入了PATH，要记得把JAVA8的PATH放到JDK上面，以防运行不了Minecraft。\nScala TODO\nKotlin TODO\nClojure TODO\nPython相关 普通版 https://www.python.org/downloads/下载最新版（注意是Windows installer (64-bit)），安装。\n安装它的原因是，因为直接把Anaconda3的Python导入环境变量实在是太容易造成冲突了，我们需要一个默认的Python给Windows用。\n我选择添加python.exe进PATH，并且Customize installation。勾选第二页的全部选项（默认就是全部）、第三页也全部勾选（注意有一个选项需要先安装Visual Studio）。\n6.jpg\r7.jpg\r8.jpg\r如上勾选之后，环境变量也会自动配置。这个普通版Python并不会影响Anaconda的virtual env，放心使用。\n更换pip源见https://mirrors.tuna.tsinghua.edu.cn/help/pypi/\nAnaconda3 https://www.anaconda.com/download下载安装包。\n安装时，我选择的是Just Me而不是All Users\n3.jpg\r勾选如下，勾选了第三个，可以让Pycharm选择里面的环境。第四个看到他推荐也就勾选了。第二个不勾选，防止环境变量冲突。\n4.jpg\rAnaconda的软件源也比较慢，推荐参考https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/换为国内源。\nLatex相关 TexStudio 这其实只是一个编辑器，不包含latex的运行环境。\nhttps://texstudio.sourceforge.net/，下载后只有安装目录可以更改，不需要设置环境变量。\ntexlive 这才是真正的运行环境。\nhttps://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/Images/，推荐在清华源下载，官网实在太慢。下载texlive.iso即可。\n下载后装载这个iso，打开install-tl-windows.bat安装\n9.jpg\r选好位置点击安装。\n安装完成后关闭，弹出iso。环境变量已经自动设定在User的Path里。\nMiktex 这个和texlive其实二选一即可。这里列出来是因为我的笔记本居然打不开texlive的安装包。\nhttps://mirrors.ustc.edu.cn/CTAN/systems/win32/miktex/setup/windows-x64/找到basic-miktex安装包。\n优点是比较小，安装包只有一百多MB，特别是相较于texlive的几GB的安装包。代价是，每用到一个包，需要当场下载这个包，在第一次运行的时候很费鼠标点下载。个人估计最终安装的体积差不了多少。\n当然，不想费鼠标的话，可以在安装时选择\n15.jpg\r换源也非常简单，只需要进管理员模式点点鼠标即可\n16.jpg\r17.jpg\r这之后点击下一步，选择ustc的源后finish。\nSQL相关 Postgresql TODO\nSQLite 大多数时候操作都是在编程语言里面操作的。这里只介绍一个看数据的软件，即SQLiteStudio。\n在https://sqlitestudio.pl/下载，我这里安装全默认，只修改了安装位置。\nJS相关 Node.js TODO\nSSH配置 ssh客户端、服务端 安装的话很简单，在设置里面找到应用-可选功能。\n13.jpg\r点击圈出来这个查看功能，搜索openssh，把客户端和服务器都安装即可。\n安装好之后在服务设置里，设置为自动即可开机启动。\n14.jpg\r一般配置文件在C:\\ProgramData\\ssh\\sshd_config，具体如何参考在校园网中用ssh连接宿舍电脑\n博客（Hugo） Hugo 见我的文章为Hugo安装goldmark-mathjax插件来更好地支持输入公式，不推荐使用官网的安装包，推荐自己加插件自己编译。\n把编译好生成的hugo.exe放到某个你喜欢的地方，比如我的G:\\Program_Files\\Hugo\\，并把这个目录设置为环境变量。\nPandoc https://www.pandoc.org/installing.html，现在有安装包，以前只有压缩文件。我只是选择了为所有用户安装以及选择了安装位置，也没有其他可选项了。\n需要手动配置环境变量，配置在xxx\\Pandoc\\即可。\n但是我现在不怎么用这个了，hugo对goldmark适配的更好\nMatlab 从各种地方下载安装包，例如学校正版软件服务、官网等，直接安装即可。\n软件包选择TODO\n环境变量一般配置在xxx\\MATLAB\\R2021b\\bin，注意版本R2021b换成自己的版本。\n其他 Gpg4win 从https://www.gpg4win.org/下载安装，环境变量其会自动配置。我勾选了除了Okular以外的所有选项。\n一般会配置在xxx\\Gpg4win\\..\\GnuPG\\bin\n1.jpg\r关闭Windows休眠 C盘下一般会有两个大文件，即hiberfil.sys和pagefile.sys。前面那个是休眠功能使用的文件，后面的是虚拟内存使用的文件。\n休眠和睡眠不一样，睡眠是电脑低功率运行，但是保持开机，内存的数据就在内存里。而休眠相当于virtualbox里面给虚拟机“快速休眠”的操作，即把内存保存在硬盘中，此时可以不用保持开机。下次开机恢复电脑布局。\n我从来不用这个功能（我甚至从来不知道它，知道了也找不到在哪里），所以关掉，防止占我C盘。办法很简单，管理员powershell运行\npowercfg -h off 环境变量顺序 众所周知，环境变量越靠前的优先级越高。我当前的设置是：最初就有的、Windows目录下的放在最前面；然后放python、java、其他编程语言编译器或者虚拟机的环境变量，这里java的环境变量把java 8放在了最前；之后才是msys的各种环境变量。其他各种应用软件的环境变量可以比较随意，毕竟不会和msys冲突。\n总而言之，优先级遵从以下规则：系统自带的最优先，各种工具链的windows原生版本第二，msys第三，不和msys冲突的应用软件随意。\n","date":"2023-09-23T11:30:14+08:00","permalink":"https://kegalas.top/inferior/windows%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%90%88%E9%9B%86%E9%95%BF%E6%9C%9F%E6%9B%B4%E6%96%B0/","title":"Windows开发环境配置合集（长期更新）"},{"content":"动机 在很久以前的使用中，我发现默认的Hugo渲染引擎无法正确渲染所有数学公式，但我并没有深究为什么。我进行一番搜索后改用pandoc来作为渲染引擎，它在数学公式方面表现的不错，但是，它无法生成目录，也无法生成代码高亮。\n再一番搜索后，我搜索到这篇文章给 Hugo 增加一些 Pandoc 支持增强，里面详细介绍了怎么才能让pandoc正确生成目录，之后我写了文章重新编译hugo来使得pandoc可以生成目录。\n在这些操作后，目录确实可以生成了，但是代码高亮却没有出现。另外，这个版本比较老，无法使用Hugo的最新特性。\n不过我暂时还是保持使用这个版本，因为比起高亮，正确显示公式才是最重要的。\n现在我开始思考要怎么才能显示高亮。Hugo官方对于其他渲染引擎的支持很少（见https://gohugo.io/content-management/formats/），例如pandoc，go-org，rst，asciidoc等。当然这里面asciidoc是个例外，不过我尝试了一下发现仍然不能生成目录。我最终转向了去研究怎么才能让默认的goldmark正确显示公式。\n问题分析 我仔细观察了一下没渲染出公式的代码变成了什么样。最终，我发现，如果一个公式里面有两个下划线，就有可能渲染不成功，并且不成功的地方会变成斜体。再研究发现，两个下划线中间包含字符，是markdown本来的斜体语法（虽然我更常用两个*号），这与Latex里面的下划线用法冲突了，并最终导致了这个问题。\n解决办法 也有一些教程，例如https://bwaycer.github.io/hugo_tutorial.hugo/tutorials/mathjax/通过往html里面嵌入mathjax的js代码来解决问题，但是我自己试了一下好像并没有成功。\n我搜索到了goldmark有mathjax插件，机缘巧合之下我又看到了这篇文章Hugo\u0026amp;Eureka\u0026amp;Nginx，明白为Hugo加入goldmark-mathjax是可能的，试验之后确实如此，实际操作过程如下。\n环境需求 Go 1.19或更新，GCC 官网没有提到GCC的版本，我这里使用的是msys2 ucrt里安装的gcc 13.1.0，而go用的是1.21.1。\nClone、修改代码 git clone https://github.com/gohugoio/hugo.git （不知道为什么shell代码没有高亮）\n可能会遇到网络问题，需要自行解决。\n之后在hugo/markup/goldmark/convert.go中进行修改。\n在import部分添加\u0026quot;github.com/litao91/goldmark-mathjax\u0026quot; 在extensions = append(extensions, images.New(cfg.Parser.WrapStandAloneImageWithinParagraph))后添加extensions = append(extensions, mathjax.MathJax) 至此修改结束，可以看这个链接查看具体怎么修改的。也可以直接克隆我的fork，https://github.com/kegalas/hugo\n编译 cd hugo go get github.com/litao91/goldmark-mathjax go install --tags extended 后两个命令都需要网络通畅。\n编译成功后，一般会生成在C:\\Users\\XXX\\go\\bin，找不到的建议可以用Everything搜一下hugo.exe。之后就可以愉快的使用了。\n已知问题 输入公式时，\u0026lt;有时要求后有空格，否则会渲染失败。一般来说，应该是\u0026lt;后加上大小写字母会渲染失败，必须加上空格。可以用搜索软件搜索所有笔记手动修改。 两个行内公式，如果中间没有间隔，或者中间间隔为英文逗号、句号，会渲染失败。例如$abc$$abc$，$abc$,$abc$，$abc$.$abc$。后面两种情况搜索即可。第一种情况，由于正常的行间公式双$符在单独一行，所以直接搜索$$，obsidian只会把搜索结果的那一行显示，所以即使有几千条也还是比较方便找到的。 行间公式，双$符要单独在一行，否则会渲染失败。解决方法同上。 ","date":"2023-09-21T21:32:37+08:00","permalink":"https://kegalas.top/p/%E4%B8%BAhugo%E5%AE%89%E8%A3%85goldmark-mathjax%E6%8F%92%E4%BB%B6%E6%9D%A5%E6%9B%B4%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E8%BE%93%E5%85%A5%E5%85%AC%E5%BC%8F/","title":"为Hugo安装goldmark-mathjax插件来更好地支持输入公式"},{"content":"本笔记会记录一些C++中，自己以前不常用、不是很熟悉需要记录来复习的、新标准（相较于C++11）引入的、可能有用的功能。不适合详细阅读过某一本C++大部头教材的人，比较适合对于C++的知识只停留在算法竞赛的人。\n本文的内容大多是我看了cppreference、hackingcpp.com、freegeektime.com、知乎和各类博客网站的文章、部分经典教材后，加上自己的理解，写作而成的。\nstd::endl std::endl会立即刷新字符缓冲区，然后输出。但是'\\n'不会。如果频繁地使用std::endl换行可能会导致性能问题，除非你非常确定这条消息在换行后必须要立即输出。\nstd::clog 其写入字符到stderr中，但不是立即输出。而std::cerr会立即输出和刷新stderr。\n\u0026lt;=\u0026gt;（三路比较 ）运算符 这个运算符是C++20引入的，\n如果a\u0026lt;b，那么(a\u0026lt;=\u0026gt;b) \u0026lt; 0 如果a\u0026gt;b，那么(a\u0026lt;=\u0026gt;b) \u0026gt; 0 如果a和b相等或等价，那么(a\u0026lt;=\u0026gt;b) == 0 其实\u0026lt;=\u0026gt;返回的是std::strong_ordering类型，某些时候给自己的类重载多种比较运算符会简单不少。其中a\u0026lt;b时返回std::strong_ordering::less，a == b时返回std::strong_ordering::equal，a\u0026gt;b时返回std::strong_ordering::greater。\nstd::numeric_limits\u0026lt;T\u0026gt; 这个命名空间包含在\u0026lt;limits\u0026gt;头文件里，其可以给出一个基本数据类型的数据范围，例如\nstd::numeric_limits\u0026lt;T\u0026gt;::lowest();//给出T的最小取值（有符号时为绝对值最大的负数） std::numeric_limits\u0026lt;T\u0026gt;::min();//对于整数，给出最小取值，对于浮点数，给出最小的正数 std::numeric_limits\u0026lt;T\u0026gt;::max();//给出T的最大取值 std::numeric_limits\u0026lt;T\u0026gt;::epsilon();//浮点数给出最小精度，比如第一个大于1的数和1的差 大括号初始化变量 我们可以用如下方法初始化变量\nfloat a = 1.5f; float b {1.5f}; 第一种是传统方法，第二种方法有一点好处是，在隐式的基本类型转换中，如果类型收窄（Type Narrowing）会给出Warning，甚至会直接给出error。\nint i = 2.5f;//编译器无warning float f = 2.5f; int j {f};//编译器产生warning，有时候类型收窄确实可能导致错误。 int k {2.5f};//编译器会直接给出error 如果你确定类型收窄是你需要的，那么用显式的强制类型转换。\n[[nodiscard]]修饰 C++17引入。这个修饰是给函数使用的，如果函数有返回值，并且希望返回值不会被忽略，就可以使用这个修饰。\n比如\nvoid normalize(vec3f \u0026amp; v);//把v变成单位向量 vec3f normalized(vec3f const \u0026amp; v);//返回v的单位向量，但v不变 这组可能分辨不清的函数，我们就可以把第二个函数加上这个修饰，编译器会在返回值没有被接收的时候发出warning。\nvector扩容（初步） 这里是一个简易版本的介绍，后续可能会专门出博客来详细解析STL的各种容器与算法（TODO）。\n我们要首先明白vector的内存布局是怎样的。一般来说，除非你在全局变量里面声明vector，不然vector对象都是在栈中的。但是vector的内容（即buffer）却是分布在堆里。\n首先我们区分一下size和capacity，前者是vector里面拥有的元素的个数，后者是vector可以放多少元素。\n当size=capacity时，此时如果我们进行push_back，容量不够，不能放进去。之后vector就要进行扩容。此时，实际上的内存不是在buffer后面再给你新分配一些，与前面的连起来。而是重新找一块更大的内存，将原来的buffer整体复制到堆中的新位置，再把新的插入元素放到最后。栈中的vector对象则简单的把指向的buffer地址改成新的即可（当然还有修改size和capacity）。\n每次扩容，capacity会变为原来大小的\\(1.1\\)至\\(2\\)倍。\n由于扩容的时候要复制，这是很大的开销。所以如果你提前知道数据个数的具体、或者大概的范围，那么最好使用vector\u0026lt;int\u0026gt; vec(n);或者vec.reserve(n);（区别是前者会有n个初值为0的元素，后者没有元素，只有capacity==n；当然resize(n)时，如果新大小大于原来的大小，会把多出来的空间用0填补）来提前给够空间。如果你不确定那么没有什么办法，大概只能这样。\n另外，扩容之后，之前的迭代器、指针都可能会失效。包括指向vector对象的指针和指向元素的指针。\nauto与“C-Like”字符串字面量 auto a = \u0026quot;test\u0026quot;;这个语句，a不会是std::string类型，而是char const[]类型。这也就意味着你也无法使用auto b = \u0026quot;123\u0026quot;+\u0026quot;456\u0026quot;;。\nstd::string的字符串字面量 这个特性是在C++14引入的。auto s = \u0026quot;test\u0026quot;s;，在原来的基础上，字符串后面加上s，即可推断为std::string类型。\n不过使用之前要先using namespace std::string_literals;\n原始字符串字面量 其用法为R\u0026quot;(此处填入原始字符串)\u0026quot;，这里面的原始字符串，不需要转义符，原本是什么，直接输出出来就是什么，而且转行也会被输出出来。这在我们的字符串是Windows目录时可能会比较方便，例如auto s = R\u0026quot;(C:\\Windows\\SysWOW64\\IME\\SHARED)\u0026quot;，不需要再像以前一样，给每个\\换成\\\\了。\n另外，auto s = R\u0026quot;(C:\\Windows\\SysWOW64\\IME\\SHARED)\u0026quot;还是被推断为char const[]，在C++14之后，声明using namespace std::string_literals;，之后auto s = R\u0026quot;(C:\\Windows\\SysWOW64\\IME\\SHARED)\u0026quot;s;可以推断为std::string\nstd::string_view C++17引入的功能，具体的用法和应该使用的地方都和std::string const \u0026amp;差不多，都是对于一个string的只读，并且不开额外空间。区别是，const \u0026amp;版本是建立了对原string的引用。string和vector很像，都是对象和buffer分开，而std::string_view就是一个对原string的buffer的只读的工具。推荐在新版本C++中使用这个功能。\n比const \u0026amp;有一个好处，如果用在函数参数里，而传入的是字符串字面量，则const \u0026amp;会有一次复制操作，而string_view没有。\n但是，如果你不在函数参数里使用，而是\nstd::string_view sv2 {\u0026#34;std::string Literal\u0026#34;s}; cout \u0026lt;\u0026lt; sv2; 则是错误的，因为字符串对象已经被销毁。所以推荐只在函数参数里使用。\n函数参数什么时候用const \u0026amp;? 可能会有人在第一次学习到用const \u0026amp;来修饰形参，觉得这东西简直太好了，可以不用花费额外开销去复制。但其实不总是这样。\n如果你传入的数据是double，int等开销本来就很小的变量，根本就不需要用const \u0026amp;，那反而还会增加开销。\n在变量复制开销本来就很小时，不需要修饰符 如果你想要防止自己不小心修改了变量，只加const即可 如果你想要修改实参，则显然必须加且只加\u0026amp;传入引用（例如swap函数） 如果你传入的复制开销很大（例如一个图片类），又不需要修改，加const \u0026amp; 左值、纯右值、亡值 2.jpg\r曾经是只有左值和右值的。左值意味着可以取地址，而右值意味着不可以取地址。叫左值右值则是因为左值一般在赋值号左边，而右值在右边。\n现代C++中，值类别必定属于三者其一：左值、亡值、纯右值。\n左值（lvalue）\n左值是有标识符、可以取地址的表达式。例如变量名、函数名确定的值。返回类型为左值引用的函数返回的值（除了自定义的，还有赋值运算符、++a、--a）。字符串字面量（const char*类型的左值）\n纯右值（prvalue）\n右值正好相反，就是没有标识符、不可获取地址的表达式。例如字面常量（除了字符串字面量），操作符的临时结果（例如a=b+c;中的b+c）（其实可以归类为下一条的），函数的返回值（除了返回左值引用和右值引用的）（例如x++）。\n但是，右值引用变量，是一个左值。因为它再怎么说也是一个变量。\n亡值（xvalue）\n可以看作是有名字、有地址的右值，跟无名的纯右值区分开。所以实际上std::move(x)这样的函数，返回的是亡值。返回类型是对象的右值引用的函数调用，返回的也都是亡值。\n泛左值（glvalue）\n即左值和亡值。其特点是有标识符，有地址。但左值不可移动而亡值可移动。\n右值（rvalue）\n即纯右值和亡值。其特点是可移动。但亡值有标识符和地址而纯右值没有。\n\u0026amp;引用\n\u0026amp;只能引用左值。也就是说void fun(int \u0026amp; a);这个函数，你传入fun(1);会编译失败，但是int \u0026amp; b=c;fun(b);是可以编译成功的。引用本身是个左值。\nconst \u0026amp;引用\nconst \u0026amp;既可以引用左值，又可以引用右值。其本身是一个左值。\n\u0026amp;\u0026amp;引用\n即右值引用，只能绑定右值。本身是个左值。\n如果函数重载里只有const \u0026amp;，那么传入右值会调用这个函数重载。如果重载有\u0026amp;\u0026amp;形式的，那么会优先调用\u0026amp;\u0026amp;形式的重载。这种特性允许了移动构造函数的存在。\n转发引用（万能引用）\n这个只会出现在模板中\ntemplate\u0026lt;class T\u0026gt; int f(T\u0026amp;\u0026amp; x){ // x 是转发引用 return g(std::forward\u0026lt;T\u0026gt;(x)); // 从而能被转发 } 见后写的完美转发部分。\n右值引用（或常左值引用）延长生命周期 std::string s1 = \u0026#34;test\u0026#34;; std::string const \u0026amp; s2 = s1+s1; // 这个右值的生命周期被延长到和s2一样，但是不可修改 std::string \u0026amp;\u0026amp; s3 = s1+s1; // 同上，但是可修改 但是，延长生命周期只能对纯右值使用，而不能对亡值使用。例如A \u0026amp;\u0026amp; x = std::move(y)，此时对x进行解引用，是未定义行为。因为y已经析构。\n移动语义 把一头大象从一台冰箱里移动到另一台冰箱里需要几步？C++曾经的做法是，首先完整地在冰箱B里复制一个一模一样的大象，然后蒸发掉冰箱A中的大象。\n正常人的想法是，把大象从A中拉出来，把大象推进B冰箱中，关上冰箱门。\nC++11的移动语义实现了这个正常人的想法。例如\nstd::vector\u0026lt;int\u0026gt; v1{1,2,3,4,5,6}; std::vector\u0026lt;int\u0026gt; v2(std::move(v1)); 可以把v1移动到v2中，而非拷贝一个一样的到v2中。发挥了关键作用的是std::move和其对应的移动构造（和移动赋值）函数。\n注意，std::move仅仅是将一个值强制转换到右值（亡值），而不进行其他操作。真正的移动行为是在移动构造（和移动赋值）函数中实现的。\n小心返回引用的函数 例如\nint\u0026amp; fun(int x){ int y = x+1; return y; } 显然y的生命周期只能持续到函数结束，返回的引用就指向了一个无效的内存，这个要特别小心。但是如果你通过new分配了一个对象，再返回引用，则是可以的，这个对象的生命周期持续到你手动使用delete或者程序结束。不过并不推荐总是这样做，有时最好直接返回值。\n引用可能会像迭代器一样失效 比如对vector进行的操作会涉及capacity的修改，比如在set中进行插入和删除操作，这些是会使原来的迭代器无效的。这同时会使引用失效。就比如我们介绍过vector在扩容时会复制元素到新的内存，原来的引用指向的内存就会被释放，变成无效内存，此时再进行操作是UB。\n不要用引用来延长函数返回值的生命周期 std::vector\u0026lt;int\u0026gt; fun(){...} auto const \u0026amp; v = fun();//现在fun的返回值的周期延长到和v一样，通常不会造成问题 auto const \u0026amp; v2 = fun()[0];//这是最危险的情况，fun的返回值其实生命周期已结束，v2引用的元素已经变成了无效内存，对v2的操作是UB 鉴于上述情况，最好不要用引用接受函数返回值，直接用传值的方式更好。\nstruct/class的大括号初值 struct St{ int x; double y; }; St st{1, 2.0};//也可以St st = {1, 2.0}; 像这样，用大括号给结构体、类赋初值，其顺序和结构体内部声明的顺序要一致。\n类拷贝（copy） C++与Java、Python等不同，在下面的例子中\nstruct Point{ double x,y; }; Point p1{1.0, 2.0}; Point p2 = p1; 用到了p2 = p1这一语句。在Java和Python中，p1、p2现在都指向同一个对象Point(1.0, 2.0)，而其本身并不是对象。在C++中，p2把p1的所有内容拷贝赋值给自己，它们两个是两个不同的对象（即使内容相等）。\n在C++中，拷贝默认是深拷贝，而Java和Python中是浅拷贝。如果要在C++里面使用浅拷贝，则使用Point \u0026amp; p3 = p1即可（也可以用指针）。\n除了是否新建一个对象以外，这两者的生命周期也不同。C++的对象在p1销毁时就销毁了，而在Java中p1销毁之后，由于还有p2指向这个对象，所以对象本身不会销毁。如果所有指向全都销毁，那么垃圾回收机制才会销毁这个对象。\n另外，通常“相等”的概念也不同。在Java中，对两个对象变量使用==运算符，如果它们指向不同的对象，则不相等，否则相等。在C++中，我们一般会重载==运算符，判断两者的内容是否相等。\n拷贝构造函数 todo\n赋值构造函数 todo\nargc, argv int main(int argc, char* argv[]){ //... } main函数可以带两个参数，按照传统我们把第一个参数叫argc，第二个参数叫argv。argc是一个整数，代表命令行中参数的个数，argv是每个参数的字符串。\n命令行中参数通常由空格分开，例如\n./g++.exe 1.cpp -o 1.exe -Wall 其中有五个参数，第一个为可运行文件本身的路径，后面的为运行它的参数。意味着argc等于5，argv存有五个字符串。一般我们会用atoi把字符串里的数字转化为int类型。\nfile stream 在NOIP、NOI等竞赛中，一般会用freopen函数。这是一个C的函数，如果要更C++一点，我们会使用file stream。\n#include \u0026lt;fstream\u0026gt; int main(){ std::ofstream os{\u0026#34;1.txt\u0026#34;}; if(os.good()){//在每次使用时都应该确保good os\u0026lt;\u0026lt;\u0026#34;hello world\\n\u0026#34;; } return 0; } 如上为写数据时的使用例子。可以看到和cout的用法很像。\n#include \u0026lt;fstream\u0026gt; int main(){ std::ifstream is{\u0026#34;2.txt\u0026#34;}; if(is.good()){//在每次使用时都应该确保good double x,y; is\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y; std::cout\u0026lt;\u0026lt;x\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;y\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } 如上为读数据的例子。可以看到和cin的用法很像。\n另外，例如写到末尾还是覆盖，是文本还是二进制，这些都是可以设置的。具体参考https://zh.cppreference.com/w/cpp/header/fstream，这里简短的给出几个常用的\nstd::ofstream os{\u0026#34;out.txt\u0026#34;, std::ios::app}; //append而不是覆盖 std::ifstream is2{\u0026#34;in.tga\u0026#34;, std::ios::binary}; //写二进制 std::ofstream os2{\u0026#34;out.tga\u0026#34;, std::ios::binary}; //读二进制 重载\u0026laquo;和\u0026raquo;运算符 struct Vec{ double x,y; }; std::istream\u0026amp; operator\u0026gt;\u0026gt;(std::istream\u0026amp; is, Vec\u0026amp; v){ return is\u0026gt;\u0026gt;v.x\u0026gt;\u0026gt;v.y; } std::ostream\u0026amp; operator\u0026lt;\u0026lt;(std::ostream\u0026amp; os, Vec\u0026amp; v){ return os\u0026lt;\u0026lt;v.x\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;v.y; } std::cout\u0026lt;\u0026lt;Vec(2.0,3.0)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;;//可以像对int一样使用cin cout 主要是方便打印、输入数据，例如你在编写一个数值计算库，需要用到很多向量、矩阵的输出。\n类成员初始化 在C++ 11以前，我们初始化类成员一般只能在构造函数里进行，如\nclass Vec{ public: double x,y; Vec():y(0),x(0){} }; 其中:后面跟着的这个叫做初始化列表，成员后跟着的括号里面的写入初始值，即可完成初始化。\n注意，初始化列表里面的赋值顺序并不是初始化列表写出来的顺序，而是按照成员变量的声明顺序。例如上例，是先初始化x，再初始化y。这有时会导致UB，建议绝大部分时候，都要保持两者顺序一致。\n当然你也有可能这样写\nVec(int x_, int y_){ //而不是写:x(x_),y(y_) x = x_; y = y_; } 这其实能看出一个C++程序员的水平。对于int、double这种内置类型还好。但如果x、y是class，那么=意味着拷贝赋值，意味着可能会先构造一个新的对象实例，再拷贝给x和y。而是用初始化列表，则会直接调用构造函数，总体上少了拷贝这一个步骤。\n在C++ 11之后，我们也可以这样给初始值\nclass Vec{ public: double x=0.0, y=0.0; Vec(){} }; explicit关键字 class Cl{ public: int n; explicit Cl(int n_):n(n_){} }; void foo (Cl a) {} foo(1); //隐式调用Cl的构造函数，但因为其构造函数是explicit的，会报错 foo(Cl(1));//正常 个人认为这主要是方便强调一下传入的数据的类型，可能在调试环节比较有用。\n构造函数相互调用 Class Vec{ public: double x, y; Vec():Vec(0){} Vec(double a):Vec(a,a){} Vec(double x_, double y_):x(x_),y(y_){} }; 在C++里最好用nullptr而不是null C++和C语言的NULL定义是不同的，在C++中#define NULL 0，而在C中#define NULL ((void*)0)。不得不这样改的原因是：C++不支持void*的隐式转换。可见NULL就是一个数字0，它会有如下问题\nvoid foo(int n){} void foo(void *n){} 此时如果你调用\nfoo(NULL); 则会有二义性问题。编译可能会无法通过。用nullptr则不会有这个问题。\n当然，有时候我们会有以下三种写法\nif(p){} if(p!=NULL){} if(p!=nullptr){} 这更多的是一种风格问题，争论这个似乎是无用的。但是之前的二义性还是要小心的。\n如果你懒得管，那么就永远使用nullptr。\nC++四种类型转换 之前有隐式转换、C风格强制转换(int)a、函数风格转换int(a)，C++提供了四个新的类型转换来规避老的显式转换的一些问题。这四种转换是关键词，而非stl库。\nstatic_cast\u0026lt;type\u0026gt;(exp)，将exp转换为type类型。没有运行时类型检查来保证转换的安全性。主要用于基本类型的转化，例如double转int。 dynamic_cast\u0026lt;type\u0026gt;(exp)，主要用于子类父类指针之间的转化，见后。 const_cast\u0026lt;type\u0026gt;(exp)，用于修改变量的cv属性。type和exp应当具有同样的“类型”，只是cv修饰不同。 reinterpret_cast\u0026lt;type\u0026gt;(exp)，用于将指针地址转为整数，或者反过来。 在子类父类指针的转换中，static_cast把子类指针转为父类指针是安全的，而反过来向下转换是不安全的。而dynamic_cast两者都可以进行。上行时等价于static_cast，下行时加入了类型检查的功能，更加安全\nDerive* d1 = new Derive(); cout \u0026lt;\u0026lt; \u0026#34;d1: \u0026#34; \u0026lt;\u0026lt; d1 \u0026lt;\u0026lt; endl; Base* b1 = dynamic_cast\u0026lt;Base*\u0026gt;(d1); cout \u0026lt;\u0026lt; \u0026#34;b1: \u0026#34; \u0026lt;\u0026lt; b1 \u0026lt;\u0026lt; endl; // 这里的内存地址和上面的是一样的 Base* b2 = new Base(); cout \u0026lt;\u0026lt; \u0026#34;b2: \u0026#34; \u0026lt;\u0026lt; b2 \u0026lt;\u0026lt; endl; Derive* d2 = dynamic_cast\u0026lt;Derive*\u0026gt;(b2); cout \u0026lt;\u0026lt; \u0026#34;d2: \u0026#34; \u0026lt;\u0026lt; d2 \u0026lt;\u0026lt; endl; // 这里是nullptr，而非b2的地址。 // 如果使用是父类引用转化为子类引用，会抛出std::bad_cast // 只有当b2本来就指向一个Derive时，转化才会成功 // 如果是static_cast，则不会抛出，也不会在失败时nullptr。只有当b2指向Derive时，程序才会符合预期。否则之后可能会调用不存在的成员。 cv限定符 即const和volatile类型限定符，其中const用于定义类型为常量类型，volatile用于定义易变类型。\nconst意味着，这种对象不能被修改。直接修改时，编译报错。间接修改时（如通过指针修改），行为未定义。\nvolatile意味着，每次对该变量的访问都可能造成副作用。编译器不应该对其进行优化（例如连续两次读取优化为一次）。例如，不能简单地放到寄存器里应对多次连续访问，而是每次访问都要去内存里面去取，防止其值变化（例如被外部设备修改）。间接通过非volatile变量访问volatile变量是未定义的。\nconst volatile，从前面的定义看得出来，这两个限定符不冲突，可以同时使用。\n函数类型本身不存在cv限定，但是函数可以返回cv限定类型，也有“cv限定函数”类型。如果有任何 cv 限定符被添加到到函数类型的别名，那么它会被忽略。\ncv限定函数指的是在非静态成员函数中使用的cv限定。例如\nclass A{ public: void foo() {} void foo() const {} void foo() volatile {} void foo() const volatile {} }; 这个可以用于函数重载，其重载决议取决于*this的类型，如果*this是const的，那么调用foo()调用的就是void foo() const {}，以此类推。或者说A const a;调用的也是这个函数。const的成员函数意味着不能修改内部变量，除非有mutable修饰。\n注意，我个人觉得把const称作常量是有些误导的，应该称作不变量。并不是所有const都可以用在常量表达式、模板实参中的。例如\nint n; std::cin\u0026gt;\u0026gt;n; int const sz = n; std::array\u0026lt;int, sz\u0026gt; ar; // 报错 这里的sz仍然是运行时确定的，并不是一个编译期常量。真正应该被叫做常量的应该是constexpr，见后。\nmutable和const的成员函数 class Vec{ public: double x,y; int mutable sth; int sth2; void foo() const { sth++;//不会报错 } void bar() const{ sth2++;//会报错 } }; 把类成员函数用const修饰（放在参数列表之后），意味着，这个函数声称不会改变类内的所有成员变量的值。如果你想让几个特例可以修改，那么就把那个特例变量声明为mutable的即可。\nconst与指针 众所周知，在指针类型的声明里，const放的位置不同会导致语义的不同。主要是指针是否可变，以及指针指向的内容是否可变。 如下表\n声明 所指内容可变？ 指针本身可变？ T * 是 是 T const * 否 是 T * const 是 否 T const * const 否 否 简单来说就是const在星号右边则指针自己不可变，在左边则所指内容不可变。也可以理解为，const修饰的是它左边的东西。要么修饰指针（即星号），要么修饰值（即T）\n所以说，我更推荐T const的写法，而不是const T。但是我们也要知道，const T *是修饰值不可变。\n成员函数引用限定符 类似于cv限定的成员函数。不过引用限定不影响*this的性质，*this都是左值表达式。可以和cv限定同时使用\n#include \u0026lt;iostream\u0026gt; struct S { void f() \u0026amp; { std::cout \u0026lt;\u0026lt; \u0026#34;左值\\n\u0026#34;; } void f() \u0026amp;\u0026amp; { std::cout \u0026lt;\u0026lt; \u0026#34;右值\\n\u0026#34;; } }; int main() { S s; s.f(); // 打印“左值” std::move(s).f(); // 打印“右值” S().f(); // 打印“右值” } constexpr 有constexpr修饰的变量是一个真正的编译期确定的常量。有constexpr修饰的函数，在传入的参数都是编译期常量时，返回一个编译期常量。也就是说，这种函数也可以当做普通函数来使用，只不过返回的值是不是编译期常量，是根据传入的参数来决定的。\nconstexpr声明的对象成员蕴含const，函数声明中的constexpr蕴含了inline。\n举个例子，\nconstexpr int foo(int n){ return n+1; } int main(){ constexpr int n = foo(1); std::array\u0026lt;int, n\u0026gt; ar; return 0; } 智能指针 C++11后只有三种智能指针，unique_ptr，shared_ptr，weak_ptr。还有一种auto_ptr已经移除。智能指针可以方便管理资源的所有权，以及提供对于资源的RAII。\nunique_ptr，如同名字一样，是独占资源的。在实现上，他只能移动构造和赋值，而不能拷贝构造和赋值，保证了其所有权无法复制，同一时间只能有一个unique_ptr拥有该资源的所有权。\nstd::unique_ptr\u0026lt;int\u0026gt; p = std::make_unique\u0026lt;int\u0026gt;(1); std::cout\u0026lt;\u0026lt;*p\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; // 输出1 这里的p就独占了一个int对象的所有权。\nauto p2 = p; // 报错，无法拷贝构造 auto p3 = std::move(p); // 可以编译，p3获得所有权而p失去所有权 在make_unique时（C++14之后），相当于调用了unique_ptr\u0026lt;T\u0026gt;(new T(std::forward\u0026lt;Args\u0026gt;(args)...))。然后在unique_ptr生命周期结束（和所有权转移）时，会自动调用删除器来释放资源。默认的删除器通过delete实现，即对其包装的指针进行delete。\nshared_ptr，也如同名字一样，允许多个shared_ptr拥有同一个资源。在实现上，他可以移动构造移动赋值，也可以拷贝构造和拷贝赋值。其RAII的实现方法是，加入一个引用计数器，表明有多少shared_ptr在使用这个资源，每次复制时计数器加一，每当一个shared_ptr析构时计数器减一。如果计数器归零，那么销毁分配的对象。\nweak_ptr，它的出现是为了解决shared_ptr中的一个问题。假如我们有一个双向链表，它支持多个线程来读数据，所以我们理所当然地使用shared_ptr来管理其中的指针（例如next和prev）。但是在某种情况下就有问题，假设我们在局部作用域分配了一个链表，插入两个元素，然后就等待作用域结束后析构。此时会发生内存泄漏，为什么呢？\n我们就分析这两个节点的引用计数。其中第一个节点被head和第二个节点的prev指针指向，而第二个节点被tail和第一个节点的next指针指向。当list析构时，list只包含head和tail指针，这两个shared_ptr析构，将两个节点的计数器各减一，但是两个节点仍然互相有指针指向对面，所以两个节点的计数器都为一。所以两个节点无法自动销毁，造成内存泄漏。\nweak_ptr的思想在于，创建一个弱引用，不增加引用计数器的值。当我们需要使用被管理的对象时，手动转换成shared_ptr（此时计数器加一），再进行使用。而使用结束后再变回弱引用（计数器减一）。\nstd::weak_ptr\u0026lt;int\u0026gt; wp; { auto sp = std::make_shared\u0026lt;int\u0026gt;(42); wp = sp; std::cout\u0026lt;\u0026lt;wp.use_count()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;;// 输出1 if(std::shared_ptr\u0026lt;int\u0026gt; spt = wp.lock()) // 需要手动转化shared_ptr std::cout\u0026lt;\u0026lt;*spt\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } std::cout\u0026lt;\u0026lt;wp.use_count()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;;// 输出0 if(std::shared_ptr\u0026lt;int\u0026gt; spt = wp.lock()) // spt为nullptr std::cout\u0026lt;\u0026lt;*spt\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; 对于上面所说的链表，只需要把内部的next和prev换成weak_ptr即可解决问题。\nmake_shared和make_unique https://zh.cppreference.com/w/cpp/memory/unique_ptr/make_unique，其中指出，make_unique和unique_ptr\u0026lt;T\u0026gt;(new ...)是等价的。但我觉得下面关于make_shared的几点也适用于make_unique\n而https://zh.cppreference.com/w/cpp/memory/shared_ptr/make_shared中指出，make_shared和shared_ptr\u0026lt;T\u0026gt;(new ...)是有略微的区别的：\n因为shared_ptr有引用计数器，所以使用shared_ptr\u0026lt;T\u0026gt;(new ...)会先new出一个对象，然后再new一个控制块。这就是两次new，并且这两次的内存是可能不连续的。而make_shared只进行一次new并且控制块和对象连续分配（标准推荐而非强制） make_shared创造出来的资源，在所有shared_ptr生命期结束后，如果还有weak_ptr引用，则该资源会持续存在，直到所有weak_ptr结束。 如果当前语境可以访问非公开构造函数，那么shared_ptr\u0026lt;T\u0026gt;(new ...)可以正常使用。但make_shared只能调用公开的构造函数。 make_shared不能自定义删除器 make_shared使用::new，如果类重载了new运算符，则不同于shared_ptr\u0026lt;T\u0026gt;(new ...) placement new A *p = new A;完成了两个操作首先是在堆上分配了一块内存，然后将A在这块内存上默认构造。\n而placement new做的操作是，给定一块内存的首地址，在这块内存上构造对象。这样，我们就可以在栈上构造对象了。这样做的好处可以参考内存池，如果有一块内存可以复用，就不用反复分配内存了，节约开销。\nchar mem[100]; A *p = new (mem) A; this指针 有点类似于Python里的self参数，都是只能用在类里的。是一个指向对象自己的指针。\n析构函数的析构顺序 在析构函数执行完毕后，类成员变量的析构顺序，是按照其声明顺序的反方向进行的。\n有时候可以尝试集中处理Exception void handle_errors(){ try{ throw; //必要的，进行re-throw } catch(...){} catch(...){} catch(...){} } void foo(...){ try{ ... } catch(...){ handle_errors(); } } void bar(...){ try{ ... } catch(...){ handle_errors(); } } 这可以复用代码，尤其是你的东西可能会抛出一样的exception的时候。\nRAII思想和其对于Exception内存泄漏的保护 RAII是Resource Acquisition Is Initialization的缩写，意为资源获取就是初始化。\n其要求，对象在构造函数中获取资源，在析构函数中释放资源。为什么这是好的呢？他可以减少你管理内存的工作量，你不需要手动去到处写delete来释放内存。它会在对象生命周期结束的时候自动释放，也就避免了内存泄漏。\n而对于Exception，它也可以很好的保护内存。C++的Exception在throw的时候，保证可以释放创建的局部对象。于是就可以自动释放内存，而不用担心是否在throw前正确处理了内存。\n像C语言这样的东西，申请完内存需要free才能释放，如果在函数中提前返回了，无法运行到free这一行，那么内存就泄漏了。如下例\nvoid foo(){ int *a = malloc(...); ... if(...){ ... return; // 这里没有释放内存，产生泄漏 } ... free(a); return; } 所以如果C++调用了某个C库，又没有很好的释放内存，就可能会造成泄漏。如果你想避免这个，可能可以尝试用C++的类包装一下，提供析构函数。\n上例在exception结构中类似下例\nvoid foo(){ int *a = new...; ... if(...){ ... throw ...;// 这里没有释放内存，产生泄漏。但是如果有析构函数则可以避免 } ... delete a; return; } 另外，RAII也就要求你，不能在析构函数本身中出现提前的throw。\nnoexcept修饰 修饰函数时，如果给出noexcept，则意味着你保证：\n函数的操作不会失败 从外部来看，任何Exception是不可见的。或者说所有Exception都在内部处理了。 如果noexcept函数还是抛出了一个Exception，那么程序会终止。\n我们可以给noexcept提供一个条件，满足条件是函数才是noexcept的。\nvoid foo() noexcept(n\u0026lt;9){...} // 当n\u0026lt;9时noexcept void bar() noexcept( noexcept(foo) ){...} // 当foo是noexcept时，bar是noexcept 注意给assert的参数加上括号 因为assert其实是宏，所以\nassert(min(a,b)==a); //不好 assert((min(a,b)==a)); //好 否则，宏替换可能会出问题，而且你无法察觉。\nstatic_assert assert是给运行时用的，而static_assert就是给编译时用的。\nstatic_assert(bool_exp, \u0026#34;msg\u0026#34;); // C++11可用 static_assert(bool_exp); //C++17可用 用-DNDBUG忽略所有assert 这是g++的编译选项，只需使用这个参数即可\ng++ -DNDBUG ... 编译器warning的编译参数 默认编译并不会打开很多warning，在生产环境中，推荐使用\n-Wall -Wextra -Wpedantic -Wshadow -Werror -fsanitize=undefined,address 来开启更多warning。\nCmake使用 TODO\ndoctest/catch2/gtest使用 TODO\n不要在调试的时候到处写cout、cerr 首先这会干扰到原本的代码逻辑，你删除的时候可能会删错、忘删。另外，这并不适合写测试样例来检测是否正确，更好的办法是，定义一个函数\nvoid log(std::ostream\u0026amp; os, ...) {...} 把要输出测试的东西放到ostream里，方便测试样例获取\nstd::ostringstream oss; log(oss, ...); ASSERT_STREQ(oss.str(), \u0026#34;123\u0026#34;); 如果要调试最好使用GDB等工具。\nGDB使用 TODO\n使用g++/clang检测内存错误使用、未定义行为等 即之前介绍到的，只需要添加-fsanitize=undefined,address编译选项即可。在运行的时候，如果出现这种错误，就会提供报错信息。\n使用valgrind检测内存泄漏、死锁问题等 我们首先编译好程序，然后通过\nvalgrind [options] ./program [program options] 来执行检查。可选参数有\n--tool=memcheck，用来检查内存泄漏、对无效内存读写等 --tool=helgrind，用来检查死锁 --leak-check=full，用来显示内存泄漏的详细信息 -v/--verbose，用来显示额外信息 使用end迭代器的值是未定义行为 std::vector\u0026lt;int\u0026gt; vec; auto it = vec.end(); std::cout\u0026lt;\u0026lt;*it; // UB std::distance 求得左闭右开区间[it1, it2)的大小。\nstd::vector\u0026lt;int\u0026gt; vec{1,2,3}; auto x = std::distance(std::begin(vec), std::end(vec)); // 3 如果满足老式随机访问迭代器，那么复杂度是常数。否则复杂度为线性。\n所有序列容器都是所谓的regular types 也即下面四个特点：\n深可拷贝：在拷贝赋值、拷贝构造的时候，都是把容器内的每个值拷贝到新容器中 深可赋值：即给容器内的元素赋值时，都是把源数据进行拷贝（而非移动） 深可比较：即两个容器相等时，当且仅当每个元素相等 深所有权：容器析构时会析构所有元素 std::span C++20引入的功能。span对于vector、array，相当于string_view对于string。声明方法如下\nstd::span\u0026lt;int\u0026gt; // 声明一个可修改的 std::span\u0026lt;int const\u0026gt; // 声明一个不可更改的 std::span\u0026lt;int, 5\u0026gt; // 声明一个固定大小的，大小需要是编译期常数 和string_view一样，推荐只用在函数参数中。对于字面量，也会存在访问已经销毁的对象的问题。\nvoid foo(std::span\u0026lt;int const\u0026gt; s); std::vector\u0026lt;int\u0026gt; v{1,2,3,4}; foo(v); foo({v.begin()+1, v.end()}); span可以使用size、empty等获取大小信息，可以通过[]获取数据。对于比较两个span是否相同，和其他序列容器略有不同\nsv.data() == sw.data(); // 对比sv和sw是否是同一个内存位置上的对象 std::ranges::equal(sv,sw); // 对比sv和sw的值是否都相同 Map和Set查询元素是否存在的新方法 在C++20之后，引入了contains函数。如下\nstd::set\u0026lt;int\u0026gt; s{1, 2, 3}; if (s.contains(7)) {…} 比起find简单，比count不用转换类型。\n用equal_range获取multiset中所有给定值 std::multiset\u0026lt;int\u0026gt; s {2,4,4,4,6}; auto e4 = s.equal_range(4); cout \u0026lt;\u0026lt; *(e4.first) \u0026lt;\u0026lt; *(e4.second);// e4.first是第一个元素的迭代器，e4.second是最后一个元素之后的元素的迭代器 不要用迭代器遍历unordered_map和unordered_set 这两个容器的begin和end迭代器指向的是bucket，而不是元素。所以用迭代器遍历是不能达到目的的。但是可以使用for(auto x:ust)来遍历\nmap和set的判断元素相同的依据 这两个容器一样，都不是按照equal的意义去判断两个元素是否相同，而是按照equivalent去判断。\na==b // equal !(a\u0026lt;b) \u0026amp;\u0026amp; !(b\u0026lt;a) // equivalent 所以说，我们只要重载小于运算符，就可以让map和set运行起来，不需要大于和等于运算符。\n自定义unordered容器的哈希函数 一般都会新建一个类，重定义其函数调用运算符，返回值是size_t。\nstruct MyHash{ constexpr std::size_t operator () (A const \u0026amp; a) const noexcept { //... } }; std::unordered_set\u0026lt;A, MyHash\u0026gt; s; 默认使用的是std::hash\u0026lt;Key\u0026gt;，设计新哈希时，可以考虑把自定义类型的各个成员变量的std::hash组合起来，形成新哈希。\n标准库算法的执行策略 在C++17之后，许多标准库里的算法都可以选择执行策略，例如\nsort(std::execution::par, begin(v), end(v), cmp); 这是sort函数的又一个重载，其函数声明为\ntemplate\u0026lt; class ExecutionPolicy, class RandomIt, class Compare \u0026gt; void sort( ExecutionPolicy\u0026amp;\u0026amp; policy, RandomIt first, RandomIt last, Compare comp ); 其中执行策略有四种：\nstd::execution::seq // 算法的执行不能并行化、向量化 std::execution::par // 算法的执行可以并行化，但是不能向量化 std::execution::par_unseq // 算法的执行可以并行化、向量化 std::execution::unseq // 算法的执行不可以并行化，但是可以向量化。C++20后可用 并行执行时，算法本身不会避免数据竞争，这是程序员需要考虑的事，例如\nint a[] = {0, 1}; std::vector\u0026lt;int\u0026gt; v; std::for_each(std::execution::par, std::begin(a), std::end(a), [\u0026amp;](int i) { v.push_back(i*2+1); // 错误：数据竞争 }); 新for循环反向遍历的方法 C++20可用，让for(:)也能反向遍历。\nfor (int x : v | std::views::reverse) { cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } 泛型Lambda 泛型lambda不需要template，只需要用auto即可，例如\n[] (auto a, auto b){ return a+b;} [] (auto const \u0026amp; a, auto const \u0026amp; b){ return a+b;} std::memcpy的重叠问题 memcpy的定义如下：\nvoid* memcpy( void* dest, const void* src, std::size_t count ); 其把src中的字节复制到dest中，但是，如果src+count\u0026gt;dest，就会出现重叠的问题。根据cppreference，这是未定义的。此时我们要使用std::memmove。它可以规避这个问题，标准规定其要如同复制字符到临时数组，再从该数组到dest一般发生复制。\n同时，cppreference补充说，尽管说明了“如同”使用临时缓冲区，此函数的实际实现并不会带来二次复制或额外内存的开销。对于小count，它可能加载并写入寄存器；对于更大的内存块，常用方法是若目标在源之前开始，则从缓冲区开始正向复制，否则从末尾反向复制，完全无重叠时回落到更高效的std::memcpy。\n我自己看过gnu实现的标准库，确实是这样。内存中，若dest在src之前，就正向复制，否则，逆向复制类似于如下的循环\nfor(int i=count-1;i\u0026gt;=0;i--){ dest[i] = src[i]; } std::copy的重叠问题 类似于上一节的纯C库，这个C++库也有这个问题。\ntemplate\u0026lt; class InputIt, class OutputIt \u0026gt; OutputIt copy( InputIt first, InputIt last, OutputIt d_first ); 如果d_first在[first, last)中，行为未定义。此时用std::copy_backward替代（如果d_last在[first, last)中，则未定义，应该用std::copy）。\nstd::random_shuffle随机重排数组 std::vector\u0026lt;int\u0026gt; v {0,1,2,3,4,5,6,7,8}; std::random_shuffle(begin(v)+2, begin(v)+7); 在pytorch中打乱数据集用到了类似的东西。\nstd::fill 在某种意义上是比memset好的，memset是按字节赋值的，而std::fill是按元素赋值。比如\nint arr[100]; std::fill(arr, arr+100, 100000); 这个是memset不方便做到的。\nstd::generate auto gen = [i=0]() mutable { i += 2; return i; }; std::vector\u0026lt;int\u0026gt; v(7, 0); generate(begin(v)+1, begin(v)+5, gen); for (int x : v) { cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#39; \u0026#39;; } // 0 2 4 6 8 0 0 即在迭代器的这个范围内，每个元素使用一次gen并对其赋值。\nstd::transform template\u0026lt; class InputIt, class OutputIt, class UnaryOp \u0026gt; OutputIt transform( InputIt first1, InputIt last1, OutputIt d_first, UnaryOp unary_op ); 对每一个[first1, last1)中的元素使用一元函数unary_op，然后将值依次赋值给d_first开始的元素。\ntemplate\u0026lt; class InputIt1, class InputIt2, class OutputIt, class BinaryOp \u0026gt; OutputIt transform( InputIt1 first1, InputIt1 last1, InputIt2 first2, OutputIt d_first, BinaryOp binary_op ); 对每一个[first1, last1)中的元素，和first2开始的对应元素，使用二元函数binary_op，然后将值依次赋值给d_first开始的元素。\nstd::accumulate和std::reduce 二者都是进行[first, last)的加和（或自定义运算）的操作，区别在于std::reduce是可以并行化的。\nreduce(v.begin(), v.end()); // 执行累加，返回累加和，初值默认为T() reduce(v.begin(), v.end(), 1.0, std::multiplies\u0026lt;\u0026gt;{}); // 第三个参数为初值，第四个参数为运算。这里就是累乘 std::tuple 可以说是一个扩展维度的std::pair。使用例如下\nstd::tuple\u0026lt;double, int, char\u0026gt; t{1.2, 3, \u0026#39;a\u0026#39;}; std::cout\u0026lt;\u0026lt;std::get\u0026lt;0\u0026gt;(t); std::cout\u0026lt;\u0026lt;std::get\u0026lt;1\u0026gt;(t); std::cout\u0026lt;\u0026lt;std::get\u0026lt;2\u0026gt;(t); 比std::array好的地方在于其可以有不同的元素类型。但是，用作函数返回值、参数可能不是一个很好的想法。因为可读性较差，不如struct。\nstd::tie可以返回左值引用的元组。如下场景会比较好用\nstruct S { int n; std::string s; float d; friend bool operator\u0026lt;(const S\u0026amp; lhs, const S\u0026amp; rhs) noexcept { // 比较 lhs.n 与 rhs.n, // 然后为 lhs.s 与 rhs.s, // 然后为 lhs.d 与 rhs.d // 返回这个次序中第一个不相等的结果 // 或者当所有元素都相等时返回 false return std::tie(lhs.n, lhs.s, lhs.d) \u0026lt; std::tie(rhs.n, rhs.s, rhs.d); } }; 以及，拆包函数返回值，\nstd::tuple\u0026lt;int, int, double\u0026gt; foo(){ return {1, 2, 0.3}; } int main(){ int a, b; double c; std::tie(a, b, c) = foo(); // 或者可以写 auto [a, b, c] = foo()，只不过前者可以在c++11后使用，后者只能在c++17后使用 return 0; } std::optional C++17引入的新工具，在以前，我们生成新的资源时，通常会返回指向该资源的指针。如果返回的是nullptr，则说明分配失败。更现代的方法是使用std::optional\nstd::optional\u0026lt;std::string\u0026gt; create(bool b) { if (b) return \u0026#34;test\u0026#34;; return {}; // 等价于返回 std::nullopt } 检测返回的东西是否有效，可以像bool类型一样使用\nauto r = create(true); if(r){ //... } else{ //... } 也可以使用r.has_value()。如果要使用其包装的值，则可以使用如下两种办法\nr-\u0026gt;push_back(\u0026#39;b\u0026#39;); // 像指针一样使用 r.value().push_back(\u0026#39;c\u0026#39;); // 把值拿出来，再使用 std::variant 是在C++17提供的一种类型安全的联合体。一个 std::variant 的实例在任意时刻要么保有它的可选类型之一的值，要么在错误情况下无值。union的问题是，如果成员之一需要析构函数来释放资源，那么union定义的变量在结束生命周期时，不会自动调用析构函数。或者类似于，三个成员分别为int,double,char*的union，其被分配了一个new char[]给char *，那么在生命周期末尾时，不会自动调用delete []去释放空间。std::variant的出现解决了这个问题\nstd::variant\u0026lt;int, double, std::string\u0026gt; x, y; x = 1; y = \u0026#34;test\u0026#34;; x = 2.0; std::variant的变量在同时只能拥有一个具体的类型。如上，x不是int，就是double或者std::string。不过，可以方便地通过重新赋值的方式改变其具体类型。如果要知道当前的是哪种类型，可以通过\nx.index() 来获取，是int就返回0，double就返回1，即为声明时的下标，以此类推。\n获取值可以用\nstd::get\u0026lt;double\u0026gt;(x); std::get\u0026lt;1\u0026gt;(x); 来获取当前的值。如果试图获取非当前类型的值，就会抛出异常\ntry { std::get\u0026lt;int\u0026gt;(x); // x 含 double 而非 int：会抛出异常 } catch (const std::bad_variant_access\u0026amp; ex) { std::cout \u0026lt;\u0026lt; ex.what() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } 如果获取本就不可能存在的值，则会编译报错，例如std::get\u0026lt;float\u0026gt;, std::get\u0026lt;3\u0026gt;。当然，不想抛异常的话，可以使用\nint *i = std::get_if\u0026lt;int\u0026gt;(\u0026amp;x); if(i==nullptr){} else{} std::any 实现了一种类似于python的动态类型，可以把任何可复制构造类型的单个值放在里面。\nstd::any a = 1; std::cout \u0026lt;\u0026lt; a.type().name() \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; std::any_cast\u0026lt;int\u0026gt;(a) \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; a = 3.14; std::cout \u0026lt;\u0026lt; a.type().name() \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; std::any_cast\u0026lt;double\u0026gt;(a) \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; a = true; std::cout \u0026lt;\u0026lt; a.type().name() \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; std::any_cast\u0026lt;bool\u0026gt;(a) \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; 有点类似于C语言中的void *，想赋值什么就赋值什么，需要的时候再转成具体类型（对应这里的std::any_cast\u0026lt;...\u0026gt;(...)）。当然，这里可能会有转换失败的场景，会抛出异常。\ntry { a = 1; std::cout \u0026lt;\u0026lt; std::any_cast\u0026lt;float\u0026gt;(a) \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } catch (const std::bad_any_cast\u0026amp; e) { std::cout \u0026lt;\u0026lt; e.what() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } 可以通过has_value来检测有没有值，reset来清除值。\nC++构建模型 基本上都是继承C语言的框架，C++的源码文件也分为头文件.h, .hpp和翻译单元（Translation Units，TUs）.cpp, .cc, .cxx两部分。编译成可执行文件的流程，可以看下图\n1.jpg\r预处理器一般是进行文本替换的，就是把翻译单元中#define，#include的内容换成对应的内容等操作。然后送进编译阶段，将翻译单元转换成汇编，再转成目标文件。最后通过链接器将各个目标文件链接成可执行文件（主要负责将机器码组合，以及确定函数调用的地址等）。\n可以通过\ng++ -E A.cpp -o A.i # 生成预处理后的结果 g++ -S A.cpp -o A.s # 生成编译后的汇编代码 g++ -c A.cpp -o A.o # 生成编译后的目标文件 重复include导致的编译错误 重复include会导致重复定义，从而无法通过编译，例如\n// a.h void foo(){} // b.h #include \u0026#34;a.h\u0026#34; void bar(){ foo(); } // c.cpp #include \u0026#34;a.h\u0026#34; #include \u0026#34;b.h\u0026#34; int main(){ foo(); bar(); } 在预处理过后，c.cpp就会变成\n//这部分来源于a.h void foo(){} //这部分来源于b.h void foo(){} void bar(){ foo(); } int main(){ foo(); bar(); return 0; } 于是foo()就重复定义了，编译报错。一般来说处理办法是\n// a.h #ifndef A_H #define A_H void foo(){} #endif // b.h #ifndef B_H #define B_H #include \u0026#34;a.h\u0026#34; void bar(){ foo(); } #endif 这样在其他文件里就可以随意include了。\n重复include导致的链接报错 发生在如下情况\n// foo.h void foo(){} // a.cpp #include \u0026#34;foo.h\u0026#34; void bar1(){ foo(); } // b.cpp #include \u0026#34;foo.h\u0026#34; void bar2(){ foo(); } 如果，最终需要把a.cpp和b.cpp链接在一起形成一个可执行文件，那么，由于两个目标文件中都有一份foo()的完整定义，链接器就不知道具体调用的是哪个foo，产生报错。\n解决办法：\n新建一个foo.cpp，头文件中只声明，foo.cpp中定义，让其他两个目标文件来链接它 使用inline 使用namespace{}（匿名） inline void foo(){} namespace{ void foo(){} } 其中前一种被称作External Linkage，后面这两种称为Internal Linkage\n类似的，static类型的成员变量（但其实大部分static并不是外部链接），也是默认进行外部链接，需要把定义和声明分在两个文件里。否则需要使用static inline变量，才可以直接在头文件里定义。\n具体有哪些东西是外部链接，哪些东西是内部链接，可以看https://zh.cppreference.com/w/cpp/language/storage_duration\n使用namespace来防止命名冲突 namespace n1{ class set{...}; } namespace n2{ class set{...}; } 如上，区分了两种不同的set，也和std::set区分开。\nnamespace可以嵌套。可以通过using n1::set，来免去前置的命名空间说明，直接使用set来表示n1中的set。可以使用using namespace n1来导入整个n1中的东西。区别相当于python中的from n1 import set和from n1 import *之间的区别。\n可以使用using sc = std::chrono来给命名空间取别名，当然我也常用using LL = long long来给类型取别名。\ninline namespace 标准的描述是：命名空间内的声明将在它的外围命名空间可见。例如\nnamespace n1{ inline namespace current{ class A{...}; } namespace old{ class A{...}; } } n1::A a; // 调用的current的A n1::old::A aa; 用在这里，可以说是一种嵌套命名空间中的默认值，默认使用最新版本。\nfriend friend关键词提供了一种让其他类、函数访问自己私有成员的方法。例如\nclass A{ friend class B; friend void foo(A const \u0026amp;); }; 标准规定，如果在非局部的类定义中，定义一个友元函数（而非仅仅声明），那么他是一个非成员函数。可以通过函数名直接从外部调用\nclass A{ friend void bar(){} // 非成员函数 }; bar();// 直接调用 public, protected, private 用在成员声明时，public声明的成员可在任意位置访问；protected成员只能被该类成员、友元、子类的成员和友元访问；private成员只能被该类成员和友元访问。注意这里说的都是类的成员，而不要求必须是同一个实例才能访问自己的private成员，同一类的各个实例可以访问各自的private\n用在继承时，代表了三种继承方式。public继承时，保留父类的成员访问说明符；protected继承时，父类的public成员在子类中转为protected；private继承时，所有父类成员在子类中都是private的。注意，如果不提供继承方式，则默认为private继承。\noverride标识符 这是一个可选的标识符，使用或者不使用并不影响子类函数是否复写基类函数。只要签名一致，并且该父类函数是virtual函数，就会复写。但是，他是一种检测手段，写在子类函数中，如果忘写virtual，或者签名不一致，就会编译报错（因为没有复写任何函数）。\n析构函数务必声明为virtual 原因是，如果使用父类指针指向子类实例，在析构时，应当通过多态来调用子类的析构函数。如果没有声明为virtual，那么就会调用父类的析构函数，从而无法对子类析构，从而内存泄漏。\nfinal标识符 class A final : public B{};代表这个类A无法被继承\nclass A : public B{ public: void print() const override final; }; 代表这个print无法被子类复写。\n不要继承成员变量，组合优于继承 这是一种设计规范，即父类不应该设置成员变量。原因在于，子类并不一定会用上所有的父类成员变量，这会导致浪费内存。并且，子类实现可能和父类成员变量有冲突。与直接在父类中定义数据相反，我们应该单独定义一个数据的类。\nclass A{ public: // 只定义一些函数接口 }; class Data{}; class B : public A{ public: // ... private: Data d_; }; class C : public A{ public: // ... // 假设C无须数据，就不需要声明 }; 不要在构造函数里调用virtual函数 我们都知道，构造的时候会从父类一路构造下来。所以，如果在构造函数里调用virtual函数，则会调用父类的函数。\n不能被继承的成员函数 分别是构造函数、析构函数、赋值运算符、友元函数。\n不过构造函数可以委托构造，并且在构造子类时，会从祖先一路构造下来。析构子类时，会从子类往上析构所有祖先。\nRTTI 全称Runtime type identification，即运行时类型识别。如果我们想要知道父类指针具体指向了哪种对象，就需要用到这个东西。这里用到的关键词是typeid\n如果指针指向的是同一种对象，那么typeid(a)==typeid(b)。如果指向不同的子类对象，或者一个指向父类一个指向子类，那么typeid(a)!=typeid(b)。用typeid(a).name()可以输出具体类型的名字，不过这个名字被编译器加工过，不是你声明的类名。\nC++四个异常安全等级 从子集到超集排列的话\n不抛出。函数始终不会抛出异常。c++中noexcept表示此等级，析构函数默认是noexcept的。swap、移动构造函数、及为提供强异常保证所使用的其他函数，都被期待为不会失败（函数总是成功）。 强异常保证。如果函数抛出异常，那么程序的状态会恰好被回滚到该函数调用前的状态。（例如 std::vector::push_back）。 基本异常保证。如果函数抛出异常，那么程序处于某个有效状态。不泄漏任何资源，且所有对象的不变式都保持完好。 无异常保证。如果函数抛出异常，那么程序可能不会处于有效的状态：可能已经发生了资源泄漏、内存损坏，或其他摧毁不变式的错误。 普通构造和拷贝构造是可以抛异常的，但是移动构造和析构最好noexcept https://isocpp.org/wiki/faq/exceptions#ctor-exceptions，https://isocpp.org/wiki/faq/exceptions#ctors-can-throw\n这里说明，当你无法正确初始化时，就可以抛出异常。如果构造函数通过抛出异常来结束，那么与对象本身相关联的内存就会被清理掉——不存在内存泄漏。另外，如果在抛出之前，构造函数已经进行了一些在失败时需要修改的操作，也是需要恢复的。更好的办法是使用shared_ptr之类的包装类，在失败时会自动恢复原状。\n移动构造函数只是推荐noexcept，但是析构理应noexcept，否则会出现很多糟糕的情况。\n当析构失败的时候，上面的网站提到，最好就是记录日志，终止程序，但是不要抛异常。\nvector的元素最好有noexcept的移动构造函数 因为vector通常有强异常保证，如果元素不拥有noexcept的移动构造函数，那么vector就会用拷贝构造函数。这在vector内部的元素移动时会有很大的性能开销。\ncopy \u0026amp; swap 具体可看https://stackoverflow.com/questions/3279543/what-is-the-copy-and-swap-idiom/3279550#3279550，我这里也简单解释下。\n这里以一个拷贝赋值运算符为例\narray\u0026amp; operator=(array const \u0026amp; other){ if(this==\u0026amp;other) return *this; delete [] data_; data_ = nullptr; size_ = other.size_; data_ = mSize_ ? new int[size_] : nullptr; std::copy(other.data_, other.data_ + size_, data_); } 这里有几个问题：\n首先是判断是否自赋值。众所周知，条件分支会降低CPU的效率，而实际工程中，出现自赋值的情况是比较少的，所以CPU的周期被白白浪费在了这个判断上。 这不提供强异常保证。如果new的时候失败了，不仅自己的size_被改了，自己之前的data_更是消失了。无法再分配失败之后保持之前的状态。 代码整体和拷贝构造函数很像，累赘。 更好的方法如下\nclass array{ public: //... friend void swap(array\u0026amp; first, array\u0026amp; second) noexcept { using std::swap; swap(first.size_, second.size_); swap(first.data_, second.data_); } array(array const \u0026amp; other): size_(other.size_), data_(size_?new int[size_]:nullptr){ std::copy(other.data_, other.data_ + size_, data_); } // 即使分配失败，也不会内存泄漏，更不会改变原有的状态（因为没有原有的状态） array\u0026amp; operator=(array other){ // 在参数中拷贝构造了，少写代码 swap(*this, other); return *this; } private: std::size_t size_; int* data_; }; 在c++11之后还可以方便地实现移动构造\narray(array \u0026amp;\u0026amp; other) noexcept : array(){ swap(*this, other); } 实参依赖查找（ADL） 简单理解来说，如果在函数调用的上下文中找不到该函数的定义，C++就会从实参的命名空间中查找该函数的定义。例如\n#include \u0026lt;iostream\u0026gt; int main() { std::cout \u0026lt;\u0026lt; \u0026#34;测试\\n\u0026#34;; // 全局命名空间中没有 operator\u0026lt;\u0026lt;，但 ADL 检验 std 命名空间， // 因为左实参在 std 命名空间中 // 并找到 std::operator\u0026lt;\u0026lt;(std::ostream\u0026amp;, const char*) operator\u0026lt;\u0026lt;(std::cout, \u0026#34;测试\\n\u0026#34;); // 同上，用函数调用记法 // 然而， std::cout \u0026lt;\u0026lt; endl; // 错误：\u0026#39;endl\u0026#39; 未在此命名空间中声明。 // 这不是对 endl() 的函数调用，所以不适用 ADL endl(std::cout); // OK：这是函数调用：ADL 检验 std 命名空间， // 因为 endl 的实参在 std 中，并找到了 std::endl (endl)(std::cout); // 错误：\u0026#39;endl\u0026#39; 未在此命名空间声明。 // 子表达式 (endl) 不是函数调用表达式 } 完美转发，引用折叠 正如前面所说，\ntemplate\u0026lt;class T\u0026gt; void f(T\u0026amp;\u0026amp; x){ // x 是转发引用 g(std::forward\u0026lt;T\u0026gt;(x)); // 从而能被转发 } 模板中的T\u0026amp;\u0026amp;是一个转发引用。当我们传入int \u0026amp; a时，T实际上就是int \u0026amp;，于是函数调用就变成了int \u0026amp; \u0026amp;\u0026amp;这样的类型，此时它是左值引用还是右值引用呢？这就要引入类型折叠。\nC++规定：type \u0026amp; \u0026amp;, type \u0026amp; \u0026amp;\u0026amp;, type \u0026amp;\u0026amp; \u0026amp;都变成左值引用type \u0026amp;，只有type \u0026amp;\u0026amp; \u0026amp;\u0026amp;仍然是右值引用type \u0026amp;\u0026amp;。那如果我们\nvoid g(int\u0026amp; x) { std::cout \u0026lt;\u0026lt; \u0026#34;int \u0026amp;\\n\u0026#34;; } void g(int\u0026amp;\u0026amp; x) { std::cout \u0026lt;\u0026lt; \u0026#34;int \u0026amp;\u0026amp;\\n\u0026#34;; } template \u0026lt;class T\u0026gt; void f(T\u0026amp;\u0026amp; x) { g(x); } void solve() { int a; f(a); // 打印int \u0026amp; f(std::move(a)); // 还是打印int \u0026amp; } 这样进行调用，x可能是左值引用或者右值引用，但是x自己作为一个变量，它是左值。我们就无法把右值的参数传递给g()，就无法调用g(int \u0026amp;\u0026amp;)，只会调用到g(int \u0026amp;)。\n为了解决这个问题，C++使用std::forward\u0026lt;T\u0026gt;(x)来保持值类型不变，来传递参数。就如同开头的代码。此时就可以分别打印出int \u0026amp;和int \u0026amp;\u0026amp;了。\n另外，转发引用会保留实参的cv属性。\n注意\ntemplate\u0026lt;class T\u0026gt; void f1(T\u0026amp;\u0026amp; x); // x 是转发引用 struct A{ template\u0026lt;class T\u0026gt; void f2(T\u0026amp;\u0026amp; x); // x 是转发引用 }; template\u0026lt;class U\u0026gt; struct B{ void f3(U\u0026amp;\u0026amp; x); // 这个x不是转发引用 template\u0026lt;class T\u0026gt; void f4(T\u0026amp;\u0026amp; x); // x 是转发引用 }; 用上形参包，完美转发例如：\ntemplate\u0026lt;class T, class... Args\u0026gt; auto f(Args\u0026amp;\u0026amp;... args){ return std::pari\u0026lt;T, int\u0026gt;{std::forward\u0026lt;Args\u0026gt;(args)..., 0}; } 模板类暴露类型给外部 template\u0026lt;class T\u0026gt; struct Point{ using value_type = T; // 外部可以使用typename Point::value_type;来获取类型 T x; T y; }; 类模板实参推导指引 // 模板的声明 template\u0026lt;class T\u0026gt; struct container { container(T t) {} template\u0026lt;class Iter\u0026gt; container(Iter beg, Iter end); }; // 额外的推导指引 template\u0026lt;class Iter\u0026gt; container(Iter b, Iter e) -\u0026gt; container\u0026lt;typename std::iterator_traits\u0026lt;Iter\u0026gt;::value_type\u0026gt;; // 使用 container c(7); // OK：用隐式生成的指引推导出 T=int std::vector\u0026lt;double\u0026gt; v = {/* ... */}; auto d = container(v.begin(), v.end()); // OK：推导出 T=double container e{5, 6}; // 错误：std::iterator_traits\u0026lt;int\u0026gt;::value_type 不存在 总而言之，通过对构造函数里传入的参数进行分析，得到类模板的实参。但有时候隐式生成的推导指引没有那么厉害，看不透用户的想法。此时就需要一个额外的用户定义的推导指引。如上面的代码，我们把container(Iter b, Iter e)这样的构造函数，推导出其实参为typename std::iterator_traits\u0026lt;Iter\u0026gt;::value_type。这样就能正确实例化模板了。\n用户定义的推导指引必须指名一个类模板，且必须在类模板的同一语义作用域（可以是命名空间或外围类）中引入，而且对于成员类模板必须拥有同样的访问，但推导指引不会成为该作用域的成员。\n推导指引不是函数且没有函数体。推导指引不会被名字查找所找到，并且除了在推导类模板实参时与其他推导指引之间的重载决议之外不会参与重载决议。不能在同一翻译单元中为同一类模板再次声明推导指引。\n模板实例化和模板特化 以前我没分清楚这两个东西。\ntemplate\u0026lt;class T\u0026gt; class A{ // ... }; A\u0026lt;int\u0026gt; a; 上面这个代码叫做模板实例化。没有实例化的模板不会作为汇编指令生成。只有当实际调用到这个模板类、模板函数的时候，才会生成一个匹配的类、函数，生成汇编指令。\ntemplate\u0026lt;class T\u0026gt; class A{ // ... }; template\u0026lt;\u0026gt; class A\u0026lt;int\u0026gt;{ // ... }; 上面的代码叫做模板特化。就是把其中的一种情况拿出来，单独有自己的逻辑。在模板实例化的时候，会先查找最特殊的模板。可以通过只声明、不定义、另外定义特化的方式来限制类型。\ntemplate\u0026lt;class T\u0026gt; class A; template\u0026lt;\u0026gt; class A\u0026lt;int\u0026gt;{ //... }; template\u0026lt;\u0026gt; class A\u0026lt;double\u0026gt;{ //... }; 以上代码，声明A\u0026lt;int\u0026gt;, A\u0026lt;double\u0026gt;的变量都会成功，而A\u0026lt;float\u0026gt;则会报错。\n模板最好都写在头文件里 如果不全写在头文件里会有什么问题呢？见下例\n// B.h template\u0026lt;class T\u0026gt; class B{ public: void foo(T x); }; // B.cpp #include \u0026#34;B.h\u0026#34; #include \u0026lt;iostream\u0026gt; template\u0026lt;class T\u0026gt; void B\u0026lt;T\u0026gt;::foo(T x){ std::cout\u0026lt;\u0026lt;x\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } // A.cpp #include \u0026#34;B.h\u0026#34; int main(){ B\u0026lt;int\u0026gt; b; b.foo(666); return 0; } 如上，我们把B中函数的定义和声明分离了。此时我们用g++ A.cpp B.cpp -o .\\A.exe编译，链接器会报错：\nx86_64-w64-mingw32/bin/ld.exe: C:\\Users\\Kegalas\\AppData\\Local\\Temp\\ccCn8we2.o:A.cpp:(.text+0x1a): undefined reference to `B\u0026lt;int\u0026gt;::foo(int)\u0026#39; collect2.exe: error: ld returned 1 exit status 未定义？我们看看汇编后的代码是什么\n.file\t\u0026#34;A.cpp\u0026#34; .text .def\t__main;\t.scl\t2;\t.type\t32;\t.endef .globl\tmain .def\tmain;\t.scl\t2;\t.type\t32;\t.endef .seh_proc\tmain main: .LFB0: pushq\t%rbp .seh_pushreg\t%rbp movq\t%rsp, %rbp .seh_setframe\t%rbp, 0 subq\t$48, %rsp .seh_stackalloc\t48 .seh_endprologue call\t__main leaq\t-1(%rbp), %rax movl\t$666, %edx movq\t%rax, %rcx call\t_ZN1BIiE3fooEi # 调用b.foo(666) movl\t$0, %eax addq\t$48, %rsp popq\t%rbp ret .seh_endproc .ident\t\u0026#34;GCC: (Rev7, Built by MSYS2 project) 13.1.0\u0026#34; .def\t_ZN1BIiE3fooEi;\t.scl\t2;\t.type\t32;\t.endef 这里好像没有什么问题，直接去调用了foo，然后我们来看看B.cpp的汇编\n.file\t\u0026#34;B.cpp\u0026#34; .text .section .rdata,\u0026#34;dr\u0026#34; _ZNSt8__detail30__integer_to_chars_is_unsignedIjEE: .byte\t1 _ZNSt8__detail30__integer_to_chars_is_unsignedImEE: .byte\t1 _ZNSt8__detail30__integer_to_chars_is_unsignedIyEE: .byte\t1 .ident\t\u0026#34;GCC: (Rev7, Built by MSYS2 project) 13.1.0\u0026#34; 什么？里面居然没有_ZN1BIiE3fooEi这个符号？为什么呢？前面也提到过，只有当模板被实例化的时候，才会生成对应的汇编指令。这里的问题正是，没有实例化。\nA.cpp中include了B.h，确实在B\u0026lt;int\u0026gt; b的时候对类模板进行了实例化。但是，类模板里面的成员函数只是声明！没有实际定义。而在编译B.cpp的时候，就没有类似于B\u0026lt;int\u0026gt; b这样的东西对它进行实例化了（A.cpp和B.cpp不是同一个翻译单元）。于是void B\u0026lt;T\u0026gt;::foo(T x)就没有进行实例化，也就没有实际的汇编指令，也就没有_ZN1BIiE3fooEi这个符号。所以链接的时候就提示无法找到定义。\n应该怎么做？我们只需要显式实例化即可：\n// B.cpp #include \u0026#34;B.h\u0026#34; #include \u0026lt;iostream\u0026gt; template\u0026lt;class T\u0026gt; void B\u0026lt;T\u0026gt;::foo(T x){ std::cout\u0026lt;\u0026lt;x\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } template class B\u0026lt;int\u0026gt;; 即加上了最后一行。再来看看现在的汇编代码\n.file\t\u0026#34;B.cpp\u0026#34; .text .section .rdata,\u0026#34;dr\u0026#34; .LC0: .ascii \u0026#34;\\12\\0\u0026#34; .section\t.text$_ZN1BIiE3fooEi,\u0026#34;x\u0026#34; .linkonce discard .align 2 .globl\t_ZN1BIiE3fooEi .def\t_ZN1BIiE3fooEi;\t.scl\t2;\t.type\t32;\t.endef .seh_proc\t_ZN1BIiE3fooEi _ZN1BIiE3fooEi: .LFB2470: pushq\t%rbp .seh_pushreg\t%rbp movq\t%rsp, %rbp .seh_setframe\t%rbp, 0 subq\t$32, %rsp .seh_stackalloc\t32 .seh_endprologue movq\t%rcx, 16(%rbp) movl\t%edx, 24(%rbp) movl\t24(%rbp), %eax movl\t%eax, %edx movq\t.refptr._ZSt4cout(%rip), %rax movq\t%rax, %rcx call\t_ZNSolsEi movq\t%rax, %rcx leaq\t.LC0(%rip), %rax movq\t%rax, %rdx call\t_ZStlsISt11char_traitsIcEERSt13basic_ostreamIcT_ES5_PKc nop addq\t$32, %rsp popq\t%rbp ret .seh_endproc .section .rdata,\u0026#34;dr\u0026#34; _ZNSt8__detail30__integer_to_chars_is_unsignedIjEE: .byte\t1 _ZNSt8__detail30__integer_to_chars_is_unsignedImEE: .byte\t1 _ZNSt8__detail30__integer_to_chars_is_unsignedIyEE: .byte\t1 .ident\t\u0026#34;GCC: (Rev7, Built by MSYS2 project) 13.1.0\u0026#34; .def\t_ZNSolsEi;\t.scl\t2;\t.type\t32;\t.endef .def\t_ZStlsISt11char_traitsIcEERSt13basic_ostreamIcT_ES5_PKc;\t.scl\t2;\t.type\t32;\t.endef .section\t.rdata$.refptr._ZSt4cout, \u0026#34;dr\u0026#34; .globl\t.refptr._ZSt4cout .linkonce\tdiscard .refptr._ZSt4cout: .quad\t_ZSt4cout 可见_ZN1BIiE3fooEi:已经在其中了。\n不过本小节的标题是“模板最好都写在头文件里”，我们不可能显式实例化所有可能情况。一切的罪魁祸首可能就是头文件中只进行了声明，而没有定义。于是无法正常实例化。我们应该做的，就是把定义放在头文件里。实际上包括stl在内的很多模板库都是head-only的。\n不过如果我们要限制用户只能使用特定的几种类型，分离定义和声明，显式实例化这几种特定的类型，是可以考虑的。\nauto类型推断 auto x = y，会抛弃y的cv、引用类别。例如\nint i = 1; int \u0026amp;j = i; int const \u0026amp; k = i; auto x = i; // int auto y = j; // int auto z = k; // int 我们可以根据自己的需求去加cv和引用类别\nauto x = i; // int auto \u0026amp;y = i; // int \u0026amp; auto const \u0026amp; y = i; // int const \u0026amp; 注意，C++11下\nauto x = {3}; // 推断为std::initializer_list\u0026lt;int\u0026gt; auto y{3}; // 推断为std::initializer_list\u0026lt;int\u0026gt; auto z{3, 4}; // 推断为std::initializer_list\u0026lt;int\u0026gt; 这其实是不符合我们的直觉的，在C++17后，第二行被推断为int，而第三行报错。\ndecltype 和auto不同，不会抛弃cv和引用。如果实参是没有括号的标识表达式或没有括号的类成员访问表达式：\nint i = 1; int \u0026amp;j = i; int const \u0026amp; k = i; using T1 = decltype(i); // int using T2 = decltype(j); // int \u0026amp; using T3 = decltype(k); // int const \u0026amp; 并且，可以用decltype保留auto中会去除的cv和引用，例如（C++14）\nint i = 1; int \u0026amp;j = i; int const \u0026amp; k = i; decltype(auto) x = i; // int decltype(auto) y = j; // int \u0026amp; decltype(auto) z = k; // int const \u0026amp; 如果decltype的实参是类型为T的任何其他表达式。表达式为亡值时，产生T\u0026amp;\u0026amp;；为左值时，产生T\u0026amp;；纯右值时产生T\nstd::declval 将任意类型T转换为（右值）引用类型，使得在 decltype 说明符的操作数中不必经过构造函数就能使用成员函数。\n注意，std::declval只能用于不求值语境，且不要求有定义；求值包含此函数的表达式是错误的。此函数不能被调用，因此不会返回值。返回类型是T\u0026amp;\u0026amp;，除非T是（可有cv限定的）void，此时返回类型是T。\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;utility\u0026gt; struct Default { int foo() const { return 1; } }; struct NonDefault { NonDefault() = delete; int foo() const { return 1; } }; int main() { decltype(Default().foo()) n1 = 1; // n1 的类型是 int // decltype(NonDefault().foo()) n2 = n1; // 错误：无默认构造函数 decltype(std::declval\u0026lt;NonDefault\u0026gt;().foo()) n2 = n1; // n2 的类型是 int std::cout \u0026lt;\u0026lt; \u0026#34;n1 = \u0026#34; \u0026lt;\u0026lt; n1 \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39; \u0026lt;\u0026lt; \u0026#34;n2 = \u0026#34; \u0026lt;\u0026lt; n2 \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } type_traits库 https://zh.cppreference.com/w/cpp/header/type_traits\n有很多用于判断类型特性的模板。例如is_const, is_class, is_pointer, is_pod, is_unsigned等等。太多不能一一介绍，见上面的链接。使用方法都是类似的\ntemplate\u0026lt;class T\u0026gt; void foo(T const\u0026amp; x){ constexpr bool check = std::is_unsigned\u0026lt;T\u0026gt;::value; // C++11 constexpr bool check2 = std::is_unsigned_v\u0026lt;T\u0026gt;;// C++17后 } 除了判断类型的，还有转换类型的。如add_const, remove_const, make_signed。这里主要讲一下decay和result_of\ndecay就是将变量的指针、引用、cv全部去掉，得到纯的T类型，如\n#include \u0026lt;type_traits\u0026gt; template\u0026lt;typename T, typename U\u0026gt; constexpr bool is_decay_equ = std::is_same_v\u0026lt;std::decay_t\u0026lt;T\u0026gt;, U\u0026gt;; // c++14可用 // c++11为typename std::decay\u0026lt;T\u0026gt;::type int main() { static_assert ( is_decay_equ\u0026lt;int, int\u0026gt; \u0026amp;\u0026amp; ! is_decay_equ\u0026lt;int, float\u0026gt; \u0026amp;\u0026amp; is_decay_equ\u0026lt;int\u0026amp;, int\u0026gt; \u0026amp;\u0026amp; is_decay_equ\u0026lt;int\u0026amp;\u0026amp;, int\u0026gt; \u0026amp;\u0026amp; is_decay_equ\u0026lt;const int\u0026amp;, int\u0026gt; \u0026amp;\u0026amp; is_decay_equ\u0026lt;int[2], int*\u0026gt; \u0026amp;\u0026amp; ! is_decay_equ\u0026lt;int[4][2], int*\u0026gt; \u0026amp;\u0026amp; ! is_decay_equ\u0026lt;int[4][2], int**\u0026gt; \u0026amp;\u0026amp; is_decay_equ\u0026lt;int[4][2], int(*)[2]\u0026gt; \u0026amp;\u0026amp; is_decay_equ\u0026lt;int(int), int(*)(int)\u0026gt; ); return 0; } result_of得到某个可调用对象的返回值的类型\nstruct S { double operator()(char, int\u0026amp;); float operator()(int) { return 1.0; } }; std::result_of\u0026lt;S(char, int\u0026amp;)\u0026gt;::type d = 3.14; // d 拥有 double 类型 double f(char c, int\u0026amp; a){ return 0.1; } std::result_of\u0026lt;decltype(\u0026amp;f)(char, int\u0026amp;)\u0026gt;::type d = 3.14; invoke_result是在C++17后加入的，用以取代result_of，后者已经在C++17中废弃，C++20中移除。语法略有不同，主要是没有括号。\nstd::invoke_result\u0026lt;S,char,int\u0026amp;\u0026gt;::type b = 3.14; std::invoke_result\u0026lt;decltype(f), char, int\u0026amp;\u0026gt;::type d = 3.14; CRTP 奇特重现模板模式（Curiously Recurring Template Pattern, CRTP）是一种惯用手法。\n主要就是父类是一个模板类，而子类继承父类，并且在模板实参里面填写子类。\ntemplate\u0026lt;class T\u0026gt; class Y {}; class X : public Y\u0026lt;X\u0026gt; {}; 主要用来实现编译期多态。\ntemplate \u0026lt;class Derived\u0026gt; struct Base { void name() { (static_cast\u0026lt;Derived*\u0026gt;(this))-\u0026gt;impl(); } }; struct D1 : public Base\u0026lt;D1\u0026gt; { void impl() { std::puts(\u0026#34;D1::impl()\u0026#34;); } }; struct D2 : public Base\u0026lt;D2\u0026gt; { void impl() { std::puts(\u0026#34;D2::impl()\u0026#34;); } }; void test() { // Base\u0026lt;D1\u0026gt; b1; b1.name(); // 未定义行为 // Base\u0026lt;D2\u0026gt; b2; b2.name(); // 未定义行为 D1 d1; d1.name(); D2 d2; d2.name(); } 可以看https://zhuanlan.zhihu.com/p/460497652学一些使用例。\ntypename消歧 template\u0026lt;class T\u0026gt; class B{ public: typedef int type; }; template\u0026lt;class T\u0026gt; class A{ typename B\u0026lt;T\u0026gt;::type a; // 在C++不那么先进的版本，不加typename会报错 }; 这被称作待决名的typename消歧义符，因为B\u0026lt;T\u0026gt;::type一般会被理解为静态成员。这里它作为一个typedef，需要我们用typename来消除歧义。\nSFINAE “替换失败不是错误” (Substitution Failure Is Not An Error)\n首先举个例子，即函数重载中\nclass A {}; class B: public A {}; class C {}; void foo(A const\u0026amp;) {} void foo(B const\u0026amp;) {} void bar() { foo(A()); foo(B()); foo(C()); } 其中foo(A());匹配void foo(B const\u0026amp;) {}失败了，但是不报错。而匹配void foo(A const\u0026amp;) {}成功了，所以调用了这个重载。foo(B());两个都能匹配成功，但是void foo(B const\u0026amp;) {}更特殊，所以调用这个重载。而foo(C());的所有匹配的失败了，才会进行编译报错。\n模板替换也是类似的，一个模板替换失败了，并不会直接导致编译错误，编译器会继续查询其他可以替换的模板，只要有一个成功，编译就可以通过。用cppreference的话来说：\n在函数模板的重载决议中会应用此规则：当模板形参在替换成显式指定的类型或推导出的类型失败时，从重载集中丢弃这个特化，而非导致编译失败。 例子：\nstruct A{ typedef int t; }; template\u0026lt;class T\u0026gt; void foo(typename T::t); template\u0026lt;class T\u0026gt; void foo(T); void bar(){ foo\u0026lt;A\u0026gt;(10); // 调用第一个重载，第二个重载匹配失败，因为10不能被隐式转化为A foo\u0026lt;int\u0026gt;(10); // 调用第二个重载，第一个重载匹配失败，因为int没有t成员 } 这只是最简单的使用例子，更为复杂一点的，STL提供了std::enable_if，来在编译时求值，从而开启或关闭某个特定的函数重载。\ntemplate\u0026lt; bool B, class T = void \u0026gt; struct enable_if; 如果B是true，那么enable_if含有typedef type，否则不含有。\n使用例：\ntemplate\u0026lt;class T\u0026gt; void destroy( T*, typename std::enable_if\u0026lt; std::is_trivially_destructible\u0026lt;T\u0026gt;::value \u0026gt;::type* = 0) { std::cout \u0026lt;\u0026lt; \u0026#34;销毁可平凡析构的 T\\n\u0026#34;; } 这里，如果T不是可平凡析构的，那么他就没有type这个成员，匹配就会失败，这个模板就会从重载集中移除。\nC++11中还添加了一个表达式SFINAE，例如：\nstruct X {}; struct Y { Y(X){} }; // X 可以转换到 Y template\u0026lt;class T\u0026gt; auto f(T t1, T t2) -\u0026gt; decltype(t1 + t2); // 重载 #1 X f(Y, Y); // 重载 #2 X x1, x2; X x3 = f(x1, x2); // 推导在 #1 上失败（表达式 x1+x2 非良构） // 重载集中只有 #2，调用它 这里由于X没有重载加法运算符，所以重载1的decltype(t1 + t2)非良构。在C++11时，这会被SFINAE使用，而在之前，这会直接导致编译错误。\n极简concept 如果我们要限定template里面的泛型T的性质，要怎么做呢？C++20提供了一个新的方法，即concept\n他有很多种使用方法，例如假设我们要求一个类型是可排序的，我们假设这个concept叫做Sortable，以有以下几种使用方法\ntemplate\u0026lt;class T\u0026gt; requires Sortable\u0026lt;T\u0026gt; void sort(T\u0026amp; s); template\u0026lt;class T\u0026gt; void sort(T\u0026amp; s) requires Sortable\u0026lt;T\u0026gt; ; // 换了下位置而已 template\u0026lt;Sortable T\u0026gt; void sort(T\u0026amp; s); void sort(Sortable auto\u0026amp; s); // 当然也可以用在返回值上，据说Stroustrup最喜欢这种 如何定义一个概念（concept）？\ntemplate \u0026lt; 模板形参列表 \u0026gt; concept 概念名 属性 ﻿(可选) = 约束表达式; 其中这个约束表达式，是一个在编译期可以被eval为bool的表达式或者编译期函数。如果代入模板形参，可以得到true的值，则返回成功，否则不成功。\ntemplate \u0026lt;class T\u0026gt; concept always_satisfied = true; // 永远成功 template \u0026lt;class T\u0026gt; concept integral = std::is_integral_v\u0026lt;T\u0026gt;; // 整型时成功 template \u0026lt;class T\u0026gt; concept signed_integral = integral\u0026lt;T\u0026gt; \u0026amp;\u0026amp; std::is_signed_v\u0026lt;T\u0026gt;; // 满足两者时成功 这里，一个概念不能提到自己，也不能用另一个概念来约束这个概念，例如\ntemplate \u0026lt;class T\u0026gt; concept integral = std::is_integral_v\u0026lt;T\u0026gt;; template \u0026lt;integral T\u0026gt; concept signed_integral = std::is_signed_v\u0026lt;T\u0026gt;; 就是不行的。必须通过逻辑运算（包括与、或、非）得到复合的概念。同样的，requires语句也可以加入逻辑运算\ntemplate \u0026lt;class T\u0026gt; requires Integral\u0026lt;T\u0026gt; \u0026amp;\u0026amp; std::is_signed_v\u0026lt;T\u0026gt; T add(T a, T b); 可以通过requires语句定义概念\ntemplate \u0026lt;class T\u0026gt; concept Addable = requires (T a, T b) { a+b; }; template \u0026lt;class T\u0026gt; requires requires (T x) { x + x; } // ad-hoc式定义 T add(T a, T b) { return a + b; } 它不会检查是否返回true，只要里面的表达式合法，就可以成功。我们还可以写出\ntemplate\u0026lt;class C\u0026gt; concept cpt1 = requires{ typename C::value_type; typename C::iterator; typename std::vector\u0026lt;C\u0026gt;; }; 这样的代码，来判断其符不符合这样的使用方法。\n变长实参 #include \u0026lt;cstdarg\u0026gt; #include \u0026lt;iostream\u0026gt; int add_nums(int count...) { int result = 0; std::va_list args; va_start(args, count); for (int i = 0; i \u0026lt; count; ++i) result += va_arg(args, int); va_end(args); return result; } int main() { std::cout \u0026lt;\u0026lt; add_nums(4, 25, 25, 50, 50) \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } 这里int count...就是一个变长实参的声明。我们通过cstdarg中的函数来访问变长实参，首先要用std::va_list来声明一个变量，用来访问实参。然后通过va_start来开启遍历，其中第一个参数为std::va_list，第二个参数为我们的变长实参。之后我们用va_arg来访问下一个实参，传入的是std::va_list和希望转为的类型。用va_end来结束遍历。\n形参包 这里指的是变长模板形参，例如\ntemplate\u0026lt;class... Types\u0026gt; struct Tuple {}; Tuple\u0026lt;\u0026gt; t0; // Types 不包含实参 Tuple\u0026lt;int\u0026gt; t1; // Types 包含一个实参：int Tuple\u0026lt;int, float\u0026gt; t2; // Types 包含两个实参：int 与 float Tuple\u0026lt;0\u0026gt; error; // 错误：0 不是类型 在有模板实参推导后，可以使用：\ntemplate\u0026lt;class... Types\u0026gt; void f(Types... args); f(); // OK：args 不包含实参 f(1); // OK：args 包含一个实参：int f(2, 1.0); // OK：args 包含两个实参：int 与 double 上面的Types... args是一个包展开。后随省略号且其中至少有一个形参包的名字的模式会被展开_﻿成零个或更多个逗号分隔的模式实例 ，其中形参包的名字按顺序被替换成包中的各个元素。\ntemplate\u0026lt;class... Us\u0026gt; void f(Us... pargs) {} template\u0026lt;class... Ts\u0026gt; void g(Ts... args) { f(\u0026amp;args...); // “\u0026amp;args...” 是包展开 // “\u0026amp;args” 是它的模式 } g(1, 0.2, \u0026#34;a\u0026#34;); // Ts... args 会展开成 int E1, double E2, const char* E3 // \u0026amp;args... 会展开成 \u0026amp;E1, \u0026amp;E2, \u0026amp;E3 // Us... 会展开成 int* E1, double* E2, const char** E3 sizeof...运算符，用于获取形参包的长度，例如sizeof...(args)，在上例中返回3\n内存池和Allocators todo\n线程池 todo\nPIMPL Pointer to implementation，也就是指向实现的指针。具体来说，我们不再在某个类中直接定义它的变量，例如：\n// A.h class A{ public: A(); void foo(); private: int x, y; }; //A.cpp A::A() = default; void A::foo(){} 而是，我们加一个私有的struct和unique_ptr，在这个struct中去定义它的变量。\nclass A{ public: A(); void foo(); private: struct Impl; unique_ptr\u0026lt;Impl\u0026gt; const p_; }; //A.cpp struct A::Impl{ int x, y; }; A::A():p_(make_unique\u0026lt;Impl\u0026gt;(0, 0)){} void A::foo(){} // 对p_中的变量进行种种操作 这样做有什么好处？如果是之前的代码，当我们修改这个类的成员变量时，所有#include了这个头文件的翻译单元都要重新编译，大大增加了编译时间。而后者，其成员变量是在翻译单元中，我们只需要重新编译这个cpp，然后在链接的时候重新链接即可。\n目前来说，上面的代码还无法通过编译，因为析构函数需要知道完整的类型，而Impl是不完整的类型，所以我们也需要把析构函数拿出来。\n//A.cpp A::~A()=default; 类似的，你也需要把其他构造函数移出来。\n返回值优化 推荐在函数返回对象的时候，直接在return语句上构造对象。例如\nA foo(){ return A(1,2); } int main(){ auto a = foo(); } （大多数）编译器即使关闭优化，也只会调用一次构造函数，而不会有复制和移动。如果改成\nA foo(){ A a(1,2); return a; } 则部分编译器可能就不会只调用一次构造了，可能会进行移动。如果\nA foo(int x){ A a1; A a2; if(x\u0026gt;3){ return a1; } else{ return a2; } } 这样更复杂的情况，编译器可能都不能进行返回值优化了。\n所以，还是推荐直接在return语句中构造对象（如果可能）\n多继承 虽然争议颇多，但是C++确实支持多继承\nclass B1{}; class B2{}; class D : public B1, public B2{} 如上，类D同时继承了B1,B2，而D的构造函数\nD():B1(), B2(){} 其构造顺序，类似于之前提到的构造顺序，其并不是以初始化列表的顺序进行的，而是以继承的顺序进行的。\n在多继承下有命名冲突的问题，需要用::来指定使用哪个继承\nclass B1{ public: void foo(){} }; class B2{ public: void foo(){} }; class D : public B1, public B2{}; void bar(){ D d; d.foo(); // 错误，不知道使用B1还是B2的foo d.B1::foo(); d.B2::foo(); } 菱形继承是多继承的一种特殊情况，如\nclass B{ public: int age = 100; }; class B1 : public B{}; class B2 : public B{}; class D : public B1, public B2{}; 这里D间接地继承了B两次，有什么问题呢？\nD d; d.age = 10; 上面这个肯定会报错，和之前的多继承一样，无法区分是使用哪一个age变量。如果我们加上::呢？\nD d; d.B1::age = 10; d.B2::age = 20; std::cout\u0026lt;\u0026lt;d.B1::age\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; std::cout\u0026lt;\u0026lt;d.B2::age\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; 这里会输出10和20，而不是两个20。这虽然在代码意义上是对的，但是很显然我们是想要这个d只有一个age。这里我们就可以引入虚继承。\nclass B1 : virtual public B{}; class B2 : virtual public B{}; class D : public B1, public B2{}; 此时，d.age, d.B1::age, d.B2::age都可以通过编译，并且三者指向的是同一个变量。\n这些东西编译器是怎么实现的呢？可以参考下面的对象模型介绍文章。\n对象模型 https://www.cnblogs.com/QG-whz/p/4909359.html\n","date":"2023-09-06T21:52:23+08:00","permalink":"https://kegalas.top/p/%E7%8E%B0%E4%BB%A3c-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"现代C++学习笔记"},{"content":"背景 可能大家的Firefox里面会有以下几个插件：\n1.jpg\r2.jpg\r此外还有火狐新标签页（个人不喜欢），火狐主页（个人不喜欢），网银支付助手（没用），网页截图（一般都用qq截图了）等插件。\n你可能完全不知道它们是什么时候装在你的Firefox里的，但是它们无形中修改了你的操作使用习惯。\n但是你会发现这几个插件（2021年或2022年以后）是没法在（至少是国际版）Firefox里同步的。也就是说你使用一台新的电脑，新的Firefox，登陆了你的账户，进行同步。却发现以前的一些操作变得非常不习惯，例如：\n新建标签页永远在最右边 无法双击关闭标签页 打开书签会默认替换当前页面而不是新开一个标签页 地址栏没有二维码生成器了 拖拽文字、超链接必须拖拽到标签页那一栏才能搜索、打开连接。以前只要拖拽几毫米就可以。 恢复最近关闭的页面的按钮没了 这些功能其实都是这两个奇怪的插件提供的。这两个插件无法在addons.mozilla.org搜索到，这两个插件实际上藏在mozilla.com.cn/moz-addon.html这个中国特供插件网站。这几个插件也是中国特供版Firefox自带的。\n为什么我的国际版也会有这些插件？曾经我在Firefox将同步由国内服务转变为国际服务，我想我可能就在这个转变的途中，把这几个插件同步到了国际版上。\n至于现在无法同步插件，我猜测以前Firefox可以同步用户自己下载的乱七八糟的插件，比如这几个，比如Listen1。而现在同步的插件必须是官方审核过的，也就是addons.mozilla.org中的。这导致这些东西无法同步，并且如果你在大陆的话甚至也没法同步uBlock Origin（因为在官网上这个插件是锁区的）。\n下面我们通过一些设置来改回我们习惯的操作，这些都是可选的，根据自己的喜好来。\n新建标签页在当前标签页的右边 我们在Firefox的地址栏输入about:config，进入之后接受风险并继续。\n搜索insert，把下面两个选项改为true。\n3.jpg\r双击关闭标签页 搜索browser.tabs.closeTabByDblclick，改为true。\n新建标签页打开书签 browser.tabs.loadBookmarksInTabs改为true。\n新建标签页打开搜索 browser.search.openintab改为true\n地址栏二维码生成器 你也许可以尝试使用https://addons.mozilla.org/zh-CN/firefox/addon/qr-code-address-bar/这个插件。\n拖拽手势 有几个插件可以使用\nhttps://addons.mozilla.org/zh-CN/firefox/addon/quickdrag-we/，它的设置比较简单，也是可以设置拖拽新建标签页在foreground还是background。我本人选用了这个。我把他的选项里的搜索引擎改成百度，位置改成Right，剩下四个选项全部取消勾选。不过这个插件好像在部分页面中不起作用，例如mozilla.org的网站中，以及Firefox自己的设置页面中。\nhttps://addons.mozilla.org/zh-CN/firefox/addon/drag-to-go/，它的设置更为复杂，可以把拖拽的四个方向的动作分开算，但是不知道为什么，拖拽文字搜索居然不可以设置background。而且拖拽的时候虽然确实能拖拽，但是鼠标指针显示的还是“禁止”的那个图样，让我很不爽。\nhttps://addons.mozilla.org/zh-CN/firefox/addon/fire-drag/，它总体而言和第一个差不多。缺点也是有几个页面用不了。\n恢复最近关闭页面的按钮 简单的可以用https://addons.mozilla.org/zh-CN/firefox/addon/%E6%81%A2%E5%A4%8D%E6%A0%87%E7%AD%BE%E9%A1%B5/，这个插件右键没有关闭页面的列表。\n功能更齐全的可以用https://addons.mozilla.org/zh-CN/firefox/addon/undoclosetabbutton/，这个插件右键就有列表了。\n","date":"2023-08-06T09:55:11+08:00","permalink":"https://kegalas.top/inferior/firefox%E4%B9%A0%E6%83%AF%E8%AE%BE%E7%BD%AE%E8%AE%B0%E5%BD%95%E5%8C%85%E5%90%AB%E5%8F%8C%E5%87%BB%E5%85%B3%E9%97%AD%E6%8B%96%E6%8B%BD%E6%89%8B%E5%8A%BF%E6%96%B0%E5%BB%BA%E6%A0%87%E7%AD%BE%E9%A1%B5%E4%BD%8D%E7%BD%AE%E7%AD%89/","title":"Firefox习惯设置记录（包含双击关闭，拖拽手势，新建标签页位置等）"},{"content":"导航页面\nBlinn-Phong反射模型 Blinn-Phong反射模型将光的反射分为了三个部分。\n漫反射 镜面反射 环境光反射 我们在具体实现光照的时候，会把这三个光照分开计算，然后最后显示出来的时候叠加显示。\n为了方便，我们作出如下约定，对于物体表面上的一点\\(\\bm p\\)，其单位法向量为\\(\\bm n\\)，从\\(\\bm p\\)指向摄像机的单位向量为\\(\\bm v\\)，指向光源的单位向量为\\(\\bm l\\)\n3.jpg\r漫反射 漫反射意味着，从四面八方看过来，这个位置的颜色（亮度）是一致的。\n2.jpg\r如图，光到了反射点后，朝着四面八方反射，并且并没有哪个方向特别突出。\n处理漫反射的规则也叫做Lambert\u0026rsquo;s Cosine Law，这个规则指明，如果光源照射到\\(\\bm p\\)点上的光照强度为\\(I\\)，则其漫反射的光照强度为\\(L_d=I\\cos\\theta\\)，其中\\(\\theta\\)是\\(\\bm l\\)和\\(\\bm n\\)的夹角。同时为了防止从物体表面以下的光线射过来影响亮度，以及考虑各种物体的反射性能不一样，我们写为\n\\[L_d = k_d I \\max(0,\\bm n\\cdot\\bm l) \\]\n其中\\(k_d\\)是该物体的材质的漫反射系数。这里\\(k_d\\)一般是三维向量，而同时\\(I\\)和\\(L_d\\)也是三维向量。这么做的原因是，我们的光是有颜色的，并且反射的时候物体也会对某种颜色反射的多，某种颜色反射的少。这里\\(k_d\\)和\\(I\\)是分量之间各自相乘的乘法，在我们的库里就是operator*，而不是dot函数。\n并且由于我们在这里做乘法，试想一下我们用\\(255\\times255\\)，得到的数超过了\\(255\\)，也就是颜色的上限值，是不对的。我们转化一下，把\\(RGB\\)三个分量的值定为\\([0,1]\\)，用这个数字去进行计算。在最后屏幕上着色的时候，再转换回整数\\([0,255]\\)。\n你可能会问，我知道光有颜色，但是亮度怎么办？简单认为，一个颜色的0.9倍亮度，就是把每个分量都乘以0.9。更详细的我会在以后介绍（TODO）。\n镜面反射 有时候，这个材质比较光滑，在反射角（指\\(\\bm v\\)和\\(\\bm n\\)的夹角）等于入射角（指\\(\\bm l\\)和\\(\\bm n\\)的夹角），或者反射角很接近入射角时，光强会明显强于其他角度。\n4.jpg\r出现这种情况的时候，不仅反射角很接近入射角，而且可以推出，半程向量\\(\\bm h\\)非常接近法向量\\(\\bm n\\)\n所谓的半程向量就是\\(\\bm l,\\bm v\\)的角平分线的单位向量，有\n\\[\\bm h = \\dfrac{\\bm v+\\bm l}{||\\bm v+\\bm l||} \\]\n此时相机接收到的光强就是\n\\[L_s = k_s I \\max(0,\\bm n\\cdot\\bm h)^p \\]\n其中\\(k_s\\)是镜面反射系数，而\\(p\\)决定了\\(\\bm n\\)和\\(\\bm h\\)有多接近才算触发镜面反射。\\(p\\)越大，触发的范围越小，通常\\(p\\geq 100\\)。\n\\(L_s,k_s,I\\)也都是三维向量，并且乘法也是分量各自相乘。\\(k_s\\)会采用比较亮的白色，而不是其他颜色。\n环境光反射 你可以把环境光当成是房间里的其他物体的漫反射经过非常多次再-漫反射，最终照射到该物体上的光。Blinn-Phong模型中，直接采取了取用常数的简单处理办法。\n\\[L_a = k_aI_a \\]\n\\(L_a,k_a,I_a\\)也都是三维向量，并且乘法也是分量各自相乘。\\(k_s\\)会采用比较暗的白色，而不是其他颜色。\\(I_a\\)通常也是比较暗的颜色。\n反射组合 直接加一起即可\n\\[L = L_a+L_d+L_s \\]\n使用例子 我们把上一节所讲的teapot模型拿出来使用一下。\n用**这个链接** 中的代码（需要去下载模型文件放到代码中的指定文件夹，见**链接** ），我们可以得到如下的效果图\n1.jpg\r看上去还好，细看的话发现盖子、壶嘴连接处一塌糊涂，这实际上是因为三角形的前后关系导致覆盖而出现的结果，在下一部分我们将介绍Z-buffer算法来解决这个问题。\n","date":"2023-08-04T21:25:38+08:00","image":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E5%85%89%E7%85%A7%E5%88%9D%E6%AD%A5/cover_hu04f6e4c5c5d9e8c832c6dfeafddfe37e_257114_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E5%85%89%E7%85%A7%E5%88%9D%E6%AD%A5/","title":"从零开始的软渲染器 光照初步"},{"content":"导航页面\nOBJ格式简介 .obj格式是描述几何模型的一种简单办法。它可以描述顶点的坐标、法向量、纹理坐标，以及三角面的顶点数据等等。\n注释\n.obj格式里的注释是以#开头的一行\n顶点坐标\n例如\nv 0.511631 -0.845357 0.127832 v 0.608654 -0.568839 -0.416318 v 0.424663 -0.649937 -0.567418 ... 以v开头，后面带三个小数。注意这个坐标是模型相对于自己原点的坐标，而不是我们渲染过程中的世界坐标。它不会提供总数，只会一条一条地提供。\n读取的时候需要注意自己统计总数，另外还要记录序号（写在数组里没有这个问题）。以及序号从\\(1\\)开始计数。\n纹理坐标\n例如\nvt 0.617 0.575 0.000 vt 0.623 0.573 0.000 vt 0.627 0.576 0.000 ... 以vt开头，后面还是带三个数。通常我们的纹理是二维的，所以第三个会是零（有些模型文件只有两个维度，忽略了第三维）。这里的纹理坐标指的是在纹理图片文件上的坐标。显然你会怀疑，纹理图片的大小不是800x800这种形式的吗？为什么这里是小数？\n我认为是为了统一，我们只要用坐标乘以宽度、长度，再四舍五入即可得到图片上的像素坐标。\n当然，也有的纹理坐标不在\\([0,1]\\)范围内，会大于\\(1\\)。此时我们有多种处理办法，比较常见的一种是取其小数部分，作为坐标。也就等价于重复纹理图片。\n法向量方向\n例如\nvn -0.250 0.462 -0.851 vn -0.192 0.568 -0.801 vn -0.359 0.279 0.891 ... 描述了法向量指向的方向。\n注意可能并不是单位向量，我没有找到限制必须是单位向量的规定。\n注意\n上面这三种数据总数不一定是一样的，它们之间的关联也不是一定是序号对应的。大部分时候不一样，也不对应。它们只是描述了一组这样的数据而已，具体到三角面上，才会体现如何使用这些数据。\n使用这些数据时，序号就变得重要了起来。再次提醒序号从\\(1\\)开始计数。\n三角面信息\n例如\nf 1206/1252/1206 1207/1254/1207 1205/1255/1205 f 1206/1252/1206 1208/1256/1208 1086/1257/1086 f 1206/1252/1206 1086/1257/1086 1087/1253/1087 ... 以f开头，带了三组数据。每组都有三个数字。带有三个数字是因为每个顶点有三个坐标要描述。\n形如a/b/c这样的形式，描述了一个顶点的信息。从上面的结构来看，每一行有三组，也就有三个顶点，代表着这个面是三角面。如果有四组，则代表为四边形面。\n其中a代表的是该顶点的局部空间坐标，其是一个序号，对应第a个v信息（从1开始计数）。其中b代表该顶点的uv坐标，也是一个序号，代表第b个vt信息。c代表该顶点的法向量信息，也是一个序号，代表第c个vn信息。\n我们目前了解以上信息即可。\nmodel.h 首先我们需要定义一下model里面要有什么内容。\nstd::vector\u0026lt;geo::vec3f\u0026gt; vertices{}; std::vector\u0026lt;geo::vec2f\u0026gt; tex_coords{}; std::vector\u0026lt;geo::vec3f\u0026gt; norms{}; std::vector\u0026lt;size_t\u0026gt; face_vi{}; std::vector\u0026lt;size_t\u0026gt; face_ti{}; std::vector\u0026lt;size_t\u0026gt; face_ni{}; 我们需要三维的顶点坐标、二维的纹理uv坐标，以及三维的顶点法向量坐标。同时也需要记录每个三角面它的顶点坐标序号，纹理坐标序号以及法向量坐标序号。\n再看看我们可能需要什么方法：\nModel(std::string const \u0026amp; dir); ~Model(); size_t getFaceSize(); geo::vec3f getVert(size_t faceid, size_t nth); bool getTriangle(std::array\u0026lt;geo::vec3f,3\u0026gt; \u0026amp; dist, size_t faceid); bool getTriangle(std::array\u0026lt;geo::vec4f,3\u0026gt; \u0026amp; dist, size_t faceid); bool getNorm(std::array\u0026lt;geo::vec3f,3\u0026gt; \u0026amp; dist, size_t faceid); 一个构造函数和一个析构函数不用多说。\n之后我们可能需要提供获取三角面数量的函数、获取（某个特定）顶点坐标的函数，获取一个三角面上所有顶点坐标的函数（在这里我按需要提供了四维坐标和三维坐标的版本），以及获得三角面上所有顶点法向量的函数。\n之后我们还会在读取材质纹理的地方需要提供纹理坐标的函数。这里先略过。\n全部代码可见**链接**\nmodel.cpp 现在我们来看看具体要怎么实现\n构造函数 Model::Model(std::string const \u0026amp; dir){ std::ifstream in; in.open(dir,std::ifstream::in); if(in.fail()) return; std::string line; while(!in.eof()){ std::getline(in,line); std::istringstream iss(line); char discard; if(line.compare(0,2,\u0026#34;v \u0026#34;)==0){ iss\u0026gt;\u0026gt;discard; geo::vec3f v; for(int i=0;i\u0026lt;3;i++) iss\u0026gt;\u0026gt;v[i]; vertices.push_back(v); } else if(line.compare(0,3,\u0026#34;vt \u0026#34;)==0){ iss\u0026gt;\u0026gt;discard\u0026gt;\u0026gt;discard; geo::vec2f vt; for(int i=0;i\u0026lt;2;i++) iss\u0026gt;\u0026gt;vt[i]; tex_coords.push_back(vt); } else if (line.compare(0,3,\u0026#34;vn \u0026#34;)==0) { iss\u0026gt;\u0026gt;discard\u0026gt;\u0026gt;discard; geo::vec3f vn; for(int i=0;i\u0026lt;3;i++) iss\u0026gt;\u0026gt;vn[i]; norms.push_back(vn); } else if(line.compare(0,2,\u0026#34;f \u0026#34;)==0){ iss\u0026gt;\u0026gt;discard; size_t fv,ft,fn; while(iss\u0026gt;\u0026gt;fv\u0026gt;\u0026gt;discard\u0026gt;\u0026gt;ft\u0026gt;\u0026gt;discard\u0026gt;\u0026gt;fn){ face_vi.push_back(fv-1); face_ti.push_back(ft-1); face_ni.push_back(fn-1); } } } std::cerr\u0026lt;\u0026lt;\u0026#34;v: \u0026#34;\u0026lt;\u0026lt;vertices.size()\u0026lt;\u0026lt;\u0026#34; t: \u0026#34;\u0026lt;\u0026lt;tex_coords.size()\u0026lt;\u0026lt;\u0026#34; n: \u0026#34;\u0026lt;\u0026lt;norms.size()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; std::cerr\u0026lt;\u0026lt;\u0026#34;f: \u0026#34;\u0026lt;\u0026lt;face_ni.size()/3\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } 这其实没什么好多说的，把之前说过的OBJ文件格式理解一下，去实际看看obj文件里面怎么写的。如果掌握了ifstream，字符串的操作，整个操作就会了。\n需要注意的是，obj里面提供的序号是从\\(1\\)开始的，而我这里用的是往vector里push_back元素的办法，方便起见把所有序号都减\\(1\\)。\n获取坐标信息的函数 这一部分其实非常容易理解和实现，就把我们读入的数据，按照下标获取，然后返回即可。全部代码可见**链接**\n使用例子 #include \u0026#34;tga_image.h\u0026#34; #include \u0026#34;raster.h\u0026#34; #include \u0026#34;model.h\u0026#34; #include \u0026lt;ctime\u0026gt; #include \u0026lt;cstdlib\u0026gt; int const width = 1500; int const height = 1500;//设置输出图片的长宽 int main(){ Model model(\u0026#34;../obj/teapot.obj\u0026#34;);//读取我们的模型 TGAImage image(width,height,TGAType::rgb);//新建一个图对象 int nface = model.getFaceSize();//获取三角面的总数 std::array\u0026lt;geo::vec4f,3\u0026gt; vert;//读取顶点坐标 std::array\u0026lt;geo::OARColor,3\u0026gt; color;//设置顶点颜色 std::array\u0026lt;geo::vec2i,3\u0026gt; screen;//把顶点的空间坐标转化到屏幕像素坐标上 for(int i=0;i\u0026lt;nface;i++){ model.getTriangle(vert, i);//把序号为i的三角形的顶点全部读入vert for(int j=0;j\u0026lt;3;j++){ color[j] = geo::OARColor(255,255,255,255);//设置颜色为全白 screen[j] = ras::world2screen(vert[j],width,height);//转换坐标，函数定义见下 } ras::triangle(image,screen,color);//绘制三角形i号 } image.writeToFile(\u0026#34;./tp.tga\u0026#34;);//写入图像文件 return 0; } 我们使用以上代码来测试我们的效果，具体步骤解释都写在上面的注释里了（模型见**链接** ）。\ngeo::vec2i ras::world2screen(geo::vec4f v, int width, int height){ return geo::vec2i(int((v.x+1.f)*width*.5f+.5f), int((v.y+1.f)*height*.5f+.5f)); } 我们的坐标转换函数如上（放在这里**链接** ），这里本来应该在坐标转换的地方讲，但是这里不得不用到，我们就提前讲一下。\n我们的物体模型，有他自己的坐标系。这个坐标的范围是\\([-1,1]^3\\)，但我们的显示屏只有两个维度，而且他还只有整数的坐标。为了将模型的坐标映射到显示屏上，我们首先压缩一维，也就是直接不考虑深度（这里是\\(z\\)轴），然后把\\([-1,1]^2\\)映射到\\(\\text{width}\\times\\text{height}\\)这个坐标上。我们分别对\\(x,y\\)进行操作，首先把\\(x\\)整体加\\(1\\)，就得到\\([0,2]\\)，再除以\\(2\\)，就得到\\([0,1]\\)，再乘以\\(\\text{width}\\)，再取四舍五入到整数就得到了显示屏上的横坐标，同理就得到了纵坐标。\n更进一步的知识等到坐标转换的地方再讲吧！\n结果如下：\n1.png\r虽然我们没有看清具体的细节（因为我们把每个三角形都设置成全白了），但是至少整个形状正确了。稍后我们将介绍光照，来让他的细节展现出来。\n","date":"2023-06-25T14:37:37+08:00","image":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E6%A8%A1%E5%9E%8B%E5%BA%93/cover_hu1d5ada73bf6b5a759e3568aecd125470_50161_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E6%A8%A1%E5%9E%8B%E5%BA%93/","title":"从零开始的软渲染器 模型库"},{"content":"读前警示 出于Obsidian不支持\\bm的标签的原因，也出于我打字方便、教科书也没用加粗的原因，从某一段开始的瞬间，很多地方都不会使用粗体来表示向量。这其实无所谓，我们可以把标量看做一维向量。我们的大部分讨论都是在向量之上的，除了部分参数是标量。大部分矩阵是大写字母。\n阅读时应结合前后文理解一个符号是什么意思。\n数学基础概念、定义 向量内积 在\\(n\\)维线性空间\\(R^n\\)中，\\(\\bm a = [a_1,a_2,\\cdots,a_n]^T\\in R^n,\\bm b = [b_1,b_2,\\cdots,b_n]^T\\in R^n\\)，则\n\\[\\bm a^T b = a_1b_1+a_2b_2+\\cdots,a_nb_n \\]\n称作向量\\(\\bm a,\\bm b\\)的内积。\n内积满足交换律，线性，以及正定性：\\(\\bm a^T \\bm a\\geq 0\\)，当且仅当\\(\\bm a=\\bm 0\\)时，取等号。\n其他各种性质都在线性代数中学过了，这里只是简单回顾。\n向量范数 称一个从向量空间\\(R^n\\)到实数域\\(R\\)的非负函数\\(||\\cdot||\\)为范数，如果它满足：\n正定性：对于所有的\\(\\bm v\\in R^n\\)，有\\(||\\bm v||\\geq 0\\)，且\\(||\\bm v||=0\\)当且仅当\\(\\bm v=0\\) 齐次性：对于所有的\\(\\bm v\\in R^n\\)和\\(\\alpha\\in R\\)，有\\(||\\alpha\\bm v||=|\\alpha|||\\bm v||\\) 三角不等式：对于所有的\\(\\bm v,\\bm w\\in R^n\\)，有\\(||\\bm v+\\bm w||\\leq ||\\bm v||+||\\bm w||\\) 对于\\(\\bm v = (v_1,v_2,\\cdots,v_n)^T\\)，常见的向量范数为\\(\\mathscr{l}_n\\)范数\\((p\u003e=1)\\)\n\\[||v||_p = (|v_1|^p+|v_2|^p+\\cdots+|v_3|^p)^{1/p} \\]\n当\\(p=\\infty\\)时，\\(\\mathscr{l}_\\infty\\)定义为\n\\[||v||_\\infty = \\max_i|v_i| \\]\n一些地方也可以见到\\(0\\)-范数，其表示分量中不为零的个数。\n最常见的是\\(2\\)-范数，又称欧几里得范数，常常\\(||\\cdot||\\)省略角标不写表示\\(2\\)-范数。\n二次型 \\(n\\)维二次函数可以表示如下\n\\[f(x_1,x_2,\\cdots,x_n)=a_{11}x_1^2+a_{12}x_1x_2+\\cdots+a_{1n}x_1x_n+a_{21}x_2x_1+\\cdots+a_{nn}x^2_n \\]\n其可以表示为向量矩阵形式\n\\[\\sum^n_{i=1}\\sum^n_{j=1}a_{ij}x_ix_j=\\bm x^T A \\bm x \\]\n这个\\(A\\)矩阵是个实对称矩阵，其元素\\(a_{ij}=a_{ji}\\)，是对应的\\(x_ix_j\\)项系数的一半（原式子出于简单起见没有把同类项合并）。\n正定矩阵 如果正定二次型\\(f(\\bm x)=\\bm x^TA\\bm x\\)，对于一组不全为零的数\\(x_1,x_2,\\cdots,x_n\\)，恒有\\(f(x_1,x_2,\\cdots,x_n)\u003e0\\)，则称\\(f\\)正定，\\(A\\)为正定矩阵。若换成\\(\\geq\\)，则称为半正定矩阵，若换成\\(\\leq\\)，则称为半负定矩阵。\n有两个判定定理\n\\(A\\)正定的充要条件为\\(A\\)的特征值都大于\\(0\\) \\(A\\)正定的充要条件为\\(A\\)的所有顺序主子式都大于\\(0\\) 方向导数 设\\(f:R^n\\to R\\)在点\\(\\bm x\\)处可微，\\(\\bm p\\)是固定不变的非零向量，\\(\\bm e\\)是方向\\(\\bm p\\)上的单位向量，则称极限\n\\[\\dfrac{\\partial f(\\bm x)}{\\partial \\bm p} = \\lim_{t\\to 0^+}\\dfrac{f(\\bm x+t\\bm e)-f(\\bm x)}{t} \\]\n为函数\\(f(x)\\)在点\\(\\bm x\\)处沿\\(\\bm p\\)方向的方向导数，记为\\(\\dfrac{\\partial f(\\bm x)}{\\partial\\bm p}\\)。当其大于零时，函数在该点沿此方向上升，小于零时沿此方向下降。\n梯度 给定函数设\\(f:R^n\\to R\\)，且\\(f\\)在点\\(\\bm x\\)的一个领域内有意义，若存在向量\\(\\bm g\\in R^n\\)满足\n\\[\\lim_{\\bm p\\to \\bm 0}\\dfrac{f(\\bm x+\\bm p)-f(\\bm x)-\\bm g^T\\bm p}{||\\bm p||}=0 \\]\n其中这个范数可以是任意向量范数，就称\\(f\\)在点\\(\\bm x\\)可微，此时\\(\\bm g\\)是\\(f\\)在点\\(\\bm x\\)处的梯度，记作\\(\\nabla f(x)\\)。可以计算，若令\\(\\bm p=\\epsilon \\bm e_i\\)，\\(\\bm e_i\\)是第\\(i\\)个分量为\\(1\\)的单位向量，可知\\(\\nabla f(x)\\)的第\\(i\\)个分量即为\\(\\dfrac{\\partial f(x)}{\\partial x_i}\\)。因此\n\\[\\nabla f(x) = \\bigg[\\dfrac{\\partial f(x)}{\\partial x_1},\\dfrac{\\partial f(x)}{\\partial x_2},\\cdots,\\dfrac{\\partial f(x)}{\\partial x_n}\\bigg]^T \\]\n一个非常浅显的事实是，一维向量函数的梯度就是它的一阶导数。\n梯度方向是函数在该点上升的最快方向，反方向是最速下降方向。\n梯度与方向导数的关系为\n\\[\\dfrac{\\partial f(\\bm x)}{\\partial \\bm p}=\\nabla f(\\bm x)^T\\bm e \\]\n其中\\(\\bm e\\)是\\(\\bm p\\)方向上的单位向量。\n\\(\\bigg|\\dfrac{\\partial f(\\bm x)}{\\partial \\bm p}\\bigg|\\leq |\\nabla f(\\bm x)^T|\\)\n梯度有几条显然的性质：\n若\\(\\nabla f(\\bm x)^T\\bm p\u003c0\\)，则\\(\\bm p\\)的方向是函数\\(f\\)在\\(\\bm x\\)处的下降方向 若\\(\\nabla f(\\bm x)^T\\bm p\u003e0\\)，则\\(\\bm p\\)的方向是函数\\(f\\)在\\(\\bm x\\)处的上升方向 梯度正交的方向变化率为零 海瑟矩阵 用一个简单的比方，梯度和海瑟矩阵的关系，就相当于一阶导数和二阶导数的关系。\n给定函数\\(f:R^n\\to R\\)，若其在点\\(\\bm x\\)处的二阶偏导数\\(\\dfrac{\\partial^2 f(\\bm x)}{\\partial \\bm x_i\\partial \\bm x_j},i,j=1,2,\\cdots,n\\)都存在，则\n\\[\\nabla^2f(\\bm x) = \\begin{bmatrix} \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_1^2} \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_1\\partial x_2} \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_1\\partial x_3} \u0026 \\cdots \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_1\\partial x_n}\\\\ \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_2\\partial x_1} \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_2^2} \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_2\\partial x_3} \u0026 \\cdots \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_2\\partial x_n}\\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_n\\partial x_1} \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_n\\partial x_2} \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_n\\partial x_3} \u0026 \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_n^2} \\end{bmatrix} \\]\n称为\\(f\\)在点\\(x\\)处的海瑟矩阵。\n泰勒展开 给定函数\\(f:R^n\\to R\\)，具有二阶连续偏导数，则\n\\[f(\\bm x+\\bm p) = f(\\bm x) + \\nabla f(\\bm x)^T\\bm p + \\dfrac{1}{2}\\bm p^T\\nabla^2 f(\\bm x)^T\\bm p + o(||\\bm p||^2) \\]\n其中\\(o(||p||^2)\\)当\\(||p||^2\\to 0\\)时，是关于\\(||p||^2\\)的高阶无穷小量。\n邻域 对于任意给定的实数\\(\\delta\u003e0\\)，满足不等式\\(||\\bm x-\\bm x_0||\u003c\\delta\\)的\\(\\bm x\\)的集合称为点\\(\\bm x_0\\)的邻域，记为\n\\[N(\\bm x_0,\\delta) = \\{\\bm x|\\ ||\\bm x-\\bm x_0||\u003c\\delta,\\delta\u003e0\\} \\]\n极小点 设\\(f:D\\subseteq R^n\\to R\\)，若存在点\\(\\bm x^*\\in D\\)和数\\(\\delta\u003e0\\)，\\(\\forall \\bm x\\in N(\\bm x^*,\\delta)\\cap D\\)，都有\\(f(\\bm x^*)\\leq f(\\bm x)\\)，则称\\(\\bm x^*\\)为\\(f(\\bm x)\\)的（非严格）局部极小点。\n设\\(f:D\\subseteq R^n\\to R\\)，若存在点\\(\\bm x^*\\in D\\)和数\\(\\delta\u003e0\\)，\\(\\forall \\bm x\\in N(\\bm x^*,\\delta)\\cap D\\)，但\\(\\bm x\\neq \\bm x^*\\)，都有\\(f(\\bm x^*)\u003c f(\\bm x)\\)，则称\\(\\bm x^*\\)为\\(f(\\bm x)\\)的严格局部极小点。\n设\\(f:D\\subseteq R^n\\to R\\)，若存在点\\(\\bm x^*\\in D\\)和数\\(\\delta\u003e0\\)，\\(\\forall \\bm x\\in D\\)，都有\\(f(\\bm x^*)\\leq f(\\bm x)\\)，则称\\(\\bm x^*\\)为\\(f(\\bm x)\\)的（非严格）全局极小点。\n设\\(f:D\\subseteq R^n\\to R\\)，若存在点\\(\\bm x^*\\in D\\)和数\\(\\delta\u003e0\\)，\\(\\forall \\bm x\\in D\\)，但\\(\\bm x\\neq \\bm x^*\\)，都有\\(f(\\bm x^*)\\leq f(\\bm x)\\)，则称\\(\\bm x^*\\)为\\(f(\\bm x)\\)的严格全局极小点。\n如果\\(\\bm x^*\\)是极小点并且是\\(D\\)的内点，则\\(\\nabla f(\\bm x^*)=0\\)。这是一个必要非充分条件。\n但如果\\(f\\)有连续二阶偏导数，\\(\\bm x^*\\)是一个驻点，并且\\(\\nabla^2 f(\\bm x^*)\\)是正定的，则\\(\\bm x^*\\)是\\(f(\\bm x)\\)的严格局部极小点。\n驻点 设\\(f:D\\subseteq R^n\\to R\\)，\\(\\bm x^*\\)是\\(D\\)的内点，若\\(\\nabla f(\\bm x^*)=0\\)，则称\\(\\bm x^*\\)为\\(f(\\bm x)\\)的驻点。\n锥 设集合\\(C\\subset R^n\\)，若对\\(\\forall\\bm x\\in C\\)以及\\(\\forall \\lambda\\geq 0\\)均有\\(\\lambda\\bm x\\in C\\)，则称\\(C\\)为锥\n凸组合 设\\(\\bm x_1,\\bm x_2,\\cdots,\\bm x_l\\)是\\(R^n\\)中的\\(l\\)个已知点。若对于某点\\(\\bm x\\in R^n\\)，存在常数\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_l\\geq 0\\)，且\\(\\sum\\lambda_i=1\\)，使得\\(\\bm x=\\sum\\lambda_i\\bm x_i\\)，则称\\(\\bm x\\)是\\(\\bm x_1,\\bm x_2,\\cdots,\\bm x_l\\)的凸组合。如果\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_l\u003e0\\)且\\(\\sum\\lambda_i=1\\)，则称为严格凸组合。\n凸集 对于\\(C\\subset R^n\\)中的任意两个点\\(\\bm x_1, \\bm x_2\\)，如果连接两个点的线段在\\(C\\)内，则称\\(C\\)为凸集。即\n\\[\\bm x_1,\\bm x_2\\in C\\Rightarrow\\theta \\bm x_1+(1-\\theta)\\bm x_2\\in C,\\forall 0\\leq\\theta\\leq 1 \\]\n定理1\n任意一组凸集的交仍然是凸集。\n特别的，规定空集是凸集。容易验证，空间\\(R^n\\)、半空间、超平面、直线、点、球都是凸集。\n凸集分离定理\n设\\(C_1,C_2\\)是\\(R^n\\)中两个非空的集合，\\(H=\\{\\bm x|\\bm p^T\\bm x=\\alpha\\}\\)为超平面，如果对\\(\\forall\\bm x\\in C_1\\)都有\\(\\bm p^T\\bm x\\geq \\alpha\\)，对\\(\\forall x\\in C_2\\)都有\\(\\bm p^T\\bm x\\leq \\alpha\\)（或二者正好相反），则称超平面\\(H\\)分离集合\\(C_1,C_2\\)\n半空间 设\\(\\bm a\\in R^n,\\bm a\\neq\\bm 0,b\\in R\\)，则集合\n\\[\\{\\bm x|\\bm a^T\\bm x\u003eb,\\bm x\\in R^n\\} \\]\n称为\\(R^n\\)的半空间。\n有限个半空间的交\\(\\{\\bm x|\\bm A\\bm x\\leq \\bm b\\}\\)称为多面集，其中\\(\\bm A\\)为\\(m\\times n\\)矩阵，\\(\\bm b\\)为\\(m\\)维向量。\n凸函数 广义实值函数\n令\\(\\bar R\\xlongequal{\\text{def}}R\\cup\\{\\pm\\infty\\}\\)为广义实数空间，则映射\\(f:R^n\\to\\bar R\\)为广义实值函数。\n规定\\(-\\infty\u003c a\u003c+\\infty,\\forall a\\in R\\)，以及\\((+\\infty)+(+\\infty)=+\\infty,(+\\infty)+a=+\\infty,\\forall a\\in R\\)\n适当函数\n给定广义实值函数\\(f\\)和非空集合\\(\\mathcal{X}\\)，如果存在\\(x\\in\\mathcal{X}\\)使得\\(f(x)\u003c+\\infty\\)，并且对任意的\\(x\\in\\mathcal{X}\\)，都有\\(f(x)\u003e-\\infty\\)，那么称函数\\(f\\)关于集合\\(\\mathcal{X}\\)是适当的。\n凸函数\n设函数\\(f\\)为适当函数，如果\\(\\text{dom} f\\)是凸集，且\n\\[f(\\theta x+(1-\\theta)y)\\leq \\theta f(x)+(1-\\theta)f(y) \\]\n对所有\\(x,y\\in\\text{dom}f,0\\leq\\theta\\leq 1\\)都成立，则称\\(f\\)是凸函数。\n如果\\(f(\\theta x+(1-\\theta)y)\u003c \\theta f(x)+(1-\\theta)f(y)\\)，则称为严格凸函数。\n性质1\n设\\(f_1,f_2\\)是凸集\\(C\\)上的凸函数，则函数\\(f_1+f_2\\)在\\(S\\)上也是凸函数。\n性质2\n设\\(f\\)是凸集\\(C\\)上的凸函数，则对任意的\\(a\\geq 0\\)，函数\\(af\\)也是凸函数。\n凸函数判定 \\(f\\)是凸函数，当且仅当对任意的\\(x\\in\\text{dom}f,v\\in R^n,g:R\\to R\\)\n\\[g(t)=f(x+tv),\\text{dom} g = \\{t|x+tv\\in\\text{dom} f\\} \\]\n是凸函数。\n一阶条件\n对于定义在凸集上的可微函数\\(f\\)，\\(f\\)是凸函数当且仅当\n\\[f(y)\\geq f(x)+\\nabla f(x)^T(y-x),\\forall x,y\\in\\text{dom}f \\]\n严格凸函数则要求\\(\u003e\\)号。物理意义是：任意点处的切线增量不超过函数的增量。\n梯度单调性\n设\\(f\\)为可微函数，则\\(f\\)为凸函数当且仅当\\(\\text{dom}f\\)为凸集且\\(\\nabla f\\)为单调映射，即\n\\[(\\nabla f(x)-\\nabla f(y))^T(x-y)\\geq 0,\\forall x,y\\in\\text{dom}f \\]\n二阶条件\n设\\(f\\)为定义在凸集上的二阶连续可微函数，则\\(f\\)是凸函数当且仅当\n\\[\\nabla^2 f(x)\\succeq 0,\\forall x\\in\\text{dom}f \\]\n如果\\(\\succ\\)，则是严格凸函数。\n或者，凸函数的充要条件是\\(\\nabla^2 f(x)\\)在\\(\\text{dom}f\\)上的任意点均半正定。\n线性规划 图解法 确定可行域 确定目标函数的等值线及优化方向 平行移动目标函数等值线，通过观察得到线性规划的最优解 高中已经学过很多次这个东西了，不再详细介绍。\n注意到，图解法只适用于有两个变量的情况，更高维的情况下，要用单纯形法。\n一般形式 一般形式如下\n\\[\\min f(x_1+x_2+\\cdots+x_n) = c_1x_1+c_2x_2+\\cdots+c_nx_n \\]\n\\[s.t. \\left\\{\\begin{matrix} a_{11}x_1+a_{12}x_2+\\cdots+a_{1n}x_n = b_1\\\\ a_{21}x_1+a_{22}x_2+\\cdots+a_{2n}x_n = b_2 \\\\ \\vdots \\\\ a_{m1}x_1+a_{m2}x_2+\\cdots+a_{mn}x_n = b_m\\\\ x_1,x_2,\\cdots,x_n\\geq 0 \\end{matrix}\\right. \\]\n一共包含\\(n\\)个决策变量，\\(m\\)个约束条件。其中对目标函数既可以求最大也可以求最小，约束条件可以是\\(=,\\leq,\\geq\\)。决策变量\\(x_i\\)通常非负，也有其他情况。\\(c_j\\)称为价值系数，\\(b_j\\)称为资源系数，\\(a_{ij}\\)称为约束系数、技术系数。\n利用矩阵，可以写作\n\\[\\min f(x) = c^Tx \\]\n\\[s.t. \\left\\{\\begin{matrix} Ax=b\\\\ x\\geq 0 \\end{matrix}\\right. \\]\n标准形式 标准形式有四个特征\n目标函数求\\(\\min\\) 约束条件两端用\\(=\\)连接 所有\\(b_i\\)非负 所有\\(x_i\\)非负 接下来介绍如何转换其他形式到标准形式（注意按顺序来）\n目标函数求最小值\n例如\\(\\min z=x_1-2x_2+3x_3\\)，等价于\\(\\max z'=-x_1+2x_2-3x_3\\)，其中\\(z'=-z\\)\n约束函数求最小值\n例如\\(-2x_1+6x_2-x_3\\leq3\\)，将其转化为 \\[-2x_1+6x_2-x_3+x_s=3 \\]\n\\(x_s\\)表示决策中尚未使用的那部分资源，所以称之为松弛变量。\\(x_s\\geq 0\\)\n例如\\(-2x_1+6x_2-x_3\\ge3\\)，将其转化为 \\[-2x_1+6x_2-x_3-x_s=3 \\]\n\\(x_s\\)表示决策中超过了实际需要的部分，因此常称它为剩余变量。\\(x_s\\geq 0\\)\n由上可见，既把函数从不等式转变成了等式，并且新添加的变量也是非负的，也不影响原来的目标函数。统一整个计算过程。\n\\(b_i\\)非负\n这个只需要将约束条件两端取反即可。\n\\(x_i\\)非负\n若\\(x_i\\leq 0\\)，则令\\(x'_i=-x_i\\)，此时\\(x'_i\\geq 0\\) 若\\(x_i\\)无约束，则令\\(x_i = x_i'-x_i'',x_i'\\geq0,x_i''\\geq0\\) 注意这里的变换要把变换也代入目标函数中\n线性规划解的基本性质 对于线性规划问题来说，可行解实际上是由约束条件构成的线性方程组的解。并且还满足非负约束条件，即决策变量都取非负值。\n我们假定线性规划问题的系数矩阵\\(A\\)的秩总等于其行数，\\(rank(A)=m\\)。这意味着系数矩阵\\(A\\)的各行是线性无关的，这也表明约束方程中的各个方程是相互独立的。\n由于\\(A\\)的秩为\\(m\\)，所以其必有一个\\(m\\times m\\)的子矩阵为\\(B\\)，其行列式不为零。\n我们将\\(A\\)的任意一个这样的子矩阵\\(B\\)称为线性规划问题的一个基。\n显然\\(B=[p_1,p_2,\\cdots,p_m]\\)，其中的每一个为基向量，与基向量对应的变量\\(x_j\\)称为基变量，\\(x_B = [x_1,x_2,\\cdots,x_m]^T\\)，其余称为非基变量，\\(x_N=[x_{m+1},x_{m+2},\\cdots,x_n]^T\\)。\n可以得到一个解\\(x=[x_B^T,x_N^T]^T=[x_1,x_2,\\cdots,x_m,0,\\cdots,0]^T\\)\n称\\(x\\)为该约束方程的基解，其中\\(x_b=B^{-1}b\\)\n对于满足非负约束条件的\\(x\\geq 0\\)（所有分量都大于等于\\(0\\)）的基解称为可行解，对应的基称为可行基。\n基可行解的非零分量个数小于\\(m\\)时，称为退化解。也就是说，不是所有基解都是可行解。\n定理1\n线性规划问题的基可行解是其可行域的顶点。\n定理2\n若可行域有界，线性规划问题的目标函数则一定在其可行域的极点上达到最优。\n单纯形法 前面提到，可行解一定在凸集的顶点上，但是，这个顶点的数量很可能非常大。单纯形法就是在这些顶点中优化的算法\n基本思路\n首先将线性规划问题化成标准形式 求出初始基本可行解 判断其是否为最优解 如果不是最优，则迭代到其相邻的基本可行解，并再次检验 单纯形法把寻优的目标集中在所有基本可行解（即可行域顶点）中。从一个初始的基本可行解出发，寻找一条达到最优基本可行解的最佳路径。\n确定初始基本可行解 确定初始的基本可行解等价于确定初始的可行基，一旦初始的可行基确定了，那么对应的初始基本可行解也就唯一确定.\n方便起见，不妨设\\(A\\)中的前\\(m\\)个系数列向量恰好构成一个可行基，即\\(A=(B|N)\\)\n其中\\(B=[p_1,p_2,\\cdots,p_m]\\)为基变量\\(x_1,x_2,\\cdots,x_m\\)的系数列向量构成的可行基。\n\\(N = [p_{m+1},p_{m+2},\\cdots,p_n]\\)为非基变量\\(x_{m+1},x_{m+2},\\cdots,x_n\\)的系数列向量构成的矩阵。\n即原始问题为\n\\[\\min z = c^Tx \\]\n\\[s.t.\\left\\{\\begin{matrix} Ax=b \\\\ x\\geq 0 \\end{matrix}\\right. \\]\n化为\n\\[\\min z = [c_B^T,c_N^T][x_B^T,x_N^T]^T \\]\n\\[s.t.\\left\\{\\begin{matrix} [B,N][x_B^T,x_N^T]^T=b \\\\ x_B,x_N\\geq 0 \\end{matrix}\\right. \\]\n乘法后得\n\\[\\min z = c_B^Tx_B+c_N^Tx_N \\]\n\\[s.t.\\left\\{\\begin{matrix} Bx_B+Nx_N=b \\\\ x_B,x_N\\geq 0 \\end{matrix}\\right. \\]\n计算出\\(x_B = B^{-1}b-B^{-1}Nx_N\\)，代入目标函数中，得到\n\\[\\min z = c_B^TB^{-1}b-(c_B^TB^{-1}N-c_N^T)x_N \\]\n\\[s.t.\\left\\{\\begin{matrix} x_B = B^{-1}b-B^{-1}Nx_N \\\\ x_B,x_N\\geq 0 \\end{matrix}\\right. \\]\n令\\(x_N=\\bm 0\\)，则\\(x_B=B^{-1}b\\)\n所以初始的基本可行解为\\(x=[x_B^T,0]^T\\)\n判断现行的基本可行解是否最优 假如求得一个基本可行解为\\(x=[x_B^T,0]^T\\)，那么\n\\[z = cx = [c_B^T,c_N^T][(B^{-1}b)^T,0]^T=c_B^TB^{-1}b \\]\n如果检验向量\\(\\sigma_N\\)满足\n\\[\\sigma_N^T = c_N^T - c_B^TB^{-1}N\\geq 0 \\]\n这个基本可行解就是最优解。检验向量的各个分量称为检验数。上面的\\(\\geq0\\)是指每个分量都\\(\\geq 0\\)\n特殊情况1\n如果\\(\\sigma_N^T\\geq 0\\)，其中存在一个检验数\\(\\sigma_{m+k}=0\\)，则线性规划问题有无穷多最优解\n特殊情况2\n\\(\\sigma_N^T\\)，其中存在一个检验数\\(\\sigma_{m+k}\u003c0\\)，且该检验数所对应的非基变量的系数列向量的全部系数都为负数或零，则线性规划问题无有界最优解。\n基本可行解的改进——基变换 如果现行的基本可行解\\(x\\)不是最优解，即在检验向量\\(σ_N^T=c_N^T－c_B^TB^{-1}N\\)中存在负的检验数，则需在原基本可行解\\(x\\)的基础上寻找一个新的基本可行解，并使目标函数值有所改善。\n具体做法是：\n先从检验数为负的非基变量中确定一个换入变量，使它从非基变量变成基变量， 再从原来的基变量中确定一个换出变量，使它从基变量变成非基变量。由此得到一个新的基本可行解。 换入变量的确定-最大减小原则\n假设检验向量\\(\\sigma_N^T = c_N^T-c_B^TB^{-1}N = [\\sigma_{m+1},\\sigma_{m+2},\\cdots,\\sigma_n]\\)。若其中有两个以上的检验数为负，那么为了使目标函数值下降最快，就要选取最小负检验数所对应的非基变量为换入变量。\n即若\\(\\sigma_{m+k}\\)是最小的，那么就要把\\(x_{m+k}\\)换入。\n换出变量的确定-最小比值原则\n如果确定\\(x_{m+k}\\)为换入变量，方程\\(x_B = B^{-1}b-B^{-1}Nx_N\\Rightarrow x_B = B^{-1}b-B^{-1}p_{m+k}x_{m+k}\\)\n其中\\(p_{m+k}\\)为\\(A\\)中与\\(x_{m+k}\\)对应的系数列向量。我们要在\\(x_B = (x_1,x_2,\\cdots,x_m)^T\\)中确定一个基变量为换出变量，可以按最小比值原则确定换出变量。\n\\[\\theta = \\min\\bigg\\{\\dfrac{(B^{-1}b)_i}{(B^{-1}p_{m+k})_i}\\bigg|(B^{-1}p_{m+k})_i\u003e0,1\\leq i\\leq m\\bigg\\} = \\dfrac{(B^{-1}b)_l}{(B^{-1}p_{m+k})_l} \\]\n则选择对应的\\(x_l\\)作为换出变量。这里的角标是因为\\(B^{-1}b\\)和\\(B^{-1}p_{m+k}\\)都是\\(m\\)维向量。\n用初等变换求改进了的基本可行解——旋转运算 假设\\(B\\)是可行基，则\n\\[Ax = b\\Rightarrow[B,N][x_B^T,x_N^T]^T = b\\Rightarrow [I,B^{-1}N][x_B^T,x_N^T]^T = B^{-1}b \\]\n令非基变量\\(x_N=\\bm 0\\)，则基变量\\(x_B = B^{-1}b\\)，基本可行解为\\(x=[(B^{-1}b)^T,0]^T\\)\n用逆阵\\(B^{-1}\\)左乘约束方程组的两端，等价于对方程组施以一系列的初等“行变换”。变换的结果是将系数矩阵\\(A\\)中的可行基\\(B\\)变换成单位矩阵\\(I\\)，把非基变量系数列向量构成的矩阵\\(N\\)变换成\\(B^{-1}N\\)，把向量\\(b\\)变换成\\(B^{-1}b\\)\n变换前后的方程组同解。\n且改进了的基本可行解\\(X'\\)只是在\\(X\\)的基变量的基础上用一个换入变量替代其中一个换出变量，其它的基变量仍然保持不变。这些基变量的系数列向量是单位矩阵\\(I\\)中的单位向量。为了求得改进的基本可行解\\(X'\\)，只需对增广矩阵\n\\[[I,B^{-1}N,B^{-1}b] \\]\n施行初等行变换，将换入变量的系数列向量变换成换出变量所对应的单位向量即可。\n表格单纯形法 1.jpg\r对偶问题原理 假设全是列向量。\n设原问题\\(P\\)为\n\\[\\min f(x) = c^Tx \\]\n\\[s.t. \\left\\{\\begin{matrix} Ax\\geq b\\\\ x\\geq 0 \\end{matrix}\\right. \\]\n则其对偶问题\\(D\\)为\n\\[\\max g(y) = b^Ty \\]\n\\[s.t. \\left\\{\\begin{matrix} A^Ty\\leq c\\\\ y\\geq 0 \\end{matrix}\\right. \\]\n对偶关系表 2.jpg\r对偶关系定理 弱对偶定理\n对偶问题(max)的任何可行解\\(Y^*\\)，其目标函数值总是不大于原问题(min)任何可行解\\(X^*\\)的目标函数值。\n对偶定理\n假如原问题或对偶问题之一具有有限的最优解，则另一问题也具有有限的最优解，且两者响应的目标函数值相等。假如一个问题的目标函数值是无界的，则另一问题没有可行解。\n互补松弛定理\n假设\\(X^*,Y^*\\)分别是原问题和对偶问题的可行解，\\(U^*\\)是原问题剩余变量的值，\\(V^*\\)是对偶问题松弛变量的值，则\\(X^*,Y^*\\)分别为原问题和对偶问题的最优解的充要条件是\n\\[X^*V^*+Y^*U^* = 0 \\]\n这个定理还表述为如下两个形式\n假如一个问题的某个变量取正数，则相应问题的另外一个约束条件必取等式 一个问题中的约束条件不取等式，则相应于另一个问题中的变量为零 说起来有些抽象，做题理解。\n一维搜索法 概念 对于一维无约束优化问题\n\\[\\min f(\\alpha) \\]\n求解极小点和极小值的数值迭代方法即为一维搜索方法。\n极小点的必要条件和充分条件见前。注意我们可以用充分条件求解最小值，但是并不是所有情况都能使用，比如函数不一定二阶可微。所以我们常使用迭代法。\n基本步骤 确定搜索区间\\([a,b]\\) 在区间内寻找最小点 优化算法的基本迭代公式为：\n\\[x^{k+1} = x^{k} + \\alpha^kd^k \\]\n其中\\(\\alpha^k\\)为搜索步长，\\(d^k\\)为搜索方向。\\(x^0\\)为人工给出的初始估计。\n终止条件 两次迭代的绝对误差\n\\[|f(x^{k+1})-f(x^k)|\u003c\\varepsilon,\\quad ||x^{k+1}-x^k||\u003c\\varepsilon \\]\n两次迭代的相对误差\n\\[\\dfrac{|f(x^{k+1})-f(x^k)|}{|f(x^k)|}\u003c\\varepsilon,\\quad \\dfrac{||x^{k+1}-x^k||}{||x^k||}\u003c\\varepsilon \\]\n目标函数梯度的模足够小\n\\[||\\nabla f(x^k)||\u003c\\varepsilon \\]\n搜索区间的确定 单谷（峰）函数 我们选取的区间使得函数是单股（峰的），这样我们有以下定理（单谷为例）\n设\\(f(x)\\)在\\([a,b]\\)上单谷，\\(x^*\\in[a,b]\\)是其极小点，\\(x_1\u003c x_2\\)是\\([a,b]\\)上任意两点。则：\n若\\(f(x_1)\\geq f(x_2)\\)，则\\(x^*\\in[x_1,b]\\) 否则\\(x^*[a,x_2]*\\) 进退算法（成功-失败法） 求取区间。\n选取初始点\\(a\\)和步长\\(h\\) 计算并比较\\(f(a),f(a+h)\\)。 若\\(f(a)\\geq f(a+h)\\)，则步长加倍，计算\\(f(a+3h)\\)。若\\(f(a+h)\\leq f(a+3h)\\)，则令\\(a_1=a,a_2=a+3h\\)，停止运算；否则步长加倍，并重复以上（计算\\(a+3h\\)和\\(a+7h\\)）。\n若\\(f(a)\u003c f(a+h)\\)，则步长变为\\(-h\\)，计算\\(f(a-h)\\)。若\\(f(a-h)\\geq f(a)\\)，则令\\(a_1=a-h,a_2=a+h\\)，停止运算；否则步长加倍，继续后退（计算\\(a-h\\)和\\(a-3h\\)）。\n二分法 已知区间\\([a,b]\\)，且\\(f(x)\\)在其中可微，求极小点\n计算\\(x_0=\\dfrac{a+b}{2}\\) 若\\(f'(x_0)\u003c0\\)，令\\(a = x_0\\)，转步骤\\(3\\)。若\\(f'(x_0)\u003e0\\)，令\\(b = x_0\\)，转步骤\\(3\\)。若\\(f'(x_0)=0\\)，停止，\\(x^*=x_0\\)。 若\\(|b-a|\u003c\\varepsilon\\)，则\\(x^*=\\dfrac{a+b}{2}\\)，停止，否则转步骤\\(1\\) 优点\n计算量少，而且总能收敛到一个局部极小点\n缺点\n收敛速度慢\n牛顿切线法 给定初始点\\(x_0,\\varepsilon\u003e0,k=0\\) 计算\\(f'(x_k),f''(x_k)\\) 若\\(|f'(x_k)|\u003c\\varepsilon\\)，停止，\\(x^*=x_k\\)，否则转步骤\\(4\\) 计算 \\[x_{k+1} = x_k - \\dfrac{f'(x_k)}{f''(x_k)} \\]\n令\\(k = k+1\\)，转步骤\\(2\\)\n优点\n收敛快，局部二阶收敛\n缺点\n计算二阶导数工作量大。对初始点要求高，需要初始点离极小点不太远，否则有可能使极小化发散或收敛到非极小点；局部收敛。\n黄金分割法 给定区间\\([a,b],\\varepsilon\u003e0\\) 计算\\(x_1 = a+0.382(b-a),x_2 = a+0.618(b-a),f(x_1),f(x_2)\\) 如果\\(f(x_1)\u003c f(x_2)\\)，则\\(b = x_2，x_2 = x_1,f_2=f_1,x_1 = a+0.382(b-a),f_1 = f(x_1)\\)。否则\\(a=x_1,x_1=x_2,f_1=f_2,x_2=a+0.618(b-a),f_2=f(x_2)\\) 判断\\(|a-b|\u003c\\varepsilon\\)，则跳转\\(5\\)，否则跳转\\(4\\) \\(x^*=0.5(a+b),f^*=f(x^*)\\)，终止。 优点\n不要求函数可微，计算量小，程序简单\n缺点\n收敛慢\n抛物线插值法 以二次插值法为例\n设置初始区间\\([x_1,x_3]\\)，和一中间点\\(x_2\\)，一般为区间中点，设置\\(\\varepsilon\u003e0\\) 计算\\(f_1,f_2,f_3\\)，计算 \\[\\overline{x} = \\dfrac{1}{2}(x_1+x_3-\\dfrac{c_1}{c_2}) \\]\n其中\n\\[c_1 = \\dfrac{f_1-f_3}{x_1-x_3}, c_2 = \\dfrac{\\dfrac{f_1-f_2}{x_1-x_2}-c_1}{x_2-x_3} \\]\n计算\\(f(\\overline{x})\\)\n若\\(\\overline{x}\u003c x_2\\)，则新区间为\\([x_1,x_2]\\)，否则新区间为\\([x_2,x_3]\\)。如果\\(|x_2-\\overline{x}|\u003c\\varepsilon\\)，停止迭代，进入\\(4\\)。新中间点为\\(\\overline{x}\\)，返回\\(2\\) \\(x^*=\\overline{x},f^*=f(\\overline{x})\\)，终止。 优点\n不要求函数可微，计算量小，程序简单，比黄金分割法快\n缺点\n不如黄金分割法可靠\n无约束最优化方法 本章和上章一样都是无约束问题，但是本章的函数是\\(f:R^N\\to R\\)\n搜索步长准则 Armijo准则 设\\(d^k\\)是\\(x^k\\)处的下降方向，若\n\\[f(x^k+\\alpha d^k)\\leq f(x^k)+c_1\\alpha \\nabla f(x^k)^Td^k \\]\n则称步长\\(\\alpha\\)满足Armijo准则，其中\\(c_1\\in (0,1)\\)是一个常数（通常很小，1e-3）\n它有一些缺点，例如\\(\\alpha=0\\)显然满足条件\nGoldstein准则 \\[f(x^k+\\alpha d^k)\\leq f(x^k)+c\\alpha \\nabla f(x^k)^Td^k \\]\n\\[f(x^k+\\alpha d^k)\\geq f(x^k)+(1-c)\\alpha \\nabla f(x^k)^Td^k \\]\n则称步长\\(\\alpha\\)满足Goldstein准则，其中\\(c\\in (0,\\dfrac{1}{2})\\)是一个常数。\n它克服了Armijo的困难。第一个公式保证了其有足够的下降，第二个公式保证了步长足够大。\n最速下降法 迭代格式为\n\\[x^{k+1} = x^k - \\alpha_k\\nabla f(x^k) \\]\n显然，这个方法就是选取方向\\(d^k = -\\nabla f(x^k)\\)，也就是最快下降方法。我们通常会记\\(g(x) = \\nabla f(x)\\)。\n终止准则为\\(||g(x^{k+1})||\\leq \\varepsilon\\)\n\\(\\alpha_k\\)可以设定为常数，也可以用线搜索算法确定。设定为常数时不会有锯齿状况，只有线搜索出来的最优步长会锯齿。\n最优步长为\n\\[t_k = \\arg\\min_t f(x^k-t\\nabla f(x^k)) \\]\n线搜索得到\\(\\alpha_k\\)的方法为回退法。其满足Armijo准则。首先给定初值\\(\\hat{\\alpha}\\)，回退发同步不断以指数方式缩小试探步长，找到第一个满足Armijo准则的点。\n选择初始步长\\(\\hat{\\alpha}\\),参数\\(\\gamma,c\\in(0,1)\\)（经验上来说，选择\\(\\gamma\\)接近\\(1\\)比如0.95，\\(c\\)很小，比如1e-3），初始化\\(\\alpha\\leftarrow\\hat{\\alpha}\\) 当\\(f(x^k+\\alpha d^k)\u003ef(x^k)+c\\alpha\\nabla f(x^k)^T d^k\\)时，令\\(\\alpha\\leftarrow \\gamma\\alpha\\) 输出\\(a_k = \\alpha\\) 正定二次函数情况\n如果\\(f(x) = \\dfrac{1}{2}x^TAx+b^Tx+c\\)\n则最优步长为\n\\[\\alpha_k = \\dfrac{||\\nabla(f^k)||^2}{\\nabla f(x^k)^TA\\nabla f(x^k)} \\]\n也可以写作\n\\[\\alpha_k = \\dfrac{g_k^Tg_k}{g_k^TAg_k} \\]\n优点\n算法简单、计算量小、占用内存小\n缺点\n收敛速度慢，前后两次的搜索方向是正交的（仅限于最优步长情况），容易困在局部最优，还可能被困在鞍点\n随机梯度降 我们的优化目标变为了\n\\[\\min f(x) = \\dfrac{1}{N}\\sum^N_{i=1}f_i(x) \\]\n其中\\(f_i(x)\\)对应第\\(i\\)个样本的损失函数。\n按照最速下降法的要求，\n\\[x^{k+1} = x^k - \\alpha_k\\nabla f(x^k) \\]\n我们的梯度为\n\\[\\nabla f(x^k) = \\dfrac{1}{N}\\sum^N_{i=1}\\nabla f_i(x^k) \\]\n通常，这个量会很大，我们不能简单的得到梯度。于是我们用到了随机梯度降\n\\[x^{k+1} = x^k - \\alpha_k\\nabla f_{S_k}(x^k) \\]\n其中\\(s_k\\)是从\\(\\{1,2,\\cdots,N\\}\\)中随机等可能的抽取的一个样本。\\(\\alpha_k\\)是步长，在人工智能算法中也叫做学习率。\n可以推断得到\n\\[E_{S_k}[\\nabla f_{S_k}(x^k)|x^k] = \\nabla f(x^k) \\]\n优缺点\n同下\n小批量随机梯度降 即抽取元素比较少的集合\\(B_k\\in \\{1,2,\\cdots,N\\}\\)\n\\[x^{k+1} = x^k - \\dfrac{\\alpha_k}{|B_k|}\\sum_{s\\in B_k}\\nabla f_{s}(x^k) \\]\n其中\\(|B_k|\\)为元素个数，又叫batch-size。大小为1时就是随机梯度降，大小和训练样本数据一样大时，算法就是梯度下降。\n优点\n同梯度降\n缺点\n学习率选取较为困难，容易收敛到局部最优，还可能被困在鞍点\n动量法 \\[v^{k+1} = \\mu_k v^k - \\alpha_k\\nabla f_{S_k}(x^k) \\]\n\\[x^{k+1} = x^k + v^{k+1} \\]\n其中\\(\\mu_k\\in [0,1)\\)，通常取\\(\\mu_k\\geq 0.5\\)，代表具有较大的惯性。\\(\\mu_k=0\\)时退化成随机梯度降。\n优点\n和上一次梯度方向一致时，能很好的加速。能够跳出局部最优。在梯度改变方向的时候，能减少迭代次数\nNesterov算法 \\[v^{k+1} = \\mu_k v^k - \\alpha_k\\nabla f_{S_k}(x^k+\\mu_k v^k) \\]\n\\[x^{k+1} = x^k + v^{k+1} \\]\n即提前预估了下一次参数所在的位置。\nAdaGrad 该方法可以自发调整参数。\n令\\(g^k = \\nabla f_{S_k}(x^k)\\)\n引入向量\n\\[G^k = \\sum^k_{i=1}g^i\\odot g^i \\]\n其中\\(\\odot\\)代表向量的对应分量相乘，然后再组合成新的向量。\n迭代格式为\n\\[x^{k+1} = x^k-\\dfrac{\\alpha}{\\sqrt{G^k+\\varepsilon}}\\odot g^k \\]\n\\[G^{k+1} = G^k + g^{k+1}\\odot g^{k+1} \\]\n这里\\(\\alpha\\)为初始步长，\\(\\varepsilon\u003e0\\)是防止除零操作。\n缺点\n随着迭代次数的增加，\\(G^k\\)越来越大，使得\\(\\dfrac{\\alpha}{\\sqrt{G^k+\\varepsilon}}\\to 0\\)，梯度消失\nRMSProp 为了解决学习率趋于\\(0\\)的问题，引入一个\\(\\rho\\in[0,1)\\)\n\\[x^{k+1} = x^k-\\dfrac{\\alpha}{\\sqrt{M^k+\\varepsilon}}\\odot g^k \\]\n\\[M^{k+1} = \\rho M^k + (1-\\rho) g^{k+1}\\odot g^{k+1} \\]\nAdaDelta 令\n\\[g'_k = \\sqrt{\\dfrac{\\Delta x^k+\\varepsilon}{M^k+\\varepsilon}}\\odot g^k \\]\n迭代如下\n\\[x^{k+1} = x^k-g'_k \\]\n\\[M^{k+1} = \\rho M^k + (1-\\rho) g^{k+1}\\odot g^{k+1} \\]\n\\[\\Delta x^{k+1} = \\rho \\Delta x^k + (1-\\rho)g'_k\\odot g'_k \\]\nAdam 可以算是RMSProp和动量方法的缝合方法，Adam不直接使用随机梯度作为基础的更新方向，而是选择了一个动量项进行更新：\n\\[S^k = \\rho_1 S^{k-1} + (1-\\rho_1)g^k \\]\n与此同时又和RMSProp相似：\n\\[M^k = \\rho_2 M^{k-1} + (1-\\rho_2) g^k\\odot g^k \\]\n并不使用这两个量进行更新，而是先修正\n\\[\\hat S^k = \\dfrac{S^k}{1-\\rho_1^k}, \\hat M^k = \\dfrac{M^k}{1-\\rho_2^k} \\]\n这里\\(\\rho_1^k,\\rho_2^k\\)是其\\(k\\)次方。然后使用如下公式更新：\n\\[x^{k+1} = x^k - \\dfrac{\\alpha}{\\sqrt{\\hat M^k+\\varepsilon}}\\odot \\hat S^k \\]\n这里的参数\\(\\rho_1\\)通常选为\\(0.9\\)，\\(\\rho_2\\)通常选为\\(0.999\\)，全局步长\\(\\alpha = 0.001\\)\n牛顿法 牛顿法和一维搜索里面的那个基本就是一样的。\n\\[x^{k+1} = x^k - \\dfrac{\\nabla f(x^k)}{\\nabla ^2f(x^k)} \\]\n它的步长恒为\\(1\\)，停止条件为\\(||\\nabla f(x^k)||\u003c\\varepsilon\\)\n修正牛顿法 第一个修正是修正在其步长上，我们不再使用固定步长\\(1\\)，而是像梯度下降法一样，使用线搜索方法确定一个步长。\n第二个修正是在海瑟矩阵上。海瑟矩阵在高维的时候既不容易计算也不容易储存，并且如果海瑟矩阵不正定，下降方向可能会很差。为此，我们求解下降方向\\(d^k\\)时，首先确定矩阵\\(E^k\\)使得矩阵\\(B^k\\xlongequal{\\text{def}}\\nabla^2f(x^k)+E^k\\)正定且条件数较小，之后求解修正的牛顿方程\\(B^k d^k=-\\nabla f(x^k)\\)得到方向\\(d^k\\)。\n迭代方程还是\\(x^{k+1}=x^k+\\alpha_kd^k\\)\n拟牛顿法 拟牛顿算法直接放弃计算海瑟矩阵，而是找到一个具有类似性质的、方便维护的矩阵去替代。\nDFP更新公式 定义矩阵\\(H^0=I\\)，其更新公式为\n\\[H^{k+1} = H^k + \\dfrac{s^k(s^k)^T}{(y^k)^Ts^k} - \\dfrac{H^ky^k(H^ky^k)^T}{(y^k)^TH^ky^k} \\]\n其中\\(s^k = x^{k+1}-x^k, y^ k= g^{k+1}-g^{k}\\)\n优化算法的迭代公式是\n\\[x^{k+1} = x^k - \\alpha_kH^k\\nabla f(x^k) \\]\n其中\\(\\alpha_k\\)用线搜索确定。注意这里的\\(H\\)直接就具有海瑟逆矩阵的性质，不用写到分母上了。\n共轭方向法 思想：为了克服锯齿现象，假设能够选定下一次迭代的搜索方向直指极小点\\(X^*\\) ，那么对于二元二次函数只需依次沿搜索方向\\(d^0,d^1\\)进行两次精确一维搜索就可以求到极小点\\(X^*\\)。此时两个方向需要满足\\((d^0)^T A d^1\\)（假设二元二次函数为\\(f(x)=\\dfrac{1}{2}x^tAx+bx+c\\)）\n定义1\n设\\(A\\in R^{n\\times m}\\)是对称正定矩阵，\\(p_1,p_2\\in R^n\\)，如果\\(p_1^TAp_2=0\\)，则称这两个向量是\\(A\\)共轭（\\(A\\)正交）的。\n如果有限个非零向量\\(p_1,p_2,\\cdots,p_m\\)，它们任意两个不同的向量都是\\(A\\)共轭的，则称这一组向量为\\(A\\)共轭方向组，也称它们是一组\\(A\\)的共轭方向。\n注意特殊情况，当\\(A=I\\)时，这些向量就是普通的正交向量。\n定理1\n如果\\(R^n\\)中的非零向量\\(p_1,p_2,\\cdots,p_m(m\\leq n)\\)是\\(A\\)共轭向量组，则这\\(m\\)个向量是线性无关的。\n定理2\n设\\(n\\)元函数\\(f(x)=\\dfrac{1}{2}x^tAx+bx+c\\)且\\(A=A^T\\)正定，又设\\(n\\)维向量组\\(p_1,p_2,\\cdots,p_n\\)是\\(A\\)共轭向量组，从任意点\\(x^1\\)出发，依次以该向量组为搜索方向进行精确一维搜索，则\n\\(\\nabla f(x^{k+1})\\)与\\(p_1,p_2,\\cdots,p_k\\)正交 最多迭代\\(n\\)次必达到二次函数的极小点。 在下降迭代法中，若取下降方向是共轭方向，所得到的方法我们称为共轭方向法。\n共轭梯度法 共轭方向的选择很多，但是效果不一样。共轭梯度法是一种好的选择共轭方向的办法。\n初始方向为\n\\[d^0 = -\\nabla f(x^0) \\]\n它的方向的更新公式是\n\\[d^{k+1} = -\\nabla f(x^{k+1}) + \\rho_k d^k \\]\n\\[\\rho_k = \\dfrac{\\nabla f(x^{k+1}) Ad^k}{(d^k)^TAd^k} \\]\n总的优化迭代公式仍然是\n\\[x^{k+1} = x^k + \\alpha_k d^k \\]\n步长仍然用线搜索确定。\nFR共轭梯度法 简单地说，就是\n\\[\\rho_k = \\dfrac{||g^{k+1}||^2}{||g^k||^2} \\]\n其他不变。在正定二次函数中，这两个计算\\(\\rho^k\\)的方法是等价的。但是这个函数看着更简单好用一些。\n有约束最优化方法 对于\n\\[\\min f(x) \\]\n\\[s.t. \\left\\{\\begin{matrix} g_i(x)\\geq 0,i=1,2,\\cdots,m\\\\ h_j(x)=0,j=1,2,\\cdots,l \\end{matrix}\\right. \\]\n这样的有不等式和等式约束的优化问题。我们用罚函数法。其本质思想是把处于可行域之外的点，加一个惩罚项，让它搜索路径向着可行域前进。对于可行域内的点则不做惩罚。\n外点罚函数法 等式约束的二次罚函数\n\\[P_E(x,\\sigma) = f(x) + \\dfrac{1}{2}\\sigma\\sum^l_{j=1}h_j^2(x) \\]\n等式右边第二项称为惩罚项，其中\\(\\sigma\u003e0\\)称为罚因子。（这里这个\\(\\dfrac{1}{2}\\)有些教材有有些没有，我不知道为什么，但我觉得没有明显影响）\n不等式约束的二次罚函数\n\\[P_I(x,\\sigma) = f(x) + \\dfrac{1}{2}\\sigma\\sum^m_{i=1}\\min\\{g_i(x),0\\}^2 \\]\n也不难理解，总之我们要使在可行域内的惩罚项设置为\\(0\\)。注意这里是\\(\\min\\)，因为我们的不等式约束是\\(\\geq0\\)型，如果是\\(\\leq0\\)型，要么改变不等式，要么改成\\(\\max\\)\n如果约束既有不等式的又有等式的，那么直接把惩罚项加起来即可。\n计算机迭代办法\n给定\\(\\sigma_0\u003e0,x^0,k=0\\)。罚因子增长函数\\(\\rho\u003e1\\) 当未达到收敛准则时，进行以下计算 求解\\(\\displaystyle {x^{k+1} = \\arg \\min_x P(x,\\sigma_k)}\\) 选取\\(\\sigma_{k+1} = \\rho\\sigma_{k}\\) \\(k = k+1\\) 解析法求解\n我们令\n\\[\\dfrac{\\partial P(x,\\sigma)}{\\partial x_i} = 0 \\]\n对于所有的\\(x\\)的分量\\(x_i\\)成立。然后我们求出所有\\(x_i\\)的表达式\n\\[x_i = F_i(\\sigma) \\]\n则我们的最优解就是\n\\[x^*_i = \\lim_{\\sigma\\to+\\infty}F_i(\\sigma) \\]\n内点罚函数法 只适用于不等式优化的，其罚函数有两种\n\\[P_I(x,\\sigma) = f(x) + \\sigma\\sum^m_{i=1}\\dfrac{1}{g_i(x)} \\]\n和\n\\[P_I(x,\\sigma) = f(x) - \\sigma\\sum^m_{i=1}\\ln(g_i(x)) \\]\n显然，我们需要选择的初始点要在可行域内，而外点罚函数不需要。\n计算机迭代办法\n给定\\(\\sigma_0\u003e0,x^0,k=0\\)。罚因子增长函数\\(\\rho\\in(0,1)\\) 当未达到收敛准则时，进行以下计算 求解\\(\\displaystyle {x^{k+1} = \\arg \\min_x P(x,\\sigma_k)}\\) 选取\\(\\sigma_{k+1} = \\rho\\sigma_{k}\\) \\(k = k+1\\) 解析法求解\n我们令\n\\[\\dfrac{\\partial P(x,\\sigma)}{\\partial x_i} = 0 \\]\n对于所有的\\(x\\)的分量\\(x_i\\)成立。然后我们求出所有\\(x_i\\)的表达式\n\\[x_i = F_i(\\sigma) \\]\n则我们的最优解就是\n\\[x^*_i = \\lim_{\\sigma\\to0}F_i(\\sigma) \\]\n混合罚函数法 我们知道，外点罚函数可以用于等式和不等式优化，而内点罚函数可以用于不等式优化。我们可以进行一个缝合，把等式约束的用外点罚函数，把不等式优化的用内点罚函数。\n罚函数的统一形式为\n\\[P(x,\\sigma) = f(x) + E(x,\\sigma) + I(x,\\sigma) \\]\n其中\\(E(x,\\sigma)\\)只有一种选择\n\\[E(x,\\sigma) = \\dfrac{1}{\\sqrt{\\sigma}}\\sum^l_{j=1}h_j^2(x) \\]\n\\(I(x,\\sigma)\\)则有三种选择\n\\[I(x,\\sigma) = \\dfrac{1}{\\sqrt{\\sigma}}\\sum^m_{i=1}\\min\\{g_i^2(x),0\\} \\]\n\\[I(x,\\sigma) = \\sigma\\sum^m_{i=1}\\dfrac{1}{g_i(x)} \\]\n\\[I(x,\\sigma) = -\\sigma\\sum^m_{i=1}\\ln(g_i(x)) \\]\n进行组合即可。\n注意内点罚函数需要起始点在可行域内。\n","date":"2023-06-16T19:47:47+08:00","image":"https://kegalas.top/inferior/%E6%9C%80%E4%BC%98%E5%8C%96%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/cover_hu54576080547634ea0a125cfdafb2aa8f_63775_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E6%9C%80%E4%BC%98%E5%8C%96%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"最优化理论学习笔记"},{"content":"数制和编码 十进制、二进制、八进制、十六进制及其转换 过于简单，不多介绍。可以在计组笔记里找到\n反码、补码和补码运算 也可以在计组笔记中找到。\n十进制代码 每四位二进制对应一个十进制数。\n主要有8421(BCD)、2421、5211、余3码、余3循环码。\n8421，2421，5211是三种恒权代码，另外两个不是。\n其中余3码就是在BCD码上加\\(3\\)得到的。余3循环码的特点是相邻的两个代码之间仅有一位状态不同。至于余3循环码怎么得到，看格雷码\n需要注意的是他们的禁止码是哪些，在后面的时序逻辑电路可能会用到。按照从小到大的顺序写出\\(0\\sim 9\\)对应的码，没写出来的就是禁止码。为什么要从小到大？比如2421码，最高位和第二低位都是2，我们要优先选择低位的。\n格雷码 格雷码的形式如下，假设为四位格雷码，最开始是0000. 则最右边的一位变化为0110的顺序，第二位为00111100的顺序，第三位为0000111111110000.以此类推。注意第四位只循环了半个周期，四位格雷码就表示完毕了。\n格雷码的特点是相邻的两个代码之间只有一位发生变化。在代码转换的过程中不会产生过渡噪声。\n四位余3码就是从第四个格雷码开始取10个，即从0010开始到1010。\nASCII码 略。\n逻辑代数基础 三个基本运算 分别是与(AND)\\((\\cdot)\\)、或(OR)\\((+)\\)、非(NOR)\\(('或\\overline{ })\\)，电路符号如下\n1.jpg\r当然，这三个运算可以复合出一些操作。与非(NAND)、或非(NOR)、与或非(AND-NOR)、异或(XOR)，同或(XNOR)。符号如下\n2.jpg\r其中异或有\n\\[A\\oplus B = A\\cdot B'+A'\\cdot B \\]\n同或有\n\\[A\\odot B = A\\cdot B + A'\\cdot B' \\]\n二者互为反运算，\\(A\\oplus B = (A\\odot B)',A\\odot B=(A\\oplus B)'\\)\n注意，与运算可以把\\(A\\cdot B\\)写为\\(AB\\)。关于运算优先级，虽然书上没说，但是应该是非\u0026gt;与\u0026gt;或。\n逻辑代数的基本公式和常用公式 3.jpg\r要证明这些公式，可以列真值表。然后这些公式就可以用来证明别的公式了，比如下面的。\n4.jpg\r逻辑代数的基本定理 代入定理 在任何一个包含变量A的逻辑等式中，若以另外一个逻辑式代入式中所有A的位置，则等式仍然成立。\n反演定理 对于任意一个逻辑式\\(Y\\)，若将所有的\\(\\cdot\\)换成\\(+\\)，所有的\\(+\\)换成\\(\\cdot\\)，\\(0\\)换成\\(1\\)，\\(1\\)换成\\(0\\)，原变量换成反变量，反变量换成原变量，得到的结果就是\\(Y'\\)。\n需要注意：\n要保留原来的运算顺序，例如原来\\(A+BC\\)，变换后要变成\\(A'(B'+C')\\) 不属于单个变量上的反号应保持不变，例如\\((AC)'\\)变换为\\((A'+C')'\\) 对偶定理 若两个逻辑式相等，则它们的对偶式也相等。\n对偶式是：对于任意一个逻辑式\\(Y\\)，若将所有的\\(\\cdot\\)换成\\(+\\)，所有的\\(+\\)换成\\(\\cdot\\)，\\(0\\)换成\\(1\\)，\\(1\\)换成\\(0\\)，得到的结果就是\\(Y^D\\)。\n想要证明两个逻辑式相等，可以转换为证明它们的对偶式相等。有时候这更简单。\n完备集 对于一个代数系统，若仅用它所定义的一组运算符号就能解决所有的运算问题，则称这一组符号是一个完备的集合，简称完备集。\n对于逻辑代数，与、或、非毫无疑问是一个完备集。但它并不是最小的。与非、或非、与或非，它们三个都是能够单独组合实现与、或、非功能的。它们是最小的完备集。\n逻辑函数 如果以逻辑变量作为输入，以运算结果作为输出，那么当输入变量的取值确定之后，输出的取值便确定了，因此输入输出之间是一种函数关系。\n\\[Y = F(A,B,C,\\cdots) \\]\n常用形式 与或式。\\(F=AB+CD\\) 或与式。\\(F=(A+B)(C+D)\\) 与非与非式。\\(F=\\overline{\\overline{AB}\\cdot\\overline{CD}}\\) 或非或非式。\\(F=\\overline{\\overline{A+B}+\\overline{C+D}}\\) 与或非式。\\(F=\\overline{{AB}\\cdot{CD}}\\) 任何逻辑函数都能转换成以上五种形式。它的作用在于，如果电路元件只给你某某元件，你要把原来的表达式转换为上述五种式子，再去套用元件。多用德摩根律。\n描述方法 真值表 逻辑函数式 逻辑图（电路图） 波形图 两种标准式 最小项 \\(n\\)个变量的最小项\\(m\\)是含\\(n\\)个变量的“乘积项”，其中每个变量都以原变量或反变量的形式出现恰好一次。\n\\(n\\)个变量的最小项有\\(2^n\\)个。\n输入变量的每一组取值都使一个对应的最小项等于\\(1\\)。为了方便，例如\\(A=1,B=0,C=1\\)时，该最小项写作\\(AB'C\\)。如果看成二进制数\\(101\\)，则最小项标记为\\(m_{101}=m_5\\)\n最小项的性质有\n在输入变量的任何取值下必有一个最小项，且仅有一个最小项的值为\\(1\\) 全体最小项的和为\\(1\\) 任意两个最小项的乘积为\\(0\\) 具有相邻性的两个最小项之和可以合并成一项并消去一对因子 最大项 \\(n\\)个变量的最大项\\(M\\)是含\\(n\\)个变量的“和”，其中每个变量都以原变量或反变量的形式出现恰好一次。\n\\(n\\)个变量的最小项有\\(2^M\\)个。\n与最小项正好相,反输入变量的每一组取值都使一个对应的最大项等于\\(0\\)。\\(A=1,B=0,C=1\\)时最大项写作\\(A'+B+C'\\)，记作\\(M_{101}=M_5\\)\n最大项的性质有\n在输入变量的任何取值下必有一个最大项，且仅有一个最大项的值为\\(0\\) 全体最大项的积为\\(0\\) 任意两个最大项的和为\\(1\\) 只有一个变量不同的两个最大项的乘积等于各相同变量之和 最后，可以发现\\(M_i=m_i'\\)\n逻辑函数的最小项之和形式 首先将给定的逻辑函数式化为若干乘积项之和的形式，亦称“积之和”形式。然后，再利用基本公式\\(A+A'=1\\)将每个乘积项中缺少的因子补全，这样就可以将与或的形式化为最小项之和的标准形式。\n例如\n\\[Y = ABC'+BC \\]\n\\[Y = ABC'+(A+A')BC = ABC'+ABC+A'BC=m_3+m_6+m_7 \\]\n也可以写作\n\\[Y(A,B,C)=\\sum m(3,6,7) \\]\n### 逻辑函数的最大项之积形式 利用公式\\(AA'=0\\)\n例如\n\\[Y = A'B+AC = (A'B+A)(A'B+C) = (A+B)(A'+C)(B+C) \\]\n\\[Y = (A+B+CC')(A'+BB'+C)(AA'+B+C) = (A+B+C)(A+B+C')(A'+B+C)(A'+B'+C) \\]\n\\[Y(A,B,C,D) = \\prod M(0,1,4,6) \\]\n或者，我们可以先求\\(Y'\\)，并且写出\\(Y'\\)的最小项，再把\\(Y'\\)求反得到最大项。或者得出\\(Y\\)的最小项，利用\\(m_i\\)和\\(M_i\\)的互补关系直接写出结果。\n互补关系指的是，例如\\(3\\)个变量的表达式，\\(Y\\)最小式之和为\\(\\sum m(0,1,4,5)\\)，则\\(Y\\)最大项之积为\\(\\prod M(2,3,6,7)\\)，把剩下没用的都放到最大项里了。这个的证明可以在离散数学笔记中找到。\n逻辑函数的化简 公式化简法 并项法，使用\\(AB+AB'=A\\) 吸收法，使用\\(A+AB=A\\) 消项法，使用\\(AB+A'C+BCDE = AB+A'C\\) 消因子法，使用\\(A+A'B = A+B\\) 配项法，使用\\(A+A=A,A+A'=1\\) 卡诺图法 介绍不方便，看教材。\n注意事项：横轴和纵轴是格雷码排列的。但是填进去的时候，按照坐标的字面量填入最小项。而不是什么转换为格雷码对应的十进制数，再填入对应的十进制表示的最小项。\n如果表达式里有这一项，就填入1，没有就填入0。例如有\\(ABCD\\)就填入坐标为\\(11,11\\)的那一格，也就是第三行第三列，填入\\(m_{15}\\)，填入\\(1\\)，没有这一项就填入\\(0\\)\n如果你得到的是最大项，那么在卡诺图对应的位置填入\\(0\\)，其他位置填入\\(1\\)。\n合并规律\n用尽可能大的圈，去套\\(1\\)，不可套\\(0\\)，但是可以重叠（不要多余，每个圈里面至少有一格只被套过一次）、可以越过边界到达相对的边界一边。\n不方便说，多做题。\n具有无关项的逻辑函数及其化简 对于输入变量的每一组取值组合，逻辑函数都有确定的值，则这类逻辑函数称为完全描述的逻辑函数。\n对于输入变量的某些取值组合，逻辑函数值不确定（可以为1，也可以为0），或者不存在，这类逻辑函数称为非完全描述的逻辑函数。\n无关项在卡诺图里填\\(\\times\\)，在真值表里填\\(\\times\\)，在逻辑函数中用约束项表示\n5.jpg\r在逻辑函数中，一般最小项的约束条件为\\(\\sum d(\\cdots) = 0\\)。最大项的约束条件为\\(\\prod d(\\cdots) = 1\\)\n在卡诺图化简中，带有\\(\\times\\)的可以圈也可以不圈。\n组合逻辑电路 概述 数字电路可以分为两类：组合逻辑电路、时序逻辑电路\n组合逻辑电路的输出仅仅取决于该时刻的输入。\n6.jpg\r输入输出关系可以表示为\n\\[\\left\\{\\begin{matrix} y_1=f_1(a_1,\\cdots,a_n) \\\\ y_2=f_2(a_1,\\cdots,a_n) \\\\ \\vdots \\\\ y_m=f_m(a_1,\\cdots,a_n) \\end{matrix}\\right. \\]\n写成向量形式为\\(Y=F(A)\\)\n分析方法 根据电路图写表达式、列真值表，判断功能\n设计方法 把想做的功能抽象出来，写成表达式，化简表达式，画电路图。\n常用组合逻辑电路模块 8-3普通编码器 7.jpg\r功能就是，把某一位输入变成二进制位输出，比如\\(I_6=1\\)，则输出\\(110\\)。\n它普通就普通在，任意时刻只允许一个输入。\n8-3优先编码器 可以有多个输入，但是按照内部的优先级顺序，会进行选择什么输出。注意这些圆点代表非门，或者说低电平有效。\n8.jpg\r3-8译码器 就是8-3编码器反过来\n9.jpg\r10.jpg\r2-10进制译码器 也就是BCD翻译为10进制数字\n11.jpg\r七段字符管 12.jpg\r数据选择器 从一组输入中选出一个进行输出。\n13.jpg\r14.jpg\r加法器 一位半加器 15.jpg\r\\[\\left\\{\\begin{matrix} S = A'B+AB' = A\\oplus B \\\\ CO = AB \\end{matrix}\\right. \\]\n不考虑低位的进位，称为半加。 \\(S\\)为本位加的结果，\\(CO\\)为进位\n一位全加器、串行加法器、超前进位加法器 见计组笔记。\n\\[\\left\\{\\begin{matrix} S = A\\oplus B\\oplus CI \\\\ CO = AB + (A\\oplus B)CI \\end{matrix}\\right. \\]\n组合逻辑电路中的竞争-冒险 在组合电路中，某一输入变量经不同途径传输后，到达电路中某一会合点的时间有先有后，这种现象称为竞争。由于竞争而使电路输出发生瞬时错误的现象称为冒险。\n将门电路两个输入信号同时向相反的逻辑电平跳变的现象称为竞争。\n应当指出，有竞争不代表一定会产生尖峰脉冲。\n判断有无竞争 只要输出端的逻辑函数在一定条件下能化简成\n\\[Y = A+A'\\quad or\\quad Y = AA' \\]\n则一定有竞争。\n例如\\(Y=AB+A'C\\)，在\\(B=C=1\\)时有\\(Y=A+A'\\)\n或者在卡诺图上看。如果两卡诺圈相切，而相切处未被其他卡诺圈包围，则有竞争。\n两个输入变量以上的竞争就难以判断了，最有效的办法是做实验。利用示波器观察，如果有毛刺，就有冒险。\n消除竞争-冒险的方法 接入滤波电容 引入选通脉冲 修改逻辑设计 修改逻辑设计需要增加冗余项。\n例如，\\(Y = AB+A'C = AB+A'C+BC\\)，此时，当\\(B=C=1\\)时，无论\\(A\\)取什么值，都有\\(Y=1\\)\n半导体存储电路 SR锁存器 16.jpg\r17.jpg\r注意我们约定不同时给SR输入有效。有些地方的SR锁存器是低电平有效，无论什么情况，记住：两个都无效时，保存原有的输出。S（Set）有效时，输出变为\\(1\\)，R（Reset）有效时，输出变为\\(0\\)。\n触发器 电平触发 只有当CLK为有效时，触发器才接受输入信号 在CLK=1的全部时间里，SR状态的变化都有可能引起输出状态的改变。在CLK回到0之后，触发器保存的是CLK回到0之前瞬间的状态。 显然，如果CLK=1时SR多次变化，输出也会多次变化。抗干扰能力弱。\n边沿触发 触发器的次态仅取决于时钟信号的上升沿（或者下降沿）到达时的逻辑状态。抗干扰能力强。\n脉冲触发 当CLK的有效电平消失以后，输出状态才改变。所以也叫延迟触发。\nSR触发器 18.jpg\r\\[\\left\\{\\begin{matrix} Q^* = S+R'Q \\\\ SR = 0(约束) \\end{matrix}\\right. \\]\nJK触发器 \\[Q^* = JQ' + K'Q \\]\n也就是\\(J=K=0\\)时，输出不变，\\(J=1,K=0\\)时输出变\\(1\\)，\\(J=0,K=1\\)时输出变\\(0\\)，\\(J=K=1\\)时，输出翻转。\n只是比SR多了一个翻转的功能而已。\n19.jpg\r由于JK可以实现SR和T，所以现在一般生产JK触发器和D触发器较多。\n注意到上面的时钟信号输入端口有个三角形，和之前的不一样。之前没有三角形的代表电平有效，这里有三角的代表上升沿有效。如果还有个非门在前面，则代表下降沿有效。这张图的JK触发器是下降沿有效。\nT触发器 \\[Q^* = TQ'+T'Q \\]\n也就是说\\(T=0\\)时保持，\\(T=1\\)时翻转。\n20.jpg\rD触发器 \\[Q^*=D \\]\n也就是说输出等于输入。\n21.jpg\r触发器功能的描述方法 状态转移真值表 次态卡诺图与特征方程 状态转移图 激励表 波形图 时序逻辑电路 概述 22.jpg\r23.jpg\r写成向量形式得到\n\\[Y = F(X,Q) \\]\n\\[Z = G(X,Q) \\]\n\\[Q^* = H(Z,Q) \\]\n第一个方程称为输出方程，第二个为驱动方程，第三个为状态方程。\n在时序电路中区分出同步时序电路和异步时序电路。由于课时问题，我们学院只讲同步时序。\n根据输出信号的特点分为米利型和穆尔型。米利型：输出信号取决于存储电路和输入变量。穆尔型：输出电路仅仅取决于存储电路。\n分析方法 从给定的逻辑图中写出每个触发器的驱动方程 驱动方程代入相应触发器的特性方程，得出每个触发器的状态方程，从而得到状态方程组 根据逻辑图写出输出方程 表示方法 状态转换表 状态转换图。输入写斜线上，输出写斜线下，没有输入就空着。 状态机流程图 可自启动电路 时序电路中的所有无效状态经过有限个CP脉冲后都能进入有效状态环，则称它是可自启动的。\n设计方法 逻辑抽象，得出电路的状态转换图或状态转换表 状态化简。如果两个电路状态在相同的输入下有相同的输出，并且转换到同一个次态中，则为等价。可以合并为一个。 状态分配 选定触发器，求出状态方程、驱动方程、输出方程 画出逻辑图 检查能否自启动 常用的时序逻辑电路 移位寄存器 同步计数器 24.jpg\rPT是计数允许端，CP是时钟信号。Cr是异步清零，ABCD是在LD有效时的置数输入。Oc是进位端。\n任意进制计数器的构成方法\n已有N进制计数器，需要M进制计数器\nM\u0026lt; N时\n置零法 置数法 M\u0026gt;N时\n将多片N进制计数器组合起来，构成M进制计数器。可以分为串行进位方式、并行进位方式、整体置零方式。\n集成寄存器 ","date":"2023-06-16T19:42:38+08:00","image":"https://kegalas.top/inferior/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/cover_hua3505806866a19c5f5a93f876aae8123_184422_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"数字电路学习笔记"},{"content":"认知与计算 认知 内涵：自身以及与外界交互中的能动的过程总称。\n外延：包括感觉、知觉、学习、记忆、注意、思维、想 象、语言、决策和行为等。\n动态：根据任务需求自主完成“感知一分析一决策一执行”的动态过程，并能够应对意外情形。\n认知金字塔 1.jpg\r元认知 对认知的认知，依据认知对象对认知过程进行主动的监则以及连续的协调\n认知信息的来源 嗅觉、味觉、视觉、听觉、触觉、平衡感、第六感等等。\n脑的构成与功能 2.jpg\r间脑位于两侧大脑半球之间，是脑干与大脑半球连接的中继站。\n丘脑是间脑中最大的卵圆形灰质团块，对称分布于第三脑室两侧。除了嗅觉输入以外，其余感觉通道的信息都需要经过丘脑中的相应区域后到达初级感觉皮质\n上丘脑位于背侧丘脑的后上方,包括缰三角、缰连合丘脑髓纹、松果体和后连合。松果体对光线敏感，与光照引起内分泌调节改变有关。\n下丘脑是有调节自主功能、内分泌和内脏功能的皮质下中枢，下丘脑的某些细胞既是神经元又是内分泌细胞。调节体温、摄食、水盐平衡、内分泌。参与情绪过程并控制垂体来调节生理周期的节律。还可以通过向血液释放激素来远距离神经调控。\n基底节是锥体外系统的中继站，各核之间有密切的纤维联系。基底节与大脑皮质及小脑协同调节随意运动、肌张力和姿势反射，也参与复杂行为的调节。\n杏仁体与情绪控制、恐惧感、动机、非语言的情绪解读等有关。\n大脑区块\n额叶：中央前回是人脑控制运动的中枢，前额叶是人类高级认知活动的生理基础，负责计划、调节和控制人 的心理活动，对人的高级的、目标导向的行为有重要作 用；前额叶受损的人会带来诸多缺陷，如无法抑制自己 的行为、无法控制自己的情绪、无法有效的做计划与执 行计划、无法有工作记忆。(反向理解额叶功能)\n顶叶：人类重要的感觉中枢，响应疼痛、触摸、品尝、温度、压力等感觉，顶叶还与注意功能、空间分辨以及数学逻辑相关。\n颞叶：负责处理听觉信息，也与记忆和情感有关。\n枕叶：负责处理视觉信息。\n岛叶：与情绪功能及自主功能有关。\n注意点\n大脑左右半球的分工并不是那么泾渭分明，功能的单侧化只具有相对的意义。 大脑组织的两个基本原则是功能整合和功能分化，需要考虑局部属性和连接属性两个方面。 大脑组织存在个体差异性，获得大脑组织的一般的特征和了解个体差异是相辅相成的，人脑的可塑性。 无论如何分区，大脑作为整体大于各部分之和。 脑的三位一体 3.jpg\r人脑的三位一体学说：古脑，也叫做爬行脑；旧脑，也叫做哺乳脑；最后一个是新脑，也就是大脑的新皮质\n古脑：平衡、自动机能、呼吸心跳\n旧脑：情感、直觉、哺乳、搏斗、逃避\n新脑：高阶认知功能，老鼠失去了脑皮质，仍然可以正常活动\n认知系统的模拟方法 功能模拟（逻辑主义，符号运算系统，例如电梯） 结构模拟（连接主义，人工神经网络，例如人脸识别） 行为模拟（涌现主义，集智、群智、社会化，例如无人机蜂群） 方法与技术 心理学方法 这里验证大脑功能的方法有\n反应时法 比较法 眼动分析法 口语报告法 内隐联想测验 计算机模拟法 损伤研究法 心理学方法设置的要点\n输入输出设置要精简全面 测试流程简洁 测试结果、测试流程、输入和输出之间的关系平衡 定性分析和定量分析 人工成像系统的基本性能指标 基本指标（最小角分辨率，空间分辨率）如下\n\\[1.22\\lambda /nD \\]\n其中\\(D\\)是口径，\\(n\\)是折射率，\\(\\lambda\\)是入射波长。\n空间分辨率的影响因素 见上\n时间分辨率的影响因素 时间分辨率指的是帧率\n脑成像包括的技术方法 CT（计算机断层扫描） PET（正电子发射计算机断层扫描技术） SPECT（单光子发射计算机断层显像技术） 干涉成像 MRI（磁共振成像技术） 光声成像技术 FMRI（功能磁共振成像技术） EEG (脑电波) MEG（脑磁图） 脑电图和脑磁图的基本概念 神经与信息 新函数的出现对科技的推动作用 函数的发展：\n参数多 形式复杂 数函数并不能理解为传统的“显示表达” 重大函数的发现，都能推进科学技术的显著进步 神经网络 理论上两层神经网络已经可以拟合任意函数\n单个人工神经元可以用一个简单函数表示，人工神经元的串联相当于函数的嵌套，并联相当于函数间的线性组合。\n激活函数的性质 输连续并可导的非线性函数，可导的激活函数可以直接利用数值优化的方法来学习网络参数； 测激活函数及其导函数要尽可能的简单，有利于提高网络的计算效率。 激活函数的导函数的值域要在一个合适的区间内，不能太大也不能太小，否则回影响训练的效率和稳定性。 神经网络的传播都是形如Y=WX+b的矩阵运算；为了给矩阵运算加入非线性，需要在隐藏层中加入激活层；输出层结果需要经过Softmax层处理为概率值，并通过交叉熵损失来量化当前网络的优劣\n4.jpg\r神经系统的组成 神经系统主要由神经元、神经胶质细胞两种细胞组成。\n数量众多的神经胶质细胞，几十倍于神经元，占脑容量的一半，有神经胶水之称，通常其胞体较小。\n神经胶质细胞在形态上与神经元最大的区别是虽然有突起但没有形成明显的轴突，自身不传递信息。\n神经元的组成及其功能 神经元是神经系统的基本结构和功能单位之一，可以分为细胞体、树突、轴突以及轴突终末。\n细胞体又被称为核周体，其由细胞膜、细胞核、细胞质、细胞器组成，进行着维持生命的各种代谢活动。细胞质内有尼氏体(Nissl Body)，强嗜碱性，均匀分布，合成蛋白质、酶类、肤类。\n树突表面有大量细小的突起，即树突棘。树突棘实际上是树突上的小突起。在树突棘的顶部有突触的连接点，负责接受刺激，并把刺激传向胞体(神经元之间通过神经递质传递神经信号的连接称为突触)。\n神经元只有一个长细而均匀的轴突，轴突以及套在外面的髓鞘，被称为神经纤维，比树突长得多。轴突在细胞起始部被称为轴丘，轴丘内没有尼氏体，其兴奋性最高，往往是动作电位发起的地方。轴突进行动作电位的快速传导和物质的转运。\n在脑和脊髓里，细胞体密集的部位色泽灰暗，叫灰质。在灰质里，功能相同的神经元细胞体汇集在一起，调节人体的某一项相应的生理功能，这部分结构就叫作神经中枢。\n神经纤维主要集中在周围神经系统里，许多神经纤维集结成束，外面包着由结缔组织形成的膜，就成为一条神经。神经纤维末端的细小分支叫神经末梢，神经末梢分布在全身各处。\n在脑和脊髓里，也有神经纤维分布，它们汇集的部位色泽亮白，叫白质。白质内的神经纤维，有的能向上传导兴奋，有的能向下传导兴奋。\n神经胶质细胞的作用有：\n支持作用 绝缘作用 屏障作用 营养性作用 修复和再生作用 维持神经元周围的K+平衡 摄取神经递质 神经信息传播一般分两个阶段，即神经元内的传导过程和神经元间的传递过程。\n在神经信号传播过程中，神经元的四个部分要产生四种类型的信号活动：输入信号、整合信号、传导信号和输出信号。\n树突是神经元的输入和接受成分，细胞体是神经元的整合或总合成分，轴突为神经元的信号传送或传导成分，轴突终末为神经元的输出或分泌成分。\n神经元机能最大的特点是特异的信息传递和处理，且具有传递信息的绝缘性和极性。\n神经元类型 按形状分\n5.jpg\r只有一个远离胞体的突起，此突起能分支形成树突和轴突，常见于无脊椎动物； 两个突起，一个树突，一个轴突，一端接收一端传递，听觉、嗅觉、视觉等信息传递系统； 一个轴突和多个树突，多见于运动和感觉系统中； 一个树突，一个轴突，多见于脊髓背根神经节，躯体感觉神经细胞。 按功能分\n感觉神经元，或称传入神经元，多为假单极或双极神经元 运动神经元，或称传出神经元，多为多极神经元 中间神经元，介于前两种神经元之间，多为多极神经元。 根据释放的神经递质分\n胆碱能神经元 胺能神经元 肤能神经元 氨基酸能神经元 神经信息的产生过程 在脑和神经元的细胞膜上一些称为离子通道的蛋白质分子允许离子流动，导致神经元细胞膜内、外的电位差，称之为膜电位。\n在没有任何外来刺激情况下的膜电位称为静息电位，这时膜内相对膜外约为-70毫伏。\n当神经元受到刺激发生兴奋时，在静息电位的基础上会发生瞬时的电位变化，这时膜内外的极性改变(即所谓的去极化作用)，此时的膜电位称之为动作电位(此时膜内可比膜外高出30–50毫伏)，它是神经元传导兴奋的电信号。\n6.jpg\rNa进K出。\n神经信息编码 7.jpg\r发放率编码：单个神经元强烈并且独立地放电，激活了下游的读出神经元\n相关性编码：较弱但同步性的发放同样可以激活下游的读出神经元\n发放率编码的效率比较低，但是抗噪音干扰的能力很强。\n相关性编码可能会与外界刺激绑定，感觉神经元通过时间特征不同的激发模式，来代表不同的外界感觉刺激，例如 光、声音、味觉、嗅觉与触觉信号。\n在一定条件下，神经系统可以在两种编码策略间进行动 态地“切换”，以达到更好的信息编码效果，这就是“动态 编码”。一个特殊的例子就是适应性期间，神经系统在接受 到恒定不变的刺激时，其反应强度会随着时间逐渐衰减。这 也就是所谓的“久居兰室，不闻其香”现象。\n视觉与计算 眼睛的组成结构及其功能，其与人工成像系统相比所具有的优势 视觉信息感知和传递的过程中，眼睛执行两个功能：\n眼睛光学系统在眼底视网膜上形成外界物体的影像； 视网膜将物像的电磁波能转换为视觉的神经冲动。 波长低于可见光的光分辨率高，但是衰减快，传播距离短。波长高于可见光的光虽然分辨率低，但是衰减慢，传播距离远。\n眼睛分为：\n瞳孔 相当于相机的光圈。外面光线强的时候，瞳孔缩小；光线弱的时候，瞳孔变大，从而使眼睛里接受的光线总是恰到好处。一旦失调，则曝光不当。\n虹膜 相当于光圈的叶片。如果光线过强，虹膜内瞳孔括约肌收缩，则瞳孔缩小；光线变弱，虹膜开大肌收缩，瞳孔变大。根据虹膜内含色素的不同，虹膜呈现不同的颜色。白种人虹膜色素较少，呈灰蓝色；黄种人色素较多，呈棕黄色；黑人色素最多，呈黑色。\n巩膜 相当于相机壳。对眼球的内部结构起保护作用，占据整个眼球后面约5/6的范围，俗称眼白。\n晶状体 相当于全自动变焦镜头。位于瞳孔虹膜后面，呈双凸透镜。正常人既能看近又能看远，全依赖于晶状体的调节。看远时，睫状肌放松，悬韧带绷紧，晶状体变扁平，折光力减少；看近时，睫状肌收缩，悬韧带放松，晶状体依靠其本身弹性变凸，折光力增加。\n通过如此调节，使光线能聚焦在视网膜黄斑上。如果通过调节，光线不能聚焦在视网膜上，就存在屈光不正。\n光线聚焦在视网膜之前称为近视眼；聚焦在视网膜之后称为远视眼； 不能聚焦在一个点，称为散光眼； 如果晶状体的调节功能失调，如年老时，晶状体不能变凸，称为老视，即老花眼； 如果晶状体变混浊，就称为白内障。 视网膜 视网膜相当于胶卷。起感光功能。感光最敏锐的那部分，称为黄斑。虽然视网膜很薄，结构却很复杂，分为10层，感光的细胞主要是视锥细胞和视杆细胞。视锥细胞主要负责明视觉和色觉，视杆细胞主要负责暗视觉。自然视网膜让人工技术难以望其项背。\n视网膜又称为外周脑，与脑组织同源，起源于外胚层。\n脉络膜 相当于照相机的暗箱。主要由血管组成，因此还兼有营养眼球的责任。\n立体视觉的分类 单眼立体视觉\n双眼立体视觉\n单眼立体视觉的因素因素 可以通过通过透视原理（绘画上的那个）来感知立体，也可以通过空气透视（想象大雾天远近的清晰度不一样），也可以通过光和阴影关系，也可以通过重叠效应、视野、单眼运动视差、调节效应、像的大小。\n重叠效应：当两个图像重叠、轮廓线相交时，交点轮廓线平滑连续的图像比轮廓线不连续的看起来更近。见下\n8.jpg\r视野：人眼的视野颇宽，水平方向约220◦，垂直方向约130◦，呈一椭圆状。所以宽荧幕的立体感比窄银幕强。\n单眼运动视差：由于视线方向的连续变化，单眼的视网膜成像也不断发生变化，这样，借助时间顺序的比较便形成立体视觉。这种利用观看者与物体间的相对运动使空间物体的相互位置产生变化，从而判断出物体间的前后关系，相当于连续地从几个方向观看景物，类似于有几只眼睛观看景物的状况。\n当用单眼观看物体时，若眼睛位置不动，调节效应便是对深度感的唯一心理暗示，若允许观看位置移动的话，便可利用双眼视差这种效应从各个方向来观看物体，从而产生出深度感，这个效应便称为单眼运动视差。显然，单眼运动视差对静态物体不起作用。单眼运动视差这一视觉因素形成立体视觉的有效距离为300m以内。\n调节效应：当人眼观看距离不同的物体时，为使物体能在视网膜上成像，人眼通过改变睫状肌的张弛程度来改变眼球晶状体的曲率，从而使晶状体凸透镜的焦距产生变化，达到视网膜上清晰成像。大脑就可以通过这个东西来判断远近。这一视觉因素单独起作用时，距离超过5m便失效了。\n像的大小：视网膜成像的相对大小同样大小的物体，当观看距离不同时，在视网膜上成像的大小也不一样。\n双眼立体视觉 双眼立体视觉：主要用于短距事物的感知。双眼立体视觉主要因素是双眼视差。\n视觉的恒常性包括那些内容 当客观条件在一定范围内改变时，大脑知觉映象在相当程度上却保持着它的稳定性，即知觉恒常性。知觉恒常性是在日常生活中造成的，是先天和经历独特影响的。\n外部世界投影在视网膜上产生了图象，大脑经过因素分解把这些影响传感器信息的条件，如照明条件、观察者的距和方位等因素分出去，得到纯粹的关于对象的信息，这些信息是不随这些条件而变的，因此被称为恒常性。\n双稳态视觉\n9.jpg\r要么看见花瓶，要么看见人脸。即使可以切换，也只能同时看到一个。\n大脑预设的前提\n10.jpg\r大脑预设了光从上面照下来，会看到左边凸，右边凹。如果预设光从下面来则相反。\n情景\n11.jpg\r亮度\n12.jpg\r分类\n大小恒常性，形状恒常性，方向恒常性，颜色恒常性，明度恒常性\n其他恒常性：距离恒常性，速度恒常性，年龄恒常性，声音恒常性，语音恒常性\n大脑解决问题的思路 大脑解决似是而非问题的思路是一个“猜测与印证＂动态交互过程。\n在日常生活中，很多时候只需要一两个回合就能成功识别。但的确有的时候一个图像看得不太清楚，我们会盯着 它左看右看，大脑内部可能就进行了信息的上传、下传的交替，不断地进行“猜测-印证-猜测-印证”，只要印证结果 是否定的，这个过程就会一直进行下去，直到得到肯定的结果。\n图像模糊的原因 透镜缺陷 相机抖动 场景运动 深度散焦 感知与运动 感觉与知觉的基本概念 人类对自身和外部世界的认知，都是从经验中获得的，而经验来源于感觉和知觉。\n感觉：是人脑对客观事物个别属性和特征的直接反映。\n知觉：人脑对客观事物各种属性、多种特征及其相互联系的综合性和整体性反映\n感觉与知觉的区别和联系 14.jpg\r感觉是人脑对客观事物个别属性和特征的直接反映，知觉则是人脑对客观事物各种属性、多种特征及其相互联系的综合性和整体性反映。\n感觉系统处理的是某种感受器感受到的未经整合的具体刺激信息，知觉系统处理的则是多种感受器整合组织后的信息。\n人类五种基本的感觉系统 13.jpg\r其中肤觉又叫躯体感觉。肤觉下面还可以加一个痒觉。内部感觉还可以把动觉分为震动觉和运动觉，还可以再加上饥感、渴感。\n其中物种基本感觉是：听觉、视觉、嗅觉、味觉、躯体感觉。\n典型感觉的感受器及其适宜刺激 感受刺激的步骤为：\n感受器感受物理刺激 神经元将刺激转化为神经信息 大脑加工信息后产生知觉或有意识的感觉体验 20.jpg\r15.jpg\r16.jpg\r感觉剥离实验告诉我们：生命活动的维持需要一定水平的外界刺激。\n感觉信息编码时，刺激信息的基本属性 刺激信息只有四个基本属性：模态-位置-强度-时间\n模态：标记线性编码（感受器特异性） 位置：空间分布编码 强度：动作电位频率编码 时间：时间适应率编码 知觉的特性及影响因素 17.jpg\r知觉的特性为：\n选择性 我们并非对一切刺激都全部接收，我们有选择地接受少数事物作为知觉的对象。例如双稳态视觉。\n影响因素有：客观上：对象与背景的差别；对象的活动性；对象各部分的组合；主观上：兴趣；需要；情绪\n对象和背景是相互依存、相互转化的。\n整体性 对象可能由不同的部分组成，但我们的知觉并不看做孤立的部分，而是当作一个整体。\n组织定律：接近律（距离上近的容易被知觉组织在一起）、相似律（物理属性相似的容易被组织在一起）、连续律（具有连续性或者共同运动方向的刺激）、封闭律（倾向于将缺损的轮廓加以补充使知觉成为一个完整的封闭图形）。\n影响因素：对象各组成部分的强度；对象各组成部分的相互关系；个体生活经验和知识储备。\n理解性 人在知觉客观事物时，总是根据已有的认知经验来解释它，赋予它一定的意义，并用词把它标志出来。\n影响因素：个人的知觉经验；言语的指导作用；实践活动的任务。\n恒常性 当知觉的客观条件在定范围内改变时，知觉的印象仍然相对地保持不变，知觉的这种特性称为知觉的恒常性。\n大小恒常性\n指在一定范围内，个体对物体大小的知觉不完全随距离变化而变化，也不随视网膜上视像大小的变化其知觉映象仍按实际大小知觉的特征。\n形状恒常性\n物体形状的知觉不因它在网膜上投影的变化而变化。\n明度恒常性\n当照明条件改变时，人知觉到的物体相对明度保持不变的知觉特征。\n颜色恒常性\n指有颜色的物体（熟悉的），当其表面颜色受到照明等条件的影响而改变时，个体对颜色的知觉不因色光改变而改变，趋于保持相对不变的知觉特征。\n错觉的分类 错觉是对客观事物的一种不正确的、歪曲的知觉。\n错觉是知觉的一种特殊状态。\n18.jpg\r物体知觉的错觉的原因假说有：\n眼动说 常性误用说 神经位移说 混淆或错误比较说 对比和同化说 社会知觉误区有：\n第一印象 近因效应 光环效应 期望效应 心理定势 生活中的刻板印象 听觉信号的转换过程 耳道引起鼓膜震动 鼓膜的震动引起三块小骨-锥骨、镫骨和钻骨上相震动,能将声音传递至充满淋巴液的内耳 内耳可产生神经冲动,冲动沿听神经转为神经能,从那儿声音的信息就传到大脑 19.jpg\r等响曲线的理解 由于耳朵的结构，我们感受到的响度和声音的频率有关，不仅局限于声压级的影响。\n听声辩位的原理 耳间时差：声音到达两耳的时间不同，分辨率为10\\(\\mu s\\) 耳间强差：声音在两耳的强度不同，分辨率为1dB 学习与记忆 脑神经科学，学习、记忆的定义 学习：人或动物通过神经系统获取新信息和新知识的神经过程\n记忆：对所获取信息的保存和读取的过程\n多媒体解释学习认知模型 21.jpg\r多媒体学习把认知分为三个基本过程\n选择 对所呈现的语词和图像相关部分予以注意，把感觉记忆中的信息转化到工作记忆中。\n组织 对已经选择的语词进行组织，以形成连贯的言语模型；对已经选择的图像进行组织，以形成连贯的图像模型；在工作记忆中深层加工信息。\n整合 将声音表征和图像表征相互联系起来，并与原有知识相结合；把长时记忆中的知识转换到工作记忆中同时也调整长时记忆内容。\n学习过程中最重要的是认知表征。\n认知表征是指个体经知觉而将其外在环境中的物体或事件转换为内在心理事件的过程，人类获得知识的过程就是对事件进行认知表征的过程。认知表征的实质其实就是观念、事件和事物在心中是如何被储存和被概念化的。\n赫布理论 突触可塑性 突触可塑性（Synaptic plasticity）是指神经细胞间的连接，即突触，其连接强度可调节的特性。突触的形态和功能可发生较为持久的改变的特性或现象。\n赫布理论(Hebbian theory)描述了学习过程中突触可塑性的基本原理，即突触前神经元向突触后神经元的持续重复的刺激可以导致突触传递效能的增加。\n赫布理论也是非监督学习的生物学基础。\nSTDP 学习规则 Henry Markram提出STDP(Spike Timing Dependent Plasticity) ：根据神经元学习的先后顺序，调整神经元之间连接的强弱——即大脑中神经元之间权重连接的更新规则。\nSTDP可以说是赫布理论的一种延伸。赫布理论强调两个神经元经常一起活动，则二者的连接会增强。\nSTDP则进一步说明，两个神经元之间的活动，如果其他神经元的信息在本身活动产生之前，则两神经元之间的连接会增强。如果神经元本身产生活动之后才接受其他神经元传来的信息，则两神经元之间的额连接会减弱。如果两个神经元的发放在时间上离的越近，他们之间的绑定关系就越紧密。（这段话摘自老师PPT，我的评价是狗屁不通，见下面的例子）\n对于神经元\\(i\\)而言，如果神经元\\(i\\)传递信息之后，神经元\\(j\\)才产生反应，那么类似于因果关系，它和传递信息的神经元之间连接\\(G(j-\u003ei)\\)会加强。\n如果\\(i\\)产生反应之后，\\(j\\)才传递信息来，那么这个信息就有可能被忽略，\\(i\\)和\\(j\\)的连接\\(G(j-\u003ei)\\)就会减弱。\n当突触前神经元的峰电位先于突触后神经元峰电位产生，即\\(t^{pre}_j\u003c t^{post}_i\\)，则连接两个神经元间的突触权值变大；反之，权值变小。\n突触前脉冲先于突触后脉冲到达时，能够引起长时程增强\\(LTP\\)；反之引起长时程抑制\\(LTD\\)\n脉冲神经网络 脉冲形式处理 传统神经网络算法仍然依据于使用高精度的浮点数进行运算， 然而人脑并不会使用浮点数进行运算。 在人的传感系统和大脑中， 信息会以动作电压或称之为电脉冲（electric spike）的形式传递，接受，和处理。因此，产生了脉冲神经网络——第三代人工神经网络。\n迁移学习：脑认知和人工智能领域定义、包含的类型 脑认知领域中\n迁移学习：一种学习对另一种学习的影响。\n知识可以迁移，动作技能、情感、态度、习惯等都可以迁移。\n迁移学习分为：\n顺向迁移：先前的学习对后来学习的影响 逆向迁移：后来的学习对先前学习的迁移 也可以分为\n正迁移（positive transfer）：指一种学习中学得的经验对另一种学习起促进作用 负迁移（negative transfer）：指一种学习中学得的经验对另一种学习起阻碍作用 也可以分为\n水平迁移(侧向迁移）：已习得的概念、规则或解决问题的方法在新的情境中的运用 垂直迁移(纵向迁移）：:低级概念和规则向高级概念和规则的迁移 也可以分为\n特殊迁移（special transfer）：具体知识和动作技能的迁移 一般迁移（nonspecial transfer）：原理和态度的迁移。这一类迁移是教育的核心。 人工智能领域中\n迁移学习涉及到两个概念，分别是域和任务。域，与特定数据集的特征空间和特征的边际概率分布有关；任务，与数据集的标签空间和目标预测函数有关。迁移学习的目的是将从某一个域（通常称为源域）任务中学习到的知识迁移至另一个域（通常称为目标域）的任务上。\n迁移学习的方法包括\n基于数据 主要通过改变源域数据来达到知识迁移的目的。例如数据增强，提升源域数据的丰富程度，减小源域数据与目标域数据的差异。\n基于特征对齐/转换 主要通过将源域和目标域的特征进行对齐或转换来进行知识的迁移。例如DANN模型。\n基于模型 通过调整模型的参数、集成模型等方式来进行知识迁移。例如将在源域内训练好的模型在目标域数据上加以微调。\n元学习定义 学会学习 选择题 脑认知领域中\n元学习是学习者意识到并逐渐控制自己已经习惯化了的感知、查询、学习和成长的过程，这一过程体现了“学会学习”的内涵。\n人工智能领域中\n利用元数据来理解如何提升学习在解决问题时的灵活性，从而提升现有学习算法性能或诱导学习算法对自身进行调整和学习的手段。元学习最大的颠覆性在于其将学习的对象由数据提升至了学习任务。\n学习形成记忆的分子机制 海兔，神经系统只有2w个神经细胞。具有一种可以保护鳃的简单保护性反射，可以用来研究基本的学习机制。\n“短期记忆”的机制是由于离子通道受影响，使更多的钙离子进入神经末梢。由此，导致神经突触释放更多的神经递质，从而使反射加强。这些转变是由几个离子通道蛋白的磷酸化所致。\n长期记忆需要生成新的蛋白质。\n长期记忆与短期记忆均发生在突触部分。\n短期记忆到长期记忆 持续重复的刺激。\n记忆的基本过程 编码或登录。感知外界事物或接受外界信息(外界刺激)的阶段，也即通过感觉系统向脑内输入讯号一学习过程。 存储：获取的信息在脑内贮存和保持的阶段。 提取或再现：将贮存于脑内的信息提取出来使之再现于意识中的过程一一回忆过程。 遗忘：是对识记过的材料不能再认与回忆，或者错误的再认与回忆。 记忆的类型 22.jpg\r短期记忆 如前图所述。\n短期记忆中，乱序的、无意义的东西，比有序的、有意义的东西记忆容量要小。\n长期记忆分类 23.jpg\r老实说我觉得记住深度为2的节点就行，更下面的了解一下。\n多重存储记忆模型 电话号码、圆周率形成长期记忆 该模型认为，信息首先被存储在感觉记忆中，被注意选择的事件将进入短时记忆。一旦进入短时记忆，如果事件被复述则可以进入长时记忆，并且信息在每一个阶段都可能遗失，其原因可能是衰退、干扰，或者两者的结合。\n多重存储记忆模型有两个重要过程：\n注意。感觉记忆通过“注意”进入短时记忆，没注意的就很快消失。 复述。短时记忆的保留时间也很短。但是，通过复述(重复背诵)可以使得信息在短时记忆中保持更长的时间并且可以存储到更加持久的长时记忆中。 工作记忆模型定义 绘制 Baddeley-Hitch 工作记忆模型 工作记忆是指在执行认知任务过程中，用于已知的或新的信息提供暂时储存与加工的容量有限的系统。这种记忆一般持续数秒，易被抹去，并随时更换。\n工作记忆=短时记忆+控制加工系统\n24.jpg\rBaddeley-Hitch工作记忆模型认为工作记忆由语音回路视觉空间模板和中央执行系统组成。\n语音回路负责以声音为基础的信息储存与控制，\n视觉空间模板主要负责储存和加工视觉信息，\n中央执行系统是工作记忆的核心，负责各子系统之间以及它们与长时记忆的联系、注意资源的协调和策略的选择与计划等。\n由于有些东西不能被原版模型解释，Baddeley又加入了情景缓冲区的概念。\n不同脑区的功能 不同脑区负责不同形式的记忆产生与存储 非陈述性记忆\n小脑：运动性技巧记忆 杏仁核：情绪性记忆 纹状体：习惯化行为记忆 陈述性记忆\n间脑（丘脑）：连接大脑皮层，是短期记忆向长期记忆过度的关键脑区。 前额皮层：工作记忆，长时情节记忆和抽象的语义记忆。 海马(内侧颞叶)： 短期(几分钟到数周) 空间方位和情节性事件记忆。海马相当于大脑中的图书管理员，将信息长期储存于大脑皮层。 HM 病人 HM，被切除了双侧颞叶内侧。记忆维持不到30秒，虽然无法记得刚讲过的话、刚阅读过的文字、刚看过的照片，但其它的心智功能并不受到影响。\n这称为顺行性失忆。\n海马体 长期记忆存储转换、空间位置定向\n记忆遗忘曲线 密集学习 间隔学习 艾宾浩斯遗忘曲线，过于著名，无需介绍。\n25.jpg\r这个告诉我们，应该采用间隔学习而不是密集学习。比如我们应该一个星期背十遍单词，而不是一天背十遍。\n人工智能专业 记忆存在在哪里 并举出一个例子 PPT没给，我猜测是存在神经网络之中。\n例子：利用预训练好的GAN（生成对抗网络）作为记忆存储器；提取GAN中的知识记忆，并作为先验指导人脸图像的修复。\n贝叶斯大脑定义 贝叶斯定理 大脑可能遵循贝叶斯定理。大脑不是外部世界刺激信号的“记录机”，而是在先验知识引导下，主动进行加工、推理与生成预测。\n贝叶斯网络 贝叶斯准则和图论相结合形成贝叶斯网络。\n沟通与语言 语言的广义和严格定义 语言就广义而言，是一套共同采用的沟通符号、表达方式与处理规则。\n严格来讲，语言是由语音、词汇和语法构成并能表达人类思想的符号系统。\n不同生物的沟通方式 果蝇：嗅觉、拍打、唱歌 蜜蜂：跳舞 长尾猴：吼叫 红毛猩猩：手势 研究动物沟通有助于了解人类语言演化 无\n人类语言关键不在于喉咙结构，而在于脑区！ 无\n人类语言演化历程 30w年前有口语（喉头位置推断），17w年前有语法（FOXP2基因），5w年前有壁画，6000年前有文字。\n语言不是人类独有的 无\n布罗卡失语症 表达性失语症 Broca区（按高中来说是S区）负责说话、发音。Broca去病变引起运动性失语症或表达性失语症。阅读、理解、书写不受影响，知道想说什么，但是发音困难。\n韦尼克失语症 感知性失语症 Wernicke区（H区）负责听懂说话。病变时可以正常流利讲话，但是话可能没有意义，并且不能听懂他人讲话。并且自己意识不到自己的问题。也叫听觉性失语症。\n其他失语症：失读症 失写症 命名型失语症 视觉性语言中枢也称阅读中枢（V区）。病变时，不能读懂字，称为失读症。\n书写性语言中枢也称书写中枢（W区）。病变时，写字、绘画等精细运动出现障碍，称为失写症。\n命名型失语症即患者不能说出一个东西的名字，得靠手势描述等方法才能指明手边的物件。\n心理词典 大脑中词汇组织方式 心理词典根据单词间的意义关系组织起来。比如car和truck、bus、taxi关联起来。cat和dog、rabbit、mouse关联起来。\n26.jpg\r不同性质的词汇会被储存在不同的脑区。\n语言对认知的影响 不同语言的母语者对于一些事物的认知有区别。\n自然语言处理的发展历程 NLP-规则时代 机器只能理解规则和逻辑，把语言抽象成规则和逻辑\nNLP-统计模型时代 一个句子是否合理，取决于其出现在自然语言中的可能性\nNLP-DL1代 本质上还是概率模型，用NN计算概率语言模型的参数。这是一个过渡期，使用向量法。\nNLP-DL2代 RNN及类RNN时期。\nNLP-DL3代 使用预训练语言模型（Transformer-GPT/BERT）\n每个人的语言区定位都不同。虽然每个人都有类似的语言区， 但是语言区在大脑的定位都不同。 无\n情感与计算-报偿与成瘾 动机的定义 与 分类 动机是引起个体活动，维持并促使活动朝向某一目标进行的内部动力。\n动机可以分为两类：\n生理动机：为了降低基本生理需求（很奇怪的一句话，难道不是维持吗）。这个动机的行为称为摄取行为，为了维持生理恒定。 奖赏动机：并无非要不可的理由，不符合降低基本需求的条件。这个动机的行为称为欲望行为，为满足奖赏（报偿）动机。 动机激发过程 27.jpg\r动物动机强弱 定义\n动机的强弱可由“获得奖励”的努力去评估。\n在缺乏立即目标的情况下，动物产生奖赏动机，并必须利用过去学习的经验来预测获得奖赏的可能性。可能包含：\n经典条件反射：又称为经典制约。例如巴甫洛夫狗与食物关联。不受意识控制的非自愿行为。 ，目标导向的操作条件反射：又称为操作性制约。这是受意识控制的自愿行为。（强化学习的原理） 测量方法实验\n静脉自身给药模型，脑电击奖赏模型，条件性位置偏爱。\n可卡因剂量实验测量动机大小\n28.jpg\r多巴胺与动机关系\n多巴胺可以引起兴奋、欣快的感觉。\n多巴胺的水平对于“报偿效应”十分关键。\n当人作出某一决策后，如果被证实正确并产生了好的结果，大脑会向负责决策的区域发送“报偿”信号，这会促进人的认知能力进一步提升，形成良性循环，这被称作报偿效应。\n而报偿效应和奖赏动机的关系见前。\n脑电击奖赏模型测量多巴胺与动机关系\n29.jpg\r环境连结实验喜爱程度去评估动机大小\n30.jpg\r更喜爱哪个环境来比较动机大小\n见上\n药品上市之前的实验\n无\n引起兴奋、欣快感觉的脑内物质 有三种: 多巴胺、血清素和内啡肽\n多巴胺报偿途径 有两条，起点都位于中脑，一条成瘾通路，一条与惯性学习、程序性记忆有关\n多巴胺何时释放、设计实验验证 多巴胺在期待奖赏的时候会大量释放。\n多巴胺神经元对奖赏出现反应。\n多巴胺神经元对预测奖赏反应，但对奖赏出现没有反应。\n多巴胺神经元对预测奖赏反应，但对奖赏未出现产生抑制反应。\n多巴胺突出效能调整过程 关于大脑奖赏系统，多巴胺的作用不是实现奖赏，而是奖赏的预期，也就是说某种行为能够导致获得奖赏的期望有多大。\n强化学习的过程就是使得每个行为决策的改进都朝向提高奖赏期望的方向。\n多巴胺强化学习的作用要依赖试错学习过程的记忆，因此海马和杏仁核作用很关键，有短期和长期作用，短期作用依赖于突触间隙中多巴胺浓度的调整，能够短期强化某种行为或者大脑网络，长期作用则依赖突触后神经元受体数量的调整，能够长时间强化某种行为或者大脑网络。两者可以统称为多巴胺突触效能调整。\n成瘾带来痛苦 不是快乐 毒品“绑架”脑中的报赏中枢。\n成瘾性最高的毒品如海洛因，甚至可能打一、两次就会成瘾。成瘾后会产生耐受性，造成需要更大量的药物，才能得到同样的效果，否则就会产生身心双重痛苦。因此大部分人一旦上瘾，不是为了追求快乐，而是为了避免戒掉的痛苦才会继续。\n毒品戒断症状定义 与多巴胺水平的关系 戒断时期，多巴胺急速下降，比药物使用前还低。\n成瘾的正负强化机制 所有的毒品都有两种作用，毒品通过两种作用协同作用引起精神依赖和生理依赖，即正性强化与负性强化。\n正性强化:初期吸毒后可产生强烈的欣快感和松弛宁静感，这种感觉能满足吸毒者的心理需要，产生精神依赖，吸毒者会再次吸毒;\n负性强化:成瘾后，停止吸毒后会产生难以忍受的痛苦，也就是通常所说的“戒断症状”产生身体依赖，吸毒者只得继续追求药物。这两种强化使人成瘾并难以自拔。\n成瘾对脑造成长期性伤害 古柯碱、酒精、鸦片类与安非他命等滥用药物，都会霸占脑部原有的报偿线路。\n重复使用这些药物，会造成脑部化学与构造上的长期变化，因而改变报偿系统神经元处理信息与互动的方式。\n成瘾难以戒除的原因：树突棘、神经结构、多巴胺系统 树突棘增加可放大神经元间的信号，也可能让脑部对引发联想的东西过度反应，或许这便是成瘾难以戒除的关键。\n其他几个见上节。\n烟瘾成瘾过程 尼古丁会刺激抑欲系统，直到其活性会超过欲求系统。大脑迅速产生适应，大幅增强欲求系统的活性，试图恢复平衡。\n尼古丁效应逐渐消退后，抑欲系统不再受到刺激而回到较低的活性状态。但因为受到戒断相关适应的促进作用，欲求系统超越了抑欲系统的活性，因而渴望可以抑欲的事\u0026ndash;再抽一根烟。\n赌瘾和毒瘾没什么区别 都会类似方式重组神经回路 无\n咖啡不会上瘾 只会产生依赖性 致瘾药物必须摄取量逐渐增加才能发挥作用 无\n情感与计算-理性与感性 前额叶 主要功能\n执行具有意义的目标导向行为\n组成部分\n背外侧、腹内侧、眶额回\n每部分的主要功能\n前两部分负责认知处理。眶额回主要和情绪处理相关。\n灵长类生物的前额叶面积更大 无\n前额受损病人心智产生的影响 设计实验 无法抑制自己的行为 无法控制自己的情绪 无法有效的做计划与执行计划 无法有工作记忆 前额叶是有限理性。\n情绪不是什么 关于情绪的说法 情绪与认知关系 不是情景的思考整合。不是推理。当人们情绪激动时，它不能透过称述心中的想法来了解这个情绪。\n刺激→ 激发→ 认知→ 感觉。 情绪刺激的评估理论：情绪是对任何被评为好的有正感觉倾向，对任何被评为不好的有远离感觉倾向，这个评估的历程是潜意识的。刺激→ 评估→ 动作倾向→ 感觉。 感情优先理论。刺激→ 潜意识的感情→ 感觉 情绪和认知是分开的，但相互作用的心智功能，是靠着不同但有互动的大脑系统来媒介运作的\n恐惧情绪 高低通路 解释盲视病人 低通道：丘脑到杏仁核：恐惧感受可以在快速且无意识状态下刺激杏仁核。\n高通道：丘脑到视觉皮层看清晰图像之后，再传回杏仁核。\n模糊图像比清晰图像更让人产生恐惧情绪\n盲视（blindsight）的人看不见物体却能躲避障碍，是因为走了低通道。\n情绪的长短通路 各有什么特点 画图表示 31.jpg\r长通路称为“理性脑”，短通路称为“情绪脑”。\n除了路径长短外：长通路携带信息多，对信息的加工更为精细，需要更长时间。短通路只能携带少量信息，速度很快。\n人脑三位一体 爬行脑 哺乳脑 新脑 见前。\n补充：古脑（爬行脑）是本能脑或者生存脑；旧脑（哺乳脑），主要是边缘系统，是情绪脑；新脑（新皮质，新哺乳动物脑），是视觉脑或智慧脑或理性脑。\n6 种基本情绪、对应脑区 生气（眶额皮质，扣带前回）、快乐（没写）、厌恶（前脑岛，扣带前回）、惊讶（没写）、伤心（杏仁核，右侧颞极）、恐惧（杏仁核）\n杏仁核受伤病人 不知恐惧：分辨表情、画恐惧表情、恐惧制约\n恐惧制约实验 无\n意识记忆与海马 情绪记忆与杏仁核 海马区：情景记忆（意识记忆、情节记忆）\n杏仁核：情绪记忆\n意识记忆和情绪记忆脑机制不同。\n镁光灯记忆 无\n3 岁以内的孩子没有记忆，但有创伤性记忆 无\n情绪与决策 32.jpg\r情绪与心理障碍、焦虑、社会感情 焦虑是来自内心，恐惧是来自外界。\n焦虑是一个不可化解的恐惧。\n罪恶感、羞耻心、嫉妒、困窘、骄傲等，这些与社会行为有关的感情，发展的时间都晚于另一些比较基本的感情像是快乐、恐怖等\n社会感情引领我们的复杂的社会行为，包括渴望帮助他人以及想要惩罚欺骗着，即使需要付出代价也在所不惜\nPTSD 相关脑结构和功能的变化 前扣带回：体积变小，活性降低；认知功能有关；与前额叶构成注意监控系统；检测冲突和可能出现的错误\n内侧前额叶：体积变小，活性降低；认知功能有关；情绪控制密切相关\n杏仁核：过度活跃，经常产生异常情绪反映；恐惧\n海马：体积变小，影响记忆形成\n感情调节方式：分心，重新评估 分心：把注意力转到别的事情上，往往通常是暂时的\n重新评估：借由重新思考某个事件的意义，来改变你对它的感受。擅长重新评估的人，多半情绪比较稳定(EQ较高)。看心理医生能获得的好处，也是因为改善了重新评估的能力，用比较建设性的方式去看事情。\n情感与计算-选择与决策 画图表示选择引起的情绪变化、并解释 33.jpg\r极大化者和满足化者定义 极大化者：做任何决定都寻求最好的结果，不停的在各种选择之间比较，期待找到一个最好的选择 满足化者：只要找到了符合自己标准的东西，就立即停止，不会继续找下去。 选择多失落感越深的原因分析 机会成本\n为了得到某种利益而所要放弃另一些利益的最大价值，被放弃的就是机会成本\n沉没成本\n人们在做出决策时，往往会受到过去的决策和损失的影响，从而导致对当前决策的不满和后悔。\n当人们已经投入了一定的时间、金钱或其他资源，但是最终决策并不理想，这些投入就会成为沉没成本。\n后悔心理\n后悔心理是指当人们面临难以避免的选择时，经常会因为过去的决策而后悔，\n损失规避心理\n失去的痛苦要远大于得到的快感。\n适应心理\n适应现象简单的说是指我们会对事物产生习惯，所以生命中很少会有事物像我们所预期的一样好。\n高期待高失望\n选择障碍的建议 选择何时做选择（限制选择范围） 学习接受“够好了” 错过的就别烦恼 控制你的期待 该用脑袋的哪个部分做决策 34.jpg\r定势效应 及 建议 定势效应：人们在认知活动中习惯用已有的知识经验，来看待当前的问题。也会因为在固定的环境中工作和生活，久而久之形成一种固定的思维模式。也习惯于从固定的角度来观察、思考和接受事物。\n这种认知捷径，有时会忽略更有效或者更适合的方法\n人工与系统 类脑研究的目标 目标是人造超级大脑。\n数值计算为基础的虚拟超级脑和以虚拟脑与生物脑为基础的脑机一体化超级大脑\n为了实现类脑计算系统，从哪些方面理解脑计算？ 明确不同尺度脑信息处理的基本单元 明确脑信息处理的重要原理和过程 揭示脑功能进化的过程和原理 类脑研究存在的挑战 35.jpg\r脑机接口的定义和应用 脑机接口(BCI)，也称作脑机融合技术，就是通过芯片和传感器，用大脑控制各种设备，也可以向大脑反馈触觉信息，再来指导输出，形成一个闭环。对患者或者常人难以企及的应用场景有着重要意义。\n正常人和心理变态罪犯的在处理负性情绪时的活性脑区不一样 无\n人工智能发展所面临的风险并解释 36.jpg\r2019 年两项人工智能伦理原则 八项原则 37.jpg\r","date":"2023-06-11T15:11:44+08:00","permalink":"https://kegalas.top/inferior/%E8%84%91%E7%A7%91%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"脑科学基础学习笔记"},{"content":"集成运算放大器 基本分析方法 一个集成运算放大器的典型形式如下\n1.jpg\r分析它的基本方式是：\n虚短：\\(u_+=u_-\\) 虚断：\\(i_+=i_-=0\\) 以下是集成运算放大器的一些参数：\n\\(u_{id}=u_{i+}-u_{i-}\\)：差模输入电压 \\(A_{uo}\\)：集成运放的开环电压放大倍数 \\(R_i\\)：集成运放的输入电阻 \\(R_o\\)：集成运放的输出电阻 其中理想条件是\\(R_i\\to\\infty,R_o\\to 0,A_{uo}\\to\\infty,i_+=i_-=0\\)。\n电压传输特性 2.jpg\r后记：假设把一个正的电压接到同相输入端，则输出端为正；把一个正的电压接到反相输入端，则输出为负。这个在后面的反馈分析中有用。\n基本运算电路 反向比例运算电路 3.jpg\r（根据虚短虚断）可以计算得到\n\\[u_O = -\\dfrac{R_f}{R}u_I \\]\n其中输出电阻\\(R_o=0\\)，输入电阻\\(R_i=R\\)\n同相比例运算电路 4.jpg\r\\[u_O = (1+\\dfrac{R_f}{R})u_I \\]\n引入了电压串联负反馈，可以认为输入电阻无穷大，输出电阻为\\(0\\)\n电压跟随器 5.jpg\r\\[u_O = u_I \\]\n反向求和运算电路 6.jpg\r\\[u_O = -R_f\\bigg(\\dfrac{u_{I1}}{R_1}+\\dfrac{u_{I2}}{R_2}+\\dfrac{u_{I3}}{R_3}\\bigg) \\]\n可以看作是反相比例放大器的叠加电路，输入电阻取决于不同的端口。\n同相求和运算电路 7.jpg\r\\[u_O = R_f\\cdot\\dfrac{R_P}{R_N}\\cdot \\bigg(\\dfrac{u_{I1}}{R_1}+\\dfrac{u_{I2}}{R_2}+\\dfrac{u_{I3}}{R_3}\\bigg) \\]\n其中，\\(R_P = R_1\\parallel R_2\\parallel R_3\\parallel R_4, R_N = R\\parallel R_f\\)，若\\(R_P=R_N\\)，则\n\\[u_O = R_f\\cdot \\bigg(\\dfrac{u_{I1}}{R_1}+\\dfrac{u_{I2}}{R_2}+\\dfrac{u_{I3}}{R_3}\\bigg) \\]\n加减运算电路 其实就是把上面两个电路结合一下。\n8.jpg\r\\[u_O = R_f\\bigg(\\dfrac{u_{I3}}{R_3}+\\dfrac{u_{I4}}{R_4}-\\dfrac{u_{I1}}{R_1}-\\dfrac{u_{I2}}{R_2}\\bigg) \\]\n要求\\(R_1\\parallel R_2\\parallel R_f=R_3\\parallel R_4\\parallel R_5\\)\n差分比例运算电路 是加减运算电路的一种特例，其只有两个输入，且参数对称\n9.jpg\r\\[u_O = \\dfrac{R_f}{R}(u_{I2}-u_{I1}) \\]\n积分器 10.jpg\r\\[u_O = -\\dfrac{1}{RC}\\int u_Idt \\]\n微分器 11.jpg\r\\[u_O = -RC\\dfrac{du_I}{dt} \\]\n滤波器 滤波器可以分为无源和有源滤波器。如果滤波电路仅由无源元件（电阻、电容、电感）组成，则称为无源滤波电路。如果滤波电路由无源元件和有源元件（双极型管，单极型管、集成运放）共同组成，则称为有源滤波电路。\n我们主要讨论有源滤波器。在分析有源滤波电路时，常常通过拉普拉斯变换将电压、电流、以及无源元件变换为等效电路（具体见信号与系统学习笔记）。输出量与输入量之比称为传递函数，即\n\\[A_u(s) = \\dfrac{U_o(s)}{U_i(s)} \\]\n下面介绍的都是有源滤波电路。\n一阶同相输入低通滤波器 12.jpg\r其传递函数为\n\\[A_u(s)=\\dfrac{U_o(s)}{U_i(s)}=\\bigg(1+\\dfrac{R_2}{R_1}\\bigg)\\dfrac{U_p(s)}{U_i(s)}=\\bigg(1+\\dfrac{R_2}{R_1}\\bigg)\\dfrac{1}{1+sRC} \\]\n用\\(jw\\)取代\\(s\\)，令\\(f_0=\\dfrac{1}{2\\pi RC}\\)，得到\n\\[\\dot{A}_u = \\bigg(1+\\dfrac{R_2}{R_1}\\bigg)\\cdot\\dfrac{1}{1+j\\dfrac{f}{f_0}} \\]\n式中\\(f_0\\)称为特征频率。令\\(f=0\\)，得到通带放大倍数。\n\\[\\dot A_{up}=1+\\dfrac{R_2}{R_1} \\]\n当\\(f=f_0\\)时，\\(\\dot A_u=\\dfrac{\\dot A_{up}}{\\sqrt 2}\\)，故通带截止频率\\(f_p=f_0\\)。\n二阶同相输入低通滤波器 13.jpg\r假设\\(C_1=C_2=C\\)\n\\[A_u(s) = \\bigg(1+\\dfrac{R_2}{R_1}\\bigg)\\dfrac{1}{1+3sRC+(sRC)^2} \\]\n用\\(jw\\)取代\\(s\\)，令\\(f_0=\\dfrac{1}{2\\pi RC}\\)，得到\n\\[\\dot A_u = \\dfrac{1+\\dfrac{R_2}{R_1}}{1-\\bigg(\\dfrac{f}{f_0}\\bigg)^2+j3\\dfrac{f}{f_0}} \\]\n称\\(f_0\\)为特征频率。令上式分母的模等于\\(\\sqrt 2\\)，可以解出通带截止频率为\\(f_p\\approx 0.37f_0\\)。\n一阶反向输入低通滤波器 14.jpg\r通带放大倍数为\n\\[\\dot A_{up} = -\\dfrac{R_2}{R_1} \\]\n电路的传输函数为\n\\[A_u(s) = -\\dfrac{R_2\\parallel\\dfrac{1}{sC}}{R_1}=\\dfrac{R_2}{R_1}\\dfrac{1}{1+sR_2C} \\]\n用\\(jw\\)取代\\(s\\)，令\\(f_0=\\dfrac{1}{2\\pi R_2C}\\)\n\\[\\dot A_u = \\dfrac{\\dot A_{up}}{1+j\\dfrac{f}{f_0}} \\]\n截止频率\\(f_p=f_0\\)\n二阶反向输入低通滤波器 15.jpg\r\\[\\dot A_{up} = -\\dfrac{R_f}{R_1} \\]\n教材上并没有给出\\(\\dot A_u\\)的表达式和截止频率。\n\\[f_0=\\dfrac{1}{2\\pi\\sqrt{C_1C_2R_2R_f}} \\]\n二阶高通滤波器 16.jpg\r\\[\\dot A_{up} = 1+\\dfrac{R_f}{R_1} \\]\n\\[f_p = \\dfrac{1}{2\\pi RC} \\]\n带通滤波器 将低通和高通串联，就得到带通。\n设前者的截止频率为\\(f_{p1}\\)，后者的截止频率为\\(f_{p2}\\)，则\\(f_{p2}\\)应该小于\\(f_{p1}\\)，则通带为\\((f_{p1}-f_{p2})\\)\n17.jpg\r\\[\\dot A_{uf} = 1+\\dfrac{R_f}{R_1} \\]\n当\\(C_1=C_2=C,R_1=R,R_2=2R\\)，令\\(f_0=\\dfrac{1}{2\\pi RC}\\)（中心频率）\n\\[\\dot A_u = \\dfrac{1}{1+j\\dfrac{1}{3-\\dot A_{uf}}\\bigg(\\dfrac{f}{f_0}-\\dfrac{f_0}{f}\\bigg)}\\dfrac{\\dot A_{uf}}{3-\\dot A_{uf}} \\]\n当\\(f=f_0\\)\n\\[\\dot A_{up}=\\dfrac{\\dot A_{uf}}{|3-\\dot A_{uf}|} \\]\n\\[f_{p1} = \\dfrac{f_0}{2}\\bigg(\\sqrt{(3-\\dot A_{uf})^2+4}-(3-\\dot A_{uf})\\bigg) \\]\n\\[f_{p2} = \\dfrac{f_0}{2}\\bigg(\\sqrt{(3-\\dot A_{uf})^2+4}+(3-\\dot A_{uf})\\bigg) \\]\n带阻滤波器 将输入电压同时作用于低通和高通，再将两个电路的输出电压求和，就可以得到带阻滤波器。\\(f_{p1}\u003c f_{p2}\\)，阻带为\\((f_{p2}-f_{p1})\\)\n18.jpg\r\\[\\dot A_{up} = 1+\\dfrac{R_f}{R_1} \\]\n全通滤波器（移相器） 19.jpg\r\\[\\dot A_u = \\dfrac{1-jwRC}{1+jwRC} \\]\n也即\n\\[|\\dot A_u| = 1 \\]\n\\[\\varphi = 180\\degree-2arctan\\dfrac{f}{f_0},f_0=\\dfrac{1}{2\\pi RC} \\]\n滤波器判断 为了避免积分、微分运算，把电路转变为拉普拉斯变换下的等效电路是必要的。\n通过拉普拉斯变换，我们可以更容易地得到输入-输出关系，或者就是求出系统函数（传递函数）。通过系统函数我们可以方便地判断滤波器的类型。\n一阶还是二阶\n传递函数中，分子分母的多项式，如果其中一个最高含有\\(s^2\\)项，则是二阶。如果两个都最高只含\\(s\\)项，就是一阶。\n二阶低通\n传递函数常见为\n\\[H(s) = \\dfrac{H(0)w_0^2}{s^2+\\dfrac{w_0}{Q}s+w_02} \\]\n其零极点图，包含了两个共轭的极点。\n二阶高通\n传递函数常见为\n\\[H(s) = \\dfrac{H(\\infty)s^2}{s^2+\\dfrac{w_0}{Q}s+w_02} \\]\n其零极点图，包含了两个共轭的极点，一个取值为零的二阶零点。\n二阶带通\n传递函数常见为\n\\[H(s) = \\dfrac{H(w_0)\\dfrac{w_0}{Q}s}{s^2+\\dfrac{w_0}{Q}s+w_02} \\]\n其零极点图，包含了一个取值为\\(0\\)的零点，两个共轭极点。\\(Q\\)为品质因数，越大，带宽越窄，选频性能越好。\n二阶带阻\n传递函数常见为\n\\[H(s) = \\dfrac{H(0)(s^2+w_0^2)}{s^2+\\dfrac{w_0}{Q}s+w_02} \\]\n其零极点图，两个零点，两个共轭极点。\\(Q\\)越大，陷波特性越尖锐。这两个零点是共轭的，在\\(jw\\)轴上。\n二阶全通\n传递函数常见为\n\\[H(s) = \\dfrac{H(0)(s^2-\\dfrac{w_0}{Q}s+w_0^2)}{s^2+\\dfrac{w_0}{Q}s+w_02} \\]\n其零极点图，两个共轭零点，两个共轭极点。构成一个矩形。\n一阶\n不知道为什么书上没讲一阶电路判断。但是根据传递函数多少也能看明白。\n半导体器件 半导体基础知识 本征半导体\n纯净的具有晶体结构的半导体称为本征半导体。例如硅和锗的纯净半导体。\n本征半导体中，共价键的价电子可以获得足够大的能量，挣脱共价键的束缚，游离出去，成为自由电子，并在共价键处留下带有一个单位的正电荷的空穴。这个过程称为本征激发。\n本征激发产生成对的自由电子和空穴，所以本征半导体中自由电子和空穴的数量相等。\n价电子的反向递补运动等价为空穴在半导体中自由移动。因此，在本征激发的作用下，本征半导体中出现了带负电的自由电子和带正电的空穴，二者都可以参与导电，统称为载流子。\n杂质半导体\n往本征半导体里掺入少量合适的杂质元素，便可得到杂质半导体。按掺入的杂质元素不同，可以分成N型半导体和P型半导体。\nN型半导体\n在本征半导体中掺入五价原子，即构成N型半导体。N型半导体中每掺杂一个杂质元素的原子，就提供一个自由电子，从而大量增加了自由电子的浓度。\nN型半导体中，自由电子的浓度大于空穴的浓度，故称自由电子为多数载流子，空穴为少数载流子，前者也称为多子，后者也称为少子，由于杂质原子可以提供电子，故称为施主原子。\nP型半导体\n在本征半导体中掺入三价原子，即构成P型半导体。P型半导体中每掺杂一个杂质元素的原子，就提供一个空穴，从而大量增加了空穴的浓度。\nP型半导体中，空穴为多子，自由电子为少子，主要靠空穴导电。因杂质原子中的空位吸收电子，故称之为受主原子。\n漂移电流和扩散电流\n漂移电流：在电场的作用下，自由电子会逆着电场方向漂移，而空穴则顺着电场方向漂移，这样产生的电流称为漂移电流，该电流的大小主要取决于载流子的浓度，迁移率和电场强度。\n扩散电流：半导体中载流子浓度不均匀分布时，载流子会从高浓度区向低浓度区扩散，从而形成扩散电流，该电流的大小正比于载流子的浓度差即浓度梯度的大小。\nPN结\n通过掺杂工艺，把本征半导体的一边做成 P 型半导体，另一边做成 N 型半导体，则 P 型半导体和 N 型半导体的交接面处会形成一个有特殊物理性质的薄层，称为 PN 结。\n在无外电场和其他激发作用下，参与扩散运动的多子数目等于参与漂移运动的少子数目，从而达到动态平衡，形成PN结。\n由于扩散到P区的自由电子与空穴复合，而扩散到N区的空穴与自由电子复合，所以在交界面附近多子的浓度下降，P区出现负离子区，N区出现正离子区，它们是不能移动的，称为空间电荷区（耗尽层），从而形成内电场。\n当外加电压极性不同时，PN结表现出截然不同的导电性能。\n当电源的正极接到PN结的P端，且电源的负极接到PN结的N端时，称PN结外加正向电压，也称正向接法或正向偏置。此时空间电荷区变窄，削弱内电场，使扩散运动加剧，漂移运动减弱。由于电源的作用，扩散运动将源源不断地进行，从而形成正向电流，PN结导通。\n当电源的正极接到PN结的N端，且电源的负极接到PN结的P端时，称PN结外加反向电压，也称反向接法或反向偏置。加强了内电场，阻止扩散运动，加剧漂移运动。但是少子数目极少，反向电流非常小，所以常常忽略不计，认为PN结外加反向电压时处于截止状态。\nPN结的电流方程\nPN结所加端电压\\(u\\)与流过它的电流\\(i\\)的关系为\n\\[i = I_S(e^{\\frac{qu}{kT}}-1) \\]\n其中\\(I_S\\)为反向饱和电流，\\(q\\)为电子的电量，\\(k\\)为玻尔兹曼常数，\\(T\\)为热力学温度，将\\(kT/q\\)用\\(U_T\\)取得，得到\n\\[i = I_S(e^{u/U_T}-1) \\]\n常温下，即\\(T=300K\\)时，\\(U_T\\approx26\\text{mV}\\)，称\\(U_T\\)为温度的电压当量。\nPN结的伏安特性、击穿特性\n当施加正向电压，且\\(u\u003e\u003eU_T\\)时，\\(i\\approx I_Se^{u/U_T}\\)，即指数变化。反向电压时，当\\(|u|\u003e\u003eU_T\\)，\\(i\\approx -I_S\\)。画出图如下\n20.jpg\r\\(u\u003e0\\)时为正向特性，\\(u\u003c0\\)时为反向特性。\n当反向电压超过一定数值\\(U_{(BR)}\\)后，反向电流急剧增加，称之为反向击穿。击穿可以分为齐纳击穿和雪崩击穿。\n在高掺杂的情况下，因为耗尽层的宽度很窄，不大的反向电压就可以在耗尽层形成很强的电场，从而直接破坏共价键，使价电子脱离共价键束缚，产生电子-空穴对，致使电流急剧加大，这种击穿称为齐纳击穿。齐纳击穿电压较低。\n如果掺杂浓度低，耗尽层宽度较宽，那么低反向电压下不会产生齐纳击穿。当反向电压较大，耗尽层的电场使少子加快漂移速度，从而与共价键中的价电子相碰撞，把价电子撞出共价键，产生电子-空穴对。新产生的电子与空穴被电场加速后又撞出其他价电子，载流子雪崩式地倍增，致使电流急剧增加，称为雪崩击穿。\nPN结的电容特性\n一定条件下，PN结具有电容效应，根据产生的原因不同分为势垒电容\\(C_b\\)和扩散电容\\(C_d\\)\nPN结的结电容\\(C_j=C_b+C_d\\)\n一般两个电容都很小，对于低频信号呈现出很大的容抗，可以忽略不计。只有在信号频率较高时才考虑结电容的作用。\n二极管 将PN结用外壳封装起来加上电极引线就构成了半导体二极管，简称二极管。P区的电极称为阳极，N区的称为阴极。\n二极管的伏安特性 和PN结差不多，但是由于二极管存在半导体体电阻和引线电阻，所以当外加正向电压时，在电流相同的情况下，二极管的端电压大于PN结上的压降。并且二极管表面有漏电流，在外加反向电压时反向电流增大。\n21.jpg\r实测发现，只有当正向电压足够大的时候，正向电流才指数增长。使得二极管开始导通的临界电压称为开启电压\\(U_{on}\\)。施加反向电压足够大的反向电流为\\(I_S\\)，太大则会击穿。\n硅管的典型导通电压为\\(0.7V\\)，锗管的典型导通电压为\\(0.2V\\)。\n二极管的特性对温度很敏感。\n二极管的等效电路 22.jpg\r等效电路是理想二极管串联电压源\\(U_{on}\\)和电阻\\(r_D\\)，且\\(r_D=\\Delta U/\\Delta I\\)\n在做题算直流电阻的时候，直接把某个点的电压除以电流即可。算交流电阻时，用\\(U_T\\)除以该点的电流即可。\n稳压二极管 稳压管在反向击穿时，在一定的电流范围内，端电压几乎不变，表现出稳压特性。\n23.jpg\r稳定电压\\(U_Z\\)是在规定电流下稳压管的反向击穿电压。 稳定电流\\(I_Z(I_{Zmin})\\)是稳压管工作在稳压状态时的参考电流。 最大稳定电流\\(I_{ZM}(I_{Zmax})\\)，电流超过这个值时，功耗会过大，超过额定功耗\\(P_{ZM}\\)，可能烧坏PN结。 二极管应用电路 整流电路\n24.jpg\r限幅电路\n25.jpg\r电平选择电路\n26.jpg\r晶体三极管 基本类型 27.jpg\rNPN型三极管如上。\n28.jpg\rPNP型三极管如上。\n使晶体管工作在放大状态的外部条件是，发射结正偏且集电结反偏。NPN型，就是\\(U_{be}\u003eU_{on}\\)，并且\\(U_{bc}\u003c0\\)。\\(PNP\\)型就是\\(U_{be}\u003c-U_{on}\\)且\\(U_{bc}\u003e0\\)。\n晶体管的放大作用体现在小的基极电流可以控制大的集电极电流。\n内部载流子运动与外部电流 以NPN型为例\n29.jpg\r内部看\n\\[I_E = I_{EN}+I_{EP}=I_{CN}+I_{BN}+I_{EP} \\]\n\\[I_C=I_{CN}+I_{CBO} \\]\n\\[I_B = I_{BN}+I_{EP}-I_{CBO} = I'_B-I_{CBO} \\]\n从外部看\n\\[I_E = I_C+I_B \\]\n注意从外部看PNP型的方程一样，但是三个电流方向都相反。\n共发射极放大倍数\n\\[\\bar\\beta = \\dfrac{I_{CN}}{I'_B}=\\dfrac{I_C-I_{CBO}}{I_B+I_{CBO}} \\]\n一般情况下\\(I_B\u003e\u003eI_{CBO},\\bar\\beta\u003e\u003e1\\)，所以\n\\[I_C\\approx\\bar\\beta I_B,\\quad I_E\\approx(1+\\bar\\beta)I_B \\]\n如果输入电压是动态电压，则\n\\[\\beta = \\dfrac{\\Delta i_C}{\\Delta i_B} \\]\n在\\(|\\Delta i_B|\\)不太大时，可以认为\\(\\beta\\approx\\bar\\beta\\)\n共基极直流放大倍数\n\\[\\bar\\alpha = \\dfrac{I_{CN}}{I_E} \\]\n同样一般有\n\\[I_C\\approx \\bar\\alpha I_E \\]\n我们可以得到关系式\n\\[\\bar\\beta = \\dfrac{\\bar\\alpha}{1-\\bar\\alpha},\\quad\\bar\\alpha=\\dfrac{\\bar\\beta}{1+\\bar\\beta} \\]\n同样\n\\[\\alpha = \\dfrac{\\Delta i_C}{\\Delta i_E} = \\dfrac{\\beta}{1+\\beta} \\]\n通常\\(\\beta\u003e\u003e1\\)，故\\(\\alpha\\approx1\\)；而且与\\(\\beta\\approx\\bar\\beta\\)相同，\\(\\alpha\\approx\\bar\\alpha\\)\n这两个放大倍数在NPN和PNP型处于放大区都可以用，注意电流方向即可。\n共射特性曲线 输入特性曲线\n输入特性曲线描述在管降压\\(U_{CE}\\)一定的情况下，基极电流\\(i_B\\)与发射结降压\\(U_{BE}\\)之间的函数关系，即\n\\[i_B = f(U_{BE})\\bigg|_{U_{CE}=常数} \\]\n30.jpg\r输出特性曲线\n输出特性曲线描述基极电流\\(I_B\\)为一常量时，集电极电流\\(i_C\\)与管降压\\(U_{CE}\\)之间的函数关系，即\n\\[i_C = f(U_{CE})\\bigg|_{I_B=常数} \\]\n31.jpg\r截止区\n其特征是发射结电压小于开启电压且集电结反向偏置。对于共射电路，\\(u_{BE}\\leq U_{on}\\)且\\(u_{CE}\u003eu_{BE}\\)。此时\\(I_B=0\\)，近似认为\\(i_c\\approx0\\)\n放大区\n其特征是发射结电压正向偏置且集电结反向偏置。对于共射电路，\\(u_{BE}\u003eU_{on}\\)且\\(u_{CE}\\geq u_{BE}\\)。此时\\(i_C\\)几乎仅仅决定于\\(i_B\\)，而与\\(u_{CE}\\)无关。\\(I_C=\\bar\\beta I_B, \\Delta i_C=\\beta\\Delta i_B\\)\n饱和区\n其特征是发射极与集电极均正向偏置。对于共射电路，\\(u_{BE}\u003eU_{on}\\)且\\(u_{CE} \u003c u_{BE}\\)。此时\\(i_C\\)不仅与\\(i_B\\)有关，而且明显随\\(u_{CE}\\)增大而增大，\\(i_C\\)小于\\(\\bar\\beta I_B\\)。此时\\(u_{CE}=U_{CE(sat)}\\)，通常为\\(0.2\\sim 0.3\\text{V}\\)\n放大电路的分析方法 放大的主要性能指标 放大倍数\n电压放大倍数\\(\\dot A_{uu}=\\dot A_{u}=\\dfrac{\\dot U_o}{\\dot U_i}\\)\n电流放大倍数\\(\\dot A_{ii}=\\dot A_{i}=\\dfrac{\\dot I_o}{\\dot I_i}\\)\n互阻放大倍数\\(\\dot A_{ui}=\\dfrac{\\dot U_o}{\\dot I_i}\\)\n互导放大倍数\\(\\dot A_{ui}=\\dfrac{\\dot I_o}{\\dot U_i}\\)\n输入电阻\n\\[R_i = \\dfrac{U_i}{I_i} \\]\n输入电阻与信号源内阻无关。\n输出电阻\n\\[R_o = \\bigg(\\dfrac{U_o'}{U_o}-1\\bigg)R_L \\]\n其中\\(U_o'\\)为空载时输出电压的有效值，\\(U_o\\)为带负载后输出电压的有效值，\\(R_L\\)为负载电阻。但是，这个只是计算方法，输出电阻与负载无关。\n静态工作点 以共射放大电路为例。\n33.jpg\r当\\(u_i=0\\)时，称放大电路处于静态。\\(V_{BB}\\)使得\\(U_{BE}\u003eU_{on}\\)并且与\\(R_b\\)共同决定\\(I_B\\)，\\(V_{CC}\\)应该足够高，使得集电极反向偏置，从而保持在放大状态，此时\\(I_C=\\beta I_B\\)，并确定了\\(U_{CE}=V_{CC}-I_CR_c\\)\n图中的输入回路和输出回路以发射极为公共端，故称为共射放大电路。\n输入信号为零，直流电源单独作用时晶体管的\\(I_{B},I_{C},U_{BE},U_{CE}\\)称为放大电路的静态工作点\\(Q\\)，常记作\\(I_{BQ},I_{CQ},U_{BEQ},U_{CEQ}\\)，通常认为\\(U_{BEQ}\\)为已知量，硅管为\\(0.7V\\)，锗管为\\(0.2V\\)，并且认为\\(\\bar\\beta=\\beta\\)\n令\\(\\dot U_i=0\\)，从上面的电路可以解出\n\\[\\left\\{\\begin{matrix} I_{BQ}=\\dfrac{V_{BB}-U_{BEQ}}{R_b} \\\\ I_{CQ}=\\bar\\beta I_{BQ}=\\beta I_{BQ} \\\\ U_{CEQ} = V_{CC}-I_{CQ}R_c \\end{matrix}\\right. \\]\n直流通路与交流通路 32.jpg\r直流通路是在直流电源作用下直流电流流经的通路, 也就是静态电流流经的通路,用于研究静态工作点。对于直流通路,\n电容视为开路; 电感线圈视为短路(即忽略线圈电阻); 信号源视为短路,但应保留其内阻。 交流通路是输入信号作用下交流信号流经的通路, 用于研究动态参数。对于交流通路,\n容量大的电容(如耦合电容)视为短路, 无内阻的直流电源(如\\(V_{CC}\\))视为短路。 三极管等效电路 晶体管等效（在做题中几乎无用）\n34.jpg\r直流模型是在静态工作时的模型。必须在放大区才可以使用，并且要求\\(\\beta=\\bar\\beta\\)\n交流小信号模型（在做题中，注意\\(r_{be}\\)是怎么求的）\n35.jpg\r忽略\\(r_{bc}\\)的影响后，\n36.jpg\r\\[r_{be} = r_{bb'}+(1+\\beta)\\dfrac{U_T}{I_{CQ}} \\]\n\\[g_mU_{b'e}=\\beta I_b \\]\n这里的\\(r_{bb'}\\)是基区体电阻，\\(r_{b'e}\\)是发射结电阻。部分题目会用到来求\\(r_{be}\\)。\\(r_{bb'}\\)一般在几十到几百欧，题目没说就取\\(200\\)欧。\nh参数等效模型（最主要用这个分析题目）\n37.jpg\r这是静态工作点一节中的电路的等效。\\(r_{ce}\\)和\\(R_c\\)并联，它很大，可以忽略。\n可以计算\n\\[\\dot A_u = \\dfrac{\\dot U_o}{\\dot U_i} = -\\dfrac{\\beta R_c}{R_b+r_{be}} \\]\n\\[R_i = R_b+r_{be} \\]\n\\[R_o = R_c \\]\n特别指出，放大电路的输入电阻与信号源内阻无关，输出电阻与负载无关。\n这个等效电路可以用来分析交流情况。\n图解法 静态工作点的分析 38.jpg\r如图，当\\(\\Delta u_I=0\\)时，静态工作点既应在晶体管的输入特性曲线上，又应满足\n\\[u_{BE}=V_{BB}-i_BR_b \\]\n在输出回路中，静态工作点既应在\\(I_B=I_{BQ}\\)的那条输出特性曲线上，又应满足外电路的回路方程\n\\[u_{CE} = V_{CC}-i_CR_c \\]\n39.jpg\r于是我们就可以从图中读出静态工作点的数据。如果\\(I_B=I_{BQ}\\)的那条曲线没有，则应当补测。\n电压放大倍数的分析 40.jpg\r\\[u_{BE}=V_{BB}+\\Delta u_I-i_BR_b \\]\n\\[A_u = \\dfrac{\\Delta u_{CE}}{\\Delta u_I} = \\dfrac{\\Delta u_O}{\\Delta u_I} \\]\n波形非线性失真的分析 假设静态工作点设置合适并且信号输入幅值较小，则可以正常工作，如下\n41.jpg\r如果\\(Q\\)点过低，输入信号负半周期峰值的某段时间内，晶体管b-e间电压总量小于开启电压，晶体管截止。因此基极电流\\(i_b\\)将产生底部失真，最后导致\\(u_O\\)顶部失真。这种情况叫做截止失真。解决办法是加大\\(V_{BB}\\)\n42.jpg\r如果\\(Q\\)点过高，虽然\\(i_B\\)本身不失真，但是在输出回路中，\\(i_B\\)的正半周期可能会进入饱和区，导致了\\(i_c\\)产生顶部失真，最后导致\\(u_O\\)底部失真。这种情况叫做饱和失真。解决办法是增大\\(R_b\\)而减小\\(I_{BQ}\\)，从而减小\\(I_{CQ}\\)；也可以减小\\(R_c\\)，从而增大\\(U_{CEQ}\\)；或者更换一只\\(\\beta\\)较小的管子，以便在\\(I_{BQ}\\)相同的情况下减小\\(I_{CQ}\\)\n43.jpg\r计算最大不失真参数\n如果将晶体管理想化，即认为在管压降总量\\(u_{CE}\\)最小值大于饱和管压降\\(U_{CES}\\)（即管子不饱和），且基极电流总量\\(i_{B}\\)大于\\(0\\)（即管子不截止）的情况下，非线性失真可以忽略不计，那么就可以得出放大电路的最大不失真电压\\(U_{om}\\)\n从图2.3.7(b)可以计算，其方法是以\\(U_{CEQ}\\)为中心，取\\(V_{CC}-U_{CEQ}\\)和\\(V_{CEQ}-U_{CES}\\)这两段距离中较小的数值，并除以\\(\\sqrt{2}\\)，则得到其有效值\\(U_{om}\\)\n为了使\\(U_{om}\\)尽可能大，应该将\\(Q\\)点放置在放大区内负载线的终点，即横坐标\\(\\dfrac{V_{CC}+U_{CES}}{2}\\)的位置，此时的\\(U_{om}=\\dfrac{V_{CC}-U_{CEQ}}{\\sqrt{2}}\\)\n或者你需要计算其他电路中的参数，按照此时的设置，\\(U_{CEQ}=\\dfrac{V_{CC}+U_{CES}}{2}\\)，用这个东西去计算\\(I_{CQ},I_{BQ},I_{EQ}\\)等等都是可以的。\n直流、交流负载线 直流通路所确定的负载线\\(u_{CE}=V_{CC}-i_CR_c\\)称为直流负载线，而动态信号遵循的负载线称为交流负载线。\n70.jpg\r交流负载线有两个特点\n输入电压为零时，其实就是静态工作点，所以负载线必过\\(Q\\)点 由于集电极电流\\(i_c\\)仅取决于基极动态电流\\(i_b\\)，而动态管压降\\(u_{ce}\\)等于\\(i_c\\)与\\(R_{c}\\parallel R_L\\)之积，所以它的斜率为\\(-1/(R_c\\parallel R_L)\\) 但其实也不一定要找出斜率。我们可以再找一个不同于\\(Q\\)的点即可。\n三极管的三种接法 共射 之前的例子都是共射电路，其特征是发射极为输出回路与输入回路的公共端（这个画出交流通路比较好判断，不要在原来的电路上判断）。\n静态工作点、放大倍数、输入输出阻抗见前。\n共集 即输出输入回路（交流通路上）以集电极为公共端。\n44.jpg\r\\[\\left\\{\\begin{matrix} I_{BQ}=\\dfrac{V_{BB}-U_{BEQ}}{R_b+(1+\\beta)R_e} \\\\ I_{EQ}=(1+\\beta)I_{BQ} \\\\ U_{CEQ} = V_{CC}-I_{EQ}R_e \\end{matrix}\\right. \\]\n\\[\\dot A_u = \\dfrac{(1+\\beta)R_e}{R_b+r_{be}+(1+\\beta)R_e} \\]\n显然\\(\\dot A_u\\)在\\(0\\)到\\(1\\)之间，输入输出同向，输出小于输入。当\\((1+\\beta)R_e\u003e\u003eR_b+r_{be}\\)时，\\(\\dot A_u\\approx 1\\)，即\\(\\dot U_o\\approx\\dot U_i\\)，故常称共集放大电路为射极跟随器。虽然电路没有电压放大能力但是输出电流\\(I_e\\)远大于输入电流\\(I_b\\)，仍有功率放大作用。\n45.jpg\r\\[R_i = R_b+r_{be}+(1+\\beta)R_e \\]\n\\[R_o = R_e\\parallel\\dfrac{R_b+r_{be}}{1+\\beta} \\]\n共基 即输出输入回路（交流通路上）以基极为公共端。\n46.jpg\r\\[\\left\\{\\begin{matrix} I_{EQ}=\\dfrac{V_{BB}-U_{BEQ}}{R_e} \\\\ I_{BQ}=\\dfrac{I_{EQ}}{1+\\beta} \\\\ U_{CEQ} = U_{CQ}-U_{EQ}=V_{CC}-I_{CQ}R_c+U_{BEQ} \\end{matrix}\\right. \\]\n\\[\\dot A_u = \\dfrac{\\beta R_c}{r_{be}+(1+\\beta)R_e} \\]\n\\[R_i=R_e+\\dfrac{r_{be}}{1+\\beta} \\]\n\\[R_o=R_c \\]\n由于共基电路的输入回路电流为\\(i_E\\)，而输出回路电流为\\(i_C\\)，所以无电流放大能力。但有足够的电压放大能力，从而实现功率放大。此外输入电压和输出电压同相。\n三种接法的比较 共射电路既能放大电流又能放大电压，输入电阻居三种电路之中，输出电阻较大,频带较窄。常作为低频电压放大电路的单元电路。 共集电路只能放大电流不能放大电压，是三种接法中输入电阻最大、输出电阻最小的电路，并具有电压跟随的特点。常用于电压放大电路的输入级和输出级，在功率放大电路中也常采用射极输出的形式。 共基电路只能放大电压不能放大电流，具有电流跟随的特点；输人电阻小，电压放大倍数、输出电阻与共射电路相当，是三种接法中高频特性最好的电路。常作为宽频带放大电路。 集成运放的内部电路 多级放大电路的一般问题 耦合方式 直接耦合\n将前一级的输出端直接连接到后一级的输入端。\n采用直接耦合方式使各级之间的直流通路相连，因静态工作点相互影响，这样就给电路的分析、设计和调试带来困难。计算静态工作点和放大倍数都要考虑前后级的影响。最大的问题是存在零点漂移现象。\n优点是具有良好的低频特性，可以放大变化缓慢的信号。由于没有大电容，易于集成在一片硅片上，构成集成放大电路。\n阻容耦合\n前级输出端通过电容接到后级输入端。\n阻容耦合的电路各级之间的直流通路各不相通，静态工作点相互独立，在求解和调试\\(Q\\)点时可以按单级处理。而且，只要输入信号频率较高，耦合电容容量较大，前级的输出就可以几乎无损地传递到后级。\n缺点是低频特性差，不能放大缓慢变化的信号。以及不便于集成化。所以一般只有频率高、输出功率大等情况下才会采用阻容耦合。\n变压器耦合\n前级输出端通过变压器接到后级输入端或负载电阻上。\n静态工作点相互独立，在求解和调试\\(Q\\)点时可以按单级处理。\n低频特性差，不能放大缓慢的信号。比阻容耦合还不能集成化。\n但其最大的特点是可以实现阻抗变换。\n光电耦合\n以光信号为媒介来实现电信号的耦合和传递，通过将发光二极管与光电三极管相互绝缘地组合在一起来实现。\n书上没有提到优缺点\n多级放大电路的动态分析 无论什么耦合，放大电路中前级的输出电压就是后级的输入电压，即\\(\\dot U_{o1}=\\dot U_{i2},\\dot U_{o2}=\\dot U_{i3},\\cdots,\\dot U_{o(N-1)}=\\dot U_{iN}\\)\n所以总体的放大倍数为\n\\[\\dot A_u = \\dfrac{\\dot U_{o1}}{\\dot U_i}\\cdot\\dfrac{\\dot U_{o2}}{\\dot U_i2}\\cdot\\cdots\\cdot\\dfrac{\\dot U_{o}}{\\dot U_{iN}}=\\dot A_{u1}\\cdot\\dot A_{u2}\\cdot\\dots\\cdot\\dot A_{uN} = \\prod^{N}_{j=1}\\dot A_{uj} \\]\n输入电阻就是第一级的输入电阻，输出电阻就是最后一级的输出电阻。\n\\[R_i = R_{i1}, R_o = R_{oN} \\]\n注意，当共集放大电路作为输入级时，它的输入电阻与其负载，即与第二级的输入电阻有关；共集放大电路作为输出级时，它的输出电阻与其信号源内阻，即倒数第二级的输出电阻有关。\n差分放大电路 共模信号：大小相等、极性相同的输入信号。\n差模信号：大小相等、极性相反的输入信号。\n差分放大电路对于共模信号有很强的抑制作用（不仅因为其电路参数对称，还因为其反馈作用），所以能克服零点漂移的问题。\n47.jpg\r由于输入的是差模信号，电路参数对称，集电极电位的变化也是大小相等且方向相反的，即\\(\\Delta u_{c1}=-\\Delta u_{c2}\\)，所以输出电压为\\(\\Delta u_o=\\Delta u_{c1}-\\Delta u_{c2}=2\\Delta u_{c1}\\)，从而实现了电压放大。\n显然的，在差模信号作用下，\\(R_e\\)中的电流变化为零，即\\(R_e\\)对差模信号没有反馈作用，相当于短路。而\\(R_e\\)对共模信号有负反馈作用，可以抑制零点漂移。\n长尾式差分放大电路 48.jpg\r如图，\\(R_e\\)接到一个\\(-V_{EE}\\)上，故称长尾式电路。参数理想对称，即\\(R_{b1}=R_{b2}=R_b,R_{e1}=R_{e2}=R_e\\)；\\(T_1\\)与\\(T_2\\)的特性相同，\\(\\beta_1=\\beta_2=\\beta,r_{be1}=r_{be2}=r_{be}\\)\n静态分析\n当\\(u_{I1}=u_{I2}=0\\)时，\n\\[I_{R_e} = I_{EQ1} + I_{EQ2} = 2I_{EQ} \\]\n根据基极回路方程\n\\[I_{BQ}R_b + U_{BEQ} + 2I_{EQ}R_e = V_{EE} \\]\n可以求出\\(I_{BQ}\\)或\\(I_{EQ}\\)从而解出静态工作点。通常，由于\\(R_b\\)很小，很多情况下\\(R_b\\)就是信号源内阻，而且\\(I_{BQ}\\)也很小，所以\\(R_b\\)上的电压可忽略不计，从而\\(U_{EQ}\\approx-U_{BEQ}\\)，因而\n\\[I_{EQ}\\approx\\dfrac{V_{EE}-U_{BEQ}}{2R_e} \\]\n\\[I_{BQ} = \\dfrac{I_{EQ}}{1+\\beta} \\]\n\\[U_{CEQ} = U_{CQ}-U_{EQ}\\approx V_{CC}-I_{CQ}R_c+U_{BEQ} \\]\n由于\\(U_{CQ1}=U_{CQ2}\\)，所以\\(u_O=U_{CQ1}-U_{CQ2}=0\\)\n对共模信号的抑制作用\n之前提到过由于参数对称，输入共模信号时集电极的电压也是共模的，从而输出电压为零。\n除此之外还有负反馈作用，见下图\n49.jpg\r\\(R_e\\)越大，负反馈作用越强。但也不宜过大，应该受到\\(V_{EE}\\)的限制，以防止\\(I_{EQ}\\)过小。为了描述对共模信号的抑制能力，引入共模放大倍数\\(A_c\\)\n\\[A_c = \\dfrac{\\Delta u_{Oc}}{\\Delta u_{Ic}} \\]\n理想情况下\\(A_c = 0\\)\n对差模信号的放大作用\n当给差分放大电路输入一个差模信号\\(\\Delta u_{Id}\\)时，由于电路参数的对称性，\\(\\Delta u_{Id}\\)经分压后，加在\\(T_1\\)管一边的为\\(+\\Delta u_{Id}/2\\)，加在\\(T_2\\)管一边的为\\(-\\Delta u_{Id}/2\\)\n50.jpg\r\\(E\\)点在差模信号下电位不变，相当于接地。负载电阻的中点电位在差模信号的作用下电位也不变，相当于接地。交流等效通路如图。\n差模放大倍数为\n\\[A_d = \\dfrac{\\Delta u_{Od}}{\\Delta u_{Id}} \\]\n由交流等效电路可得\\(\\Delta u_{Id}=2\\Delta i_{B1}(R_b+r_{be}),\\Delta u_{Od}=-2\\Delta i_{C1}\\bigg(R_c\\parallel\\dfrac{R_L}{2}\\bigg)\\)，所以\n\\[A_d = -\\dfrac{\\beta\\bigg(R_c\\parallel\\dfrac{R_L}{2}\\bigg)}{R_b+r_{be}} \\]\n可见，用了两只晶体管，放大能力只相当于一只晶体管，牺牲了一只管子为代价换来了低温漂的效果。\n从等效电路也可以看出\n\\[R_i = 2(R_b+r_{be}) \\]\n\\[R_o = 2R_c \\]\n为了综合考察对差模信号的放大能力和对共模信号的抑制能力，引入共模抑制比\n\\[K_{CMR} = \\bigg|\\dfrac{A_d}{A_c}\\bigg| \\]\n理想情况下\\(K_{CMR}=\\infty\\)\n当然这些输入输出电阻、差模放大倍数等东西，都是从这个图中推出来的，如果某个题中的电路没有某个电阻什么的，要自己学会用这个方法推断。\n四种接法 双入双出\n之前介绍的叫做双入双出接法。\n双入单出\n51.jpg\r其中右边的直流通路是用戴维南定理来算的，有\n\\[V'_{CC} = \\dfrac{R_L}{R_c+R_L}\\cdot V_{CC} \\]\n\\[R'_c = R_c\\parallel R_L \\]\n现在输出回路不对称了，\\(T_1\\)管和\\(T_2\\)管的集电极电位\\(U_{CQ1}\\neq U_{CQ2}\\)，从而\\(U_{CEQ1}\\neq U_{CEQ2}\\)。由图可得\n\\[U_{CQ1} = V'_{CC}-I_{CQ}R'_c \\]\n\\[U_{CQ2} = V_{CC}-I_{CQ}R_c \\]\n静态工作点和之前的计算方法一致。\n在差模信号作用时，负载电阻只取得\\(T_1\\)管集电极电位的变化量，所以与双出电路相比，差模放大倍数的数值减小。画出等效电路如下，\n52.jpg\r易计算输出电压为\\(\\Delta u_{Od}=-\\Delta i_C(R_c\\parallel R_L)\\)，输入电压为\\(\\Delta u_{Id}=2\\Delta i_b(R_b+r_{be})\\)\n差模放大倍数变为\n\\[A_d = \\dfrac{\\Delta u_{Od}}{\\Delta u_{Id}} = -\\dfrac{1}{2}\\cdot\\dfrac{\\beta(R_c\\parallel R_L)}{R_b+r_{be}} \\]\n输入电阻仍然为\\(R_i=2(R_b+r_{be})\\)，输出电阻为\\(R_o=R_c\\)，是双端输出电路的一半。\n分析\\(A_c\\)时，输入共模电压，我们注意到\\(\\Delta i_{Re} = 2\\Delta i_E,\\Delta u_e = 2\\Delta i_ER_e\\)，对于每只管子，可以认为是\\(\\Delta i_E\\)流过阻值为\\(2R_e\\)的电阻造成的，如下\n55.jpg\r可以计算得到\n\\[A_c = \\dfrac{\\Delta u_{Oc}}{\\Delta u_{Ic}} = -\\dfrac{\\beta(R_c\\parallel R_L)}{R_b+r_{be}+2(1+\\beta)R_e} \\]\n\\[K_{CMR} = \\bigg|\\dfrac{A_d}{A_c}\\bigg| = \\dfrac{R_b+r_{be}+2(1+\\beta)R_e}{2(R_b+r_{be})} \\]\n增大\\(R_e\\)，\\(K_{CMR}\\)越大，电路性能越好。\n单入双出\n53.jpg\r这个也叫做射极耦合电路，因为\\(T_2\\)管的信号是从\\(T_1\\)管传来的。\n将电路等效为右边，如果\\(A_c\\)不等于零，则输出电压不仅有差模信号产生的，还有共模信号产生的。\n\\[\\Delta u_{O} = A_d\\Delta u_I + A_c\\cdot\\dfrac{\\Delta u_I}{2} \\]\n当然理想状况下\\(A_c=0\\)。单入双出和双入双出分析完全一样，不再介绍。\n单入单出\n54.jpg\r对于单出电路，常把不输出信号一边的\\(R_c\\)省掉。对\\(Q\\)点、\\(A_d\\)、\\(A_c\\)、\\(R_i\\)、\\(R_o\\)的分析和双入单出一样，对于输入信号作用的分析和单入双出一样。\n总结\n四种解法的特点：\n输入电阻均为\\(2(R_b+r_{be})\\) \\(A_d,A_c,R_o\\)与输出方式有关，双端输出时，\\(A_d\\)见前，\\(A_c=0,R_o=2R_c\\)；单端输出时\\(A_d,A_c\\)见前，\\(R_o=R_c\\) 单端输入时，差模信号输入的同时总伴随着共模输入。若输入信号为\\(\\Delta u_I\\)，则\\(\\Delta u_{Id}=\\Delta u_{I},\\Delta u_{Ic}=+\\Delta u_{I}/2\\)，输出电压表达式见前。 改进型差分放大电路 在差分放大电路中，提高\\(R_e\\)能抑制温漂，提高共模抑制比。\n我们可以利用工作点稳定电路来取代\\(R_e\\)，得到下图的恒流源差分放大电路\n56.jpg\r电源\\(V_{EE}\\)可取几伏，电路参数应满足\\(I_2\u003e\u003eI_{B3}\\)。这样\\(I_1\\approx I_2\\)，所以\\(R_2\\)上的电压为\n\\[U_{R2}\\approx\\dfrac{R_2}{R_1+R_2}\\cdot V_{EE} \\]\n\\[I_{C3}\\approx I_{E3} = \\dfrac{U_{R2}-U_{BE3}}{R_3} \\]\n若\\(U_{BE3}\\)的变换可忽略不计，则\\(I_{C3}\\)基本不受温度影响。由于没有动态信号可以作用到\\(T_3\\)的基极和发射极，因此\\(I_{C3}\\)为恒流，发射极所接电路可以等效成一个恒流源。有\n\\[I_{EQ1}=I_{EQ2}=\\dfrac{I_{C3}}{2} \\]\n当\\(T_3\\)管输出特性为理想特性时，\\(T_3\\)在放大区的输出特性曲线是横轴的平行线时，恒流源的内阻为无穷大，即相当于\\(T_1,T_2\\)接了一个无穷大的电阻，此时\\(A_c=0,K_{CMR}=\\infty\\)\n电流源电路 单管电流源电路 57.jpg\r（题外话，这和改进型差分放大器中的下面接的那个电流源一模一样）\n\\[I_O = I_C\\approx I_E = \\bigg(\\dfrac{R_2}{R_1+R_2}|U_{EE}|-U_{BE}\\bigg)\\bigg/R_3 \\]\n\\[R_O = r_{ce}\\bigg(1+\\dfrac{\\beta R_3}{r_{be}+R_3+R_1\\parallel R_2}\\bigg)\u003e\u003er_{ce} \\]\n镜像电流源 58.jpg\r它由两只特性完全相同的管子构成，由于\\(T_0\\)的管压降\\(U_{CE0}\\)与其\\(b-e\\)间电压\\(U_{BE0}\\)相等，从而保证\\(T_0\\)工作在放大状态。所以\\(I_{C0}=\\beta_0I_{B0}\\)，由于图中\\(T_0,T_1\\)的\\(b-e\\)间电压相等，所以有\\(I_{B0}=I_{B1}=I_B\\)；由于放大系数相等，所以\\(I_{C0}=I_{C1}=I_C=\\beta I_B\\)。由于电流相等的关系，所以叫做镜像电流源，\\(I_{C1}\\)为输出电流。\n电阻\\(R\\)中的电流称为基准电流，其表达式为\n\\[I_R = \\dfrac{V_{CC}-U_{BE}}{R} = I_C+2I_B = I_C + 2\\cdot\\dfrac{I_C}{\\beta} \\]\n所以集电极电流\n\\[I_C = \\dfrac{\\beta}{\\beta+2}I_R \\]\n\\(\\beta\u003e\u003e2\\)时，输出电流\n\\[I_C \\approx I_R = \\dfrac{V_{CC}-U_{BE}}{R} \\]\n镜像电流源具有一定的温度补偿作用，如下\n59.jpg\r这个电路不好用的地方在于，如果要求\\(I_{C1}\\)较大，\\(I_R\\)就要大，\\(R\\)的功耗也要很大。如果要求\\(I_{C1}\\)很小，那么\\(R\\)的数值就要很大。这两点在集成电路中都难以做到。\n比例电流源 60.jpg\r\\[U_{BE0} + I_{E0}R_{e0} = U_{BE1} + I_{E1}R_{e1} \\]\n根据晶体管发射结电压与发射极电流的近似关系可得\n\\[U_{BE}\\approx U_T\\ln \\dfrac{I_E}{I_S} \\]\n（上述公式是忽略基区电阻\\(r_{bb'}\\)上的电压时，晶体管发射极电流与\\(b-e\\)间电压的关系，\\(I_E\\approx I_S\\exp({U_{BE}/U_T})\\)，推导得到的）\n由于两只管的特性完全相同，所以\n\\[U_{BE0}-U_{BE1}\\approx U_T\\ln\\dfrac{I_{E0}}{I_{E1}} \\]\n代入前式整理得\n\\[I_{E1}R_{e1}\\approx I_{E0}R_{e0}+U_{T}\\ln\\dfrac{I_{E0}}{I_{E1}} \\]\n当\\(\\beta\u003e\u003e2\\)时，\\(I_{C0}\\approx I_{E0}\\approx I_{R},I_{C1}\\approx I_{E1}\\)，所以\n\\[I_{C1}\\approx\\dfrac{R_{e0}}{R_{e1}}\\cdot I_R+\\dfrac{U_T}{R_{e1}}\\ln\\dfrac{I_R}{I_{C1}} \\]\n在一定的取值范围内，如果对数项可以忽略，那么\n\\[I_{C1}\\approx\\dfrac{R_{e0}}{R_{e1}}\\cdot I_R \\]\n当然我们可以很容易地算出\n\\[I_{R}\\approx\\dfrac{V_{CC}-U_{BE0}}{R+R_{e0}} \\]\n微电流源 如果不想用很大的电阻，又要使得输出电流较小，可以把\\(R_{e0}\\)直接舍弃掉，如下图\n61.jpg\r当\\(\\beta\u003e\u003e1\\)时，有\n\\[I_{C1}\\approx I_{E1}=\\dfrac{U_{BE0}-U_{BE1}}{R_e} \\]\n其中这个电压差只有几十毫伏，甚至更小。只需要几千欧的\\(R_e\\)就可以得到几十微安的输出电流。\n两管完全相同，则\n\\[I_{C1}\\approx \\dfrac{U_T}{R_e}\\ln\\dfrac{I_R}{I_{C1}} \\]\n在\\(R_e\\)已知的情况下，上式对\\(I_{C1}\\)是超越方程，可以通过图解法或累试法解出\\(I_{C1}\\)（做题意义上，题目会直接给出一些数据方便你求解）。\n易算\n\\[I_{R}\\approx \\dfrac{V_{CC}-U_{BE0}}{R} \\]\n改进型电流源 上面三个电路很多分析结果都要\\(\\beta\\)很大时才成立，也就是没考虑基极电流的影响。\n加射极输出器的电流源\n62.jpg\r加了\\(T_2\\)后，利用放大作用，减小了\\(I_{B0},I_{B1}\\)对于\\(I_R\\)的分流。三个管特性要完全相同，即\\(\\beta_0=\\beta_1=\\beta_2=\\beta\\)，而由于\\(U_{BE1}=U_{BE0},I_{B1}=I_{B0}=I_B\\)，因此输出电流\n\\[I_{C1}=I_{C0} = I_R-I_{B2} = I_R-\\dfrac{I_{E2}}{1+\\beta}=I_R-\\dfrac{2I_B}{1+\\beta} = I_R-\\dfrac{2I_{C1}}{(1+\\beta)\\beta} \\]\n最后整理得\n\\[I_{C1} = \\dfrac{I_R}{1+\\dfrac{2}{(1+\\beta)\\beta}}\\approx I_R \\]\n有时会加上图中的\\(R_{e2}\\)，用于提高\\(T_2\\)管的\\(\\beta\\)\n威尔逊电流源\n63.jpg\r如上图，三个管子也是特性一致。由于\\(c-e\\)间等效电阻非常大，所以可以使\\(I_{C2}\\)高度稳定。\\(\\beta_0=\\beta_1=\\beta_2=\\beta,I_{C1}=I_{C0}=I_C\\)\n\\[I_{E2} = I_C + 2I_B = I_C + \\dfrac{2I_C}{\\beta} \\]\n所以\n\\[I_C = \\dfrac{\\beta}{\\beta+2}\\cdot I_{E2}=\\dfrac{\\beta}{\\beta+2}\\cdot\\dfrac{1+\\beta}{\\beta}I_{C2} = \\dfrac{\\beta+1}{\\beta+2}\\cdot I_{C2} \\]\n在上图的\\(B\\)点有\n\\[I_R = I_{B2}+I_C = \\dfrac{I_{C2}}{\\beta}+\\dfrac{\\beta+1}{\\beta+2}\\cdot I_{C2}=\\dfrac{\\beta^2+2\\beta+2}{\\beta^2+2\\beta}\\cdot I_{C2} \\]\n整理得\n\\[I_{C2} = (1-\\dfrac{2}{\\beta^2+2\\beta+2})I_R\\approx I_R \\]\n多路电流源 64.jpg\r\\(I_R\\)为基准电流，\\(I_{C1},I_{C2},I_{C3}\\)为三路输出电流。\n\\[U_{BE0}+I_{E0}R_{e0}=U_{BE1}+I_{E1}R_{e1}=U_{BE2}+I_{E2}R_{e2}=U_{BE3}+I_{E3}R_{e3} \\]\n由于各管的\\(U_{BE}\\)大致相等，则\n\\[I_{E0}R_{e0}\\approx I_{E1}R_{e1}\\approx I_{E2}R_{e2}\\approx I_{E3}R_{e3} \\]\n当\\(I_{E0}\\)确定之后，只要选择合适的电阻，就可以得到所需的电流。注意这里有\\(I_R\\approx I_{C0}\\approx I_{E0}\\)，其他路有\\(I_{Ci}\\approx I_{Ei}\\)\n当然可能会遇到\\(R_e\\)全都等于零的情况，那么输出电流全部都等于\\(I_R\\)。\n65.jpg\r上图的叫做多集电极管，集电极电流之比等于它们的集电区面积之比\n\\[\\dfrac{I_{C1}}{I_{C0}}=\\dfrac{S_1}{S_0},\\dfrac{I_{C2}}{I_{C0}}=\\dfrac{S_2}{S_0} \\]\n有源负载共射放大电路 66.jpg\r如上图，\\(T_1\\)为放大管，\\(T_2,T_3\\)构成镜像电流源。\\(T_2\\)是\\(T_1\\)的有源负载。设\\(T_2,T_3\\)管特性相同，从而\\(\\beta_2=\\beta_3=\\beta,I_{C2}=I_{C3}\\)。基准电流有\n\\[I_R = \\dfrac{V_{CC}-U_{EB3}}{R} \\]\n根据前面镜像电流源的讨论，空载时\\(T_1\\)管有\n\\[I_{CQ1} = I_{C2} = \\dfrac{\\beta}{\\beta+2}\\cdot I_R \\]\n可见设置\\(I_{CQ1}\\)只需要\\(V_{CC}\\)和\\(R\\)相配合。\n应当指出，输入端\\(u_I\\)中应含有直流分量，为\\(T_1\\)提供静态基极电流\\(I_{BQ1}=I_{CQ1}/\\beta_1\\)，而不与镜像电流源提供的\\(I_{C2}\\)产生冲突。带上负载电阻\\(R_L\\)后，由于分流作用，\\(I_{CQ1}\\)会有所变化。\n\\[\\dot A_u=-\\dfrac{\\beta_1(r_{ce1}\\parallel r_{ce2}\\parallel R_L)}{R_b+r_{be1}} \\]\n若\\(R_L \u003c\u003c (r_{ce1}\\parallel r_{ce2})\\)，则\n\\[\\dot A_u\\approx -\\dfrac{\\beta_1 R_L}{R_b+r_{be1}} \\]\n频率响应 我们学院的模电学时很少，没有涉及这方面，主要介绍一下波特图的横纵坐标。可能会在放大倍数中用到\n波特图 波特图由对数幅频特性和对数相频特性两部分组成，它们的横轴采用对数刻度\\(\\lg f\\)，幅频特性的纵轴采用\\(20\\lg |\\dot A_u|\\)表示，单位是分贝\\((dB)\\)，相频特性的纵轴仍采用\\(\\varphi\\)表示。这样不但开阔了视野，还能将放大倍数的乘除运算转换成加减运算。\n反馈 反馈的基本概念 在电子电路中，将输出量的一部分或全部通过一定的电路形式作用到输入回路，来影响其输入量的措施称为反馈。\n67.jpg\r使得净输入量增大的反馈称为正反馈，减小的称为负反馈。由于净输入影响输出，所以也有使得输出变化增大的称为正反馈，减小的称为负反馈。\n如果反馈量只含有直流量，则成为直流反馈。如果反馈量只含有交流量，则成为交流反馈。或者说，仅在直流通路中存在的反馈是直流反馈，仅在交流通路中存在的反馈是交流反馈。很多电路中二者都有。\n反馈的判断 有无反馈 如果放大电路中存在将输出回路与输入回路相连的通路，并且影响了净输入，则引入了反馈，否则没有引入。\n反馈极性的判断 我们用到了瞬时极性法。\n规定电路输入信号在某一时刻对地的极性，并以此为依据，逐级判断电路中各相关点电流的流向和电位的极性，从而得到输出信号的极性。根据输出信号的极性判断反馈信号的极性；若反馈信号使基本放大电路的净输入增大，则为正反馈，反之为负反馈。\n书上描述的并没有很详细。其实是将信号源断开，然后在输入端加上一个“上升”信号，记为\u0026quot;+\u0026quot;，然后推其他相关点的极性。\n对于集成放大器，从同相输入端输入，则输出端与输入相同。从反相输入端输入，则输出端与输入相反。\n对于三极管，无论是PNP还是NPN，基极和发射极相同，基极和集电极相反。\n经过电阻不变。由于交流、直流分开讨论，所以不需要讨论电容。\n对于集成放大器，如果反馈电路接到与输入不同的那一端，一般我们会考察那一端输入电压的变化。如果是反馈到相同的一端，一般我们会考察这一端输入电流的变化。对于三极管，我们可以考察净输入电压（\\(U_{be},U_{eb}\\)）或者净输入电流\\(I_B,I_E\\)。\n有一个好用的规律：从集成运放的输出端通过电阻、电容等反馈通路引回到其反相输入端的电路必然构成负反馈电路。从集成运放的输出端通过电阻、电容等反馈通路引回到其同相输入端的电路必然构成正反馈电路\n不方便做笔记，这个靠做题和解析来弄明白。\n特别指出，反馈量仅仅取决于输出量，与输入量无关。\n直流反馈与交流反馈的判断 画出直流通路和交流通路，存在于哪个电路中，就是哪种反馈。\n电压负反馈与电流负反馈的判断 令负反馈放大电路的输出电压\\(u_O=0\\)，然后判断反馈量。如果反馈量也立即归零，则为电压负反馈。否则为电流负反馈。\n注意这里是反馈量\\(u_F,i_F\\)，不是某个器件上的电压电流，有可能那个器件上的电压电流并没有归零，但是，由于输出电压作用引起的电流电压值归零了，则是电压负反馈。它们还可能有其他东西作用，所以并不一定全部归零。\n这个东西不能用于实验，强制接地将会导致集成运放烧坏。只能用于理论判断。\n串联反馈与并联反馈的判断 若反馈信号为电压量，与输入电压求差而获得净输入电压，则为串联反馈。若反馈信号为电流量，与输入电流求差获得净输入电流，则为并联反馈。\n负反馈放大电路的四种基本组态 分为电压串联负反馈、电流串联负反馈、电压并联负反馈、电流并联负反馈。\n负反馈放大电路的方块图及一般表达式 68.jpg\r任何负反馈都可以用这个图来表示。图中\\(\\dot X_i\\)为输入量，\\(\\dot X_f\\)为反馈量，\\(\\dot X_i'\\)为净输入量，\\(\\dot X_o\\)为输出量。另外箭头表示信号是单向流通的。\n显然，由图\n\\[\\dot X_i' = \\dot X_i-\\dot X_f \\]\n在信号的中频段，\\(\\dot X_i,\\dot X_i',\\dot X_f\\)都为实数，所以可以写为\n\\[|\\dot X_i'| = |\\dot X_i| - |\\dot X_f|\\quad \\text{or}\\quad X_i' = X_i-X_f \\]\n基本放大器传输增益（放大倍数）、开环增益、开环放大倍数\n\\[\\dot A = \\dfrac{\\dot X_o}{\\dot X_i'} \\]\n反馈网络的传输系数、反馈系数\n\\[\\dot F = \\dfrac{\\dot X_f}{\\dot X_o} \\]\n反馈放大器的传输增益、闭环增益、闭环放大倍数\n\\[\\dot A_f=\\dfrac{\\dot X_o}{\\dot X_i} \\]\n环路增益、环路放大倍数\n\\[\\dot T = \\dot A\\dot F = \\dfrac{\\dot X_f}{\\dot X_i'} \\]\n由此可以推出闭环增益的另一个表达式\n\\[\\dot A_f=\\dfrac{\\dot A}{1+\\dot A\\dot F} \\]\n以上这些在中频段都可以把头上的点去掉。\n注意到若\\(\\dot A\\dot F\u003c0\\)，则\\(|\\dot A_f|\u003e|\\dot A|\\)，则说明引入了正反馈。若\\(\\dot A\\dot F=-1\\)，则说明电路在没有输入的时候就有输出，称电路产生了自激震荡。正反馈时\\(X_i'=X_i+X_f,A_f=\\dfrac{A}{1-AF}\\)（此时\\(AF\u003e0\\)）\n四种组态的方块图 69.jpg\r显然不同电路的输入输出反馈量不同，得到的各种放大倍数量纲都不同，功能也就不同。除了环路放大倍数的量纲，它们都为一。\n深度负反馈 方便我打字起见，后面不打字母上面的点了。\n定义反馈深度为\n\\[D = 1+AF = \\dfrac{X_i}{X_i'} \\]\n若\\(D\u003e\u003e1\\)即\\(AF\u003e\u003e1\\)时，有\n\\[A_f \\approx \\dfrac{1}{F} \\]\n此时引入了深度负反馈。又因为\n\\[A_f = \\dfrac{X_o}{X_i},\\quad F=\\dfrac{X_f}{X_o},\\quad A_f\\approx\\dfrac{1}{F}=\\dfrac{X_o}{X_f} \\]\n所以有\\(X_i\\approx X_f\\)。可见深度负反馈的实质是在近似分析中忽略净输入量。\n求解深度负反馈放大电路放大倍数的一般步骤是\n正确判断反馈组态 求解反馈系数 利用\\(F\\)求解\\(A_f\\) 负反馈对放大电路性能的影响 稳定放大系数 \\[\\dfrac{dA_f}{A_f} = \\dfrac{1}{1+AF}\\dfrac{dA}{A} \\]\n也就是说，负反馈放大电路放大倍数的相对变化量\\(dA_f/A_f\\)仅为其开环增益相对变化量的\\((1+AF)\\)分之一。也就是说\\(A_f\\)的稳定性是\\(A\\)的\\((1+AF)\\)倍。\n但是，这是以损失了放大倍数为代价的，\\(A_f\\)是\\(A\\)的\\((1+AF)\\)分之一。\n对输入电阻的影响 串联负反馈时\n\\[R_{if} = (1+AF)R_i \\]\n注意，有些输入电阻是有多个的，有些并联有些串联，这里引入串联负反馈，只影响在反馈环上的输入电阻，其他并联的输入电阻不变，将这些电阻最后全部并联起来再计算。之后也有类似的情况，不再讨论。\n并联负反馈时\n\\[R_{if} = \\dfrac{R_{i}}{1+AF} \\]\n对输出电阻的影响 电压负反馈时\n\\[R_{of} = \\dfrac{R_o}{1+AF} \\]\n电流负反馈时\n\\[R_{of} = (1+AF)R_o \\]\n展宽频带 原来的频带，假设中频段放大倍数为\\(A_m\\)，则低频使得放大倍数为\\(0.707A_m\\)或\\(A_m-3dB\\)的频率叫做下限频率\\(f_L\\)。高频使得放大倍数为\\(0.707A_m\\)或\\(A_m-3dB\\)的频率叫做上限频率\\(f_H\\)。\n\\[f_{Lf} = \\dfrac{f_L}{1+A_mF} \\]\n一般情况下，由于\\(f_H\u003e\u003ef_L,f_{Hf}\u003e\u003ef_{Lf}\\)，因此，近似有\n\\[f_{bw} = f_H-f_L \\approx f_H \\]\n\\[f_{bwf} = f_{Hf}-f_{Lf}\\approx f_{Hf} \\]\n即引入负反馈使频带展宽到基本放大电路的\\((1+AF)\\)倍。\n减小非线性失真 \\[THD_f=\\dfrac{THD}{1+AF} \\]\n提高信噪比 提高\\((1+AF)\\)倍。\n","date":"2023-05-25T16:29:15+08:00","image":"https://kegalas.top/inferior/%E6%A8%A1%E6%8B%9F%E7%94%B5%E8%B7%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/cover_hu519ff8a40d33619eeac863a3de25a967_23559_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E6%A8%A1%E6%8B%9F%E7%94%B5%E8%B7%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"模拟电路学习笔记"},{"content":"导航页面\n线段光栅化算法 从《Fundamentals of Computer Graphics》（第五版）中的第179页，我们得到了一种直线的表达方式，\n\\[f(x,y)\\equiv (y_0-y_1)x+(x_1-x_0)y + x_0y_1-x_1y_0 = 0 \\]\n其中\\((x_0,y_0),(x_1,y_1)\\)代表直线上的任意不同的两点。并且\\(x_0\\leq x_1\\)，如果这个不满足，就交换两点的序号。然后直线的斜率显然就是\n\\[m = \\dfrac{y_1-y_0}{x_1-x_0} \\]\n方便起见，我们先假设\\(m\\in(0,1]\\)。\n显然，我们要画一条直线的话，无非就两种情况：\n1.jpg\r要么向右移动一格，要么向右后再向上移动一格。总之，我们总是向右移动一格，然后根据某种条件向上移动一格。我们可以把这个条件设置为\n\\[\\mathbf{if}\\ f(x+1,y+0.5)\u003c0\\ \\mathbf{then}\\ y=y+1 \\]\n注意这里的\\((x,y)\\)取整数，起始像素在直线上。\n进一步的，如果我们不想每次都调用函数\\(f\\)，我们有如下优化\ny = y0 d = f(x0+1,y0+0.5) for x = x0 to x1 do draw(x,y) if d\u0026lt;0 then y = y+1 d = d+(x1-x0)+(y0-y1) else d = d+(y0-y1) 不优化的方法写成cpp的样子大概如下\nif(p0-\u0026gt;x\u0026gt;p1-\u0026gt;x) std::swap(p0,p1); auto fxy = [\u0026amp;](float x, float y)-\u0026gt;float{ return (p0-\u0026gt;y-p1-\u0026gt;y)*x+(p1-\u0026gt;x-p0-\u0026gt;x)*y+p0-\u0026gt;x*p1-\u0026gt;y-p1-\u0026gt;x*p0-\u0026gt;y; }; int y = p0-\u0026gt;y; for(int x = p0-\u0026gt;x ; x\u0026lt;=p1-\u0026gt;x ; x++){ image.setFragment(x,y,color); float er = fxy(static_cast\u0026lt;float\u0026gt;(x)+1.f, static_cast\u0026lt;float\u0026gt;(y)+.5f); if(p0-\u0026gt;y\u0026lt;p1-\u0026gt;y \u0026amp;\u0026amp; er\u0026lt;0.f \u0026amp;\u0026amp; y\u0026lt;image.getHeight()-1){ y++; } else if(p0-\u0026gt;y\u0026gt;p1-\u0026gt;y \u0026amp;\u0026amp; er\u0026gt;0.f \u0026amp;\u0026amp; y\u0026gt;0){ y--; } } 这里写的包括了\\(m\\in[-1,1]\\)的情况，负数情况很简单，就把y++变成y\u0026ndash;，以及判断小于零转变为判断大于零。\n当\\(m\\in(1,+\\infty]\\)时，情况转变为，我们要么向上走一格，要么向上后向右走一格，与之前的情况非常相似，我们只要把遍历x改成遍历y，判断x++的条件即可。\n三角形光栅化算法 我会直接使用三角形的重心坐标来实现三角形的光栅化，因为比起其他一些扫描方法，重心坐标能比较方便的实现插值。\n三角形的重心坐标可见《Fundamentals of Computer Graphics》（第五版）中的第52页。\n根据线性代数的知识，假设我们三角形有三个不重合的点\\(A,B,C\\)，则我们可以用\\(\\vec{AB},\\vec{AC}\\)表示平面中任意的点\\(p\\)，我们有如下公式\n\\[\\vec{p} = \\alpha\\vec{a} + \\beta\\vec{b}+\\gamma\\vec{c} \\]\n其中\\(\\alpha+\\beta+\\gamma=1\\)\n可以计算得到，对于平面上的任意一个点\\((x,y)\\)\n\\[\\gamma = \\dfrac{(y_a-y_b)x+(x_b-x_a)y+x_ay_b-x_by_a}{(y_a-y_b)x_c+(x_b-x_a)y_c+x_ay_b-x_by_a} \\]\n\\[\\beta = \\dfrac{(y_a-y_c)x+(x_c-x_a)y+x_ay_c-x_cy_a}{(y_a-y_c)x_b+(x_c-x_a)y_b+x_ay_c-x_cy_a} \\]\n\\[\\alpha = 1-\\beta-\\gamma \\]\n当这个点在三角形内时，满足以下条件\n\\[0\u003c\\alpha\u003c1 \\]\n\\[0\u003c\\beta\u003c1 \\]\n\\[0\u003c\\gamma\u003c1 \\]\n特别的，如果在三角形上，则可以取等号。总体还是要满足\\(\\alpha+\\beta+\\gamma=1\\)。\n这个东西好就好在，如果需要对颜色进行插值，对于三角形内部任意一点\\(p\\)，有\\(color_p=\\alpha color_a+\\beta color_b+\\gamma color_c\\)。\n我们绘制的时候设置三个点为红、绿、蓝，中间颜色进行插值，就会得到这个结果\n2.jpg\r接下来我们谈谈具体怎么画三角形。\n首先非常暴力的想法是，把整个屏幕上的点扫描一遍，如果这个点在三角形内部，就给他上色。\n稍微优化一下，我们只需要扫描三角形的外接矩形（四边平行于坐标轴）即可。\ncpp代码如下\nint maxx = 0, minx = image.getWidth()-1, maxy = 0, miny = image.getHeight()-1; for(int i=0;i\u0026lt;3;i++){ maxx = std::max(maxx, points[i].x); minx = std::min(minx, points[i].x); maxy = std::max(maxy, points[i].y); miny = std::min(miny, points[i].y); } for(int x=minx;x\u0026lt;=maxx;x++){ for(int y=miny;y\u0026lt;=maxy;y++){ std::tuple\u0026lt;float,float,float\u0026gt; ret = geo::getBarycentric(points, x, y); float alpha = std::get\u0026lt;0\u0026gt; (ret); float beta = std::get\u0026lt;1\u0026gt; (ret); float gamma = std::get\u0026lt;2\u0026gt; (ret); if(0.f\u0026lt;=alpha \u0026amp;\u0026amp; alpha\u0026lt;=1.f \u0026amp;\u0026amp; 0.f\u0026lt;=beta \u0026amp;\u0026amp; beta \u0026lt;=1.f \u0026amp;\u0026amp; 0.f\u0026lt;=gamma \u0026amp;\u0026amp; gamma\u0026lt;=1.f) { geo::OARColor color = static_cast\u0026lt;geo::vec4i\u0026gt;( alpha*static_cast\u0026lt;geo::vec4f\u0026gt;(colors[0]) + beta*static_cast\u0026lt;geo::vec4f\u0026gt;(colors[1]) + gamma*static_cast\u0026lt;geo::vec4f\u0026gt;(colors[2])); image.setFragment(x,y,color); } } } 全部光栅化的代码可见**这里**\n另外，求重心坐标的代码我写到了geometry.cpp里，方便别处调用。链接在**这里**（在文件末尾）\n另外，求重心坐标还有一种不那么复杂的公式，见**计算机图形学基础学习笔记-数学基础**\n注意，\nif(0.f\u0026lt;=alpha \u0026amp;\u0026amp; alpha\u0026lt;=1.f \u0026amp;\u0026amp; 0.f\u0026lt;=beta \u0026amp;\u0026amp; beta \u0026lt;=1.f \u0026amp;\u0026amp; 0.f\u0026lt;=gamma \u0026amp;\u0026amp; gamma\u0026lt;=1.f) 这一段代码也可以写作\nif(alpha \u0026lt; 0.f || beta \u0026lt; 0.f || gamma \u0026lt; 0.f) continue; 这也是对的。唯一需要小心的是精度问题，float的精度可能不足以把边界上的每一个点都画出来。如果你不在乎这一两个像素点就可以不用管，如果你在乎，那么我们可以修改为alpha\u0026lt;-(1e-5)这样的条件。\n使用例子 绘制线段 #include \u0026#34;tga_image.h\u0026#34; #include \u0026#34;raster.h\u0026#34; int main(){ TGAImage image(100,100,TGAType::rgb); geo::vec2i pts0[2] = {geo::vec2i(99,0),geo::vec2i(0,99)}; ras::line(image, pts0, geo::OARColor(255,0,0,255)); for(int i=0;i\u0026lt;=99;i+=10){ pts0[0] = geo::vec2i(i,0); ras::line(image, pts0, geo::OARColor(255,0,0,255)); } image.writeToFile(\u0026#34;./line.tga\u0026#34;); } 如上，我们首先绘制了一条\\((99,0),(0,99)\\)的直线，也就是从右下角到左上角，然后我们用循环绘制了一组，一个点固定在右上角的直线。\n效果如下\n3.jpg\r绘制三角形 #include \u0026#34;tga_image.h\u0026#34; #include \u0026#34;raster.h\u0026#34; int main(){ TGAImage image2(100,100,TGAType::rgb); geo::vec2i pts1[3] = {geo::vec2i(60,5),geo::vec2i(5,60),geo::vec2i(70,90)}; geo::OARColor colors[3] = {geo::OARColor(255,0,0,255),geo::OARColor(0,255,0,255),geo::OARColor(0,0,255,255)}; ras::triangle(image2,pts1,colors); image2.writeToFile(\u0026#34;./triangle.tga\u0026#34;); return 0; } 代码非常直观，就是把三个点和三个点的颜色设置一下扔到光栅化函数里去。效果如下\n2.jpg\r","date":"2023-05-17T21:31:12+08:00","image":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E7%BA%BF%E6%AE%B5%E5%92%8C%E4%B8%89%E8%A7%92%E5%BD%A2%E7%9A%84%E5%85%89%E6%A0%85%E5%8C%96/cover_hu72dadf0d98aceb343e3fe7cb76faf398_301126_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E7%BA%BF%E6%AE%B5%E5%92%8C%E4%B8%89%E8%A7%92%E5%BD%A2%E7%9A%84%E5%85%89%E6%A0%85%E5%8C%96/","title":"从零开始的软渲染器 线段和三角形的光栅化"},{"content":"你可能会遇到如下情况：无论你使用MSYS2还是MinGW64还是Ucrt64还是Clang64，去输入pacman -S make，你的make都只会安装在/usr/bin里，也就是MSYS2里。如果你安装它们的toolchain，例如pacman -S mingw-w64-ucrt-x86_64-toolchain，里面包含了mingw-w64-ucrt-x86_64-make这个工具，但是在/ucrt64/bin里面并没有make.exe。\n其实并不是没有安装，只不过，他叫mingw32-make.exe。你如果要像使用make一样使用这个工具，你可以在打开cmd，在/ucrt64/bin中，输入mklink make mingw32-make.exe来创建软连接。这样，如果这个目录在环境变量之下，你就可以使用ucrt64中的make工具了。\n值得注意的是，虽然他叫mingw32-make，不过编译32位和64位的源码都可以用。\n","date":"2023-05-13T15:15:55+08:00","permalink":"https://kegalas.top/inferior/msys2%E4%B8%AD%E7%9A%84make%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/","title":"MSYS2中的make工具安装方法"},{"content":"这篇文章不探讨这几个东西的历史、关系，只来说一下什么时候该用什么，以及区别。\n首先，在MSYS2官网上下载安装后，它会提供许许多多的exe文件，包括msys2.exe, clang64.exe, mingw64.exe, ucrt64.exe等。这些东西里面都提供gcc或者clang/llvm等编译器，当然也提供其他一些工具链，但是编译出来的目标文件却不相同。我们把这些东西分为两类。\n第一类是msys2.exe，它的目标文件依赖于msys2提供的一个叫做msys-2.0.dll的动态链接库，这是一个虚拟POSIX环境。通过这个东西，一个程序可以调用Linux的API，但是经过这个dll后，转换到调用Windows对应的API来实现。程序本身不是原生的目标文件，而是中间加了一个仿真。\n第二类是其他三个，它们的目标文件是原生Windows的，也就是说，不需要这个msys-2.0.dll，直接就可以打开用。缺点是如果你要开发的东西非常依赖于POSIX，则这个东西没法编译，只能去用MSYS2。\n而Cygwin，和MSYS2差不多（非常简略地来说的话），只不过POSIX环境变成了cygwin.dll。\n总结，如果你需要给别人发Release，那么用MinGW、UCRT、CLANG的编译器（当然你也可以使用MSYS2然后附上msys-2.0.dll）。如果你开发的东西非常依赖POSIX，那么用MSYS2。\n至于Cygwin，由于它的安装和卸载我不是很喜欢，我一般不用。不过Cygwin有它很优秀的X server适配，在Windows下表现很好，这点比MSYS2好（实际上它根本没有X server和一些图形库）。不过随着WSL2的发布，也不是必需品了。\n现在MSYS2官网更推荐使用UCRT而不是MINGW。如果你要使用clang/llvm，那么用clang64是肯定的（我试了，在clang64里面装用pacman -S clang装进的是MSYS2里面。而且版本比较旧，也没有clangd等工具。我们要用的是 pacman -S mingw-w64-clang-x86_64-toolchain，当然也可以用llvm-mingw，不过好像有一些其他问题。而且这个clang64的前端好像是gcc，而不是在Windows下安装的llvm的默认前端msvc）。它们的具体区别可见https://www.msys2.org/docs/environments/。\n另外，笔者曾经有使用MinGW的困难（链接），不过现在我觉得可能不是MinGW的问题，具体什么问题由于我现在没有再遇到，可能不能解决了。\n注意，你安装ucrt64中的gcc后，可能会遇到编译过后，exe文件运行不正常的情况，例如打开直接错误退出，例如emacs的native compile错误的问题。这很可能是因为，你的电脑里面有太多g++的库了，比如GPG4Win，git，cmake，emacs，qt都会自带libstdc++-6.dll，这是gnu实现的c++的STL，这可能没什么，但是如果它们都在环境变量里，即使不会干扰到各自的运行（因为在同一个目录下的dll优先级高于在环境变量里的），也会对你自己编译的程序造成影响。解决办法是，把ucrt64的环境变量优先级拉高；或者复制一份ucrt64的libstdc++-6.dll到你的build目录下；或者干脆静态链接libstdc++。\n如果你要打包发送给别人用，别人一般不会拥有libstdc++这个库，你要么选择静态链接，要么把dll一起打包发布。可能这里静态链接会有被GPL感染的风险（我查到的说法基本上各执一词），建议还是动态链接吧。\n","date":"2023-05-06T23:44:47+08:00","permalink":"https://kegalas.top/p/msys2mingw64cygwin%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8C%BA%E5%88%AB%E6%B5%85%E8%B0%88/","title":"MSYS2,MinGW64,Cygwin的使用区别浅谈"},{"content":"信号与系统概论 信号的能量与功率 对于连续时间信号\\(x(t)\\)，在\\(t_1\\leq t\\leq t_2\\)内的总能量为\n\\[\\int^{t_2}_{t_1}|x(t)|^2 dt \\]\n\\(|\\cdot|\\)指的是模，因为可能是复数。\n在\\(n_1\\leq n\\leq n_2\\)内的离散时间信号\\(x[n]\\)的总能量为\n\\[\\sum^{n_2}_{n=n_1}|x[n]|^2 \\]\n功率将能量除以时间间隔即可。\n能量有限信号指\\(E\u003c\\infty\\)的信号，此时\\(P=0\\)（无限长时间意义上）\n功率有限信号指\\(0\u003c P\u003c\\infty\\)的信号，此时\\(E=\\infty\\)（无限长时间意义上）\n时限信号为能量信号，周期信号是功率信号，非周期信号可能是其中之一，有些信号两种都不是。\n自变量的变换 时移 时间翻转 时间尺度变换 周期信号 基波周期就是最小正周期。其对应的频率称为基波频率。\n两个周期信号的周期分别为\\(T_1\\)和\\(T_2\\)，若\\(T_1/T_2\\)为有理数，则周期信号之和仍然是周期信号，其周期为\\(T_1\\)和\\(T_2\\)的最小公倍数。\n离散的情况下，\\(sin(\\beta k)\\)是否为周期信号？\n如果\\(2\\pi/\\beta\\)是整数，则周期为\\(N=2\\pi/\\beta\\) 如果\\(2\\pi/\\beta\\)是有理数，则周期为\\(N=M(2\\pi/\\beta)\\)，\\(M\\)为使\\(N\\)称为正整数的最小正整数 如果\\(2\\pi/\\beta\\)是无理数，则不是周期信号。 偶信号与奇信号 任何信号都能分解成一个偶信号和一个奇信号的和。\n单位冲激函数与单位阶跃函数 单位冲激的符号是\\(\\delta\\)，单位阶跃的符号是\\(\\varepsilon\\)或\\(u\\)\n在离散情况下\n\\[\\delta[n] = u[n]-u[n-1] \\]\n是一次差分关系\n而\n\\[u[n] = \\sum^n_{m=-\\infty}\\delta [m] \\]\n连续情况下\n\\[\\delta(t) = \\dfrac{du(t)}{dt} \\]\n\\[u(t) = \\int^t_{-\\infty}\\delta(\\tau)d\\tau \\]\n单位冲激的导数，即单位冲激偶有\n\\[\\delta'(t) = \\begin{cases} \\pm\\infty \u0026 \\text{ if } t=0 \\\\ 0 \u0026 \\text{ if } t\\neq 0 \\end{cases} \\]\n连续时间系统和离散时间系统 定义 系统的互联 需要记住的是，并联在一起的是用加法，级联在一起的是用卷积。\n系统的基本性质 有记忆与无记忆 一个系统的输出仅仅取决于该时刻的输入，则为无记忆系统。\n可逆系统 一个系统在不同的输入下，导致不同的输出，那么就是可逆的。\n因果性 一个系统在任何时刻的输出只取决于现在的输入和过去的输入，则称为因果系统。\n因果系统的零状态响应不会出现在激励之前。\n稳定性 一个稳定系统，若其输入是有界的，那么输出也必须是有界的。\n时不变性 若系统的特性和行为不随时间改变，那么该系统就是时不变的。\n如果在输入信号上有一个时移，而在输出信号中产生同样的时移，那么就是时不变的。\n\\[T[f(t-t_0)] = y(t-t_0) \\]\n有一个直观的办法可以判定一个系统是时变的。如果\\(f(\\cdot)\\)前出现变系数，或者有反转、伸缩变换，则一定是时变系统。\n线性 一个线性系统应该满足\n\\(y_1(t)+y_2(t)\\)是对\\(x_1(t)+x_2(t)\\)的响应。 \\(ay_1(t)\\)是对\\(ax_1(t)\\)的响应，此处\\(a\\)为任意复常数。 可以记作\n\\[T[af_1(\\cdot)+bf_2(\\cdot)] = aT[f_1(\\cdot)]+bT[f_2(\\cdot)] \\]\n动态系统 动态系统不仅和激励\\(\\{f(\\cdot)\\}\\)有关，还与它过去的历史状况\\(\\{x(0)\\}\\)有关。\n完全响应\n\\[y(\\cdot) = T[\\{f(\\cdot)\\},\\{x(0)\\}] \\]\n零状态响应\n\\[y_{zs}(\\cdot) = T[\\{f(\\cdot)\\},\\{0\\}] \\]\n零输入响应\n\\[y_{zi}(\\cdot) = T[\\{0\\},\\{x(0)\\}] \\]\n当动态系统满足下列三个条件时，可以成为线性系统\n可分解性 \\[y = y_{zs} + y_{zi} \\]\n零状态线性 \\[T[\\{af_1(\\cdot)+bf_2(\\cdot)\\},\\{0\\}] = aT[\\{f_1(\\cdot)\\},\\{0\\}]+bT[\\{f_2(\\cdot)\\},\\{0\\}] \\]\n零输入线性 \\[T[\\{0\\},\\{ax_1(0)+bx_2(0)\\}] = aT[\\{0\\},\\{x_1(0)\\}]+bT[\\{0\\},\\{x_2(0)\\}] \\]\n线性时不变系统 卷积 离散情况\n\\[a[n]*b[n] = \\sum^{+\\infty}_{k=-\\infty} a[k]b[n-k] \\]\n连续情况\n\\[a(t)*b(t) = \\int^{+\\infty}_{-\\infty}a(\\tau)b(t-\\tau)d\\tau \\]\n用脉冲表示信号，及其响应 以下系统指线性时不变系统（LTI）。\n脉冲信号的筛选性质：\n\\[x[n] = \\sum^{+\\infty}_{k=-\\infty} x[k]\\delta[n-k] = x[n]*\\delta[n] \\]\n\\[x(t) = \\int^{+\\infty}_{-\\infty}x(\\tau)\\delta(t-\\tau)d\\tau = x(t)*\\delta(t) \\]\n一个系统对脉冲信号的（零状态）响应记作\\(h\\)。一个系统的特征可以完全由脉冲响应刻画，一个系统对其他信号的响应可以用该信号和脉冲响应的卷积表示。\n\\[y[n] = x[n]*h[n] \\]\n\\[y(t) = x(t)*h(t) \\]\n通常，题目中不会给以下两个条件。因为是零状态的响应，所以\\(h(0_-)=h'(0_-)=0\\)\n线性时不变系统的性质 线性时不变下卷积的性质 交换律 分配律 结合律 当然他都叫线性时不变系统了，肯定有线性和时不变性。\n微分特性（仅限于连续情况）\n\\[\\dfrac{d^n}{dt^n}[f_1*f_2] = \\dfrac{d^n f_1}{dt^n}*f_2 = f_1*\\dfrac{d^n f_2}{dt^n} \\]\n积分特性（仅限于连续情况）\n\\[\\int^t_{-\\infty}[f_1*f_2]d\\tau = [\\int^t_{-\\infty}f_1d\\tau]*f_2 = f_1 * [\\int^t_{-\\infty}f_2d\\tau] \\]\n\\(f_1(-\\infty)=0\\)或\\(f_2'(\\infty) = 0\\)（仅限连续情况）\n\\[f_1*f_2=f_1'*f_2' \\]\n（后向）差分特性（仅限于离散情况）\n\\[\\nabla[f_1*f_2] = \\nabla f_1*f_2 = f_1*\\nabla f_2 \\]\n时移特性\n若\\(f(t)=f_1(t)*f_2(t)\\)\n则\n\\[f_1(t-t_1)*f_2(t-t_2) = f_1(t-t_1-t_2)*f_2(t) = f_1(t)*f_2(t-t_1-t_2) = f(t-t_1-t_2) \\]\n无记忆的LTI 因为输出只和当前的输入有关，所以其冲激响应为\\(h(t)=K\\delta(t)\\)。\n系统对于其他信号的响应就为\\(y(t)=Kx(t)\\)。离散的情况类似。\n微分特性 \\[if\\quad x(t)\\to y(t)\\quad then\\quad x'(t)\\to y'(t) \\]\n积分特性 \\[if\\quad x(t)\\to y(t)\\quad then\\quad \\int^t_{-\\infty}x(t)dt\\to \\int^t_{-\\infty}y(t)dt \\]\n可逆性 仅当存在一个逆系统，其与原系统级联后所产生的输出等于第一个系统的输入时，这个系统才是可逆的。\n设一个系统的冲激响应是\\(h(t)\\)，逆系统的冲激响应是\\(h_1(t)\\)，则\n\\[h(t)*h_1(t) = \\delta(t) \\]\n离散的情况类似。\n因果性 如果\\(h(t)=0,t\u003c0\\)，那么一个LTI就是因果的，这时\n\\[y(t) = \\int^t_{-\\infty} x(\\tau)h(t-\\tau)d\\tau = \\int^\\infty_0 h(\\tau)x(t-\\tau)d\\tau \\]\n稳定性 一个稳定的离散LTI，要求\n\\[\\sum^{+\\infty}_{k=-\\infty}|h[k]| \u003c \\infty \\]\n一个稳定的连续LTI，要求\n\\[\\int^{+\\infty}_{-\\infty} |h(\\tau)|d\\tau \u003c \\infty \\]\nLTI的单位阶跃响应 单位阶跃响应记作\\(s\\)或\\(g\\)\n\\[s[n] = u[n]*h[n] = \\sum^n_{k=-\\infty}h[k] \\]\n\\[h[n] = s[n]-s[n-1] \\]\n\\[s(t) = \\int^t_{-\\infty} h(\\tau)d\\tau \\]\n\\[h(t) = \\dfrac{ds(t)}{dt} \\]\n用微分方程描述的连续因果线性时不变系统 微分方程 微分方程的形式如下\n\\[y^{(n)}(t) + a_{n-1}y^{(n-1)}(t)+\\cdots+a_{1}y^{(1)}(t)+a_0y(t) = b_{m}f^{(m)}(t)+b_{m-1}f^{(m-1)}(t)+\\cdots+b_{1}f^{(1)}(t)+b_{0}f(t) \\]\n解的形式如下\n\\[y(t) = y_h(t) + y_p(t) \\]\n其中\\(y_h\\)是齐次解，\\(y_p\\)是特解。\n齐次解是对应的齐次方程\n\\[y^{(n)}(t) + a_{n-1}y^{(n-1)}(t)+\\cdots+a_{1}y^{(1)}(t)+a_0y(t) = 0 \\]\n的解。\n解这个方程，我们首先要求得特征根\\(\\lambda\\)，由以下方程解出\n\\[\\lambda^n + a_{n-1}\\lambda^{n-1}+\\cdots+a_0=0 \\]\n对于每一个\\(\\lambda_i\\)，\n如果它是单实根，则 \\[y_h = Ce^{\\lambda t} \\]\n如果它是二重实根，则 \\[y_h = (C_1t+C_0)e^{\\lambda t} \\]\n如果是一对共轭复根\\(\\lambda_{1,2} = \\alpha\\pm j\\beta\\)，则 \\[e^{\\alpha t}[C\\cos(\\beta t)+D\\sin(\\beta t)] \\]\n整个齐次解就是把这些对于每一个\\(\\lambda_i\\)的齐次解加起来，再根据条件求出待定系数。\n特解的常见形式为\n激励为\\(f(t)=t\\)时，如果所有的特征根均不等于\\(0\\)， \\[P_1 t+P_0 \\]\n如果有\\(1\\)个等于\\(0\\)的特征根，\n\\[t(P_1t+P_0) \\]\n激励为\\(f(t)=e^{\\alpha t}\\)，如果\\(\\alpha\\)不等于特征根 \\[Pe^{\\alpha t} \\]\n如果\\(\\alpha\\)等于特征根\n\\[(P_1t+P_0)e^{\\alpha t} \\]\n激励为\\(cos(\\beta t)\\)或\\(\\sin(\\beta t)\\)，如果所有的特征根都不等于\\(\\pm j\\beta\\) \\[P\\cos(\\beta t) + Q\\sin(\\beta t) \\]\n这个通常可以把\\(y_p\\)直接代入原方程求解系数。\n激励为\\(\\delta,\\varepsilon\\)等时，由于我们的特解是零状态响应中的部分，所以都是在\\(0_+\\)时的取值，我们直接把激励在\\(0_+\\)的值写在等号右边，然后设定\\(y_p=p\\)（常数），解出\\(p\\)即可。显然，\\(p\\)的值会是\\(\\varepsilon\\text{的系数}/y\\text{的系数}\\)（因为\\(y\\)现在是常数，任意阶导数为\\(0\\)）。如果是\\(e^t\\varepsilon(t)\\)这种形式又怎么办呢，还是老话，我们求特解是\\(0_+\\)时的值，此时看做激励为\\(e^t\\)，然后用上面的特解。 注意，如果题目给的条件是\\(y(0),y'(0)\\)等条件，我们需要在全解中去求齐次解中设的参数。如果题目给的条件是\\(y_{zi},y'_{zi}\\)等条件，我们在齐次解中求参数即可。\n题目中也可能只给出\\(y(0^-),y'(0^-)\\)的条件，这显然就是给零输入条件。如果你还要求出零状态响应和全解，你必须在这之前求出\\(y(0^+),y'(0^+)\\)，才能带进去求零状态响应的参数，求解方法见后。\n如果给的激励包含多种情况？我自己的思考是，求出冲激响应即可，然后根据线性性质，将激励分别与冲激响应卷积，再相加。\n还有一种办法是求频率响应\\(H(jw)\\)来求零状态响应，见后。\n系统的初始值 初始值是\\(n\\)阶系统在\\(t=0\\)时接入激励，其响应在\\(t=0_+\\)时刻的值，即\\(y^{(j)}(0_+) (j=0,1,2,\\cdots,n-1)\\)。\n初始状态是指系统在激励尚未接入的\\(t=0_-\\)时刻的响应值\\(y^{(j)}(0_-)\\)，该值反映了系统的历史情况，而与激励无关。\n例如\\(y''(t)+3y'(t)+2y(t)=2\\delta(t)+6\\varepsilon(t)\\)，（老师在PPT中给出但我没有看懂的办法是）两端积分\n\\[\\int^{0_+}_{0_-}y''(t)dt+3\\int^{0_+}_{0_-}y'(t)dt+2\\int^{0_+}_{0_-}y(t)dt = 2\\int^{0_+}_{0_-}\\delta(t)dt + 6\\int^{0_+}_{0_-}\\varepsilon(t)dt \\]\n其中从左到右每一项分别对应，\\(y'(0_+)-y'(0_-),y(0_+)-y(0_-),0,2,0\\)\n所以\\(y'(0_+)-y'(0_-) = 2, y(0_+)-y(0_-) = 0\\)\n结论是，微分方程等号右边含有\\(\\delta(t)\\)及其各阶导数时，响应\\(y(t)\\)及其各阶导数由\\(0_-\\)到\\(0_+\\)的瞬间将发生跃变（如果不含，则\\(y(t)\\)在t=0处是连续的，\\(y(0_+)=0\\)）。这时可按如下步骤由\\(0_-\\)求取\\(0_+\\)（以二阶系统为例）\n将\\(f(t)\\)代入微分方程。如果等号右边含有\\(\\delta(t)\\)及其各阶导数，根据微分方程等号两端各奇异函数的系数相等原理，判断方程左端\\(y(t)\\)的最高阶导数所含\\(\\delta(t)\\)导数的最高阶次。 令\\(y''(t) = a\\delta''(t)+b\\delta'(t)+c\\delta(t)+r_0(t)\\)（其中\\(r_0(t)\\)是指不含\\(\\delta(t)\\)及其各阶导数的项，在第四步中的积分，由于不含这些项，所以是\\(0\\)），对\\(y''(t)\\)进行积分（从\\(-\\infty\\)到\\(t\\)），求得\\(y'(t),y(t)\\)。 将\\(y'',y',y\\)代入微分方程，根据等号两端各奇异函数的系数相等，从而求得各个待定系数。 分别对\\(y',y''\\)等号两端从\\(0_-\\)到\\(0_+\\)积分，求得\\(0_+\\)值 用这种方法能对上式较好的求解。\n必须要提到的一点是，设\\(g(f) = \\int^{0_+}_{0_-}f(x)dx\\)，应该只有\\(f(x)=\\delta(x)\\)（不考虑常数系数），才有\\(g(f)=1\\)，其他全部都有\\(g(f)=0\\)。或许有其他函数也满足\\(g(f)\\neq 0\\)，但是在信号这里，所有连续的函数、阶跃函数、冲激函数的导数、二阶导数、\\(n\\)阶导数\\(g(f)\\)都等于\\(0\\)，只有冲激函数自己等于\\(1\\)。\n零输入响应 记作\\(y_{zi}\\)，对应齐次微分方程的解。故不存在跃变。\n零状态响应 记作\\(y_{zs}\\)，对应非齐次方程的解，需要求出来齐次解和特解，再加起来。最后的全响应需要将零输入和零状态加起来。注意零输入和零状态都要求一个齐次解，虽然它们形式相同，但是系数可能不同。\n有一种投机取巧的办法求全响应就是用电路课中介绍的三要素法。\n响应分类 响应可以分为固有响应和强迫响应\n固有响应仅与系统本身的特性有关，而与激励的函数形式无关。是微分方程的齐次解。\n强迫响应与激励的函数形式有关。是微分方程的特解。\n响应可以分为暂态响应和稳态响应\n暂态响应是指响应中暂时出现的分量，随着时间的增长，它将消失。\n稳态响应是稳定的分量，若存在，通常表现为阶跃函数和周期函数。比如，电路系统中的直流稳态响应和正弦稳态响应。\n微分方程求冲激响应 例如我们有\\(y''+a_1y'+a_0y' = b_2f''+b_1f'+b_0f\\)，我们可以分两步进行\n选择一个响应\\(h_1(t)\\)，使得 \\[h_1''+a_1h_1'+a_0h_1 = \\delta \\]\n\\[h_1(0_-)=h_1'(0_-) = 0 \\]\n计算出\\(h_1(0_+),h_1'(0_+)\\)，然后我们使用之前提到的解法求出\\(h_1\\)，不过显然这里特解为\\(0\\)，和齐次解具有同样的形式。冲激响应求的是一种零状态响应，虽然它和齐次解有同样的形式。\n根据线性性质和微分特性，可知\\(h = b_2h_1''+b_1h_1'+b_0h_1\\)。不过注意这个\\(b_i\\)是常数，如果我们等式右边是\\(b_2f''+b_0f+q\\)，这个\\(q\\)不是\\(f\\)的导数（其他情况类似），则我们的\\(h=b_2h_1''+b_0h_1+q*h_1\\)。当然你也可以全部都做卷积，只是不是把\\(b_2,b_1,b_0\\)拿来做卷积，而是把整体的\\(b_2f'',b_1f',b_0f\\)拿来做卷积。如果\\(f=h\\)，卷积的结果就是\\(b_2h_1''+b_1h_1'+b_0h_1\\) 当然我强烈推荐你用拉普拉斯变换来算。\n微分方程求阶跃响应 类似的，还是上面那个例子\n选择一个响应\\(g_1(t)\\)，使得 \\[g_1''+a_1g_1'+a_0g_1 = \\varepsilon \\]\n\\[g_1(0_-)=g_1'(0_-) = 0 \\]\n计算出\\(g_1(0_+),g_1'(0_+)\\)，然后我们使用之前提到的解法求出\\(g_1\\)。阶跃响应求的是一种零状态响应，它有特解和齐次解。\n根据线性性质和微分特性，可知\\(g = b_2g_1''+b_1g_1'+b_0g_1\\) 或者，如果我们已知冲激响应，我们有更简单的办法，由于微积分特性，我们可以求出\n\\[g(t) = \\int^t_{-\\infty} h(\\tau)d\\tau \\]\n同理\n\\[h(t) = g'(t) \\]\n用差分方程描述的离散因果线性时不变系统 差分方程 一般形式为\n\\[y[k]+a_{n-1}y[k-1]+\\cdots+a_0y[k-n] = b_mf[k]+\\cdots+b_0f[k-m] \\]\n和微分方程相似，差分方程的解也可以分为\\(y = y_h+y_p\\)\n齐次解也是由齐次方程求特征根得到。\n对于每一个\\(\\lambda_i\\)，\n如果它是单实根，则 \\[y_h = C\\lambda^k \\]\n如果它是二重实根，则 \\[y_h = (C_1k+C_0)\\lambda^k \\]\n如果是一对共轭复根\\(\\lambda_{1,2} = \\alpha\\pm j\\beta\\)，则 \\[\\rho^k[C\\cos(\\beta k)+D\\sin(\\beta k)] \\]\n整个齐次解就是把这些对于每一个\\(\\lambda_i\\)的齐次解加起来，再根据条件求出待定系数。\n特解的常见形式为\n激励为\\(f[k]=k\\)时，如果所有的特征根均不等于\\(1\\)， \\[P_1 k+P_0 \\]\n如果有\\(1\\)个等于\\(1\\)的特征根，\n\\[k(P_1k+P_0) \\]\n激励为\\(f[k]=a^k\\)，如果\\(a\\)不等于特征根 \\[Pa^k \\]\n如果\\(a\\)等于特征根\n\\[(P_1k+P_0)a^k \\]\n激励为\\(cos(\\beta k)\\)或\\(\\sin(\\beta k)\\)，如果所有的特征根都不等于\\(e^{\\pm j\\beta}\\) \\[P\\cos(\\beta k) + Q\\sin(\\beta k) \\]\n这个通常可以把\\(y_p\\)直接代入原方程求解系数。\n激励为\\(\\delta,\\varepsilon\\)时。如果只有\\(\\varepsilon\\)，则我们直接设置\\(y[k]\\)为常数，与连续的情况不同，差分不会使得\\(y[k-1]\\)等于零。解出的特解就是\\(y\\)的各项系数之和分之\\(\\varepsilon\\)的系数之和（我确定这个在激励只有\\(\\varepsilon[k]\\)的时候是成立的，如果有\\(\\varepsilon[k-1]\\)等东西成不成立我不确定，没找到网上和教材中讨论这个）。如果只有\\(\\delta\\)，则实际上是在求冲激响应，由后面可得，就是在求齐次解形式的解，不存在特解。如果两个都有，只管\\(\\varepsilon\\)（这是我的猜测，没找到教材讨论这个，我们或许还可以考虑\\(\\delta[k]=\\varepsilon[k]-\\varepsilon[k-1]\\)）。 注意，如果题目给的条件是\\(y[k],y[k-1]\\)等条件，我们需要在全解中去求齐次解中设的参数。如果题目给的条件是\\(y_{zi}[k],y_{zi}[k-1]\\)等条件，我们在齐次解中求参数即可。\n零输入响应 同前\n零状态响应 同前\n差分方程求单位脉冲响应 例如\\(y[k]-4y[k-1]+3y[k-2]=3f[k]-f[k-1]\\)，我么可以首先\n\\[h[k]-4h[k-1]+3h[k-2]=3\\delta[k]-\\delta[k-1] \\]\n由隐含条件（二阶下），\\(h[-1]=h[-2]=0\\)，又由上式，我们可以求出\\(h[0],h[1]\\)。再对上式用传统方法求出齐次解。\n由于代入求解参数时代入的是\\(h[0],h[1]\\)，对于\\(k=1,k=0\\)时方程也成立（实际上单位脉冲响应和零输入响应、齐次解具有同样的形式，不需要特解），所以单位脉冲响应就是\\(h[k] = [-1+4(3)^k]\\varepsilon[k]\\)\n当然，如果等式右边出现的是\\(f[k-2]+f[k-1]\\)这样的，我们就要求出\\(h[2],h[1]\\)，然后用这个代入求解齐次解的参数。\n或者我们还是用老办法，求出\\(h_1[k]-4h_1[k-1]+3h_1[k-2]=\\delta[k]\\)，中\\(h_1[k]\\)的表达式（需要用\\(h[0],h[-1]\\)求出参数），然后在根据线性性质求出\\(h[k]\\)\n差分方程求单位阶跃响应 阶跃响应和差分方程的全解是一个形式。我们求出全解即可。注意隐含条件（二阶下）是\\(g[-1]=g[-2]=0\\)，我们可以求出\\(g[0],g[1]\\)，代入求出参数。\n或者由差分特性\n\\[g[k] = \\sum^k_{i=-\\infty}h[i] \\]\n同理有\n\\[h[k] = g[k] - g[k-1] \\]\n用方框图描述LTI 不做细致介绍（主要是我懒，但这玩意其实很浅显，做一两题就会列表达式了，会不会解题另说），注意级联的时候\\(h(t)\\)之间用卷积，\\(H(jw)\\)用乘号即可。有时会用上设中间变量的方法。\n奇异函数 对于连续情况\n\\[x(t) = x(t) * \\delta(t) \\]\n\\[x'(t) = x(t)*\\delta '(t) \\]\n\\[x''(t) = x(t) * \\delta ''(t) = x(t) * \\delta '(t) * \\delta '(t) \\]\n以此类推。而\n\\[x(t) * u(t) = \\int^t_{-\\infty}x(\\tau)d\\tau \\]\n也可以以此类推。\n其中\\(u(t)*u(t) = tu(t)\\)称为单位斜坡函数。\n此外还有\n\\[f(t)\\delta(t)=f(0)\\delta(t) \\]\n\\[\\int^{+\\infty}_{-\\infty}f(t)\\delta(t)dt=f(0) \\]\n\\[f(t)\\delta(t-a) = f(a)\\delta(t-a) \\]\n\\[\\int^{+\\infty}_{-\\infty}f(t)\\delta(t-a)dt = f(a) \\]\n\\[f(t)\\delta'(t) = f(0)\\delta'(t)-f'(0)\\delta(t) \\]\n\\[\\int^{+\\infty}_{-\\infty}f(t)\\delta'(t)dt = -f'(0) \\]\n\\[\\int^{+\\infty}_{-\\infty}f(t)\\delta'(t-a)dt = -f'(a) \\]\n\\[\\int^{+\\infty}_{-\\infty}f(t)\\delta^{(n)}(t)dt = (-1)^nf^{(n)}(0) \\]\n\\[\\delta(at) = \\dfrac{1}{|a|}\\delta(t) \\]\n\\[\\delta^{(n)}(at) = \\dfrac{1}{|a|}\\dfrac{1}{a^n}\\delta^{(n)}(t) \\]\n\\[\\delta^{(n)}(-t)=(-1)^n\\delta^{(n)}(t) \\]\n对于离散情况\n\\[f[k]*\\delta[k] = f[k] \\]\n\\[f[k]*\\delta[k-k_0] = f[k-k_0] \\]\n\\[f[k]*\\varepsilon[k] = \\sum^k_{i=-\\infty}f[i] \\]\n此外还有\n\\[f[k]\\delta[k] = f[0]\\delta[k] \\]\n\\[f[k]\\delta[k-k_0] = f[k_0]\\delta[k-k_0] \\]\n\\[\\sum^{+\\infty}_{k=-\\infty}\\delta[k] = 1 \\]\n\\[\\sum^{+\\infty}_{k=-\\infty}f[k]\\delta[k] = f[0] \\]\n\\[\\sum^{+\\infty}_{k=-\\infty}f[k]\\delta[k-k_0] = f[k_0] \\]\n\\[\\sum^{k}_{i=-\\infty}\\delta[i] = \\varepsilon[k] \\]\n\\[\\delta[k] = \\varepsilon[k]-\\varepsilon[k-1] \\]\n\\[\\delta[k] = \\delta[-k] \\]\n相关函数 实函数\\(f_1(t)\\)和\\(f_2(t)\\)，如为能量有限信号，它们之间的互相关函数定义为：\n\\[R_{12}(\\tau) = \\int^{+\\infty}_{-\\infty}f_1(t)f_2(t-\\tau)dt = \\int^{+\\infty}_{-\\infty}f_1(t+\\tau)f_2(t)dt \\]\n\\[R_{21}(\\tau) = \\int^{+\\infty}_{-\\infty}f_1(t-\\tau)f_2(t)dt = \\int^{+\\infty}_{-\\infty}f_1(t)f_2(t+\\tau)dt \\]\n一般两者不相等，但是有\\(R_{12}(\\tau) = R_{21}(-\\tau)\\)\n如果\\(f_1,f_2\\)是同一个函数，那么无须区分二者，直接用\\(R\\)表示自相关系数，\n\\[R(\\tau) = \\int^{+\\infty}_{-\\infty}f(t+\\tau)f(t)dt = \\int^{+\\infty}_{-\\infty}f(t)f(t-\\tau)dt \\]\n此时\\(R(\\tau)=R(-\\tau)\\)\n这东西和卷积的形式很像，显然我们可以推出来\n\\[R_{12} = f_1(t)*f_2(-t) \\]\n周期信号的傅里叶级数表示 信号的正交分解 LTI对复指数信号的响应 LTI对复指数信号的响应也是一个复指数信号，不同的只是在幅度上的变化\n\\[e^{st}\\rightarrow H(s)e^{st} \\]\n\\[z^n = H(z)z^n \\]\n上面\\(s,z\\)是复数，我们更多讨论\\(s=jw,z=e^{jw}\\)的情况。\n其中\\(H\\)是一个复振幅因子。\n一个信号，如果系统对该信号的输出响应仅是一个常数（可能是复数）乘以输入，那么这个信号就是这个系统的特征函数，幅度因子称为特征值。\n如果将输入信号表示为傅立叶级数\n\\[x(t) = \\sum_ka_ke^{s_kt} \\]\n则响应一定是\n\\[y(t) = \\sum_k a_kH(s_k)e^{s_kt} \\]\n离散情况下\n\\[x[n] = \\sum_ka_kz^n_k \\]\n\\[y[n] = \\sum_k a_kH(z_k)z^n_k \\]\n连续时间周期信号的傅里叶级数表示 \\[x(t) = \\sum^{+\\infty}_{k=-\\infty}a_ke^{jkw_0t} = \\sum^{+\\infty}_{k=-\\infty}a_ke^{jk(2\\pi/T)t} \\]\n\\(k=0\\)的一项是一个常数，\\(k=\\pm 1\\)的两项合称为基波分量，也称为一次谐波分量，之后类推。\n也可以写作\n\\[x(t) = a_0 + 2\\sum^\\infty_{k=1}[B_k\\cos kw_0 t - C_k\\sin kw_0t] \\]\n或者\n\\[x(t) = \\dfrac{a_0}{2}+\\sum^\\infty_{n=1}a_n\\cos(n\\Omega t)+\\sum^\\infty_{n=1}b_n\\sin(n\\Omega t) = \\dfrac{A_0}{2} + \\sum^\\infty_{n=1}A_n\\cos(n\\Omega t+\\varphi_n) \\]\n其中（指数表示的那个）\\(a_n\\)由以下公式确定\n\\[a_n = \\dfrac{1}{T}\\int^T_0x(t)e^{-jnw_0t}dt \\]\n或者也可以是在任意一个最小正周期内的积分，记作\\(\\int_T\\)\n\\(a_n\\)称为傅里叶级数系数或频谱系数，\\(a_0\\)为直流或常数分量。\n傅立叶级数的收敛 条件1\n在任何周期内，\\(x(t)\\)必须绝对可积，即\n\\[\\int_T|x(t)|dt\u003c\\infty \\]\n这也保证了平方可积，也就保证了能量有限，每一个系数有限。\n条件2\n在任意有限区间内，\\(x(t)\\)具有有限个起伏变化。也就是说，在任何单个周期内，\\(x(t)\\)的最大值和最小值的数目有限。\n条件3\n在\\(x(t)\\)的任何有限区间内，只有有限个不连续点，而且在这些不连续点上，函数是有限值。\n在这些不连续点上，傅里叶级数收敛到不连续点处的平均值。\n连续时间傅里叶级数的性质 首先设\\(x(t),y(t)\\)的周期都为\\(T\\)，傅立叶系数为\\(a_k,b_k\\)\n线性\n\\[Ax(t)+By(t)\\leftrightarrow Aa_k+Bb_k \\]\n时移\n\\[x(t-t_0) \\leftrightarrow a_ke^{-jkw_0t_0} = a_ke^{-jk(2\\pi/T)t_0} \\]\n频移\n\\[e^{jMw_0t}x(t) = e^{jM(2\\pi/T)t}x(t) \\leftrightarrow a_{k-M} \\]\n共轭\n\\[x^*(t) = a^*_{-k} \\]\n时间反转\n\\[x(-t) = a_{-k} \\]\n时域尺度变换\n\\[x(\\alpha t),\\alpha \u003e0(周期为T/\\alpha) \\leftrightarrow a_k \\]\n周期卷积\n\\[\\int_Tx(\\tau)y(t-\\tau)d\\tau\\leftrightarrow Ta_kb_k \\]\n相乘\n\\[x(t)y(t) \\leftrightarrow a_k*b_k \\]\n微分\n\\[\\dfrac{dx(t)}{dt} \\leftrightarrow jkw_0a_k=jk\\dfrac{2\\pi}{T}a_k \\]\n积分\n\\[\\int^t_{-\\infty} x(t)dt \\leftrightarrow \\dfrac{1}{jkw_0}a_k = \\dfrac{1}{jk(2\\pi/T)}a_k \\]\n周期信号的帕塞瓦尔定理\n\\[\\dfrac{1}{T}\\int_T|x(t)|^2 dt = \\sum^{+\\infty}_{k=-\\infty}|a_k|^2 \\]\n谐波特性 偶函数\n如果\\(x(t)\\)是偶函数，则其没有正弦分量，只有余弦分量和直流分量。\n奇函数\n如果\\(x(t)\\)是奇函数，则其没有余弦分量和直流分量，只有正弦分量。\n奇谐函数\n傅里叶级数中只含有奇次谐波分量，不含有偶次谐波分量，即\n\\[a_0=a_2=a_4=\\cdots=b_2=b_4=\\cdots=0 \\]\n表现为\\(x(t) = -x(t\\pm T/2)\\)\n偶谐函数\n傅里叶级数中只含有偶次谐波分量，不含有奇次谐波分量，即\n\\[a_1=a_3=\\cdots=b_1=b_3=\\cdots=0 \\]\n表现为\\(x(t) = x(t\\pm T/2)\\)\n离散时间周期信号的傅里叶级数表示 离散时间周期信号的傅里叶级数是有限项级数，而连续情况下是无穷级数。所以离散情况下不存在收敛的问题。\n离散情况下，周期N满足\n\\[x[n] = x[n+N] \\]\n其中最小的正整数\\(N\\)对应的角频率称为基波频率。\n\\(x[n]\\)的傅里叶级数表示为\n\\[x[n] = \\sum_k a_ke^{jkw_0n} = \\sum_ka_ke^{jk(2\\pi/N)n} \\]\n其中这个求和是，k在任意连续\\(N\\)个数中都成立的。所以也可以记作\n\\[x[n] = \\sum_{k= \u003c N \u003e }a_ke^{jkw_0n} \\]\n\\(a_k\\)由以下公式确定\n\\[a_k = \\dfrac{1}{N}\\sum_{n= \u003c N \u003e }x[n]e^{-jkw_0n} = \\dfrac{1}{N}\\sum_{n= \u003c N \u003e }x[n]e^{-jk(2\\pi/N)n} \\]\n离散时间傅里叶级数的性质 整体和连续的情况差别不大。\n首先设\\(x[n],y[n]\\)的周期都为\\(N\\)，傅立叶系数为\\(a_k,b_k\\)，系数是周期的，周期也为\\(N\\)\n线性\n\\[Ax[n]+By[n]\\leftrightarrow Aa_k+Bb_k \\]\n时移\n\\[x[n-n_0] \\leftrightarrow a_ke^{-jk(2\\pi/N)n_0} \\]\n频移\n\\[e^{jM(2\\pi/N)n}x[n]\\leftrightarrow a_{k-M} \\]\n共轭\n\\[x^*[n] = a^*_{-k} \\]\n时间反转\n\\[x[-n] = a_{-k} \\]\n时域尺度变换\n\\[x_{(m)}[n] = \\begin{cases} x[n/m] \u0026 n是m的倍数\\\\ 0 \u0026 n不是m的倍数 \\end{cases} \\leftrightarrow \\dfrac{1}{m}a_k,周期为mN \\]\n周期卷积\n\\[\\sum_{r= \u003c N \u003e }x[r]y[n-r]\\leftrightarrow Na_kb_k \\]\n相乘\n\\[x[n]y[n] \\leftrightarrow \\sum_{l= \u003c N \u003e }a_l b_{k-l} \\]\n差分\n\\[x[n]-x[n-1] \\leftrightarrow (1-e^{-jk(2\\pi/N)})a_k \\]\n求和\n\\[\\sum^n_{k=-\\infty}x[n](仅当a_0=0才为有限的且为周期的)\\leftrightarrow \\bigg(\\dfrac{1}{1-e^{-jk(2\\pi/N)}}\\bigg)a_k \\]\n周期信号的帕塞瓦尔定理\n\\[\\dfrac{1}{N}\\sum_{n= \u003c N \u003e }|x[n]|^2 = \\sum_{k= \u003c N \u003e }|a_k|^2 \\]\n傅里叶级数与LTI 若\\(x(t)=e^{st}\\)是一个连续时间线性时不变系统的输入，其输出就为\\(y(t)=H(s)e^{st}\\)，而\n\\[H(s) = \\int^{+\\infty}_{-\\infty} h(\\tau)e^{-s\\tau}d\\tau \\]\n其中\\(h(\\tau)\\)是该线性时不变系统的单位冲激响应（这其实是\\(h(t)\\)的傅立叶变换）。\n同理离散情况下\\(x[n]=z^n\\)，\\(y[n]=H(z)z^n\\)\n\\[H(z) = \\sum^{+\\infty}_{k=-\\infty}h[k]z^{-k} \\]\n当\\(s,z\\)是一般复数时，\\(H(s),H(z)\\)就称为该系统的系统函数。一般我们考虑\\(s=jw,z=e^{jw}\\)，此时\\(H(s),H(z)\\)称为频率响应。\n此时我们可以说\n若用傅里叶级数表示输入\n\\[x(t) = \\sum^{+\\infty}_{k=-\\infty}a_ke^{jkw_0t} \\]\n则输出为\n\\[y(t) = \\sum^{+\\infty}_{k=-\\infty}a_kH(jkw_0)e^{jkw_0t} \\]\n此时\\(y(t)\\)也是周期的，并且与\\(x(t)\\)有相同的基波频率。若\\(a_k\\)是\\(x(t)\\)的傅立叶系数，那么\\(a_kH(jkw_0)\\)就是\\(y(t)\\)的傅里叶系数。\n离散情况下，若用傅里叶级数表示输入\n\\[x[n] = \\sum_{k= \u003c N \u003e } a_ke^{jk(2\\pi/N)n} \\]\n那么输出为\n\\[y[n] = \\sum_{k= \u003c N \u003e } a_kH(e^{j2\\pi k/N})e^{jk(2\\pi/N)n} \\]\n\\(y[n]\\)也是周期的，且和\\(x[n]\\)具有相同的周期，\\(y[n]\\)的第\\(k\\)个傅里叶系数就是\\(a_kH(e^{j2\\pi k/N})\\)\n周期信号的频谱 分为单边谱和双边谱。\n单边谱是对于三角函数形式展开的，\n\\[x(t) = \\dfrac{A_0}{2} + \\sum^\\infty_{n=1}A_n\\cos(n\\Omega t+\\varphi_n) \\]\n频谱分为两个函数图像，即\\(A_n\\sim\\omega\\)的幅度谱和\\(\\varphi_n\\sim\\omega\\)的相位谱（\\(\\omega=n\\Omega,n=0,1,2,\\cdots\\)）\n双边谱是对于指数形式展开的，\n\\[x(t) = \\sum^{+\\infty}_{k=-\\infty}a_ke^{jkw_0t} \\]\n频谱分为两个函数图像，即\\(|a_k|\\sim\\omega\\)的幅度谱和\\(\\varphi_k\\sim\\omega\\)的相位谱（\\(\\omega=k\\omega_0,\\varphi_k=k\\omega_0 t,k=0,\\pm1,\\pm2,\\cdots\\)）\n滤波 按我的理解，简单来说，就是弄一个系统，使得它的频率响应\\(H(jw)\\)弄成你想要滤波的效果。\n比如，你想要弄一个理想低通滤波器，那么你就设计一个系统，使得其\n\\[H(jw) = \\begin{cases} 1 \u0026 \\text{ if } |w|\\leq w_c \\\\ 0 \u0026 \\text{ if } |w| \u003ew_c \\end{cases} \\]\n这样输出\\(y(t)=H(jw)x(t)\\)，就只会保留\\(x(t)\\)中频率在\\([-w_c,w_c]\\)之间的部分。\n连续时间傅里叶变换 非周期信号的表示 可以把非周期信号当成一个周期信号在周期任意大时的极限。\n设\\(\\tilde x(t)\\)是一个周期信号，而\\(x(t)\\)是这个周期信号的其中一个周期，其他部分全为\\(0\\)，那么（方便起见取周期\\([-T/2,T/2]\\)）\n\\[a_k = \\dfrac{1}{T}\\int^{T/2}_{-T/2}x(t)e^{-jkw_0t}dt = \\dfrac{1}{T}\\int^{+\\infty}_{-\\infty}x(t)e^{-jkw_0t}dt \\]\n定义\\(Ta_k\\)的包络\\(X(jw)\\)为\n\\[X(jw) = \\int^{+\\infty}_{-\\infty}x(t)e^{-jwt}dt \\]\n则\n\\[a_k= \\dfrac{1}{T}X(jkw_0) \\]\n然后我们就可以用上式去表示\\(\\tilde{x}(t)\\)，当周期无限大时，表示\\(x(t)\\)如下\n\\[x(t) = \\dfrac{1}{2\\pi}\\int^{+\\infty}_{-\\infty}X(jw)e^{jwt}dw \\]\n\\[X(jw) = \\int^{+\\infty}_{-\\infty}x(t)e^{-jwt}dt \\]\n这两个式子称为傅立叶变换对。\\(X(jw)\\)称为\\(x(t)\\)的傅里叶变换，也称为\\(x(t)\\)的频谱。\n傅立叶变换的收敛 和之前一样\n\\(\\int^{+\\infty}_{-\\infty}|x(t)|dt\u003c\\infty\\) 任何有限区间内，\\(x(t)\\)只有有限个最大值和最小值 任何有限区间内，\\(x(t)\\)有有限个不连续点，并且在每个不连续点处都必须是有限值。 但有些函数其实不满足，也可以收敛，有傅里叶变换，比如阶跃函数。\n周期信号的傅立叶变换 \\[x(t) = \\sum^{+\\infty}_{k=-\\infty}a_ke^{jkw_0t} \\]\n\\[X(jw) = \\sum^{+\\infty}_{k=-\\infty}2\\pi a_k\\delta(w-kw_0) \\]\n连续时间傅里叶变换的性质 设非周期信号\\(x(t),y(t)\\)，傅立叶变换分别为\\(X(jw),Y(jw)\\)\n线性\n\\[ax(t)+by(t)\\leftrightarrow aX(jw)+bY(jw) \\]\n时移\n\\[x(t-t_0)\\leftrightarrow e^{-jwt_0}X(jw) \\]\n频移\n\\[e^{jw_0t}x(t)\\leftrightarrow X(j(w-w_0)) \\]\n共轭\n\\[x^*(t)\\leftrightarrow X^*(-jw) \\]\n时间反转\n\\[x(-t)\\leftrightarrow X(-jw) \\]\n如果\\(x(t)\\)为实函数，\\(x(-t)\\leftrightarrow X(-jw) = X^*(jw)\\)\n如果\\(x(t)\\)为虚函数\\(jg(t)\\)，\\(x(-t)\\leftrightarrow X(-jw) = -X^*(jw)\\)\n尺度变换\n\\[x(at)\\leftrightarrow\\dfrac{1}{|a|}X(\\dfrac{jw}{a}) \\]\n卷积\n\\[x(t)*y(t)\\leftrightarrow X(jw)Y(jw) \\]\n相乘\n\\[x(t)y(t)\\leftrightarrow \\dfrac{1}{2\\pi} X(jw)*Y(jw) \\]\n时域微分\n\\[\\dfrac{d^n}{dt^n}x(t)\\leftrightarrow (jw)^nX(jw) \\]\n积分\n\\[\\int^t_{-\\infty}x(t)dt\\leftrightarrow \\dfrac{1}{jw}X(jw)+\\pi X(0)\\delta(w) \\]\n频域微分\n\\[tx(t)\\leftrightarrow j\\dfrac{d}{dw}X(jw) \\]\n\\[(-jt)^nx(t)\\leftrightarrow X^{(n)}(jw) \\]\n频域积分\n\\[\\dfrac{1}{-jt}x(t)+\\pi x(0)\\delta(t)\\leftrightarrow \\int^w_{-\\infty}X(jx)dx \\]\n非周期信号的帕塞瓦尔定理\n\\[\\int^{+\\infty}_{-\\infty}|x(t)|^2dt=\\dfrac{1}{2\\pi}\\int^{+\\infty}_{-\\infty}|X(jw)|^2dw \\]\n对称\n\\[X(jt)\\leftrightarrow 2\\pi x(-w) \\]\n相关定理\n前面我们介绍过相关函数，有\n\\[R_{12}(t) = x_1(t)*x_2(-t) \\]\n\\[R_{21}(t) = x_2(t)*x_1(-t) \\]\n\\[R(t) = x(t)*x(-t) \\]\n我们有\n\\[R_{12}(t)\\leftrightarrow X_1(jw)X_2^*(jw) \\]\n\\[R_{21}(t)\\leftrightarrow X_2(jw)X_1^*(jw) \\]\n\\[R(\\tau)\\leftrightarrow |X(jw)|^2 \\]\n基本傅立叶变换对 \\[\\sum^{+\\infty}_{k=-\\infty}a_k e^{jkw_0t}\\leftrightarrow 2\\pi\\sum^{+\\infty}_{k=-\\infty}a_k\\delta(w-kw_0) \\]\n\\[e^{jkw_0t}\\leftrightarrow 2\\pi\\delta(w-kw_0) \\]\n\\[cos(w_0t)\\leftrightarrow\\pi[\\delta(w-w_0)+\\delta(w+w_0)] \\]\n\\[sin(w_0t)\\leftrightarrow \\dfrac{\\pi}{j}[\\delta(w-w_0)-\\delta(w+w_0)] \\]\n\\[x(t)=1\\leftrightarrow 2\\pi\\delta(w) \\]\n\\[g_\\tau(t)\\leftrightarrow \\tau Sa(\\dfrac{w\\tau}{2}) \\]\n\\[sgn(t)\\leftrightarrow \\dfrac{2}{jw} \\]\n\\[\\delta(t)\\leftrightarrow 1 \\]\n\\[\\delta^{(n)}\\leftrightarrow(jw)^n \\]\n\\[u(t)\\leftrightarrow\\dfrac{1}{jw}+\\pi\\delta(w) \\]\n\\[e^{-\\alpha t}\\varepsilon(t)\\leftrightarrow\\dfrac{1}{\\alpha+jw},\\alpha\u003e0 \\]\n\\[e^{-\\alpha |t|}\\leftrightarrow\\dfrac{2\\alpha}{\\alpha^2+w^2},\\alpha\u003e0 \\]\n其中\n\\(sgn(t)\\)是符号函数，\\(Sa(\\theta)=sin\\theta/\\theta\\)，\\(g_\\tau(t)\\)代表门函数，即在\\([-\\tau/2,\\tau/2]\\)的范围内取\\(1\\)，其他范围内取\\(0\\)。\n阶跃函数此时可以表示为\\(\\varepsilon(t) = \\dfrac{1}{2}[1+sgn(t)]\\)\n线性常系数微分方程表征的系统 线性常系数微分方程有如下形式\n\\[\\sum^N_{k=0}a_k\\dfrac{d^k y(t)}{dt^k} = \\sum^m_{k=0}b_k\\dfrac{d^k x(t)}{dt^k} \\]\n我们可以像之前一样用经典方法去解输入对应的输出（零状态响应）。但是我们也可以使用频率响应来求出。\n如果我们有\\(x(t)=e^{jwt}\\)，则系统的输入就是\\(y(t)=H(jw)e^{jwt}\\)。\n一个事实是，\\(H(jw)\\leftrightarrow h(t)\\)。我们之前还说过，\\(y(t)=h(t)*x(t)\\)，我们就可以得到\\(Y(jw)=H(jw)X(jw)\\)。\n或者我们有\n\\[H(jw) = \\dfrac{Y(jw)}{X(jw)} = \\dfrac{\\sum^M_{k=0}b_k(jw)^k}{\\sum^{N}_{k=0}a_k(jw)^k} \\]\n其中第二个等号后面的式子可以把微分方程的两边全部取傅立叶变换，再提项得到。\n有了\\(H(jw)\\)，我们就容易求出对于任意一个输入信号\\(f(t)\\)，这个系统的零状态响应。\n要么我们可以\\(Y(jw)=H(jw)F(jw)\\)再傅立叶逆变换得到\\(y(t)\\)，要么\\(y(t)=H(jw)f(t)\\)。\n\\(H(jw)\\)一般是复函数，记为\n\\[H(jw)=|H(jw)|e^{j\\theta(w)} \\]\n其中\\(|H(jw)|\\)称为幅频特性或者幅频响应，是\\(w\\)的偶函数。\n\\(\\theta(w)\\)称为相频特性或相频响应，是\\(w\\)的奇函数。\n当然，我们可以直接在微分方程转变为\\(Y(jw)=aX(jw)\\)（\\(a\\)是某个系数）后，直接将两边傅立叶逆变换得到\\(y(t)\\)而不用先得到\\(H(jw)\\) 。\n再次提醒，傅里叶变换只能求零状态响应。想要求出零输入响应和全响应，用后面介绍的拉普拉斯变换。\n傅立叶变换与电路 虽然书上没说，但我觉得电阻、电容、电感也可以有傅立叶变换的模型。但是这样就无法求初始值了，还是用拉普拉斯变换吧，见后。\n帕塞瓦尔能量方程 \\[E = \\lim_{T\\to\\infty}\\int^T_{-T}|f(t)|^2dt = \\int^\\infty_{-\\infty}|f(t)|^2dt = \\dfrac{1}{2\\pi}\\int^\\infty_{-\\infty}|F(jw)|^2dw \\]\n能量频谱 \\[\\mathcal{E}(w) = |F(jw)|^2 \\]\n根据前面的相关定理，我们可以得到\n\\[R(\\tau)\\leftrightarrow \\mathcal{E}(w) \\]\n即能量信号的自相关函数与其能量谱是一对傅里叶变换。\n频带宽度 在满足一定失真条件下，信号可以用某段频率范围的信号来表示，此频率范围称为频带宽度。\n信号频谱的距离原点最近的两个零点之间集中了信号的绝大部分能量。信号的功率集中在低频段。\n一般把第一个零点作为信号的频带宽度 对于一般周期信号，将幅度下降为\\(\\dfrac{1}{10}|F_n|_{\\text{max}}\\)的频率定义为频带宽度 系统的通频带\\(\u003e\\)信号的带宽，才能不失真。 无失真传输 信号无失真传输是指系统的输出信号与输入信号相比，只有幅度的大小和出现时间的先后不同，而没有波形上的变化。\n其条件为\n对于系统的\\(h(t)\\)，\\(h(t)=K\\delta(t-t_d)\\)\n或者对于系统的\\(H(jw)=Ke^{-jwt_d}\\)\n功率频谱 \\[P = \\lim_{T\\to\\infty}\\dfrac{1}{T}\\int_T f^2(t)dt = \\dfrac{1}{2\\pi}\\int^\\infty_{-\\infty}\\lim_{T\\to\\infty}\\dfrac{|F_T(jw)|^2}{T}dw \\]\n记\n\\[\\mathcal{P}(w) = \\lim_{T\\to\\infty}\\dfrac{|F_T(jw)|^2}{T} \\]\n也可以证明\n\\[R(\\tau)\\leftrightarrow\\mathcal{P}(w) \\]\n即功率信号的自相关函数与其功率谱是一对傅里叶变换。\n物理可实现条件 一个系统要在物理上可以实现，要求\n时域特性\n\\(h(t)=0,t\u003c0\\)，也就是要求是因果系统。响应不应出现在激励之前。\n频域特性\n\\[\\int ^{+\\infty}_{-\\infty} |H(jw)^2|dw\u003c\\infty\\quad \\text{and}\\quad \\int ^{+\\infty}_{-\\infty} \\dfrac{|\\ln |H(jw)||}{1+w^2}dw\u003c\\infty \\]\n这称为佩利-维纳准则，这是一个必要条件。\n对于物理可实现系统,可以允许\\(H(jw)\\)特性在某些不连续的频率点上为\\(0\\)，但不允许在一个有限频带内为\\(0\\)。\n佩利-维纳准则要求可实现的幅度特性其总的衰减不能过于迅速；\n离散时间傅里叶变换 信号与系统的时域和频域特性 采样 冲激串采样 周期冲激串\\(p(t)\\)称为采样函数，周期\\(T\\)称为采样周期，而\\(p(t)\\)的基波频率\\(w_s=2\\pi/T\\)称为，采样频率。\n在时域中有\n\\[x_p(t) = x(t)p(t) \\]\n其中\n\\[p(t) = \\sum^{+\\infty}_{n=-\\infty}\\delta(t-nT) \\]\n经过计算可以得到，频域中有\n\\[X_p(jw) = \\dfrac{1}{T}\\sum^{+\\infty}_{k=-\\infty}X(j(w-kw_s)) \\]\n采样定理 设\\(x(t)\\)是某一个带限信号，在\\(|w|\u003ew_M\\)时，\\(X(jw)=0\\)。如果采样频率\\(w_s\u003e2w_M\\)，其中\\(w_s=2\\pi /T\\)，那么\\(x(t)\\)就唯一地由其样本\\(x(nT),n=0,\\pm1,\\pm2,\\cdots\\)所确定\n在采样定理中，采样频率必须大于\\(2w_M\\)，该频率\\(2w_M\\)一般称为奈奎斯特速率。\n已知样本值，重建\\(x(t)\\)的方法：产生一个周期冲激串，其冲激幅度就是这些依次而来的样本值；然后将该冲激串通过一个增益为\\(T\\)，截止频率\\(w_c\\)大于\\(w_M\\)而小于\\(w_s-w_M\\)的理想低通滤波器，该滤波器的输出就是\\(x(t)\\)。\n这个滤波器的\\(h(t)\\)为\n\\[h(t) = T_s\\dfrac{w_c}{\\pi}Sa(w_ct) \\]\n其中\\(w_M\u003c w_c\u003c w_s-w_M\\)，方便起见常取\\(w_c=0.5w_s\\)\n此时\n\\[x(t) = \\sum^{+\\infty}_{n=-\\infty}x(nT_s)Sa[\\dfrac{w_s}{2}(t-nT_s)] \\]\n注意，你可能会奇怪式子里面的\\(T_s\\dfrac{w_c}{\\pi}\\)到哪里去了，实际上当\\(w_c=0.5w_s\\)时，因为\\(w_s=\\dfrac{2\\pi}{T_s}\\)，这个式子约分为\\(0\\)\n奈奎斯特速率的运算性质 假设\\(f(t)\\)的最高频率为\\(w_M\\)\n\\(f(at)\\)，则对应\\(w_M'=|a|w_M,w_s=2w'_M\\)\n\\(f_1(t)+f_2(t)\\)，则对应\\(w'_M=\\max{\\{w_{m1},w_{m2}\\}}\\)\n\\(f_1(t)\\ast f_2(t)\\)，则对应\\(w'_M=\\min{\\{w_{m1},w_{m2}\\}}\\)\n\\(f_1(t)f_2(t)\\)，则对应\\(w'_M=w_{m1}+w_{m2}\\)\n频率采样定理 一个在时域区间\\((-t_m,t_m)\\)以外为\\(0\\)的时限信号\\(f(t)\\)的频谱函数，可唯一地由其在均匀频率间隔\\(f_s\\)上的样值点\\(F(jnw_s)\\)确定。要求\\(f_s\u003c1/(2t_m)\\)，或者说\\(w_s\u003c2\\pi/(2t_m)\\)\n\\[F(jw) = \\sum^{+\\infty}_{n=-\\infty} F(j\\dfrac{n\\pi}{t_m})Sa(wt_m-n\\pi) \\]\n拉普拉斯变换 一个信号\\(x(t)\\)的拉普拉斯变换定义如下\n\\[X(s) = \\int^{+\\infty}_{-\\infty}x(t)e^{-st}dt \\]\n当然，傅立叶变换就是\\(s=jw\\)时的一个特例。\n复变量\\(s\\)可以写为\\(s=\\sigma+jw\\)，其中\\(\\sigma,w\\)分别是它的实部和虚部。方便起见\\(X(s)=\\mathcal{L}\\{x(t)\\}\\)，或者记作\n\\[x(t)\\overset{\\mathcal{L}}{\\longleftrightarrow} X(t) \\]\n因为\n\\[X(\\sigma+jw) = \\int^{+\\infty}_{-\\infty}x(t)e^{-(\\sigma+jw)t}dt = \\int^{+\\infty}_{-\\infty}[x(t)e^{-\\sigma t}]e^{-jwt}dt \\]\n所以\\(x(t)\\)的拉普拉斯变换可以看成\\(x(t)\\)乘以一个实指数信号以后的傅立叶变换。\n当然，正如傅立叶变换不是对所有信号都收敛，拉普拉斯变换对有些\\(Re\\{s\\}\\)收敛，而有些不收敛。\n拉普拉斯变换的有理分式情况 如果拉普拉斯变换具有以下形式\n\\[X(s) = \\dfrac{N(s)}{D(s)} \\]\n使得\\(N(s)=0\\)的\\(s\\)称为零点，使得\\(D(s)=0\\)的\\(s\\)称为极点。把这些点标记在复平面上。我们可以判断收敛域。极点用叉号表示，零点用圈圈表示。\n也可以通过零-极点图来反过来求拉普拉斯变换，这时你需要设\\(X(s)=\\dfrac{KN(s)}{D(s)}\\)，保留一个常系数\\(K\\)。然后根据题目的已知条件解出\\(K\\)。\n拉普拉斯变换的收敛域 收敛域记作\\(ROC\\)\n\\(X(s)\\)的收敛域在\\(s\\)平面内是由平行于\\(jw\\)轴的带状区域组成的。 对有理拉普拉斯变换来说，收敛域内不包括任何极点。 如果\\(x(t)\\)是有限持续期的，并且是绝对可积的，那么收敛域就是整个\\(s\\)平面。 如果\\(x(t)\\)是右边信号，并且\\(Re\\{s\\}=\\sigma_0\\)这条线位于收敛域内，那么\\(Re\\{s\\}\u003e\\sigma_0\\)的全部\\(s\\)值一定在收敛域内 如果\\(x(t)\\)是左边信号，并且\\(Re\\{s\\}=\\sigma_0\\)这条线位于收敛域内，那么\\(Re\\{s\\}\u003c\\sigma_0\\)的全部\\(s\\)值一定在收敛域内 如果\\(x(t)\\)是双边信号，并且\\(Re\\{s\\}=\\sigma_0\\)这条线位于收敛域内，那么收敛域就一定由\\(s\\)平面的一条带状区域组成，直线\\(Re\\{s\\}=\\sigma_0\\)位于该区域中。 如果\\(x(t)\\)的拉普拉斯变换\\(X(s)\\)是有理的，那么它的收敛域是被极点所界定的或延伸到无限远。另外，在收敛域内不包含任何极点。 如果\\(x(t)\\)的拉普拉斯变换\\(X(s)\\)是有理的，若\\(x(t)\\)是右边信号，那么收敛域在\\(s\\)平面上位于最右边极点的右边；若\\(x(t)\\)是左边信号，那么收敛域在\\(s\\)平面上位于最左边极点的左边 拉普拉斯逆变换 \\[x(t) = \\dfrac{1}{2\\pi j}\\int^{\\sigma+j\\infty}_{\\sigma-j\\infty}X(s)e^{st}dt \\]\n显然不太可能用这玩意去算，大部分时候我们都用后面的常用变换对来算。\n如果\\(X(s)\\)是一个有理分式，则我们要做的就是将他拆开，为此我们可以使用待定系数法。\n例如\n\\[X(s) = \\dfrac{1}{x^2(x-1)} \\]\n我们就要拆成\n\\[X(s)=\\dfrac{a}{x}+\\dfrac{b}{x^2}+\\dfrac{c}{x-1} \\]\n然后根据系数关系求得待定系数的值。注意，这里\\(x^{-2}\\)要拆成两项，一项是\\(x^{-1}\\)，一项是\\(x^{-2}\\)，其他情况以此类推。\n（双边）拉普拉斯变换的性质 假设\\(x_1(t)\\leftrightarrow X_1(s),ROC=R_1\\)和\\(x_2(t)\\leftrightarrow X_2(s),ROC=R_2\\)\n线性\n\\[ax_1(t)+bx_2(t)\\leftrightarrow aX_1(s)+bX_2(s), ROC至少是R_1\\cap R_2 \\]\n时移\n\\[x(t-t_0)\\leftrightarrow e^{-st_0}X(s), ROC=R \\]\n\\(s\\)域平移\n\\[e^{s_0t}x(t)\\leftrightarrow X(s-s_0),ROC=R的平移 \\]\n时域尺度变换\n\\[x(at)\\leftrightarrow \\dfrac{1}{|a|}X(\\dfrac{s}{a}),ROC=R/a \\]\n共轭\n\\[x^*(t) \\leftrightarrow X^*(s^*), ROC=R \\]\n卷积\n\\[x_1(t)*x_2(t)\\leftrightarrow X_1(s)X_2(s), ROC至少是R_1\\cap R_2 \\]\n乘积\n\\[x_1(t)x_2(t)\\leftrightarrow \\dfrac{1}{2\\pi j}\\int^{c+j\\infty}_{c-j\\infty}X_1(\\eta)X_2(s-\\eta)d\\eta \\]\n设\\(R_1\\)为\\(Re\\{s\\}\u003e\\sigma_1\\)，\\(R_2\\)为\\(Re\\{s\\}\u003e\\sigma_2\\)，则\\(R\\)为\\(Re\\{s\\} \u003e \\sigma_1+\\sigma_2,\\sigma_1 \u003c c \u003c Re\\{s\\}-\\sigma_2\\)\n这里\\(c\\)是\\(X_1(\\eta)\\)与\\(X_2(\\eta)\\)收敛域重叠部分内与虚轴平行的直线。这里对积分路线的限制较严，积分计算也比较复杂，所以很少用该定理。\n时域微分\n\\[\\dfrac{d}{dt}x(t)\\leftrightarrow sX(s), ROC至少是R \\]\n\\(s\\)域微分\n\\[-tx(t)\\leftrightarrow \\dfrac{d}{ds}X(s), R \\]\n\\[(-t)^nx(t)\\leftrightarrow \\dfrac{d^n}{ds^n}X(s), R \\]\n\\(s\\)域积分\n\\[\\dfrac{x(t)}{t}\\leftrightarrow \\int^{+\\infty}_{s}X(\\eta)d\\eta \\]\n时域积分\n\\[\\int^t_{-\\infty}x(\\tau)d\\tau\\leftrightarrow\\dfrac{1}{s}X(s), ROC至少是R\\cap\\{Re{s}\u003e0\\} \\]\n初值定理和终值定理\n若\\(t\u003c0\\)时\\(x(t)=0\\)且在\\(t=0\\)不包括任何冲激或高阶奇异函数，则\n\\[x(0^+)=\\lim_{s\\to\\infty} sX(s) \\]\n\\[\\lim_{t\\to\\infty}x(t) = \\lim_{s\\to 0}sX(s) \\]\n常用拉普拉斯变换对 \\[\\delta(t)\\leftrightarrow 1, s\\in C \\]\n\\[\\varepsilon(t)\\leftrightarrow\\dfrac{1}{s},Re\\{s\\}\u003e0 \\]\n\\[-\\varepsilon(-t)\\leftrightarrow \\dfrac{1}{s},Re\\{s\\}\u003c0 \\]\n\\[\\dfrac{t^{n-1}}{(n-1)!}\\varepsilon(t)\\leftrightarrow\\dfrac{1}{s^n},Re\\{s\\}\u003e0 \\]\n\\[-\\dfrac{t^{n-1}}{(n-1)!}\\varepsilon(-t)\\leftrightarrow\\dfrac{1}{s^n},Re\\{s\\}\u003c0 \\]\n\\[e^{-at}\\varepsilon(t)\\leftrightarrow\\dfrac{1}{s+a},Re\\{s\\}\u003e-a \\]\n\\[-e^{-at}\\varepsilon(-t)\\leftrightarrow\\dfrac{1}{s+a},Re\\{s\\}\u003c-a \\]\n\\[\\dfrac{t^{n-1}}{(n-1)!}e^{-at}\\varepsilon(t)\\leftrightarrow\\dfrac{1}{(s+a)^n},Re\\{s\\}\u003e-a \\]\n\\[-\\dfrac{t^{n-1}}{(n-1)!}e^{-at}\\varepsilon(-t)\\leftrightarrow\\dfrac{1}{(s+a)^n},Re\\{s\\}\u003c-a \\]\n\\[\\delta(t-T)\\leftrightarrow e^{-sT}, s\\in C \\]\n\\[\\cos(w_0t)\\varepsilon(t)\\leftrightarrow \\dfrac{s}{s^2+w_0^2}, Re\\{s\\}\u003e0 \\]\n\\[\\sin(w_0t)\\varepsilon(t)\\leftrightarrow \\dfrac{w_0}{s^2+w_0^2}, Re\\{s\\}\u003e0 \\]\n\\[e^{-at}\\cos(w_0t)\\varepsilon(t)\\leftrightarrow \\dfrac{s+a}{(s+a)^2+w_0^2}, Re\\{s\\}\u003e-a \\]\n\\[e^{-at}\\sin(w_0t)\\varepsilon(t)\\leftrightarrow \\dfrac{w_0}{(s+a)^2+w_0^2}, Re\\{s\\}\u003e-a \\]\n\\[\\dfrac{d^n}{dt^n}\\delta(t)\\leftrightarrow s^n, s\\in C \\]\n\\[t\\varepsilon(t)\\leftrightarrow \\dfrac{1}{s^2}, Re\\{s\\}\u003e0 \\]\n\\[t^n\\varepsilon(t)\\leftrightarrow \\dfrac{n!}{s^{n+1}}, Re\\{s\\}\u003e0 \\]\n\\[\\varepsilon(t)*\\cdots*\\varepsilon(t)\\leftrightarrow\\dfrac{1}{s^n}, Re\\{s\\}\u003e0 \\]\n周期函数\n设\\(f(t)\\)是周期为\\(T\\)的周期函数，则其一个周期的拉普拉斯变换为\n\\[f_T(t)\\leftrightarrow \\dfrac{F(s)}{1-e^{-sT}} \\]\n用拉普拉斯变换分析与表征线性时不变系统 一个线性时不变系统的输入和输出的拉普拉斯变换由该系统的单位冲激响应的拉普拉斯变换联系起来，和傅里叶变换一样\n\\[Y(s) = H(s)X(s) \\]\n若一个线性是不变系统的输入是\\(x(t)=e^{st}\\)，则输出一定是。\\(H(s)e^{st}\\)，即\\(e^{st}\\)是系统的一个特征函数，其特征值就等于单位冲激响应的拉普拉斯变换。\n在拉普拉斯变换的范畴内，称\\(H(s)\\)为系统函数或传递函数。\\(s=jw\\)时\\(H(s)\\)称为系统的频率响应。\n因果性 一个因果系统的系统函数的收敛域是某个右半平面。\n对于一个具有有理系统函数的系统来说，系统的因果性就等效于收敛域位于最右边极点的右边的右半平面。\n反因果信号则为左半平面。\n稳定性 当且仅当系统函数\\(H(s)\\)的收敛域包括\\(jw\\)轴时，一个线性时不变系统是稳定的。\n当且仅当\\(H(s)\\)的全部极点都位于\\(s\\)平面的左半平面时，一个具有有理\\(H(s)\\)的因果系统才是稳定的。\n反因果系统需要极点都在右半平面。\n由线性常系数微分方程表征的线性时不变系统 和用傅立叶变换求解微分方程一样，我们这里换成了两边求拉普拉斯变换。\n注意，如果有初始值，那么需要用后面的单边拉普拉斯变换中的微分和积分性质。不能用之前的双边性质。\n微分方程为\n\\[\\sum^N_{k=0}a_k\\dfrac{d^k y(t)}{dt^k}= \\sum^M_{k=0}b_k\\dfrac{d^k x(t)}{dt^k} \\]\n两边同时应用拉普拉斯变换（初始值为零，即零输入响应为零，假设在\\(t=0\\)时接入\\(x(t)\\)），得\n\\[\\bigg(\\sum^N_{k=0}a_ks^k\\bigg)Y(s)= \\bigg(\\sum^M_{k=0}b_ks^k\\bigg)X(s) \\]\n如果初始值不为零，则全响应为\n\\[\\bigg(\\sum^N_{k=0}a_ks^k\\bigg)Y(s)-\\sum^N_{k=0}a_k\\bigg[\\sum^{k-1}_{p=0}s^{k-1-p}y^{(p)}(0^-)\\bigg]= \\bigg(\\sum^M_{k=0}b_ks^k\\bigg)X(s) \\]\n之后我们可以算出\n\\[H(s) = \\dfrac{Y(s)}{X(s)} \\]\n注意冲激响应是冲激函数的零状态响应。\n然后我们就可以用\\(H(s)\\)去求任意输入的零状态响应，\\(Y(s)=H(s)X(s)\\)，再拉普拉斯逆变换换到\\(s\\)域上。\n或者，我们不求\\(H(s)\\)。\n\\[Y_{zs}(s) = \\bigg(\\sum^M_{k=0}b_ks^k\\bigg)X(s)\\bigg/\\bigg(\\sum^N_{k=0}a_ks^k\\bigg) \\]\n如果有零输入响应，那么\n\\[Y_{zi} = \\sum^N_{k=0}a_k\\bigg[\\sum^{k-1}_{p=0}s^{k-1-p}y^{(p)}(0^-)\\bigg]\\bigg/\\bigg(\\sum^N_{k=0}a_ks^k\\bigg) \\]\n全响应就是两个相加，之后要求\\(s\\)域上的则逆变换即可。\n相比之下，傅立叶变换只能求零状态而不能求零输入。\n系统的\\(s\\)域框图 不做细致介绍。\n电路的\\(s\\)域模型 电阻\n\\[u(t) = Ri(t)\\leftrightarrow U(s) = RI(s) \\]\n变换后仍然是电阻。\n电感\n\\[u(t) = L\\dfrac{di(t)}{dt}\\leftrightarrow U(s) = sLI(s)-Li(0^-) \\]\n变换后变成了一个大小为\\(sL\\)的电阻，和一个电压大小为\\(Li(0^-)\\)的电压源，方向：\\(i\\)从电压源的负极流进，正极流出。也可以等效为电流源。\n电容\n\\[i(t) = C\\dfrac{du(t)}{dt}\\leftrightarrow U(s)=\\dfrac{1}{sC}I(s)+\\dfrac{u(0^-)}{s} \\]\n变换后变成了一个大小为\\(1/(sC)\\)的电阻，和一个电压大小为\\(u(0^-)/s\\)的电压源，方向：\\(i\\)从电压源的正极流进，负极流出。也可以等效为电流源。\n电源\n\\[u_s(t),i_s(t)\\leftrightarrow U_s(s),I_s(s) \\]\nKCL和KVL\n节点\n\\[\\sum_k i_k(t) = 0\\leftrightarrow\\sum_k I_k(s)=0 \\]\n回路\n\\[\\sum_k u_k(t) = 0\\leftrightarrow\\sum_k U_k(s)=0 \\]\n用了这些变换后，得到的新电路，就可以只用算电阻，不用算难算的电容和电感关系，解出来所需要的量之后，再逆变换得到\\(t\\)上的式子即可。\n单边拉普拉斯变换及其性质 一个连续时间信号\\(x(t)\\)的单边拉普拉斯变换\\(X(s)\\)定义为\n\\[X(s)=\\int^\\infty_{0^-}x(t) e^{-st}dt \\]\n积分下限取\\(0^-\\)，来表示积分区间内包括了集中于\\(t=0\\)的任何冲激或高阶奇异函数。\n\\[x(t)\\overset{\\mathcal{UL}}{\\longleftrightarrow}X(s) = \\mathcal{UL}\\{x(t)\\} \\]\n如果两个信号在\\(t\u003c0\\)时不同，而在\\(t\\geq0\\)时相同，则具有不同的双边变换，相同的单边变换。任何在\\(t\u003c0\\)时都为零的信号，双边和单边变换相同。\n单边变换就是将信号在\\(t\u003c0\\)时将它置零而求得的双边变换。\n性质\n不列出收敛域，任何单边拉普拉斯变换的收敛域总是某右半平面。\n线性，\\(s\\)域平移，时域尺度变换，\\(s\\)域微分，初值终值定理\n和双边的一样。\n时移\n和双边的不同，这里没有这个性质。\n共轭\n\\[x^*(t)\\leftrightarrow X^*(s) \\]\n与双边不同的是\\(s\\)没有取共轭（其实我有点怀疑是否是书的错误，因为后面的\\(z\\)变换又是单边双边相同的，有点出乎我的意料。但是我不知道是这个错了还是那个错了）\n卷积\n特别要求\\(t\u003c0\\)时，\\(x_1(t),x_2(t)\\)都为零。\n时域微分\n\\[x'(t)\\leftrightarrow sX(s)-x(0^-) \\]\n\\[x''(t)\\leftrightarrow s^2X(s)-sx(0^-)-x'(0^-) \\]\n\\[x^{(n)}(t)\\leftrightarrow s^nX(s)-\\sum^{n-1}_{m=0}s^{n-1-m}x^{(m)}(0^-) \\]\n并且特别给出，当\\(x(t)\\)是因果信号时，\\(x^{(n)}(t)\\leftrightarrow s^nX(s)\\)。\n时域积分\n初始条件为零（松弛）时\n\\[\\bigg(\\int^t_{0^-}\\bigg)^nx(\\tau)d\\tau\\leftrightarrow \\dfrac{1}{s^n}X(s) \\]\n在初始条件不是松弛的情况下，以下公式对于求微分方程的解非常好用。\n\\[x^{(-1)}(t)=\\int^t_{-\\infty}x(\\tau)d\\tau \\leftrightarrow s^{-1}X(s) +s^{-1}x^{(-1)}(0^-) \\]\n\\(z\\)变换 一个离散时间信号\\(x[n]\\)的\\(z\\)变换定义为\n\\[X(z) = \\sum^{+\\infty}_{n=-\\infty} x[n]z^{-n} \\]\n其中\\(z\\)是一个复变量。我们也记作\n\\[x[n]\\overset{z}{\\longleftrightarrow}X(z)=\\mathcal{Z}\\{x[n]\\} \\]\n当然，离散傅里叶变换就是\\(z=e^{jw}\\)时的一个特例。我们现在将\\(z\\)表示为\\(z=re^{jw}\\)，用\\(r\\)表示\\(z\\)的模，用\\(w\\)表示它的相角。于是就可以把\\(X(re^{jw})\\)看成序列\\(x[n]\\)乘以实指数\\(r^{-n}\\)后的傅里叶变换，即\n\\[X(re^{jw}) = \\mathcal{F}\\{x[n]r^{-n}\\} \\]\n类似于在虚轴\\(jw\\)上的拉普拉斯变换就是傅里叶变换，在复平面的单位圆上进行的\\(z\\)变换，就是傅里叶变换。\n\\(z\\)变换的有理分式情况 和拉普拉斯变换一样。同时也有极点和零点的概念。记住，求零点极点时，分子分母的\\(z\\)不要出现负幂项，全部转成正幂项再来求。\n\\(z\\)变换的收敛域 收敛域记作\\(ROC\\)\n\\(X(z)\\)的收敛域是在\\(z\\)平面内以原点为中心的圆环 收敛域内不包括任何极点 如果\\(x[n]\\)是有限长序列，那么收敛域就是整个\\(z\\)平面，可能除去\\(z=0\\)和/或\\(z=\\infty\\) 如果\\(x[n]\\)是一个右边序列，并且\\(|z|=r_0\\)的圆位于收敛域内，那么\\(|z|\u003er_0\\)的全部有限\\(z\\)值都一定在这个收敛域内 如果\\(x[n]\\)是一个左边序列，而且\\(|z|=r_0\\)的圆位于收敛域内，那么满足\\(0\u003c|z|\u003c r_0\\)的全部\\(z\\)值都一定在这个收敛域内 如果\\(x[n]\\)是一个双边序列，而且\\(|z|=r_0\\)的圆位于收敛域内，那么该收敛域在\\(z\\)域中一定是包含\\(|z|=r_0\\)这一圆环的环状区域 如果\\(x[n]\\)的\\(z\\)变换\\(X(z)\\)是有理的，它的收敛域就被极点所界定，或延伸至无限远 如果\\(x[n]\\)的\\(z\\)变换\\(X(z)\\)是有理的，并且\\(x[n]\\)是右边序列，那么收敛域就位于\\(z\\)平面内最外层的极点的外边，也就是半径等于\\(X(z)\\)极点中最大模值的圆的外边。而且，若\\(x[n]\\)是因果序列，即\\(x[n]\\)为\\(n\u003c0\\)时等于零的右边序列，那么收敛域也包括\\(z=\\infty\\) 如果\\(x[n]\\)的\\(z\\)变换\\(X(z)\\)是有理的，并且\\(x[n]\\)是左边序列，那么收敛域就位于\\(z\\)平面内最外层的极点的里边，也就是半径等于\\(X(z)\\)中除去\\(z=0\\)的极点中最小模值的圆的里边，并且向内延伸到可能包括\\(z=0\\)。特别是，若\\(x[n]\\)是反因果序列，即\\(x[n]\\)为\\(n\u003e0\\)时等于零的左边序列，那么收敛域也包括\\(z=0\\) \\(z\\)逆变换 \\[x[n] = \\dfrac{1}{2\\pi j}\\oint X(z)z^{n-1}dz \\]\n和拉普拉斯逆变换一样，很难直接用这个东西去算。遇上有理分式就待定系数法拆开，遇上其他函数就分开来看，然后套用常用\\(z\\)变换表和其性质来算。\n当然，你可能会发现拆出来的项是\\(\\dfrac{1}{z-1}\\)这种形式的，然后就会发现变换表里的不是\\(z\\)而是\\(z^{-1}\\)。这种情况应该对\\(\\dfrac{X(z)}{z}\\)进行因式分解，得到结果后两边同乘\\(z\\)，然后再转换一下就可以使用变换表了。\n（双边）\\(z\\)变换的性质 假设\\(x_1[n]\\leftrightarrow X_1(z),ROC=R_1\\)和\\(x_2[n]\\leftrightarrow X_2(z),ROC=R_2\\)\n线性\n\\[ax_1[n]+bx_2[n]\\leftrightarrow aX_1(z)+bX_2(z) \\]\n时移\n\\[x[n-n_0]\\leftrightarrow z^{-n_0}X(z), ROC=R \\]\n\\(z\\)域尺度变换\n\\[e^{jw_0n}x[n]\\leftrightarrow X(e^{-jw_0}z),ROC=R \\]\n\\[z_0^nx[n]\\leftrightarrow X(\\dfrac{z}{z_0}),ROC=z_0R \\]\n\\[a^nx[n]\\leftrightarrow X(a^{-1}z),ROC=R的尺度变换 \\]\n时间翻转\n\\[x[-n]\\leftrightarrow X(z^{-1}),ROC=R^{-1} \\]\n时间扩展\n\\[x_{(k)}[n] = \\left\\{\\begin{matrix} x[r], \u0026 n=rk\\\\ 0, \u0026 n\\neq rk \\end{matrix}\\right.\\leftrightarrow X(z^k),ROC = R^{1/k} \\]\n共轭\n\\[x^*[n] \\leftrightarrow X^*[z^*], ROC=R \\]\n卷积\n\\[x_1[n]*x_2[n]\\leftrightarrow X_1(z)X_2(z), ROC至少是R_1\\cap R_2 \\]\n一次差分\n\\[x[n]-x[n-1]\\leftrightarrow (1-z^{-1})X(z),ROC至少是R\\cap|z|\u003e0 \\]\n累加\n\\[\\sum^n_{k=-\\infty}x[k]\\leftrightarrow \\dfrac{1}{1-z^{-1}}X(z),ROC至少是R\\cap|z|\u003e1 \\]\n\\(z\\)域微分\n\\[nx[n]\\leftrightarrow -z\\dfrac{d}{dz}X(z), ROC=R \\]\n\\(z\\)域积分\n\\[\\dfrac{x[n]}{n+m}\\leftrightarrow z^m\\int^{\\infty}_{z}\\dfrac{X(\\eta)}{\\eta^{m+1}}d\\eta,ROC=R \\]\n初值定理和终值定理\n若\\(n\u003c0\\)时,\\(x[n]=0\\)则\n\\[x[0]=\\lim_{z\\to\\infty} X(z) \\]\n若\\(n","date":"2023-04-05T20:24:29+08:00","image":"https://kegalas.top/inferior/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/cover_hu1925d5b7c7f8a1062326c6e2b8e7c8b0_29169_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"信号与系统学习笔记"},{"content":"简称表 简称 含义 CPU 中央处理器 PC 程序计数器 IR 指令寄存器 CU 控制单元 ALU 算术逻辑单元 ACC 累加器 MQ 乘商寄存器 X 操作数寄存器 MAR 存储器地址寄存器 MDR 存储器数据寄存器 MM 主寄存器 I/O 输入输出设备 简称 含义 SATA 串行ATA总线 PCI 外围设备互联 DMA 直接存储器访问 DMI 直接媒体接口 QPI 快速通道互联 FSB 前端总线 PCH 平台控制中心 IOH 输入/输出中心 ICH 控制器集线器 MCH 内存控制器集线器 NVRAM 非易失型随机存储器 SCSI 小型计算机系统接口 简称 含义 RAM 随机存储器 ROM 只读存储器 SRAM 静态随机读写存储器 DRAM 动态随机读写存储器 DDR SDRAM 双倍数据率同步DRAM MROM 掩模ROM PROM 可一次编程ROM EPROM 可擦除的PROM EEPROM 电可擦除的EPROM EAROM 电改写ROM SIMM 单列直插式存储器模块 DIMM 双列直插式存储器模块 FIFO 先进先出算法 LRU 近期最少使用算法 TLB 转换后援缓冲器，快表 计算机的性能描述 机器字长 指CPU一次能处理的数据位数\n存储容量 存储容量=存储单元个数×存储字长。其中MAR反应存储单元个数，MDR反应存储字长。\n运行速度 主频/时钟周期 主频与时钟周期二者互为倒数\nCPI 执行一条指令（平均）需要的时钟周期数\n\\[CPI = \\dfrac{\\text{所有指令的时钟周期之和}}{\\text{指令总数}}\\\\ = \\sum(\\text{各类指令的CPI}\\times \\text{该类指令的比例}) \\]\nMIPS 每秒钟CPU能执行的指令总条数（百万条/秒）\n\\[MIPS = \\dfrac{\\text{指令条数}}{\\text{执行时间}\\times 10^6} \\]\n\\[= \\dfrac{\\text{指令条数}}{\\left(\\dfrac{\\text{所有指令CPU时钟周期数之和}}{f}\\right)\\times 10^6}\\\\ \\]\n\\[= \\dfrac{f}{\\text{CPI}\\times 10^6} \\]\n其中最后一个公式又称为全性能公式\nAmdahl定律 加速比\n\\[\\text{加速比} = \\dfrac{\\text{改进后的系统性能}}{\\text{改进前的系统性能}}\\\\ \\]\n\\[= \\dfrac{\\text{改进前的系统执行时间}}{\\text{改进后的系统执行时间}} \\]\n可改进比例\\(f_e\\)\n可改进部分在原系统执行时间中所占的比例\n部件加速比\\(r_e\\)\n可改进部分改进后性能提高的程度\nAmdahl定律\n假设改进前的系统执行时间为\\(T_0\\)，改进后的系统执行时间为\\(T_n\\)，则\n\\[T_n = T_0\\bigg(1-f_e+\\dfrac{f_e}{r_e}\\bigg) \\]\n若加速比用\\(S_p\\)表示，则有\n\\[S_p = \\dfrac{1}{1-f_e+\\dfrac{f_e}{r_e}} \\]\n有多个部件同时可以改进时\n\\[S_p = \\dfrac{1}{(1-\\sum f_e)+\\sum(\\dfrac{f_e}{r_e})} \\]\n总线和IO 分类 按照总线的传输方式不同（定时），可以分为同步总线和异步总线； 按照总线中数据线的多少不同（传送信息），可以分为并行总线和串行总线。 按照总线的使用方式不同，可以分为专用总线和公用总线。 按照连接部件不同，可分为片内总线、系统总线、通信总线 按照系统总线传输信息的不同，又可分为数据总线、地址总线、控制总线 总线带宽 \\[\\text{总线带宽} = \\text{数据线宽度}\\times \\text{总线频率} \\]\n总线结构 可以分为单总线和多总线结构。\n总线控制 中断 存储系统 主存 技术指标 存储容量\n\\[\\text{存储容量}=\\text{存储单元个数}\\times\\text{存储字长} \\]\n上式的单位是位，如果用字节需要除以8。\n存储器带宽\n\\[B_m = \\dfrac{n}{t_m} \\]\n其中\\(n\\)为每次读出/写入的字节数，\\(t_m\\)为存储周期\n半导体存储芯片的译码驱动方式 DRAM的刷新 存储器芯片的扩展 Cache Cache的命中率 在一个程序执行期间，设\\(N_c\\)为访问Cache的总命中次数，\\(N_m\\)为访问主存的总次数，则命中率\\(h\\)（hit rate）为\n\\[h = \\dfrac{N_c}{N_c+N_m} \\]\n设\\(t_c\\)为命中时的Cache访问时间，\\(t_m\\)为未命中时的主存访问时间，通常\\(t_m \u003e\u003e tc\\) ，\\(1-h\\)表示未命中率（缺失率，miss rate）\n当Cache和主存同时访问时，Cache-主存系统的平均访问时间\\(ta\\)为：\n\\[t_a = ht_c + (1-h)t_m \\]\n当Cache和主存不同时访问时，Cache-主存系统的平均访问时间\\(ta\\)为（我们一般考虑同时访问的情况）：\n\\[t_a = ht_c+(1-h)(t_m+t_c) = t_c+(1-h)t_m \\]\nCache-主存系统的效率 \\[e = \\dfrac{t_c}{t_a} = \\dfrac{\\text{访问Cache的时间}}{\\text{平均访问时间}}\\times 100\\% \\]\n\\[= \\dfrac{t_c}{t_c+(1-h)\\times t_m}\\times 100\\% \\]\nCache-主存系统的加速比 \\[S_p = \\dfrac{t_m}{t_a} = \\dfrac{t_m}{t_c+(1-h)\\times t_m} = \\dfrac{1}{1-h+\\dfrac{1}{r}} \\]\n其中，\\(r=t_m/t_c\\)为从主存到Cache速度提升的倍数。\nCache-主存系统的成本 假设计算机中的主存与Cache的容量分别为\\(S_1\\)和\\(S_2\\),显然\\(S_1 \u003e\u003e S_2\\)；\n主存与Cache的单位价格分别为\\(C_1\\)和\\(C_2\\)，且\\(C_1\\)是价格较低的。\n那么Cache—主存系统的平均价格\\(C\\)为\n\\[C = \\dfrac{C_1\\times S_1+C_2\\times S_2}{S_1+S_2} \\]\nCache的映射 替换算法 多级Cache 虚拟存储器 外部存储器 磁盘 非格式化容量\n\\[\\text{非格式化容量} = \\text{位密度}\\times\\dfrac{\\text{内圈磁道周长}+\\text{外圈磁道周长}}{2}\\times\\text{每盘面磁道数}\\times\\text{盘面数} \\]\n格式化容量\n\\[\\text{格式化容量} = \\text{每扇区字节数}\\times\\text{每道扇区数}\\times\\text{每盘面磁道数}\\times\\text{盘面数} \\]\n平均存取时间\n\\[\\text{平均存取时间} = \\text{平均寻道时间}+\\text{平均等待时间}+\\text{传输时间} \\]\n数据传输率\n\\[\\text{数据传输率} = \\text{每个扇区的字节数}\\times\\text{每道扇区数}\\times\\text{磁盘的转速} \\]\n数据表示 带符号的定点小数 其一般形式为\n\\[X_s.X_{-1}X_{-2}\\cdots X_{-(n-1)} \\]\n其中第一位是符号位，后面的每一位都在小数点后，也就是说定点小数一定是纯小数，不含整数部分。\n原码、反码、补码、移码 原码转换为另外三个码的规则\n原码符号 反码 补码 移码 正 相同 相同 符号位改为1 负 除符号位外取反 反码+1 符号位与补码相反 假设不含符号位有\\(n\\)位，则原码和反码的范围为\\(-2^{n}+1\\sim 2^{n}-1\\)，补码和移码的范围为\\(-2^{n}\\sim 2^{n}-1\\)\n以上是定点整数的转换方法，定点小数的转换方法相同，数据范围不同\n假设不含符号位有\\(n\\)位，则原码和反码的范围为\\(-(1-2^n)\\sim 1-2^n\\)，补码和移码的范围为\\(-1\\sim 1-2^n\\)\n浮点数 浮点数\\(N\\)由三部分来决定，阶码\\(E\\)，尾数\\(M\\)和阶码的底\\(B\\)\n\\[N = B^E\\cdot M \\]\n阶码的底\\(B\\)一般隐含表示，取决于机器本身。阶码是定点整数，尾数是定点小数。\n非规格化浮点数 非规格化浮点数不要求定点小数的第一位是1.其数据范围如下，假设尾数部分\\(n+1\\)位，阶码部分\\(k+1\\)位，均用补码表示\n阶码最小值 \\(-2^k\\) 阶码最大值 \\(2^k-1\\) 尾数最小负值 \\(-1\\) 尾数最大负值 \\(-2^{-n}\\) 尾数最小正值 \\(2^{-n}\\) 尾数最大正值 \\(1-2^{-n}\\) 可表示的最小负数 \\(-1\\times 2^{2^k-1}\\) 可表示的最大负数 \\(-2^{-n}\\times 2^{-2^k}\\) 可表示的最小正数 \\(2^{-n}\\times 2^{-2^k}\\) 可表示的最大正数 \\((1-2^{-n})\\times 2^{2^k-1}\\) 规格化浮点数 要求定点小数的第一位是1.在用补码表示时，符号位和第一位如果不同，则为规格化浮点数。\n阶码最小值 \\(-2^k\\) 阶码最大值 \\(2^k-1\\) 尾数最小负值 \\(-1\\) 尾数最大负值 \\(-(1/2+2^{-n})\\) 尾数最小正值 \\(+1/2\\) 尾数最大正值 \\(1-2^{-n}\\) 可表示的最小负数 \\(-1\\times 2^{2^k-1}\\) 可表示的最大负数 \\(-(1/2+2^{-n})\\times 2^{-2^k}\\) 可表示的最小正数 \\(1/2\\times 2^{-2^k}\\) 可表示的最大正数 \\((1-2^{-n})\\times 2^{2^k-1}\\) IEEE754标准浮点数 以单精度为例，单精度有32位长，最高位(\\(S\\))是浮点数的符号位，接下来8位是指数(\\(E\\))，最后23位是尾数(\\(F\\))。\n其表示为\n\\[(-1)^S\\times (1+F)\\times 2^{(E-Bias)} \\]\n其中，尾数本来应该为1.xxxxx，但是我们将第一位暗含了，所以式子中为\\(1+F\\)，那23位尾数只包含小数点后面的数。这个尾数永远为正，不需要考虑补码等问题，符号由符号位提供。\n而\\(Bias\\)提供了一种类似于移码的方式来表示正负，在单精度中，Bias为\\(127\\)，也就是说，如果我们要表示\\(2^6\\)，则\\(E = 6+127 = 133\\)，而133才是会被记录在那8位尾数中的数字。\n单精度表示对象表如下\n指数 尾数 表示对象 0 0 0 0 非0 \\(\\pm\\)非规格化数 1-254 任意 \\(\\pm\\)浮点数 255 0 \\(\\pm\\)无穷 255 非0 NaN 其中浮点数的表示范围为\\(\\pm[1,2)\\times 2^{[-126,127]}\\)\n双精度浮点数的Bias为1023。\nASCII码 汉字编码 \\[\\text{国标码} = (\\text{区位码})_{16} + 2020H \\]\n\\[\\text{机内码} = (\\text{国标码})_{16} + 8080H \\]\n\\[\\text{机内码} = (\\text{区位码})_{16} + A0A0H \\]\nUnicode与UTF-8 检错与纠错码 校验码的码距 \\[d_{min} \\geq t+e+1, 且e\\geq t \\]\n其中\\(d_{min}\\)为编码码距，\\(t\\)为可纠错的位数，\\(e\\)为可检错的位数\n\\(d_{min}\\geq 2\\)的数据校验码具有检错的能力\n奇偶校验 海明码 设信息码为\\(n\\)位，欲检测\\(1\\)位错误，增添\\(k\\)位校验位，组成\\(m=n+k\\)位的校验码，应满足\n\\[2^k\\geq n+k+1 \\]\nCRC码 运算方法与运算器 机器数的逻辑运算 按位与、或、非、异或等等。\n机器数的移位运算 算术移位 正数的原码、补码、反码，左移右移都补0.\n负数的原码左右都补0；补码右补1，左移补0；反码左右都补1.\n运算的结果\\(p+q\\)位，保留前\\(p\\)位，常见的舍入方法有：\n恒舍（切断）。实现简单，误差大。 冯诺依曼舍入法，又称恒置1法，把保留部分\\(p\\)位的最低位置1.实现简单，平均误差接近0，应用较多。 下舍上入法，即0舍1入。用\\(q\\)位的最高位作为标志。如果为0，则全部舍去；如果为1，则在保留的\\(p\\)位的最低位上加1. 查表舍入法，或ROM舍入法。每次经查表来读得相应的处理结果。表的设计通常是当尾数最低\\(k-1\\)位全1时用截断法，其余用舍入法。实现速度快，虽然增加了硬件，但是整体性能最佳。 逻辑移位 把所有码都看成无符号码，左移右移都添加0，多出来的位直接舍弃。\n循环移位 1.jpg\r一位全加器 输入\\(X_i,Y_i,C_i\\)，表示两个加数和一个进位。\n输出\\(Z_i,C_{i+1}\\)，表示结果和进位。\n\\[Z_i = X_i\\oplus Y_i\\oplus C_i \\]\n\\[C_{i+1} = (X_i\\cdot Y_i)+(X_i+ Y_i)\\cdot C_i \\]\n若果令\\(G_i = X_i\\cdot Y_i, P_i = X_i+ Y_i\\)，则\\(C_{i+1}=G_i+P_i\\cdot C_i\\)\n当然\\(P_i=X_i\\oplus Y_i\\)其实是等效的，有些地方会这么写。\n\\(G_i\\)为进位产生函数：若本位两个输入均为\\(1\\)，必向高位产生进位，与低位进位无关。\n\\(P_i\\)为进位传递函数：当\\(P_i =1\\)时，若低位有进位，本位将产生进位。\nn位加减法器 串行（行波）进位的并行加减法器 \\(n\\)个全加器串接起来，就可以进行两个\\(n\\)位数的相加减。进位信号是逐级形成的。\n并行加法器的快速进位 并行进位（先行进位、同时进位、CLA）方式 即把\\(C_{i+2}\\)用\\(C_{i+1}\\)表示，把\\(C_{i+3}\\)用\\(C_{i+2}\\)表示，以此类推，然后从一开始就得到进位信息。\n分组并行进位 单级先行进位，即，组内并行，组间串行。因为全部都并行电路很复杂，所以采用这个方法。\n多级先行进位，即组内并行，组间并行。\nALU电路 既能完成算术运算又能完成逻辑运算的部件。\n定点数加减运算 补码 两个数连同符号位一起相加，符号位产生的进位丢掉。减法则是把右边的加数变成相反数的补码再来相加。得到的结果也是补码。\n符号扩展 将采用给定位数表示的数转换成具有更多位数的某种表示形式。\n对于补码，正数用0填充，负数用1填充。\n溢出判断 有两种情况，一种是正溢，即两个正数相加。一种是负溢，即两个负数相加。\n采用符号位判断。如果正数相加符号位变成1了，那么正溢。如果负数相加符号位变成0了，那么负溢。 采用进位法。如果正数相加，最高有效位产生进位而符号位不产生进位，那么正溢。如果负数相加最高有效位不产生进位，而符号位产生进位，那么负溢。 采用变形补码（双符号位补码，模4补码）。计算方法相同，都是相加然后进位。如果符号位为00，则为正数；11则为负数，01则为正溢，10则为负溢。 标志信息 零标志ZF=1表示结果为0，不论有符号还是无符号都有意义。\n符号SF表示结果的符号，即最高位。对于无符号数没有意义。\nCF表示无符号加减运算时的借进位。加法时CF=1表示溢出，减法时CF=1表示借位。对于有符号数没有意义。\n溢出表示OF=1表示有符号数的运算结果发生了溢出。对于无符号数没有意义。\nBCD加法器 对于一位数，加出来的结果如果大于9，则加6进位。\n移码加减运算 两个移码直接相加 将结果的符号取反 定点数乘法运算 乘法用加法和移位实现，参照手算竖式乘法。\n原码乘法，略。\n部分积这个概念可能会考。\n补码乘法——校正法 计算x*y\n当y\u0026gt;0时，不管被乘数x的正负都直接按原码乘法计算，只是移位时按补码规则进行。\ny\u0026lt;0时，可以先把[y]补的符号位丢掉不管，仍按原码乘法运算，最后再加上[-x]补进行校正。\n综上，表达式为\n\\[=[X]_补\\cdot 0.y_1y_2\\cdots y_n + [-X]_补\\cdot y_0 \\]\n补码乘法——比较法（Booth法） 我们可以证明，\\([-X]_补=-[X]_补\\)，布斯法从这里入手。\n\\[[X\\cdot Y]_补 = [X]_补\\cdot(-y_0\\cdot 2^0+y_1\\cdot 2^{-1}+y_2\\cdot 2^{-2}+\\cdots+y_n\\cdot 2^{-n}) \\]\n\\[= [X]_补\\cdot[-y_0\\cdot 2^0+(y_1\\cdot 2^{0}-y_1\\cdot 2^{-1})+(y_2\\cdot 2^{-1}-y_2\\cdot 2^{-2})+\\cdots+(y_n\\cdot 2^{-(n-1)}-y_n\\cdot 2^{-n})] \\]\n\\[= [X]_补\\cdot[(y_1-y_0)\\cdot 2^0+(y_2-y_1)\\cdot 2^{-1}+\\cdots+(y_n-y_{n-1})\\cdot 2^{-(n-1)}+(y_{n+1}-y_n)\\cdot 2^{-n}] \\]\n其中\\(y_{n+1}=0\\)，写出来只是方便起见。\n于是我们可以方便的递推\n\\[[z_0]_补 = 0 \\]\n\\[[z_1]_补 = 2^{-1}\\{(y_{n+1}-y_n)[x]_补+[z_0]_补\\} \\]\n\\[\\vdots \\]\n\\[[z_n]_补=2^{-1}\\{(y_2-y_1)[x]_补+[z_{n-1}]_补\\} \\]\n\\[[x\\cdot y]_补 = [z_n]_补+(y_1-y_0)[x]_补 \\]\n阵列乘法器 原码和补码的乘法算法，利用加法和移位进行，属于串行乘法，它是一行行地来实现竖式乘法的。而阵列乘法器，通过电路实现了整个竖式乘法，速度快。\n定点数除法运算 类似的，除法是用减法和移位实现。\n原码除法分为恢复余数法和加减交替法\n恢复余数法是直接作减法试探方法，不管被除数（或余数）减除数是否够减，都一律先做减法。 若余数为正，表示够减，该位商上“1”；若余数为负，表示不够减，该位商上“0”，并要恢复原来的被除数（或余数）。\n加减交替法 符号位不参与运算；上商 n+1 次；第一次上商判溢出；左移 n 次，加 n+1 或n+2次；用移位的次数判断除法是否结束；若最终余数为负，需恢复余数。\n补码除法：补码除法共上商 n +1 次（末位恒置 1）第一次为商符；第一次商可判溢出；加 n+1 次 左移 n 次；用移位的次数判断除法是否结束；精度误差最大为\\(2^{-n}\\)\n浮点数加减运算 步骤如下\n使两个数的小数点位置对齐 将尾数按定点加减运算计算 将尾数计算结果重新规格化 尾数在规格化后进行舍入 判断是否溢出 浮点数乘除运算 步骤如下\n阶码采用补码（对于IEEE754则不是补码，总之是定点加减）定点加减运算 尾数乘除同定点运算 规格化 舍入 溢出判断 运算器的组成和结构 指令系统 存储模式 大端存储（大部分RISC），小端存储（Intel/AMD）\n堆栈（Stack）：具有先进后出(FILO)操作规则的被特殊定义的主存区域。\n使用堆栈时用三个专用地址寄存器来管理\n堆栈指针（Stack Pointer，SP）：指示当前可操作的堆栈单元。 堆栈基址（Stack Base，SB）：指示堆栈的底部。 堆栈界限（Stack Limit，SL）：指示堆栈的最顶端 堆栈界限\\(=\\)堆栈基址\\(\\pm\\)堆栈大小。\n寄存器组织 寄存器按功能可以分为通用寄存器和专用寄存器。按可操作性分为可见与不可见寄存器。\n典型寄存器有地址寄存器(AR)、数据寄存器(DR)、指令寄存器(IR)、程序计数器(PC)、堆栈指针寄存器(SP)、标志寄存器(FR)等。\n指令格式 为了使指令能够有效地指挥计算机完成各种操作，一条指令应包含两个基本要素：操作码和地址码，其基本格式为：操作码字段+地址码字段。\n指令功能不同，需要的操作数数量也不同。地址码字段为指令指定源操作数、目的操作数和下条指令地址等信息，格式为：源操作数+目的操作数+下条指令地址。\n按照地址码字段的数量，指令可以分为四地址、三地址、两地址、单地址和零地址指令。\n四地址指令：op,rd, rs1, rs2,ni; rs1 op rs2-\u0026gt;rd, ni提供顺序或转移地址\n三地址指令：op,rd,rs1,rs2 rs1 op rs2-\u0026gt;rd, PC提供顺序地址\n二地址指令：op,rd,rs1 rd op rs1-\u0026gt;rd或rs1 op ACC-\u0026gt;rd, PC提供顺序地址\n单地址指令：op rd rd op ACC -\u0026gt; ACC或rd自身操作-\u0026gt;rd, PC提供顺序地址；或rd提供转移地址。ACC为累加器或操作码隐含指定的操作数。\n零地址指令：op 由操作码指定操作数（隐含寻址）或无需操作数。\n定长操作码 对所有指令的操作码用相同位数的二进制数进行编码，即为定长操作码编码方式。\n某计算机的指令系统需要设置\\(N\\)条指令，若所有指令的操作码均用\\(n\\)位二进制数表示，则应满足关系式：\n\\[N\\leq 2^n \\]\n从\\(2^n\\)个编码中选出\\(N\\)个编码分配给\\(N\\)条指令，即可完成操作码设计。\n变长操作码 对不同类型的指令操作码用不固定长度的二进制数进行编码即为变长操作码或扩展操作码编码方式。\n扩展操作码技术是指令优化技术，其技术核心是：\n使程序中指令的平均操作码长度尽可能短，以减少操作码在程序中的总位数； 尽可能充分地利用指令的二进制数位，以增加指令字表示的操作信息。 扩展操作码的设计原则：\n如果指令字长固定，则长地址码对应短操作码，操作码长度随地址码长度缩短而增加。 如果指令字长可变，则以指令的使用频率作为设计依据，频率高的用短操作码，长的用长操作码。用到了霍夫曼编码。 设计总是从短操作码开始，并且保证短码不能是长码的前缀。 寻址 隐含寻址：操作数的存放地由操作码指定。 立即寻址：操作数在指令中。 寄存器寻址：操作数在指令指定的寄存器中。 直接寻址：操作数地址在指令中，操作数在主存单元中，访问一次主存便可获得操作数。 （存储器）间接寻址：操作数地址的地址在指令中，操作数在主存单元中。 寄存器间接寻址：操作数地址在指令指定的寄存器中，操作数在主存单元中，访问一次主存即可获得操作数。 相对寻址：操作数地址由程序计数器和指令提供的地址偏移量决定，操作数在主存单元中，访问一次主存即可获得操作数。 基址寻址：操作数地址由基址寄存器和指令提供的地址偏移量决定，操作数在主存单元中,访问一次主存即可获得操作数。 变址寻址：操作数地址由变址寄存器和指令提供的地址偏移量决定，操作数在主存单元中。 堆栈寻址：该寻址方式通常由指令操作码指定，用在涉及堆栈操作的指令中，所寻址的操作数在堆栈中。 中央处理器 CPU的功能和结构 CPU的功能 CPU主要由控制器+运算器+寄存器组构成。\nCPU具有以下四方面功能\n指令控制 操作控制 时间控制 数据加工 CPU的主要功能是执行存储在主存中的指令序列,也即执行程序，具体操作如下:\n取得指令：cpu从主存中取指令，存在指令寄存器中 执行指令 确定下条指令的地址：可能是顺序地址，或者分支跳转地址 重复1~3，直到执行完毕 其中，控制器CU的功能为：从存储器中取指令、对指令译码、产生控制信号并控制计算机系统各部件有序地执行，从而实现这条指令的功能。\n控制器组成为：PC，IR，AR，DR，指令译码器，操作控制信号形成部件，时序信号产生器。\n指令周期 CPU执行一条指令所用的时间即为指令周期，在指令周期内CPU完成一组操作。\n一个周期分为三个子周期：取指令子周期、执行指令子周期（分为取数子周期、执行子周期、存数字周期）、中断子周期。\n2.jpg\r微操作 概念\n在CISC系统中，指令周期内的CPU行为常常被分解为一系列微操作\\((\\mu op)\\)\n微操作是CPU可以进行的基本或原子操作。它是CPU可实现的、不可分解的操作。以含有一个寄存器传递（移进、移出）操作为标志。\n每一个微操作是通过控制器将控制信号发送到相关部件上引起部件动作而完成的。\n这些控制微操作完成的控制信号称为微命令。 微命令是由控制器产生的。 流程\n时序信号\nCPU执行微操作有严格的时间顺序性，这种时间关系是由计算机的时序系统来控制的。CPU执行微操作序列中的时序信号：\n指令周期：执行一条指令所用的时间 CPU周期：完成一个子周期所用的时间 节拍周期：完成一个微操作所用的时间 通常利用时序电路为控制器提供所需的时序信号。\n节拍周期 最基本的时序信号为节拍，它可由顺序脉冲发生器（也称脉冲分配器或节拍脉冲发生器）产生。\n节拍周期\\(T\\)：完成各种CPU微操作所需时间的最大者，常作为定义CPU时钟周期\\(T_{clk}\\)或时钟频率\\(f_{clk}\\)的依据。\n\\[T = (1\\sim n)\\times T_{clk} = (1\\sim n)/f_{clk} \\]\n节拍脉冲发生器分为两类：计数型=计数器+译码器；移位型=移位寄存器+译码器。\nCPU周期（机器周期） 完成一个子周期所用的时间。一般指CPU与内存交换一次信息所需要的时间。若干个节拍组成一个CPU周期。\nCPU周期可以设计为定长 CPU周期与不定长CPU周期两种。\n指令周期 执行一条指令所用的时间。若干个CPU周期组成一个指令周期，指令周期也可以设计为定长指令周期与不定长指令周期两种。\n取指令与中断子周期微操作流程\n当一条指令在该系统上执行时，可以被看作是一组微操作的执行。\n每条指令对应的一组微操作，称为该指令的微操作流程或微操作序列。\n取指令周期 一个简单的取指令周期可由3个节拍、4个微操作组成\nT1: AR\u0026lt;-PC //PC的内容传送到AR T2: DR\u0026lt;-Memory[AR], Mread //读取主存到DR PC\u0026lt;-PC+I //PC自增到下一条指令，其中I为指令长度 T3: IR\u0026lt;-DR //DR的内容传送到IR 组合微操作：\nT1: AR\u0026lt;-PC T2: DR\u0026lt;-Memory[AR], Mread T3: PC\u0026lt;-PC+I IR\u0026lt;-DR 组合微操作的规则：遵守操作发生的顺序、必须避免冲突\n所有指令的取指令操作相同，故取指令周期称为公操作。\n中断周期 在执行周期结束时有一个检测，用来确定被允许的中断是否已出现，若是，中断周期产生。\n中断周期也是公操作。\n中断周期微操作序列举例：\nT1: DR\u0026lt;-PC //将PC的内容传到DR保护 T2: AR\u0026lt;-Save_Address //中断断点信息保护区的存储单元地址传送到AR PC\u0026lt;-Routine_Address //中断服务程序首地址送入PC T3: Memory[AR]\u0026lt;-DR, Mwrite //将老PC的内容保存于主存（如堆栈）中 执行周期 MOV R1, R0 实现将寄存器R0的内容传送至寄存器R1中。\nT1: R1\u0026lt;-R0 MOV R0, X 实现将存储单元X中的内容传送至寄存器R0中。\nT1: AR\u0026lt;-IR //IR = X T2: DR\u0026lt;-Memory[AR], Mread T3: R0\u0026lt;-DR MOV (R1), R0 将寄存器R0的内容传送至由寄存器R1间接寻址的存储单元中。\nT1: AR\u0026lt;-R1 T2: DR\u0026lt;-R0 T3: Memory[AR]\u0026lt;-DR, Mwrite ADD R1, R0 将寄存器R0的内容与寄存器R1的内容相加并将结果存入R1。\nT1: Y\u0026lt;-R0 T2: Z\u0026lt;-R1+Y T3: R1\u0026lt;-Z SUB R0, (X) 实现寄存器R0中的被减数减去存储器地址X间接寻址的存储单元中的减数、将差值传送至寄存器R0中。\nT1: AR\u0026lt;-IR //IR = X T2: DR\u0026lt;-Memory[AR], Mread T3: AR\u0026lt;-DR T4: DR\u0026lt;-Memory[AR], Mread T5: Y\u0026lt;-R0 T6: Z\u0026lt;-Y﹣DR T7: R0\u0026lt;-Z IN R0, P 从I/O地址为P的I/O设备(接口)中输入数据并存入寄存器R0中。\nT1: AR\u0026lt;-IR //IR = P T2: DR\u0026lt;-IO[AR], IOread T3: R0\u0026lt;-DR OUT P, R0 将寄存器R0中的数据输出到I/O地址为P的I/O设备(接口)中。\nT1: AR\u0026lt;-IR //IR = P T2: DR\u0026lt;-R0 T3: IO[AR]\u0026lt;-DR, IOwrite JUMP X 无条件跳转指令，实现将程序执行地址从当前跳转指令所在位置转移到存储器地址为X处。\nT1: PC\u0026lt;-IR JZ offs 采用相对寻址的条件跳转指令。当条件为真（即零标志ZF=1）时，程序发生跳转；条件为假（即零标志ZF=0）时，程序顺序执行下条指令。跳转地址=PC+offs，offs为带符号地址偏移量。\nIf(ZF==1) then { T1: Y\u0026lt;-IR T2: Z\u0026lt;-PC+Y T3: PC\u0026lt;-Z } PUSH R0 实现将寄存器R0中的数据压入到堆栈中。\nT1: SP\u0026lt;-SP-n // SP指向新栈顶，n为一次压栈的字节数 DR\u0026lt;-R0 T2: AR\u0026lt;-SP T3: Memory[AR]\u0026lt;-DR, Mwrite POP R0 实现将堆栈栈顶的数据弹出至寄存器R0中。\nT1: AR\u0026lt;-SP T2: DR\u0026lt;-Memory[AR], Mread T3: R0\u0026lt;-DR SP\u0026lt;-SP+n //将SP指向新栈顶，n为一次弹出的字节数 CALL(X) 子程序调用指令。将程序执行地址从当前调用指令所在位置转移到以存储器地址X间接寻址的存储单元处，并保存返回地址。\nT1：SP\u0026lt;-SP-n DR\u0026lt;-PC T2：AR\u0026lt;-SP T3：Memory[AR]\u0026lt;-DR, Mwrite T4：AR\u0026lt;-IR T5：DR\u0026lt;-Memory[AR], Mread T6：PC\u0026lt;-DR RET 子程序返回指令，实现从堆栈栈顶处获得子程序调用时保存的返回主程序的地址。\nT1: AR\u0026lt;-SP T2: DR\u0026lt;-Memory[AR], Mread T3: PC\u0026lt;-DR SP\u0026lt;-SP+n 控制器的组成 控制器应完成的任务：\n产生微命令（即控制信号） 按节拍产生微命令 在设计控制器前需要：\n定义计算机基本硬件组成和基本指令系统 基于定义的硬件结构，针对每条指令，描述CPU完成的微操作 确定控制单元应该完成的功能，即何时产生何种微命令 有两种方法：\n硬布线控制设计法 微程序控制或微码控制设计法 硬布线控制器设计 硬布线控制器设计法将控制单元看作一个顺序逻辑电路或有限状态机，它可以产生规定顺序的控制信号，这些信号与提供给控制单元的指令相对应。\n它的设计目标是：使用最少的元器件，达到最快的操作速度。\nRISC-V\n对于RISC-V，其为单周期实现。\n类x86\n对于类x86系统，其为多周期实现。有两种设计方法：\n采用一级时序，即只利用节拍信号。一条指令执行的全过程是用一个从取指令到执行指令的完整微操作序列来描述的，而且对这个微操作序列也是从头至尾分配节拍的。 采用两级时序，即利用节拍和CPU周期两种时间信号。按照CPU周期来描述一条指令的微操作序列。 我们要从微操作序列得出微命令序列。例如把AR\u0026lt;-PC转换为\\(PC_{out},AR_{in}\\)\n由控制单元产生并加载到CPU内外的全部控制信号均可用下述形式表述：\n两级时序：\n\\[C_i = \\sum(M_m\\cdot T_n\\cdot I_j\\cdot F_k) \\]\n在执行指令\\(I_j\\)时，若状态\\(F_k\\)满足要求，则在第\\(m\\)个CPU周期\\(M_m\\)的第\\(n\\)个节拍\\(T_n\\)，控制单元发出\\(C_i\\)控制命令。\n一级时序：\n\\[C_i = \\sum(T_n\\cdot I_j\\cdot F_k) \\]\n总结：\n每个控制信号的逻辑表达式就是一个与或逻辑方程式。 用一个与或逻辑电路就可以实现该控制信号的生成。 将所有控制信号的与或逻辑电路组合在一起就构成了硬布线控制单元。 时间信息（单周期实现不需要）、指令信息、状态信息是硬布线控制单元的输入，控制信号是硬布线控制单元的输出。 特点： 一旦完成设计，改变控制器的行为的唯一方法就是重新设计电路（修改不灵活） 在现代复杂处理器中，需要定义庞大的方程组（与或组合电路实现困难） 微程序控制器设计 用软件方法组织和控制数据处理系统的信息传送，并最终用硬件实现。依据微程序顺序产生一条指令执行时所需的全部控制信号。相当于把控制信号存储起来，因此又称存储控制逻辑方法。\n对在一个时间单位（节拍）内出现的一组微操作进行描述的语句称作微指令。\n一个微指令序列称作微程序或固件。\n通过一组微指令产生的控制信号，使一条指令中的所有微操作得以实现，从而实现一条指令的功能。\n一条（机器）指令对应一个微程序，该微程序包含从取指令到执行指令一个完整微操作序列对应的全部微指令，它被存入一个称为控制存储器的ROM中。\n微指令周期：一条微指令执行的时间（包括从控制存储器中取得微指令和执行微指令所用时间）。\n微指令格式 水平型微指令\n多个控制信号同时有效-\u0026gt;多个微操作同时发生\n3.jpg\r垂直型微指令\n类似于机器指令，利用微操作码的不同编码来表示不同的微操作功能。\n4.jpg\r微程序控制器的一般结构和工作原理 5.jpg\r微指令地址的生成 两地址格式 单地址格式 可变格式 微指令控制域编码 水平型微指令控制域的编码： 直接表示法 译码法 字段译码法 垂直型微指令控制域的编码 微程序设计及示例 微程序结构\n在设计微程序时，通常采用如下两种典型结构\n一条指令对应一段完整的微程序 将微程序中的公共部分设计成微子程序进行公共调用 编写微程序\nCPU性能测量与提高 CPU性能测量 CPU主频\\(f_{CLK}\\)：CPU使用的时钟的频率，单位为赫兹。\nCPU时钟周期\\(T_{CLK}\\)：时钟频率的倒数。\n一般而言，主频高代表速度快。\nCPU时间\n运行一个程序所花费的时间\n响应时间：CPU时间与等待时间（包括用于磁盘访问、存储器访问、I/O操作、操作系统开销等时间）的总和。\n假设时钟周期为\\(T_{CLK}\\)，执行某程序时，CPU需要使用\\(N\\)个时钟周期，那么，CPU执行该程序所用时间为\n\\[T_{CPU}=N\\times T_{CLK} = N/f_{CLK} \\]\nCPI与IPC\nCPI是每条指令执行所用的时钟数的平均值。\nIPC是每时钟周期执行的指令数。\n设某个程序要用\\(N\\)个时钟周期，该程序汇总的指令数为\\(I\\)，其CPI记为\\(CPI\\)，则\n\\[N = I\\times CPI \\]\n\\[T_{CPU} = I\\times CPI\\times T_{CLK} = \\dfrac{I\\times CPI}{f_{CLK}} \\]\n有三方面的因素使得程序的CPI可能不同于CPU执行的CPI：\nCache行为发生变化 指令混合发生变化 分支预测发生变化 影响CPU性能的三个关键因素：\nCPI 时钟频率 指令数 MIPS\nCPU每秒钟执行的百万指令数。\n\\[MIPS = \\dfrac{I}{T\\times 10^6} = \\dfrac{f_{CLK}}{CPI\\times 10^6} \\]\n其中\\(T\\)为程序的执行时间。\nMIPS的局限：\n不能对指令集不同的计算机使用MIPS进行比较：MIPS只说明了指令执行速率，而没有考虑指令的能力 计算机对所有程序没有单一的MIPS值：对于同一个计算机上的不同程序，MIPS是变化的 MIPS会与性能反向变化 Flops\nCPU每秒完成的浮点运算次数\n\\[FLOPS = \\dfrac{M}{T} \\]\n其中\\(M\\)为浮点运算次数，\\(T\\)为执行时间。\nFLOPS可以用于不同计算机之间的比较。\n就像MB，GB，TB。FLOPS也有MFLOPS，GFLOPS，PFLOPS等等\nCPU性能提高 采用更先进的硅加工制造技术 缩短指令执行路径长度。减少执行指令的时钟周期数：优化微操作、微程序；双总线、三总线；增加特定硬件，实现并行 简化组织结构来缩短时钟周期。例如RISC 采用并行处理技术。指令级和处理器级并行 多核与多线程技术 流水线技术 流水线处理的概念 流水线的处理方式 若将一重复的处理过程分解为若干子过程，每个子过程都可在专用设备构成的流水线功能段上实现，并可与其它子过程同时执行，这种技术称为流水技术。\n流水线的类型 按流水线位于计算机系统的层次划分\n系统级流水线/宏流水线：在多个系统中有多个处理机串行构成的流水线 处理器级流水线：在处理器内部由多个部件构成的流水线。——指令流水线 部件级流水线：在处理器中某部件内部由多个子部件构成的流水线。 按功能强弱划分\n单功能流水线 多功能流水线 按是否有反馈回路划分\n线性流水线 非线性流水线-流水线调度 按流水线输出端任务流出顺序与输入端任务流入顺序是否相同划分\n顺序流动流水线（入出顺序相同） 异步流动流水线（入出顺序不同） 按流水线一次处理对象的数量划分\n标量流水线 超标量流水线 向量流水线 超长指令字流水线 设计运算流水线的一般方法 寻找一个适当的、可分解为多步骤的、连续运行的算法，该算法的每一步骤应是时间均衡的、可以由硬件电路实现的。 将实现算法每一步骤的硬件电路作为流水线的一段，并按照步骤顺序将各段连接起来。 在流水线各段之间放置快速缓冲寄存器来分离各段，并利用缓冲寄存器逐段传送处理数据（部分或全部结果）。所有缓冲寄存器受同一时钟控制。 指令流水线 基本的指令流水线 指令流水线是利用执行指令时存在的直接并行性实现多条指令重叠执行的一种技术。\n指令流水线对于程序员是不可见的，它由程序编译器和CPU内部程序控制单元自动管理。\n如果流水线各段采用同步方式控制各段间信息的同步推进，则流水线同步控制时钟的周期应选定为\n\\[T_{CLK} = \\max_i\\{\\tau_i\\} \\]\n其中\\(\\tau_i\\)是该指令的运行时间。由于时钟周期取决于最长指令的运行时间，所以其他指令运行完后就要等待，造成浪费，速度减慢。所以要将指令的执行步骤再分解，使每一步骤所用时间尽可能均衡，并依此设计一个多级的指令流水线。\n例如，将指令处理分为以下四步\n指令获取（IF）：从主存或cache中获取指令并对指令进行译码 操作数加载（OL）：从主存或cache中获取操作数放入寄存器中 执行指令（EX）：利用ALU等执行部件，对寄存器中的操作数进行处理，结果存于寄存器中 写操作数（WO、OS）：将寄存器中的结果存入主存或cache中 指令流水线策略 采用深度指令流水线结构 将指令的执行过程进一步细化，使流水线的级（段）数变多，而每一级的工作更少（有可能一个时钟周期完成）、时间更均衡。\n多条流水线结构 流水线性能测量 时空图 装入时间=(流水线级数-1)\\(\\times\\)时钟周期\\(\\tau\\)；\\(\\tau=(1\\sim n)\\times T_{CLK}\\)\n吞吐率 吞吐率：指单位时间内流水线所完成的任务数或输出结果的数量，它是衡量流水线速度的重要指标。\n最大吞吐率\\(TP_{max}\\)：流水线在达到稳定状态后所得到的吞吐率。\n假设流水线各段运行时间相等，为\\(1\\)个时钟周期\\(T_{CLK}\\)，则：\n\\[TP_{max} = 1/T_{CLK} \\]\n假设流水线各段运行时间不等，第\\(i\\)段时间为\\(\\tau_i\\)，则：\n\\[TP_{max} = 1/\\max_i\\{\\tau_i\\} \\]\n所以瓶颈在于最慢的一段。消除瓶颈的办法有：\n细分瓶颈段（首选）（例如把他拆分成两个阶段） 重复设置瓶颈段（即物理上再增加一个一样的，和原来的并联） 实际吞吐率\n之前说的吞吐率是当待执行任务无限多时，取得的极限。若流水线由m段组成，完成n个任务的吞吐率称为实际吞吐率，记作\\(TP\\)。\n假设流水线各段运行时间相等，为\\(1\\)个时钟周期\\(T_{CLK}\\)，在不出现流水线断流的情况下，完成\\(n\\)个任务所用时间为\n\\[T_n(m) = (m+(n-1))\\tau = (m+(n-1))T_{CLK} \\]\n实际吞吐率为\n\\[TP = \\dfrac{n}{T_n(m)} = \\dfrac{n}{(m+(n-1))\\times T_{CLK}} = \\dfrac{TP_{max}}{1+\\dfrac{m-1}{n}} \\]\n假设流水线各段运行时间不等，第\\(i\\)段时间为\\(\\tau_i\\) ，则完成\\(n\\)个任务所用时间为\n\\[T_n(m) = \\sum^m_{i=1}\\tau_i + (n-1)\\times \\max_i\\{\\tau_i\\} \\]\n实际吞吐率为\n\\[TP = \\dfrac{n}{\\sum^m_{i=1}\\tau_i + (n-1)\\times \\max_i\\{\\tau_i\\}} \\]\n对于指令流水线而言，吞吐率TP就是每秒执行的指令数，所以也可以用MIPS指标表示吞吐率，即\n\\[TP = MIPS = f_{CLK}/CPI \\]\n对于单流水线系统，它的\\(CPI\\)是\\(1\\)，所以\\(TP_{max} = f_{CLK}\\)\n加速比 若流水线为\\(m\\)段，加速比\\(S\\)定义为等功能的非流水线执行时间\\(T(1)\\)与流水线执行时间\\(T(m)\\)之比，即\n\\[S = S_n(m) = T_n(1)/T_n(m) \\]\n若每段运行时间均为\\(\\tau\\)，在不流水情况下，总时间为\\(T_n(1)=nm\\tau\\)\n在流水但不出现断流的情况下，完成n个任务所需时间为\\(T_n(m)=m\\tau+(n-1)\\tau\\)，因此\n\\[S_n(m) = \\dfrac{mn}{m+n-1} = \\dfrac{m}{1+\\dfrac{m-1}{n}} \\]\n从上式可以看出，增大流水线的级数和送入流水线的指令数均可以加速流水线的运行速度。\n效率 效率：流水线中各功能段（或设备）的利用率。\n由于流水线有通过（填充）时间和排空时间，还有各种引起断流的状况，所以流水线的各段并非一直满负荷工作，效率\\(E\u003c1\\)。\n通常用流水线各段处于工作时间的时空区（面积）与流水线中各段总的时空区（面积）之比来衡量流水线的效率。\n\\[E = \\dfrac{n个任务占用的时空区}{m个段总的时空区} \\]\n假设流水线各段运行时间相等为\\(\\tau\\)，则整个流水线效率\\(e\\)为：\n\\[E = \\dfrac{mn\\tau}{m(m+n-1)\\tau} = \\dfrac{n}{m+n-1} = \\dfrac{1}{1+\\dfrac{m-1}{n}} \\]\n指令流水线的性能提高 流水线的基本性能问题 限制指令流水线性能提高的因素：\n流水线的深度受限于流水线的延迟、流水线段的时间不均衡和流水线的额外开销。 指令执行时可能存在的“相关”或“冒险”问题。 冒险：指相邻或相近的两条指令因存在某种关联，后一条指令不能在原指定的时钟周期开始执行。\n冒险分为三类：\n结构冒险：资源冲突 数据冒险：一条指令需要用到前面某条指令的结果 控制冒险：分支等转移类指令/其他能够改变PC值的指令 前两个是局部性相关，后一个是全局性相关\n结构冒险 有两种情况会导致结构冒险：\n部分功能单元没有充分流水\n解决办法：将流水线设计的更合理。\n资源冲突\n当两个以上流水线段需要同时使用同一个硬件资源时，发生冲突。\n解决办法：\n增加资源副本。如哈佛结构、两个ALU 改变资源以便它们能并发的使用。不相关的数据尽量使用不同的寄存器；寄存器重命名 通过延迟（或暂停）流水线的冲突段或在冲突段插入流水线气泡（气泡在流水线中只占资源不做实际操作），使各段“轮流”使用资源。 数据冒险 指令在流水线中重叠执行有可能改变指令读/写操作数的顺序\n当一条指令的结果还未有效生成，该结果就被作为后续指令的操作数时，数据冒险出现。\n解决办法：\n增加专用硬件（推后法）。增加流水线互锁（pipeline interlock）硬件。当互锁硬件发现数据相关时，使流水线工作停顿下来，直到冒险消失为止。 采用直通/转发技术 乱序，流水线（指令）调度：利用编译器（RISC），硬件（CISC）。编译器可以对指令重新排序或插入空操作指令 对寄存器读写做特别设计 控制冒险 使程序执行顺序发生改变的转移指令有两类：\n无条件转移指令（如无条件跳转、调用、返回指令等） 条件分支转移指令（为零跳转、循环控制指令等） 处理办法：\n冻结流水线 静态分支预测 动态分支预测 延迟分支 冒险影响性能 冒险可能引起流水线停顿, 停顿也称为流水线气泡。\n有停顿的流水线的CPI为：CPI = 理想流水线CPI+(结构冒险停顿 + 数据冒险停顿 + 控制冒险停顿) / 指令数\n有停顿的流水线的加速比为：\n\\[加速比=\\dfrac{流水线深度}{1+平均每条指令的流水线停顿周期} \\]\n多发射处理器 多发射(Multiple Issue)是在一个时钟周期内启动多个指令并行执行的处理器实现方案。\n实现多发射处理器主要有两种方法:\n静态多发射——编译时由编译器决定 动态多发射——执行过程中由处理器决定 指令级并行 ","date":"2023-03-29T16:00:26+08:00","image":"https://kegalas.top/inferior/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/cover_huaa3a4f4fef897a96376c721aafe499bc_261058_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"计算机组成原理学习笔记"},{"content":"原版快捷键 光标、页面移动相关 按键 功能 C-v 下一屏 M-v 上一屏 C-l 重绘屏幕，将光标至于中央、顶端、底端 C-p 方向键上 C-n 方向键下 C-b 方向键左 C-f 方向键右 M-f 这个词的末尾 M-b 这个词的开头 C-a 行首 C-e 行尾 M-a 这一句的开头 M-e 这一句的末尾 M-\u0026lt; 文件开头 M-\u0026gt; 文件末尾 C-M-v 在另一个window里下一屏 C-M-S-v 在另一个window里上一屏 M-g M-g 行号 跳转到某一行 文本操作 按键 功能 \u0026lt;DEL\u0026gt; 删除(delete)光标前的一个字符，windows上为Backspace C-d 删除光标后的一个字符 M-\u0026lt;DEL\u0026gt; 移除(kill)光标前的一个词 M-d 移除光标后的一个词 C-k 移除光标到行尾间的字符 M-k 移除光标到句尾间的字符 C-\u0026lt;SPC\u0026gt; 开始标记范围，从光标处开始，移动光标扩大选中范围 C-w 移除选中范围的字符，其实就是剪切 M-w 复制选中范围的字符 C-y 召回(yanking)被最近一次移除(kill)的字符 M-y 在C-y之后，紧接着使用，可以替换为召回再上一次被移除的字符，连续使用多次则替换为召回在上多次被移除的字符 C-/ 撤回，多次使用则撤回更以前的操作。如果使用C-g打断undo，则之后的C-/是重做 C-s 向下文搜索。再次按C-s则搜索下一个出现的位置。\u0026lt;Return\u0026gt;即回车将光标停在这个位置，结束搜索。C-g结束搜索并将光标还原到原来的位置 C-r 向上文搜索,其他类似 M-x replace-string 替换字符串 C-o 与回车不同的是，光标不会进入到下一行 C-x C-o 将光标前后的所有空白行变成一个空白行 C-x h 全选 文件相关 按键 功能 C-x C-f 寻找并打开一个文件，如果不存在，则新建这个文件 C-x C-s 保存文件 C-x C-r 以只读方式打开文件 C-x C-q 切换为只读模式 Buffer相关 按键 功能 C-x C-b 列出Buffer C-x b 缓冲区名 切换到这个缓冲区 C-x s 保存多个缓冲区 Window相关 按键 功能 C-x 0 关闭当前光标所在的window C-x 1 保留当前光标所在的window，关闭其他所有 C-x 2 将屏幕分为上下两个window C-x 3 将屏幕分为左右两个window C-x o 光标切换到另一个window C-x 4 以该命令为前缀时，表示在另外一个窗口做……例如C-x 4 f表示在另一个窗口打开新文件 其他 按键 功能 C-u 数字 其他命令 给其他命令传递一个数字，大部分都是重复次数 C-g 取消没输完的命令或者正在执行的命令 C-x 字符扩展，之后输入另一个字符或组合键 M-x 命令名扩展，之后输入一个命令名 C-x C-c 退出Emacs C-x C-= 放大字号 C-x C-- 减小字号 C-x C-0 默认字号 evil-mode快捷键 大部分都是从vim教程中整理来的，标注一些与emacs冲突的快捷键。\n光标、页面移动相关 按键 功能 j 向下 k 向上 h 向左 l 向右 w 移动到下一个单词开始。W,b,B,$等可通过motion表推出来 2w 往后移动两个单词，类似的33w是33个单词，33b等可以类推 C-o 在搜索后移动到之前的位置 C-i 相当于C-o的反向操作 % 当前光标是括号的话，光标移动到与该括号匹配的括号 C-f 下一屏 C-b 上一屏 行号-G 输入行号后按G，跳转到行号，也可以用:行号 行号-\u0026lt;RET\u0026gt; 输入行号后回车，跳转到n行后 切换模式 按键 功能 \u0026lt;ESC\u0026gt; 切换到命令模式（指从其他模式退出） i 输入模式（方框光标的字符前，竖线光标则为原地） a 输入模式（方框光标的字符后，竖线光标则为下一个字符） A 输入模式（光标在行尾） v 可视模式，跟emacs原版的C-\u0026lt;SPC\u0026gt;可以说是一样 o 在光标下新建一行并换到插入模式 O 在光标上新建一行并换到插入模式 motion motion有些类似原版emacs指令中，C-x后面加的那个东西。\nmotion 含义 w 从光标开始，到（本行）下一个单词的第一个字符前。标点符号会被识别为单独的单词 W 遇上一个不同的是，单词只会被空字符隔开，如果标点符号和字母连在一起会是一个单词 b 光标开始往左数，第一个单词的首字母，如果在单词中间使用会移动到该单词首字母 B 类似于W与w的区别 e 光标开始，到本单词的最后一个字符，竖线光标为字符前，方框光标则为该字符 E 类似于W与w的区别 $ 光标开始到行尾 g_ 光标开始到本行最后一个非空字符 0 光标之前到行首 ^ 光标之前到本行第一个非空字符 G 光标开始到文本最后一行第一个非空字符 gg 光标前到文本第一行第一个非空字符 文本相关 按键 功能 x 删除（也可理解为剪切）光标所在的字符（光标是方框时，如果光标是竖线则删除之后的一个字符） dw 删除光标开始，到下一个单词的第一个字符前。dW,db,dB,d$之类可以类推 d2w 删除两个单词，d33w则是删除33个，d33b可以类推 dd 删除一整行，2dd删除光标所在的和下一行，以此类推 u 撤销操作 U 撤销对改行的操作 C-r 重做操作（emacs不兼容，推荐用C-g打断后再用u撤销撤销） p 在方框光标后粘贴文本，可以是从外部剪贴板来的，也可以是之前操作删除的（可以理解为只有剪切操作而没有删除） y 复制v模式选中的文本 yw 复制一个词，其他类推 r 输入之后输入任意字符，把方框光标的字符替换为该字符 R 替换更多字符，有些类似其他文本编辑器按到了Insert cw 其实就只是dw操作完后直接进入插入模式，ce,cb等类推，c2w等也类推 /name 搜索name，完成后按回车。按n搜索下一个，N搜索上一个 ?name 反向搜索name，和/的操作逻辑正好相反 :s/old/new 将本行的第一个old替换为new :s/old/new/g 将本行的所有old替换为new :#,#s/old/new/g 将#,#这两个行号之间的所有行的old替换为new :%s/old/new/g 将全文的old替换为new :%s/old/new/gc 替换全文，但是会要求逐个确认 /name\\c 搜索时忽略大小写（暂时） :set ic 设置永久忽略大小写 :set noic 设置成永久不忽略大小写 文件相关 按键 功能 :w 保存文件（可以和q结合使用，见后） :w filename 另存为filename :\u0026rsquo;\u0026lt;,\u0026rsquo;\u0026gt;w filename 用v选中一些字符后，按:会自动出现\u0026rsquo;\u0026lt;,\u0026rsquo;\u0026gt;，输入w filename将选中的东西另存为 :r filename 将filename里的东西复制到光标后 :r !dir 将dir命令的输出复制到光标后 其他 按键 功能 :q 退出程序 :wq 保存并退出 :q! 未保存强制退出 :!command 执行外部命令，例如:!ls evil代替不了或者最好不要代替的原版按键 M-x\n由于安装了counsel，提供的命令列表不宜直接替换为:，因为这两个是不同的东西。虽然都是输入命令，但是:经常只会使用一些短小的命令，例如:dw，:wq。虽然:也能使用emacs里面的其他指令，例如package-install，但是却又没有补全。而M-x补全强大，但是根本无法使用:dw, :wq。综上不建议替代。不应当把counsel绑定到:上\nC-s\n由于安装了swiper，emacs的搜索快捷键被替换成了更强的插件，与/或者?相比也算是操作逻辑有不同，不应当把swiper绑定到/或者?上。\nC-x\n很多关于buffer，file，window的操作是emacs特有的，不应该换掉。好在原版vim也没有C-x这个快捷键。不过是否可以把切换window的操作绑定成vim的，TODO。\n另外注意，不应当把undo-tree绑定到u和C-r上，具体怎么做，TODO。\n\u0026lt;f1\u0026gt;~\u0026lt;f12\u0026gt;\n大部分也都是绑定的插件，没有必要替换。\nM-., M-?\n感觉可以替换成vim按键，TODO。\n自己设置的快捷键\n尝试找到vim的替代，TODO。\n自用插件 use-package 在init.el里自动安装其他插件的必备。通常可以用M-x package-install来手动安装use-package。\ngood-scroll 平滑滚动的插件。\nmwim 优化了原版的C-a和C-e快捷键，具体如下。\n按键 功能 C-a 跳到文字的开头或这一行的开头 C-e 跳到文字的结尾或一行的结尾 但是安装了evil后，我怀疑这个插件是否有必要，TODO。\nall-the-icons 提供emacs内许多图标的显示功能，需要在下载插件后M-x all-the-icons-install-font。或是去其github下载fonts安装后才能使用。\ncounsel、ivy、swiper 三个著名的插件，优化了诸多功能，如搜索、切换buffer、文件操作、命令列表等等。\n下面的命令可能会根据我使用的熟练程度来更新。\n按键 功能 C-s 使用swiper代替原版的搜索 C-x b 替代原版的buffer列表 C-x C-f 替代原版的文件操作 M-x 替代原版的命令列表 amx 将我们在M-x中输入命令的历史记录下来，每次显示最常用的。\nace-window 按键 功能 C-x o 优化切换window的操作逻辑，可以根据编号进行切换 undo-tree 提供比原版更好的撤销、重做操作。\n按键 功能 C-x u 打开undo tree which-key 在输入快捷键时提醒我们可以接下来输入什么，以及有什么功能。\nflycheck 语法检查程序，对于c/c++需要装好clang才能使用。另外在windows上并不是完美支持的，虽然github的issue里最近没有什么东西。\nsolarized-theme Emacs下的Solarized主题。\nayu-theme 一个主题。我目前喜欢Ayu的light主题胜过了Solarized的light主题。\ndashboard 一个欢迎界面。\nyasnippet 在补全的时候提供代码片段。\nhighlight-symbol 高亮Buffer中所有的、与光标处符号相同的符号。按\u0026lt;f3\u0026gt;开启。\n按键 功能 \u0026lt;f3\u0026gt; 开启高亮 rainbow-delimiters 彩虹括号，方便在lisp系语言中看清。\navy 一套跳转光标的操作。暂时还不太会使用。\n见https://github.com/abo-abo/avy\ncompany 自动补全插件。\n按键 功能 \u0026lt;f1\u0026gt; 显示候选项的文档（如果有、如果支持） company-box 在图形界面下为company提供图标。以及可以开一个小的悬浮窗口展示候选项的文档（如果有）。但是其有一些问题，我觉得还是不开好。\nlsp-mode 代码分析。如定义跳转等等功能由lsp提供。\nlsp-ui 为lsp提供图形化的显示，同时\n按键 功能 M-. 寻找符号定义 M-? 寻找符号引用 lsp-ivy 使lsp和ivy协作，可以通过命令 lsp-ivy-workspace-symbol 来搜索当前工作区的符号。\nprojectile 项目管理插件。通常我们查找一个函数的定义或者别的什么的定义的时候，这些定义并不会在同一个文件里，而是在同一个项目里，此时我们lsp需要projectile才能正确查找。\ncounsel-projectile 允许我们在项目中进行搜索。\nmagit 内置git。\nneotree 打开文件夹树形结构图\n按键 功能 \u0026lt;f8\u0026gt; 打开neotree c++-mode 提供c++、c的支持。\npowerline 更好的mode-line显示。\nyasnippet-snippets 相当于yasnippet那个插入代码片段的插件的一个范例。\nmarkdown-mode 与markdown相关，还在探索中。\ntexfrag 与latex相关，还在探索中。\ngoto-chg evil部分功能的前置插件。\nevil 使我们可以在emacs中使用vim的快捷键\n自用设置 init.el https://github.com/kegalas/.emacs.d/blob/main/init.el\n额外快捷键 按键 功能 M-n 下十行 M-p 上十行 C-\u0026lt;TAB\u0026gt; 打4个空格，而不是像TAB在emacs中的智能缩进 C-c c 适用于打codeforces等竞赛，编译当前window里的单c++文件 ","date":"2023-01-20T16:09:29+08:00","permalink":"https://kegalas.top/inferior/emacs%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","title":"Emacs使用笔记"},{"content":"导航页面\nTGA格式介绍 具体可以参考http://paulbourke.net/dataformats/tga/\n这里将部分重要的介绍一下。\n首先为了简单起见，我们使用没有颜色表，也没有压缩的TGA格式。\n文件头 首先是文件头。\n字节数 内容 1 图像信息长度 1 颜色表类型 1 图像类型 5 颜色表规范 10 图像规范 图像信息长度\n我们并不会使用这个部分，所以我们定为0.\n颜色表类型\n0代表不使用颜色表，1代表使用，我们定为0.\n图像类型\n0代表没有图像数据，2代表未压缩的真彩色图像，3代表未压缩的彩色图像，其他类型可以参照原文。\n颜色表规范\n前两个字节为颜色表首地址，然后的两个字节为颜色表长度，最后一个字节是颜色表位数。我们不会使用颜色表，所以全部设置为0.\n图形规范\n十个字节分为\n字节数 内容 2 图像x坐标起始位置 2 图像y坐标起始位置 2 图像宽度 2 图像高度 1 每个像素占用的位数 1 图像描述字节 和一些图像格式不同，TGA的坐标原点是左下角。不过这不影响我们选择xy坐标起始位置为(0,0)。\n图像宽度和高度也不难理解，唯一需要注意的是，数据是以小端序来存储的，也就是说800在用两个字节表示，16进制的形式是，0x0320。但是实际上写入文件时，由低到高，第一个字节是20，第二个字节是03，连起来是2003。\n每个像素占用的位数，如果是黑白图像，只有一个颜色，也就是0~255，只需要一个字节，也就是8位，所以会显示为8. 如果是RGB图像，就会是24，RGBA图像，就会是32. 值得注意的一点是，写入到文件的顺序是BGR和BGRA。\n图像描述字节，占一个字节，从低到高，\n0-3位 TGA 16位图像设为0或1，TGA 24位设为0，TGA 32位设为8. 原文并没有说8位图像设置为多少，我设置为0没有问题。\n4位 必须为0\n5位 设置原点在左下角还是左上角，0为左下角，1为左上角，实际上就是垂直翻转图像，不过TGA默认为0.\n6-7位 我们不考虑这个，直接设置为0，原文有详细解释\n图像信息 如果没有颜色表，那么在文件头的十八个字节之后就进入图像信息。\n很简单，如果是黑白图像，每个字节表示一个像素。如果是RGB图像，每三个字节表示一个像素，并且在文件中是以BGR的顺序放置的。如果是RGBA图像，每四个字节表示一个像素，并且在文件中是以BGRA的顺序放置的。\n总共有“宽\\(\\times\\)高\\(\\times\\)每个像素占用的字节数”个字节\n文件尾 在写完图像信息之后是文件尾，内容包含\n字节数 内容 2 扩展区域 2 开发者自定义区域 8 签名 2 结束 扩展区域和开发者自定义区域我们不用，直接设置为0.\n签名是TRUEVISION-XFILE的ASCII码表示，注意小端序。如果我们用两个uint64表示，就是0x4953495645555254和0x454C4946582D4E4F\n最后的结束是ASCII中的.符号和eof符号，分别是0x2E和0x00，写成一个uint16就是0x002E（考虑小端序）。\n整个TGA文件到此结束。\ntga_image.h 首先我们根据文件头的描述设定一个结构体\nstruct TGAHeader{ std::uint8_t length = 0; //TGA图像Identification Field的长度 std::uint8_t colorMapType = 0; //0：不使用颜色表，1：使用颜色表 std::uint8_t imageType = 0; //图像类型，2代表未压缩的真彩色图像，3代表未压缩的黑白图像 std::uint16_t cMapStart = 0; //颜色表首地址 std::uint16_t cMapLength = 0; //颜色表长度 std::uint8_t cMapDepth = 0; //颜色表位数 std::uint16_t xOffset = 0; //x坐标的起始位置 std::uint16_t yOffset = 0; //y坐标的起始位置 std::uint16_t width = 0; //图形宽度 std::uint16_t height = 0; //图像高度 std::uint8_t pixelDepth = 0; //图像每一个像素占用的位数，例如RGB为24位，RGBA为32位 std::uint8_t descriptor = 0; //图像描述信息，可见http://paulbourke.net/dataformats/tga/ TGAHeader(){} }; 然后是文件尾的结构体\nstruct TGAFooter{ std::uint32_t extend = 0; //扩展区域 std::uint32_t custom = 0; //开发者自定义区域 std::uint64_t sig1 = 0; //签名1 std::uint64_t sig2 = 0; //签名2 std::uint16_t end = 0; //结束 TGAFooter(){ sig1 = 0x4953495645555254; //TRUEVISI sig2 = 0x454C4946582D4E4F; //ON-XFILE end = 0x002E; } }; 注意，内存默认是以4字节对齐的，我们需要使用如下语句来保证对齐到1个字节，防止写入错误。\n#pragma pack(push) #pragma pack(1) //...这里放入刚刚的两个结构体。 #pragma pack(pop) 方便起见，我们定义\nnamespace TGAType{ const unsigned int rgb = 0; const unsigned int rgba = 1; const unsigned int grey = 2; const unsigned int pixelSize[] = {3,4,1}; } 来帮助我们定义颜色的编号和颜色格式占用的字节数，这可能并不是最好的写法，并且可能会暴露我的C++水平。\n然后我们给文件头一个新的构造函数\nTGAHeader(unsigned int type, std::uint16_t width_, std::uint16_t height_){ if(type == TGAType::rgb){ imageType = 2; pixelDepth = 24; } else if(type == TGAType::rgba){ imageType = 2; pixelDepth = 32; } else if(type == TGAType::grey){ imageType = 3; pixelDepth = 8; } else{ std::cerr\u0026lt;\u0026lt;\u0026#34;Error! Wrong TGA Type!\\n\u0026#34;; } width = width_; height = height_; if(type == TGAType::grey || type == TGAType::rgb){ descriptor |= 0x00; } else if(type == TGAType::rgba){ descriptor |= 0x08; } } 这不难理解，如果我们要写入到一个新的文件中，我们定义它的颜色类型和宽度高度，然后修改内容。\n之后我们定义一个图片类\nclass TGAImage{ private: std::uint16_t width; std::uint16_t height; std::uint8_t *data; unsigned int type; bool isFlipVertically; public: TGAImage(std::uint16_t const width_, std::uint16_t const height_, unsigned int const type_); TGAImage(std::string const \u0026amp; dir); ~TGAImage(); bool readFromFile(std::string const \u0026amp; dir); bool writeToFile(std::string const \u0026amp; dir); bool setFragment(std::uint16_t const x, std::uint16_t const y, geo::OARColor const \u0026amp; color); bool flipVertically(); inline std::uint16_t getWidth(){return width;} inline std::uint16_t getHeight(){return height;} }; 赋予了它少量功能，包括读写图片文件，图像翻转，以及设置某个像素的颜色值。\n完整的代码在这里\ntga_image.cpp TGAImage::TGAImage(std::uint16_t const width_, std::uint16_t const height_, unsigned int const type_){ width = width_; height = height_; type = type_; data = new std::uint8_t[width*height*TGAType::pixelSize[type]]; isFlipVertically = 0; std::fill(data,data+width*height*TGAType::pixelSize[type],0); } 首先是一个构造函数，也不难理解，只是设定了图像自身的属性以及分配了图像数据的内存。\n注意我们分配图像数据内存的时候，要乘以每个像素占用的字节数。同时注意要把图像数据清零，也可以用memset来。\nTGAImage::TGAImage(std::string const \u0026amp; dir){ readFromFile(dir); } 如果要从文件中定义个新图像，则我们直接调用读取文件的功能。\nTGAImage::~TGAImage(){ delete[] data; } 析构函数，释放内存。\n读取文件\nbool TGAImage::readFromFile(std::string const \u0026amp; dir){ //... } std::ifstream ifs; ifs.open(dir, std::ios::binary); if(!ifs.is_open()){ std::cerr \u0026lt;\u0026lt; \u0026#34;Error! Can\u0026#39;t open file: \u0026#34; \u0026lt;\u0026lt; dir \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; ifs.close(); return false; } 首先我们以二进制形式打开文件，并且检查错误\nTGAHeader header; ifs.read(reinterpret_cast\u0026lt;char *\u0026gt;(\u0026amp;header), sizeof(header)); if(!ifs.good()){ std::cerr \u0026lt;\u0026lt; \u0026#34;An error occured while reading the header. File: \u0026#34; \u0026lt;\u0026lt; dir \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; ifs.close(); return false; } if(header.descriptor\u0026amp;0x20){ isFlipVertically = 1; } width = header.width; height = header.height; if(width\u0026lt;=0||height\u0026lt;=0){ std::cerr \u0026lt;\u0026lt; \u0026#34;Error! Bad image width/height. File: \u0026#34; \u0026lt;\u0026lt; dir \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; ifs.close(); return false; } 然后我们读取文件头，并且检查是否成功读取以及数据是否有误。\nif(header.imageType == 2){ if(header.pixelDepth == 24){ type = TGAType::rgb; } else if(header.pixelDepth == 32){ type = TGAType::rgba; } else{ std::cerr \u0026lt;\u0026lt; \u0026#34;Error! Unknown pixel depth. File: \u0026#34; \u0026lt;\u0026lt; dir \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; ifs.close(); return false; } } else if(header.imageType == 3){ type = TGAType::grey; if(header.pixelDepth != 8){ std::cerr \u0026lt;\u0026lt; \u0026#34;Error! Unknown pixel depth. File: \u0026#34; \u0026lt;\u0026lt; dir \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; ifs.close(); return false; } } else{ std::cerr \u0026lt;\u0026lt; \u0026#34;Error! Unknown image type. File: \u0026#34; \u0026lt;\u0026lt; dir \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; ifs.close(); return false; } 根据图像信息来设置图像信息。\nint pixelSize = TGAType::pixelSize[type]; data = new std::uint8_t[width * height * pixelSize]; ifs.read(reinterpret_cast\u0026lt;char *\u0026gt;(data), pixelSize*width*height); if(!ifs.good()){ std::cerr \u0026lt;\u0026lt; \u0026#34;An error occured while reading the data. File: \u0026#34; \u0026lt;\u0026lt; dir \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; ifs.close(); return false; } 分配内存并读入图像数据，之后检查错误。\nif(isFlipVertically){ flipVertically(); } 如果图像有翻转那么进行翻转。\n文件写入\n和文件读取大同小异，不再详细说明。\n翻转图像\nbool TGAImage::flipVertically(){ int pixelSize = TGAType::pixelSize[type]; int half = height/2; isFlipVertically = isFlipVertically^1; for(int i=0;i\u0026lt;width;i++){ for(int j=0;j\u0026lt;half;j++){ for(int k=0;k\u0026lt;pixelSize;k++){ std::swap(data[(i+j*width)*pixelSize+k], data[(i+(height-1-j)*width)*pixelSize+k]); } } } return true; } 如上，我们将isFlipVertically取反，并且将图像数据按height/2位轴做翻转。不过我们这里虽然叫图像翻转，但是最后输出的图像和原图不会有区别，因为我们翻转图像的时候同时改变了坐标原点的位置。这样做只是方便将两个坐标系下的图像数据统一到一起去计算。\n设置像素颜色\nbool TGAImage::setFragment(std::uint16_t const x, std::uint16_t const y, geo::OARColor const \u0026amp; color){ assert(x\u0026gt;=0 \u0026amp;\u0026amp; x\u0026lt;width \u0026amp;\u0026amp; y\u0026gt;=0 \u0026amp;\u0026amp; y\u0026lt;height); assert(color.r\u0026gt;=0 \u0026amp;\u0026amp; color.r\u0026lt;=255); assert(color.g\u0026gt;=0 \u0026amp;\u0026amp; color.g\u0026lt;=255); assert(color.b\u0026gt;=0 \u0026amp;\u0026amp; color.b\u0026lt;=255); assert(color.a\u0026gt;=0 \u0026amp;\u0026amp; color.a\u0026lt;=255); int pixelSize = TGAType::pixelSize[type]; size_t index = (y*width + x)*pixelSize; if(type==TGAType::grey){ data[index] = static_cast\u0026lt;std::uint8_t\u0026gt; (color.r/3.0+color.g/3.0+color.b/3.0+0.5); } else if(type==TGAType::rgb || type==TGAType::rgba){ data[index] = color.b; data[index+1] = color.g; data[index+2] = color.r; if(type==TGAType::rgba){ data[index+3] = color.a; } } else{ std::cerr\u0026lt;\u0026lt;\u0026#34;An error occured while set fragment\\n\u0026#34;; return false; } return true; } 主要注意下标要乘以像素占用的字节大小，以及颜色顺序为BGRA。\n完整的代码在这里\n使用例子 我们用红色画一条从左下到右上的斜线，我们可以用以下代码\n#include \u0026#34;tga_image.h\u0026#34; int main(){ TGAImage image(100,100,TGAType::rgb); for(int i=0;i\u0026lt;100;i++){ image.setFragment(i,i,{255,0,0,255}); } image.writeToFile(\u0026#34;./test.tga\u0026#34;); return 0; } 输出结果如下：\n1.jpg\r","date":"2022-11-01T14:24:29+08:00","image":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E5%9B%BE%E7%89%87%E5%A4%84%E7%90%86%E5%BA%93/cover_hu2fa2362891bfb402ec26ffe12b2b88a0_64078_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E5%9B%BE%E7%89%87%E5%A4%84%E7%90%86%E5%BA%93/","title":"从零开始的软渲染器 图片处理库"},{"content":"一些概念解释 弱人工智能与强人工智能 弱人工智能是指不能真正实现推理和解决问题的智能机器，这些机器表面看像是智能的，但是并不真正拥有智能，也不会有自主意识。\n强人工智能是指真正能思维的智能机器，并且认为这样的机器是有知觉的和自我意识的，这类机器可分为类人（机器的思考和推理类似人的思维）与非类人（机器产生了和人完全不一样的知觉和意识，使用和人完全不一样的推理方式）两大类。\n符号处理系统 六种功能 输入符号 输出符号 存储符号 复制符号 建立符号结构：在符号系统中形成符号结构 条件性迁移：根据已有符号，继续完成活动的过程 可以把人看作是一个物理符号系统。如果一个物理符号系统具有上述全部6种功能，能够完成这个全过程，那么它就是一个完整的物理符号系统。人具有上述6种功能；现代计算机也具备物理符号系统的这6种功能。\n有一个假设：任何一个系统，如果它能表现出智能，那么它就必定能够执行上述6种功能。反之，任何系统如果具有这6种功能，那么它就能够表现出智能；这种智能指的是人类所具有的那种智能。把这个假设称为物理符号系统的假设。\n这个假设有很多局限性，许多乐观预言都成了泡影。90年代之后人工智能领域形成了很多新的研究模式\n人工智能的学派 符号主义 又称：逻辑主义、心理学派或计算机学派\n原理：物理符号系统（即符号操作系统）假设和有限合理性原理\n符号主义认为人的认知基元是符号，认知过程即符号操作过程。认为人是一个物理符号系统，计算机也是一个物理符号系统，因此能够用计算机来模拟人的智能行为。人工智能的核心问题是知识表示、知识推理和知识运用。\n连接主义 又称：仿生学派或生理学派\n原理：神经网络及神经网络间的连接机制与学习算法。\n连接主义认为思维基元是神经元，而不是符号处理过程。认为人脑不同于电脑，并提出连接主义的大脑工作模式，用于取代符号操作的电脑工作模式。\n行为主义 又称：进化主义或控制论学派\n原理：控制论及感知—动作型控制系统\n行为主义认为智能取决于感知和行动（所以被称为行为主义），提出智能行为的“感知—动作”模式。认为智能不需要知识、不需要表示、不需要推理；人工智能可以象人类智能一样逐步进化(所以称为进化主义)；智能行为只能在现实世界中与周围环境交互作用而表现出来。\n研究领域 自然语言理解 是计算机对人类的书面和口头形式的自然语言信息进行处理加工的技术,涉及语言学,数学和计算机科学等多学科知识领域.其主要任务是建立各种自然语言处理系统,如:文字(语音)自动识别系统,电子词典,机器翻译,自动索引系统等.\n模式识别 模式识别是指用计算机代替人类或帮助人类感知模式，是对人类感知外界功能的模拟，研究的是计算机模式识别系统，也就是使一个计算机系统具有模拟人类通过感官接受外界信息、识别和理解周围环境的感知能力。\n其已在医学图象,指纹识别,天气预报,汽车牌照识别中广泛应用。\n计算机视觉 机器视觉或计算机视觉是一种用计算机实现(或模拟)人的视觉功能，对客观外界进行感知和理解的技术。它是在图像处理和模式识别技术基础上发展起来的一门新兴的学科分支，其主要目的就是用机器识别客观外界景物，即从外界获得二维图像，抽取其特征(如形状、位置、大小、灰度、颜色、纹理等)构成本征描述，然后与已知物体的描述相匹配，从而辨认出所描述的物体。\n专家系统 专家系统是一个具有大量专门知识和经验的程序系统，它应用于人工智能技术，根据某个领域中一个或多个人类专家提供的知识和经验进行推理和判断，模拟人类专家的决策过程，以解决那些需要专家决定的复杂问题。\n机器学习 所谓机器学习，就是要使计算机能模拟人的学习行为，自动地通过学习获取知识和技能，不断改善性能，实现自我完善。机器学习就是计算机自动获取知识，它是知识工程的三个分支（使用知识、知识表示、获取知识）之一 。\n神经网络 也称神经计算,是指一类计算模型,其工作原理模仿了人类大脑的某些工作机制,其利用大量人工神经元组成一个大网络,来实现大规模并行运算。\n状态空间知识表示及其搜索技术 知识 知识是人们在改造客观世界的实践中积累起来的认识和经验。\n一般来说，我们把有关信息关联在一起所形成的信息结构称为知识。\n知识表示就是对知识的一种描述，一种计算机可以 接受的用于描述知识的数据结构。\n知识的要素，一般而言，人工智能系统的知识包含事实、规则、控制和元知识。\n事实：事物的分类、属性、事物间关系、科学事实、客观事实等。\n规则：事物的行动、动作和联系的因果关系知识。\n控制：是有关问题的求解步骤、规划、求解策略等技巧性知识，告诉怎么做一件事。\n元知识：怎样使用规则、解释规则、校验规则、解释程序结构等知识。是有关知识的知识，是知识库中的高层知识。\n知识表示的一般方法 一般有：状态空间法、问题归约法、谓词逻辑法、语义网络、框架表示、剧本表示、过程表示等。\n状态空间法 问题求解(problem solving)是个大课题，它涉及归约、推断、决策、规划、常识推理、定理证明和相关过程的核心概念。在分析了人工智能研究中运用的问题求解方法之后，就会发现许多问题求解方法是采用试探搜索方法的。也就是说，这些方法是通过在某个可能的解空间内寻找一个解来求解问题的。这种基于解答空间的问题表示和求解方法就是状态空间法，它是以状态和算符(operator)为基础来表示和求解问题的。\n状态\n为描述某类不同事物间的差别而引入的一组最少变量\\(q_0,q_1,\\cdots,q_n\\)的有序集合\n可用矢量来表示：\\(Q=[q_0,q_1,\\cdots,q_n]^T\\)\n其中的每一个元素为集合的分量，称为状态变量。\n给定每个分量的一组值就得到一个具体的状态。\n算符\n把问题从一种状态变换为另一种状态的手段。\n问题的状态空间\n是一个表示该问题全部可能状态及其关系的图。\n它包含三种说明的集合,即三元状态（S，F，G），S-初始状态集合，F-操作符集合，G-目标状态集合。\n状态图示法\n用有向带权图来表示，图上的节点代表状态，边代表状态转移的路径以及转移的代价。这个路径通常也和算符有关。\n搜索推理技术 知识表示是问题求解所必须的，从问题表示到问题的解决，有一个求解过程，也就是搜索推理过程。\n搜索 根据问题的实际情况不断寻找可利用的知识,构造出一条代价较少的推理路线,使问题得到圆满解决的过程称为搜索\n要求，找到一条从初始事实到问题的最终答案的一条推理路径、找到的这条路在时间和空间复杂度上最优。\n在状态空间中搜索时，我们通常会用：图搜索策略、盲目搜索、启发式搜索等方法。\n图搜索策略 这是一种在图中寻找路径的方法。\n图中每个节点对应一个状态，每条连线对应一个操作符。\n搜索方法有很多，例如深度优先搜索等，可以看算法竞赛整理。\n在这里我们通常需要\n必须记住下一步可以走哪些点。OPEN表，记录还没有扩展的节点，用于存放刚生成的节点。 必须记住哪些点走过了。CLOSED表，记录已经扩展过的节点，用于存放已经扩展或将要扩展的节点 必须记住从目标返回的路径 其基本思想是，先把问题的初始状态作为当前扩展节点对其进行扩展，生成一组子节点，然后检查问题的目标状态是否出现在这些子节点中。\n若出现，则找到问题的解。\n若没有出现，则按照某种策略继续扩展。\n重复上述过程，直到找到解或者没有可以操作的节点为止。\n总结如下\n1.jpg\r其中第七步的排序可以是任意的即盲目的（属于盲目搜索），也可以用之后讨论的各种启发性思想或其他准则为依据（属于启发式搜索）。\n盲目搜索 这是没有启发信息的一种搜索形式，搜索过程中获得的信息不会用来改进策略。\n一般只适用于求解比较简单的问题。\n不需要重排OPEN表。\n种类主要分为：宽度优先、深度优先、等代价搜索。\nDFS和BFS不再介绍，介绍一个有界深度优先搜索。\n有界深度优先搜索\n对深度优先搜索引入搜索深度的界限（设为\\(d_m\\)），当搜索深度达到了深度界限，而仍未出现目标节点时，就换一个分支进行搜索。\n等代价搜索\n它宽度优先搜索的一种推广。不是沿着等长度路径断层进行扩展，而是沿着等代价路径断层进行扩展。\n代价树的广度优先搜索\n每次从OPEN表中选择节点往CLOSED表传送时，总是选择其中代价最小的节点。\n换句话说就是用二叉堆去维护OPEN表的节点。\n代价树的深度优先搜索\n如果说深度优先搜索是将后继节点按枚举顺序放入OPEN表里，那么代价树的深度优先搜索就是将后继节点按代价从小到大的顺序放入OPEN表。\n启发式搜索 特点是重排OPEN表,选择最有希望的节点加以扩展。种类有：有序搜索、\\(A^*\\)算法等等。\n启发式搜索的估价函数\n估价函数(evaluation function)，是估算节点希望程度的量度，用\\(f(n)\\)表示节点\\(n\\)的估价函数值。\n建立估价函数的一般方法是：提出任意节点与目标集之间的距离量度或差别量度\n有序搜索\n有序搜索，也称最好优先搜索，选择OPEN表上具有最小\\(f\\)值的节点作为下一个要扩展的节点。\n\\(A^*\\)算法\n它是有序搜索的一种，其特点在于对估价函数的定义上。\n用\\(k(n_i,n_j)\\)表示任意两个节点\\(n_i\\)和\\(n_j\\)之间最小代价路径的实际代价。\n如果两个节点没有通路，则\\(k\\)没有定义。\n对于一个具体的目标节点\\(t_i\\)，用\\(h^*(n)\\)表示整个目标节点集合\\(\\{t_i\\}\\)上所有\\(k(n,t_i)\\)中最小的一个，此时\\(h^*(n)\\)就是从\\(n\\)到目标节点最小代价路径的代价，从\\(n\\)到目标节点的代价为\\(h^*(n)\\)的任一路径就是一条最佳路径。\n估价函数设计如下(S是初始状态)\n\\[g^*(n) = k(S,n) \\]\n\\[f^*(n) = g^*(n)+h^*(n) \\]\n\\(f^*(n)\\)就是从\\(S\\)开始约束通过节点\\(n\\)的一条最佳路径的代价。\n希望估价函数\\(f\\)是\\(f^*\\)的一个估计，\\(g\\)是\\(g^*\\)的一个估计，\\(h\\)是\\(h^*\\)的一个估计，\\(h\\)叫做启发函数\n\\[f(n) = g(n)+h(n) \\]\n在图搜索中，如果OPEN表的重排是根据\\(f(n) = g(n)+h(n)\\)来进行的，那么称为\\(A\\)算法。\n在\\(A\\)算法中,如果对所有的\\(n\\)存在\\(h(n)\\leq h^*(n)\\) ,则称\\(h(n)\\)为\\(h^*(n)\\)的下界,它表示某种偏于保守的估计;\n采用\\(h^*(n)\\)的下界\\(h(n)\\)为启发函数的\\(A\\)算法，称为\\(A^*\\)算法。\n问题归约知识表示及其搜索技术 已知问题的描述，通过一系列变换把此问题最终变为一个子问题集合；这些子问题的解可以直接得到，从而解决了初始问题。\n该方法也就是从目标(要解决的问题)出发逆向推理，建立子问题以及子问题的子问题，直至最后把初始问题归约为一个平凡的本原问题集合。这就是问题归约的实质。\n问题归约法的组成部分：\n一个初始问题描述 一套把问题变为子问题的操作符 一套本原问题描述 举个例子\n2.jpg\r与或图表示 3.jpg\r或节点：只要解决某个问题就可以解决其父节点的问题\n与节点：只有解决所有子问题才可以解决其父节点的问题\n终叶节点：对应本原问题的节点\n可解节点：如下定义\n终叶节点是可解节点 如果某个非终叶节点含有或后继节点，那么只有当其后继节点至少有一个是可解的时，此非终叶节点才是可解的。 如果某个非终叶节点含有与后继节点，那么只要当其后继节点全部为可解时，此非终叶节点才是可解的 不可解节点：如下定义\n没有后裔的非终叶节点为不可解节点 如果某个非终叶节点含有或后继节点，那么只有当其全部后裔为不可解时，此非终叶节点才是不可解的。 如果某个非终叶节点含有与后继节点，那么只要当其后裔至少有一个为不可解时，此非终叶节点才是不可解的。 与或图搜索 整体与之前提到的图搜索基础没有差别，只是要去记录节点的可解性。如果最终初始节点可解，原问题就有解，否则就无解。\nMax-Min搜索 目的是为博弈的双方中的一方寻找一个最优行动方案 要寻找这个最优方案，就要通过计算当前所有可能的方案来进行比较； 方案的比较是根据问题的特征来定义一个估价函数，用来估算当前博弈树端节点的得分； 当计算出端节点的估值后，再推算出父节点的得分（即计算倒推值）； 对或节点，选其子节点中一个最大得分作为父节点的得分 对与节点，选其子节点中一个最小得分作为父节点的得分 如果一个行动方案能获得较大的倒推值，则它就是当前最好的行动方案。 假设Max是机器人下棋，Min是人类对手下棋，搜索的步骤是\n以\\(c(o)\\)为根，生成\\(k\\)-步博弈树； 评估博弈树叶节点对应的博弈状态(棋局)； 进行极大极小运算 (Max-Min 运算)； 等待 Min 行棋，产生新的 c(o)，返回 step1. 其实和人类思考差不多，往下多想\\(k\\)步可能的局面，选择自己最优，对方最差的局面。但是机器暴力地枚举了所有可能。\n\\(\\alpha-\\beta\\)剪枝 之前说的暴力算法，先生成一棵博弈树，然后再计算其倒推值，效率非常低。\n而\\(\\alpha-\\beta\\)剪枝技术的基本思想是，边生成博弈树边计算评估各节点的倒推值并且根据评估出的倒推值范围，及时停止扩展那些已无必要再扩展的子节点，即相当于剪去了博弈树上的一些分枝，从而节约了机器开销，提高了搜索效率。\n谓词逻辑表示与推理技术 谓词逻辑的概念和离散数学中讲授的一样，不再重复。具体可见离散数学整理\n谓词逻辑法 谓词逻辑法采用谓词合式公式和一阶谓词演算把要解决的问题变为一个有待证明的问题,然后采用消解原理和消解反演来证明一个新语句是从已知的正确语句导出的,从而证明新语句也是正确的.\n利用谓词公式进行知识表示的步骤 定义谓词及个体，确定其含义 根据要表达的事物或概念,为每个谓词中的变元赋值 根据表达的知识的含义,用适当的连接符号将各个谓词连接起来,形成谓词公式。 置换与合一 置换 介绍一下在离散数学中不是很详细的部分。\n一个表达式的置换就是在该表达式中用置换项置换变量。\n置换是形如\n\\[\\{t_1/x_1,t_2/x_2,\\cdots,t_n/x_n\\} \\]\n的有限集合。其中，\\(t_i\\)是不同于\\(x_i\\)的项（常量、变量、函数）；\\(x_1,x_2,\\cdots,x_n\\)是互不相同的变量；\\(t_i/x_i\\)表示用\\(t_i\\)代换\\(x_i\\)\n令置换\\(s=\\{t_1/x_1,t_2/x_2,\\cdots,t_n/x_n\\}\\)，而\\(E\\)是一个谓词公式，那么\\(s\\)作用于\\(E\\)，就是将\\(E\\)中出现的\\(x_i\\)都以\\(t_i\\)代入。结果以\\(Es\\)表示，并称为\\(E\\)的一个例\n而合成，也称为置换乘法，是置换之间的一种运算，若\n\\[\\theta = \\{t_1/x_1,\\cdots,t_n/x_n\\} \\]\n\\[\\lambda = \\{u_1/y_1,\\cdots,u_m/y_m\\} \\]\n置换的乘积\\(\\theta\\cdot\\lambda\\)是个新的置换，作用于\\(E\\)相当于先\\(\\theta\\)后\\(\\lambda\\)对\\(E\\)的作用。\n先作置换\n\\[\\{t_1\\cdot\\lambda/x_1,\\cdots,t_n\\cdot\\lambda/x_n,u_1/y_1,\\cdots,u_m/y_m\\} \\]\n若\\(y_i\\in\\{x_1,\\cdots,x_n\\}\\)时，先从中删除\\(u_i/y_i\\)；\\(t_i\\cdot\\lambda=x_i\\)时，再从中删除\\(t_i\\cdot\\lambda/x_i\\)\n所得的置换称为\\(\\theta\\)与\\(\\lambda\\)的乘积，记作\\(\\theta\\cdot\\lambda\\)\n置换的乘法是有结合律的，但没有交换率。\n合一 合一是寻找项对变量的置换，以使两表达式一致。\n如果一个置换\\(s\\)作用于表达式集\\(\\{E_i\\}\\)的每个元素，则我们用\\(\\{E_i\\}s\\)来表示置换例的集。\n称表达式集\\(\\{E_i\\}\\)是可合一的。如果存在一个置换\\(s\\)，使得：\n\\[E_1s=E_2s=E_3s=\\cdots \\]\n那么我们称此\\(s\\)为\\(\\{E_i\\}\\)的合一者，因为\\(s\\)的作用是使 集合\\(\\{E_i\\}\\)成为单一形式。\n通过置换最少的变量以使表达式一致，这个置换就叫最一般合一者,记为mgu。\n消解原理 消解原理又称为归结原理。该原理是Robinson提出的一种基于逻辑的、采用反证法的推理方法。\n消解法的基本原理是采用反证法或者称为反演推理方法，将待证明的表达式（定理）转换成为逻辑公式（谓词公式），然后再进行归结，归结能够顺利完成，则证明原公式(定理）是正确性的。\n子句集的求解 先给出一些定义\n文字\n一个原子公式和原子公式的否定都叫做文字\n子句\n由文字的析取组成的公式\n空子句\n不包含任何文字的子句\n子句集\n由子句构成的集合\n任一谓词演算公式可以化成一个子句集。由九个步骤组成\n消去蕴涵符号（使用蕴含律）\n减少否定符号的辖域，应用德摩根定律等使得每个否定符号都只结合一个谓词符号\n对变量标准化。在任一量词辖域内，受该量词约束的变量为一哑元(虚构变量)，它可以在该辖域内处处统一地被另一个没有出现过的任意变量所代替，而不改变公式的真值。\n消去存在量词\n如果要消去的存在量词在某些全称量词的辖域内，例如\\((\\forall y)[(\\exists x)P(x,y)]\\)中，中，存在量词是在全称量词的辖域内，我们允许所存在的\\(x\\)可能依赖于\\(y\\)值。令这种依赖关系明显地由函数\\(g(y)\\)所定义，它把每个\\(y\\)值映射到存在的那个\\(x\\)。这种函数叫做Skolem函数。如果用Skolem函数代替存在的\\(x\\),我们就可以消去全部存在量词，并写成：\\((\\forall y)P(g(y),y)\\) 如果不在全称量词的辖域内，直接用一个新的常量符号来替代即可。 化为前束形。把所有全称量词移到公式的左边，并使每个量词的辖域包括这个量词后面公式的整个部分。所得公式称为前束形。前束形公式由前缀和母式组成，前缀由全称量词串组成，母式由没有量词的公式组成。\n把母式化为合取范式\n消去全称量词\n消去连词符号\\(\\wedge\\)。用\\(\\{(A\\vee B),(A\\vee C)\\}\\)替代\\((A\\vee B)\\wedge(A\\vee C)\\)\n更换变量名称，把每个子句中重复变量的名称换成不同的。\n消解反演 一般过程\n建立子句集\\(S\\) 从子句集\\(S\\)出发,仅对\\(S\\)的子句间使用归结推理规则（也即反证法） 如果得出空子句, 则结束;否则转下一步 将所得归结式仍放入\\(S\\)中 对新的子句集使用归结推理规则 转3. 空子句不含有文字,它不能被任何解释满足,所以空子句是永假的,不可满足的。\n归结过程出现空子句,说明出现互补文字,说明S中有矛盾,因此S是不可满足的。\n语义网络法 语义网络是知识的一种结构化图解表示，它由节点和弧线组成。节点用于表示实体、概念和情况等，节点之间的弧线用于表示节点间的关系。\n框架表示 框架是一种结构化表示法，通常采用语义网络中的节点-槽-值表示结构。\n规则演绎系统 基于规则的演绎推理是一种直接的推理方法，它不像消解反演把知识转化为子句集，而是把有关问题的知识和信息划分为规则和事实两种类型。\n规则由包含蕴含形式的表达式表示，事实由无蕴含形式的表达式表示，并画出相应的与或图，然后通过规则进行演绎推理。\n规则演绎系统可以分为规则正向演绎推理、规则逆向演绎系统和规则双向演绎系统。\n基于规则的问题求解系统运用下述规则来建立：\n\\[If\\to Then \\]\n其中，If部分可能由几个if组成，而Then部分可能由一个或一个以上的then组成。\n在这种系统中，通常称每个if部分为前项，称每个then部分为后项。\n规则正向演绎系统 规则正向演绎系统是从事实到目标进行操作的，即从状况条件到动作进行推理的，也就是从if到then的方向进行推理的。\n过程\n事实表达式的与或形变换。把事实表示为非蕴涵形式的与或形，作为系统的总数据库。具体变换步骤与前述化为子句形类似。 事实表达式的与或图表示，即用与或图来表达事实表达式。 与或图的F规则变换 这些规则是建立在某个问题辖域中普通陈述性知识的蕴涵公式基础上的。我们把允许用作规则的公式类型限制为下列形式：\n\\[L\\Rightarrow W \\]\n式中：\\(L\\)是单文字；\\(W\\)为与或形的公式。\n作为终止条件的目标公式 基于规则的正向演绎推理的基本原理是：应用F规则作 用于表示事实的与或图，改变与或图的结构，从而产生 新的事实，直到推出目标公式，则推理成功结束。\n其推理过程为\n首先用与或图把已知事实表示出来。 用F规则的左部和与或图的叶节点进行匹配，并将匹配成功的F规则加入到与或图中，即利用F规则转换与或图。 重复第（2）步，直到产生一个含有以目标节点作为终止节点的解图为止。 规则逆向演绎系统 规则逆向演绎系统是从then向if进行推理的，即从目标或动作向事实或状况条件进行推理的。\n逆向演绎系统能够处理任意形式的目标表达式。采用和变换事实表达式类似的过程，把目标公式化成与或形。\n与或图的B规则变换\n这个B规则是建立在确定的蕴涵式基础上的，正如正向系统的F规则一样。不过，我们现在把这些B规则限制为: \\(W\\Rightarrow L\\)形式的表达式。\n其中，W为任一与或形公式，L为文字，而且蕴涵式中任何变量的量词辖域为整个蕴涵式。其次，把B规则限制为这种形式的蕴涵式还可以简化匹配，使之不会引起重大的实际困难。\n此外，可以把像\\(W\\Rightarrow(L1\\wedge L2)\\)这样的蕴涵式化为两个规则\\(W\\Rightarrow L1\\)和\\(W\\Rightarrow L2\\)。\n作为终止条件的事实节点的一致解图\n逆向系统中的事实表达式均限制为文字合取形，它可以表示为一个文字集。当一个事实文字和标在该图文字节点上的文字相匹配时，就可把相应的后裔事实节点添加到该与或图中去。这个事实节点通过标有mgu的匹配弧与匹配的子目标文字节点连接起来。同一个事实文字可以多次重复使用(每次用不同变量)，以便建立多重事实节点。逆向系统成功的终止条件是与或图包含有某个终止在事实节点上的一致解图。\n规则双向演绎系统 正向和逆向组合系统是建立在两个系统相结合的基础上的。此组合系统的总数据库由表示目标和表示事实的两个与或图结构组成，并分别用F规则和B规则来修正。\n双向演绎系统的主要复杂之处在于其终止条件，终止涉及两个图结构之间的适当交接处。这些结构可由标有合一文字的节点上的匹配棱线来连接。\n产生式系统 用来描述若干个不同的以一个基本概念为基础的系统。这个基本概念就是产生式规则或产生式条件和操作对的概念。\n在产生式系统中，论域的知识分为两部分：用事实表示静态知识，如事物、事件和它们之间的关系；用产生式规则表示推理过程和行为。由于这类系统的知识库主要用于存储规则，因此又把此类系统称为基于规则的系统。\n不确定性推理 模糊计算和模糊推理 与二值逻辑这样的非真即假的概念不同，模糊概念中，从属于该概念到不属于该概念之间无明显分界线。\n比如快慢、大小、软硬、强弱等。\n其基本思想是，用属于程度替代属于或不属于。\n经典集合 设\\(A\\)是论域\\(U\\)上的一个集合，对任意\\(u\\in U\\)，令\n\\[C_A(u) = \\left\\{\\begin{matrix} 1,u\\in A\\\\ 0,u\\notin A \\end{matrix}\\right. \\]\n则称\\(C_A(u)\\)为集合\\(A\\)的特征函数。\n模糊理论基本概念 模糊集合\n论域\\(U\\)中的模糊集\\(F\\)用一个在区间\\([0,1]\\)的取值的隶属函数\\(\\mu_F\\)来表示，即：\n\\[\\mu_F:U\\to[0,1] \\]\n\\(\\mu_F\\)称为\\(F\\)的隶属函数，\\(\\mu_F(u)\\)称为\\(u\\)对\\(A\\)的隶属度。\n直观上来说，就是将一些元素属于某个集合的程度映射到连续的\\([0,1]\\)上。\n模糊集的表示方法 若\\(U\\)为离散域且为有限集合时，模糊集合可以表示为：\n扎德表示法\n\\[F = \\sum^n_{i=1}\\mu_F(u_i)/u_i \\]\n其中“\\(/\\)”符号表示的意思是，分母是论域中的元素，分子是该元素对模糊子集\\(F\\)的隶属度。\\(\\sum\\)也不是表示相加，只是一个记号。\n比如我们写出来的可能是\\(A = 1/u_1+0.7/u_2+0/u_3+0.5/u_4\\)这样的形式。如果隶属度为\\(0\\)可以省略不写。\n序偶表示法\n\\[F=\\{(u_1,\\mu(u_1)),(u_2,\\mu(u_2)),\\cdots,(u_n,\\mu(u_n))\\} \\]\n向量表示法\n\\[F = \\{\\mu(u_1),\\mu(u_2),\\cdots,\\mu(u_n)\\} \\]\n无论论域是有限的还是无限的，连续的还是离散的，扎德都用如下记号作为模糊子集的一般表示形式：\n\\[F = \\int_U\\frac{\\mu_F}{u} \\]\n这里的积分号不是数学中的积分，也不是求和，只是表示论域中各元素与其隶属度对应关系的总括，是一个记号。\n集合运算 定义1\n设\\(A,B\\)是论域\\(U\\)的模糊集，即\\(A,B\\in F(U)\\)，若对于任一\\(u\\in U\\)都有\\(\\mu_B(u)\\leq\\mu_A(A)\\)，则称\\(B\\)包含于\\(A\\)，或者说\\(B\\)是\\(A\\)的一个子集，记作\\(B\\subseteq A\\)。若对于任一\\(u\\in U\\)都有\\(\\mu_B(u)=\\mu_A(A)\\)，则称\\(B\\)等于\\(A\\)，记作\\(B=A\\)\n定义2\n并运算（\\(A\\bigcup B\\)）的隶属度函数\\(\\mu_{A\\bigcup B}\\)对所有的\\(u\\in U\\)被逐点定义为取大运算，即\n\\[\\mu_{A\\bigcup B} = \\mu_A(u)\\vee\\mu_B(u) \\]\n式中，\\(\\vee\\)符号取极大值运算。\n定义3\n交运算（\\(A\\bigcap B\\)）的隶属度函数\\(\\mu_{A\\bigcap B}\\)对所有的\\(u\\in U\\)被逐点定义为取小运算，即\n\\[\\mu_{A\\bigcap B} = \\mu_A(u)\\wedge\\mu_B(u) \\]\n式中，\\(\\wedge\\)符号取极小值运算。\n定义4\n补，隶属度函数\\(\\mu_{\\bar A}\\)，对所有的\\(u\\in U\\)，被逐点定义为\\(\\mu_{\\bar A}(u) = 1-\\mu_{A}(u)\\)\n模糊集合中有时会用\\(\\neg A\\)表示\\(A\\)的补集。\n定理\n集合运算的定理和经典的集合没有区别，例如结合、分配律，德摩根律等等。\n模糊集的截集 定义1\n设\\(A\\in F(u),\\lambda\\in[0,1]\\)，则\n\\(A_\\lambda=\\{u|u\\in U,\\mu_A(u)\\geq\\lambda\\}\\)，称\\(A_\\lambda\\)为\\(A\\)的一个\\(\\lambda\\)截集，称\\(\\lambda\\)为阈值（置信水平） \\(A_\\lambda=\\{u|u\\in U,\\mu_A(u)\u003e\\lambda\\}\\)，称\\(A_\\lambda\\)为\\(A\\)的一个\\(\\lambda\\)强截集 \\(SuppA=\\{u|u\\in U,\\mu_A(u)\u003e0\\}\\)为\\(A\\)的支集 \\(KerA=\\{u|u\\in U,\\mu_A(u)=1\\}\\)为\\(A\\)的核 当\\(A\\)的核不为空，则称\\(A\\)为正规\\(F\\)集。\n模糊集合的模糊度 模糊度是模糊集模糊程度的一种度量\n定义\n设\\(A\\in F(U)\\)，\\(d\\)是定义在\\(F(U)\\)上的一个实函数，如果它满足以下条件：\n对任意\\(A\\in F(U)\\)，有\\(d(A)\\in[0,1]\\) 当且仅当\\(A\\)是一个普通集合时，\\(d(A) = 0\\) 若\\(A\\)的隶属函数\\(\\mu_A(U)\\equiv0.5\\)，则\\(d(A)=1\\) 若\\(A,B\\in F(U)\\)，且对任意\\(u\\in U\\)，满足 \\[\\mu_B(u)\\leq\\mu_A(u)\\leq0.5或者\\mu_B(u)\\geq\\mu_A(u)\\geq0.5 \\]\n则有\\(d(B)\\leq d(A)\\)\n对任意\\(A\\in F(U)\\)，有\\(d(A)=d(\\neg A)\\) 则称\\(d\\)为定义在\\(F(U)\\)上的一个模糊度，\\(d(A)\\)称为\\(A\\)的模糊度。\n直观地理解\n模糊度是\\([0,1]\\)上的一个数 普通集合的模糊度是\\(0\\)，也就代表其不模糊 越靠近\\(0.5\\)就越模糊，\\(\\mu_A(u)=0.5\\)时最模糊 模糊集\\(A\\)与其补集\\(\\neg A\\)具有相同的模糊度 模糊度的计算方法\nHaming（海明）模糊度\n\\[d_1(A) = \\frac{2}{n}\\sum^n_{i=1}|\\mu_A(u_i)-\\mu_{A_{0.5}}(u_i)| \\]\n其中，\\(\\mu_{A_{0.5}}(u_i)\\)是\\(A\\)的\\(\\lambda=0.5\\)截集的隶属函数。由于\\(A_{0.5}\\)是一个普通集合，所以\\(\\mu_{A_{0.5}}(u_i)\\)实际上是特征函数\nEuclid（欧几里得）模糊度\n\\[d_2(A) = \\frac{2}{\\sqrt n }(\\sum^n_{i=1}|\\mu_A(u_i)-\\mu_{A_{0.5}}(u_i)|^2)^{1/2} \\]\nMinkowski（明可夫斯基）模糊度\n\\[d_p(A) = \\frac{2}{n^{1/p}}(\\sum^n_{i=1}|\\mu_A(u_i)-\\mu_{A_{0.5}}(u_i)|^p)^{1/p} \\]\nShannon（香农）模糊度\n\\[d(A) = \\frac{1}{n\\ln 2}\\sum^n_{i=1}S(\\mu_A(u_i)) \\]\n其中\\(S(x)\\)是定义在\\([0,1]\\)上的香农函数，即\n\\[S(x) = \\left\\{\\begin{matrix} -x\\ln x-(1-x)ln(1-x),\\quad \u0026x\\in(0,1) \\\\ 0,\\quad \u0026x=1\\ or\\ x = 0 \\end{matrix}\\right. \\]\n模糊数 模糊的数量，例如：500人左右，大约0.6等\n定义\n如果实数域\\(R\\)上的模糊集\\(A\\)的隶属函数\\(\\mu_A(u)\\)在\\(R\\)上连续且具有如下性质\n\\(A\\)是凸模糊集，即对任意\\(\\lambda\\in[0,1]\\)，\\(A_\\lambda\\)是闭区间 \\(A\\)是正规模糊集，即存在\\(u\\in R\\)，使得\\(\\mu_A(u)=1\\) 则称\\(A\\)为一个模糊数\n直观上模糊数的隶属函数图形是单峰的，且在峰顶使隶属度达到\\(1\\)\n模糊关系 在普通集合上定义的关系已经在离散数学中介绍过了。这种关系是一种确定性的关系，要么有，要么没有。\n而模糊关系就不是非常明确的。\n定义\n设论域\\(U,V\\)，则\\(U\\times V\\)（笛卡尔积）的一个子集\\(R\\)就是从\\(U\\)到\\(V\\)的模糊关系，记作\n\\[U\\overset{R}{\\rightarrow} V \\]\n这里的模糊关系\\(R\\)是属于模糊二元关系。\n其隶属函数为映射\\(\\mu_R:U\\times V\\to[0,1]\\)\n隶属度\\(\\mu_R(u_0,v_0)\\)，表示\\(u_0\\)与\\(v_0\\)具有关系\\(R\\)的程度。\n对于有限论域\\(U = \\{u_1,u_2,\\cdots,u_m\\},V = \\{v_1,v_2,\\cdots,v_n\\}\\)，则\\(U\\)对\\(V\\)的模糊关系的隶属函数可以用\\(m\\times n\\)阶模糊矩阵\\(R\\)来表示，即\n\\[R = (r_{ij})_{m\\times n} \\]\n模糊集的笛卡尔乘积\n模糊集\\(A,B\\)的笛卡尔乘积为\n\\[A\\times B = \\int_{U\\times V}\\min(\\mu_A(u),\\mu_B(v))/(u,v) \\]\n模糊关系的合成\n设\\(R_1\\)与\\(R_2\\)分别是\\(u\\times v\\)及\\(v\\times w\\)上的两个模糊关系，则\\(R_1\\)与\\(R_2\\)的合成是指从\\(u\\)到\\(w\\)的一个模糊关系，记为\\(R_1\\circ R_2\\)，其隶属度为\n\\[\\mu_{R_1\\circ R_2}(u,w) = \\{\\bigvee^{v}\\mu_{R_1}(u,v)\\wedge\\mu_{R_2}(v,w) \\} \\]\n模糊推理 模糊命题\n含有模糊概念、模糊数据的语句称为模糊命题。\n它的一般表示形式为\n\\[x\\quad is \\quad A \\]\n或者\n\\[x\\quad is \\quad A(CF) \\]\n其中\\(A\\)是模糊概念或模糊数，用相应的模糊集及隶属函数刻画；\\(x\\)是论域上的变量，用以代表所论述对象的属性； \\(CF\\)是该模糊命题的可信度，它既可以是一个确定的数，也可以是一个模糊数或者模糊语言值。\n模糊语言值是指表示大小、长短、多少等程度的一些词汇。如：极大、很大、相当大、比较大。模糊语言值同样可用模糊集描述。\n模糊的知识表示 模糊产生式规则的一般形式是 \\[IF\\quad E\\quad THEN\\quad H\\quad (CF,\\lambda) \\]\n其中\\(E\\)是用模糊命题表示的模糊条件；\\(H\\)是用模糊命题表示的模糊结论；\\(CF\\)是知识的可信度因子，它既可以是一个确定的数，也可以是一个模糊数或模糊语言值。\\(\\lambda\\)是匹配度的阈值，用以指出知识被运用的条件。\n推理中所用的证据也用模糊命题表示，一般形式为 \\[x\\quad is \\quad A' \\]\n或者\n\\[x\\quad is \\quad A'(CF) \\]\n模糊推理要解决的问题：证据与知识的条件是否匹配；如果匹配，如何利用知识及证据推出结论。 模糊匹配与冲突消解 贴近度 设\\(A,B\\)分别是论域\\(U=\\{u_1,u_2,\\cdots,u_n\\}\\)上的两个模糊集，则它们的贴近度定义为：\n\\[(A,B) = [A\\cdot B+(1-A\\odot B)]/2 \\]\n其中\n\\[A\\cdot B = \\bigvee_U(\\mu_A(u_i)\\wedge\\mu_B(u_i)) \\]\n是内积\n\\[A\\odot B = \\bigwedge_U(\\mu_A(u_i)\\vee\\mu_B(u_i)) \\]\n是外积。\n语义距离 海明距离\n\\[d(A,B) = \\frac{1}{n}\\sum^n_{i=1}|\\mu_A(u_i)-\\mu_B(u_i)| \\]\n\\[d(A,B) = \\frac{1}{b-a}\\int^b_a|\\mu_A(u)-\\mu_B(u)|du \\]\n欧几里得距离\n\\[d(A,B) = \\frac{1}{\\sqrt n}\\sqrt{\\sum^n_{i=1}(\\mu_A(u_i)-\\mu_B(u_i))^2} \\]\n明可夫斯基距离\n\\[d(A,B) = [\\frac{1}{n}\\sum^n_{i=1}|\\mu_A(u_i)-\\mu_{A_{0.5}}(u_i)|^p]^{1/p},\\quad p\\geq1 \\]\n切比雪夫距离\n\\[d(A,B) = \\underset{1\\leq i\\leq n}{\\max}|\\mu_A(u_i)-\\mu_B(u_i)| \\]\n匹配度为\\(1-d(A,B)\\)\n相似度 最大最小法 \\[r(A,B) = \\frac{\\sum\\min\\{\\mu_A(u_i),\\mu_B(u_i)\\}}{\\sum\\max\\{\\mu_A(u_i),\\mu_B(u_i)\\}} \\]\n算术平均法 \\[r(A,B) = \\frac{\\sum\\min\\{\\mu_A(u_i),\\mu_B(u_i)\\}}{\\frac{1}{2}\\sum(\\mu_A(u_i)+\\mu_B(u_i))} \\]\n几何平均最小法 \\[r(A,B) = \\frac{\\sum\\min\\{\\mu_A(u_i),\\mu_B(u_i)\\}}{\\sum\\sqrt {(\\mu_A(u_i)\\times\\mu_B(u_i))}} \\]\n相关系数法 \\[r(A,B) = \\frac{\\sum(\\mu_A(u_i)-\\bar\\mu_A)\\times(\\mu_B(u_i)-\\bar\\mu_B)}{\\sqrt{[\\sum(\\mu_A(u_i)-\\bar\\mu_A)^2]\\times[\\sum(\\mu_B(u_i)-\\bar\\mu_B)^2]}} \\]\n\\[\\bar\\mu_A = \\frac{1}{n}\\sum\\mu_A(u_i),\\quad\\bar\\mu_B = \\frac{1}{n}\\sum\\mu_B(u_i) \\]\n指数法 \\[r(A,B) = \\exp\\bigg(-\\sum|\\mu_A(u_i)-\\mu_B(u_i)|\\bigg) \\]\n复合条件的模糊匹配 分别计算出每一个子条件与其证据的匹配度 求出整个前提条件与证据的总匹配度。目前常用的方法有“取极小”和“相乘”等。 检查总匹配度是否满足阈值条件，如果满足就可以匹配，否则为不可匹配。 冲突消解 按匹配度大小排序 按加权平均值排序 按广义顺序关系排序 模糊推理的基本形式 模糊假言推理 知识：\\(IF\\quad x\\ is\\ A\\quad THEN\\quad y\\ is\\ B\\)\n证据：\\(x\\ is\\ A'\\)\n结论：\\(y\\ is\\ B'\\)\n模糊拒取式推理 知识：\\(IF\\quad x\\ is\\ A\\quad THEN\\quad y\\ is\\ B\\)\n证据：\\(y\\ is\\ B'\\)\n结论：\\(x\\ is\\ A'\\)\n知识中只含有简单条件，且不带可信度因子的模糊推理称为简单模糊推理。\n合成推理知识\n对于知识\\(IF\\quad x\\ is\\ A\\quad THEN\\quad y\\ is\\ B\\)\n首先构造出\\(A,B\\)之间的模糊关系\\(R\\)，\n如果已知证据是\\(x\\ is\\ A'\\)，且\\(A,A'\\)之间可以进行模糊匹配，则\\(B' = A'\\circ R\\)\n如果已知证据是\\(y\\ is\\ B'\\)，且\\(B,B'\\)之间可以进行模糊匹配，则\\(A' = R\\circ B'\\)\n构造模糊关系R的方法 扎德方法 扎德提出了两种方法：一种称为条件命题的极大极小规则。另一种称为条件命题的算术规则，由它们获得的模糊关系分别记为\\(R_m\\)和\\(R_a\\)\n设\\(A\\in F(U), B\\in F(V)\\)，其分别表示为\n\\[A = \\int_U \\mu_A(u)/u, B = \\int_V \\mu_B(u)/u \\]\n则\n\\[R_m = (A\\times B)\\cup(\\neg A\\times V) = \\int_{U\\times V}(\\mu_A(u)\\wedge\\mu_B(v))\\vee(1-\\mu_A(u))/(u,v) \\]\n\\[R_a = (\\neg A\\times V)\\oplus(U\\times B) = \\int_{U\\times V}1\\wedge(1-\\mu_A(u)+\\mu_B(v))/(u,v) \\]\n其中\\(\\times\\)是笛卡尔积；有界和\\(x\\oplus y=\\min\\{1,x+y\\}\\)\nMamdani方法 对于知识\\(IF\\quad x\\ is\\ A\\quad THEN\\quad y\\ is\\ B\\)\n\\[R_C = A\\times B = \\int_{U\\times V}\\mu_A(u)\\wedge\\mu_B(v)/(u,v) \\]\nMizumoto方法 米祖莫托等人根据多值逻辑中计算\\(T(AB)\\)的定义，提出了一组构造模糊关系的方法，分别记为\\(R_s,R_g,R_{sg},R_{gs},R_{gg},R_{ss}\\)等等。\n\\[R_s = A\\times V \\underset{s}{\\Rightarrow} U\\times B = \\int_{U\\times V}[\\mu_A(u)\\underset{s}{\\to}\\mu_B(v)]/(u,v) \\]\n其中\n\\[\\mu_A(u)\\underset{s}{\\to}\\mu_B(v) = \\left\\{\\begin{matrix} 1,\\mu_A(u)\\leq\\mu_B(v) \\\\ 0,\\mu_A(u)\u003e\\mu_B(v) \\end{matrix}\\right. \\]\n\\[R_s = A\\times V \\underset{g}{\\Rightarrow} U\\times B = \\int_{U\\times V}[\\mu_A(u)\\underset{g}{\\to}\\mu_B(v)]/(u,v) \\]\n其中\n\\[\\mu_A(u)\\underset{g}{\\to}\\mu_B(v) = \\left\\{\\begin{matrix} 1,\u0026\\mu_A(u)\\leq\\mu_B(v) \\\\ \\mu_B(v),\u0026\\mu_A(u)\u003e\\mu_B(v) \\end{matrix}\\right. \\]\n模糊判决方法 在推理得到的模糊集合中取一个相对最能代表这个模糊集合的单值的过程就称作解模糊（去模糊）或模糊判决(Defuzzification)。\n方法有：重心法、最大隶属度方法、加权平均法、隶属度限幅元素平均法等等。\n重心法 所谓重心法就是取模糊隶属函数曲线与横坐标轴围成面积的重心作为代表点。理论上应该计算输出范围内一系列连续点的重心，即\n\\[u = \\frac{\\int_x x\\mu_N(x)dx}{\\int_x \\mu_N(x)dx} \\]\n最大隶属度法 这种方法最简单，只要在推理结论的模糊集合中取隶属度最大的那个元素作为输出量即可。不过，要求这种情况下的隶属函数曲线一定是单峰曲线。如果该曲线是梯形平顶，那么具有最大隶属度的元素就可能不只一个，这时就要对所有取最大隶属度的元素求其平均值。\n系数加权平均法 \\[u = \\sum k_i\\cdot x_i/\\sum k_i \\]\n其中系数\\(k_i\\)的选择要根据实际情况而定。\n隶属度限幅元素平均法 用所确定的隶属度值 a对隶属度函数曲线进行切割，再对切割后大于等于该隶属度的所有元素进行平均，用这个平均值作为输出执行量，这种方法就称为隶属度限幅元素平均法。\n不确定性推理的基本概念 不确定性推理是建立在非经典逻辑基础上的一种推理，它是对不确定性知识的运用与处理。\n具体地说，所谓不确定性推理就是从不确定性的初始证据（即事实）出发，通过运用不确定性的知识，最终推出具有一定程度不确定性的结论。\n不确定性推理中的基本问题 不确定性的表示与度量 不确定性一般分为两类，一类是知识的不确定性，一类是证据的不确定性。\n知识不确定性的表示：目前在专家系统中知识的不确定性一般是由领域专家给出的，通常用一个数值表示，它表示相应知识的不确定性程度，称为知识的静态强度。\n证据不确定性的表示：证据不确定性的表示方法与知识不确定性的表示方法一致，通常也用一个数值表示，代表相应证据的不确定性程度，称之为动态强度。\n不确定性匹配算法及阈值的选择 推理是不断运用知识的过程,为了找到所需的知 识,需要在这一过程中用知识的前提与已知证据进 行匹配.只有匹配成功的知识才有可能被应用.\n组合证据不确定性的计算方法 即已知证据\\(E_1\\)和\\(E_2\\)的不确定性度量，求证据\\(E_1\\)和\\(E_2\\)的析取和合取的不确定性，常用的方法有：\n最大最小法 \\[T(E_1\\ AND\\ E_2) = \\min\\{T(E_1),T(E_2)\\} \\]\n\\[T(E_1\\ OR\\ E_2) = \\max\\{T(E_1),T(E_2)\\} \\]\n概率法 \\[T(E_1\\ AND\\ E_2) = T(E_1)\\times T(E_2) \\]\n\\[T(E_1\\ OR\\ E_2) = T(E_1)+T(E_2) - T(E_1)\\times T(E_2) \\]\n有界法 \\[T(E_1\\ AND\\ E_2) = \\max\\{0,T(E_1)+T(E_2)-1\\} \\]\n\\[T(E_1\\ OR\\ E_2) = \\min\\{1,T(E_1)+T(E_2)\\} \\]\n其中，\\(T(E)\\)表示证据\\(E\\)为真的程度（动态强度），如可信度、概率等。\n不确定性的传递算法 在每一步推理中，如何把证据及知识的不确定性传递给结论 在多步推理中，如何把初始证据的不确定性传递给最终结论 结论不确定性的合成 用不同知识进行推理得到了相同结论，但所得结论的 不确定性却不同。此时，需要用合适的算法对结论的 不确定性进行合成。\n不确定性推理方法的分类 不确定性推理方法主要可分为模型法与控制法。\n模型法：在推理一级对确定性推理进行扩展，引入证据的不确定性及知识的不确定性。\n模型方法又分为数值方法和非数值方法两类。数值方法对不确定性进行定量的描述，按其所依据的理论又可分为基于概率的方法和基于模糊理论的方法。\n本节主要针对模型方法中相关的典型算法展开.\n逆概率法 经典概率方法\n设有如下产生式规则： \\[\\text{IF\\quad E\\quad\\quad THEN\\quad H} \\]\n其中，\\(E\\)为前提条件，\\(H\\)为结论。条件概率\\(P(H|E)\\)可以作为在证据\\(E\\)出现时结论\\(H\\)的确定性程度，即规则的静态强度。\n对于复合条件 \\[E=E_1\\ \\text{AND}\\ E_2\\ \\text{AND}\\cdots\\text{AND}\\ E_n \\]\n当已知条件概率\\(P(H|E_1,E_2,\\cdots,E_n)\\)时，就可把它作为在证 据\\(E_1,E_2,\\cdots,E_n\\)出现时结论H的确定性程度。\n先验概率：\\(P(H)\\)，后验概率\\(P(H|E)\\) 经典概率方法要求给出条件概率\\(P(H|E)\\)，在实际中通常比较困难。例如\\(E\\)代表咳嗽，\\(H\\)代表支气管炎，则\\(P(H|E)\\)表示在咳嗽的人群中患支气管炎的概率，这个比较困难，因为样本空间太大。而\\(P(E|H)\\)表示在得支气管炎的人群中咳嗽的概率，这个就比较容易获得。我们可以根据Bayes定理从\\(P(E|H)\\)推出\\(P(H|E)\\)\n优点\n逆概率法有较强的理论背景和良好的数学特性，当证据彼此独立时计算的复杂度比较低。\n缺点\n逆概率法要求给出结论\\(H_i\\)的先验概率\\(P(H_i)\\)及条件概率\\(P(E_j|H_i)\\)。\n可信度方法 可信度方法是在确定性理论的基础上，结合概率论等提出的一种不确定性推理方法，简称C-F模型。该方法首先在医疗系统MYCIN中得到成功的应用。\n可信度的概念\n根据经验对一个事物和现象为真的相信程度称为可信度。\n在可信度方法中，由专家给出规则或知识的可信度，从而可避免对先验概率、或条件概率的要求。\n1.知识不确定性的表示 在C-F模型中，知识是用产生式规则表示的，其一般形式为：\n\\[\\text{IF}\\quad E\\quad \\text{THEN}\\quad H\\quad (CF(H,E)) \\]\n其中\n前提\\(E\\)可以是命题的合取和析取组合 结论\\(H\\)可为单一命题，也可以是复合命题 \\(CF(H,E)\\)为确定性因子(Certainty factor)，简称可信度，用以量度规则的确定性（可信）程度。取值于\\([-1，1]\\)，表示\\(E\\)为真时，对\\(H\\)的支持程度。\\(CF(H,E)\\)值越大，\\(E\\)就越支持\\(H\\)为真。 可信度因子的定义\n\\(CF(H,E)\\)定义为\n\\[CF(H,E) = MB(H,E) - MD(H,E) \\]\nMB反映了证据对结论有利的一面，MD反映了证据对结论不利的一面。MB(Measure Belief) 表示因与\\(E\\)匹配的证据出现，使\\(H\\)为真的信任增长度。MD(Measure Disbelief)指不信任增长度，表示因与\\(E\\)匹配的证据出现，使\\(H\\)为真的不信任增长度。 MB和MD的定义为：\n\\[MB(H,E) = \\left\\{\\begin{matrix} 1 \u0026 ,P(H)=1\\\\ \\dfrac{max\\{P(H|E),P(H)\\}-P(H)}{1-P(H)} \u0026 ,\\text{other} \\end{matrix}\\right. \\]\n\\[MD(H,E) = \\left\\{\\begin{matrix} 1 \u0026 ,P(H)=0\\\\ \\dfrac{min\\{P(H|E),P(H)\\}-P(H)}{-P(H)} \u0026 ,\\text{other} \\end{matrix}\\right. \\]\n当\\(P(H|E)\u003eP(H)\\)时：表示证据E支持结论\\(H\\)，\\(MB(H,E)\u003e0，MD(H,E)=0\\)。 当\\(P(H|E)\u003c P(H)\\)时，表示\\(E\\)不支持\\(H\\)，\\(MD(H,E)\u003e0， MB(H,E)=0\\)。当\\(p(H|E)=p(H)\\)时，表示\\(E\\)对\\(H\\)无影响，则有\\(MB=MD=0\\) \\(MB(H,E)\\)与\\(MD(H,E)\\)是互斥的：当\\(MB(H,E)\u003e0\\)时，\\(MD(H,E)=0\\);当\\(MD(H,E)\u003e0\\)时，\\(MB(H,E)=0\\) \\(CF(H,E)\\)的计算公式\n根据上述定义，可知\n\\[CF(H,E) = \\left\\{\\begin{matrix} MB(H,E)-0=\\dfrac{P(H|E)-P(H)}{1-P(H)} \u0026 ,P(H|E) \u003e P(H)\\\\ 0 \u0026 ,P(H|E)=P(H)\\\\ 0-MD(H,E)=-\\dfrac{P(H)-P(H|E)}{P(H)}\u0026 ,P(H|E) \u003c P(H) \\end{matrix}\\right. \\]\n从上式可以看出\n\\(CF(H,E)\u003e0\\)对应于\\(P(H|E)\u003eP(H)\\)\n\\(CF(H,E)=0\\)对应于\\(P(H|E)=P(H)\\)\n\\(CF(H,E) \u003c 0\\)对应于\\(P(H|E) \u003c P(H)\\)\n当且仅当\\(P(H|E)=1\\)时,\\(CF(H,E)=1\\)\n当且仅当\\(P(H|E)=0\\)时,\\(CF(H,E)=-1\\)\n\\(CF(H,E)\\)定性地反映了\\(P(H|E)\\)的大小,因此可以用\\(CF(H,E)\\)近似表示\\(P(H|E)\\)的大小,从而描述了规则的可信度。\n2.证据不确定性的表示 证据的不确定性也用可信度因子表示。如：\\(CF(E)=0.6\\)\n\\(CF(E)\\)的取值范围：\\([-1，+1]\\)。\n\\(CF(E)\u003e0\\):表示证据以某种程度为真。\n\\(CF(E)\u003c0\\):表示证据以某种程度为假。\n\\(CF(E)\\)表示证据的强度，即动态强度。\n设证据E所在的环境为\\(S\\)，则可用可信度\\(CF(E,S)\\)来表示\\(E在$S\\)下的确定性程度，并有：\n\\[CF(E,S) = MB(E,S)-MD(E,S) \\]\n若\\(S\\)下\\(E\\)为真，则\\(CF(E,S) = 1\\)；\n若\\(E\\)为假，则\\(CF(E,S) =-1\\)；\n若\\(S\\)对\\(E\\)的真值无影响，则\\(CF(E,S)= 0\\)。\n类似于规则的不确定性，证据的可信度往往可由领域专家凭经验主观确定。\n证据的可信度值来源于两种情况：\n初始证据由领域专家或用户给出； 中间结论由不确定性传递算法计算得到。 3.组合证据不确定性的算法 当组合证据是多个单一证据的合取时，即: \\[E=E_1\\ \\text{AND}\\ E_2\\ \\text{AND}\\cdots\\text{AND}\\ E_n \\]\n则\\(CF(E)=min\\{CF(E_1),CF(E_2),\\cdots,CF(E_n)\\}\\)\n当组合证据是多个单一证据的析取时，即: \\[E=E_1\\ \\text{OR}\\ E_2\\ \\text{OR}\\cdots\\text{OR}\\ E_n \\]\n则\\(CF(E)=max\\{CF(E_1),CF(E_2),\\cdots,CF(E_n)\\}\\)\n4. 不确定性的传递 不确定性的传递算法定义如下：\n\\[CF(H) = CF(H,E)\\times max\\{0,CF(E)\\} \\]\n由上式可以看出:\n\\(CF(E)\u003c0\\)时,\\(CF(H)=0\\),说明该模型没有考虑证据为假时对结论\\(H\\)所产生的影响。 \\(CF(E)=1\\)时,\\(CF(H)=CF(H,E)\\),说明规则可信度\\(CF(H,E)\\)就是证据为真时的结论\\(H\\)的可信度。 5. 结论不确定性的合成算法 若由多条不同知识推出了相同的结论，但可信度不同，则可用合成算法求出综合的可信度。由于对多条知识的综合可通过两两的合成实现，所以下面只考虑两条知识的情况。\n设有如下知识：\n\\[\\text{IF}\\quad E_1\\quad \\text{THEN}\\quad H\\quad\\quad (CF(H,E_1)) \\]\n\\[\\text{IF}\\quad E_2\\quad \\text{THEN}\\quad H\\quad\\quad (CF(H,E_2)) \\]\n则结论H的综合可信度可分为如下两步算出：\n首先分别对每一条知识求出\\(CF(H)\\) \\[CF_1(H) = CF(H,E_1)\\times max\\{0,CF(E_1)\\} \\]\n\\[CF_2(H) = CF(H,E_2)\\times max\\{0,CF(E_2)\\} \\]\n然后用下述公式求出\\(E_1\\)与\\(E_2\\)对\\(H\\)的综合可信度\\(CF_{12}(H)\\): \\[CF_{12}(H) = \\left\\{\\begin{matrix} CF_1(H)+CF_2(H)-CF_1(H)\\times CF_2(H) \u0026,CF_1(H)\\geq 0,CF_2(H)\\geq 0\\\\ CF_1(H)+CF_2(H)+CF_1(H)\\times CF_2(H) \u0026,CF_1(H)\u003c0,CF_2(H)\u003c0\\\\ \\dfrac{CF_1(H)+CF_2(H)}{1-min\\{|CF_1(H)|,|CF_2(H)|\\}} \u0026,CF_1(H)\\times CF_2(H)\u003c0\\\\ \\end{matrix}\\right. \\]\n冲突消解\n\\[r_1: \\text{IF}\\quad \\{E_1(\\omega_1)\\}\\quad \\text{THEN}\\quad H_1\\quad\\quad (CF(H_1,E_1),\\lambda_1) \\]\n\\[r_2: \\text{IF}\\quad \\{E_2(\\omega_2)\\}\\quad \\text{THEN}\\quad H_2\\quad\\quad (CF(H_2,E_2),\\lambda_2) \\]\n且\\(CF(\\{E_1(\\omega_1)\\})\\geq\\lambda_1,CF(\\{E_2(\\omega_2)\\})\\geq\\lambda_2\\)\n若\\(CF(\\{E_1(\\omega_1)\\})\\geq CF(\\{E_2(\\omega_2)\\})\\)，则优先使用\\(r_1\\)进行推理。\n加权的不确定性推理 1. 知识的不确定性的表示 \\[\\text{IF}\\quad \\{E_1(\\omega_1)\\}\\quad \\text{AND}\\quad \\{E_2(\\omega_2)\\}\\quad \\text{AND}\\cdots\\text{AND}\\quad \\{E_n(\\omega_n)\\} \\]\n\\[\\text{THEN}\\quad H\\quad (CF(H,E),\\lambda) \\]\n其中\\(\\omega_i(i=1,2,\\cdots,n)\\)是加权因子，\\(λ\\)是阈值，其值均由专家给出。\n其中\n\\[0\\leq \\omega_i\\leq 1,\\sum\\omega_i=1 \\]\n2. 组合证据不确定性的算法 若有\\(CF(E_1),CF(E_2),\\cdots,CF(E_n)\\)，则组合证据的可信度为：\n\\[CF(E)=\\sum(\\omega_i\\times CF(E_i)) \\]\n3. 不确定性的传递算法 当一条知识的\\(CF(E)\\)满足如下条件时，\n\\[CF(E)\\geq\\lambda \\]\n该知识就可被应用。结论\\(H\\)的可信度为：\n\\[CF(H) = CF(H,E)\\times CF(E) \\]\n加权因子的引入不仅可以区分不同证据的重要性同时还可以解决证据不全时的推理问题。\n基于可信度的不确定性推理方法的特点\n优点\n简单、直观。\n缺点\n可信度因子依赖于专家主观指定，没有统一、客观的尺度，容易产生片面性。\n随着推理延伸，可信度越来越不可靠，误差越来越大。当推理深度达到一定深度时，有可能出现推出的结论不再可信的情况。\n遗传算法 计算智能 计算智能就是受自然界（生物界）规律的启迪，根据其原理，模仿设计求解问题的算法。\n计算智能:生物智能的计算模拟, 是一种智力方式的低层认知，它与人工智能的区别只是认知层次从中层下降至低层而已。中层系统含有知识，低层系统则没有。\n当一个系统只涉及数值（低层）数据，含有模式识别部分，不应用人工智能意义上的知识，而且能够呈现出：\n计算适应性 计算容错性 接近人的速度 误差率与人相近 则该系统就是计算智能系统。\n当一个智能计算系统以非数值方式加上知识，即成为人工智能系统。\n进化计算 进化计算是一类模拟生物进化过程与机制求解问题的自组织、自适应技术。\n生物种群的生存过程普遍遵循达尔文的物竞天择、适者生存的进化准则；生物通过个体间的选择、交叉、变异来适应大自然环境。\n依照达尔文的自然选择和孟德尔的遗传变异理论，生物的进化是通过繁殖、变异、竞争、选择来实现的，进化算法就是建立在上述生物模型基础上的一种随机搜索技术。\n几十年来的研究与应用已经清楚地表明：虽然模拟自然进化搜索过程的一些模型还只是自然界生物体的粗糙简化，但是已经可以产生非常鲁棒的计算方法。\n进化算法（Evolutionary Algorithm—EA）就是基于这种思想发展起来的，目前研究的进化算法主要有三种典型的算法：遗传算法、进化规划和进化策略。这三种算法是彼此独立发展起来的。\n种群搜索策略和种群中个体之间的信息交换是进化算法的两大特点。它们的优越性主要表现在：\n进化算法在搜索过程中不容易陷入局部最优 由于它们固有的并行性，进化算法非常适合于并行机 由于它们容易介入到已有的模型中并且具有可扩展性，以及易于同别的技术混合等因素，因而进化算法目前已经在最优化、机器学习和并行处理等领域得到越来越广泛的应用。 基本思想 遗传算法把问题的解表示成“染色体”，在算法中即是以一定方式编码的串。并且，在执行遗传算法之前，给出一群“染色体”，也即假设解（候选解）。然后，把这些假设解置于问题的“环境”中，并按适者生存的原则，从中选择出较适应环境的“染色体”进行复制，再通过交叉，变异过程产生更适应环境的新一代“染色体”群。这样，一代一代地进化，最后就会收敛到最适应环境的一个“染色体”上，它就是问题的最优解。\n其算法框图为\n4.jpg\r一些基本概念 串(String) 它是个体(Individual)的形式，在算法中为二进制串或者其它编码方式的串，并且对应于遗传学中的染色体(Chromosome)。 种群(Population) 个体的集合称为种群，串是种群的元素 种群规模(Population Size) 在种群中个体的数量称为种群的规模。 基因(Gene) 基因是串中的元素，基因用于表示个体的特征 适应度(Fitness) 表示某一个体对于环境的适应程度 基本机理 一般的遗传算法由四个部分组成: 编码机制、适应度函数、控制参数、遗传算子 编码机制(encoding mechanism) 用遗传算法解决问题时，首先要对待解决问题的模型结构和参数进行编码，一般用字符串表示。 编码机制是GA的基础 GA不是对研究对象直接进行讨论,而是通过某种编码机制把对象统一赋于由特定符号(字母)按一定顺序排成的串(string)。正如研究生物遗传,是从染色体着手,染色体则是由基因排成的串。 适应度函数 优胜劣败是自然进化的原则。优、劣要有标准。在GA中，用适应度函数描述每一个体的适应程度。 对优化问题,适应度函数与目标函数直接相关。引进适应度函数的目的在于可根据其适应度对个体进行评估比较,定出优劣程度。 在遗传算法的执行过程中,每一代有许多不同的个体(染色体)同时存在。这些染色体中哪个保留(生存)、哪个淘汰(死亡),是根据它们对环境的适应能力来决定的,适应性强的有更多的机会保留下来。 适应性强弱是通过计算适应度函数f(x)的值来判别的,这个值称为适应值。适应度函数f(x)的构成与目标函数有密切关系。 算法参数；在GA的实际操作时,需适当确定某些参数的值以提高选优的效果。这些参数包含： 字符串所含字符的个数,即串长。这一长度为常数,即为定长,记为\\(L\\) 每一代种群的大小,即所包含字符串的个数,也称种群规模,记为\\(n\\) 交叉概率(crossover rate),即施行交叉算子的概率,记为\\(P_c\\) 变异概率(mutation rate),即施行变异算子的概率,记为\\(P_m\\) 在GA中,种群规模\\(n\\)太小时难以求出最优解，太大则增长收敛时间。一般\\(n=30\\sim 160\\)。 交叉概率\\(P_c\\)太小时难以向前搜索，太大则容易破坏高适应值的结构。一般取\\(P_c=0.25\\sim 0.75\\)。 变异概率\\(P_m\\)太小时难以产生新的基因结构，太大使遗传算法成了单纯的随机搜索。一般取\\(P_m=0.01\\sim 0.2\\)。系统参数对算法的收敛速度及结果有很大的影响，应视具体问题选取不同的值。 遗传算子 选择算子(Selection/Reproduction): 选择算子从 种群中按某一概率成对选择个体，某个体\\(x_i\\)被选择的概率\\(P_i\\)与其适应度值成正比。最通常的实现方法是轮盘赌(roulette wheel)模型。 交叉算子(Crossover): 交叉算子将被选中的两个个体的基因链按概率\\(P_c\\)进行交叉，生成两个新的个体，交叉位置是随机的。其中\\(P_c\\)是一个系统参数。 变异算子(Mutation): 变异算子将新个体的基因链的各位按概率\\(P_m\\)进行变异，对二值基因链(0,1编码)来说即是取反。上述各种算子的实现是多种多样的，而且许多新的算子正在不断地提出，以改进GA的某些性能。 编码与解码 GA中的编码方法可分为三大类：二进制编码方法、浮点数编码方法和符号编码方法。\n二进制编码方案\n是GA中最常用的一种编码方法。它所构成的个体基因型是一个二进制编码符号串。\n二进制编码符号串的长度与问题所要求的求解精度有关。设某一参数的取值范围是\\([A, B]，A\u003c B\\)。则二进制编码的编码精度为：\n\\[\\delta = \\dfrac{B-A}{2^l-1} \\]\n假设某一个体的编码是：\\(X:b_lb_{l-1}b_{l-2}\\cdots b_2b_1\\)，则对应的解码公式为：\n\\[x = A+\\dfrac{B-A}{2^l-1}\\bigg(\\sum^l_{i=1}b_i2^{i-1}\\bigg) \\]\n格雷码\n格雷码是这样的一种编码方法，其连续的两个整数所对应的编码值之间仅仅有一个码位是不相同的，其余码位都完全相同。\n浮点编码\n所谓浮点数编码方法是指个体染色体编码串中的基因值用某一范围内的一个浮点数来表示，个体的编码长度等于其决策变量的个数。因为这种编码方法使用的是决策变量的真实值，所以浮点数编码方法也叫做真值编码方法。\n符号编码\n符号编码方法是指个体染色体编码串中的基因值取自一个无数值含义、而只有代码含义的符号集。\n这个符号集可以是一个字母表，如\\(\\{A,B,C,D,\\cdots\\}\\)；也可以是一个数字序号表，如\\(\\{1,2,3,\\cdots\\}\\)；还可以是一个代码表，如\\(\\{A_1,A_2,A_3,\\cdots\\}\\)等等。\n适应度函数 为了体现染色体的适应能力，引入了对问题中的每一个染色体都能进行度量的函数，叫适应度函数。通过适应度函数来衡量染色体的优、劣程度，它体现了自然进化中的优胜劣汰原则。一般，对于最大化的优化问题，适应度函数就是目标函数。\n交叉算子 对于选中用于繁殖下一代的个体，随机地选择两个个体的相同位置，按交叉概率\\(P_c\\)在选中的位置实行交叉。这个过程反映了随机信息交换；\n目的在于产生新的基因组合，也即产生新的个体。交叉时，可实行单点交叉或多点交叉。\n例如有个体\n\\[P1 = 10010110\\\\ P2 = 01011110 \\]\n选择它们的左边\\(3\\)位进行交叉操作，则有\n\\[P1 = 01010110\\\\ P2 = 10011110 \\]\n变异算子 根据生物遗传中基因变异的原理，以变异概率\\(P_m\\)对某些个体的某些位执行变异。\n在变异时，对执行变异的串的对应位求反，即把\\(1\\)变为\\(0\\)，把\\(0\\)变为\\(1\\)。\n变异概率\\(P_m\\)与生物变异极小的情况一致，所以，\\(P_m\\)的取值较小。\n变异能保证算法过程不会产生无法进化的单一种群。因为在所有的个体一样时，交叉是无法产生新的个体的，这时只能靠变异产生新的个体。\n选择算子 选择操作：根据适应度函数值所度量的个体的优、劣程度决定它在下一代是被淘汰还是被保留。\n简单遗传算法采用轮盘赌选择机制\n轮盘赌选择机制\n令\\(\\sum f_i\\)表示种群的适应度值之总和，\\(f_i\\)表示种群中第\\(i\\)个染色体的适应度值，则它产生后代的能力正好为其适应度值所占份额\\(f_i/\\sum f_i\\)。\n显然，从上式可知：\n适应度较高的个体，繁殖下一代的能力就较强。 适应度较小的个体，繁殖下一代的能力就较弱，甚至被淘汰。 这样，就产生了对环境适应能力较强的后代。对于问题求解角度来讲，就是选择出和最优解较接近的中间解。\n停止条件 完成了预先给定的进化代数则停止； 种群中的最优个体在连续若干代没有改进 平均适应度在连续若干代基本没有改进时停止 特点 遗传算法是从问题解的编码组开始而非从单个解开始搜索； 遗传算法利用目标函数的适应度这一信息而非利用导数或其它辅助信息来指导搜索； 遗传算法利用选择、交叉、变异等算子而不是利用确定性规则进行随机操作。 不足 在变量多，取值范围大或无给定范围时，收敛速度下降； 可找到最优解附近，但无法精确确定最优解位置； 遗传算法的参数选择尚未有定量方法。 进化策略概述 进化策略 (Evolution Strategies，ES)是一类模仿自然进化原理以求解参数优化问题的算法。\n进化策略与遗传算法的结构类似，只是在算法的具体策略上存在差异。\n染色体编码：浮点数编码 交叉：离散重组、中值重组、混杂重组 变异：在每个分量上面加上零均值、某一方差的高斯分布的变化产生新的个体 选择：\\((\\mu+\\lambda)-ES\\)、\\((\\mu, \\lambda)-ES\\) 进化规划概述 进化规划（Evolutionary Programming）又称为进化编程，是由福格尔（Fogel）在1962年提出的一种模仿人类智能的方法。进化规划根据正确预测的符号数来度量适应值。通过变异，为父代群体中的每个机器状态产生一个子代。父代和子代中最好的部分被选择生存下来。\n5.jpg\r遗传算法、进化策略、进化规划的对比 进化计算的三种算法——遗传算法、进化策略和进化规划都是模拟生物界自然进化过程而建立的鲁棒性计算机算法。在统一框架下对三种算法进行比较，可以发现它们有许多 相似之处，同时也存在较大的差别。\n进化策略和进化规划都把变异作为主要搜索算子，而在标准的遗传算法中，变异只处于次要位置。交叉在遗传算法中起着重要作用，而在进化规划中却被完全省去，在进化策略中与自适应结合使用，起了很重要的作用。标准遗传算法和进化规划都强调随机选择机制的重要性，而从进化策略的角度看，选择是完全确定的。\n6.jpg\r进化计算的应用 复杂的非线性最优化问题 复杂的组合规划或整数规划问题 生物学：小生境理论、生物物种的形成 计算机科学：图像处理、自动识别、文档自动处理 工程应用：通讯网络的优化、超大规模集成电路布线、飞机外形设计 社会科学：人类行为规范进化过程的模拟、人口迁移模型 人工生命 人工生命(试图通过人工方法建造具有自然生命特征的人造系统。人工生命(Artificial Life ，AL))\n1987年兰德提出的人工生命定义为：“人工生命是研究能够演示出自然生命系统特征行为的人造系统”。\n人工生命的研究内容 人工生命的研究对象包括人工动物、人工植物和人工人等，而人工人的研究又涉及人工脑和其它人工器官。\n研究内容包括\n构成生物体的内部系统，包括脑、神经系统、内分泌系统、免疫系统、遗传系统、酶系统、代谢系统等。 生物体及其种群的外部系统，包括环境适应系统和遗传进化系统等。 人工生命的科学框架 生命现象仿生系统 生命现象的建模与仿真 进化动力学 人工生命的计算理论和工具 进化机器人 进化和学习等方面的结合 人工生命的应用 人工生命的研究方法 从生物体内部和外部系统的各种信息出发，可得到人工生命的不同研究方法，主要可分为两类：\n信息模型法。 工作原理法。 人工生命的研究技术途径也可分为两种：\n工程技术途径。 生物科学途径。 人工生命的实例 人工脑、计算机病毒、计算机进程、细胞自动机、人工核苷酸\n群智能算法 群智能概述 群智能（Swarm Intelligence, SI）\n群（swarm）：某种交互作用的组织或agent的结构集合。\n对于群居昆虫，如蚂蚁、蜜蜂、鱼群、鸟群等，个体在结构上是很简单的，而它们的集体行为却可能变得相当复杂。\n人们把群居昆虫的集体行为称作“群智能”，即低智能的主体通过合作表现出高智能行为的特性。\n群智能算法是一种基于生物群体行为规律的计算技术。\n特点\n个体的行为很简单，但当它们一起协同工作时却能够突现出非常复杂（智能）的行为特征。\n群智能优化在没有集中控制且不提供全局模型的前提下，为寻找复杂的分布式问题求解方案提供了基础。\n优点\n灵活性：群体可以适应随时变化的环境； 稳健性：个体失败，群体仍能完成任务； 自组织：活动既不受中央控制，也不受局部监管。 典型算法\n粒子群优化算法（鸟群捕食），蚁群算法（蚂蚁觅食）\n粒子群优化算法 简述\n粒子群优化算法（Particle Swarm Optimization，PSO），也称为粒子群算法，是近几年来发展起来的一种新的群体搜索算法。\n和遗传算法相似，它也是从随机的解出发，通过迭代寻找最优解，通过适应度来评价解的品质。\n比遗传算法规则更为简单，它没有遗传算法的“交叉”(Crossover) 和“变异”(Mutation) 操作，而是追随当前搜索到的最优值来寻找全局最优。\n原理描述\n假设存在一个区域，所有的鸟都不知道食物的位置，但是它们知道当前的位置离食物还有多远。找到食物的最优策略是什么呢？搜寻目前离食物最近的鸟的周围区域。\n在该算法中，每个解看作一只鸟，称为粒子(particle)，所有的粒子都有一个适应值，每个粒子都有一个速度决定它们的飞翔方向和距离，粒子们追随当前最优粒子在解空间中搜索。\n当其它鸟发现了更佳的觅食地点，鸟群间会有某种类似广播的沟通行为，渐渐的将其它鸟群引领至较佳的地点。这样的觅食行为是利用社会中所存在的互相影响的概念，来引领所有个体朝向最佳解位置。\n假设在D维搜索空间中，有m个粒子；\n其中第i个粒子的位置矢量表示为： \\[\\overrightarrow{x_i} = (x_{i1},x_{i2},\\cdots,x_{iD}) \\]\n飞翔速度矢量表示为： \\[\\overrightarrow{v_i} = (v_{i1},v_{i2},\\cdots,v_{iD}) \\]\n第 i个粒子搜索到的最优位置为： \\[\\overrightarrow{p_i} = (p_{i1},p_{i2},\\cdots,p_{iD}) \\]\n整个粒子群搜索到的最优位置为： \\[\\overrightarrow{p}_{gbest} = (p_{gbest1},p_{gbest2},\\cdots,p_{gbestD}) \\]\n粒子速度和位置的更新\n\\[v_{id}^{k+1} = wv_{id}^k+c_1\\text{rand}()(p_{id}-x_{id}^k)+c_2\\text{rand}()(p_{gbest}-x_{id}^k) \\]\n\\[x_{id}^{k+1} = x_{id}^k + v_{id}^{k+1} \\]\n其中\\(w\\)为惯性权重，\\(d=1,2,\\cdots,D,\\quad i=1,2,\\cdots,M\\)。\\(c_1,c_2\\)为两个正常数称为加速因子，\\(\\text{rand}()\\)为分布于\\([0,1]\\)的随机数\n\\(v_{id}^{k+1}\\)分为三项，第一项是惯性部分，第二项是认知部分，第三项是社会部分\n7.jpg\r参数分析\n惯性权重\\(w\\) 使粒子保持运动惯性，使其有搜索扩展空间的趋势，有能力探索新的区域。\n也表示微粒对当前自身运动状态的信任，依据自身的速度进行惯性运动。\n较大的\\(w\\)有利于跳出局部极值，而较小的\\(w\\)有利于算法收敛。\n改进的惯性权重\\(w\\) 在优化实际优化问题时，往往希望先采用全局搜索，使搜索空间快速收敛于某一区域，然后采用局部精细搜索以获得高精度的解。\n因此提出了自适应调整的策略，即随着迭代的进行，线性地减小\\(w\\)的值。\n\\[w = w_{\\text{max}} - \\dfrac{w_{\\text{max}}-w_{\\text{min}}}{iter_{\\text{max}}}\\times iter \\]\n其中\\(iter,iter_{\\text{max}}\\)分别是当前迭代次数和最大迭代次数\n加速因子\\(c_1,c_2\\) 使代表将微粒推向\\(pbest\\)和\\(gbest\\)位置的统计加速项的权重。\n表示粒子的动作来源于自己经验的部分和其它粒子经验的部分。\n低的值粒子在目标区域外徘徊，而高的值导致粒子越过目标域。\n改进的加速因子\\(c_1\\)和\\(c_2\\) 通常将\\(c_1\\)和\\(c_2\\)统一为一个控制参数，\\(\\varphi=c_1+c_2\\)\n如果\\(\\varphi\\)很小，微粒群运动轨迹将非常缓慢；\n如果\\(\\varphi\\)很大，则微粒位置变化非常快；\n通过仿真可以获得\\(\\varphi\\)的经验值，当\\(\\varphi=4.0(c_1=2.0,c_2=2.0)\\)时，具有很好的收敛效果。\n粒子数 通常一般取20～40，对较难或特定类别的问 题可以取100～200。\n最大速度\\(v_{max}\\) 决定粒子在一个循环中最大的移动距离，通常设定为粒子的范围宽度。\n粒子群算法与遗传算法的比较\n共性：\n都属于仿生算法； 都属于全局优化方法； 都属于随机搜索算法； 都隐含并行性； 根据个体的适配信息进行搜索，因此不受函数约束条件的限制，如连续性、可导性。 对高维复杂问题，无法保证收敛到最优点。 差异：\nPSO有记忆，所有粒子都保存较优解的知识，而GA，以前的知识随着种群的改变被改变； PSO中的粒子是一种单向共享信息机制。而GA中的染色体之间相互共享信息； GA需要编码和遗传操作，粒子只是通过内部速度进行更新，实现更容易。 蚁群算法 蚂蚁可以找出最短路径，为什么？\n信息素（pheromone）：蚂蚁在寻找食物时，其经过的路 上释放的一种易挥发的物质。该信息素 可以被其它的蚂蚁感知，并且信息素的浓度越高，对应的路径越短。\n正反馈：蚂蚁会以较大的概率选择信息素浓度较高的路径，并释放一定量的信息素以增强该路径上的信息素浓素，从而距离较短的路径被加强，形成一个正反馈。\n蚁群算法的模型与实现\u0026mdash;-TSP\n不失一般性设蚂蚁的数量为\\(m\\)，城市的数量为\\(n\\)，城市\\(i\\)和城市\\(j\\)的距离为\\(d(i,j)\\)，距离选用欧式距离，\\(t\\)时刻城市\\(i\\)和城市\\(j\\)连接路径的信息素浓度为\\(\\tau(i,j)\\)。\n在算法初始时刻，设各城市连接路径的信息素浓度具有相同的值，\\(m\\)只蚂蚁放到\\(n\\)座城市。\n蚂蚁的初始分布\n所有蚂蚁初始时刻放在同一城市。 所有蚂蚁初始时刻分布在不同城市中。 显而易见，第二种方法将蚂蚁放在不同的城市中算法具有较高的性能。在不同城市分布时，随机分布与统一均匀分布的效果差别不大。\n每只蚂蚁根据路径上的信息素和启发式信息，独立地访问下一座城市，概率公式如下 \\[p^k(i,j)=\\left\\{\\begin{align*} \u0026 \\dfrac{[\\tau(i,j)]^\\alpha\\cdot[\\eta(i,j)]^\\beta}{\\displaystyle{\\sum_{s\\notin tabu_k}}[\\tau(i,s)]^\\alpha\\cdot[\\eta(i,s)]^\\beta},\\ \u0026if\\ j\\notin tabu_k\\\\ \u0026 0,\\ \u0026otherwise \\end{align*}\\right. \\]\n其中\\(\\eta(i,j) = 1/d(i,j)\\)是启发函数，表示蚂蚁从城\\(i\\)到城\\(j\\)的期望程度，距离越短函数值越大。\n\\(\\alpha\\)是信息素重要程度因子。\\(\\beta\\)是启发函数重要程度因子。\n\\(tabu_k\\)为禁忌表，表示已经访问的城市集合\n蚂蚁从当前城市访问下一城市的概率确定后，通常采用轮盘赌法选择下一城市，概率大被选中机会就大。\n当所有蚂蚁完成一次访问后，各路径上的信息素将进行更新，信息素公式更新如下\n\\[\\tau_{i,j}(t+1) = (1-\\rho)\\cdot\\tau_{i,j}(t)+\\Delta\\tau_{ij} \\]\n\\[\\Delta\\tau_{ij} = \\sum^m_{k=1}\\Delta\\tau_{ij}^k \\]\n其中\\(ρ\\)的取值为\\(0\u003cρ\u003c1\\)，表示路径上信 素的挥发系数。\n针对蚂蚁释放信息素问题，比较常用的有如下三种模型： Ant cycle system\n\\[\\Delta\\tau^k_{ij}=\\left\\{\\begin{align*} \u0026 \\dfrac{Q}{L_k},\\ \u0026ij\\in l_k\\\\ \u0026 0,\\ \u0026otherwise \\end{align*}\\right. \\]\n\\(Q\\)为正常数，\\(L_k\\)表示第\\(k\\)只蚂蚁在本次访问城市中所走过路径的长度\nAnt quantity system\n\\[\\Delta\\tau^k_{ij}=\\left\\{\\begin{align*} \u0026 \\dfrac{Q}{D_{ij}},\\ \u0026ij\\in l_k\\\\ \u0026 0,\\ \u0026otherwise \\end{align*}\\right. \\]\n\\(Q\\)为正常数，\\(D_{ij}\\)表示第\\(k\\)只蚂蚁在本次访问中城市\\(i\\)和城市\\(j\\)的距离\nAnt density system\n\\[\\Delta\\tau^k_{ij}=\\left\\{\\begin{align*} \u0026 Q,\\ \u0026ij\\in l_k\\\\ \u0026 0,\\ \u0026otherwise \\end{align*}\\right. \\]\n\\(Q\\)为正常数，在整个访问过程中密度始终保持不变。\n这三种模型分别对应路径的整体信息（蚂蚁所访问路径的总长）、局部信息（蚂蚁所访问城市间的距离）和不考虑路径信息。\n以下优化TSP问题，选用ant cycle system模型，即路径的整体信息路径越短，释放的信息素度越高\n蚁群算法解决TSP问题基本流程 8.jpg\r优点\n蚁群算法与其他启发式算法相比，在求解性能上，具有很强的鲁棒性（对基本蚁群算法模型稍加修改，便可以应用于其他问题）和搜索较好解的能力。 蚁群算法是一种基于种群的进化算法，具有本质并行性，易于并行实现。 蚁群算法很容易与多种启发式算法结合如遗传算法、粒子群算法，以改善算法性能。 不足\n如果初始化参数设置不当，导致求解速度很慢且所得解的质量特别差。 基本蚁群算法即无改进的蚁群算法计算量大，求解所需时间较长。 基本蚁群算法理论上要求所有的蚂蚁选择同一路线，该线路即为所求的最优线路；但在实际计算中，在给定一定循环数的条件下很难达到这种情况。 改进\n最优解保留策略（Ant System with Elitist）该策略能够以更快的速度获得最好解，但是如果选择的精英过多则算法会由于较早收敛于局部次优解而导致搜索的过早停滞。 局部信息素更新使已选的路径对后来的蚂蚁具有较小的影响力，从而使蚂蚁对没有选中的路径有更强的探索能力。 最大\u0026ndash;最小蚂蚁系统（max-min ant system） 每次迭代后，只有最优解（最优蚂蚁）所属路径上的信息被更新； 为了避免过早收敛，将各条路径可能的信息素限制于\\([\\tau_{min},\\tau_{max}]\\)； 在算法初始时刻，\\(\\rho\\)取较小值，算法有更好的发现较好解的能力。随着迭代次数的增加，\\(\\rho\\)变大加快算法的收敛。 群智能优化的特点与不足 共同特点：\n基于概率计算的随机搜索进化算法，在结 构、研究内容、方法以及步骤上有较大的相似性；结果偏随机性。\n存在的问题：\n数学理论基础相对薄弱； 参数设置没有确切的理论依据，对具体问题和应用环境的依赖性大； 进一步的改进：\n进一步研究真实群居动物的行为特征，建立合适的数学模型； 进一步研究算法的收敛性； 进一步提高收敛速度，从而解决大规模优化问题； 进一步研究各种参数设置问题； 研究群智能的并行算法； 进一步研究各算法的适用范围； 研究与其它算法的混合技术。 人工神经网络 神经计算 智慧（思维）是人的大脑的功能的表现。\n大脑是由无数的脑细胞组成。既然“思维”是大脑的功能的表现，即智慧是脑神经网络的功能。那么人们希望利用人工神经网络来模拟人脑的神经网络，研究其性能，希望从中悟出人的思维的一些“奥秘”。这就是所谓的人工神经网络技术，这种技术为人工智能提供新的解决问题的方法,并广泛应用于各个领域。\n生物神经系统 生物神经系统是一个有高度组织和相互作用的数量巨大的细胞组织群体。\n神经细胞也称神经元，是神经系统的基本单元，它们按不同的结合方式构成了复杂的神经网络。通过神经元及其联接的可塑性，使得大脑具有学习、记忆和认知等各种智能。\n生物神经元主要由以下3个部分组成：\n细胞体，是神经细胞的本体; 树突，用于接受来自其它细胞元的信号; 轴突，用于输出信号，与多个神经元连接; 突触，是神经元之间相互连接的的接口部分，即一个神经元的神经末梢与另一个神经元的树突相接触的交界面，位于神经元的神经末梢尾端。\n生物神经元的基本工作机制\n一个神经元有两种状态-兴奋和抑制。\n平时处于抑制状态的神经元，其树突和细胞体接受其它神经元经由突触传来的兴奋电位，多个输入在神经元中以代数和的方式叠加。\n如输入兴奋总量超过阈值，神经元被激发进入兴奋状态，发出输出脉冲，由轴突的突触传递给其它神经元。\n生物神经特性\n并行分布处理的工作模式。 神经系统的可塑性和自组织性。 信息处理与信息存贮合二为一。 信息处理的系统性。 能接受和处理模糊的、模拟的、随机的信息。 求满意解而不是精确解。 系统的恰当退化和冗余备份(鲁棒性和容错性) 人工神经网络 人工神经网络（Artificial Neural Network，ANN）是由大量处理单元经广泛互连而组成的人工网络，用来模拟脑神经系统的结构和功能。而这些处理单元称作人工神经元。\n人工神经网络的结构\n人工神经网络（ANN）可以看成是以人工神经元为结点，用有向加权弧连接起来的有向图。\n在此有向图中，人工神经元就是对生物神经元的模拟，而有向弧则是树突—突触—轴突对的模拟。有向弧的权值表示相互连接的两个人工神经元间相互作用的强弱。\n人工神经网络的进展\n初创阶段（二十世纪四十年代至六十年代） 过渡阶段（二十世纪六十年代初至七十年代） 高潮阶段（二十世纪八十年代） 平稳发展阶段（二十世纪九十年代以后） 人工神经网络的特性\n可以充分逼近任意复杂的非线性关系 所有定量或定性的信息都等势分布贮存于网络内的各神经元，故有很强的鲁棒性和容错性 采用并行分布处理方法，使得快速进行大量运算成为可能 可学习和自适应不知道或不确定的系统 能够同时处理定量、定性知识。 可以通过软件和硬件实现。 人工神经元模型\n神经元单元由多个输入\\(x_i,i=1,2,\\cdots,n\\)和一个输出\\(y\\)组成。中间状态由输入信号的权和表示，而输出为\n\\[y_j = a\\bigg(\\sum^n_{i=1}\\omega_{ji}x_i-\\theta_j \\bigg) \\]\n式中，\\(\\theta_j\\)为神经元单元的偏置或阈值，\\(w_{ji}\\)为连接权系数。\\(n\\)为输入信号数目，\\(y_j\\)为神经元输出， \\(a(\\cdots)\\)为输出变换函数,也叫激励函数，特性函数。\n神经网络的基本特性和结构\n人工神经网络是具有下列特性的有向图\n对于每个节点\\(i\\)，存在一个状态变量\\(x_i\\)； 从节点\\(i\\)至节点\\(j\\),存在一个连接权系数\\(w_{ij}\\)； 对于每个节点\\(i\\)，存在一个阈值\\(\\theta_i\\)； 对于每个节点\\(i\\)，定义一个激活函数。 神经网络中的常见模型\n主要有前馈神经网络（也叫前向神经网络）；反馈神经网络（也叫递归神经网络）。\n前馈神经网络：具有递阶分层结构,神经元从一层连接至下一层，不存在同层神经元间的连接。\n反馈神经网络：有些神经元的输出被反馈至同层或前层神经元。其输入数据决定反馈系统的初始状态，然后系统经过一系列的状态转移后逐渐收敛于平衡状态，即为反馈神经网络经过计算后的输出结果。\n前馈神经网络 前馈网络具有递阶分层结构，由同层神经元间不存在互连的层级组成。\n从输入层至输出层的信号通过单向连接流通；神经元从一层连接至下一层，不存在同层神经元间的连接，前馈网络的例子有：\n反向传播神经网络（BP） 径向基神经网络（RBF） 多层感知器（MLP） 学习矢量量化（LVQ）网络 小脑模型联接控制（CMAC）网络 反馈神经网络 反馈网络又叫做递归网络。在反馈（递归）神经网络中，多个神经元互连以组织一个互连神经网络。如图所示。有些经元的输出被反馈至同层或前层神经元。因此，信号能够从正向和反向流通。\nHopfield网络，Elmman网络和Jordan网络是递归网络有代表性的例子。\n神经网络的主要学习算法 学习是神经网络研究的一个重要内容，它的适应性是通过学习实现的。根据环境的变化，对权值进行调整，改善系统的行为。\n神经网络主要通过指导式（有师）学习算法和非指导式（无师）学习算法。此外，还存在第三种学习算法，即强化学习算法；可把它看做有师学习的一种特例。\n有师学习\n有师学习算法能够根据期望的和实际的网络输出（对应于给定输入）间的差来调整神经元间连接的强度或权。因此，有师学习需要有个老师或导师来提供期望或目标输出信号。\n有师学习算法的例子包括\\(\\delta\\)规则、广义\\(\\delta\\)规则或反向传播算法以及LVQ算法等。\n无师学习\n无师学习算法不需要知道期望输出。在训练过程中，只要向神经网络提供输入模式，神经网络就能够自动地适应连接权，以便按相似特征把输入模式分组聚集。\n无师学习算法的例子包括Kohonen算法和 Carpenter-Grossberg自适应谐振理论(ART) 等.\n强化学习\n强化（增强）学习是有师学习的特例。它不需要老师给出目标输出。强化学习算法采用一个“评论员”来评价与给定输入相对应的神经网络输出的优度（质量因数）。\n基于神经网络的知识表示 在基于神经网络的系统中，知识的表示方法与传统人工智能系统中所用的方法（如产生式系统、框架、语义网络等）完全不同。人工智能系统中所用的方法是知识的显式表示，而神经网络中的知识是一种隐式的表示方法。在这里，知识并不像在产生式系统中那样独立地表示为每一条规则, 而是将某一问题的若干知识在同一网络中表示。\n基于神经网络的知识推理 基于神经网络的知识推理实质上是在一个已经训练成熟的网络基础上对未知样本进行反应或者判断。\n神经网络的训练是一个网络对训练样本内在规律的学习过程，而对网络进行训练的目的主要是为了让网络模型对训练样本以外的数据具有正确的映射能力。\n通常将神经网络在训练完成后输入其训练样本以外的新数据时获得正确输出的能力定义为神经网络的泛化能力（推广能力）。\n它是人工神经网络的一个属性，称为泛化性能。\n泛化性能的好坏取决于人工神经网络是否 从训练样本中找到内在的真正规律。\n影响泛化能力的因素主要有：\n训练样本的质量和数量 网络结构 问题本身的复杂程度 神经网络的训练次数也称为神经网络的学 习时间。在一定范围内，训练次数的增加 可以提高神经网络的泛化能力。\n然而，在神经网络的训练过程中经常出现一种过拟合现象，即在训练样本的误差逐渐减小并达到某个定值以后，往往会出现网络对训练样本以外的测试样本的误差反而开始增加的情况。因而，对网络的训练，并不是使训练误差越小越好，而是要从实际出发，提高泛化能力。\n最佳的泛化能力往往出现在训练误差的全局最小点出现之前，最佳泛化点出现存在一定的时间范围。只要训练时间合适，较大的神经网络也会有好的泛化能力。\n训练完成后，基于神经网络的推理是通过网络计算实现的。把用户提供的初始证据用作网络的输入，通过网络计算最终得到输出结果。\n网络推理的大致过程。一般来说，正向网络推理的步聚如下：\n把已知数据输入网络输入层的各个节点。 利用特性函数分别计算网络中各层的输出。计算中，前一层的输出作为后一层有关节点的输入，逐层进行计算 ，直至计算出输出层的输出值为止。 用阈值函数对输出层的输出进行判定，从而得到输出结果。 机器学习 ","date":"2022-10-31T09:56:28+08:00","image":"https://kegalas.top/inferior/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E7%AC%94%E8%AE%B0/cover_hu729735102c3c060f4a29b2f0df39e169_86954_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E7%AC%94%E8%AE%B0/","title":"人工智能概论笔记"},{"content":"导航页面\n图形学中最基础的数学涉及到线性代数，我们需要自己先写一个能处理简单的向量、矩阵运算的库。前置知识：大学本科水平的线性代数。\ngeometry.h 向量的定义 首先构造一个一般化的向量类\ntemplate\u0026lt;class T, size_t dim\u0026gt; class Vec{ public: Vec(){ for(size_t i=0;i\u0026lt;dim;i++){ data_[i] = T(); } } Vec(Vec\u0026lt;T,dim\u0026gt; const \u0026amp; v){ for(size_t i=0;i\u0026lt;dim;i++){ data_[i] = v[i]; } } T\u0026amp; operator[](const size_t i){ assert(i\u0026lt;dim \u0026amp;\u0026amp; i\u0026gt;=0); return data_[i]; } const T\u0026amp; operator[](const size_t i) const { assert(i\u0026lt;dim \u0026amp;\u0026amp; i\u0026gt;=0); return data_[i]; } Vec\u0026lt;T, dim\u0026gt;\u0026amp; operator=(const Vec\u0026lt;T,dim\u0026gt; vec){ if(this==\u0026amp;vec){ return *this; } for(size_t i=0;i\u0026lt;dim;i++){ this-\u0026gt;data_[i] = vec[i]; } return *this; } private: T data_[dim]; }; 首先template\u0026lt;class T, size_t dim\u0026gt;指的是让它的向量元素的数据类型为T，然后有dim维\nVec()这个默认构造函数不难理解，Vec(Vec\u0026lt;T,dim\u0026gt; const \u0026amp; v)是一个复制构造函数，而相应的Vec\u0026lt;T, dim\u0026gt;\u0026amp; operator=(const Vec\u0026lt;T,dim\u0026gt; vec)是一个复制赋值运算符。\nT\u0026amp; operator[]是为了方便取向量的某一个元素，并且同时提供了const的版本，这是一个经常可以见到的设计。并且我们检查数组越界。\n下面对其进行模板特殊化\ntemplate\u0026lt;class T\u0026gt; class Vec\u0026lt;T,2\u0026gt;{ public: union{ struct {T x,y;}; struct {T s,t;}; struct {T u,v;}; T raw[2]; }; Vec\u0026lt;T,2\u0026gt;():x(),y(){} Vec\u0026lt;T,2\u0026gt;(T x_, T y_):x(x_),y(y_){} Vec\u0026lt;T,2\u0026gt;(Vec\u0026lt;T,2\u0026gt; const \u0026amp; v):x(v.x),y(v.y){} template\u0026lt;class U\u0026gt; Vec\u0026lt;T,2\u0026gt;(Vec\u0026lt;U,2\u0026gt; const \u0026amp;); template\u0026lt;class U\u0026gt; Vec\u0026lt;T,2\u0026gt;(Vec\u0026lt;U,3\u0026gt; const \u0026amp;); template\u0026lt;class U\u0026gt; Vec\u0026lt;T,2\u0026gt;(Vec\u0026lt;U,4\u0026gt; const \u0026amp;); T\u0026amp; operator[](const size_t i){ assert(i\u0026lt;2 \u0026amp;\u0026amp; i\u0026gt;=0); return raw[i]; } const T\u0026amp; operator[](const size_t i) const{ assert(i\u0026lt;2 \u0026amp;\u0026amp; i\u0026gt;=0); return raw[i]; } Vec\u0026lt;T, 2\u0026gt;\u0026amp; operator=(const Vec\u0026lt;T,2\u0026gt;\u0026amp; vec){ if(this==\u0026amp;vec){ return *this; } for(size_t i=0;i\u0026lt;2;i++){ this-\u0026gt;raw[i] = vec[i]; } return *this; } }; 如上，我们定义了一个二维的向量，这个叫做模板特殊化，当我们声明Vec\u0026lt;float,2\u0026gt;时，会首先调用最特殊的那个，在此处会调用Vec\u0026lt;T,2\u0026gt;，而不是更一般的Vec\u0026lt;T,dim\u0026gt;\n另外需要注意的是，模板特殊化并不是继承，特殊的模板不会继承一般的模板的成员。所以我们需要重新地定义整个Vec\u0026lt;T,2\u0026gt;\nunion{ struct {T x,y;}; struct {T s,t;}; struct {T u,v;}; T raw[2]; }; 这是一个联合，但实际上只用了两个sizeof(T)的内存，其中x、s、u和raw[0]表示的都是第一维，而y、t、v、raw[1]表示的是第二维\nVec\u0026lt;T,2\u0026gt;():x(),y(){} Vec\u0026lt;T,2\u0026gt;(T x_, T y_):x(x_),y(y_){} Vec\u0026lt;T,2\u0026gt;(Vec\u0026lt;T,2\u0026gt; const \u0026amp; v):x(v.x),y(v.y){} 这是三个构造函数，有时我们可能会写成\nVec\u0026lt;T,2\u0026gt;(T x_, T y_){ x = x_; y = y_; } 这效果是相同的，但是如果T是一个类，而不是一个int、float这样的类型，那会导致性能问题。\n此时会先调用x的默认构造函数，然后再将x_赋值给x，调用复制赋值运算符，这是两步。而我们用成员初始化列表就直接调用了赋值构造函数，只有一步。\n虽然你可能会想为什么会有人给向量除了int和float之外的类型，我觉得你最好不要推断用户的想法。\ntemplate\u0026lt;class U\u0026gt; Vec\u0026lt;T,2\u0026gt;(Vec\u0026lt;U,2\u0026gt; const \u0026amp;); template\u0026lt;class U\u0026gt; Vec\u0026lt;T,2\u0026gt;(Vec\u0026lt;U,3\u0026gt; const \u0026amp;); template\u0026lt;class U\u0026gt; Vec\u0026lt;T,2\u0026gt;(Vec\u0026lt;U,4\u0026gt; const \u0026amp;); 这是我们之后要让float类型和int类型互相转化而提前声明的模板。\n对三维和四维的向量基本相同，目前我们要学的图形学不会用到更高维的向量了。\n下面开始定义向量的各种运算\ntemplate\u0026lt;class T, size_t dim\u0026gt; Vec\u0026lt;T, dim\u0026gt; operator+(Vec\u0026lt;T, dim\u0026gt; const \u0026amp; lhs, Vec\u0026lt;T, dim\u0026gt; const \u0026amp; rhs){ Vec\u0026lt;T,dim\u0026gt; ret; for(size_t i=0;i\u0026lt;dim;i++){ ret[i] = lhs[i] + rhs[i]; } return ret; } 代码不难理解，我们选择在全局定义这个运算符，而不是在类内部定义成员函数。这是为了更好的泛用性。以及缩短码量。\n其他的加减乘除类似，不过我们这里的乘法和除法指的是各个元素对应的乘除，并且我们还要定义向量和的数乘，数除。数除还应该注意左右操作数。\n然后再定义点乘和叉乘\ntemplate\u0026lt;class T, size_t dim\u0026gt; T dot(Vec\u0026lt;T, dim\u0026gt; const \u0026amp; lhs, Vec\u0026lt;T, dim\u0026gt; const \u0026amp; rhs){ T ret = T(); for(int i=0;i\u0026lt;dim;i++){ ret += lhs[i] * rhs[i]; } return ret; } template\u0026lt;class T\u0026gt; Vec\u0026lt;T, 3\u0026gt; cross(Vec\u0026lt;T, 3\u0026gt; const \u0026amp; lhs, Vec\u0026lt;T, 3\u0026gt; const \u0026amp; rhs){ Vec\u0026lt;T, 3\u0026gt; ret; ret.x = lhs.y*rhs.z - lhs.z*rhs.y; ret.y = lhs.z*rhs.x - lhs.x*rhs.z; ret.z = lhs.x*rhs.y - lhs.y*rhs.x; return ret; } 不把*设计为点乘，主要是考虑到OpenGL也是用dot表示点乘，而*表示元素对应相乘。\n代码并不困难，数学也是高中知识，值得注意的是，叉乘只有三维向量才有定义。\ntemplate\u0026lt;class T, size_t dim\u0026gt; T norm(Vec\u0026lt;T, dim\u0026gt; const \u0026amp; vec){ T ret = dot(vec,vec); ret = std::sqrt(ret); return ret; } 定义向量的2-范数，也就是\\(\\sqrt{x_1^2+x_2^2+\\cdots}\\)，这可以方便我们计算长度。1-范数和无穷范数暂时用不上。\ntemplate\u0026lt;class T, size_t dim\u0026gt; void normalize(Vec\u0026lt;T, dim\u0026gt; \u0026amp; vec){ T vnorm = (static_cast\u0026lt;T\u0026gt; (1))/norm(vec); for(size_t i=0;i\u0026lt;dim;i++){ vec[i] *= vnorm; } } template\u0026lt;class T, size_t dim\u0026gt; Vec\u0026lt;T, dim\u0026gt; normalized(Vec\u0026lt;T, dim\u0026gt; const \u0026amp; vec){ Vec\u0026lt;T, dim\u0026gt; ret; T vnorm = (static_cast\u0026lt;T\u0026gt; (1))/norm(vec); for(size_t i=0;i\u0026lt;dim;i++){ ret[i] = vec[i] * vnorm; } return ret; } 分别定义了，将一个向量标准化，和返回一个向量的标准化。后者是可以对const变量使用的。\n值得注意的一点是，我们使用vnorm这个变量，是因为除法比乘法慢，我们通过预先计算倒数，来加速这个过程。\ntemplate\u0026lt;class T, size_t dim\u0026gt; std::ostream\u0026amp; operator\u0026lt;\u0026lt;(std::ostream\u0026amp; out, const Vec\u0026lt;T, dim\u0026gt;\u0026amp; vec){ for(size_t i=0;i\u0026lt;dim;i++){ out\u0026lt;\u0026lt;vec[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } return out; } 我们重载了输出流，方便直接打印出来调试。\nVec\u0026lt;int,4\u0026gt; toOARColor(int const \u0026amp; v); Vec\u0026lt;int,4\u0026gt; toOARColor(float const \u0026amp; v); Vec\u0026lt;int,4\u0026gt; toOARColor(Vec\u0026lt;int,3\u0026gt; const \u0026amp; v); Vec\u0026lt;int,4\u0026gt; toOARColor(Vec\u0026lt;float,3\u0026gt; const \u0026amp; v); Vec\u0026lt;int,4\u0026gt; toOARColor(Vec\u0026lt;int,4\u0026gt; const \u0026amp; v); Vec\u0026lt;int,4\u0026gt; toOARColor(Vec\u0026lt;float,4\u0026gt; const \u0026amp; v); 在计算机图形学中，颜色也可以表示为一个向量，为此我们声明几个函数将其他的向量转变为RGB或RGBA颜色值。\n这里其中前两个是转换灰度值，中间两个是转换RGB，最后两个是转换RGBA。具体的实现后面会介绍到。\n矩阵的定义 template\u0026lt;class T, size_t nRow, size_t nCol\u0026gt; class Mat{ private: Vec\u0026lt;T, nCol\u0026gt; rowVec[nRow]; public: Mat\u0026lt;T, nRow, nCol\u0026gt;(){ size_t minDim = std::min(nRow, nCol); for(size_t i=0 ; i\u0026lt;minDim ; i++){ rowVec[i][i] = static_cast\u0026lt;T\u0026gt; (1); } } Mat\u0026lt;T, nRow, nCol\u0026gt;(T const value){ size_t minDim = std::min(nRow, nCol); for(size_t i=0 ; i\u0026lt;minDim ; i++){ rowVec[i][i] = value; } } Mat\u0026lt;T, nRow, nCol\u0026gt;(Mat\u0026lt;T, nRow, nCol\u0026gt; const \u0026amp; m){ for(size_t i=0 ; i\u0026lt;nRow ; i++){ rowVec[i] = m[i]; } } Vec\u0026lt;T, nCol\u0026gt;\u0026amp; operator[](size_t const i){ assert(i\u0026gt;=0 \u0026amp;\u0026amp; i\u0026lt;nRow); return rowVec[i]; } const Vec\u0026lt;T, nCol\u0026gt;\u0026amp; operator[](size_t const i) const { assert(i\u0026gt;=0 \u0026amp;\u0026amp; i\u0026lt;nRow); return rowVec[i]; } Mat\u0026lt;T, nRow, nCol\u0026gt;\u0026amp; operator=(Mat\u0026lt;T, nRow, nCol\u0026gt; const \u0026amp; mat){ if(this==\u0026amp;mat){ return *this; } for(size_t i=0 ; i\u0026lt;nRow ; i++){ this-\u0026gt;rowVec[i] = mat[i]; } return *this; } Vec\u0026lt;T, nRow\u0026gt; getColVec(size_t const index) const { assert(index\u0026gt;=0 \u0026amp;\u0026amp; index\u0026lt;nCol); Vec\u0026lt;T, nRow\u0026gt; ret; for(size_t i=0 ; i\u0026lt;nRow ; i++){ ret[i] = rowVec[i][index]; } return ret; } void setColVec(size_t const index, Vec\u0026lt;T, nRow\u0026gt; const \u0026amp; vec){ assert(index\u0026gt;=0 \u0026amp;\u0026amp; index\u0026lt;nCol); for(size_t i=0 ; i\u0026lt;nRow ; i++){ rowVec[i][index] = vec[i]; } } }; Vec\u0026lt;T, nCol\u0026gt; rowVec[nRow] 这一句，意味着我们采取了行先序，我们将一个矩阵看成了n个行向量。意味着mat[1][2]代表着第1行的第2个元素。行先序和matlab一致，也和glm库一致。\n我们的默认构造函数默认地构造了一个单位矩阵，即主对角线上的元素都是1，而Mat\u0026lt;T, nRow, nCol\u0026gt;(T const value)这个构造函数将主对角线上的元素设置为value。\nMat\u0026lt;T, nRow, nCol\u0026gt;\u0026amp; operator=(Mat\u0026lt;T, nRow, nCol\u0026gt; const \u0026amp; mat){ if(this==\u0026amp;mat){ return *this; } for(size_t i=0 ; i\u0026lt;nRow ; i++){ this-\u0026gt;rowVec[i] = mat[i]; } return *this; } 另外我们提供了复制构造函数以及复制赋值运算符，后者是很有必要的，否则默认的赋值运算，将会把rowVec这个指针指向右值中对应的地址，此时两个矩阵实际上用的是同一份数据，为了避免这个，我们有必要重新设计复制赋值运算符。\nVec\u0026lt;T, nRow\u0026gt; getColVec(size_t const index) const { assert(index\u0026gt;=0 \u0026amp;\u0026amp; index\u0026lt;nCol); Vec\u0026lt;T, nRow\u0026gt; ret; for(size_t i=0 ; i\u0026lt;nRow ; i++){ ret[i] = rowVec[i][index]; } return ret; } void setColVec(size_t const index, Vec\u0026lt;T, nRow\u0026gt; const \u0026amp; vec){ assert(index\u0026gt;=0 \u0026amp;\u0026amp; index\u0026lt;nCol); for(size_t i=0 ; i\u0026lt;nRow ; i++){ rowVec[i][index] = vec[i]; } } 我们也提供了获取和修改列向量的函数。\n接下来同样是提供全局的运算符重载。\n矩阵的相加、相减、数乘、数除和向量的代码基本一致。但同样为了和OpenGL着色器语言保持一致，我们矩阵乘以向量和向量相乘用的是*符号。\ntemplate\u0026lt;class T, size_t nRow, size_t nCol\u0026gt; Vec\u0026lt;T, nRow\u0026gt; operator*(Mat\u0026lt;T, nRow, nCol\u0026gt; const \u0026amp; lhs, Vec\u0026lt;T, nCol\u0026gt; const \u0026amp; rhs){ Vec\u0026lt;T, nRow\u0026gt; ret; for(size_t i=0 ; i\u0026lt;nRow ; i++){ ret[i] = dot(lhs[i] , rhs); } return ret; } template\u0026lt;class T, size_t nRow, size_t nCol, size_t sameDim\u0026gt; Mat\u0026lt;T, nRow, nCol\u0026gt; operator*(Mat\u0026lt;T, nRow, sameDim\u0026gt; const \u0026amp; lhs, Mat\u0026lt;T, sameDim, nCol\u0026gt; const \u0026amp; rhs){ Mat\u0026lt;T, nRow, nCol\u0026gt; ret; for(size_t i=0 ; i\u0026lt;nRow ; i++){ for(size_t j=0 ; j\u0026lt;nCol ; j++){ ret[i][j] = dot(lhs[i] , rhs.getColVec(j)); } } return ret; } 这里我们默认向量都是列向量，所以矩阵向量要求向量的维数和矩阵的列数相同。 在图形学中，我们大部分时候其实只会把矩阵当成左操作数，向量当成右操作数，所以我们就暂时不考虑相反情况的代码了。\n而矩阵乘以矩阵要求前者的列数等于后者的行数。\n用模板可以很好地实现上述内容。\ntemplate\u0026lt;class T, size_t nRow, size_t nCol\u0026gt; Mat\u0026lt;T, nCol, nRow\u0026gt; transpose(Mat\u0026lt;T, nRow, nCol\u0026gt; const \u0026amp; mat){ Mat\u0026lt;T, nCol, nRow\u0026gt; ret; for(size_t i=0 ; i\u0026lt;nRow ; i++){ ret.setColVec(i, mat[i]); } return ret; } 矩阵转置很简单，将原来的行向量设置给新的列向量即可。\ntemplate\u0026lt;class T, size_t dim\u0026gt; Mat\u0026lt;T, dim-1, dim-1\u0026gt; getMinor(Mat\u0026lt;T, dim, dim\u0026gt; const \u0026amp; mat, size_t x, size_t y){ assert(dim\u0026gt;0); Mat\u0026lt;T, dim-1, dim-1\u0026gt; ret; for(size_t i=0;i\u0026lt;dim-1;i++){ for(size_t j=0;j\u0026lt;dim-1;j++){ ret[i][j] = mat[i\u0026lt;x?i:i+1][j\u0026lt;y?j:j+1]; } } return ret; } 这是在计算一个矩阵，去除某个元素的所在行和所在列得到的子矩阵。\ntemplate\u0026lt;class T, size_t dim\u0026gt; T det(Mat\u0026lt;T, dim, dim\u0026gt; const \u0026amp; mat){ assert(dim\u0026gt;0); T ret = T(); for(size_t i=0;i\u0026lt;dim;i++){ ret += cofactor(mat, 0, i) * mat[0][i]; } return ret; } template\u0026lt;class T\u0026gt; T det(Mat\u0026lt;T,2,2\u0026gt; const \u0026amp; mat){ return mat[0][0]*mat[1][1] - mat[0][1]*mat[1][0]; } template\u0026lt;class T\u0026gt; T det(Mat\u0026lt;T,1,1\u0026gt; const \u0026amp; mat){ return mat[0][0]; } template\u0026lt;class T\u0026gt; T det(Mat\u0026lt;T,0,0\u0026gt; const \u0026amp; mat){ return static_cast\u0026lt;T\u0026gt;(0); } template\u0026lt;class T, size_t dim\u0026gt; T cofactor(Mat\u0026lt;T, dim, dim\u0026gt; const \u0026amp; mat, size_t x, size_t y){ return det(getMinor(mat,x,y)) * static_cast\u0026lt;T\u0026gt;((x+y)%2?-1:1); } 这是计算行列式与代数余子式的代码。\n计算大于2阶的行列式，需要用到代数余子式的方法，可以参考线性代数笔记。\n值得注意的是，det中我们每次计算都会减少dim一阶，但是你并不能使用if(dim==2);if(dim==1);if(dim\u0026lt;=0)这样的语句来在模板内部定义特例，这是无法编译通过的。你需要做的是将模板特殊化，这样才能通过编译。\ntemplate\u0026lt;class T, size_t dim\u0026gt; Mat\u0026lt;T,dim,dim\u0026gt; adjugate(Mat\u0026lt;T, dim, dim\u0026gt; const \u0026amp; mat){ Mat\u0026lt;T, dim, dim\u0026gt; ret; for(size_t i=0;i\u0026lt;dim;i++){ for(size_t j=0;j\u0026lt;dim;j++){ ret[j][i] = cofactor(mat,i,j); } } return ret; } template\u0026lt;class T, size_t dim\u0026gt; Mat\u0026lt;T,dim,dim\u0026gt; inverse(Mat\u0026lt;T, dim, dim\u0026gt; const \u0026amp; mat){ Mat\u0026lt;T, dim, dim\u0026gt; ret; ret = adjugate(mat)/det(mat); return ret; } 这是计算伴随矩阵和逆矩阵的代码，有一点值得注意，就是伴随矩阵的下标相当于进行了转置。\ntypedef Vec\u0026lt;float,2\u0026gt; vec2f; typedef Vec\u0026lt;float,3\u0026gt; vec3f; typedef Vec\u0026lt;float,4\u0026gt; vec4f; typedef Vec\u0026lt;int,2\u0026gt; vec2i; typedef Vec\u0026lt;int,3\u0026gt; vec3i; typedef Vec\u0026lt;int,4\u0026gt; vec4i; typedef Vec\u0026lt;int,4\u0026gt; OARColor; typedef Mat\u0026lt;float, 4, 4\u0026gt; mat4f; typedef Mat\u0026lt;int, 4, 4\u0026gt; mat3f; 最后声明一下变量的别名方便使用。\n另外这些全部都是在geo命名空间中，方便辨别。\n着重讲一下为什么我们的颜色信息（OARColor）被设置成4维的int向量。\n相信大家都听过RGB颜色，在这上面多加一维透明度，就是RGBA，基本上可以达到我们所有想要的效果了。而RGBA四个属性的取值范围分别都是\\([0,255]\\)的整数，所以用四维int向量就理所当然了。\n你可能会问为什么不拆成黑白、RGB、RGBA三种颜色。确实，这可能会更省内存，但是现在电脑内存一点也不稀缺，并且我们的微型渲染器很难有多大开销，统一处理可能更简单一些。\n完整的代码在这里\ngeometry.cpp 这个文件里大部分都是涉及向量类型转换的。唯一需要注意的是四舍五入。以三维为例\ntemplate\u0026lt;\u0026gt; template\u0026lt;\u0026gt; geo::Vec\u0026lt;int,3\u0026gt;::Vec(geo::Vec\u0026lt;float, 2\u0026gt; const \u0026amp; v, float const z_){ x = static_cast\u0026lt;int\u0026gt;(v.x + 0.5f); y = static_cast\u0026lt;int\u0026gt;(v.y + 0.5f); z = static_cast\u0026lt;int\u0026gt;(z_ + 0.5f); } 这段代码将二维的float向量转为三维的int向量，+0.5f即是四舍五入。\n然后就是转化为RGBA颜色格式，为了简单起见，我们假设所有的颜色都用RGBA表示，所以我们需要将RGB和灰度图像转化为RGBA，然后在写入图像时再具体分析写入什么颜色数据。举例将float的RGB和int的灰度转换为RGBA：\n（注：RGBA其实每一个颜色的权重也可以表示为\\([0,1]\\)之间的实数（这样在处理光照的时候容易些），但我们的图像写出去的是离散的值，所以要将\\([0,1]\\)映射到\\([0,255]\\)上的实数。注意四舍五入）\ngeo::Vec\u0026lt;int,4\u0026gt; geo::toOARColor(geo::Vec\u0026lt;float,3\u0026gt; const \u0026amp; v){ OARColor ret; for(int i=0;i\u0026lt;3;i++){ ret[i] = static_cast\u0026lt;int\u0026gt;(v[i]*255.f+0.5f); if (ret[i]\u0026lt;0) ret[i] = 0; else if(ret[i]\u0026gt;255) ret[i] = 255; } ret[3] = 255; return ret; } geo::Vec\u0026lt;int,4\u0026gt; geo::toOARColor(int const \u0026amp; v){ OARColor ret; for(int i=0;i\u0026lt;3;i++){ if(v\u0026lt;0) ret[i] = 0; else if(v\u0026gt;255) ret[i] = 255; else ret[i] = v; } ret[3] = 255; return ret; } 其将连续的[0,1]映射到离散的[0,255]（或者本来就是离散的），并且超出的部分映射到边界上，同时也计算了四舍五入。\n完整的代码在这里\n","date":"2022-10-28T15:34:04+08:00","image":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E6%95%B0%E5%AD%A6%E5%B7%A5%E5%85%B7%E5%BA%93/cover_huc0107afa81d973e7d87fe5de99d27181_24753_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E6%95%B0%E5%AD%A6%E5%B7%A5%E5%85%B7%E5%BA%93/","title":"从零开始的软渲染器 数学工具库"},{"content":"目录 1. 从零开始的软渲染器-数学工具库\n2. 从零开始的软渲染器-图片处理库\n3. 从零开始的软渲染器-线段和三角形的光栅化\n4. 从零开始的软渲染器-模型库\n5. 从零开始的软渲染器-光照初步\nTODO:\n6. 从零开始的软渲染器-坐标变换与视角\n番外1. 从零开始的软渲染器-YAML记录参数\n7. 从零开始的软渲染器-Z-Buffer\n8. 从零开始的软渲染器-图形渲染管线\n9. 从零开始的软渲染器-纹理贴图\n10. 从零开始的软渲染器-阴影贴图\n11. 从零开始的软渲染器-更真实的光照\n12. 从零开始的软渲染器-光线追踪初步\nTODO: 改成导航与前言，前言部分介绍这个项目的目的，以及主要参考了什么资料（例如Fundamentals of Computer Graphics、tiny renderer，learnopengl）\n","date":"2022-10-28T15:33:42+08:00","image":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E5%AF%BC%E8%88%AA/cover_huef498dd5cf38693b5a441291f5d52b83_173498_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E5%AF%BC%E8%88%AA/","title":"从零开始的软渲染器 导航"},{"content":"基础知识 多项式求值 对于形如下式的多项式\n\\[P(x)=2x^4+3x^3-3x^2+5x-1 \\]\n如果我们普通地代入计算，则会需要计算10次乘法，以及4次加法。这显然不是最优的，更优的方法例如秦九韶算法，将多项式重写为\n\\[P(x)=-1+x*(5+x*(-3+x*(3+x*2))) \\]\n此时再代入值计算，则只用4次乘法和4次加法。一般来说\\(d\\)阶多项式可以通过\\(d\\)次乘法和\\(d\\)次加法求值。\n标准形式的多项式\n\\[P(x) = c_1+c_2x+c_3x^2+c_4x^3+c_5x^4 \\]\n可以写成\n\\[P(x)=c_1+x(c_2+x(c_3+x(c_4+x(c_5)))) \\]\n或者也有更一般的形式，可以用于之后的插值计算\n\\[P(x)=c_1+(x-r_1)(c_2+(x-r_2)(c_3+(x-r_3)(c_4+(x-r_4)(c_5)))) \\]\n其中称\\(r1,r2,r3,r4\\)为基点。\n二进制数字 二进制数字可以表示为：\n\\[\\cdots b_2b_1b_0b_{-1}b_{-2}\\cdots \\]\n其等价于十进制下的\n\\[\\cdots b_22^2+b_12^1+b_02^0+b_{-1}2^{-1}+b_{-2}2^{-2}\\cdots \\]\n十进制转化为二进制 例如\\(53.7\\)转化为二进制，可以拆分为整数部分和小数部分，分别转化，然后在拼接起来。\n整数部分\n将整数连续除以\\(2\\)，记录余数，直到整数最后变为\\(0\\)，余数反过来排列在一起就是二进制表示。例如\n\\[53\\div 2 = 26\\cdots1 \\]\n\\[26\\div 2 = 13\\cdots0 \\]\n\\[13\\div 2 = 6\\cdots1 \\]\n\\[6\\div 2 = 3\\cdots0 \\]\n\\[3\\div 2 = 1\\cdots1 \\]\n\\[1\\div 2 = 0\\cdots1 \\]\n那么二进制表示就是\\(110101\\)\n小数部分\n将小数部分不断乘以\\(2\\)，得到的结果保留整数部分，直到小数部分为\\(0\\)，整数部分顺序排列即为小数部分的二进制表示\n例如\n\\[0.7*2 = 0.4+1 \\]\n\\[0.4*2 = 0.8+0 \\]\n\\[0.8*2 = 0.6+1 \\]\n\\[0.6*2 = 0.2+1 \\]\n\\[0.2*2 = 0.4+0 \\]\n\\[0.4*2 = 0.8+0 \\]\n\\[\\vdots \\]\n后面重复，代表在二进制中是无限循环小数。有\\((0.7)_{10}=(0.1\\overline{0110})_2\\)\n最后有\\((53.7)_{10} = (110101.1\\overline{0110})_2\\)。\n二进制转化为十进制 开头已经介绍过一般情况，对于有限小数是容易计算的。\n无限小数时，例如\\(x=(0.\\overline{1011})_2\\)，先左移\\(4\\)位，再减去原始的\\(x\\)，有\n\\[2^4x = 1011.\\overline{1011}\\\\ x=0000.\\overline{1011} \\]\n相减得\n\\[(2^4-1)x = (1101)_2 = (11)_{10} \\]\n求解\\(x\\)可得，\\(x=(0.\\overline{1011})_2=11/15\\)。\n实数的浮点表示 本节按照IEEE754标准。\n浮点格式 一个浮点数字包含三个部分：符号（正负）、尾数（包含一串有效数位）和一个指数，这些部分都在一个计算机字(WORD)里。\n浮点数常用三种精度级别：单精度、双精度、扩展精度。它们分配的数位分别是32、64、80。具体如下\n精度 符号 指数 尾数 单精度 1 8 23 双精度 1 11 52 扩展精度 1 15 64 三种精度以相同的方式运行。标准化的IEEE浮点数表示为\n\\[\\pm 1.bbb\\cdots b\\times 2^p \\]\n其中\\(N\\)个\\(b\\)或0或1，\\(p\\)是一个\\(M\\)位的二进制数表示指数。最左边的一位（主导数位）必须是\\(1\\)。\n当一个二进制数用一个标准浮点数字表示的时候，它被称为“左对齐”，意味着其中最左边的一个数位\\(1\\)被平移到小数点的左边，平移通过指数的变化来补偿，例如，十进制数\\(9\\)，对应的二进制数\\(1001\\)保存为\n\\[+1.001\\times 2^3 \\]\n以双精度（\\(M=11,N=52\\)）为例，1的双精度表示为\n\\[+1.0000000000000000000000000000000000000000000000000000\\times 2^0 \\]\n其中有52位尾数，下一个比\\(1\\)大的浮点数是\n\\[+1.0000000000000000000000000000000000000000000000000001\\times 2^0 \\]\n或者说是\\(1+2^{-52}\\)\n定义1\n机器精度对应的数字，记作\\(\\varepsilon_{math}\\)，是\\(1\\)和比\\(1\\)大的最小浮点数之间的距离。对于双精度来说就是\\(2^{-52}\\)\n如果一个小数是无限小数，或者是超过了52位的小数，IEEE规定，如果在第53位为0，则52位以后的全部社区，如果53位为1，则在52位上加1。特别的，如果第53位为1，其后所有已知位为0，那么当且仅当52位是1时在52位上加1。\n上述方法称为IEEE舍入最近法则。\n定义2\n将IEEE双精度浮点数字记做\\(x\\)，利用舍入最近法则记做\\(fl(x)\\)\n在计算机算术中，实数\\(x\\)用一串数位\\(fl(x)\\)替换。根据这个定义，\\(9.4\\)在二进制中表示如下\n\\[+1.0010110011001100110011001100110011001100110011001100|110\\cdots\\times 2^3 \\]\n则\\(fl(9.4)\\)表示为\n\\[+1.0010110011001100110011001100110011001100110011001101\\cdots\\times 2^3 \\]\n我们通过去掉最右边无穷长的数字尾巴\\(0.\\overline{1100}\\times 2^{-52}\\times 2^3=\\overline{0.0110}\\times 2^{-51}\\times 2^3=0.4\\times 2^{-48}\\)得到浮点表达。并在舍入过程中加上\\(2^{-52}\\times 2^3=2^{-49}\\)。因而\n\\[fl(9.4) = 9.4+2^{-49}-0.4\\times 2^{-48}\\\\ =9.4+(1-0.8)2^{-49}\\\\ =9.4+0.2\\times 2^{-49} \\]\n换句话说，将\\(9.4\\)保存为双精度浮点数时可能产生了\\(0.2\\times 2^{-49}\\)的误差，我们把它称作舍入误差。\n定义3\n令\\(x_c\\)是计算版本\\(x\\)的精确度量，则\n\\[绝对误差=|x_c-x| \\]\n\\[相对误差=\\frac{|x_c-x|}{|x|}(x\\neq 0) \\]\n相对舍入误差\n在IEEE机器算术模型中，\\(fl(x)\\)的相对舍入误差不会比机器精度的一半大：\n\\[\\frac{|fl(x)-x|}{|x|}\\leq \\frac{1}{2}\\varepsilon_{math} \\]\n浮点数的机器表示 每个双精度浮点数字被分配了8字节，或者说64位，来存储对应的三个部分。每个字都有如下形式\n\\[se_1e_2\\cdots e_{11}b_1b_2\\cdots b_{52} \\]\n其中第1位保存了符号位，后面11位用于保存指数，再后面小数点后的52位保存尾数。符号位0是正数，1是负数。11位指数表示的正二进制整数，这些正数通过往指数上叠加\\(2^10-1=1023\\)得到，指数范围在\\(-1022\\)和\\(1023\\)之间，\\(e_1\\cdots e_{11}\\)覆盖了从\\(1\\)到\\(2046\\)之间对应的指数，由于特殊目的，没有使用\\(0\\)和\\(2047\\)。\n数字\\(1023\\)称为双精度格式的指数偏差。它被用于把正和负指数转化为正的二进制数保存在指数位中，对于单精度和扩展精度，指数偏差位分别是127和16383.\n也就是说，指数位上的数字，减去1023才是浮点数中所应该是的指数。\n再来看特殊值\\(2047\\)。如果尾数位串都是0，则用于表示\\(\\infty\\)（其符号取决于第一位），否则表示\\(NaN\\)，意为不是一个数字。\n例如\\(1/0\\)是\\(+\\inf\\)，前\\(12\\)位用十六进制表示为7FF，后面全是0.\n\\(-1/0\\)是\\(-\\inf\\)，前\\(12\\)位用十六进制表示为FFF，后面全是0.\n\\(0/0\\)是\\(NaN\\)，前\\(12\\)位用十六进制表示为FFF，后面不全是0.\n再来看特殊值\\(0\\)，意味着\\(e_1e_2\\cdots e_{11}=(000 0000 0000)_2\\)。其表示一个非标准浮点数\n\\[\\pm 0.b_1b_2\\cdots b_{52}\\times 2^{-1022} \\]\n由上可见，第一位不再假设为1.这样的非标准化数字称作异常浮点数字。这样就扩展了数字的表示范围，因而，最小的可表达的双精度数字是\\(2^{-52}\\times 2^{-1022}\\)。\n另外\\(+0,-0\\)也是一个异常数字。计算中它们被看作是相同的两个实数。\n浮点数加法 首先对齐进行加法的两个数字的小数点位，接着相加，然后把结果保存为浮点数字。\n在加法寄存器中，可以进行超过52位的加法，但是在相加之后必须舍入变回52位。\n有效数字缺失 有一个主要问题以多种形式出现，该问题是由于对近似相等的两个数字相减造成有效数字的位数减少。\n例如\\(123.4567-123.4566=0.0001\\)，有效数字从原来的七位减少到一位。\n很多情况下我们可以通过重新构造计算来解决这个问题。\n例1\n在三位小数的计算机上计算\\(\\sqrt{9.01}-3\\)\n正确的结果接近\\(1.6662\\times 10^{-3}\\)，但当我们使用三位有效数字时，由于\\(\\sqrt{9.01}\\approx 3.0016662\\)，保存三位有效数字时得到\\(3.00\\)。再减去\\(3.00\\)，得到\\(0.00\\)，没有一个有效数位是正确的。\n但是我们可以用以下方法挽救\n\\[\\sqrt{9.01}-3 = \\frac{(\\sqrt{9.01}-3)(\\sqrt{9.01}+3)}{\\sqrt{9.01}+3}=\\frac{9.01-9}{\\sqrt{9.01}+3} \\]\n\\[=\\frac{0.01}{3.00+3.00}=\\frac{0.01}{6}=0.00167\\approx 1.67\\times 10^{-3} \\]\n这种方法本质上是一个窍门。称作“共轭等式”。通常会使用一些特定的恒等式，例如三角恒等式。\n例如\n\\[E_1=\\frac{1-cosx}{sin^2x},E_2=\\frac{1}{1+cosx} \\]\n两个式子虽然等价，但是在数值计算上，输入一个较为靠近0的数，则第二个比第一个精度高。\n例2\n解方程\\(ax^2+bx+c=0\\)\n对于最基础的求根公式\n\\[x=\\frac{-b\\pm \\sqrt{b^2-4ac}}{2a} \\]\n其中间取负号问题可能不大，但是取正号时，如果\\(ac\\)相对于\\(b^2\\)非常小，则分式上面会直接舍入等于0，造成整个结果等于0.\n为了解决这个问题，可以在\\(b\\)是正数时\n\\[x_1=-\\frac{b+\\sqrt{b^2-4ac}}{2a},x_1=-\\frac{2c}{b+\\sqrt{b^2-4ac}} \\]\n\\(b\\)是负数时\n\\[x_1=\\frac{-b+\\sqrt{b^2-4ac}}{2a},x_1=\\frac{2c}{-b+\\sqrt{b^2-4ac}} \\]\n微积分回顾 书中回顾了函数的连续性、罗尔定理、拉格朗日中值定理、泰勒展开、积分中值定理等。\n求解方程 二分法 方法 定义1\n如果\\(f(r)=0\\)，函数\\(f(x)\\)在\\(x=r\\)时有一个根。\n定理1\n根据函数的连续性，我们知道，如果一个函数是连续的（在[a,b]上），并且在\\(a\u003c b\\)时有\\(f(a)f(b)\u003c0\\)，那么函数在\\((a,b)\\)之间至少有一个根\\(r\\)使得\\(f(r)=0\\)\n显然，我们可以判断\\(c=(b+a)/2\\)时\\(f(a)f(c)\\)的符号来判断根具体在\\([a,c]\\)还是\\([c,b]\\)之中\n由此我们就可以得到一个求出根的伪代码\n二分法 给定初始区间[a,b]使得f(a)f(b)\u0026lt;0 while (b-a)/2\u0026gt;TOL c = (a+b)/2 if f(c)=0,stop,end if f(a)f(c)\u0026lt;0 b = c else a = c end end 最终的区间[a,b]中包含一个根 近似根为(a+b)/2 显然我们求出的是一个区间\\([a,b]\\)，有一个根在其中，我们只能估计一个值。另外代码中的TOL指的是精度，即这个根在\\((a+b)/2\\pm TOL\\)这个范围内。\n分析 现在来分析二分法的精确度和收敛速度。\n假设\\([a,b]\\)是初始区间，在\\(n\\)次二分之后，得到的最终区间\\([a_n,b_n]\\)的长度为\\((b-a)/2^n\\)。选择中点\\(x_c=(a_n+b_n)/2\\)为解的最优估计值，与真实值的误差不会超过区间长度的一般。总之，n步二分法之后，我们得到\n\\[求解误差=|x_c-r|\u003c\\frac{b-a}{2^{n+1}} \\]\n\\[函数计算次数=n+2 \\]\n对于其精度，每一次函数计算后，解的不确定性都会减少一半。\n定义2\n如果误差小于\\(0.5\\times 10^{-p}\\)，解精确到小数点后\\(p\\)位。\n不动点迭代 举一个例子，以弧度制计算\\(\\cos\\)。以任意值代入，比如我们代入\\(1\\).有\\(cos1=0.5403\\cdots\\)，再将结果代入，有\\(cos(cos1)=0.85755\\cdots\\)，以此类推，多次代入后，我们发现无论初始值是多少，最后都会收敛到\\(0.7390851332\\cdots\\)\n函数的不动点 定义1\n当\\(g(r)=r\\)，实数\\(r\\)是函数\\(g\\)的不动点。\n例如，我们求解\\(\\cos x-x=0\\)的方程，用不动点的视角来看，就是求解\\(\\cos x=x\\)，或者说求解\\(\\cos x\\)的不动点。\n一旦方程写做\\(g(x)=x\\)，从一个初始估计\\(x_0\\)开始进行不动点迭代过程，对函数\\(g\\)进行迭代，\n\\[x_1=g(x_0)\\\\ x_2=g(x_1)\\\\ x_3=g(x_2)\\\\ \\vdots \\]\n依此下去。当进行无穷多步迭代后序列\\(x_i\\)可能收敛，也可能不收敛。但是，如果函数\\(g\\)是一个连续函数并且\\(x_i\\)收敛，收敛到一个数字\\(r\\)，那么\\(r\\)就是对应的不动点。意味着\n\\[g(r) = g(\\lim_{i\\to\\infty}x_i)=\\lim_{i\\to\\infty}g(x_i) = \\lim_{i\\to\\infty}x_{i+1}=r \\]\n所有方程\\(f(x)=0\\)都能转化为\\(g(x)=x\\)来不动点迭代吗？答案是肯定的。\n虽然都能迭代，但不总是能收敛的。\n例如\\(x^3+x-1=0\\)换成\\(x=1-x^3\\)来迭代，最后结果就会在\\(1,0\\)之间摆动，这是因为\\(g(0)=1,g(1)=0\\)。\n但是，如果使用\\(x=\\sqrt[3]{1-x}\\)来迭代，就可以求出正确的不动点\\(x=0.6823\\cdots\\)。迭代了大概25次。\n如果使用\\(x=(1+2x^3)/(1+3x^2)\\)，也可以收敛，并且只需要迭代4次就可以得到\\(x=0.6823\\cdots\\)。\n不动点迭代几何 我们要解释出现上述差异的原因。\n如下图，将\\(g(x),x\\)画在同一坐标系下，其中交点就是不动点，图中的箭头代表迭代过程。这种表示又被称作cobweb图。\n1.jpg\r图\\(a\\)中迭代逐渐远离了不动点，而\\(b,c\\)两图，迭代都在不断靠近不动点。\n由图我们猜测迭代收敛与否和\\(g(x)\\)在不动点附近的斜率有关。\n不动点迭代的线性收敛 以\\(g_1(x)=-\\frac{3}{2}x+\\frac{5}{2},g_2(x)=-\\frac{1}{2}x+\\frac{3}{2}\\)为例。它们的不动点都是\\(x=1\\)。\n我们把\\(g(x)\\)写作\\(x-r\\)的形式，其中\\(r=1\\)：\n\\[g_1(x)=-\\frac{3}{2}(x-1)+1\\\\ g_1(x)-1=-\\frac{3}{2}(x-1)\\\\ x_{i+1}-1=-\\frac{3}{2}(x_i-1) \\]\n如果我们把\\(e_i=|r-x_i|\\)作为第\\(i\\)步时的误差，可以看到上式的误差是\\(e_{i+1}=3e_i/2\\)，意味着误差越来越大，也就是发散。\n对于\\(g_2(x)\\)有\n\\[x_{i+1}-1=-\\frac{1}{2}(x_i-1) \\]\n\\(e_{i+1}=e_i/2\\)，误差越来越小，就是收敛。\n定义2\n令\\(e_i\\)表示迭代过程中第\\(i\\)步时的误差，如果\n\\[\\lim_{i\\to\\infty}\\frac{e_{i+1}}{e_i}=S\u003c1 \\]\n该方法被称为满足线性收敛，收敛速度为\\(S\\)。\n这样的推理过程也可以适用于更加一般的连续可微函数\n定理1\n假设函数\\(g\\)是连续可微函数，\\(g(r)=r,S=|g'(r)|\u003c1\\)，则不动点迭代对于一个足够接近\\(r\\)的初始估计，以速度\\(S\\)线性收敛到不动点\\(r\\)。\n定义3\n如果迭代方法对于一个足够接近\\(r\\)的初值能收敛到\\(r\\)，该迭代方法称为局部收敛到\\(r\\)。\n终止条件 同二分法不同，FPI没有误差与迭代次数的关系公式，必须决定何时终止算法，这称为终止条件。\n对于一组容差\\(TOL\\)，我们可能使用绝对终止条件\n\\[|x_{i+1}-x_i| \u003c \\text{TOL} \\]\n当解不在\\(0\\)附件时可以使用相对误差条件\n\\[\\frac{|x_{i+1}-x_i|}{|x_{i+1}|} \u003c \\text{TOL} \\]\n还有混合绝对/相对误差终止条件\n\\[\\frac{|x_{i+1}-x_i|}{max(|x_{i+1}|,\\theta)} \u003c \\text{TOL} \\]\n其中\\(\\theta\u003e0\\)，常常用于\\(0\\)附近的解。此外，如果收敛失败，一个好的FPI也应该设置迭代次数上限。\n二分法可以保证线性收敛，不动点迭代仅仅是局部收敛。不动点迭代收敛时，是线性收敛。二分法每次可以去掉\\(1/2\\)的不确定性，而FPI的不确定性每次会乘上\\(S=|g'(r)|\\)，因此可能比二分法更快或更慢，依赖于\\(S\\)比\\(1/2\\)更大还是更小。\n精度的极限 前向与后向误差 定义1\n假设\\(f\\)是一个函数，\\(r\\)是一个根，意味着满足\\(f(r)=0\\)。假设\\(x_a\\)是\\(r\\)的近似值。对于根求解问题，近似\\(x_a\\)的后向误差是\\(|f(x_a)|\\)，前向误差是\\(|r-x_a|\\)。\n举个例子，求解以下函数的根\n\\[f(x) = x^3-2x^2+\\frac{4}{3}x-\\frac{8}{27} \\]\n我们可以通过手算验证\\(2/3\\)是它的根。\n当我们使用双精度浮点数去二分法求解时，最后可能解出\\(r=0.6666641\\)，并且到此结束，因为此时\\(f(r)=0\\)，意味着其等于机器\\(0\\)。在这\\(2/3\\pm 10^{-5}\\)的范围上，其函数值都等于机器\\(0\\)。\n事实上，\\(r\\)的后向误差接近\\(\\varepsilon_{math}=2.2\\times 10^{-16}\\)，而前向误差在大约\\(10^{-5}\\)。双精度不能在机器精度的相对误差下可靠计算，从而导致了一个范围内的数最终都等于机器\\(0\\)。\n事实上\\(2/3\\)是这个函数的三重根\n定义2\n假设\\(r\\)是可微函数\\(f\\)的根，如果\\(0=f(r)=f'(r)=f''(r)=\\cdots=f^{(m-1)}(r)\\)，但是\\(f^{(m)}(r)\\neq 0\\)，就说\\(f\\)在\\(r\\)点具有\\(m\\)重根。多于一个根的叫重根，只有一个根的叫单根。\n由于函数在多根附近十分平缓，前向和后向误差之间在近似解的附近存在很大的不一致。后向误差在垂直方向进行度量，通常比在水平方向度量的前向误差小得多。\n前向和后向误差的讨论和方程求解器的终止条件有关。我们有两种方法更加接近方程的根\n使得\\(|x_a-r|\\)足够小 使得\\(|f(x_a)|\\)足够小 具体选择使用哪一种，取决于问题所处的环境。对于二分法，两种误差都可以观察到。而FPI只能知道后向误差，而不可能知道前向误差。\n威尔金森多项式 一个难以进行数值求解的单根例子在威尔金森的论著中进行了讨论，威尔金森多项式是\n\\[W(x) = (x-1)(x-2)\\cdots(x-20) \\]\n但当我们把它展开，并用二分法等方法却很难求出正确的解，精确度甚至不到第二个小数。\n这主要是因为其展开式的每一项的常数太大，例如常数项是\\(2432902008176640000\\)，这导致在求值计算中会由于近似相等、大数字的消去而有损失。\n但是若不展开，代入求根器中却能算出精确根。当然如果已经分解好了，也就没有求解的必要了。\n根搜索的敏感性 威尔金森多项式和多重根的问题，其本质都是方程中小的求解误差造成求解根中的大误差。\n如果在输入中是一个小误差，在这种情况下对问题进行求解，造成输出中的大问题，这样的问题被称作敏感性问题。\n假设问题是找到\\(f(x)=0\\)的根\\(r\\)，但是对输入做了一个小变化\\(\\varepsilon g(x)\\)，其中\\(\\varepsilon\\)很小。令\\(\\Delta r\\)是对应根中的变化，因而\n\\[f(r+\\Delta r)+\\varepsilon g(r+\\Delta r)=0 \\]\n将\\(f\\)和\\(g\\)一阶泰勒展开，有\n\\[f(r)+(\\Delta r)f'(r)+\\varepsilon g(r)+\\varepsilon(\\Delta r)g'(r)+O((\\Delta r)^2) \\]\n对于小的\\(\\Delta r\\)，直接忽略掉\\(O((\\Delta r)^2)\\)，有\n\\[(\\Delta r)(f'(r)+\\varepsilon g'(r))\\approx-f(r)-\\varepsilon g(r)=-\\varepsilon g(r) \\]\n假设和\\(f'(r)\\)相比，\\(\\varepsilon\\)很小，则又有\n\\[\\Delta r\\approx\\frac{-\\varepsilon g(r)}{f'(r)+\\varepsilon g'(r)}\\approx -\\varepsilon\\frac{g(r)}{f'(r)} \\]\n上式就叫做根的敏感公式。（假设\\(r\\)是\\(f(x)\\)的根，并且\\(r+\\Delta r\\)是\\(f(x)+\\varepsilon g(x)\\)的根，则当\\(\\varepsilon \u003c\u003c f'(r)\\)时有上式）\n对于一个一般算法生成的近似\\(x_c\\)，我们定义\n\\[误差放大因子=\\frac{相对前向误差}{相对后向误差} \\]\n条件\n条件数也是误差放大度量的一种方式。数值分析是对算法的研究，算法把定义问题的数据作为输入，对应的结果作为输出。条件数指的是理论问题本身所带来的的误差放大部分，和用于求解问题的特定算法无关。\n问题的条件数定义为所有输入变化，或者至少规定类型的变化所造成的最大误差放大。\n条件数高的问题称为病态问题，条件数在\\(1\\)附件的问题称为良态问题。\n牛顿方法 为了找到\\(f(x)=0\\)的根，给定一个初始估计\\(x_0\\)，画出函数\\(f\\)在\\(x_0\\)的切线。用切线来近似函数\\(f\\)，求出其与\\(x\\)轴的交点作为\\(f\\)的根。由于函数\\(f\\)的弯曲，该交点可能不是精确解，因而该步骤要迭代进行。\n\\[x_0=初始估计 \\]\n\\[x_{i+1}=x_i-\\frac{f(x_i)}{f'(x_i)},\\quad i=0,1,2,\\cdots \\]\n牛顿方法的二次收敛 定义1\n令\\(e_i\\)表示一个迭代方法第\\(i\\)步后得到的误差。该迭代是二次收敛，如果满足下式\n\\[M=\\lim_{i\\to\\infty}\\frac{e_{i+1}}{e^2_i}\u003c\\infty \\]\n定理1\n令\\(f\\)是二阶连续可微函数，\\(f(r)=0\\)。如果\\(f'(r)\\neq 0\\)，则牛顿方法局部二次收敛到\\(r\\)。第\\(i\\)步的误差\\(e_i\\)满足\n\\[\\lim_{i\\to\\infty}\\frac{e_i}{e_i^2}=M \\]\n其中\n\\[M=\\frac{f''(r)}{2f'(r)} \\]\n也可被看作\n\\[e_{i+1}\\approx M e_i^2 \\]\n对于线性收敛方法，这个误差公式应该和\\(e_{i+1}\\approx Se_i\\)进行比较，FPI方法中\\(S=|g'(r)|\\)，二分法中\\(S=1/2\\)\n尽管\\(S\\)对线性收敛很关键，但是\\(M\\)的值并不是很重要，这是由于其包含了平方，只要\\(M\\)不太大，误差就会进一步下降。\n牛顿方法的线性收敛 上面的定理并不意味着牛顿方法总能二次收敛。\n例如求\\(f(x)=x^2\\)的实根，牛顿法如下\n\\[x_{i+1}=x_i-\\frac{f(x_i)}{f'(x_i)}=\\frac{x_i}{2} \\]\n仅仅每步除以\\(2\\).对于其他幂函数也有类似的结果。\n定理1\n假设在区间\\([a,b]\\)上，\\((m+1)\\)阶连续可微函数\\(f\\)在\\(r\\)点有一个\\(m\\)阶多重根，则牛顿方法局部收敛到\\(r\\)，第\\(i\\)步误差\\(e_i\\)满足\n\\[\\lim_{i\\to \\infty}\\frac{e_{i+1}}{e_i}=S \\]\n其中\\(S=(m-1)/m\\)\n事实上，牛顿法在单根位置上，\\(f'(r)\\neq 0\\)，具有二次收敛速度，在多根位置上\\(f'(r)=0\\)，收敛式线性的。\n定理2\n如果在\\([a,b]\\)区间上\\(f\\)是\\((m+1)\\)阶连续函数，包含\\(m\u003e1\\)的多重根，则改进的牛顿方法\n\\[x_{i+1}=x_i-\\frac{mf(x_i)}{f'(x_i)} \\]\n收敛到\\(r\\)，并具有二次收敛速度。\n牛顿法如同FPI，也可能不会收敛到根。例如两个数循环出现、某一步\\(f'(x_i)=0\\)等。\n不需要导数的根求解 虽然牛顿法在非重根时表现的比二分法和FPI更好，因为它获取了“导数”这个额外信息。但有时候我们可能难以计算导数。\n这种情况下，割线方法就是一个好的替代。它使用近似值割线替代了切线，并且收敛速度差不多快。\n割线方法及其变体 不难想到，直接用差商\n\\[\\frac{f(x_i)-f(x_{i-1})}{x_i-x_{i-1}} \\]\n去近似替换牛顿法中的\\(f'(x_i)\\)，就得到了割线方法\n\\[x_0,x_1=初始估计 \\]\n\\[x_{i+1}=x_i-\\frac{f(x_i)(x_i-x_{i-1})}{f(x_i)-f(x_{i-1})},i=1,2,3,\\cdots \\]\n假设割线方法收敛到函数\\(f\\)的根\\(r\\)，且\\(f'(r)\\neq 0\\)，近似误差关系\n\\[e_{i+1}\\approx \\bigg|\\frac{f''(r)}{2f'(r)}\\bigg|e_ie_{i-1} \\]\n成立并且\n\\[e_{i+1}\\approx \\bigg|\\frac{f''(r)}{2f'(r)}\\bigg|^{\\alpha-1}e_i^\\alpha \\]\n其中\\(\\alpha = (1+\\sqrt 5)/2\\approx 1.62\\)。割线方法以超线性的速度收敛到一个单根，意味着它在线性和二次收敛方法之间。\n割线方法有三种推广形式，它们也很重要。\n试位方法（Regula Falsi）\n和二分法相似，但是其中的中点被类似割线方法的近似所替换，给定区间\\([a,b]\\)，该区间包含根（假设\\(f(a)f(b)\u003c0\\)），使用割线方法定义下一个点为\n\\[c = a-\\frac{f(a)(a-b)}{f(a)-f(b)}=\\frac{bf(a)-af(b)}{f(a)-f(b)} \\]\n根据\\(f(a)f(c)\u003c0\\)或者\\(f(c)f(b)\u003c0\\)，分别选择新的区间\\([a,c]\\)或\\([c,b]\\)，新的区间仍然可以括住根。\n通常试位方法会表现地比二分法和割线方法都好，但是试位方法不能包子每一步都消除一半的不确定性，有时收敛会很慢。\nMuller方法\n该方法不是计算经过先前两个点的直线和\\(x\\)轴的交点，而是使用桑耳前面生成的点\\(x_0,x_1,x_2\\)，画出通过它们的抛物线\\(y=p(x)\\)，并计算抛物线和\\(x\\)轴的交点。\n书上并没有详细介绍这个方法。\n逆二次插值（IQI）\n是割线方法到抛物线的一种相近的泛化方法。但是使用形如\\(x=p(y)\\)的抛物线，而不是Muller方法中的\\(y=p(x)\\)。\n我们的问题可以立刻求解：这个抛物线和\\(x\\)轴只有一个交点，所以从上一步中的三个估计\\(x_i,x_{i+1},x_{i+2}\\)寻找\\(x_{i+3}\\)，这个过程中没有混淆。\n经过三点\\((a,A),(b,B),(c,C)\\)的二阶多项式\\(x=P(y)\\)为\n\\[P(y) = a\\frac{(y-B)(y-C)}{(A-B)(A-C)}+b\\frac{(y-A)(y-C)}{(B-A)(B-C)}+c\\frac{(y-A)(y-B)}{(C-A)(C-B)} \\]\n这是一个拉格朗日插值的例子，用\\(y=0\\)代入，得到和\\(x\\)轴的交点，经过重新组合与替代，我们得到\n\\[P(0)=c-\\frac{r(r-q)(c-b)+(1-r)s(c-a)}{(q-1)(r-1)(s-1)} \\]\n其中\\(q=f(a)/f(b),r=f(c)/f(b),s=f(c)/f(a)\\)\n对于IQI，设置\n\\[a=x_i,b=x_{i+1},c=x_{i+2},A=f(x_i),B=f(x_{i+1}),C=f(x_{i+2}) \\]\n下一步的估计\\(x_{i+3}=P(0)\\)为\n\\[x_{i+3}=x_{i+2}-\\frac{r(r-q)(x_{i+2}-x_{i+1})+(1-r)s(x_{i+2}-x_{i})}{(q-1)(r-1)(s-1)} \\]\n其中\\(q=f(x_{i})/f(x_{i+1}),r=f(x_{i+2})/f(x_{i+1}),s=f(x_{i+2})/f(x_{i})\\)\nBrent方法 这是一种混合方法，该方法使用前面介绍的迭代技术，推出一个新的方法。\n该方法用于连续函数\\(f\\)，区间的边界是\\(a\\)和\\(b\\)，同时\\(f(a)f(b)\u003c0\\)。Brent方法记录当前点\\(x_i\\)，该点具有最优的后向误差，同时有包含根的区间\\([a_i,b_i]\\)。简单来讲，尝试使用逆二次方法，并在下述情况下，使用结果来替代\\(x_i,a_i,b_i\\)中的一个\n后向误差得到改进 包含根的区间至少减小一半 否则，尝试使用割线方法以实现相同的目的，如果割线方法也失败了，则使用二分法，保证至少减少一半的不确定性。\n方程组 高斯消元法 朴素的高斯消元法 和线性代数中介绍的一致\n对于一个线性方程组可以进行三种操作\n两个方程彼此交换位置 在一个方程上加上或减去另外一个方程的倍数 对于一个方程乘以非零的常数 通常我们也会使用增广矩阵来替代方程组。\n操作次数 引理1\n对于任何正整数\\(n\\)\n\\(1+2+3+\\cdots+n = n*(n+1)/2\\) \\(1^2+2^2+\\cdots+n^2 = n(n+1)(2n+1)/6\\) 消去某一列在主对角线下的元素，以第一列为例，将第二行变为如下形式\n\\[\\begin{matrix} a_{11} \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n} \u0026 | \u0026 b_1\\\\ 0 \u0026 a_{22}-\\frac{a_{21}}{a_{11}}a_{12} \u0026 \\cdots \u0026 a_{2n}-\\frac{a_{21}}{a_{11}}a_{1n} \u0026 | \u0026b_2-\\frac{a_{21}}{a_{11}}b_1 \\end{matrix} \\]\n其他行同理，其中\\(a_{11}\\)在操作中作为除数，这样的数字称为主元。不难得知，如果主元为\\(0\\)，算法会终止，这是朴素办法的一个问题。\n高斯消元法中消去步骤的操作次数\n\\(n\\)个方程\\(n\\)个未知数的消去计算（下三角除了对角线的部分转换为\\(0\\)），可以在\\(2n^3/3+n^2/2-7n/6\\)次操作后完成\n消去之后，矩阵变成上三角形式，之后从最后一个未知数往回带进行求解。\n高斯消元法中回代过程的操作次数\n\\(n\\)个方程\\(n\\)个未知数的三角形系统的回代过程，可以在\\(n^2\\)次操作后完成\n综上，消去的事件复杂度为\\(O(n^3)\\)，回代是\\(O(n^2)\\)，总的是\\(O(n^3)\\)\nLU分解 高斯消元法的矩阵形式 继续同线性代数，我们可以把方程组写成一个矩阵和一个向量相乘的形式，即\\(\\bm A\\bm x=\\bm b\\)\n吧方程组写成矩阵的形式的优势在于可以使用矩阵运算。LU分解是高斯消元法的矩阵形式。它包含把系数矩阵\\(A\\)写做下三角矩阵\\(L\\)和上三角矩阵\\(U\\)的乘积\n我们有关于LU分解的三个事实\n令\\(L_{ij}(-c)\\)表示下三角矩阵，其主对角线上的元素为\\(1\\)，在\\((i,j)\\)位置上的元素为\\(-c\\)。则\\(A\\to L_{ij}(-c)A\\)表示行运算“从第\\(i\\)行中减去第\\(j\\)行的\\(c\\)倍”。 例如\\(L_{21}(-c)\\)\n\\[A= \\begin{bmatrix} a_{11} \u0026 a_{12} \u0026 a_{13}\\\\ a_{21} \u0026 a_{22} \u0026 a_{23}\\\\ a_{31} \u0026 a_{32} \u0026 a_{33} \\end{bmatrix}\\to \\begin{bmatrix} 1 \u0026 0 \u0026 0\\\\ -c \u0026 1 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} a_{11} \u0026 a_{12} \u0026 a_{13}\\\\ a_{21} \u0026 a_{22} \u0026 a_{23}\\\\ a_{31} \u0026 a_{32} \u0026 a_{33} \\end{bmatrix} \\]\n\\[=\\begin{bmatrix} a_{11} \u0026 a_{12} \u0026 a_{13}\\\\ a_{21}-ca_{11} \u0026 a_{22}-ca_{12} \u0026 a_{23}-ca_{13}\\\\ a_{31} \u0026 a_{32} \u0026 a_{33} \\end{bmatrix} \\]\n\\(L_{ij}(-c)^{-1}=L_{ij}(c)\\) 下面的矩阵乘积成立 \\[\\begin{bmatrix} 1 \u0026 \u0026 0\\\\ c_1 \u0026 1 \u0026 \\\\ \u0026 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 \u0026 \\\\ \u0026 1 \u0026 \\\\ c_2 \u0026 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 \u0026 \\\\ \u0026 1 \u0026 \\\\ \u0026 c_3 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 \u0026 \\\\ c_1 \u0026 1 \u0026 \\\\ c_2 \u0026 c_3 \u0026 1 \\end{bmatrix} \\]\n根据以上事实，我们可以把系数矩阵\\(A\\)表示为\\(A=LU\\)，其中\\(U\\)和高斯消元得到的上三角矩阵相同，而\\(L\\)矩阵就是所进行的操作乘起来的矩阵。\n使用LU分解回代 一旦知道\\(L,U\\)，问题\\(Ax=b\\)就可以转化为\\(LUx=b\\)。定义\\(c=Ux\\)，则回代有两个步骤\n对于方程\\(Lc=b\\)，求解\\(c\\) 对于方程\\(Ux=c\\)，求解\\(x\\) 其中\\(Lc=b\\)因为\\(L\\)是下三角矩阵，从上往下回代，\\(Ux=c\\)因为\\(U\\)是上三角矩阵，从下往上回代。\nLU分解的复杂度 如果只有一个方程组，那么和高斯消元法没有区别\n但是，如果我们遇到的问题是\n\\[Ax=b_1\\\\ Ax=b_2\\\\ \\cdots\\\\ Ax=b_k \\]\n这样的。那LU分解会比高斯消元一个一个去计算要来得快。\n但是，并不是所有的矩阵都可以进行\\(LU\\)分解\n例如分解\n\\[\\begin{bmatrix} 0 \u0026 1\\\\ 1 \u0026 1 \\end{bmatrix} = \\begin{bmatrix} 1 \u0026 0\\\\ a \u0026 1 \\end{bmatrix} \\begin{bmatrix} b \u0026 c\\\\ 0 \u0026 d \\end{bmatrix}= \\begin{bmatrix} b \u0026 c\\\\ ab \u0026 ac+d \\end{bmatrix} \\]\n由于\\(ab=1,b=0\\)不可能同时成立，所以反证法得知不能分解。\n误差来源 误差放大和条件数 定义1\n向量\\(x=(x_1,\\cdots,x_n)\\)的无穷范数或者最大范数为\\(||x||_\\infty=max|x_i|\\)，即\\(x\\)所有元素中的最大绝对值。\n定义2\n令\\(x_a\\)是线性方程组\\(Ax=b\\)的近似解。余项是向量\\(r=b-Ax_a\\)，后向误差是余项的范数\\(||b-Ax_a||_\\infty\\)，前向误差是\\(||x-x_a||_\\infty\\)\n同时也定义相对后向误差为\n\\[\\frac{||r||_\\infty}{||b||_\\infty} \\]\n相对前向误差定义为\n\\[\\frac{||x-x_a||_\\infty}{||x||_\\infty} \\]\n这个方程的误差放大因子是二者的比率，即\n\\[误差放大因子=\\frac{相对前向误差}{相对后向误差} \\]\n定义3\n方阵\\(A\\)的条件数\\(cond(A)\\)为求解\\(Ax=b\\)时，对于所有右侧向量\\(b\\)，可能出现的最大误差放大因子。\n和向量范数类似，定义\\(n\\times n\\)矩阵\\(A\\)的矩阵（无穷）范数为\n\\[||A||_\\infty = 每行元素绝对值之和的最大值 \\]\n定理1\n\\(n\\times n\\)矩阵\\(A\\)的条件数是\n\\[cond(A) = ||A||\\cdot||A^{-1}|| \\]\n依据误差放大因子，在求解\\(Ax=b\\)可能出现的相关前向误差是\\(\\varepsilon_{math}\\cdot cond(A)\\)。换句话说，如果\\(cond(A)\\approx 10^k\\)，我们在计算\\(x\\)时，将丢掉\\(k\\)位数字精度。\n向量范数和矩阵范数的性质\n对于向量无穷范数\n\\(||x||\\geq 0\\)，当且仅当\\(x=[0,\\cdots,0]\\)时等号成立 对于每个标量\\(\\alpha\\)和向量\\(x\\)，\\(||\\alpha x||=|\\alpha|\\cdot ||x||\\) 对于向量\\(x,y\\)有\\(||x+y||\\leq||x||+||y||\\) 对于矩阵无穷范数\n\\(||A||\\geq 0\\)，当且仅当\\(A=0\\)时等号成立 对于每个标量\\(\\alpha\\)和向量\\(x\\)，\\(||\\alpha A||=|\\alpha|\\cdot ||A||\\) 对于矩阵\\(A,B\\)有\\(||A+B||\\leq||A||+||B||\\) 被称为算子范数的矩阵范数，也可以使用特定的向量范数进行定义\n\\[||A||=\\max \\frac{||Ax||}{||x||} \\]\n对于任意矩阵\\(A\\)和向量\\(x\\)满足\n\\[||Ax||\\leq ||A||\\cdot||x|| \\]\n淹没 考虑如下方程组\n\\[10^{-20}x_1+x_2=1\\\\ x_1+2x_2=4 \\]\n高斯消元如下\n\\[\\begin{bmatrix} 10^{-20} \u0026 1 \u0026 | \u0026 1\\\\ 1 \u0026 2 \u0026 | \u0026 4 \\end{bmatrix}\\to \\begin{bmatrix} 10^{-20} \u0026 1 \u0026 | \u0026 1\\\\ 0 \u0026 2-10^{20} \u0026 | \u0026 4-10^{20} \\end{bmatrix} \\]\n然后解出\n\\[[x_1,x_2]=\\bigg [\\frac{2\\times 10^{20}}{10^{20}-2},\\frac{4-10^{20}}{2-10^{20}}\\bigg]\\approx[2,1] \\]\n我们手算是可以这样的，但是当我们使用IEEE双精度的时候，\n\\[\\begin{bmatrix} 10^{-20} \u0026 1 \u0026 | \u0026 1\\\\ 0 \u0026 2-10^{20} \u0026 | \u0026 4-10^{20} \\end{bmatrix} \\]\n舍入得\n\\[\\begin{bmatrix} 10^{-20} \u0026 1 \u0026 | \u0026 1\\\\ 0 \u0026 -10^{20} \u0026 | \u0026 -10^{20} \\end{bmatrix} \\]\n然后首先解出\\(x_2=1\\)，然后\\(x_1=0\\)，与精确解相比相差巨大。\n我们的解决办法是，更换行顺序，\n\\[\\begin{bmatrix} 1 \u0026 2 \u0026 | \u0026 4\\\\ 10^{-20} \u0026 1 \u0026 | \u0026 1 \\end{bmatrix}\\to \\begin{bmatrix} 1 \u0026 2 \u0026 | \u0026 4\\\\ 0 \u0026 1-2\\times 10^{-20} \u0026 | \u0026 1-4\\times 10^{-20} \\end{bmatrix} \\]\n舍入后也可以得到\\(x_2=1\\)，然后\\(x_1=2\\)。\n上述例子告诉我们，高斯消去的过程中要尽可能保证乘子比较小。\nPA=LU分解 部分主元 部分主元要求，在每一次选择主元时，找到这一列中绝对值最大的一个元素，其对应行与主元行进行交换。交换之后作为新的主元。这样我们就能完全避免淹没问题。\n同样，这样可以避免\\(0\\)主元问题。如果这一列没有非零元素，则矩阵是奇异矩阵，此时高斯消元怎样都不能得到正确解。\n置换矩阵 定义1\n置换矩阵是一个\\(n\\times n\\)矩阵，其在每一行、每一列仅有一个\\(1\\)，其他全部为\\(0\\)\n置换矩阵基础定理\n令\\(P\\)是通过对单位矩阵实施一组特定的行交换后得到的一个\\(n\\times n\\)的置换矩阵，则对于任意的\\(n\\times n\\)矩阵\\(A\\)，\\(PA\\)对应于对矩阵\\(A\\)实施同样的行变换得到的结果。\n例如\n\\[\\begin{bmatrix} 1 \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \\\\ 0 \u0026 1 \u0026 0 \\end{bmatrix} \\]\n是由单位矩阵交换二三行得到的，则\n\\[\\begin{bmatrix} 1 \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \\\\ 0 \u0026 1 \u0026 0 \\end{bmatrix} \\begin{bmatrix} a \u0026 b \u0026 c\\\\ d \u0026 e \u0026 f \\\\ g \u0026 h \u0026 i \\end{bmatrix}= \\begin{bmatrix} a \u0026 b \u0026 c \\\\ g \u0026 h \u0026 i \\\\ d \u0026 e \u0026 f \\end{bmatrix} \\]\n即把后面那个矩阵也交换了二三行。\n","date":"2022-10-02T16:42:53+08:00","image":"https://kegalas.top/inferior/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/cover_hu6778f7153b0100018882cd949f083bca_49831_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"数值分析学习笔记"},{"content":"电路的基本规律 集中（或集总）参数电路 实际电路的几何尺寸远小于工作波长时，我们用能足够精确反映其电磁性质的一些理想电路元件或他们的组合来模拟实际元件，这种理想化的电路元件称为集中参数元件。由其连接组成的电路称为集中参数电路。\n而一些远距离输电线就不能看做集中参数电路，称作分布参数电路，要用其他理论来研究。\n电流 单位时间内通过导体横截面的电荷量\\(q\\)定义为电流强度，简称电流，用\\(i,i(t)\\)表示，即\n\\[i(t)=\\frac{dq(t)}{dt} \\]\n电荷量的单位是库伦，时间的单位是秒，电流的单位是安培。\n方向，一般把正电荷运动的方向定义为电流的实际方向。但在具体电路中，电流的实际方向常常随时间变化。通常在分析电路时会指定某一方向为电流方向，称为电流的参考方向。如果参考方向和实际方向一致，则电流\\(i\u003e0\\)，否则\\(i\u003c0\\)。\n电流的参考方向是任意指定的，一般用箭头和双下标表示，如\\(i_{ab}\\)指\\(a\\)到\\(b\\)的电流。\n电压 电路中，电场力将单位正电荷从某点移到另一点所作的功定义为该两点之间的电压，也称电位差，用\\(u,u(t)\\)表示，即\n\\[u(t)=\\frac{dw(t)}{dq(t)} \\]\n功的单位是焦耳，电压的单位是伏特。\n通常，高电位为正极，低电位为负极。\n和电路的参考方向一样，我们也可以为电压指定参考极性。在分析电路问题时，先指定电压的参考极性，\\(+\\)表示高电位，\\(-\\)表示低电位。如果电压的参考极性和实际极性一致，则\\(u\u003e0\\)，否则\\(u\u003c0\\)。\n电流参考方向给定，若电流流入的方向是电压的高电位，流出的方向是电压的低电位，则称此时电流、电压是关联参考方向。反之为非关联参考方向。\n能量 正电荷从电路元件上电压的正极经元件移动到负极是电场力对电荷做功的结果，此时元件吸收能量。反之发出能量。\n若某元件两端的电压为\\(u\\)，在\\(dt\\)时间内流过该元件的电荷量为\\(dq\\)，那么，根据电压的定义式，电场力做的功\\(dw(t)=u(t)dq(t)\\)。\n在关联参考方向时，\\(dw(t)=u(t)i(t)dt\\)\n功率 能量对时间的变化率称为电功率。\n\\[p(t)=u(t)i(t) \\]\n基尔霍夫定律 电路图\n如果仅研究各元件的连接关系，暂不关心元件本身的特性，则可用一条线段来代表元件。\n支路\n电路图中的每一个元件，即图中的每一条线段，称为支路。\n节点\n支路的连接点称为节点。\n路径\n在图中，从某一节点出发。连续地经过一些支路和节点（只能各经过一次），到达另一节点，就构成路径。\n回路\n如果路径的最后到达点就是出发点，则这样的闭合路径称为回路。\n基尔霍夫 电流定律 对于集中参数电路中的任一节点，在任意时刻，流出该节点电流的和等于流入该节点电流的和。\n\\[\\sum_{流出} i(t) = \\sum_{流入} i(t)\\quad \\forall t \\]\n基尔霍夫电压定律 在集中参数电路中，任意时刻沿任一回路绕行，回路中所有支路电压的代数和恒为零\n\\[\\sum u(t) = 0\\quad\\forall t \\]\n注意，上式在计算时，需要任意指定一个回路的绕行方向，凡是之路电压的参考方向与回路的绕行方向一致者，该电压前面去+号；否则取-号。\n电阻元件 二端电阻 二端电阻元件可以定义为：一个二端元件，如果在任意时刻\\(t\\)，其两端电压\\(u\\)与流经它的电流\\(i\\)之间的关系(VCR)能用\\(u-i\\)平面上通过原点的曲线所确定，就称其为二端电阻元件，简称电阻元件。\n由于电压和电流的单位是V和A，因而电阻元件的特性称为伏安特性或伏安关系。\n如果电阻元件的伏安特性不随时间变化，则称其为非时变的。否则就是时变的。\n如果伏安特性是通过原点的直线，则称为线性的，否则是非线性的。\n欧姆定律\n在电压、电流参考方向相关联时，其电压与电流的关系就是熟知的欧姆定律\n\\[u(t)=Ri(t)\\quad\\forall t \\]\n或者\n\\[i(t) = Gu(t)\\quad\\forall t \\]\n其中电阻\\(R\\)的单位是欧姆\\(\\Omega\\)，电导\\(G\\)的单位是西\\(S\\)。对于线性非时变电阻元件，\\(R\\)和\\(G\\)都是常实数，他们的关系是\n\\[G=\\frac{1}{R} \\]\n分立电阻与集成电阻 任何材料都有电阻。导体、半导体和绝缘体三者的区别是材料的电阻率\\(\\rho\\)。通常\\(\\rho\u003c10^{-4}\\Omega\\cdot m\\)的材料称为导体，\\(\\rho\u003e10^4\\Omega\\cdot m\\)的材料称为绝缘体，介于其中的称为半导体。\n一段长度为\\(L\\)、截面积为\\(S\\)、电阻率为\\(\\rho\\)的材料，其电阻值为\n\\[R = \\rho\\frac{L}{S} \\]\n分立电阻器的主要参数\n电子电路中单个使用的具有电阻特性的元件，称为分立电阻器。电阻元件是由实际电阻器抽象出来的理想化模型。\n电阻元件和电阻器不是一个概念。电阻元件的参数只有一个电阻值，而电阻器的元件参数包括标称值、容差、额定功率、温度系数等。\n集成电阻\n集成电阻又称扩散电阻、薄层电阻。\n通过复杂的扩散工艺在硅片上生成一定尺寸的薄层而制成的电阻，称为扩散电阻。\n无论是分离电阻器还是集成电阻，分析时都应该抽象为电阻元件。\n电源 电压源 一个二端元件，如果其端口电压总能保持为给定的电压\\(u_s(t)\\)，而与通过它的电流无关，则称其为电压源。\n如果\\(u_s(t)\\)为恒定值，则称其为直流电压源或恒定电压源。\n电压源具有如下特点：\n无论通过它的电流为何值，电压源的端口电压\\(u\\)总保持\\(u(t)=u_s(t)\\) 电压源的电流由电压源和与它相连的外电路共同决定。 电流源 一个二端元件，如其端口电流值总能保持为给定的电流\\(i_s(t)\\)，而与其端口电压无关，则称其为电流源。\n如果\\(i_s(t)\\)为恒定值，则称其为直流电流源或恒定电流源。\n电流源具有如下特点：\n无论其端口电压\\(u\\)为何值，电流源的电流\\(i\\)总保持\\(i(t)=i_s(t)\\) 电流源的端口电压源由电流源和与它相连的外电路共同决定。 电路中的参考点 在电路分析中，常常指定电路中的某点为参考点，计算或测量其它各节点对参考点的电位差，称其为各节点的电位，或各节点的电压。\n受控源 非独立电源是指电压源的电压或电流源的电流不是给定的时间函数，而是受电路中某支路电压或电流控制的，因此常称为受控源。\n受控源的符号通常用菱形，而不是圆形。\n电路等效 概念 对于两部分结构、元件参数完全不同的电路，若它们具有完全相同的端口电压电流关系，就称它们是等效的。\n电阻的串联和并联 串联\n\\[R_{eq}=R_1+R_2+\\cdots \\]\n串联时，电流相等；各电阻的电压如下\n\\[u_k=R_k i =\\frac{R_k}{R_{eq}}u \\]\n并联\n电导有\n\\[G_{eq}=G_1+G_2+\\cdots \\]\n电阻有\n\\[\\frac{1}{R_{eq}}=\\frac{1}{R_{1}}+\\frac{1}{R_{2}}+\\cdots \\]\n并联时，电压相同，各电阻的电流如下\n\\[i_k=G_iu=\\frac{G_k}{G_{eq}}i \\]\n电阻Y型和三角形电路的等效变换 1.jpg\r含独立源电路的等效 独立源的串联和并联 电压源串联\n电压源串联时，得到的净电压等于电压极性相同的各个电源电压总和，减去极性相反的各电源电压总和。净电压方向与大的那个相同。\n电压源并联\n只有两端电压是相同的电压源才可以并联。可以增加输出电流的能力。\n电流源串联\n只有电流大小相同的电流源能串联。\n电流源并联\n电流源并联时，得到的等效电流源电流大小等于极性相同的各个电源流总和，减去极性相反的各电源电流总和。净电流方向与大的那个相同。\n实际电源的等效变换\n实际电源，比如电池，我们在高中通常会说它含有一个内阻。也就是等价为一个理想电压源+一个电阻的串联。我们也可以将其等价为一个理想电流源+一个电阻的并联。如下图\n2.jpg\r电压源的等效转移\n电流源可以转移到各并联支路上，如下图\n3.jpg\r可以证明，此时电路中的KVL仍然保持不变。\n电流源的等效转移\n电流源可以转移成如下形式\n4.jpg\r电阻电路分析 图与电路方程 图的基本概念\n图的定义和离散数学、算法竞赛图论部分没有什么差别。\n主要介绍基本回路：仅包含一条连支（其余为树枝，即树加了任意一条连支）的回路称为单连支回路或基本回路\n基本割集：仅包含一条树枝（其余为连支）的割集称为单树支割集或基本割集。\nKCL与KVL的独立方程\n根据我们的朴素想法，我们会把每一个节点的KCL方程和每一个回路的KVL方程列出来，试图求解电路中的所有未知量。这的确是可行的，但是，我们会发现我们有一些方程是可以由其他方程推出的，这就导致了不是所有方程都是独立的。\n可以证明，对于有\\(n\\)个节点的连通图，任选\\(n-1\\)个节点所列的\\(KCL\\)方程是独立的。这些对应的节点叫独立节点，另外一个节点叫参考节点。\n对于\\(n\\)个节点、\\(b\\)条支路的连通图，有\\(L=b-n+1\\)个基本回路，可以列出\\(L\\)个独立的KVL方程。\n或者说，对于平面图，有\\(L\\)个网孔，可以根据这\\(L\\)个网孔列出独立的KVL方程。\n在平面图中，网孔就是内部不包含边的回路。\n2b法和支路法 2b法 对一个具有\\(b\\)条支路和\\(n\\)个节点的电路，当以支路电压和支路电流为变量列写方程时，共有\\(2b\\)个未知变量，根据KCL可列出\\(n-1\\)个独立方程，根据KVL可列出\\(b-n+1\\)个独立方程；根据元件的伏安关系，每条支路可以列出\\(b\\)个支路电压和电流关系的方程。于是总共列出了\\(2b\\)个方程。\n这个方法称为\\(2b\\)法，可行，但是对于手算不方便\n支路法 如果以支路电流（或支路电压）为电路变量列出方程，求解支路电流（或支路电压），则称为支路电流（支路电压）法。\n步骤如下\n选定各支路电流的参考方向 对\\(n-1\\)个独立节点，列出KCL方程 对所有的网孔，按指定回路绕行方向，根据KVL，列出电压方程 总共列出了\\(b\\)个方程。\n例如：\n5.jpg\r任一回路内，电阻上电压的代数和等于电压源电压的代数和，其中支路电流参考方向与回路方向一致者，\\(R_ki_k\\)前取\\(+\\)号，否则取\\(-\\)号，电压源\\(u_{sk}\\)的参考方向与回路方向相反者取\\(+\\)号，否则取\\(-\\)号。（当然在本例中电压源写在了方程等号左边，上面说的符号是写在右边时的符号）\n回路法和网孔法 以独立回路电流为未知变量列出并求解方程的方法称为回路法。若选平面电路的网孔作独立回路，则这样的回路法又常称为网孔法。\n回路电流实际上并不存在，只是为了方便分析而引入的概念。\n回路法的步骤归纳如下\n选定一组独立回路，并指定各回路电流的参考方向 列出回路方程（注意电阻和电压源的符号） 解方程 例如：\n6.jpg\r节点法 以节点电压为未知变量列出并求解方程的方法称为节点法\n在电路中任选一个节点为参考节点，其余节点与参考节点之间的电压称为节点电压或节点电位。\n7.jpg\r8.jpg\r但以上方程不需要推导，可以直观的列出\n规律如下：\n\\(G_{ii}\\)称为节点\\(i\\)的自电导，等于与节点\\(i\\)相连的所有支路的电导之和，恒取\\(+\\) \\(G_{ij}(i\\neq j)\\)称为节点\\(i,j\\)之间的互电导，等于两节点之间的电导之和，恒取\\(-\\) \\((\\sum I_s)_i\\)称为节点\\(i\\)的等效电流源，等于流入节点\\(i\\)的所有电流源电流的代数和。流入为\\(+\\)，流出为\\(-\\) 齐次定理和叠加定理 首先介绍齐次性和叠加性，对于线性映射\\(f\\)，它满足\n齐次性（比例性），即 \\[f(ax)=af(x) \\]\n可加性（叠加性） \\[f(x_1+x_2) = f(x_1)+f(x_2) \\]\n两者也可以结合使用。\n例如\\(f(x)=ax\\)是线性的，但\\(f(x)=ax+b\\)就不是线性的。\n齐次定理 对于有唯一解的线性电路，当只有一个激励源（独立电压源或独立电流源，必须是独立的）x(t)作用时，其响应y(t)（电路任意处的电压或电流）与激励成齐次关系。例如\n9.jpg\r注意：\n只能用于有唯一解的线性电路，不能用于非线性电路 响应也称为输出，指电路中任意处的电流或电压；功率与激励源之间不存在线性关系 激励也称为输入，指电路中的独立源，受控源不是激励源 叠加定理 对于有唯一解的线性电路，多个激励源共同作用时引起的响应（电路中各处的电流、电压）等于各个激励源单独作用时（其他激励源置零，具体表现为电压源变成导线，电流源变成开路）所引起的响应之和\n替代定理 对于有唯一解的线性或非线性电路，若某支路的电压\\(u\\)或电流\\(i\\)已知，则该支路可用方向和大小与\\(u\\)相同的电压源替代，或用方向和大小与\\(i\\)相同的电流源替代，而不会影响其他点的电流和电压。\n注意，替换成电流源后电压不变，替换成电压源后电流也不变。\n等效电源定理 戴维南定理 任意一个线性二端含源电路\\(N\\)，对其外部而言，可以用一个电压源和电阻的串联组合来等效。该电压源的电压值\\(U_{OC}\\)等于电路\\(N\\)二端子间的开路电压，其串联电阻值\\(R_0\\)等于电路N内部所有独立源置零时二端子的等效电阻。\n例如\n10.jpg\r求其等效电源，先将\\(ab\\)断开，计算等效电压\n\\[U_{OC}=\\frac{6}{6+3}\\times 24-\\frac{4}{4+4}\\times 24 = 4V \\]\n将电压源置零，得到一根导线，计算等效电阻为\n\\[R_0=\\frac{18}{9}+\\frac{16}{8}=4\\Omega \\]\n得到的等效电源为\n11.jpg\r诺顿定理 诺顿定理与戴维南不同的地方是，诺顿定理等效为一个电流源和一个电阻并联。本质上是等效的。\n我们可以选择先计算戴维南等效，再电源等效为电流源。\n也可以选择将两个端子短路来计算等效电流源，将独立源置零来计算等效并联电阻。\n计算技巧 等效的电流源和电压源是容易计算的，电流源将两个端子短路，电压源将两个端子开路。\n没有受控源时，将独立源置零，根据串并联关系，等效电阻也是容易计算的。\n当有受控源时\n外加电源法\n12.jpg\r13.jpg\r开路短路法\n即计算开路电压\\(u_{oc}\\)和短路电流\\(i_{sc}\\)，得到\\(R_0=u_{oc}/i_{sc}\\)\n伏安关系法\n直接对二端线性电路\\(N\\)，推导出两端子上的电压\\(u\\)和电流\\(i\\)之间的一次关系式，通常是以下形式\n\\[u=u_{oc}-R_0i \\]\n就可以得到开路电压和等效内阻。\n最大传输功率电源定理 在电子技术中，常要求负载从给定电源（或给定电路）获得最大功率，即最大功率传输问题。\n实际应用常遇到这样的问题：一个有源二端电路，向负载电阻\\(R_L\\)供电。问\\(R_L\\)为何值时其上获得最大功率？\n由于电路\\(N\\)给定，可以将其等效为戴维南等效电路来分析。\n设等效电压为\\(u_{oc}\\)，电源内阻为\\(R_0\\)，则\n\\[P_L = \\bigg(\\frac{u_{oc}}{R_0+R_L}\\bigg)^2R_L \\]\n可以用求导等方式证明，\\(R_L=R_0\\)时，其\\(P_L\\)最大。这称为最大功率匹配条件。\n特勒根定理和互易定理 特勒根定理 定理1\n对于任意一个具有\\(b\\)条支路\\(n\\)个节点的集总参数电路，设支路电压、支路电流分别为\\(u_k,i_k\\)，且各支路电压和电流取关联参考方向，对任何时间\\(t\\)，有\n\\[\\sum^b_{k=1}u_ki_k=0 \\]\n定理2\n对于任意两个拓扑结构完全相同（即图完全相同，各支路组成元件性质任意）的集中参数电路\\(N\\)和\\(N'\\)。设它们具有\\(b\\)条支路\\(n\\)个节点，其相对应的各支路和各节点的编号相同。设它们的支路电压分别为\\(u_k\\)和\\(u'_k\\)，支路电流分别为\\(i_k\\)和\\(i'_k(k=1,2,\\cdots,b)\\)，且各支路电压和电流取关联参考方向，则对任意时刻\\(t\\)，有\n\\[\\sum^b_{k=1}u_ki'_k=0 \\]\n\\[\\sum^b_{k=1}u'_ki_k=0 \\]\n互易定理 互易定理表明: 对于一个仅含线性电阻的二端口电路\\(N_R\\)，在只有一个激励源的情况下，当激励与响应互换位置时，同一激励所产生的响应相同。\n有三个形式\n15.png\r16.png\r动态电路 动态元件 电容 一个二端元件，若在任一时刻\\(t\\)，其电荷\\(q(t)\\)与电压\\(u(t)\\)之间的关系能用\\(q\\sim u\\)平面上的曲线表征，即具有代数关系\\(f(u,q)=0\\)，则称该元件为电容元件，简称电容。\n电容分为时变的和非时变的、线性的和非线性的，我们主要讨论线性非时变电容。\n此时电容的库伏特性是\n\\[q(t) = Cu(t) \\]\n其中\\(C\\)与时间无关，是电容的大小，单位为法拉（电量单位为库伦时）。\n电容的VAR\n当电容两端的电压变化时，聚集在电容上的电荷也相应发生变化，表明连接电容的导线上电荷移动，即电流流过；若电容上电压不变化，电荷也不变化，即电流为零。\n微分关系\n若电容上电压与电流参考方向关联，则有\n\\[i(t) = C\\frac{du(t)}{dt} \\]\n积分关系\n\\[u(t) = \\frac{1}{C}\\int^t_{-\\infty}i(\\xi)d\\xi \\]\n设\\(t=t_0\\)为初始观察时刻，上式可改写为\n\\[u(t) = \\frac{1}{C}\\int^{t_0}_{-\\infty}i(\\xi)d\\xi+\\frac{1}{C}\\int^{t}_{t_0}i(\\xi)d\\xi=u(t_0)+\\frac{1}{C}\\int^{t}_{t_0}i(\\xi)d\\xi,t\\geq t_0 \\]\n其中\n\\[u(t_0)=\\frac{1}{C}\\int^{t_0}_{-\\infty}i(\\xi)d\\xi \\]\n称电容电压在\\(t_0\\)时刻的初始值，或初始状态，它包含了在\\(t_0\\)以前电流的“全部历史”信息。一般取\\(t_0=0\\)。\n注意\n电容的伏安关系是微积分关系，因此电容元件是动态元件。而电阻元件的伏安关系是代数关系，电阻是一个即时(瞬时)元件。 任意时刻，通过电容的电流与该时刻电压的变化率成正比。当电容电流\\(i\\)为有限值时，其\\(du/dt\\)也为有限值，则电压\\(u\\)必定是连续函数，此时电容电压不会跃变。 当电容电压为直流电压时，则电流\\(i = 0\\)，此时电容相当于开路，故电容有隔直流的作用。 由电容VAR的积分形式可知:在任意时刻t，电容电压u是此时刻以前的电流作用的结果，它“记载”了以前电流的“全部历史”。即电容电压具有“记忆”电流的作用，故电容是一个记忆元件，而电阻是无记忆元件。 电容的功率和储能\n功率\n当电压和电流为关联方向时，电容吸收的瞬时功率为\n\\[p(t) = u(t)i(t) = Cu(t)\\frac{du(t)}{dt} \\]\n电容是储能元件，它不消耗能量。释放的能量不会超过吸收的能量。电容不能产生能量，因此为无源元件。\n储能\n对功率从\\(-\\infty\\)到\\(t\\)进行积分，即得\\(t\\)时刻电容上的储能：\n\\[w_c(t)=\\int^t_{-\\infty}p(\\xi)d\\xi=\\int^{u(t)}_{u(-\\infty)}Cu(\\xi)du(\\xi)=\\frac{1}{2}Cu^2(t)-\\frac{1}{2}Cu^2(-\\infty) \\]\n而未充电时应有\\(u(-\\infty)=0\\)，所以\n\\[w_c(t) = \\frac{1}{2}Cu^2(t) \\]\n电容在某一时刻\\(t\\)的储能仅取决于此时刻的电压，而与电流无关，并且大于等于零。\n电感 一个二端元件，若在任一时刻\\(t\\)，其磁链\\(\\varPsi(t)\\)与电流\\(i(t)\\)之间的关系能用\\(\\varPsi\\sim i\\)平面上的曲线表征，即具有代数关系\\(f (\\varPsi, i ) = 0\\)，则称该元件为电感元件，简称电感。\n电感也分为时变的和非时变的、线性的和非线性的。\n主要讨论的是线性非时变电感。\n线性时不变电感的外特性（韦安特性）是\\(\\varPsi\\sim i\\)平面上一条过原点的直线，且其斜率\\(L\\)不随时间变化，\n\\[\\varPsi(t) = Li(t) \\]\n磁链单位是韦伯，电感单位是亨利。\n电感的VAR\n电感中，当电流变化时，磁链也发生变化，从而产生感应电压。在电流与电压参考方向关联时，若电压参考方向与磁通的方向符合右手法则，根据法拉第电磁感应定律，感应电压\\(u_L(t)\\)与磁链的变化率成正比，即：\n微分关系\n\\[u_L(t)=\\frac{d\\varPsi(t)}{dt}=L\\frac{di(t)}{dt} \\]\n积分关系\n\\[i(t) = \\frac{1}{L}\\int^t_{-\\infty}u(\\xi)d\\xi \\]\n设\\(t=t_0\\)为初始观察时刻，上式可改写为\n\\[i(t) = \\frac{1}{L}\\int^{t_0}_{-\\infty}u(\\xi)d\\xi+\\frac{1}{L}\\int^{t}_{t_0}u(\\xi)d\\xi=i(t_0)+\\frac{1}{L}\\int^{t}_{t_0}u(\\xi)d\\xi,t\\geq t_0 \\]\n其中\n\\[i(t_0)=\\frac{1}{L}\\int^{t_0}_{-\\infty}u(\\xi)d\\xi \\]\n称电感电流在\\(t_0\\)时刻的初始值，或初始状态，它包含了在\\(t_0\\)以前电压的“全部历史”信息。一般取\\(t_0=0\\)。\n注意\n电感元件是动态元件。 电感的电压与该时刻电流的变化率成正比 电流\\(i\\)是连续函数，电感电流不会跃变 电感对直流相当于短路。 电感电流\\(i\\)是此时刻以前的电压作用的结果，它“记载” 了以前电压的“全部历史”。即电感也是一个记忆元件。 电感是一个储能元件，它从外部电路吸收的能量，以磁场能量的形式储存于自身的磁场中。电感\\(L\\)在某一时刻的储能只与该时刻\\(t\\)电感电流有关。 电感的功率与储能\n功率\n当电压和电流为关联方向时，电感吸收的瞬时功率为\n\\[p(t) = u(t)i(t) = Li(t)\\frac{di(t)}{dt} \\]\n电感是储能元件，它不消耗能量。释放的能量不会超过吸收的能量。电感不能产生能量，因此为无源元件。\n储能\n对功率从\\(-\\infty\\)到\\(t\\)进行积分，即得\\(t\\)时刻电感上的储能：\n\\[w_c(t)=\\int^t_{-\\infty}p(\\xi)d\\xi=\\int^{i(t)}_{i(-\\infty)}Li(\\xi)di(\\xi)=\\frac{1}{2}Li^2(t)-\\frac{1}{2}Li^2(-\\infty) \\]\n而未充电时应有\\(i(-\\infty)=0\\)，所以\n\\[w_c(t) = \\frac{1}{2}Li^2(t) \\]\n电感在某一时刻\\(t\\)的储能仅取决于此时刻的电流，而与电压无关，并且大于等于零。\n电容的串并联 串联\n\\[\\frac{1}{C_{eq}}=\\frac{1}{C_1}+\\frac{1}{C_2}+\\cdots+\\frac{1}{C_n} \\]\n并联\n\\[C_{eq}=C_1+C_2+\\cdots+C_n \\]\n电感的串并联 串联\n\\[L_{eq}=L_1+L_2+\\cdots+L_n \\]\n并联\n\\[\\frac{1}{L_{eq}}=\\frac{1}{L_1}+\\frac{1}{L_2}+\\cdots+\\frac{1}{L_n} \\]\n动态电路方程及其解 动态电路方程 一阶电路\n17.jpg\r由KCL等可得\n\\[\\frac{du_C}{dt}+\\frac{1}{\\tau}u_C = \\frac{1}{RC}u_S \\]\n其中\\(\\tau=RC\\)，量纲为秒，称为时常数。\n18.jpg\r由\\(KVL\\)等可得\n\\[\\frac{i_L}{dt} + \\frac{1}{\\tau}i_L = \\frac{R}{L}i_s \\]\n其中\\(\\tau=L/R\\)，其量纲也为秒。\n观察两个方程，除了变量不同，均为典型的一阶微分方程，因此均为一阶电路。一般形式为\n\\[y'(t)+ay(t) = bf(t) \\]\n其中\\(y(t)\\)为响应，\\(f(t)\\)为激励。\n二阶电路\n19.jpg\r\\[\\frac{d^2 u_C}{dt^2} + \\frac{R}{L}\\frac{du_C}{dt}+\\frac{1}{LC}u_c = \\frac{1}{LC}u_S \\]\n建立动态方程的一般步骤\n根据电路建立KCL或KVL方程，写出各个元件的伏安关系 在以上方程中消去中间变量，得到所需变量的微分方程 对于较复杂的动态电路，常用拉普拉斯变换进行分析 动态电路方程的求解 同高数内容，不再赘述。对于电路的一些形式可以在三要素部分介绍。\n电路的初始值 换路定律 若电容电流\\(i_C\\)和电感电压\\(u_L\\)在\\(t=0\\)时为有限制，则换路前后瞬间电容电压\\(u_C\\)和电感电流\\(i_L\\)是连续的，即\n\\[\\left\\{\\begin{matrix} u_C(0_+) =u_C(0_-)\\\\ i_L(0_+) = i_L(0_-) \\end{matrix}\\right. \\]\n而除了这两个值（独立初始值），其余各处的电压电流（非独立初始值）不受换路定律的约束，可以出现跃变。\n独立初始值的求解 在换路之前，也就是\\(t\u003c0\\)时，直流电源作用下电路处于稳态。此时电容可以视为开路，电感视为短路，由此我们可以直接计算\\(u_C(0_-)\\)和\\(i_L(0_-)\\)，就像没有动态元件时所做的那样。\n然后根据换路定律就可以求出\\(t=0_+\\)时的独立初始值。\n非独立初始值的求解 在\\(t=0_+\\)时刻，将电容用电压等于\\(u_C(0_+)\\)的电压源替代，电感用电流等于\\(i_L(0_+)\\)的电流源替代，再去计算各处的电流电压。\n动态电路的响应 零输入响应 外加激励均为零时，仅由初始状态所引起的响应，称为零输入响应，记为\\(y_x(t)\\)或\\(y_{zi}(t)\\)。\n例如\n20.jpg\r通过某种手段先给\\(C\\)充电到电压为\\(u_C\\)，然后接入电阻\n此时方程为\n\\[RC\\frac{du_C}{dt}+u_C=0 \\]\n解得\n\\[u_C(t) = Ke^{-t/\\tau} \\]\n其中\\(\\tau = RC\\)，\\(K=u_C(0_+)\\)\n零状态响应 当电路的初始储能为零(即初始状态为零)时，仅由外加激励所引起的响应，称为零状态响应，记为\\(y_f(t)\\)或\\(y_{zs}(t)\\)。\n例如\n21.jpg\r\\(t=0\\)突然将开关打开，给右侧电路一个激励。\n方程解得\n\\[i_c = I_Se^{-t/\\tau} \\]\n其中\\(\\tau=RC\\)\n若有多个激励，零状态响应与各激励之间也满足可加性。这种性质称之为零状态线性。\n全响应 电路在外加激励和初始状态共同作用下所产生的响应，称为全响应。\n全响应=零输入响应+零状态响应，即\n\\[y(t) = y_{zi}(t) + y_{zs}(t) \\]\n计算只要\n将独立源置零计算零输入响应 将电容、电感的状态置零计算零状态响应 一阶电路的三要素 对于直流激励下的一阶电路中任意一处的电流和电压，只要计算出其在\\(t=0_+\\)和\\(t=\\infty\\)时的值以及整个电路的时常数，就可以直接列出它随时间的函数\n\\[y(t) = y(\\infty) + [y(0_+)-y(\\infty)]e^{-t/\\tau} \\]\n如果起始时间是\\(t=t_0\\)，则\n\\[y(t) = y(\\infty) + [y(t_{0_+})-y(\\infty)]exp(-(t-t_0)/\\tau) \\]\n计算\\(y(0_+)\\)\n独立初始值和非独立初始值的计算已经介绍过，不再重复。\n计算\\(y(\\infty)\\)\n\\(t\\to\\infty\\)时，电路进入直流稳态，此时电容看做开路，电感看做短路。然后再用这个电路去计算我们所要的电流、电压值。\n计算\\(\\tau\\)\n对于一阶\\(RC\\)电路，\\(\\tau = R_0C\\)\n对于一阶\\(RL\\)电路，\\(\\tau = L/R_0\\)\n\\(R_0\\)是换路后从动态元件\\(C\\)或\\(L\\)看进去的戴维南等效内阻。\n阶跃函数与阶跃响应 阶跃函数 单位阶跃函数用\\(\\varepsilon(t)\\)表示，其定义为\n\\[\\varepsilon(t) = \\left\\{\\begin{matrix} 1,t\u003e0\\\\ 0,t\u003c0 \\end{matrix}\\right. \\]\n其中\\(t=0\\)处的值可以不定义。\n如果单位直流电源接入的时刻为\\(t_0\\)，则可用延迟单位阶跃函数表示\n\\[\\varepsilon(t-t_0) = \\left\\{\\begin{matrix} 1,t \u003e t_0\\\\ 0,t \u003c t_0 \\end{matrix}\\right. \\]\n阶跃响应 当激励为单位阶跃函数\\(\\varepsilon(t)\\)时，电路的零状态响应称为单位阶跃响应，简称阶跃响应，用g(t)表示。\n单位阶跃函数\\(\\varepsilon(t)\\)作用于电路相当于单位直流源(\\(1V\\)或\\(1A\\))在\\(t = 0\\)时接入电路，因此，一阶电路的阶跃响应仍可用三要素法求得。\n正弦稳态分析 正弦量 正弦量的三要素 按正弦(余弦)规律变化的电压、电流称为正弦电压、电流，统称为正弦量\n正弦量的三要素是：振幅、初相、角频率。\n瞬时值表达式为\n\\[i(t) = I_m\\cos(\\omega t+\\varphi_i)\\\\ u(t) = U_m\\cos(\\omega t+\\varphi_u) \\]\n\\(U_m(I_m)\\)是最大值，称为振幅\n\\(\\omega t+\\varphi\\)是相位（角），单位\\(rad\\)或度\n\\(t=0\\)时的相位\\(\\varphi\\)称为初相位，\\(-\\pi\\leq \\varphi\\leq\\pi\\)\n\\(\\omega\\)是正弦量相位变化的速率\n正弦量的有效值 \\[I = \\frac{1}{\\sqrt 2}I_m \\]\n\\[U = \\frac{1}{\\sqrt 2}U_m \\]\n相位差 两个同频率的正弦波之间的相位之差称为相位差\n频率相同，则相位差即为初相之差。\n相量法 正弦量与相量 根据欧拉公式\n\\[u(t) = U_mcos(\\omega t+\\varphi_u) = Re[U_me^{j(\\omega t+\\varphi_u)}] = Re[U_me^{j\\varphi_u}e^{j\\omega t}] = Re[\\dot{U_m}e^{j\\omega t}] \\]\n这样，一个余弦时间函数就能用一个复指数函数来表示，其中\n\\[\\dot{U_m} = U_me^{j\\varphi_u} = U_m\\angle\\varphi_u \\]\n\\(\\dot{U_m}\\)的模式正弦电压的振幅\\(U_m\\)，辐角是正线电压的初相角\\(\\varphi_u\\)，我们称其为电压\\(u\\)的振幅相量。为了将相量与一般复数做区别，\\(U_m\\)上加\\(\\cdot\\)。\n式中\\(e^{j\\omega t}\\)称为旋转因子，它是模等于\\(1\\)，初相为零，并以角速度\\(\\omega\\)逆时针旋转的复值函数。向量\\(\\dot{U_m}\\)乘以旋转因子\\(e^{j\\omega t}\\)得到的\\(\\dot{U_m}e^{j\\omega t}\\)称为旋转相量，\\(\\dot{U_m}\\)称为其振幅。\n有效值与最大值的关系为\n\\[\\dot{I_m} = \\sqrt 2 \\dot I,\\dot{U_m} = \\sqrt 2 \\dot U \\]\n\\(u(t) = Re[\\dot{U_m}e^{j\\omega t}]\\)的几何意义是，一个正弦量在任意时刻的瞬时值，等于对应的旋转向量同一时刻在实轴上的投影。\n注意相量法只适用于同频率正弦激励的线性时不变电路。\n正弦量的相量运算 同频率正弦量加减\n设\n\\[u_1(t) = \\sqrt 2U_1\\cos(\\omega t+\\varphi_1) = Re[\\sqrt 2\\dot{U_1}e^{j\\omega t}] \\]\n\\[u_2(t) = \\sqrt 2U_2\\cos(\\omega t+\\varphi_1) = Re[\\sqrt 2\\dot{U_2}e^{j\\omega t}] \\]\n\\[u(t) = u_1(t) + u_2(t) = Re[\\sqrt 2\\dot{U_1}e^{j\\omega t}] + Re[\\sqrt 2\\dot{U_2}e^{j\\omega t}] \\]\n\\[Re[\\sqrt 2\\dot{U}e^{j\\omega t}] = Re[\\sqrt 2\\dot{U_1}e^{j\\omega t} + \\sqrt 2\\dot{U_2}e^{j\\omega t}] = Re[\\sqrt{2}(\\dot{U_1}+\\dot{U_2})e^{j\\omega t}] \\]\n所以有\\(\\dot U = \\dot{U_1}+\\dot{U_2}\\)\n对于\\(\\dot I\\)同理。\n正弦量的微分、积分\n设\\(i = \\sqrt 2I\\cos(\\omega t+\\varphi_i)=\\sqrt 2Re[\\dot Ie^{j\\omega t}]\\)\n微分\n\\[\\dfrac{di(t)}{dt} = \\sqrt 2Re[j\\omega\\dot Ie^{j\\omega t}] \\]\n其中\n\\[\\dot I' = j\\omega\\dot I = \\omega I e^{j(\\varphi_i+\\pi/2)} \\]\n积分\n\\[\\int i(t)dt = \\sqrt 2Re[\\dfrac{\\dot I}{j\\omega}e^{j\\omega t}] \\]\n\\[\\dot I' = \\dfrac{\\dot I}{j\\omega} = \\dfrac I\\omega e^{j(\\varphi_i-\\pi/2)} \\]\n电路定律的相量形式 KCL和KVL \\[\\sum\\dot I = 0 \\]\n\\[\\sum\\dot U = 0 \\]\n如果改用最大值，也有\n\\[\\sum\\dot I_m = 0 \\]\n\\[\\sum\\dot U_m = 0 \\]\nVAR的相量形式 22.jpg\r阻抗与导纳 阻抗 阻抗以如下形式定义\n\\[Z = \\dfrac{\\dot U}{\\dot I} = \\dfrac{U\\angle\\varphi_u}{I\\angle\\varphi_i} = |Z|\\angle\\theta_Z = R+jX \\]\n其中\\(|Z|=\\dfrac{U}{I}=\\sqrt{R^2+X^2}\\)称为阻抗模，\\(\\theta_Z = \\varphi_u-\\varphi_i = \\arctan\\dfrac{X}{R}\\)称为阻抗角。\n\\(R = |Z|\\cos\\theta_Z\\)称为电阻，即阻抗的实部。\\(X = |Z|\\sin\\theta_Z\\)称为电抗，即阻抗的虚部。\n单个元件\\(R,L,C\\)的阻抗\\(Z_R,Z_L,Z_C\\)分别为\n\\[\\left\\{\\begin{align*} \u0026Z_R = R\\\\ \u0026Z_L = j\\omega L = jX_L = X_L\\angle\\dfrac{\\pi}{2} \\\\ \u0026Z_C = \\dfrac{1}{j\\omega C} = -j\\dfrac{1}{\\omega C} = -jX_C = X_C\\angle-\\dfrac{\\pi}{2} \\end{align*}\\right. \\]\n阻抗串联时\n\\[Z_{eq} = \\sum Z_k \\]\n分压为\n\\[\\dot U_k = \\dfrac{Z_k}{Z_{eq}}\\dot U \\]\n导纳 导纳以如下形式定义\n\\[Y = \\dfrac{\\dot I}{\\dot U} = \\dfrac{I\\angle\\varphi_i}{U\\angle\\varphi_u} = |Y|\\angle\\theta_Y = G+jB \\]\n其中\\(|Y|=\\dfrac{I}{U}=\\sqrt{G^2+B^2}\\)称为导纳模，\\(\\theta_Y = \\varphi_i-\\varphi_u = \\arctan\\dfrac{B}{G}\\)称为导纳角。\n\\(G = |Y|\\cos\\theta_Y\\)称为电导，即导纳的实部。\\(B = |B|\\sin\\theta_Y\\)称为电纳，即导纳的虚部。\n单个元件\\(R,L,C\\)的导纳\\(Y_R,Y_L,Y_C\\)分别为\n\\[\\left\\{\\begin{align*} \u0026Y_R = \\dfrac{1}{R} = G\\\\ \u0026Y_L = \\dfrac{1}{j\\omega L} = -j\\dfrac{1}{\\omega L} = -jB_L\\\\ \u0026Y_C = j\\omega C = jB_C \\end{align*}\\right. \\]\n导纳并联时\n\\[Y_{eq} = \\sum Y_k \\]\n分流为\n\\[\\dot I_k = \\dfrac{Y_k}{Y_{eq}}\\dot I \\]\n阻抗和导纳的关系 对统一电路，阻抗和导纳互为倒数。\n\\[Z = \\dfrac{1}{Y},Y=\\dfrac{1}{Z} \\]\n或者\n\\[|Y| = \\dfrac{1}{|Z|},\\theta_y = -\\theta_z \\]\n阻抗与导纳的性质 对于阻抗\\(Z = R+jX\\)\n若\\(X\u003e0\\)，电路呈感性，\\(0\\degree\u003c\\theta_z\u003c90\\degree\\)。\\(X=0\\)，电路呈阻性，\\(\\theta_z=0\\)。\\(X\u003c0\\)，电路呈容性，\\(-90\\degree\u003c\\theta_z\u003c0\\degree\\)。\n对于导纳\\(Y = G+jB\\)\n若\\(B\u003e0\\)，电路呈容性，\\(0\\degree\u003c\\theta_y\u003c90\\degree\\)。\\(B=0\\)，电路呈阻性，\\(\\theta_y=0\\)。\\(B\u003c0\\)，电路呈感性，\\(-90\\degree\u003c\\theta_y\u003c0\\degree\\)。\n电路为感性时，电压超前于电流，\\(\\theta_z\u003e0\\)，电路为阻性时，电压和电流同向，电路为容性时，电压落后与电流，\\(\\theta_z\u003c0\\)\nRLC串联电路中会出现分压和大于总电压的情况。\nRLC并联电路中会出现分流和大于总电流的情况。\n正弦稳态电路的计算 和直流电阻电路的电路定律是相似的，也就是说网孔法、节点法、阻抗的串并联、电源的等效互换、等效电源等方法可以使用。\n正弦稳态电路的功率 一端口电路的功率 设无源一端口正弦稳态电路端口\\(u,i\\)关联\n\\[u(t) = \\sqrt 2U\\cos(\\omega t+\\varphi_u) \\]\n\\[i(t) = \\sqrt 2I\\cos(\\omega t+\\varphi_u-\\theta) \\]\n\\(\\theta = \\varphi_u-\\varphi_i\\)，即\\(u,i\\)的相位差\n瞬时功率\n\\[p(t) = ui = UI[\\cos\\theta + \\cos(2\\omega t+2\\varphi_u-\\theta)] \\]\n\\(p\u003e0\\)是电路吸收功率，\\(p\u003c0\\)是电路发出功率。\n或者也可以\n\\[p(t) = UI\\cos\\theta[1+\\cos 2(\\omega t+\\varphi_u)] + UI\\sin\\theta\\sin 2(\\omega t+\\varphi_u) \\]\n其中\\(UI\\cos\\theta[1+\\cos 2(\\omega t+\\varphi_u)]\\)为消耗功率，\\(UI\\sin\\theta\\sin 2(\\omega t+\\varphi_u)\\)为交换功率。\n平均功率\n\\[P = \\dfrac{1}{T}\\int^T_0 p(t)dt = \\dfrac{1}{T}\\int^T_0[UI\\cos\\theta + UI\\cos(2\\omega t+2\\varphi_u-\\theta)]dt \\]\n上式积分得\n\\[P = UI\\cos\\theta = \\dfrac{1}{2}U_mI_m\\cos\\theta \\]\n其中\\(\\cos\\theta\\)为功率因数，\\(\\theta=\\varphi_u-\\varphi_i\\)为功率因数角。无源网络中为等效阻抗的阻抗角。\n如果\\(\\cos\\theta = 0\\)，其为纯电抗电路，\\(\\cos\\theta = 1\\)，其为纯电阻电路。\n平均功率实际上是电阻消耗的功率，也称为有功功率。\n无功功率\n\\[Q = UI\\sin\\theta \\]\n表示交换功率的最大值，单位\\(var\\)（乏）。\\(Q\\)的大小反映电路\\(N\\)与外电路交换功率的大小，由储能元件\\(L,C\\)决定。\n视在功率\n\\[S = UI \\]\n反映电气设备的容量。\nRLC的有功和无功功率\n\\(P_R=UI,Q_R=0\\)，电阻只吸收功率，不发出功率\n\\(P_L=0,Q_L=UI\\)，电感不消耗功率，\\(u\\)超前\\(i90\\degree\\)\n\\(P_C=0,Q_C=-UI\\)，电容不消耗功率，\\(i\\)超前\\(u90\\degree\\)\n可见二端电路中只有电阻在消耗功率，电感和电容不消耗功率，只储存能量、交换能量。\n复功率 \\[\\~S = P+jQ \\]\n可以计算得到\n\\[\\~S = Ue^{j\\varphi_u}Ie^{-j\\varphi_i} = \\dot U\\dot I^* = Se^{j\\theta} \\]\n\\[S = \\sqrt{P^2+Q^2} \\]\n其中\\(\\dot I^* = Ie^{-j\\varphi_i}\\)是\\(\\dot I\\)的共轭值。\n功率与阻抗、导纳的关系为\n\\[\\~S = ZI^2 = RI^2+jXI^2 \\]\n\\[P = RI^2,Q=XI^2,S=|Z|I^2 \\]\n\\[\\~S = Y^*U^2 = GU^2-jBU^2 \\]\n\\[P = GU^2,Q=-BU^2,S=|Y|U^2 \\]\n对于正弦稳态电路，利用特勒根定理可以证明\n\\[\\sum\\~S = 0 \\]\n拆开为\n\\[\\sum P = \\sum UI\\cos\\theta = 0\\\\ \\sum Q = \\sum UI\\sin\\theta = 0 \\]\n即对于正弦稳态电路，电路的总有功功率之代数和等于零，或者说，电路中发出的各有功功率之和等于吸收的各有功功率之和；电路的总无功功率之代数和恒等于零。\n注意复功率守恒不等于视在功率守恒。并且一般\\(S\\neq\\sum S_k\\)\n多频电路的响应和平均功率 多频电路响应\n我们可以把多个频率不相同的激励源先计算单独作用时的响应，再利用叠加定理计算多频电路响应。\n多频电路瞬时功率\n同样先计算单独作用时的电流，这里假设有两个，为\\(i_1(t),i_2(t)\\)\n\\[p_R(t) = R[i_1(t)+i_2(t)]^2 = p_1(t)+p_2(t) + 2Ri_1(t)i_2(t) \\]\n多频电路平均功率\n当\\(i_1(t),i_2(t)\\)的频率之比为有理数，且不相等时\n\\[P_R = P_1 + P_2 \\]\n如果相等时\n\\[P_R = P_1 + P_2 + RI_{m1}I_{m2}\\cos(\\varphi_1-\\varphi_2) \\]\n非正弦周期信号平均功率\n可以把电压和电流展开为傅里叶级数，即分解为直流和各次谐波分量之和\n\\[u(t) = U_0 + \\sum^N_{k=1}\\sqrt 2U_k\\cos(k\\omega t+\\mu_{u_k}) \\]\n\\[i(t) = I_0 + \\sum^N_{k=1}\\sqrt 2I_k\\cos(k\\omega t+\\mu_{i_k}) \\]\n则该一端口电路吸收的平均功率为\n\\[P = U_0I_0+\\sum^N_{k=1}U_kI_k\\cos\\theta_k = P_0 + \\sum^N_{k=1}P_k\\quad(\\theta_k = \\varphi_{u_k}-\\varphi_{i_k}) \\]\n电压和电流的有效值为\n\\[U = \\sqrt{\\sum^N_{k=0}U_k^2} \\]\n\\[I = \\sqrt{\\sum^N_{k=0}I_k^2} \\]\n最大功率传输条件 讨论正弦稳态电路中负载\\(Z_L\\)获得最大功率\\(P_{\\max}\\)的条件。\n23.jpg\r共轭匹配\n\\[Z_L = R_L + jX_L \\]\n其中\\(R_L,X_L\\)可以独立调节时\n\\[P_{\\max} = \\dfrac{U_s^2}{4R_s} \\]\n条件是\\(Z_L = Z_S^*\\)，即\\(R_L=R_S,X_L=-X_S\\)\n模匹配\n若\\(Z_L = R_L+jX_L=|Z_L|\\angle\\theta\\)，\\(|Z_L|\\)可变，\\(\\theta\\)不变，此时\n\\[P_{\\max} = \\dfrac{\\cos\\theta U_s^2}{2|Z_S|+2(R_S\\cos\\theta+X_S\\sin\\theta)} \\]\n条件是\\(|Z_L|=|Z_S|\\)\n","date":"2022-09-02T11:22:59+08:00","image":"https://kegalas.top/inferior/%E7%94%B5%E8%B7%AF%E5%9F%BA%E7%A1%80%E6%95%B4%E7%90%86/cover_hu0536c6b8cad2f38cd8d175ab5c2d8577_29925_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E7%94%B5%E8%B7%AF%E5%9F%BA%E7%A1%80%E6%95%B4%E7%90%86/","title":"电路基础整理"},{"content":"复数与复变函数 复数的定义及其运算 把负数定义为一堆有序的实数\\((a,b)\\)，如果用\\(\\bm R\\)作为实数集，\\(\\bm C\\)为复数集，则\n\\[\\bm C = \\{(a,b):a\\in\\bm R,b\\in\\bm R\\} \\]\n定义加法和乘法如下\n\\[(a,b)+(c,d)=(a+c,b+d) \\]\n\\[(a,b)(c,d)=(ac-bd,ad+bc) \\]\n易知，加法和乘法满足交换率和结合律。\n\\((0,0)\\)是零元素，\\((-a,-b)\\)是\\((a,b)\\)的负元素，\\((1,0)\\)是乘法的单位元素。每个非零元素\\((a,b)\\)的逆元素是\\((\\frac{a}{a^2+b^2},-\\frac{b}{a^2+b^2})\\)\n此外还满足分配律\n\\[[(a,b)+(c,d)](e,f) = (a,b)(e,f)+(c,d)(e,f) \\]\n可以直接记\\((a,0)=a\\)。\n对于\\((0,1)\\)有\n\\[(0,1)^2=(-1,0)=-1 \\]\n记为\\((0,1)=i\\)\n同样有\\((0,b)=(b,0)(0,1)=bi\\)\n于是每一个复数都可以写成\n\\[(a,b)=(a,0)+(0,b)=a+bi \\]\n定理1\n复数域不是有序域，换句话说，不可以比较大小。\n出于方便和其他一些原因，用\\(z=a+bi\\)来描述复数，\\(a\\)称为\\(z\\)的实部，\\(b\\)称为\\(z\\)的虚部。可以记为\\(a=Rez,b=Imz\\)。\n四则运算\n加法\n\\[(a+bi)+(c+di)=(a+c)+(b+d)i \\]\n乘法\n\\[(a+bi)(c+di)=(ac-bd)+(ad+bc)i \\]\n减法\n\\[(a+bi)-(c+di)=(a-c)+(b-d)i \\]\n除法\n\\[\\frac{a+bi}{c+di}=(a+bi)\\left(\\frac{c-di}{c^2+d^2}\\right)=\\frac{ac+bd}{c^2+d^2}+\\frac{bc-ad}{c^2+d^2}i \\]\n模\n\\[|z|=\\sqrt{a^2+b^2} \\]\n共轭\n\\[\\overline{z}=a-bi \\]\n定理2\n\\(Rez=(z+\\overline{z})/2,Imz=(z-\\overline z)/2i\\) \\(z\\overline z=|z|^2\\) \\(\\overline{z+w}=\\overline z+\\overline w,\\overline{zw}=\\overline z\\cdot\\overline w,\\overline{z/w}=\\overline{z}/\\overline{w}\\) \\(|zw|=|z||w|,|z/w|=|z|/|w|\\) \\(|z|=|\\overline z|\\) \\(|Rez|\\leq |z|,|Imz|\\leq|z|\\) \\(|z+w|\\leq|z|+|w|\\)当且仅当存在一个\\(t\\geq 0,z=tw\\)时取等。 \\(|z-w|\\geq||z|-|w||\\) 复数的几何表示 三角表示法\n复数能用上一节提到的实数对\\((a,b)\\)表示，同时就可以看成平面上的一个点。同样的，也可以用极坐标\\((r,\\theta)\\)表示，那么有，\n\\[a=rcos\\theta,b=rsin\\theta \\]\n所以复数也可以表示为\n\\[z=r(cos\\theta+isin\\theta) \\]\n其中\\(r=|z|\\)，\\(\\theta\\)称为辐角，记为\\(\\theta=Argz\\)。显然若\\(\\theta\\)是辐角，那么\\(\\theta+2k\\pi\\)也是辐角。但在\\(Argz\\)中，只有一个辐角满足\\(-\\pi\u003c\\theta\\leq\\pi\\)，称为辐角的主值，记为\\(argz\\)，所以有\n\\[Argz=argz+2k\\pi,\\quad k\\in Z \\]\n特别注意，模为0的复数的辐角没有意义。\n指数表示法\n由欧拉公式\n\\[e^{i\\theta}=cos\\theta+isin\\theta \\]\n得到\n\\[z=re^{i\\theta} \\]\nde Moivre公式\n设\\(z_1=r_1(cos\\theta_1+isin\\theta_1),\\cdots,z_n=r_n(cos\\theta_n+isin\\theta_n)\\)是给定的n个复数，数学归纳法可知\n\\[z_1\\cdots z_n=r_1\\cdots r_n[cos(\\theta_1+\\cdots+\\theta_n)+isin(\\theta_1+\\cdots+\\theta_n)] \\]\n作为特殊情况，有\n\\[z^n=r^n(\\cos n\\theta+i\\sin n\\theta) \\]\n同样对于负整数也是成立的\n\\[z^{-n}=r^{-n}(\\cos(-n\\theta)+i\\sin(-n\\theta)) \\]\n现在设\\(\\omega=r(\\cos\\theta+i\\sin\\theta)\\)是给定的，要求的\\(z=\\rho(\\cos\\varphi+i\\sin\\varphi)\\).由de Moivre公式，\\(z^n=\\omega\\)等价为\n\\[\\rho^n(\\cos n\\varphi+i\\sin n\\varphi)=r(\\cos\\theta+i\\sin\\theta) \\]\n所以\\(\\rho=\\sqrt[n]{r},n\\varphi=\\theta+2k\\pi,k=0,1,\\cdots,n-1\\).共有\\(n\\)个复数满足\\(z^n=w\\)，即\n\\[z=\\sqrt[n]{|\\omega |}\\left(\\cos\\frac{\\theta+2k\\pi}{n}+i\\sin\\frac{\\theta+2k\\pi}{n}\\right),k=0,1,\\cdots,n-1 \\]\n这\\(n\\)个复数恰好是以原点为中心，\\(\\sqrt[n]{|\\omega |}\\)为半径的圆的内接正\\(n\\)边形的顶点。\n\\(\\omega=1\\)时，若记\\(w=\\cos\\frac{2\\pi}{n}+i\\sin\\frac{2\\pi}{n}\\)，则\\(\\sqrt[n]{1}\\)的\\(n\\)个值为\n\\[1,w,w^2,\\cdots,w^{n-1} \\]\n称为\\(n\\)个单位根，如果用\\(\\sqrt[n]{\\omega}\\)的任一\\(n\\)次根，那么\\(\\omega\\)的\\(n\\)个\\(n\\)次根又可以表示为\n\\[\\sqrt[n]{\\omega}, \\sqrt[n]{\\omega}w,\\cdots,\\sqrt[n]{\\omega}w^{n-1} \\]\n扩充平面和复数的球面表示 因为需要，在\\(\\bm C\\)中引入一个新的数\\(\\infty\\)，其模是\\(\\infty\\)，辐角没有意义，运算规则如下\n\\[z\\pm\\infty = \\infty, z\\cdot \\infty = \\infty(z\\neq 0) \\]\n\\[\\frac{z}{\\infty} = 0, \\frac{z}{0} = \\infty(z\\neq 0) \\]\n而\\(0\\cdot \\infty\\)和\\(\\infty\\pm\\infty\\)不规定意义。引入之后的复数系记为\\(\\bm C_\\infty\\)。在复平面上，没有一个点和\\(\\infty\\)对应，但是我们想象有一个无穷远点和\\(\\infty\\)对应，加上无穷远点的复平面称为扩充平面或闭平面。否则是开平面。\n在复平面上，无穷远点和普通点是不一样的。但在黎曼引入的球面表示中没有什么区别。\n设\\(S\\)是\\(\\bm R^3\\)中的单位球面，即\n\\[S = \\{(x_1,x_2,x_3)\\in \\bm R^3:x_1^2+x_2^2+x_3^2=1\\} \\]\n把\\(\\bm C\\)等同于平面\n\\[\\bm C = \\{(x_1,x_2,0):x_1,x_2\\in \\bm R\\} \\]\n称\\(N=(0,0,1)\\)为北极点。在\\(\\bm C\\)上的任一一点\\(z\\)，连接\\(N,z\\)的直线必然和\\(S\\)交于一点\\(P\\)。若\\(|z|\u003e1\\)，则\\(P\\)在北半球；若\\(|z|\u003c1\\)，则\\(P\\)在南半球；若\\(|z|=1\\)，则\\(z\\)就是\\(P\\)。\n当\\(z\\)趋向\\(\\infty\\)时，球面上的点就会趋向于\\(N\\)，所以就可以把\\(\\infty\\)对应于\\(N\\)。这样一来\\(\\bm C_\\infty\\)中的所有点都可以被移植到球面上去了，并且所有的点一视同仁。\n设\\(z=x+iy\\)，则\\(P\\)的坐标为\n\\[x_1=\\frac{2x}{x^2+y^2+1},x_2=\\frac{2y}{x^2+y^2+1},x_3=\\frac{x^2+y^2-1}{x^2+y^2+1} \\]\n或者用复数表示为\n\\[x_1=\\frac{z+\\bar z}{1+|z|^2},x_2=\\frac{z-\\bar z}{i(1+|z|^2)},x_3=\\frac{|z|^2-1}{|z|^2+1} \\]\n同样也就可以用球面上的点来表示复数\n\\[z=\\frac{x_1+ix_2}{1-x_3} \\]\n复数列的极限 极限\n复数列\\(\\{z_n\\}\\)收敛到点\\(z_0\\)，指的是对于任给的\\(\\varepsilon\u003e0\\)，存在正整数\\(N\\)，当\\(n\u003eN\\)时，\\(|z_n-z_0|\u003c\\varepsilon\\)，记作\\(\\lim_{n\\to \\infty}z_n=z_0\\)\n复数列\\(\\{z_n\\}\\)收敛到\\(\\infty\\)，指的是对于任意正数\\(M\u003e0\\)，存在正整数\\(N\\)，当\\(n\u003eN\\)时，\\(|z_n|\u003eM\\)，记为\\(\\lim_{n\\to\\infty}z_n=\\infty\\)\n邻域\n对于\\(a\\in\\bm C,r\u003e0\\)，称\n\\[B(a,r)=\\{z\\in C:|z-a|\u003c r\\} \\]\n为以\\(a\\)为中心、以\\(r\\)为半径的圆盘，特别当\\(a=0,r=1\\)时称为单位圆盘。\\(B(a,r)\\)也称为\\(a\\)点的一个\\(r\\)邻域，或简称邻域。无穷远点的邻域是指集合\\(\\{z\\in \\bm C:|z|\u003eR\\}\\)，记为\\(B(\\infty, R)\\)\n此时极限有可以表示为：\n\\(\\lim_{n\\to \\infty}z_n=z_0\\)可以说成对任意\\(\\varepsilon\u003e0\\)，当\\(n\\)充分大时，\\(z_n\\in B(z_0,\\varepsilon)\\)\n\\(\\lim_{n\\to\\infty}z_n=\\infty\\)可以说成对任意\\(M\u003e0\\)，当\\(n\\)充分大时，\\(z_n\\in B(\\infty, M)\\)\n同时马上就可以得到，\\(\\lim_{n\\to \\infty}z_n=z_0\\)的充要条件是，其实部和虚部分别有\\(\\lim_{n\\to \\infty}x_n=x_0\\)和\\(\\lim_{n\\to \\infty}y_n=y_0\\)。\n开集、闭集和紧集 内点\n如果存在\\(r\u003e0\\)，使得\\(B(a,r)\\subset E\\)，就称\\(a\\)为\\(E\\)的内点\n外点\n如果存在\\(r\u003e0\\)使得\\(B(a,r)\\subset E^c\\)，就称\\(a\\)为\\(E\\)的外点。其中\\(E^c\\)是补集。\n边界点\n如果对于任意\\(r\u003e0\\)，\\(B(a,r)\\)中既有\\(E\\)的点，也有\\(E^c\\)的点，就称\\(a\\)为\\(E\\)的边界点。\n内部\n\\(E\\)的内点的全体称为\\(E\\)的内部，记为\\(E\\degree\\)\n外部\n\\(E\\)的外点的全体称为\\(E\\)的外部，记为\\((E^c)\\degree\\)\n边界\n\\(E\\)的边界点的全体称为\\(E\\)的边界，记为\\(\\partial E\\)\n开集\n如果\\(E\\)的所有点都是他的内点，即\\(E=E\\degree\\)，就称\\(E\\)是开集。\n另外，空集是开集。\n闭集\n如果\\(E^c\\)是开集，就称\\(E\\)为闭集。\n另外，无限集是闭集。\n极限点、聚点\n如果对任意\\(r\u003e0\\)，\\(B(a,r)\\)中除\\(a\\)外总有\\(E\\)中的点，则称\\(a\\)为极限点或聚点。\n导集\n集\\(E\\)的所有极限点构成的集称为\\(E\\)的导集，记为\\(E'\\)。\n孤立点\n\\(E\\)中不属于\\(E'\\)的点称为孤立点。\n闭包\n\\(E\\)和它的导集的并称为\\(E\\)的闭包，记为\\(\\bar E=E\\cup E'\\)\n直径\n点集\\(E\\)的直径定义为\\(E\\)中任意两点间距离的上确界，记为\\(diamE\\)，即\n\\[diamE=sup\\{|z_1-z_2|:z_1,z_2\\in E\\} \\]\nCantor定理\n若非空闭集序列\\(\\{F_n\\}\\)满足\n\\(F_1\\supset F_2\\supset\\cdots\\supset F_n\\supset\\cdots\\) \\(diamF_n\\to 0\\)（当\\(n\\to \\infty\\)时） 那么\\(\\bigcap^\\infty_{n=1}F_n\\)是一个独点集（只有一个点的集）。\n开集族、开覆盖\n设\\(E\\)是一个集，\\(\\mathscr{F}=\\{G\\}\\)是一个开集族，即\\(\\mathscr{F}\\)中的每一个元素都是开集。如果\\(E\\)中每一点至少属于\\(\\mathscr{F}\\)中的一个开集，就说\\(\\mathscr{F}\\)是\\(E\\)的一个开覆盖。\n有限覆盖性质\n点集\\(E\\)具有有限覆盖性质，是指从\\(E\\)的任一个开覆盖中必能选出有限个开集\\(G_1,\\cdots,G_n\\)，使得这有限个开集的并就能覆盖\\(E\\)，即\n\\[E\\subset\\bigcup^n_{j=1}G_j \\]\n紧集\n具有有限覆盖性质的集称为紧集。\n有界\n集\\(E\\)称为是有界的，如果存在\\(R\u003e0\\)，使得\\(E\\subset B(0,R)\\)\nHeine-Borel定理\n在\\(C\\)中，\\(E\\)是紧集的充要条件为\\(E\\)是有界闭集；在\\(C_\\infty\\)中，\\(E\\)是紧集的充要条件为\\(E\\)是闭集。\n定理\n设\\(E\\)是紧集，\\(F\\)是闭集，且\\(E\\cap F=\\empty\\)，则\n\\[d(E,F) \u003e 0 \\]\n其中\n\\[d(E,F) = \\inf\\{|z_1-z_2|:z_1\\in E, z_2\\in F\\} \\]\nBolzano-Weierstrass定理\n任一无穷点集至少有一个极限点。\n曲线和域 连续曲线\n定义在闭区间\\([a,b]\\)上的一个复值连续函数\\(\\gamma:[a,b]\\to \\bm C\\)，写为\n\\[z = \\gamma(t)=x(t)+iy(t),\\quad a\\leq t\\leq b \\]\n这里\\(x(t),y(t)\\)都是\\([a,b]\\)上的连续函数。\n如果用\\(\\gamma^*\\)记\\(\\gamma\\)的像点所成的集合\n\\[\\gamma^* = \\{\\gamma(t):a\\leq t\\leq b\\} \\]\n那么\\(\\gamma^*\\)是\\(\\bm C\\)上的紧集。\n曲线\\(\\gamma\\)的方向就是\\(t\\)增加的方向。此时\\(\\gamma(a)\\)为起点，\\(\\gamma(b)\\)为终点。\n闭曲线\n如果\\(\\gamma(a)=\\gamma(b)\\)，则称为闭曲线。\n简单曲线\n如果当且仅当\\(t_1=t_2\\)时才有\\(\\gamma(t_1)=\\gamma(t_2)\\)，则称为简单曲线或Jordan曲线。\n简单闭曲线\n如果当且仅当如果当且仅当\\(t_1=a,t_2=b\\)时才有\\(\\gamma(t_1)=\\gamma(t_2)\\)，则称为简单闭曲线或Jordan闭曲线，或简称围道。\n可求长的\n设\\(z=\\gamma(t)\\)是一条曲线，对区间\\([a,b]\\)做分割\\(a=t_0\u003c t_1\u003c\\cdots\u003c t_n=b\\)，得到以\\(z_k=\\gamma(t_k)\\)为顶点的折线\\(P\\)，那么\\(P\\)的长度为\n\\[|P|=\\sum_{k=1}^n|\\gamma(t_k)-\\gamma(t_{k-1})| \\]\n如果不论如何分割区间\\([a,b]\\)，所得折线的长度都是有界的，就称曲线\\(\\gamma\\)是可求长的，其长度定义为\\(\\gamma\\)的上确界。\n光滑曲线\n如果\\(\\gamma'(t)=x'(t)+iy'(t)\\)存在，且\\(y'(t)\\neq 0\\)，那么\\(\\gamma\\)在每一点都有切线，\\(\\gamma'(t)\\)就是曲线\\(\\gamma\\)在\\(\\gamma(t)\\)处的切向量，它与正实轴的夹角为\\(Arg\\gamma'(t)\\)，\n如果\\(\\gamma'(t)\\)是连续函数，那么\\(\\gamma\\)的切线随\\(t\\)而连续变动，这时称\\(\\gamma\\)为光滑曲线。\n此时\\(\\gamma\\)的长度为\n\\[\\int^b_a \\sqrt{(x'(t))^2+(y'(t))^2}dt = \\int^b_a|\\gamma'(t)|dt \\]\n曲线\\(\\gamma\\)称为逐段光滑的。\n如果存在\\(t_0,t_1,\\cdots,t_n\\)，使得\\(a=t_0\u003c t_1\u003c\\cdots\u003c t_n=b\\)，\\(\\gamma\\)在每个参数区间\\([t_{j-1},t_j]\\)上是光滑的，那么在每个分点\\(t_1,\\cdots,t_{n-1}\\)处\\(\\gamma\\)的左右导数存在。\n连通性\n平面点集\\(E\\)称为是联通的，如果对任意两个不相交的非空集\\(E_1\\)和\\(E_2\\)满足\n\\[E = E_1\\bigcup E_2 \\]\n那么\\(E_1\\)必含有\\(E_2\\)的极限点，或者\\(E_2\\)必含有\\(E_1\\)的极限点，也就是说，\\(E_1\\cap\\bar E_2\\)和\\(E_2\\cap\\bar E_1\\)至少有一个非空。\n定理1\n平面上的非空开集\\(E\\)是连通的充分必要条件是：\\(E\\)中任意两点可用位于\\(E\\)中的折线连接起来。\n域\n非空的连通开集称为域\nJordan定理\n一条简单闭曲线\\(\\gamma\\)吧复平面分成两个域，其中一个是有界的，称为\\(\\gamma\\)的内部；另一个是无界的，称为\\(\\gamma\\)的外部，而\\(\\gamma\\)是这两个域的共同的边界。\n单连通与多连通\n域\\(D\\)称为是单连通的，如果\\(D\\)内任意简单闭曲线的内部仍在\\(D\\)内。\n不是单连通的域称为多连通的。\n如果域\\(D\\)是由\\(n\\)跳简单闭曲线围成的，就称\\(D\\)是\\(n\\)连通的，简单闭曲线中也可以有退化成一条简单曲线或一点的。\n复变函数的极限和连续性 设\\(E\\)是复平面上一点集，如果对每一个\\(z\\in E\\)，按照某一规则有一确定复数\\(\\omega\\)与之对应，我们就说在\\(E\\)上确定了一个单值复变函数，记为\\(\\omega=f(z)\\)或\\(f:E\\to C\\)。\n\\(E\\)称为\\(f\\)的定义域，点集\\(\\{f(z):z\\in E\\}\\)称为\\(f\\)的值域。\n如果对于\\(z\\in E\\)，对应的\\(\\omega\\)有几个或无穷多个，则称在\\(E\\)上确定了一个多值函数。\n复变函数是定义在平面点集上的，而它的值域也是一个平面点集，因此复变函数也称为映射，它把一个平面点集映成另一个平面点集。\n设\\(z=x+iy\\)，用\\(u\\)和\\(v\\)记\\(\\omega=f(z)\\)的实部和虚部，则有\n\\[\\omega=f(z)=u(z)+iv(z)=u(x,y)+iv(x,y) \\]\n这就是说，一个复变函数等价于两个二元的实变函数。\n极限\n设\\(f\\)是定义在点集\\(E\\)上的一个复变函数，\\(z_0\\)是\\(E\\)的一个极限点，\\(a\\)是给定的一个复数。如果对任意的\\(\\varepsilon\u003e0\\)，存在于\\(\\varepsilon\\)有关的\\(\\delta\u003e0\\)，使得当\\(z\\in E\\)且\\(0\u003c|z-z_0|\u003c\\delta\\)时有\\(|f(z)-a|\u003c\\varepsilon\\)，就说当\\(z\\to z_0\\)时\\(f(z)\\)有极限\\(a\\)，记作\\(\\lim_{z\\to z_0}f(z)=a\\)。\n\\(\\lim_{z\\to z_0}f(z)=a\\)的充分必要条件是\n\\[\\lim_{x\\to x_0,y\\to y_0}u(x,y)=\\alpha,\\lim_{x\\to x_0,y\\to y_0}v(x,y)=\\beta \\]\n连续\n我们说\\(f\\)在点\\(z_0\\in E\\)连续，如果\n\\[\\lim_{z\\to z_0}f(z)=f(z_0) \\]\n如果\\(f\\)在集\\(E\\)中每点都连续，就说\\(f\\)在集\\(E\\)上连续。\n定理\n设\\(E\\)是\\(\\bm C\\)中的紧集，\\(f:E\\to\\bm C\\)在\\(E\\)上连续，那么\n\\(f\\)在\\(E\\)上有界 \\(|f|\\)在\\(E\\)上能取得最大值和最小值，即存在\\(a,b\\in E\\)使得对于每个\\(z\\in E\\)都有 \\[|f(z)|\\leq |f(a)|，|f(z)|\\geq|f(b)| \\]\n\\(f\\)在\\(E\\)上一致连续。即对任意\\(\\varepsilon\u003e0\\)，存在只与\\(\\varepsilon\\)有关的\\(\\delta\u003e0\\)，对\\(E\\)上任意的\\(z_1,z_2\\)，只要\\(|z_1-z_2|\u003c\\delta\\)，就有\\(|f(z_1)-f(z_2)|\u003c\\varepsilon\\) 全纯函数/解析函数 复变函数的导数 设\\(f:D\\to\\bm C\\)是定义在域\\(D\\)上的函数，\\(z_0\\in D\\)，如果极限\n\\[\\lim_{z\\to z_0}\\frac{f(z)-f(z_0)}{z-z_0} \\]\n存在，就说\\(f\\)在\\(z_0\\)处复可导或可微，这个极限称为在此处的导数或微商。\n如果\\(f\\)在\\(D\\)中每点都可微，就称\\(f\\)是域\\(D\\)中的全纯函数或解析函数。\n如果\\(f\\)在\\(z_0\\)的一个邻域中全纯，就称\\(f\\)在\\(z_0\\)处全纯。\n定理1\n如果\\(f\\)在\\(z_0\\)处可微，则必在\\(z_0\\)处连续。反过来说则不一定成立。\n求复变函数的导数时，跟一元实变函数几乎没有什么区别，例如\\(f(z)=z^3, f'(z)=3z^2\\)。但是更加严格的一点时，在复平面上任何一个方向上的导数都要相等，而不是一元实变函数左右相等。\n实变函数的四则运算的求导法则在全纯函数中也成立。\n定理2\n设\\(D_1,D_2\\)是\\(\\bm C\\)中的两个域，且\n\\[f:D_1\\to D_2\\\\ g:D_2\\to\\bm C \\]\n都是全纯函数，那么\\(h=g\\circ f\\)是\\(D_1\\to \\bm C\\)的全纯函数，并且\\(h'(z)=g'(f(z))f'(z)\\)\nCauchy-Riemann方程 实可微\n设\\(f(z)=u(x,y)+iv(x,y)\\)是定义在域\\(D\\)上的函数，\\(z_0=x_0+iy_0\\in D\\).我们说\\(f\\)在\\(z_0\\)处实可微，是指\\(u,v\\)作为\\(x,y\\)的二元函数在\\((x_0,y_0)\\)处可微。\n设\\(f:D\\to C\\)是定义在域\\(D\\)上的函数，\\(z_0\\in D\\)，那么\\(f\\)在\\(z_0\\)处实可微的充要条件是下式成立\n\\[f(z_0+\\Delta z)-f(z_0)=\\frac{\\partial f}{\\partial z}(z_0)\\Delta z+\\frac{\\partial f}{\\partial \\bar z}(z_0)\\Delta z+o(|\\Delta z|) \\]\n其中算子定义如下\n\\[\\frac{\\partial}{\\partial z}=\\frac{1}{2}\\left(\\frac{\\partial}{\\partial x}-i\\frac{\\partial}{\\partial y}\\right) \\]\n\\[\\frac{\\partial}{\\partial \\bar z}=\\frac{1}{2}\\left(\\frac{\\partial}{\\partial x}+i\\frac{\\partial}{\\partial y}\\right) \\]\n在进行微分运算时，可以把\\(z,\\bar z\\)看成独立的变量。\n柯西-黎曼方程\n设\\(f\\)是定义在域\\(D\\)上的函数，\\(z_0\\in D\\)，那么\\(f\\)在\\(z_0\\)处可微的充要条件是\\(f\\)在\\(z_0\\)处实可微且\\(\\frac{\\partial f}{\\partial \\bar z}(z_0)=0\\).\n在可微的情况下，\\(f'(z_0)=\\frac{\\partial f}{\\partial z}(z_0)\\).\n其中\\(\\frac{\\partial f}{\\partial \\bar z}(z_0)=0\\)就称为柯西-黎曼方程。\n将\\(u,v\\)代入以及算子展开，可以得到其等价于\n\\[\\left\\{\\begin{matrix} \\frac{\\partial u}{\\partial x}=\\frac{\\partial v}{\\partial y} \\\\ \\frac{\\partial u}{\\partial y}=-\\frac{\\partial v}{\\partial x} \\end{matrix}\\right. \\]\n设\\(D\\)是\\(\\bm C\\)中的域，用\\(C(D)\\)表示\\(D\\)上连续函数的全体，\\(H(D)\\)表示\\(D\\)上全纯函数的全体。\n用\\(C^1(D)\\)记\\(\\frac{\\partial f}{\\partial x},\\frac{\\partial f}{\\partial y}\\)在\\(D\\)上连续的\\(f\\)的全体。\n\\(C^k(D)\\)记在\\(D\\)上有\\(k\\)阶连续偏导数的函数的全体，\\(C^\\infty(D)\\)记在\\(D\\)上有任意阶连续偏导数的函数的全体。\n之后我们用柯西积分公式证明，有\n\\[H(D)\\subset C^\\infty(D)\\subset C^k(D)\\subset C^1(D)\\subset C(D) \\]\n即域\\(D\\)上的全纯函数在\\(D\\)上有任意阶的连续偏导数。\n调和函数\n设\\(u\\)是域\\(D\\)上的实值函数（或称二元实变函数），如果\\(u\\in C^2(D)\\)，且对于任意\\(z\\in D\\)，有\n\\[\\Delta u(z)=\\frac{\\partial^2u(z)}{\\partial x^2}+\\frac{\\partial^2u(z)}{\\partial y^2}=0 \\]\n就称\\(u\\)是\\(D\\)中的调和函数。\n\\[\\Delta=\\frac{\\partial^2}{\\partial x^2}+\\frac{\\partial^2}{\\partial y^2} \\]\n称为拉普拉斯算子。\n定理1\n设\\(f=u+iv\\in H(D)\\)，那么\\(u,v\\)都是\\(D\\)上的调和函数。\n共轭调和函数\n设\\(u,v\\)是\\(D\\)上的一对调和函数，如果它们还满足柯西-黎曼方程，\n\\[\\left\\{\\begin{matrix} \\frac{\\partial u}{\\partial x}=\\frac{\\partial v}{\\partial y} \\\\ \\frac{\\partial u}{\\partial y}=-\\frac{\\partial v}{\\partial x} \\end{matrix}\\right. \\]\n就称\\(v\\)为\\(u\\)的共轭调和函数。\n定理1\n设\\(u\\)是单连通域\\(D\\)上的调和函数，则必存在\\(u\\)的共轭函数\\(v\\)，使得\\(u+iv\\)是\\(D\\)上的全纯函数。\n其中\n\\[v(x,y) = \\int^{(x,y)}_{(x_0,y_0)}\\dfrac{\\partial v}{\\partial x}dx+\\dfrac{\\partial v}{\\partial y}dy = \\int^{(x,y)}_{(x_0,y_0)}-\\dfrac{\\partial u}{\\partial y}dx+\\dfrac{\\partial u}{\\partial x}dy \\]\n且这个积分与路径无关。\n反过来说如果有\\(v\\)，则也必存在\\(u\\)\n\\[u(x,y) = \\int^{(x,y)}_{(x_0,y_0)}\\dfrac{\\partial u}{\\partial x}dx+\\dfrac{\\partial u}{\\partial y}dy = \\int^{(x,y)}_{(x_0,y_0)}\\dfrac{\\partial v}{\\partial y}dx-\\dfrac{\\partial v}{\\partial x}dy \\]\n导数的几何意义 过\\(z_0\\)点作一条光滑曲线\\(\\gamma\\)，它的方程为\n\\[z = \\gamma(t),a\\leq t\\leq b \\]\n设\\(\\gamma(a)=z_0,\\gamma'(a)\\neq 0\\)。\\(\\gamma\\)在点\\(z_0\\)处的切线与正实轴的夹角为\\(Arg\\gamma'(a)\\)。设\\(\\omega = f(z)\\)把曲线\\(\\gamma\\)映为\\(\\sigma\\)，它的方程为\n\\[\\omega=\\sigma(t)=f(\\gamma(t)),a\\leq t\\leq b \\]\n由于\\(\\sigma'(a)=f'(\\gamma(a))\\gamma'(a)=f'(z_0)\\gamma'(a)\\neq 0\\)，所以\\(\\sigma\\)在\\(\\omega_0=f(z_0)\\)处的切线与正实轴的夹角为\n\\[Arg\\sigma'(a) = Argf'(z_0)+Arg\\gamma'(a) \\]\n或者写为\n\\[Arg\\sigma'(a) - Arg\\gamma'(a) = Argf'(z_0) \\]\n这就说明像曲线\\(\\sigma\\)在\\(\\omega_0\\)处的切线与正实轴的夹角与原曲线\\(\\gamma\\)在\\(z_0\\)处的切线与正实轴的夹角之差总是\\(Argf'(z_0)\\)，而与曲线\\(\\gamma\\)无关，\\(Argf'(z_0)\\)就称为映射\\(\\omega=f(z)\\)在\\(z_0\\)处的转动角。\n过点\\(z_0\\)作两条光滑曲线\\(\\gamma_1,\\gamma_2\\)，它们的方程分别为\n\\[z=\\gamma_1(t),a\\leq t\\leq b \\]\n和\n\\[z=\\gamma_2(t),a\\leq t\\leq b \\]\n且\\(\\gamma_1(a)=\\gamma_2(a)=z_0\\)。映射\\(\\omega=f(z)\\)把它们分别映为过\\(\\omega_0\\)点的两条光滑曲线\\(\\sigma_1\\)和\\(\\sigma_2\\)，他们的方程分别为\n\\[\\omega = \\sigma_1(t)=f(\\gamma_1(t)),a\\leq t\\leq b \\]\n\\[\\omega = \\sigma_2(t)=f(\\gamma_2(t)),a\\leq t\\leq b \\]\n因为\\(\\sigma'(a)=f'(\\gamma(a))\\gamma'(a)=f'(z_0)\\gamma'(a)\\neq 0\\)，所以有\n\\[Arg\\sigma'(a) = Argf'(z_0)+Arg\\gamma'(a) \\]\n或者写为\n\\[Arg\\sigma'(a)-Arg\\gamma'(a) = Argf'(z_0) \\]\n由此就有\n\\[Arg\\sigma_1'(a)-Arg\\gamma_1'(a) = Argf'(z_0) = Arg\\sigma_2'(a)-Arg\\gamma_2'(a) \\]\n上式说明，如果\\(f'(z_0)\\neq 0\\)，那么在映射\\(\\omega=f(z)\\)的作用下，过\\(z_0\\)点的任意两条光滑曲线的夹角的大小与旋转方向都是保持不变的。\n我们把这种性质的映射称为在\\(z_0\\)点是保角的。\n定理\n全纯函数在其导数不为零的点处是保角的。\n导数的模的几何意义\n\\(|f'(z_0)|\\)为\\(f\\)在\\(z_0\\)处的伸缩率。\n像点之间的距离与原像之间的距离之比只与\\(z_0\\)有关，而与\\(\\gamma\\)无关。\n共形映射的概念\n综合导数辐角和模的几何意义，我们看到：如果\\(f'(z_0)\\neq0\\)，在\\(z_0\\)的邻域中，作一个以\\(z_0\\)为顶点的小三角形，这个小三角形被\\(f\\)映射为一个曲边三角形，它的微分三角形和原来的小三角形相似。因此，我们把这样的一个映射称为共形映射。\n更形式化的定义是：设函数\\(\\omega=f(z)\\)在\\(z_0\\)的领域内有定义，且在\\(z_0\\)处具有保角性和伸缩率的不变性，那么称映射\\(\\omega=f(z)\\)是共形映射。如果对\\(D\\)内每一点都是共形的，那么\\(\\omega=f(z)\\)是在\\(D\\)内的共形映射。\n如果\\(\\omega=f(z)\\)在\\(z_0\\)全纯，\\(f'(z_0)\\neq 0\\)，那么其在\\(z_0\\)是共形的。\n如果\\(\\omega=f(z)\\)只保证伸缩率的不变性和夹角的绝对值不变（但方向相反），那么称为第二类共形映射，之前提到的属于第一类共形映射。\n初等全纯函数 指数函数 设\\(z=x+iy\\)，定义\n\\[e^z = e^x(\\cos y+i\\sin y) \\]\n具有如下性质\n\\((e^z)'=e^z\\) 复数的三角表示\\(z=r(\\cos\\theta+i\\sin\\theta)\\)可以表示为\\(z=re^{i\\theta}\\) 对于任意\\(z\\in \\bm C,e^z\\neq 0\\)，这是因为 \\[|e^z|=e^x\u003e0 \\]\n对于任意\\(z_1,z_2\\)，有 \\[e^{z_1}e^{z_2}=e^{z_1+z_2} \\]\n\\(e^z\\)是以\\(2\\pi i\\)为周期的周期函数。 单叶\n设\\(f:D\\to \\bm C\\)是一个复变函数，如果对于\\(D\\)中的任意两点\\(z_1,z_2(z_1\\neq z_2)\\)，必有\\(f(z_1)\\neq f(z_2)\\)，就称\\(f\\)在\\(D\\)中是单叶的，\\(D\\)称为\\(f\\)的单叶性域。\n\\(\\omega=e^z\\)的单叶性域有\n\\[\\{z=x+iy:2k\\pi\u003c y\u003c2(k+1)\\pi\\},k=0,\\pm1,\\cdots \\]\n对数函数 对于给定的\\(z\\in C\\)，满足方程\\(e^\\omega=z\\)的\\(\\omega\\)称为\\(z\\)的对数，记为\\(\\omega=Logz\\)。\n设\\(z=re^{i\\theta}\\)，\\(\\omega=u+iv\\)，则\\(e^{u+iv}=re^{i\\theta}\\)，所以\\(e^u=r,v=\\theta+2k\\pi\\)。所以有\n\\[Logz=log|z|+iargz+2k\\pi i=log|z|+iArgz \\]\n所以，\\(Logz\\)是一个多值函数，它的多值性是由\\(z\\)的辐角\\(Argz\\)的多值性产生的。\n定理1\n如果\\(D\\)是不包含原点和无穷远点的单连通域，则必在\\(D\\)上存在无穷多个单值全纯函数\\(\\varphi_k,k=0,\\pm1,\\cdots\\)，使得在\\(D\\)上成立\n\\[e^{\\varphi_k(z)}=z,k=0,\\pm1,\\cdots; \\]\n而且对每一个\\(k\\)，有\\(\\varphi_k'(z)=\\frac{1}{z}\\).其中的每一个\\(\\varphi_k\\)都称为\\(Logz\\)在\\(D\\)上的单值全纯分支。\n至于为什么不包含原点和无穷远点：如果包含原点，那么\\(D\\)中就包含绕原点\\(z=0\\)的简单闭曲线\\(\\gamma\\)，当\\(z\\)从\\(\\gamma\\)上的一点\\(z_0\\)沿\\(\\gamma\\)的正方向（即逆时针）回到\\(z_0\\)时，\\(z\\)的辐角增加了\\(2\\pi\\)，\\(\\varphi_{k_0}(z_0)\\)的值连续地变为\\(\\varphi_{k_0+1}(z_0)\\)，而不再回到原来的\\(\\varphi_{k_0}(z_0)\\)。因此再这样的域中就不可能分出单值的全纯分支。无穷远点同理。\n定义1\n如果当\\(z\\)沿着\\(z_0\\)的充分小邻域中的任意简单闭曲线绕一圈时，多值函数的值就从一支变到另一支，那么称\\(z_0\\)为该多值函数的一个支点。\n以对数函数为例，\\(z=0,z=\\infty\\)就是\\(Logz\\)的支点。\n幂函数 \\(\\omega=z^\\mu\\)称为幂函数，这里\\(\\mu=a+bi\\)，分情况讨论\n1. \\(\\mu=n\\)，是一个自然数\n按照导数的定义，可以直接算出\n\\[(z^n)'=nz^{n-1} \\]\n其在\\(C\\)上每一点都是全纯的。这种函数也称作整函数\n它的单叶性域是\n\\[\\bigg\\{z:\\alpha \u003c argz\u003c\\beta,0\u003c\\beta-\\alpha\\leq\\frac{2\\pi}{n}\\bigg\\} \\]\n2. \\(\\mu=\\frac{1}{n}\\)，n是一个自然数\n对于一个给定的\\(z\\)，\\(z^{1/n}\\)有\\(n\\)个值，所以它是一个多值函数。多值性由\\(Argz\\)产生，\\(0,\\infty\\)是其支点。\\(C\\)去掉正实轴后所成的域上可以分出\\(n\\)个单值的全纯分支，它们是\n\\[\\omega = \\varphi_k(z) = \\sqrt[n]{|z|}\\bigg(\\cos\\frac{\\theta+2k\\pi}{n}+i\\sin\\frac{\\theta+2k\\pi}{n}\\bigg) \\]\n\\[k=0,1,\\cdots,n-1 \\]\n其中\\(\\theta=argz\\)，变化范围在\\(0\u003c argz\u003c2\\pi\\)\n3. \\(\\mu = a+bi\\)，是一个复数\n一般的幂函数\\(\\omega=z^\\mu\\)定义为\n\\[\\omega = z^\\mu=e^{\\mu Logz} \\]\n显然这也是个多值函数\n\\[\\omega = exp(alog|z|-b(argz+2k\\pi))exp(i[blog|z|+a(argz+2k\\pi)]) \\]\n\\[k=0,\\pm1,\\cdots \\]\n若\\(b=0,a=n\\)是一个整数，则\\(\\omega=z^n\\)是一个单值函数 若\\(b=0,a=p/q\\)是一个有理数，不妨设\\(p\u003c q\\)，这时 \\[\\omega=z^\\mu=z^{p/q}=|z|^{p/q}exp(i\\frac{p}{q}(argz+2k\\pi)) \\]\n当\\(k=0,1,\\cdots,q-1\\)时，\\(\\omega\\)有\\(q\\)个不同的值\n若\\(b=0,a\\)是一个无理数，这时 \\[\\omega = z^\\mu = |z|^aexp(iaargz)exp(i2k\\pi a) \\]\n此时\\(z^a\\)是一个无穷值函数\n若\\(b\\neq 0\\)，则\\(\\omega=z^\\mu\\)是一无穷值函数。 三角函数 由欧拉公式知道\n\\[e^{ix} = \\cos x+i\\sin x\\\\ e^{-ix} = \\cos x -i\\sin x \\]\n可以得到\n\\[\\cos z = \\frac{1}{2}(e^{iz}+e^{-iz})\\\\ \\sin z = \\frac{1}{2i}(e^{iz}-e^{-iz}) \\]\n有如下性质\n正弦余弦都是整函数，并且 \\[(\\cos z)' = -\\sin z\\\\ (\\sin z)' = \\cos z \\]\n以\\(2\\pi\\)为周期 \\(\\cos z\\)是偶函数，\\(\\sin z\\)是奇函数 对任意\\(z_1,z_2\\) \\[\\cos (z_1+z_2) = \\cos z_1\\cos z_2 - \\sin z_1\\sin z_2\\\\ \\sin (z_1+z_2) = \\sin z_1\\cos z_2 + \\cos z_1\\sin z_2\\\\ \\]\n\\(\\cos^2 z+\\sin^2 z=1,\\quad \\sin 2z = 2\\sin z\\cos z\\) \\(\\sin z\\)仅在\\(z=k\\pi\\)处为零，\\(\\cos z\\)仅在\\(k\\pi+\\pi/2\\)处为零，\\(k=0,\\pm1,\\cdots\\) \\(\\cos z,\\sin z\\)不是有界函数 同样我们就能定义正切余切\n\\[\\tg z = \\frac{\\sin z}{\\cos z} \\]\n\\[\\ctg z = \\frac{\\cos z}{\\sin z} \\]\n前者在除掉\\(z=\\pi/2+k\\pi\\)的开平面上全纯，后者在除掉\\(z=k\\pi\\)的开平面上全纯，\\(k=0,\\pm1,\\cdots\\)。\n之后我们也能定义双曲函数\n\\[chz=\\frac{e^z+e^{-z}}{2},shz=\\frac{e^z-e^{-z}}{2} \\]\n并且有\n\\[(chz)'=shz,(shz)'=chz \\]\n反三角函数有\n\\[Arcsinz=-iLn(iz+\\sqrt{1-z^2}) \\]\n\\[Arccosz=-iLn(z+\\sqrt{z^2-1}) \\]\n\\[Arctanz=-\\frac{i}{2}Ln\\frac{1+iz}{1-iz} \\]\n反双曲函数有\n\\[Arshz = Ln(z+\\sqrt{z^2+1}) \\]\n\\[Archz = Ln(z+\\sqrt{z^2-1}) \\]\n\\[Arthz = \\frac{1}{2}Ln\\frac{1+z}{1-z} \\]\n分式线性变换 形如\\(\\omega=T(z)=\\frac{az+b}{cz+d}\\)的映射称为分式线性变换或Mobius变换，其中\\(a,b,c,d\\)是复常数，且满足\\(ad-bc\\neq 0\\)，如果等于\\(0\\)原式就是常数或无意义，没有讨论价值。\n如果\\(c\\neq 0\\)，则除去点\\(z=-\\frac{d}{c}\\)外，\\(T(z)\\)在\\(\\bm C\\)上是全纯的，而且\n\\[T'(z)=\\frac{ad-bc}{(cz+d)^2}\\neq 0 \\]\n所以分式线性变换在\\(z\\neq -\\frac{d}{c}\\)处是保角变换。\n若\\(c=0\\)，则必\\(d\\neq 0\\)，此时\\(T(z)=Az+B(A=a/d,B=b/d)\\)，称为整线性变换，它是一个整函数。\n从方程\\(\\omega=T(z)\\)中把\\(z\\)解出来，得\n\\[z = T^{-1}(\\omega)=\\frac{-d\\omega+b}{c\\omega-a} \\]\n称为\\(\\omega=T(z)\\)的逆变换，它仍然是一个分式线性变换。由此可知\\(\\omega=T(z)\\)在\\(\\bm C\\)上是单叶的，当\\(c\\neq 0\\)时，规定\\(T(-\\frac{d}{c})=\\infty,T(\\infty)=\\frac{a}{c}\\)。当\\(c=0\\)时，规定\\(T(\\infty)=\\infty\\)，于是\\(\\omega=T(z)\\)把\\(\\bm C_\\infty\\)单叶地映射为\\(C_\\infty\\)。\n设\\(S,T\\)是两个分式线性变换，那么\\(S\\circ T\\)也是分式线性变换。且对每一个\\(T\\)，都有逆变换\\(T^{-1}\\)，即\\(T(T^{-1}(z))=z\\)\n分式线性变换有如下性质\n保角性 分式线性变换把圆周变成圆周（保圆性） 分式线性变换也能拆成多个变换，例如\n\\[\\omega = \\dfrac{az+b}{cz+d} \\]\n就可以拆成三个变换\n\\[z' = cz+d\\\\ z'' = \\dfrac{1}{z'}\\\\ \\omega=\\alpha+\\beta z'' \\]\n其中\\(\\alpha = \\dfrac{a}{c},\\beta=\\dfrac{bc-ad}{c}\\)。\n这个变换中第一个第三个是整线性变换，也就是进行了伸缩和平移变换。当然圆在伸缩和平移后还是一个圆。我们同样可以证明\\(\\omega=\\dfrac{1}{z}\\)把圆周变为圆周，此时我们证明了分式线性变换把圆周变为圆周。\n交比是分式线性变换的不变量 命题1\n分式线性变换\\(T\\)最多只有两个不动点，除非是恒等变换，即\\(T(z)\\equiv z\\)\n定义1\n设\\(z_1,z_2,z_3,z_4\\)是给定的四个点，其中至少有三个点是不相同的，称比值\n\\[\\frac{z_1-z_3}{z_1-z_4}\\bigg /\\frac{z_2-z_3}{z_2-z_4} \\]\n为这四个点的交比，记为\\((z_1,z_2,z_3,z_4)\\)\n规定\n\\[(\\infty,z_2,z_3,z_4)=\\frac{z_2-z_4}{z_2-z_3} \\]\n\\[(z_1,\\infty,z_3,z_4)=\\frac{z_1-z_3}{z_1-z_4} \\]\n\\[(z_1,z_2,\\infty,z_4)=\\frac{z_2-z_4}{z_1-z_4} \\]\n\\[(z_1,z_2,z_3,\\infty)=\\frac{z_1-z_3}{z_2-z_3} \\]\n按照交比的定义，有\n\\[(z,z_2,z_3,z_4)=\\frac{z-z_3}{z-z_4}\\cdot\\frac{z_2-z_4}{z_2-z_3} \\]\n它是一个分式线性变换，若把它记为\\(L(z)\\)，那么\n\\[L(z_2)=1,\\\\ L(z_3)=0,\\\\ L(z_4)=\\infty. \\]\n定理1\n有且只有一个分式线性变换把\\(\\bm C_\\infty\\)上三个不同的点\\(z_2,z_3,z_4\\)映为事先给定的\\(\\bm C_\\infty\\)上的三个点\\(\\omega_2,\\omega_3,\\omega_4\\)\n定理2\n交比是分式线性变换的不变量。也就是说，如果分式线性变换\\(T\\)把\\(z_1,z_2,z_3,z_4\\)映为\\(T(z_1),T(z_2),T(z_3),T(z_4)\\)，那么\n\\[(z_1,z_2,z_3,z_4)=(T(z_1),T(z_2),T(z_3),T(z_4)) \\]\n定理3\n如果\\(f(z_1,z_2,z_3,z_4)\\)是分式线性变换下的不变量，即对任意分式线性变换\\(T\\)都有\n\\[f(z_1,z_2,z_3,z_4) = f(T(z_1),T(z_2),T(z_3),T(z_4)) \\]\n那么\\(f\\)只能是交比\\((z_1,z_2,z_3,z_4)\\)的函数。\n命题2\n四点\\(z_1,z_2,z_3,z_4\\)共圆的充要条件是\n\\[Im(z_1,z_2,z_3,z_4)=0 \\]\n定义2\n设\\(\\bm C_\\infty\\)上的圆周\\(\\gamma\\)把平面分成\\(g_1\\)和\\(g_2\\)两个域，\\(z_1,z_2,z_3\\)是\\(\\gamma\\)上有序的三个点。如果当我们从\\(z_1\\)走到\\(z_2\\)再走到\\(z_3\\)时，\\(g_1\\)和\\(g_2\\)分别在我们的左边和右边，就分别称\\(g_1\\)和\\(g_2\\)为\\(\\gamma\\)关于走向\\(z_1,z_2,z_3\\)的左边和右边\n命题3\n\\(z_1,z_2,z_3\\)是\\(\\bm C_\\infty\\)上的圆周\\(\\gamma\\)上有序的三个点，那么\\(\\gamma\\)关于走向\\(z_1,z_2,z_3\\)的右边和左边的点\\(z\\)分别满足\n\\[Im(z,z_1,z_2,z_3)\u003e0\\\\ Im(z,z_1,z_2,z_3)\u003c0 \\]\n定理4\n设\\(\\gamma_1\\)和\\(\\gamma_2\\)是\\(\\bm C_\\infty\\)中的两个圆周，\\(z_1,z_2,z_3\\)是\\(\\gamma_1\\)上有序的三个点，如果分式线性变换\\(T\\)把\\(\\gamma_1\\)映为\\(\\gamma_2\\)，那么它一定把\\(\\gamma_1\\)关于走向\\(z_1,z_2,z_3\\)的右边和左边分别变为\\(\\gamma_2\\)关于走向\\(T(z_1),T(z_2),T(z_3)\\)的右边和左边。\n对称点及其在分布线性变换下的不变性 定义1\n设\\(\\gamma\\)是以\\(a\\)为中心，以\\(R\\)为半径的圆周，如果点\\(z,z^*\\)在从\\(a\\)出发的射线上，且满足\n\\[|z-a||z^*-a|=R^2 \\]\n则称\\(z,z^*\\)是关于\\(\\gamma\\)对称的。如果\\(\\gamma\\)是直线时，则当\\(\\gamma\\)是线段\\([z,z^*]\\)的垂直平分线时，称\\(z,z^*\\)关于\\(\\gamma\\)是对称的。\n其中\n\\[z^* = a+\\dfrac{R^2}{\\bar{z}-\\bar{a}} \\]\n命题1\n设\\(\\gamma\\)是\\(\\bm C_\\infty\\)中的圆周，那么\\(z,z^*\\)关于\\(\\gamma\\)对称的充要条件是对\\(\\gamma\\)上任意三点\\(z_1,z_2,z_3\\)，有\n\\[(z^*,z_1,z_2,z_3)=\\overline{(z,z_1,z_2,z_3)} \\]\n对于直线的情形，可以看做无限半径的圆。\n定理1\n对称点在分式线性变换下不变。这就是说，设分式线性变换\\(T\\)把圆周\\(\\gamma\\)变为\\(\\Gamma\\)，如果\\(z,z^*\\)是关于\\(\\gamma\\)的对称点，那么\\(T(z),T(z^*)\\)是关于\\(\\Gamma\\)的对称点。\n全纯函数的积分表示 复变函数的积分 设\\(z=\\gamma(t)(a\\leq t\\leq b)\\)是一条可求长曲线，\\(f\\)是定义在\\(\\gamma\\)上的函数，沿\\(\\gamma\\)的正方向取分点\\(\\gamma(a)=z_0,z_1,z_2,\\cdots,z_n=\\gamma(b)\\)，在\\(\\gamma\\)中从\\(z_{k-1}\\)到\\(z_k\\)的弧段上任取点\\(\\zeta_k,k=1,\\cdots,n\\)，作Riemann和\n\\[\\sum_{k=1}^n f(\\zeta_k)(z_k-z_{k-1}) \\]\n用\\(s_k\\)记弧段\\(z_{k-1}z_k\\)的长度，如果\\(\\lambda=max\\{s_k\\}\\to 0\\)时，不论\\(\\zeta_k\\)的取法，上式总有一确定的极限，就称次极限为\\(f\\)沿\\(\\gamma\\)的积分，记为\n\\[\\int_{\\gamma}f(z)dz = \\lim_{\\lambda\\to 0}\\sum_{k=1}^n f(\\zeta_k)(z_k-z_{k-1}) \\]\n只要\\(f\\)在\\(\\gamma\\)上连续，上述积分、上述极限一定存在。\n命题1\n设\\(f=u+iv\\)在可求长曲线\\(\\gamma\\)上连续，则有\n\\[\\int_{\\gamma}f(z)dz = \\int_{\\gamma}udx-vdy+i\\int_{\\gamma}vdx+udy \\]\n或者便于记忆\n\\[f(z)dz = (u+iv)(dx+idy) = (udx-vdy)+i(vdx+udy) \\]\n如果曲线光滑，还可以通过曲线的参数方程来计算积分。\n命题2\n如果\\(z=\\gamma(t)(a\\leq t\\leq b)\\)是光滑曲线，\\(f\\)在\\(\\gamma\\)上连续，那么\n\\[\\int_{\\gamma}f(z)dz = \\int^b_af(\\gamma(t))\\gamma'(t)dt \\]\n命题3\n如果\\(f,g\\)在可求长曲线\\(\\gamma\\)上连续，那么\n\\(\\int_{\\gamma^-}f(z)dz=-\\int_{\\gamma}f(z)dz\\)，\\(\\gamma^-\\)是与\\(\\gamma\\)反向的曲线 \\(\\int_{\\gamma}f(\\alpha f(z)+\\beta g(z))dz=\\alpha\\int_{\\gamma}f(z)dz+\\beta \\int_{\\gamma}g(z)dz\\)，\\(\\alpha,\\beta\\)是两个复常数 \\(\\int_{\\gamma}f(z)dz=\\int_{\\gamma_1}f(z)dz+\\int_{\\gamma_2}f(z)dz\\)，这里\\(\\gamma\\)是由\\(\\gamma_1\\)和\\(\\gamma_2\\)组成的曲线。 命题4\n如果\\(\\gamma\\)的长度为\\(L\\)，\\(M=\\sup|f(z)|\\)（即上确界），那么\n\\[\\bigg |\\int_\\gamma f(z)dz\\bigg |\\leq ML \\]\nCauchy积分定理 Cauchy定理\n设\\(D\\)是\\(\\bm C\\)中的单连通域，\\(f\\in H(D)\\)（即全纯函数），且\\(f'\\)在\\(D\\)中连续，则对\\(D\\)中任意的可求长闭曲线\\(\\gamma\\)，均有\n\\[\\int_\\gamma f(z)dz = 0 \\]\n注意，只要使得\\(f\\)的不全纯的点在\\(\\gamma\\)包围的区域中（而不是必须在\\(\\gamma\\)上）就不能使用这个定理。\n引理1\n设\\(f\\)是域\\(D\\)中的连续函数，\\(\\gamma\\)是\\(D\\)内的可求长曲线，对于任给的\\(\\varepsilon\u003e0\\)，一定存在一条\\(D\\)中的折线\\(P\\)，使得\n\\(P\\)和\\(\\gamma\\)有相同的起点和终点，\\(P\\)中其他的顶点都在\\(\\gamma\\)上 \\(|\\int_\\gamma f(z)dz-\\int_P f(z)dz|\u003c\\varepsilon\\) Cauchy-Goursat定理\n设\\(D\\)是\\(\\bm C\\)中的单连通域，如果\\(f\\in H(D)\\)，那么对\\(D\\)中任意的可求长闭曲线\\(\\gamma\\)，均有\n\\[\\int_\\gamma f(z)dz = 0 \\]\n注意点同上。\n这个定理也意味着积分和路径无关，只与始末位置有关。\n定理1\n设\\(D\\)是可求长简单闭曲线\\(\\gamma\\)的内部，若\\(f\\in H(D)\\bigcap C(\\bar D)\\)（即在\\(D\\)上全纯且在\\(\\bar D\\)（闭包）上连续），则\n\\[\\int_\\gamma f(z)dz = 0 \\]\n定理2\n设\\(\\gamma_0,\\gamma_1,\\cdots,\\gamma_n\\)是\\(n+1\\)条可求长简单闭曲线，\\(\\gamma_1,\\cdots,\\gamma_n\\)都在\\(\\gamma_0\\)内部，\\(\\gamma_1,\\cdots,\\gamma_n\\)中的每一条都在其他\\(n-1\\)条的外部，\\(D\\)是由这\\(n+1\\)条曲线围成的域，用\\(\\gamma\\)记\\(D\\)的边界，如果\\(f\\in H(D)\\bigcap C(\\bar D)\\)，那么\n\\[\\int_\\gamma f(z)dz = 0 \\]\n或者也可以写作\n\\[\\int_{\\gamma_0} f(z)dz = \\int_{\\gamma_1} f(z)dz+\\cdots+\\int_{\\gamma_n} f(z)dz \\]\n全纯函数的原函数 定义1\n设\\(f:D\\to \\bm C\\)是定义在域\\(D\\)上的一个函数，如果存在\\(F\\in H(D)\\)，使得\\(F'(z)=f(z)\\)在\\(D\\)上成立，就称\\(F\\)是\\(f\\)的一个原函数\n定理1\n设\\(f\\)在\\(D\\)中连续，且对\\(D\\)中任意可求长闭曲线\\(\\gamma\\)均有\n\\[\\int_\\gamma f(z)dz=0 \\]\n那么\n\\[F(z) = \\int^z_{z_0}f(\\zeta)d\\zeta \\]\n是\\(D\\)中的全纯函数，且在\\(D\\)中有\\(F'(z)=f(z)\\)，这里\\(z_0\\)是\\(D\\)中一固定点。\n定理2\n设\\(D\\)是\\(\\bm C\\)中的单连通域，\\(f\\in H(D)\\)，那么\\(F(z)=\\int^z_{z_0}f(\\zeta)d\\zeta\\)是\\(f\\)在\\(D\\)中的一个原函数。\n定理3\n设\\(D\\)是\\(\\bm C\\)中的单连通域，\\(f\\in H(D)\\)，\\(\\varPhi\\)是\\(f\\)的任一原函数，那么\n\\[\\int^z_{z_0}f(\\zeta)d\\zeta = \\varPhi(z)-\\varPhi(z_0) \\]\nCauchy积分公式 定理1\n设\\(D\\)是由可求长简单闭曲线\\(\\gamma\\)围成的域，如果\\(f\\in H(D)\\bigcap C(\\bar D)\\)，那么对任意\\(z\\in D\\)，均有\n\\[f(z) = \\frac{1}{2\\pi i}\\int_\\gamma \\frac{f(\\zeta)}{\\zeta-z}d\\zeta \\]\n定理2\n设\\(\\gamma\\)是\\(C\\)中的可求长曲线，\\(g\\)是\\(\\gamma\\)上的连续函数，那么由Cauchy型积分确定的函数\n\\[G(z) = \\frac{1}{2\\pi i}\\int_\\gamma \\frac{g(\\zeta)}{\\zeta-z}d\\zeta \\]\n在\\(C\\setminus y\\)（差集）上有任意阶导数，而且\n\\[G^{(n)}(z)=\\frac{n!}{2\\pi i}\\int_\\gamma\\frac{g(\\zeta)}{(\\zeta-z)^{n+1}}d\\zeta,n=1,2,\\cdots \\]\n定理3\n设\\(D\\)是由可求长简单闭曲线\\(\\gamma\\)围成的域，如果\\(f\\in H(D)\\bigcap C(\\bar D)\\)，那么\\(f\\)在\\(D\\)上有任意阶导数，而且对任意\\(z\\in D\\)，有\n\\[f^{(n)}(z)=\\frac{n!}{2\\pi i}\\int_\\gamma\\frac{f(\\zeta)}{(\\zeta-z)^{n+1}}d\\zeta,n=1,2,\\cdots \\]\n定理4\n如果\\(f\\)是域\\(D\\)上的全纯函数，那么\\(f\\)在\\(D\\)上有任意阶导数。\n定理5\n设\\(\\gamma_0,\\gamma_1,\\cdots,\\gamma_k\\)是\\(k+1\\)条可求长简单闭曲线，\\(\\gamma_1,\\cdots,\\gamma_k\\)都在\\(\\gamma_0\\)的内部，\\(\\gamma_1,\\cdots,\\gamma_k\\)中的每一条都在其他\\(k-1\\)条的外部，\\(D\\)是由这\\(k+1\\)条曲线围成的域，\\(D\\)的边界\\(\\gamma\\)由\\(\\gamma_0,\\gamma_1,\\cdots,\\gamma_k\\)所组成，如果\\(f\\in H(D)\\bigcap C(\\bar D)\\)，则对任意\\(z\\in D\\)，有\n\\[f(z) = \\frac{1}{2\\pi i}\\int_\\gamma \\frac{f(\\zeta)}{\\zeta-z}d\\zeta \\]\n\\(f\\)在\\(D\\)内有任意阶导数，且\n\\[f^{(n)}(z)=\\frac{n!}{2\\pi i}\\int_\\gamma\\frac{f(\\zeta)}{(\\zeta-z)^{n+1}}d\\zeta,n=1,2,\\cdots \\]\nCauchy积分公式的一些重要推论 Cauchy不等式\n设\\(f\\)在\\(B(a,R)\\)中全纯，且对任意\\(z\\in B(a,R)\\)，有\\(|f(z)|\\leq M\\)，那么\n\\[|f^{(n)}(a)|\\leq\\frac{n!M}{R^n},n=1,2,\\cdots \\]\nLiouville定理\n有界整函数必为常数\n代数学基本定理\n任意复系数多项式\n\\[P(z)=a_0z^n+a_1z^{n-1}+\\cdots+a_n,a_0\\neq 0 \\]\n在\\(\\bm C\\)中必有零点\nMorera定理\n如果\\(f\\)是域\\(D\\)上的连续函数，且沿\\(D\\)内任一可求长闭曲线的积分为零，那么\\(f\\)在\\(D\\)上全纯\n非齐次Cauchy积分公式 TODO\n一维\\(\\bar\\partial\\)问题的解 TODO\n全纯函数的Taylor展开及其应用 Weierstrass定理 设\\(z_1,z_2,\\cdots\\)是\\(\\bm C\\)中的一列复数，称\n\\[\\sum^\\infty_{n=1}z_n = z_1+z_2+\\cdots \\]\n为一个复数项级数。这个级数称为是收敛的，如果它的部分和数列\\(S_n=\\sum^n_{k=1}z_k\\)收敛，如果\\(\\{S_n\\}\\)的极限为\\(S\\)，就说这个级数的和为\\(S\\)，记为\\(\\sum^\\infty_{n=1}z_n = S\\)\n从数列的Cauchy收敛准则马上可得级数的Cauchy收敛准则：\n级数收敛的充要条件是对任意\\(\\varepsilon\u003e0\\)，存在正整数\\(N\\)，使得当\\(n\u003eN\\)时，不等式\n\\[z_{n+1}+z_{n+2}+\\cdots+z_{n+p}\u003c\\varepsilon \\]\n对任意自然数\\(p\\)成立\n从收敛准则即得\\(\\sum^\\infty_{n=1}z_n\\)收敛的必要条件是\\(\\lim_{n\\to \\infty}z_n=0\\)\n如果\\(\\sum^\\infty_{n=1}|z_n|\\)收敛，就说级数\\(\\sum^\\infty_{n=1}z_n\\)绝对收敛。同样，绝对收敛的级数一定收敛，反之不一定成立。并且有\\(\\sum^\\infty_{n=1}|z_n|\\geq|\\sum^\\infty_{n=1}z_n|\\)\n另外，\\(\\sum^\\infty_{n=1}z_n\\)收敛的充要条件是其实部和虚部构成的数列分别都收敛。\n设\\(E\\)是\\(\\bm C\\)中的一个点集，\\(f_n:E\\to \\bm C\\)是定义在\\(E\\)上的一个函数列，如果对于每一个\\(z\\in E\\)，级数\n\\[\\sum^\\infty_{n=1}f_n(z)=f_1(z)+f_2(z)+\\cdots \\]\n收敛到\\(f(z)\\)，就说其在\\(E\\)上收敛，其和函数为\\(f\\)，记为\\(\\sum^\\infty_{n=1}f_n(z)=f(z)\\)\n一致连续\n设\\(\\sum^\\infty_{n=1}f_n(z)\\)是定义在点集\\(E\\)上的级数，我们说\\(\\sum^\\infty_{n=1}f_n(z)\\)在\\(E\\)上一致收敛到\\(f(z)\\)，是指对任意\\(\\varepsilon\u003e0\\)，存在正整数\\(N\\)，当\\(n\u003eN\\)时，不等式\n\\[|S_n(z)-f(z)|\u003c\\varepsilon \\]\n对所有的\\(z\\in E\\)成立，这里，\\(S_n(z)=\\sum^n_{k=1}f_k(z)\\)是级数的部分和。\nCauchy收敛准则\n级数\\(\\sum^\\infty_{n=1}f_n(z)\\)在\\(E\\)上一致收敛的充要条件是对任意\\(\\varepsilon\u003e0\\)，存在正整数\\(N\\)，当\\(n\u003eN\\)时，不等式\n\\[|f_{n+1}(z)+f_{n+2}(z)+\\cdots+f_{n+p}(z)|\u003c\\varepsilon \\]\n对所有\\(z\\in E\\)及任意自然数\\(p\\)成立。\nWeierstrass一致收敛判别法\n设\\(f_n:E\\to \\bm C\\)是定义在\\(E\\)上的函数列，且在\\(E\\)上满足\\(|f_n(z)|\\leq a_n,n=1,2,\\cdots\\)，如果\\(\\sum^\\infty_{n=1}a_n\\)收敛，那么\\(\\sum^\\infty_{n=1}f_n(z)\\)在\\(E\\)上一致收敛。\n定理1\n设级数\\(\\sum^\\infty_{n=1}f_n(z)\\)在点集\\(E\\)上一致收敛到\\(f(z)\\)，如果每个\\(f_n(n=1,2,\\cdots)\\)都是\\(E\\)上的连续函数，那么\\(f\\)也是\\(E\\)上的连续函数。\n定理2\n设级数\\(\\sum^\\infty_{n=1}f_n(z)\\)在可求长曲线\\(\\gamma\\)上一致收敛到\\(f(z)\\)，如果每个\\(f_n(n=1,2,\\cdots)\\)都在\\(\\gamma\\)上连续，那么\n\\[\\int_\\gamma f(z)dz=\\sum^\\infty_{n=1}\\int_\\gamma f_n(z)dz \\]\n内闭一致收敛\n如果级数\\(\\sum^\\infty_{n=1}f_n(z)\\)在域\\(D\\)的任意紧子集上一致收敛，就称\\(\\sum^\\infty_{n=1}f_n(z)\\)在\\(D\\)中内闭一致收敛。\n定义1\n如果\\(D\\)的子集\\(G\\)满足\n\\(\\bar G\\subset D\\) \\(\\bar G\\)是紧的 就说\\(G\\)相对于\\(D\\)是紧的，记为\\(G\\subset\\subset D\\)\n引理1\n设\\(D\\)是\\(\\bm C\\)中的域，\\(K\\)是\\(D\\)中的紧子集，且包含在相对于\\(D\\)是紧的开集\\(G\\)中，即\\(K\\subset G\\subset\\subset D\\)，那么对任意\\(f\\in H(D)\\)，均有\n\\[sup\\{|f^{(k)}|:z\\in K\\}\\leq Csup{|f(z)|:z\\in G} \\]\n这里，\\(k\\)是任意自然数，\\(C\\)是与\\(k,K,G\\)有关的常数。\nWeierstrass定理\n设\\(D\\)是\\(\\bm C\\)中的域，如果\n\\(f_n\\in H(D),n=1,2,\\cdots\\) \\(\\sum^\\infty_{n=1} f_n(z)\\)在\\(D\\)中内闭一致收敛到\\(f(z)\\) 那么\n\\(f\\in H(D)\\) 对任意自然数\\(k\\)，\\(\\sum^\\infty_{n=1} f_n^{(k)}(z)\\)在\\(D\\)中内闭一致收敛到\\(f^{(k)}(z)\\) 幂级数 幂级数，是指形如\n\\[\\sum^\\infty_{n=0}a_n(z-z_0)^n = a_0+a_1(z-z_0)+a_2(z-z_0)^2+\\cdots \\]\n的级数，其中\\(a_n,z_0\\)都是复常数。\n定义1\n如果存在常数\\(R\\)，使得当\\(|z|\u003c R\\)时，级数\\(\\sum^\\infty_{n=0}a_nz^n\\)收敛；当\\(|z|\u003eR\\)时，级数发散，就称\\(R\\)为该级数的收敛半径，\\(\\{z:|z|\u003c R\\}\\)称为该级数的收敛圈。\n定理1\n\\(\\sum^\\infty_{n=0}a_nz^n\\)的收敛半径为\n\\[R=1\\bigg/\\overline{\\lim_{n\\to\\infty}}\\sqrt[n]{|a_n|} \\]\n其中\\(\\overline\\lim\\)是上极限\nAbel定理\n如果\\(\\sum^\\infty_{n=0}a_nz^n\\)在\\(z=z_0\\neq 0\\)处收敛，则必在\\(\\{z:|z|\u003c|z_0|\\}\\)中内闭绝对一致收敛。\n定理2\n幂级数在其收敛圆内确定一个全纯函数。\n非切向极限\n设\\(g\\)是定义在单位圆中的函数，\\(e^{i\\theta_0}\\)是单位圆周上一点，\\(S_\\alpha(e^{i\\theta_0})\\)如下图所示，其中\\(\\alpha\u003c\\frac{\\pi}{2}\\)，如果当\\(z\\)在\\(S_\\alpha(e^{i\\theta_0})\\)中趋于\\(e^{i\\theta_0}\\)时，\\(g(z)\\)有极限\\(l\\)，就称\\(g\\)在\\(e^{i\\theta_0}\\)处有非切向极限\\(l\\)，记为\n\\[\\lim_{z\\to e^{i\\theta_0},z\\in S_\\alpha(e^{i\\theta_0})}g(z)=l \\]\n1.jpg\rAbel第二定理\n设\\(f(z)=\\sum^\\infty_{n=0}a_nz^n\\)的收敛半径\\(R=1\\)，且级数在\\(z=1\\)处收敛于\\(S\\)，那么\\(f\\)在\\(z=1\\)处有非切向极限\\(S\\)，即\n\\[\\lim_{z\\to 1,z\\in S_\\alpha(1)}f(z)=S \\]\n其他一些求收敛半径的方法\n总体上和高等数学差别不大\n比值法\n如果\\(\\lim_{n\\to \\infty}|c_{n+1}/c_n|=\\lambda\\neq 0\\)，那么半径为\\(R=1/\\lambda\\)\n根值法\n如果\\(\\lim_{n\\to \\infty}\\sqrt[n]{|c_n|}=\\mu\\neq 0\\)，那么半径为\\(R=1/\\mu\\)\n定理3\n设幂级数\\(\\sum^\\infty_{n=0}c_n(z-z_0)^n\\)的收敛半径为\\(R\\)，那么\n它的和函数\\(f(z)\\)，即 \\[f(z) = \\sum^\\infty_{n=0}c_n(z-a)^n \\]\n是收敛圆：\\(|z-a|\u003c R\\)内的解析函数\n\\(f(z)\\)在收敛圆内的导数可将其幂级数逐项求导得到，即 \\[f'(z) = \\sum^\\infty_{n=0}nc_n(z-a)^{n-1} \\]\n\\(f(z)\\)在收敛圆内可以逐项积分，即 \\[\\int_C f(z)dz = \\sum^\\infty_{n=0}c_n\\int_C(z-a)^ndz, C\\in|z-a|\u003c R \\]\n或\n\\[\\int_0^zf(z)dz = \\sum^\\infty_{n=0}\\frac{c_n}{n+1}(z-a)^{n+1} \\]\n全纯函数的Taylor展开 前面已经证明，幂级数在它的收敛圆内表示一个全纯函数，而在一个圆内全纯的函数也一定可以展开成幂级数。\n定理1\n若\\(f\\in H(B(z_0,R))\\)，则\\(f\\)可以在\\(B(z_0,R)\\)中展开成幂级数\n\\[f(z)=\\sum_{n=0}^\\infty\\frac{f^{(n)}(z_0)}{n!}(z-z_0)^n,z\\in B(z_0,R) \\]\n右端的级数称为\\(f\\)的Taylor级数\n定理2\n\\(f\\)在点\\(z_0\\)处全纯的充要条件是\\(f\\)在\\(z_0\\)的邻域内可以展开成幂级数\n\\[f(z)=\\sum_{n=0}^\\infty a_n(z-z_0)^n \\]\n定义1\n设\\(f\\)在\\(z_0\\)点全纯且不恒为零，如果\n\\[f(z_0)=0,f'(z_0)=0,\\cdots,f^{(m-1)}(z_0)=0,f^{(m)}(z_0)\\neq 0 \\]\n则称\\(z_0\\)是\\(f\\)的\\(m\\)阶零点。\n命题1\n\\(z_0\\)为\\(f\\)的\\(m\\)阶零点的充要条件是\\(f\\)在\\(z_0\\)的邻域内可以表示为\n\\[f(z)=(z-z_0)^mg(z) \\]\n这里，\\(g\\)在\\(z_0\\)点全纯，且\\(g(z_0)\\neq 0\\)\n事实上，如果\\(z_0\\)是\\(f(z)\\)的\\(m\\)阶零点，那么\\(f(z)\\)可以表示成上述的形式，设\\(g(z)\\)在\\(z_0\\)处的泰勒展开为\n\\[g(z) = c_0+c_1(z-z_0)+c_2(z-z_0)^2+\\cdots \\]\n其中\\(c_0=g(z_0)\\neq 0\\)，从而\n\\[f(z) = c_0(z-z_0)^m+c_1(z-z_0)^{m+1}+\\cdots \\]\n也就是前\\(m\\)项系数都为0.\n命题2\n设\\(D\\)是\\(\\bm C\\)中的域，\\(f\\in H(D)\\)，如果\\(f\\)在\\(D\\)中的小圆盘\\(B(z_0,\\varepsilon)\\)上恒等于零，那么\\(f\\)在\\(D\\)上恒等于\\(0\\)。\n命题3\n设\\(D\\)是\\(\\bm C\\)中的域，\\(f\\in H(D), f(z)\\not\\equiv 0\\)，那么\\(f\\)在\\(D\\)中的零点是孤立的。即若\\(z_0\\)为\\(f\\)的零点，则必存在\\(z_0\\)的领域\\(B(z_0,\\varepsilon)\\)，使得\\(f\\)在\\(B(z_0,\\varepsilon)\\)中除了\\(z_0\\)外不再有其他的零点。\n唯一性定理\n设\\(D\\)是\\(\\bm C\\)中的域，\\(f_1,f_2\\in H(D)\\)，如果存在\\(D\\)中的点列\\(\\{z_n\\}\\)，使得\\(f_1(z_n)=f_2(z_n),n=1,2,\\cdots\\)，且\\(\\lim_{n\\to\\infty}z_n=a\\in D\\)，那么在\\(D\\)中有\\(f_1(z)=\\equiv f_2(z)\\)\n常见的泰勒展开\n以下都是在\\(z=0\\)处的展开式\n\\[\\frac{1}{1-z}=\\sum^\\infty_{n=0}z^n,|z|\u003c1 \\]\n\\[\\frac{1}{1+z}=\\sum^\\infty_{n=0}(-1)^nz^n,|z|\u003c1 \\]\n\\[e^z = \\sum^\\infty_{n=0} \\frac{z^n}{n!},z\\in\\bm C \\]\n\\[cosz = \\sum^\\infty_{n=0} (-1)^n\\frac{z^{2n}}{(2n)!},z\\in\\bm C \\]\n\\[sinz = \\sum^\\infty_{n=0} (-1)^n\\frac{z^{2n+1}}{(2n+1)!},z\\in\\bm C \\]\n\\[\\log(1+z) = \\sum^\\infty_{n=1} (-1)^{n-1}\\frac{z^n}{n},|z|\u003c1 \\]\n\\[exp[a\\log(1+z)] = \\sum^\\infty_{n=0}\\binom{a}{n}z^n,|z|\u003c1 \\]\n辐角原理和Rouche定理 TODO\n最大模原理和Schwarz引理 TODO\n全纯函数的Laurent展开及其应用 前面证明了，圆盘中的全纯函数一定可以在圆盘中展开成幂级数。但圆环中的全纯函数不一定，但是一定可以展开成洛朗级数。\n全纯函数的Laurent展开 称级数\n\\[\\sum^\\infty_{n=-\\infty}a_n(z-z_0)^n=\\sum^\\infty_{n=0}a_n(z-z_0)^n+\\sum^\\infty_{n=1}a_{-n}(z-z_0)^{-n} \\]\n为洛朗级数。由两部分组成，第一部分是幂级数，第二部分为负幂项的级数。如果这两个级数都收敛，则整个洛朗级数收敛。\n定理1\n如果洛朗级数\n\\[\\sum^\\infty_{n=-\\infty}a_n(z-z_0)^n=\\sum^\\infty_{n=0}a_n(z-z_0)^n+\\sum^\\infty_{n=1}a_{-n}(z-z_0)^{-n} \\]\n的收敛域为圆环\\(D=\\{z:r\u003c |z-z_0|\u003c R\\}\\)，那么它在\\(D\\)中绝对收敛且内闭一致收敛，它的和函数在\\(D\\)中全纯。\n上述级数的幂级数部分称为全纯部分，负幂项级数部分称为主要部分。\n该定理的逆定理也成立。\n设\\(D=\\{z:r\u003c|z-z_0|\u003c R\\}\\)，如果\\(f\\in H(D)\\)，那么\\(f\\)在\\(D\\)上可以展开为洛朗级数\n\\[f(z) = \\sum^\\infty_{n=-\\infty}a_n(z-z_0)^n \\]\n其中\n\\[a_n = \\frac{1}{2\\pi i}\\int_{\\gamma_\\rho}\\frac{f(\\zeta)}{(\\zeta-z_0)^{n+1}}d\\zeta \\]\n\\[\\gamma_\\rho = \\{\\zeta:|\\zeta-z_0|=\\rho\\}(r\u003c\\rho\u003c R) \\]\n并且这个展开式是唯一的。\n孤立奇点 如果\\(f\\)在无心圆盘\\(\\{z:0\u003c|z-z_0|\u003c R\\}\\)中全纯（而在圆心不全纯），就称\\(z_0\\)是\\(f\\)的孤立奇点。在奇点附近有三种情况\n\\(\\lim_{z\\to z_0}f(z)=a,a\\)是一有限数，这时称\\(z_0\\)是\\(f\\)的可去奇点 \\(\\lim_{z\\to z_0}f(z)=\\infty\\)，这时称\\(z_0\\)是\\(f\\)的极点 \\(\\lim_{z\\to z_0}f(z)\\)不存在，这时称\\(z_0\\)是\\(f\\)的本性奇点 定理1\n\\(z_0\\)是\\(f\\)的可去奇点的充要条件是\\(f\\)在\\(z_0\\)附近有界。\n命题1\n\\(z_0\\)是\\(f\\)的极点的充要条件是\\(z_0\\)为\\(1/f\\)的零点。\n定义1\n如果\\(z_0\\)是\\(1/f(z)\\)的\\(m\\)阶零点，就称\\(z_0\\)是\\(f\\)的\\(m\\)阶极点。\n定理2\n\\(z_0\\)是\\(f\\)的\\(m\\)阶极点的充要条件是\\(f\\)在\\(z_0\\)附近的洛朗级数为\n\\[f(z) = \\frac{a_{-m}}{(z-z_0)^m}+\\cdots+\\frac{a_{-1}}{z-z_0}+a_0+a_1(z-z_0)+\\cdots \\]\n其中\\(a_{-m}\\neq 0\\)\n定理3\n\\(f\\)在可去奇点处的特征是洛朗级数没有主要部分，只有全纯部分\n\\(f\\)在极点处的特征是洛朗级数的主要部分只有有限项。最高负幂项为\\(t^{-m}\\)，则为\\(m\\)级极点。\n\\(f\\)在本性奇点处的特征是洛朗级数的主要部分有无限项。\n定理4\n设\\(z_0\\)是\\(f\\)的本性奇点，那么对任意\\(A\\in\\bm C_\\infty\\)，必存在趋于\\(z_0\\)的点列\\(\\{z_n\\}\\)，使得\\(\\lim_{n\\to\\infty}f(z_n)=A\\)\n定理5\n全纯函数在本性奇点的邻域内无穷多次地取到每个有穷复值，最多只有一个例外\n定义2\n我们讨论无穷远点。如果\\(f\\)在无穷远点的邻域（不包括无穷远点）\\(\\{z:0\\leq R\u003c|z|\u003c\\infty\\}\\)中全纯，\\(\\infty\\)就是\\(f\\)的孤立奇点。\n记\n\\[g(\\zeta)=f(\\frac{1}{\\zeta}) \\]\n如果\\(\\zeta=0\\)是\\(g\\)的可去奇点、\\(m\\)阶极点或本性奇点，那么我们相应地称\\(z=\\dfrac{1}{\\zeta}=\\infty\\)是\\(f\\)的可去奇点、\\(m\\)阶极点或本性奇点。\n整函数与亚纯函数 如果\\(f\\)在整个复平面\\(\\bm C\\)上全纯，就称\\(f\\)为整函数\n定理1\n在无穷远处全纯的整函数一定是常数。\n定理2\n如果无穷远点是整函数\\(f\\)的一个\\(m\\)阶极点，那么\\(f\\)是一个\\(m\\)次多项式。\n如果\\(f\\)在整个复平面\\(\\bm C\\)上除去极点外没有其他的奇点，就称\\(f\\)是一个亚纯函数。整函数显然是亚纯函数。\n此外有理函数\n\\[f(z) = \\frac{P_n(z)}{Q_m(z)} \\]\n也是亚纯函数，这里，\\(P_n(z),Q_m(z)\\)是两个既约（分式最简）的多项式\n定理3\n若\\(z=\\infty\\)是亚纯函数\\(f\\)的可去奇点或极点，则\\(f\\)一定是有理函数。\n反过来也成立。\n残数定理 定义1\n设\\(a\\)是\\(f\\)的一个孤立奇点，\\(f\\)在\\(a\\)点的邻域\\(B(a,r)\\)中的洛朗级数为\\(f(z)=\\sum^\\infty_{n=-\\infty}c_n(z-a)^n\\)，称\\(c_{-1}\\)为\\(f\\)在\\(a\\)点的残数，记为\n\\[Res(f,a) = c_{-1} \\]\n或\n\\[\\underset{z=a}{Res}f = c_{-1} \\]\n根据洛朗级数的计算方法，我们知道\n\\[c_{-1} = \\frac{1}{2\\pi i}\\int_\\gamma f(\\zeta)d\\zeta \\]\n结合上上式就有\n\\[\\int_\\gamma f(z)dz = 2\\pi iRes(f,a) \\]\n这里，\\(\\gamma=\\{z:|z-a|=\\rho\\},0\u003c\\rho\u003c r\\)\n若\\(z=\\infty\\)是\\(f\\)的孤立奇点，即\\(f\\)在\\(R\u003c|z|\u003c\\infty\\)中全纯，我们定义\\(f\\)在\\(z=\\infty\\)处的残数为\n\\[Res(f,\\infty) = -\\frac{1}{2\\pi i}\\int_\\gamma f(z)dz \\]\n这里，\\(\\gamma=\\{z:|z|=\\rho\\},R\u003c\\rho\u003c\\infty\\)\n命题1\n若\\(a\\)是\\(f\\)的\\(m\\)阶极点，则\n\\[Res(f,a) = \\frac{1}{(m-1)!}\\lim_{z\\to a}\\frac{d^{m-1}}{dz^{m-1}}\\{(z-a)^mf(z)\\} \\]\n命题2\n若\\(a\\)是\\(f\\)的\\(1\\)阶极点，则\n\\[Res(f,a) = \\lim_{z\\to a}(z-a)f(z) \\]\n命题3\n设\\(f=\\frac{g}{h}\\)，\\(g,h\\)都在\\(a\\)处全纯，且\\(g(a)\\neq 0\\)，\\(h(a)=0\\)，\\(h'(a)\\neq 0\\)，那么\n\\[Res(f,a) = \\frac{g(a)}{h'(a)} \\]\n残数定理\n设\\(D\\)是复平面上的一个有界区域，它的边界\\(\\gamma\\)由一条或若干条简单闭曲线组成，如果\\(f\\)在\\(D\\)中除去孤立奇点\\(z_1,\\cdots,z_n\\)外是全纯的，在闭域\\(\\overline{D}\\)上除去\\(z_1,\\cdots,z_n\\)外是连续的，那么\n\\[\\int_\\gamma f(z)dz = 2\\pi i\\sum^n_{k=1} Res(f,z_k) \\]\n定理1\n若\\(f\\)在\\(\\bm C\\)中除去\\(z_1,\\cdots,z_n\\)外是全纯的，则\\(f\\)在\\(z_1,\\cdots,z_n\\)及\\(z=\\infty\\)处的残数之和为零。\n这个定理可以用在，在用残数定理求积分时，如果里面的众多奇点不好算，就可以转化为算无穷远点的残数来代替。\n定理2\n\\[Res[f(z),\\infty] = -Res\\bigg[f\\bigg(\\frac{1}{z}\\bigg)\\cdot\\frac{1}{z^2},0\\bigg] \\]\n利用残数定理计算定积分 \\(\\int^\\infty_{-\\infty}f(x)dx\\)型\n设\\(f\\)在上半平面\\(\\{z: Imz\u003e0\\}\\)中除去\\(a_1,\\cdots,a_n\\)外是全纯的，在\\(\\{z: Imz\\geq0\\}\\)中除去\\(a_1,\\cdots,a_n\\)外是连续的，如果\\(\\lim_{z\\to\\infty}zf(z)=0\\)，那么\n\\[\\int^\\infty_{-\\infty}f(x)dx = 2\\pi i\\sum^n_{k=1}Res(f,a_k) \\]\n推论1\n设\\(P,Q\\)是两个既约多项式，\\(Q\\)没有实的零点，且\\(degQ-degP\\geq2\\)，那么\n\\[int^\\infty_{-\\infty}\\frac{P(x)}{Q(x)}dx = 2\\pi i\\sum^n_{k=1}Res\\bigg(\\frac{P(z)}{Q(z)},a_k\\bigg) \\]\n这里\\(a_k\\)为\\(Q\\)在上半平面中的全部零点，\\(degP,degQ\\)为\\(P,Q\\)的次数。\nJordan引理\n设\\(f\\)在\\(\\{z:R_0\\leq|z|\u003c\\infty,Imz\\geq0\\}\\)上连续，且\\(\\lim_{z\\to\\infty,Imz\\geq0}f(z)=0\\)，则对任意\\(a\u003e0\\)，有\n\\[\\lim_{R\\to\\infty}\\int_{\\gamma_R}e^{iaz}f(z)dz = 0 \\]\n这里\\(\\gamma_R=\\{z:z=Re^{i\\theta},0\\leq\\theta\\leq\\pi,R\\geq R_0\\}\\)\n定理1\n设\\(f\\)在上半平面\\(\\{z: Imz\u003e0\\}\\)中除去\\(a_1,\\cdots,a_n\\)外是全纯的，在\\(\\{z: Imz\\geq0\\}\\)中除去\\(a_1,\\cdots,a_n\\)外是连续的，如果\\(\\lim_{z\\to\\infty}f(z)=0\\)，那么对任意\\(\\alpha\u003e0\\)，有\n\\[\\int^\\infty_{-\\infty}e^{i\\alpha x}f(x)dx = 2\\pi i\\sum^n_{k=1}Res(e^{i\\alpha z}f(z),a_k) \\]\n推论2\n\\[\\int^\\infty_{-\\infty}f(x)\\cos\\alpha xdx = Re\\{ 2\\pi i\\sum^n_{k=1}Res(e^{i\\alpha z}f(z),a_k) \\} \\]\n\\[\\int^\\infty_{-\\infty}f(x)\\sin\\alpha xdx = Im\\{ 2\\pi i\\sum^n_{k=1}Res(e^{i\\alpha z}f(z),a_k) \\} \\]\n引理1\n设\\(f\\)在扇形域\n\\[G = \\{z=a+\\rho e^{i\\theta}:0\u003c\\rho\\leq \\rho_0,\\theta_0\\leq\\theta\\leq\\theta_0+\\alpha\\} \\]\n上连续，如果\\(\\lim_{z\\to a}(z-a)f(z) = A\\)，那么\n\\[\\lim_{\\rho\\to 0}\\int_{\\gamma_\\rho}f(z)dz = iA\\alpha \\]\n这里，\\(\\gamma_\\rho = \\{z=a+\\rho e^{i\\theta}:\\theta_0\\leq\\theta\\leq\\theta_0+\\alpha\\}\\)，它的方向是沿着辐角增加的方向。\n\\(\\int^\\infty_0f(x)dx\\)型\nTODO\n\\(\\int^b_af(x)dx\\)型\n对于一种重要的又穷限积分\n\\[\\int^{2\\pi}_0 R(\\sin\\theta,\\cos\\theta)d\\theta \\]\n一种办法是\n\\[\\int^{2\\pi}_0 R(\\sin\\theta,\\cos\\theta)d\\theta = 2\\int^\\infty_{-\\infty}R\\bigg(\\frac{2t}{1+t^2},\\frac{1-t^2}{1+t^2}\\bigg)\\frac{1}{1+t^2}dt \\]\n另一种办法是\n\\[\\int^{2\\pi}_0 R(\\sin\\theta,\\cos\\theta)d\\theta = \\int_{|z|=1}R\\bigg(\\frac{1}{2i}\\bigg(z-\\frac{1}{z}\\bigg),\\frac{1}{2}\\bigg(z+\\frac{1}{z}\\bigg)\\bigg)\\frac{1}{iz}dz \\]\n对于另一种重要的又穷限积分\n\\[\\int^b_a(x-a)^r(b-x)^sf(x)dx \\]\nTODO\nFresnel积分\n\\[\\int^\\infty_0 \\cos x^2dx = \\int^\\infty_0 \\sin x^2dx = \\frac{1}{2}\\sqrt{\\frac{\\pi}{2}} \\]\nPoisson积分\n\\[\\int^\\infty_0 e^{-ax^2}\\cos bxdx = \\frac{1}{2}\\sqrt{\\frac{\\pi}{a}}exp\\bigg(-\\frac{b^2}{4a}\\bigg) \\]\n共形映射 分式线性变换 见前\n几个初等函数所构成的映射 幂函数 \\(\\omega=z^n(n\\in N,n\\geq2)\\)这个函数在\\(z\\)平面内处处可导，当\\(z\\neq 0\\)时\\(\\omega'\\neq 0\\)，也就是说除了原点外处处共形映射。\n幂函数映射的特点是：把以原点为顶点的角形域映射为以原点为顶点的角形域。但张角变成了原来的\\(n\\)倍。\n指数函数 \\(\\omega=e^z\\)，易知在全平面上都是一个共形映射。\n其特点是：把水平的带形区域\\(0\u003c Im(z)\u003c a(a\\leq 2\\pi)\\)映射成角形域\\(0\u003c arg\\omega\u003c a\\)。\n几个常见的分式线性变换 把单位圆映为单位圆 \\[w = e^{i\\varphi}\\bigg(\\dfrac{z-\\alpha}{1-\\bar{\\alpha}z}\\bigg),|\\alpha|\u003c1,\\varphi\\in R \\]\n把上半平面映为单位圆 \\[w = e^{i\\theta}\\bigg(\\dfrac{z-\\lambda}{z-\\bar{\\lambda}}\\bigg),Im(\\lambda)\u003e0,\\theta\\in R \\]\n","date":"2022-09-01T13:44:54+08:00","permalink":"https://kegalas.top/inferior/%E5%A4%8D%E5%8F%98%E5%87%BD%E6%95%B0%E6%95%B4%E7%90%86/","title":"复变函数整理"},{"content":"基本概念 随机试验E 针对随机现象的观察、记录、试验（广义）。\n特点：\n可以在相同的条件下重复进行 每次试验的可能结果不止一个，并且能事先明确试验的所有可能结果 但一次试验前不能确定哪个结果会出现 样本空间\\(\\Omega\\) 随机试验\\(E\\)的所有结果构成的集合为\\(E\\)的样本空间\\(\\Omega\\)，记为\\(\\Omega\\{\\omega\\}\\)，每个结果\\(\\omega\\)是\\(\\Omega\\)中的一个元素，称为样本点。\n频率 在相同的条件下，进行了\\(n\\)次试验，其中事件\\(A\\)发生的次数\\(n_A\\)称为事件\\(A\\)发生的频数，比值\\(n_A/n\\)称为事件\\(A\\)发生的频率，记为\\(f_n(A)\\)\n概率 定义1: 事件A发生频率的稳定值\\(p\\)称为它的概率\\(P(A)\\)，即\\(P(A)=p\\)\n定义2: 随机试验\\(E\\)，样本空间\\(\\Omega\\)，对于\\(E\\)的每一事件\\(A\\)赋予一个实数，记为\\(P(A)\\)，如果集合函数满足以下条件，P(A)称为事件A的概率\n非负性: 对于每一个事件\\(A\\)，有\\(P(A)\\geq0\\) 规范性: 对于必然事件\\(\\Omega\\)，有\\(P(\\Omega)=1\\) 可列可加性: 设\\(A_1,A_2,\\cdots\\)是两两不相容的事件，即对于\\(A_iA_j=\\empty,i\\neq j(i,j=1,2,\\cdots)\\) \\[P(\\bigcup^\\infty_{i=1}A_i)=\\sum^\\infty_{i=1}P(A_i) \\]\n性质\n\\(P(\\empty)=0\\) 可列可加性（见上） 若\\(A\\subset B\\)，则\\(P(B-A)=P(B)-P(A)\\) 任意事件\\(A\\)，\\(P(A)\\leq 1\\) 任意事件\\(A\\)，\\(P(\\overline{A})=1-P(A)\\) 加法公式，对任意事件\\(A,B\\)，\\(P(A\\cup B)=P(A)+P(B)-P(AB)\\)，扩展情况同容斥原理。 极限性：设\\(A_1\\subset A_2\\subset\\cdots\\)，则\\(\\lim_{n\\to\\infty}P(A_n)=P(\\bigcup^{\\infty}_{i=1}A_i)\\)；设\\(A_1\\supset A_2\\supset\\cdots\\)，则\\(\\lim_{n\\to\\infty}P(A_n)=P(\\bigcap^{\\infty}_{i=1}A_i)\\) 注意，没有以下性质\n\\(P(A)=0\\)不能推出\\(A=\\empty\\) \\(P(A)=1\\)不能推出\\(A=\\Omega\\) \\(P(A)=P(B)\\)不能推出\\(A=B\\) 古典概率 定义 设一个试验有\\(N\\)个等可能的结果，而事件\\(E\\)恰包含其中的\\(M\\)个结果，则事件\\(E\\)的概率，记为\\(P(E)\\)，定义为\n\\[P(E)=\\frac{M}{N} \\]\n一些有用的公式 n个相异物件取\\(r(1\\leq r\\leq n)\\)个的不同排列总数 \\[P^n_r=n(n-1)(n-2)\\cdots(n-r+1) \\]\nn个相异物体取\\(r(1\\leq r\\leq n)\\)个的不同组合总数 \\[C^n_r = \\frac{P^n_r}{r!}=\\frac{n!}{r!(n-r)!}=\\frac{n(n-1)(n-2)\\cdots(n-r+1)}{r!}=\\binom{n}{r} \\]\n另外，只要\\(r\\)为非负整数，不论\\(n\\)为任何实数，都有意义。例如\n\\[\\binom{-1}{r} = \\frac{(-1)(-2)\\cdots(-r)}{r!}=(-1)^r \\]\n二项式系数 \\[(a+b)^n=\\sum_{i=0}^n\\binom{n}{i}a^ib^{n-i} \\]\n令\\(a=b=1\\)\n\\[\\binom{n}{0}+\\binom{n}{1}+\\cdots+\\binom{n}{n}=2^n \\]\n令\\(a=-1,b=1\\)\n\\[\\binom{n}{0}-\\binom{n}{1}+\\binom{n}{2}+\\cdots+(-1)^n\\binom{n}{n}=0 \\]\n还有\n\\[\\binom{m+n}{k}=\\sum_{i=0}^k\\binom{m}{i}\\binom{n}{k-i} \\]\n\\(n\\)个相异物件分成\\(k\\)堆，各堆物件数分别为\\(r_1,\\cdots,r_k\\)的分法是 \\[\\frac{n!}{r_1!\\cdots r_n!} \\]\n以上是有序堆的情况，无序堆时\n\\[\\frac{n!}{P^k_k(r_1!\\cdots r_n!)} \\]\n几何概率 古典概率的样本空间为有限集，如果样本空间是无限集，就应该使用几何概率。\n直线上的几何概率：设线段\\(l\\)是\\(L\\)的一部分，向\\(L\\)上随机投一点，投中\\(l\\)的概率为 \\[P=\\frac{l的长度}{L的长度} \\]\n平面、体积上的概率：类似于直线上，通过总体的面积或体积，以及事件所代表的面积或体积来计算。 事件的运算 蕴含、包含和相等 在同一试验下的两个事件\\(A,B\\)，若\\(A\\)发生时\\(B\\)必发生，则称\\(A\\)蕴含\\(B\\)，或者说\\(B\\)包含\\(A\\)，记为\\(A\\subset B\\)，若它们互相蕴含，则称为相等，记为\\(A=B\\)\n互斥和对立 若\\(A,B\\)不能在同一次试验中都发生（但可以都不发生），则称他们是互斥的（不相容的）。\n对立事件是互斥事件的一种特殊情况。若\\(A\\)为一事件，则事件\n\\[B=\\{A不发生\\} \\]\n称为\\(A\\)的对立事件，记为\\(\\bar{A}\\)\n事件的和 \\[C=\\{A发生，或B发生\\}=\\{A，B至少发生一个\\}=A+B=A\\cup B \\]\n概率的加法定理 若干个互斥事件之和的概率，等于各事件的概率之和\n\\[P(A_1+A_2+\\cdots)=P(A_1)+P(A_2)+\\cdots \\]\n若不是两两互斥的事件，则要考虑用容斥原理来计算。\n上式能推出\n\\[P(\\bar A)=1-P(A) \\]\n事件的积 \\[C=\\{A,B都发生\\}=AB=A\\cap B \\]\n事件的差 \\[C=\\{A发生，B不发生\\}=A-B \\]\n显然有\n\\[A-B = A\\bar B \\]\n两个重要公式 \\[\\overline{A_1A_2\\cdots A_n}=\\sum_{i=1}^n\\bar{A_i} \\]\n\\[\\overline{A_1+A_2+\\cdots+A_n}=\\prod_{i=1}^n\\bar{A_i} \\]\n条件概率 设有两个事件\\(A,B\\)，而\\(P(B)\\neq0\\)。则“在给定\\(B\\)发生的条件下\\(A\\)的条件概率”，记为\\(P(A|B)\\)，定义为\n\\[P(A|B)=P(AB)/P(B) \\]\n但并不一定要用这个公式去计算，有时直接用加入了条件的情况去算会更为方便。\n事件的独立性、概率乘法定理 若\\(P(A)=P(A|B)\\)，则\\(B\\)的发生与否对\\(A\\)发生的可能性毫无影响。这时，在概率论上称\\(A,B\\)两事件独立。\n同时就有\n\\[P(AB) = P(A)P(B) \\]\n若两事件\\(A,B\\)满足上式，则称\\(A,B\\)独立。反过来说独立的两个事件就有上式，也称为概率的乘法定理。\n将其推广，设\\(A_1,A_2,\\cdots\\)为有限或无限个事件。如果从其中任意取出有限个\\(A_{i_1},A_{i_2},\\cdots,A_{i_m}\\)，都有\n\\[P(A_{i_1}A_{i_2}\\cdots A_{i_m})=P(A_{i_1})P(A_{i_2})\\cdots P(A_{i_m}) \\]\n则称\\(A_1,A_2,\\cdots\\)互相独立。互相独立的几个事件则具有以上的乘积性质。\n等价的来说也有\n\\[P(A_{i_1}|A_{i_2}\\cdots A_{i_m})=P(A_{i_1}) \\]\n可以推出：独立事件的任一部分也独立。\n还有：若一列事件相互独立，则将其中任一部分改为对立事件时，所有事件仍然相互独立。\n全概率公式 设\\(B_1,B_2,\\cdots\\)为有限或无限个事件，它们两两互斥且在每次试验中至少发生一个。即\n\\[B_iB_j=\\empty(i\\neq j) \\]\n\\[B_1+B_2+\\cdots = \\Omega（必然事件） \\]\n有时，这样的一组事件称为完备事件群。\n现有任一事件\\(A\\)，有\\(A=A\\Omega=AB_1+AB_2+\\cdots\\)。而\\(B_1,B_2,\\cdots\\)两两互斥，则\\(AB_1,AB_2,\\cdots\\)也两两互斥，固有\n\\[P(A) = P(AB_1)+P(AB_2)+\\cdots \\]\n再由条件概率\\(P(AB_i)=P(B_i)P(A|B_i)\\)，得\n\\[P(A) = P(B_1)P(A|B_1) + P(B_2)P(A|B_2) + \\cdots \\]\n上式称为全概率公式。\n贝叶斯公式 由全概率公式，有\n\\[P(B_i|A)=P(AB_i)/P(A)\\\\=P(B_i)P(A|B_i)/\\sum_jP(B_j)P(A|B_j) \\]\n随机变量及其分布 随机变量的概念 随机变量就是其值随机会而定的变量。例如从一大批产品中随机抽出100个，其中所含的废品数为\\(X\\)。这个\\(X\\)就是一个随机变量。\n随机变量区分为两大类\n离散型随机变量。其特征是只能取有限个值，或者虽然能取无限个，但可以一个一个地排列出来（类似于可数无限）。 连续性随机变量。不仅是无穷多的，而且类似于不可数无限，充满一个区间。 离散型随机变量 定义1\n设\\(X\\)为离散型随机变量，其全部可能值为\\(\\{a_1,a_2,\\cdots\\}\\)，则\n\\[p_i=P(X=a_i)\\quad(i=1,2,\\cdots) \\]\n称为\\(X\\)的概率函数\n显然有\n\\[p_i\\geq 0,\\quad p_1+p_2+\\cdots = 1 \\]\n定义2\n设\\(X\\)为一随机变量，则函数\n\\[P(X\\leq x) = F(x)\\quad(-\\infty\u003c x\u003c\\infty) \\]\n称为\\(X\\)的分布函数。这里不限制\\(X\\)是离散型的。\n\\[F(x) = P(X\\leq x) = \\sum_{\\{i|a_i\\leq x\\}}p_i \\]\n分布函数具有如下性质\n\\(F(x)\\)是单调非降的：\\(x_1\\leq x_2\\)时，有\\(F(x_1)\\leq F(x_2)\\) \\(x\\to \\infty\\)时，\\(F(x)\\to 1\\)。\\(x\\to -\\infty\\)时，\\(F(x)\\to 0\\) 连续型随机变量 与离散型的有限或可数无限不同，这是一种充满整个区间的随机变量，或者说不可数无限。\n刻画连续型随机变量可以用之前提到的概率分布函数，但是更常用概率密度函数。\n概率密度函数 设连续型随机变量\\(X\\)有概率分布函数\\(F(x)\\)，则\\(F(x)\\)的导数\\(f(x)=F'(x)\\)称为\\(X\\)的概率密度函数。\n具有如下性质\n\\(f(x)\\geq 0\\) \\(\\int^\\infty_{-\\infty}f(x)dx=1\\) 对于任何常数\\(a\u003c b\\)，有 \\[P(a\\leq X\\leq b)=F(b)-F(a) = \\int^b_af(x)dx \\]\n多维随机变量（随机向量） 离散型随机向量的分布 一般的，设\\(X=(X_1,X_2,\\cdots,X_n)\\)为一个\\(n\\)维向量，其每个分量，即\\(X_1,\\cdots,X_n\\)都是一维随机变量，则称\\(X\\)是一个\\(n\\)维随机向量或\\(n\\)维随机变量。\n如果一个随机向量\\(X\\)，其每一个分量\\(X_i\\)都是一维离散型随机变量，则称\\(X\\)是离散型的。\n以\\(\\{a_{i1},a_{i2},\\cdots\\}\\)记\\(X_i\\)的全部可能值，则事件\\(\\{X_1=a_{1j_1}, X_2=a_{2j_2},\\cdots,X_n=a_{nj_n}\\}\\)的概率\n\\[p(j_1,j_2,\\cdots,j_n)=P(X_1=a_{1j_1}, X_2=a_{2j_2},\\cdots,X_n=a_{nj_n}) \\]\n称为随机向量\\(X\\)的概率函数或概率分布，其应该满足\n\\[p(j_1,j_2,\\cdots,j_n)\\geq 0,\\sum_{j_n}\\cdots\\sum_{j_2}\\sum_{j_1}p(j_1,j_2,\\cdots,j_n) = 1 \\]\n连续型随机向量的分布 设\\(X\\)是一个\\(n\\)维随机向量，其取值可视为\\(n\\)维欧式空间\\(\\mathbb{R} ^n\\)中的一个点。如果\\(X\\)的全部取值能充满\\(\\mathbb{R} ^n\\)中某一区域，则称它是连续型的。\n若\\(f(x_1,\\cdots,x_n)\\)是定义在\\(\\mathbb{R} ^n\\)上的非负函数，使对\\(\\mathbb{R} ^n\\)中的任何集合\\(A\\)，有\n\\[P(X\\in A) = \\int\\cdots\\int f(x_1,\\cdots,x_n)dx_1\\cdots dx_n \\]\n则称\\(f\\)是\\(X\\)的概率密度函数\n如果把\\(A\\)取成\\(\\mathbb{R} ^n\\)，则有\n\\[\\int^\\infty_{-\\infty}\\cdots\\int^\\infty_{-\\infty} f(x_1,\\cdots,x_n)dx_1\\cdots dx_n = 1 \\]\n对于二维情况\n\\[F(x,y) = \\int^y_{-\\infty}\\int^x_{-\\infty}f(u,v)dudv \\]\n\\[\\frac{\\partial^2 F(x,y)}{\\partial x\\partial y}=f(x,y) \\]\n在\\(\\Delta x,\\Delta y\\)很小时，有\\(P(x\u003c X\u003c x+\\Delta x,y\u003c Y\u003c y+\\Delta y)\\approx f(x,y)\\Delta x\\Delta y\\)\n若\\(G\\)为\\(xOy\\)内的任意区域，点\\((x,y)\\)落在\\(G\\)内的概率为\n\\[P\\{(X,Y)\\in G\\}=\\iint_G f(x,y)dxdy \\]\n与一维的情况一样，也可以用概率分布函数去描述多维随机向量的概率分布，其定义为\n\\[F(x_1,x_2,\\cdots,x_n)=P(X_1\\leq x_1, X_2\\leq x_2,\\cdots,X_n\\leq x_n) \\]\n其基本性质，以二维为例，有\n\\(F(x,y)\\)是\\(x,y\\)的不减函数 \\(0\\leq F(x,y)\\leq 1,F(-\\infty,-\\infty) = 0,F(\\infty,\\infty)=1\\) 对于任意\\(x\\)，\\(F(x,-\\infty)=0\\)，对于任意\\(y\\)，\\(F(-\\infty,y)=0\\)\n\\(F(x,y)\\)关于\\(x,y\\)均为右连续，\\(F(x+0,y) = F(x,y)\\)，\\(F(x,y+0) = F(x,y)\\) 若\\(x_1\u003c x_2,y_1\u003c y_2\\)，则\\(F(x_2,y_2)+F(x_1,y_1)-F(x_2,y_1)-F(x_1,y_2)\\geq 0\\) 另外，有\n\\[f(x,y) = \\frac{\\partial^2F(x,y)}{\\partial x\\partial y} \\]\n边缘分布 设\\(X=(X_1,\\cdots,X_n)\\)为一个\\(n\\)维随机向量。\\(X\\)有一定的分布\\(F\\)，这是一个\\(n\\)维分布，因为\\(X\\)的每个分量\\(X_i\\)都是一维随机变量，故它们都有各自的分布\\(F_i\\)，这些都是一维分布，称为随机向量\\(X\\)或其分布\\(F\\)的边缘分布。边缘分布完全由原分布\\(F\\)确定。\n例如，在离散型的情况下，边缘分布\\(P(X_1=a_{1k})\\)就等于\n\\[P(X_1=a_{1k})=\\sum_{j_2,\\cdots,j_n}p(k,j_2,\\cdots,j_n) \\]\n对于连续型的情况，例如求\\(f_1(x_1)\\)\n\\[f_1(x_1) = \\int^\\infty_{-\\infty}\\cdots \\int^\\infty_{-\\infty}f(x_1,x_2,\\cdots,x_n)dx_2\\cdots dx_n \\]\n当然，如果题目有要求变量的范围，则积分上下限要改成相应的值。\n直观上的理解，就是将其他变量的所有情况的概率全部加起来。\n联合分布 边缘分布指的是随机向量中的一个分量的分布。\n而相对应的联合分布，就是强调\\((X_1,\\cdots,X_n)\\)的分布是把\\(X_1,\\cdots,X_n\\)作为一个有联系的整体来考虑的。\n当然有些时候边缘分布也可以指众多分量中几个分量的分布。\n条件概率分布 概念同前面提到的条件概率。\n离散型 同之前计算条件概率相同，只不过通常此时要用到边缘分布等概念。\n例如设\n\\[p_{ij}=P(X_1=a_i,X_2=b_j) \\]\n则\n\\[P(X_1=a_i|X_2=b_j) = P(X_1=a_i,X_2=b_j)/P(X_2=b_j) = p_{ij}/P(X_2=b_j) \\]\n连续型 以二维情况为例\n\\[P(X_1\\leq x_1|a\\leq X_2\\leq b)=P(X_1\\leq x_1,a\\leq X_2\\leq b)/P(a\\leq X_2\\leq b) \\]\n写成积分形式\n\\[=\\int^{x_1}_{-\\infty}dt_1\\int^b_af(t_1,t_2)dt_2\\bigg/\\int^b_af_2(t_2)dt_2 \\]\n\\(a=b\\)的情况下，可以通过极限求出\n\\[f_1(x_1|x_2) = f(x_1,x_2)/f_2(x_2) \\]\n可改写为\n\\[f(x_1,x_2) = f_1(x_1|x_2)f_2(x_2) \\]\n可以推广到\n\\[f(x_1,\\cdots,x_n) = g(x_1,\\cdots,x_k)h(x_{k+1},\\cdots,x_n|x_1,\\cdots,x_k) \\]\n随机变量的独立性 定义1\n设\\(n\\)维随机向量\\((X_1,\\cdots,X_n)\\)的联合密度函数为\\(f(x_1,x_2,\\cdots,x_n)\\)，而\\(X_i\\)的边缘密度函数为\\(f_i(x_i)\\)，如果\n\\[f(x_1,\\cdots,x_n) = f_1(x_1)\\cdots f_n(x_n) \\]\n则称随机变量\\(X_1,\\cdots,X_n\\)相互独立。\n定理1\n如果连续变量\\(X_1,\\cdots,X_n\\)相互独立，则对任何\\(a_i\u003c b_i\\)，则由下式定义的\\(n\\)个事件也独立\n\\[A_1=\\{a_1\\leq X_1\\leq b_1\\},\\cdots,A_n=\\{a_n\\leq X_n\\leq b_n\\} \\]\n反之，若对任何\\(a_i\u003c b_i\\)，事件\\(A_1,\\cdots,A_n\\)独立，则变量\\(X_1,\\cdots,X_n\\)独立。\n定理2\n若随机向量\\((X_1,\\cdots,X_n)\\)的概率密度函数\\(f(x_1,x_2,\\cdots,x_n)\\)可表示为\\(n\\)个函数\\(g_1,\\cdots,g_n\\)之积，其中\\(g_i\\)只依赖于\\(x_i\\)，即\n\\[f(x_1,x_2,\\cdots,x_n) = g_1(x_1)\\cdots g_n(x_n) \\]\n则\\(X_1,\\cdots,X_n\\)相互独立，且\\(X_i\\)的边缘密度函数\\(f_i(x_i)\\)与\\(g_i(x_i)\\)只相差一个常数因子。\n定理3\n若\\(X_1,\\cdots,X_n\\)相互独立，而\n\\[Y_1=g_1(X_1,\\cdots,X_m), Y_2 = g_2(X_{m+1},\\cdots,X_n) \\]\n则\\(Y_1,Y_2\\)独立。\n定义2\n设\\(X_1,\\cdots,X_n\\)是离散型随机变量，若对任何常数\\(a_1,\\cdots,a_n\\)都有\n\\[P(X_1=a_1,\\cdots,X_n=a_n) = P(X_1=a_1)\\cdots P(X_n=a_n) \\]\n则称\\(X_1,\\cdots, X_n\\)相互独立。\n随机变量的函数的概率分布 在理论和应用上，经常碰到这种情况：已知某个或某些随机变量\\(X_1,\\cdots,X_n\\)的分布，现另有一些随机变量\\(Y_1,\\cdots,Y_m\\)，它们都是\\(X_1,\\cdots,X_n\\)的函数：\n\\[Y_i=g_i(X_1,\\cdots,X_n) \\]\n要求\\((Y_1,\\cdots,Y_m)\\)的概率分布。\n离散型分布的情况 离散分布的情况比较简单，只需要列举\\(Y_i=y_i\\)时的所有\\(X\\)的可能就可以了。\n连续型分布的情况的一般讨论 先考虑一个变量的情况，设\\(X\\)有密度函数\\(f(x)\\). 设\\(Y=g(x)\\)。\\(g\\)严格上升或下降。所以\\(g'\\)存在，反函数\\(X=g^{-1}(Y)\\)存在，且\\((g^{-1})'\\)也存在。\n则\\(Y\\)的密度函数为\n\\[f_Y(y)=f(g^{-1}(y))|(g^{-1}(y))'| \\]\n现在考虑多个变量，以两个变量为例，设\\((X_1,X_2)\\)的密度函数为\\(f(x_1,x_2)\\)，以及\n\\[Y_1=g_1(X_1,X_2),\\quad Y_2=g_2(X_1,X_2) \\]\n要求\\(f_Y(y_1,y_2)\\)，假定上式是一一对应变换，则有逆变换\n\\[X_1=g^{-1}_1(Y_1,Y_2),\\quad X_2=g^{-1}_2(Y_1,Y_2) \\]\n假设\\(g_1,g_2\\)都有一阶连续偏导数，则其反函数也有一阶连续偏导数，且雅克比行列式\n\\[J(y_1,y_2)= \\begin{vmatrix} \\partial g^{-1}_1/\\partial y_1 \u0026 \\partial g^{-1}_1/\\partial y_2\\\\ \\partial g^{-1}_2/\\partial y_1 \u0026 \\partial g^{-1}_2/\\partial y_2 \\end{vmatrix} \\]\n不为\\(0\\). 有\n\\[f_Y(y_1,y_2) = f(g^{-1}_1(y_1,y_2),g^{-1}_2(y_1,y_2))|J(y_1,y_2)| \\]\n随机变量和的密度函数 设\\((X_1,X_2)\\)的联合密度函数为\\(f(x_1,x_2)\\)，要求\n\\[Y=X_1+X_2 \\]\n的密度函数。\n有\n\\[f_Y(y) = \\int^\\infty_{-\\infty}f(x_1,y-x_1)dx_1=\\int^\\infty_{-\\infty}f(x,y-x)dx \\]\n或者作变量代换也有\n\\[f_Y(y) = \\int^\\infty_{-\\infty}f(y-x,x)dx \\]\n如果\\(X_1,X_2\\)独立，则\\(f(x_1,x_2)=f_1(x_1)f_2(x_2)\\)，有\n\\[f_Y(y) = \\int^\\infty_{-\\infty}f_1(x)f_2(y-x)dx = \\int^\\infty_{-\\infty}f_1(y-x)f_2(x)dx \\]\n随机变量商的密度函数 设\\((X_1,X_2)\\)有密度函数\\(f(x_1,x_2)\\)，\\(Y=X_2/X_1\\)，要求\\(Y\\)的密度函数\n\\[f_Y(y) = \\int^\\infty_{-\\infty} |x_1|f(x_1,x_1y)dx_1 \\]\n若\\(X_1,X_2\\)独立，则\n\\[f_Y(y) = \\int^\\infty_{-\\infty} |x_1|f_1(x_1)f_2(x_1y)dx_1 \\]\n随机变量积的密度函数 设\\((X_1,X_2)\\)有密度函数\\(f(x_1,x_2)\\)，\\(Y=X_1X_2\\)，要求\\(Y\\)的密度函数\n\\[f_Y(y) = \\int^\\infty_{-\\infty} \\frac{1}{|x_1|}f(x_1,\\frac{y}{x_1})dx_1 \\]\n若\\(X_1,X_2\\)独立，则\n\\[f_Y(y) = \\int^\\infty_{-\\infty} \\frac{1}{|x_1|}f_1(x_1)f_2(\\frac{y}{x_1})dx_1 \\]\n常见的分布 0-1分布 设某个事件\\(A\\)在一次试验中发生的概率为\\(p\\)，重复试验\\(1\\)次，以\\(X\\)记\\(A\\)在\\(1\\)次试验中发生的次数，则\n\\[P(X=i)=p^i(1-p)^{1-i}\\quad (i=0,1) \\]\n数学期望 \\[p \\]\n方差 \\[p(1-p) \\]\n二项分布 设某个事件\\(A\\)在一次试验中发生的概率为\\(p\\)，重复试验\\(n\\)次，以\\(X\\)记\\(A\\)在\\(n\\)次试验中发生的次数，则\n\\[p_i=b(i;n,p)=\\binom{n}{i}p^i(1-p)^{n-i}\\quad (n=0,1,\\cdots,n) \\]\n服从有两个条件\n各次试验的条件是稳定的 各次试验的独立性 如果抽检后放回，则每次抽出废品的概率是相等的。如果抽检后不放回，则废品率发生了变化，试验条件不稳定，不符合二项分布。但是如果总数远大于抽出的数量，则不放回也几乎不影响，可以近似地作为二项分布。\n通常也会记作，\\(B(n,p)\\)\n数学期望 \\[np \\]\n方差 \\[np(1-p) \\]\n泊松分布 若随机变量\\(X\\)的可能取值为\\(0,1,2,\\cdots\\)，且概率分布为\n\\[P(X=i)=e^{-\\lambda}\\lambda^i/i! \\]\n则称\\(X\\)服从泊松分布。记为\\(X\\sim P(\\lambda)\\)。\\(\\lambda\u003e0\\)是某一常数。式子右边对\\(i=0,1,\\cdots\\)求和的结果为\\(1\\)。可以从\\(e^\\lambda=\\sum^\\infty_{i=0}\\lambda^i/i!\\)得出。\n这个分布多出现在当\\(X\\)表示在一定时间或空间内出现的事件个数的场合。比如一定时间内某交通路口所发生的事故个数。\n泊松分布可以看做二项分布的极限。若\\(X\\sim B(n,p)\\)中\\(n\\)很大，\\(p\\)很小，而\\(np=\\lambda\\)不太大时，\\(X\\)的分布接近与泊松分布\\(P(\\lambda)\\)。推导如下：\n\\[P(X=i)=\\binom{n}{i}\\left(\\frac{\\lambda}{n}\\right)^i\\left(1-\\frac{\\lambda}{n}\\right)^{n-i} \\]\n当\\(n\\to\\infty\\)时\n\\[\\binom{n}{i}/n^i\\to 1/i!,\\quad \\left(1-\\frac{\\lambda}{n}\\right)^{n-i}\\to e^{-\\lambda} \\]\n则有\n\\[P(X=i)=e^{-\\lambda}\\lambda^i/i! \\]\n显然通常我们不会遇到\\(n\\)无限的情况，只会遇到\\(n\\)较大的情况，所以只能说接近泊松分布。\n数学期望 \\[\\lambda \\]\n我们可以证明\\(X\\)服从泊松分布时\n\\[E(X) = \\sum^\\infty_{i=0}i\\frac{\\lambda^i}{i!}e^{-\\lambda}=\\lambda \\]\n方差 \\[\\lambda \\]\n超几何分布 以\\(X\\)记从含\\(M\\)个废品的\\(N\\)个产品中随机抽出\\(n\\)个里面所含有的废品数，\\(X\\)的分布为\n\\[P(X=m)=\\binom{M}{m}\\binom{N-M}{n-m}\\bigg/\\binom{N}{n} \\]\n这是一种抽检不放回的试验，如果\\(N\\)特别大，\\(n\\)不够大时，放回与不放回差别不大。可以当作二项分布来看。或者说，若\\(X\\)服从超几何分布，则当\\(n\\)固定时，\\(M/N=p\\)固定；\\(N\\to \\infty\\)时，\\(X\\)近似服从二项分布\\(B(n,p)\\)。\n数学期望 \\[\\frac{nM}{N} \\]\n方差 \\[\\frac{nM(N-M)(N-n)}{N^2(N-1)} \\]\n负二项分布 先指定一个自然数\\(r\\)，一个一个地从一批产品中抽样检查，直到发现第\\(r\\)个废品，以\\(X\\)记此时已经抽出的合格产品个数。\n显然\\(\\{X=i\\}\\)这个事件发生时，需要满足\n在前\\(i+r-1\\)次抽取中，正好有\\(r-1\\)个废品 第\\(i+r\\)次抽出废品 所以有\n\\[P(X=i) = b(r-1;i+r-1,p)p \\]\n\\[=\\binom{i+r-1}{r-1}p^r(1-p)^i \\]\n负二项分布的名称来源于\n\\[(1-x)^{-r}=\\sum_{i=0}^{\\infty}\\binom{-r}{i}(-x)^i=\\sum_{i=0}^{\\infty}\\binom{i+r-1}{i}x^i \\]\n\\[=\\sum_{i=0}^{\\infty}\\binom{i+r-1}{r-1}x^i \\]\n其中令\\(x=1-p\\)，两边乘以\\(p^r\\)，得\n\\[1 = p^r[1-(1-p)]^{-r}=\\sum_{i=0}^{\\infty}\\binom{i+r-1}{r-1}p^r(1-p)^i \\]\n几何分布 当负二项分布中的\\(r=1\\)时，有\n\\[P(X=i) = p(1-p)^i \\]\n数学期望 \\[\\frac{1}{p} \\]\n方差 \\[\\frac{1-p}{p^2} \\]\n多项分布 设\\(A_1,A_2,\\cdots,A_n\\)是某一试验之下的完备事件群，即事件\\(A_1,\\cdots,A_n\\)两两互斥，其和为必然事件。分别以\\(p_1,p_2,\\cdots,p_n\\)记每个事件对应的概率。\n现将试验独立重复\\(N\\)次，而以\\(X_i\\)记载着\\(N\\)次试验中事件\\(A_i\\)出现的次数。\\(X\\)的概率分布就叫做多项分布，有时记为\\(M(N;p_1,\\cdots,p_n)\\)。其概率有\n\\[P(X_1=k_1,X_2=k_2,\\cdots,X_n=k_n)=\\frac{N!}{k_1!k_2!\\cdots k_n!}p_1^{k_1}p_2^{k_2}\\cdots p_n^{k_n} \\]\n正态分布 如果一个随机变量具有概率密度函数\n\\[f(x)=(\\sqrt{2\\pi}\\sigma)^{-1}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\quad (-\\infty \u003c x \u003c + \\infty ) \\]\n则称\\(X\\)为正态随机变量，并记为\\(X\\sim N(\\mu,\\sigma^2)\\)。\\(\\mu,\\sigma^2\\)是常数，\\(\\mu\\in R,0\u003c\\sigma^2\u003c\\infty\\)，它们称为这个分布的参数。由后续的方差一节，\\(Var(X)=\\sigma^2\\)，就是分布的方差。\n正态分布的概率密度函数的图像关于\\(x=\\mu\\)对称，中间高两边低。\n当\\(\\mu=0,\\sigma^2=1\\)时，称为标准正态分布\\(N(0,1)\\)\n\\[f(x)=e^{-x^2/2}/\\sqrt{2\\pi} \\]\n通常\\(N(0,1)\\)的密度函数和分布函数也会记为\\(\\varphi(x)\\)和\\(\\varPhi(x)\\)。\n任意一个正态分布都可以转化为标准正态分布，便于查表。\n\\[if\\quad X\\sim N(\\mu,\\sigma^2),then\\quad Y=(X-\\mu)/\\sigma\\sim N(0,1) \\]\n例如\\(X\\sim N(1.5,2^2)\\)，要计算\\(P(-1\\leq X\\leq 2)\\)，则因\\((X-1.5)/2\\sim N(0,1)\\)，有\n\\[P(-1\\leq X\\leq 2) = P\\left(\\frac{-1-1.5}{2}\\leq\\frac{X-1.5}{2}\\leq\\frac{2-1.5}{2}\\right) \\]\n\\[=P(-1.25\\leq(X-1.5)/2\\leq 0.25) \\]\n\\[=\\varPhi(0.25)-\\varPhi(-1.25) \\]\n可以查表代入。但是通常只有非负数的值，对于负数\\(x\\)，有\n\\[\\varPhi(x) = 1-\\varPhi(-x) \\]\n正态分布的线性组合性质 对于正态分布，设\\(X_1,X_2\\)分别服从正态分布\\(N(\\mu_1,\\sigma_1^2),N(\\mu_2,\\sigma_2^2)\\)，对于\\(Y=X_1+X_2\\)\n\\(X_1,X_2\\)独立，则\\(Y\\sim N(\\mu_1+\\mu_2, \\sigma_1^2+\\sigma_2^2)\\)。并且反过来说\\(Y\\)符合正态分布，而\\(Y\\)可以表示为两个独立变量的和\\(Y=X_1+X_2\\)，则\\(X_1,X_2\\)必须服从正态分布。 \\(X_1,X_2\\)不独立，但其联合分布为二维正态分布\\(N(\\mu_1,\\mu_2, \\sigma_1^2,\\sigma_2^2,\\rho)\\)，则\\(Y\\)仍然服从正态分布\\(Y\\sim N(\\mu_1+\\mu_2, \\sigma_1^2+\\sigma_2^2+2\\rho\\sigma_1\\sigma_2)\\) 同样可以推广到多维情况，\\(X_1,\\cdots,X_n\\)相互独立，分别服从\\(N(\\mu_1,\\sigma_1^2),\\cdots,N(\\mu_n,\\sigma_n^2)\\)，则\\(X_1+\\cdots+X_n\\)服从\\(N(\\mu_1+\\cdots+\\mu_n,\\sigma_1^2+\\cdots+\\sigma_n^2)\\)\n对于不全为\\(0\\)的常数\\(C_0,C_1,\\cdots,C_n\\)，线性组合\n\\[C_0+C_1X_1+\\cdots+C_nX_n\\sim N(C_0+C_1\\mu_1+\\cdots+C_n\\mu_n,C_1^2\\sigma_1^2+\\cdots+C_n^2\\sigma_n^2) \\]\n数学期望 \\[\\mu \\]\n方差 \\[\\sigma^2 \\]\n上\\(\\alpha\\)分位点 标准正态分布的上\\(\\alpha\\)分位点查表可知，具有一个性质为\\(w_{1-\\alpha}=-w_\\alpha\\)。对于非标准的则和中位数对称。\n二维正态分布 \\[f(x_1,x_2)=(2\\pi\\sigma_1\\sigma_2\\sqrt{1-\\rho^2})^{-1}\\exp\\left[-\\frac{1}{2(1-\\rho^2)}\\left(\\frac{(x_1-a)^2}{\\sigma_1^2}-\\frac{2\\rho(x_1-a)(x_2-b)}{\\sigma_1\\sigma_2}+\\frac{(x_2-b)^2}{\\sigma_2^2}\\right)\\right] \\]\n常把这个分布记为\\(N(a,b,\\sigma_1^2,\\sigma_2^2,\\rho)\\)\nn维正态随机变量 定义1\n设\\((X_1,X_2)\\)的四个二阶中心矩都存在，把\n\\[\\begin{bmatrix} Cov(X_1) \u0026 Corr(X_1,X_2) \\\\ Corr(X_2,X_1) \u0026 Cov(X_2) \\end{bmatrix} \\]\n称为随机变量\\((X_1,X_2)\\)的协方差矩阵。\n扩展到\\(n\\)维就是\n\\[\\begin{bmatrix} Cov(X_1) \u0026 Corr(X_1,X_2) \u0026 \\cdots \u0026 Corr(X_1,X_n)\\\\ Corr(X_2,X_1) \u0026 Cov(X_2) \u0026 \\cdots \u0026 Corr(X_2,X_n)\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ Corr(X_n,X_1) \u0026 Corr(X_n,X_2) \u0026 \\cdots \u0026 Cov(X_n) \\end{bmatrix} \\]\n当然所有的协方差必须存在。\n对于二维正态分布\n\\[f(x_1,x_2)=\\\\ (2\\pi\\sigma_1\\sigma_2\\sqrt{1-\\rho^2})^{-1}\\exp\\left[-\\frac{1}{2(1-\\rho^2)}\\left(\\frac{(x_1-\\mu_1)^2}{\\sigma_1^2}-\\frac{2\\rho(x_1-\\mu_1)(x_2-\\mu_2)}{\\sigma_1\\sigma_2}+ \\frac{(x_2-\\mu_2)^2}{\\sigma_2^2}\\right)\\right] \\]\n其中\\(\\rho\\)是\\(X,Y\\)的相关系数\n所以\\((X_1,X_2)\\)的协方差矩阵是\n\\[B = \\begin{bmatrix} \\sigma_1^2 \u0026 \\rho\\sigma_1\\sigma_2 \\\\ \\rho\\sigma_1\\sigma_2 \u0026 \\sigma_2^2 \\end{bmatrix} \\]\n定义\n\\[X=\\begin{bmatrix} X_1 \\\\ X_2 \\end{bmatrix}, \\mu = \\begin{bmatrix} \\mu_1 \\\\ \\mu_2 \\end{bmatrix} \\]\n则\\(f(x_1,x_2)\\)也可以写为\n\\[f(x_1,x_2)=(2\\pi|B|^{1/2})exp\\bigg[-\\frac{1}{2}(X-\\mu)^TB^{-1}(X-\\mu)\\bigg] \\]\n扩展到\\(n\\)维，则有\n\\[f(x_1,x_2,\\cdots,x_n)=[(2\\pi)^{n/2}|B|^{1/2}]exp\\bigg[-\\frac{1}{2}(X-\\mu)^TB^{-1}(X-\\mu)\\bigg] \\]\nn维正态变量的性质\n\\(n\\)维正态随机变量\\((X_1,X_2,\\cdots,X_n)\\)的每一个分量\\(X_i\\)都是正态随机变量；反之若\\(X_1,X_2,\\cdots,X_n\\)都是正态随机变量且相互独立，则\\((X_1,X_2,\\cdots,X_n)\\)是\\(n\\)维正态随机变量 \\((X_1,X_2,\\cdots,X_n)\\)是\\(n\\)维正态随机变量的充要条件是\\(X_1,X_2,\\cdots,X_n\\)的任意线性组合\\(l_1X_1,l_2X_2,\\cdots,l_nX_n\\)服从一维正态分布（其中\\(l_1,l_2,\\cdots,l_n\\)不全为\\(0\\)） 若\\((X_1,X_2,\\cdots,X_n)\\)服从\\(n\\)维正态分布，设\\(Y_1,Y_2,\\cdots,Y_k\\)是\\(X_i\\)的线性变换，则\\((Y_1,Y_2,\\cdots,Y_k)\\)也服从\\(k\\)维正态分布 若\\((X_1,X_2,\\cdots,X_n)\\)是\\(n\\)维正态随机变量，\\(m \u003c n\\)，则\\((X_1,X_2,\\cdots,X_n)\\)的任意\\(m\\)个分量是\\(m\\)维正态随机变量 设\\((X_1,X_2,\\cdots,X_n)\\)是\\(n\\)维正态随机变量，则“\\(X_1,X_2,\\cdots,X_n\\)相互独立”与“\\(X_1,X_2,\\cdots,X_n\\)两两不相关”等价。 指数分布 若随机变量\\(X\\)有概率密度函数\n\\[f(x)=\\left\\{\\begin{matrix} \\lambda e^{-\\lambda x},\\quad x\u003e0\\\\ 0,\\quad x\\leq 0 \\end{matrix}\\right. \\]\n则\\(X\\)服从指数分布，其中\\(\\lambda\u003e0\\)是参数。通常记作\\(E(\\lambda)\\)\n其概率分布函数为\n\\[F(x)=\\left\\{\\begin{matrix} 1-e^{-\\lambda x},\\quad x\u003e0\\\\ 0,\\quad x\\leq 0 \\end{matrix}\\right. \\]\n数学期望 \\[\\frac{1}{\\lambda} \\]\n方差 \\[\\frac{1}{\\lambda^2} \\]\n威布尔分布 满足\n\\[f(x)=\\left\\{\\begin{matrix} \\lambda\\alpha x^{\\alpha-1} e^{-\\lambda x^\\alpha},\\quad x\u003e0\\\\ 0,\\quad x\\leq 0 \\end{matrix}\\right. \\]\n其概率分布函数是\n\\[F(x)=\\left\\{\\begin{matrix} 1-e^{-\\lambda x^\\alpha},\\quad x\u003e0\\\\ 0,\\quad x\\leq 0 \\end{matrix}\\right. \\]\n可见，指数分布是威布尔分布的一个特例。\n均匀分布 满足\n\\[f(x)=\\left\\{\\begin{matrix} 1/(b-a),\\quad a\\leq x\\leq b\\\\ 0,\\quad else \\end{matrix}\\right. \\]\n其概率分布函数是\n\\[F(x)=\\left\\{\\begin{align*} \u00260, \u0026\u0026x\\leq a\\\\ \u0026(x-a)/(b-a), \u0026\u0026a \u003c x \u003c b\\\\ \u00261, \u0026\u0026x\\geq b \\end{align*}\\right. \\]\n常记作\\(R(a,b),U(a,b)\\)\n数学期望 \\[\\frac{a+b}{2} \\]\n方差 \\[\\frac{(b-a)^2}{12} \\]\n二维随机向量的均匀分布 \\[f(x_1,x_2)= \\left\\{\\begin{matrix} 1/[(b-a)(d-c)],\\quad a\\leq x_1\\leq b, c\\leq x_2\\leq d\\\\ 0,\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad other\\quad\\quad\\quad\\quad\\quad\\quad \\end{matrix}\\right. \\]\n以上是矩形情况的密度函数\n如果扩展到任意形状的图形，只要求出来其面积，那么密度函数在图形内部就是\\(1/S\\)，图形外部是\\(0\\)\n最大值分布 设\\(M=max\\{X,Y\\}\\)，\\(X,Y\\)相互独立，则\n\\[F_{max}(z)=P(M\\leq z)=P(X\\leq z, Y\\leq z)=P(X\\leq z)P(Y\\leq z) \\]\n\\[F_{max}(z) = F_X(z)F_Y(z) \\]\n扩展到多维情况\n\\[F_{max}(z) = F_{X_1}(z)F_{X_2}(z)\\cdots F_{X_n}(z) \\]\n最小值分布 设\\(N=min\\{X,Y\\}\\)，\\(X,Y\\)相互独立，则\n\\[F_{min}(z)=P(N\\leq z)=1-P(N\u003ez)=1-P(X\u003ez, Y\u003ez)=1-P(X\u003ez)P(Y\u003ez) \\]\n\\[F_{min}(z) = 1-[1-F_X(z)][1-F_Y(z)] \\]\n扩展到多维情况\n\\[F_{min}(z) = 1-[1-F_{X_1}(z)][1-F_{X_2}(z)]\\cdots [1-F_{X_n}(z)] \\]\n卡方分布 \\(\\Gamma\\)函数\n通过积分\n\\[\\Gamma(x) = \\int^\\infty_0 e^{-t}t^{x-1}dt(x\u003e0) \\]\n来定义\n\\(\\Beta\\)（Beta）函数\n通过积分\n\\[\\Gamma(x) = \\int^1_0 t^{x-1}(1-t)^{y-1}dt(x\u003e0 ,y\u003e0) \\]\n来定义\n\\(\\Gamma\\)函数的性质\n\\(\\Gamma(1)=1\\) \\(\\Gamma(1/2)=\\sqrt{\\pi}\\) \\(\\Gamma(x+1)=x\\Gamma(x)\\) 因此可知，\\(n\\)为正整数时\n\\[\\Gamma(n) = (n-1)! \\]\n\\(n\\)为正奇数时\n\\[\\Gamma(n/2) = 1\\cdot 3\\cdot 5\\cdots(n-2)2^{-(n-1)/2}\\sqrt{\\pi} \\]\n其中\\(\\Gamma\\)与\\(\\Beta\\)函数之间有重要的关系式\n\\[\\Beta(x,y)=\\Gamma(x)\\Gamma(y)/\\Gamma(x+y) \\]\n卡方分布\n由\\(\\Gamma\\)函数的定义可知，若\\(n\u003e0\\)，则函数\n\\[k_n(x)=\\left\\{\\begin{align*} \u0026\\frac{1}{\\Gamma(n/2)2^{n/2}}e^{-x/2}x^{(n-2)/2} \u0026,\\quad x\u003e0\\\\ \u00260 \u0026,\\quad x\\leq 0 \\end{align*}\\right. \\]\n是概率密度函数。它称为“自由度为\\(n\\)的皮尔逊卡方密度”，常记为\\(\\mathcal{X}{}_n^2\\)\n定理1\n若\\(X_1,\\cdots,X_n\\)相互独立，都服从正态分布\\(N(0,1)\\)，则\\(Y=X_1^2+\\cdots+X_n^2\\)服从自由度为\\(n\\)的卡方分布\\(\\mathcal{X}{}_n^2\\)\n卡方分布有如下性质\n设\\(X_1,X_2\\)独立，\\(X_1\\sim \\mathcal{X}_m^2,X_2\\sim \\mathcal{X}_n^2\\)，则\\(X_1+X_2\\sim \\mathcal{X}_{m+n}^2\\) 若\\(X_1,\\cdots,X_n\\)独立，且都服从指数分布，则 \\[X=2\\lambda(X_1+\\cdots+X_n)\\sim \\mathcal{X}_{2n}^2 \\]\n期望\n若\\(X\\sim\\mathcal{X}_n^2\\)，\\(E(X)=n\\)\n方差\n若\\(X\\sim\\mathcal{X}_n^2\\)，\\(D(X)=2n\\)\n上\\(\\alpha\\)分位点\n可由查表得到。有一个性质，当\\(n\\)充分大，如\\(n\u003e40\\)时，则其上\\(\\alpha\\)分位点约为\n\\[\\dfrac{1}{2}\\bigg(w_\\alpha+\\sqrt{2n-1}\\bigg)^2 \\]\n其中\\(w_\\alpha\\)是标准正态分布的上\\(\\alpha\\)分位点\nt分布 若\\(X\\sim N(0,1),Y\\sim\\mathcal{X}_n^2\\)，且\\(X,Y\\)相互独立\n\\(t=X/\\sqrt{Y/n}\\)的密度函数为\n\\[t_n(y)=\\frac{\\Gamma((n+1)/2)}{\\sqrt{n\\pi}\\Gamma(n/2)}\\bigg(1+\\frac{y^2}{n}\\bigg)^{-\\frac{n+1}{2}} \\]\n这个密度函数称为“自由度为\\(n\\)的\\(t\\)分布”的密度函数，常简记为\\(t_n\\)\n\\(n\\)充分大时\n\\[\\lim_{n\\to\\infty}t_n(y)=\\frac{1}{\\sqrt{2\\pi}}e^{-t^2/2} \\]\n上\\(\\alpha\\)分位点\n查表可知。\n具有对称性\\(w_{1-\\alpha}=-w_\\alpha\\)\n当\\(n\\)充分大，如\\(n\u003e45\\)时，其分位点和标准正态分布近似。\nF分布 设\\(U\\sim\\mathcal{X}_{n_1}^2,V\\sim\\mathcal{X}_{n_2}^2\\)，且\\(U,V\\)相互独立，则称随机变量\n\\[F = \\frac{U/n_1}{V/n_2} \\]\n服从自由度为\\((n_1,n_2)\\)的\\(F\\)分布，概率密度为\n\\[f_{n_1,n_2}(y) = n_1^{n_1/2}n_2^{n_2/2}\\frac{\\Gamma(\\frac{n_1+n_2}{2})}{\\Gamma(\\frac{n_1}{2})\\Gamma(\\frac{n_2}{2})}y^{n_1/2-1}(n_1y+n_2)^{-(n_1+n_2)/2} \\]\n性质\n若\\(F\\sim F(n_1,n_2)\\)，则\\(\\frac{1}{F}\\sim F(n_2,n_1)\\)\n上\\(\\alpha\\)分位点\n查表可知。\n性质如下：\n\\[F_{1-\\alpha}(n_1,n_2) = \\dfrac{1}{F_\\alpha(n_2,n_1)} \\]\n八大分布 单正态总体 设\\(X\\sim N(\\mu,\\sigma^2)\\)，而\\(X_1,X_2,\\cdots,X_n\\)是来自正态总体\\(N(\\mu,\\sigma^2)\\)的样本，\\(\\overline{X}\\)和\\(S^2\\)分别是样本均值和样本方差，则有\n\\[\\overline{X}\\sim N(\\mu,\\sigma^2/n)\\quad\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt n}\\sim N(0,1) \\]\n\\[\\frac{\\sum^n_{i=1}(X_i-\\mu)^2}{\\sigma^2}\\sim \\mathcal{X}^2_n \\]\n\\[\\frac{(n-1)S^2}{\\sigma^2}\\sim\\mathcal{X}^2_{n-1}\\quad \\frac{\\sum^n_{i=1}(X_i-\\overline X)^2}{\\sigma^2}\\sim \\mathcal{X}^2_{n-1}且\\overline X与S^2相互独立 \\]\n\\[\\frac{\\overline X-\\mu}{S/\\sqrt n}\\sim t(n-1) \\]\n双正态总体 设\\((X_1,\\cdots,X_{n_1})\\)和\\((Y_1,\\cdots,Y_{n_2})\\)分别是来自正态总体\\(N(\\mu_1,\\sigma_1^2)\\)和\\(N(\\mu_2,\\sigma_2^2)\\)的样本，且这两个样本相互独立，设\\(\\overline X,\\overline Y\\)分别是样本均值\n\\[\\frac{(\\overline X-\\overline Y)-(\\mu_1-\\mu_2)}{\\sqrt{\\sigma_1^2/n_1+\\sigma_2^2/n_2}}\\sim N(0,1) \\]\n当\\(\\sigma_1=\\sigma_2\\)未知时 \\[\\frac{(\\overline X-\\overline Y)-(\\mu_1-\\mu_2)}{S_W\\sqrt{1/n_1+1/n_2}}\\sim t(n_1+n_2-2) \\]\n其中\n\\[S_W = \\sqrt{\\frac{(n_1-1)S_1^2+(n_2-1)S_2^2}{n_1+n_2-2}} \\]\n\\[\\frac{n_2\\sigma_2^2\\sum^{n_1}_{i=1}(X_i-\\mu_1)^2}{n_1\\sigma_1^2\\sum^{n_2}_{i=1}(Y_i-\\mu_2)^2}\\sim F(n_1,n_2) \\]\n\\[\\frac{S_1^2/S_2^2}{\\sigma_1^2/\\sigma_2^2}\\sim F(n_1-1,n_2-1) \\]\n随机变量的数字特征 数学期望与中位数 定义 定义1\n设随机变量\\(X\\)只取有限个可能值\\(a_1,\\cdots,a_m\\)，其概率分布为\\(P(X=a_i)=p_i(i=1,\\cdots,m)\\)，则\\(X\\)的数学期望，记为\\(E(X)\\)或\\(EX\\)，定义为\n\\[E(X) = a_1p_1+a_2p_2+\\cdots+a_mp_m \\]\n如果取无穷个值\\(a_1,a_2,\\cdots\\)，而概率分布为\\(P(X=a_i)=p_i(i=1,\\cdots)\\)，则有其数学期望为\n\\[E(X) = \\sum^\\infty_{i=1}a_ip_i（式1） \\]\n这个期望存在，必须要求这个级数收敛，并且是绝对收敛。\n定义2\n如果\n\\[\\sum^\\infty_{i=1}|a_i|p_i\u003c\\infty \\]\n则称式1的右边的级数之和为\\(X\\)的数学期望\n定义3\n设\\(X\\)有概率密度函数\\(f(x)\\)，如果\n\\[\\int^\\infty_{-\\infty}|x|f(x)dx\u003c\\infty \\]\n则称\n\\[E(X) = \\int^\\infty_{-\\infty}xf(x)dx \\]\n为\\(X\\)的数学期望。\n性质 定理1\n若干个随机变量之和的期望等于各变量的期望之和\n\\[E(X_1+X_2+\\cdots+X_n) = E(X_1)+E(X_2)+\\cdots+E(X_n) \\]\n定理2\n若干个独立（注意独立）随机变量之积的期望等于各变量期望之积\n\\[E(X_1X_2\\cdots X_n) = E(X_1)E(X_2)\\cdots E(X_n) \\]\n随机变量函数的期望\n设随机变量\\(X\\)为离散型，有分布\\(P(X=a_i)=p_i(i=1,2,\\cdots)\\)；或者为连续型，有概率密度函数\\(f(x)\\)，则\n\\[E(g(x)) = \\sum_i g(a_i)p_i（要求绝对收敛） \\]\n或\n\\[E(g(x)) = \\int^\\infty_{-\\infty}g(x)f(x)dx（要求\\int^\\infty_{-\\infty}|g(x)|f(x)dx\u003c\\infty） \\]\n有一个特例是，若\\(c\\)为常数，则\n\\[E(cX) = cE(X) \\]\n多维情况 以二维为例\n设\\(Z\\)是随机变量\\(X,Y\\)的函数，\\(Z=g(X,Y)\\)，\\(g\\)是连续函数，\\(Z\\)是一维随机变量\n离散情况\n设\\((X,Y)\\)的分布律为\\(P(X=x_i,Y=y_j)=p_{ij}\\)\n\\[E(Z) = E[g(X,Y)] = \\sum_j\\sum_i g(x_i,y_j)p_{ij} \\]\n连续情况\n设\\((X,Y)\\)的概率密度是\\(f(x,y)\\)，则有\n\\[E(Z)=E[g(X,Y)]=\\int^{+\\infty}_{-\\infty}\\int^{+\\infty}_{-\\infty}g(x,y)f(x,y)dxdy \\]\n更高维可以同理推出。\n条件数学期望 \\[E(Y|x) = \\int^\\infty_{-\\infty}yf(y|x)dy \\]\n类似于全概率公式，我们可以求得无条件的数学期望的一个重要公式\n\\[E(Y) = \\int^\\infty_{-\\infty}E(Y|x)f_1(x)dx \\]\n其中\n\\[f_1 = \\int^\\infty_{-\\infty}f(x,y)dy \\]\n如果将\\(g(x)=E(Y|x)\\)，则\n\\[E(Y) = \\int^\\infty_{-\\infty}g(x)f_1(x)dx=E(g(X))=E(E(Y|X)) \\]\n整理得到\n\\[E(Y) = E[E(Y|X)] \\]\n如果是多维的，也有\n\\[E(Y) = \\int^\\infty_{-\\infty}\\cdots\\int^\\infty_{-\\infty}E(Y|x_1,\\cdots,x_n)f(x_1,\\cdots,x_n)dx_1\\cdots dx_n \\]\n如果是离散的，有\\(P(X=a_i)=p_i\\)，则\n\\[E(Y) = \\sum^\\infty_{i=1}p_iE(Y|a_i) \\]\n中位数 定义1\n设连续型随机变量\\(X\\)的分布函数为\\(F(x)\\)，则满足条件\n\\[P(X\\leq m)=F(m)=1/2 \\]\n的数\\(m\\)称为\\(X\\)或分布\\(F\\)的中位数。\n而连续的时候，有\n\\[P(X\\leq m) = P(X \u003c m) = P(X \u003e m) = P(X\\geq m) = 1/2 \\]\n方差与矩 方差与标准差 定义1\n设\\(X\\)为随机变量，分布为\\(F\\)，则\n\\[Var(X) = E(X-EX)^2 \\]\n称为\\(X\\)的方差，有时会记为\\(DX\\)，其算术平方根称为标准差。\n将其展开得\n\\[Var(X)=E(X^2)-(EX)^2 \\]\n定理1\n常数的方差为\\(0\\) 若\\(c\\)为常数，则\\(Var(X+c)=Var(X)\\) 若\\(c\\)为常数，则\\(Var(cX)=c^2Var(X)\\) \\(Var(X)=0\\)的充要条件为，\\(P(X=E(X))=1\\) 定理2\n独立（注意独立）随机变量之和的方差等于各变量的方差之和，即\n\\[Var(X_1+X_2+\\cdots+X_n) = Var(X_1)+Var(X_2)+\\cdots+Var(X_n) \\]\n如果不要求独立，二维有\n\\[Var(X+Y)=Var(X)+Var(Y)+2E\\{[X-E(X)][Y-E(Y)]\\} \\]\n矩 定义1\n设\\(X\\)为随机变量，\\(c\\)为常数，\\(k\\)为正整数，则量\\(E[(X-c)^k]\\)称为\\(X\\)关于\\(c\\)点的\\(k\\)阶矩\n\\(c=0\\)时称为\\(X\\)的\\(k\\)阶原点矩，记作\\(\\mu_k\\) \\(c=E(X)\\)时称为\\(X\\)的\\(k\\)阶中心矩，记作\\(v_k\\)。 另外\n\\(\\mu_{kl}=E(X^kY^l)\\)称为\\(X,Y\\)的\\(k+l\\)阶混合原点矩，简称\\(k+l\\)混合矩 \\(v_{kl}=E[(X-E(X))^k(Y-E(Y))^l]\\)称为\\(X,Y\\)的\\(k+l\\)阶混合中心矩 协方差与相关系数 对于二维随机向量\\((X,Y)\\)，\\(X,Y\\)本身都是一维随机变量，可以定义其均值、方差，我们记为\n\\[E(X)=m_1,E(Y)=m_2,Var(X)=\\sigma_1^2,Var(Y)=\\sigma_2^2 \\]\n定义1\n称\\(E[(X-m_1)(Y-m_2)]\\)为\\(X,Y\\)的协方差，并记为\\(Cov(X,Y)\\)\n显然有\\(Cov(X,Y)=Cov(Y,X)\\)\n也有\n对常数\\(c_1,c_2,c_3,c_4\\)，有 \\[Cov(c_1X+c_2,c_3Y+c_4)=c_1c_3Cov(X,Y) \\]\n\\(Cov(X,Y)=E(XY)-m_1m_2=E(XY)-E(X)E(Y)\\) \\(Cov(X,X)=Var(X)\\) \\(Cov(X_1+X_2,Y)=Cov(X_1,Y)+Cov(X_2,Y)\\) \\(Var(X\\pm Y)=Var(X)+Var(Y)\\pm 2Cov(X,Y)\\) 定理1\n若\\(X,Y\\)独立，则\\(Cov(X,Y)=0\\) \\([Cov(X,Y)]^2\\leq\\sigma_1^2\\sigma_2^2\\)，等号当且仅当\\(X,Y\\)之间有严格线性关系（即存在常数\\(a,b\\)使\\(Y=a+bX\\)）时成立。 定义2\n称\\(Cov(X,Y)/(\\sigma_1\\sigma_2)\\)为\\(X,Y\\)的相关系数，并记为\\(Corr(X,Y)\\)，有时也记为\\(\\rho_{XY}\\)\n可以将相关系数看做标准尺度下的协方差。\n定理2\n若\\(X,Y\\)独立，则\\(Corr(X,Y)=0\\)，当然也要求方差大于\\(0\\)才有定义。 \\(-1\\leq Corr(X,Y)\\leq 1\\)，等号当且仅当\\(X,Y\\)之间有严格线性关系时达到。 需要注意几点：\n当\\(Corr(X,Y)=0\\)（或\\(Cov(X,Y)=0\\)）时，称\\(X,Y\\)不相关，通常我们只能由“独立”推出“不相关”，而不能反过来。但是对于服从二维正态分布的\\(X,Y\\)，“独立”和“不相关”是一回事。 相关系数也常称为“线性相关系数”，相关系数并不是刻画\\(X,Y\\)之间一般关系的程度，而只刻画了“线性”关系的程度。上述定理的第二条提供了一个依据。 如果\\(0\u003c |Corr(X,Y)|\u003c 1\\)，则解释为\\(X,Y\\)之间有一定程度的线性关系。 线性相关的意义还可以从最小二乘法的角度去解释。 大数定理和中心极限定理 大数定理 定义1\n设\\(X_1,X_2,\\cdots\\)是随机变量序列，如果存在数列\\(a_1,a_2,\\cdots\\)使得对任意的\\(\\varepsilon\u003e0\\)，有\n\\[\\lim_{n\\to\\infty}P\\bigg(\\bigg|\\frac{1}{n}\\sum^n_{i=1}X_i-a_n\\bigg|\\geq\\varepsilon\\bigg)=0 \\]\n则称随机变量序列\\(\\{X_i\\}\\)服从大数定律。\n定义2\n设\\(X_1,X_2,\\cdots\\)是随机变量序列，\\(X\\)是随机变量，若对任意的\\(\\varepsilon\u003e0\\)，有\n\\[\\lim_{n\\to\\infty}P(|X_n-X|\\geq \\varepsilon)=0 \\]\n此时我们称\\(\\{X_i\\}\\)依概率收敛到\\(X\\)，记为\n\\[X_n\\stackrel{P}\\rightarrow X,n\\to\\infty \\]\n马尔科夫不等式\n若\\(Y\\)为只取非负值的随机变量，则对任给常数\\(\\varepsilon\u003e0\\)，有\n\\[P(Y\\geq \\varepsilon)\\leq E(Y)/\\varepsilon \\]\n切比雪夫不等式\n若\\(Var(Y)\\)存在，则\n\\[P(|Y-EY|\\geq\\varepsilon)\\leq Var(Y)/\\varepsilon^2 \\]\n可以推知\n\\[P(|Y-EY|\u003c\\varepsilon)\\geq 1-Var(Y)/\\varepsilon^2 \\]\n切比雪夫大数定理\n设\\(X_1,X_2,\\cdots,X_n,\\cdots\\)是相互独立的随机变量，具有相同的期望和方差，记它们的均值都为\\(a\\)。又设它们的方差存在并记为\\(\\sigma^2\\)。则对任意给定的\\(\\varepsilon\u003e0\\)，有\n\\[\\lim_{n\\to \\infty}P(|\\bar X_n-a|\\geq \\varepsilon) = 0 \\]\n更一般的形式\n设\\(X_1,X_2,\\cdots,X_n,\\cdots\\)是相互独立的随机变量序列，具有相同的期望\\(\\mu\\)，如果存在常数\\(C\u003e0\\)，使得\\(D(X_k)\\leq C\\)，则对于任意\\(\\varepsilon\u003e0\\)，有\n\\[\\lim_{n\\to\\infty}P\\bigg(\\bigg|\\frac{1}{n}\\sum^n_{k=1}X_k-\\mu\\bigg|\\geq\\varepsilon\\bigg)=0 \\]\n马尔科夫大数定律\n设\\(X_1,X_2,\\cdots,X_n,\\cdots\\)是随机变量序列，且\n\\[\\lim_{n\\to\\infty}\\frac{1}{n^2}D\\bigg[\\sum^n_{k=1}X_k\\bigg]=0 \\]\n则对于任意\\(\\varepsilon\u003e0\\)，有\n\\[\\lim_{n\\to\\infty}P\\bigg(\\bigg|\\frac{1}{n}\\sum^n_{k=1}X_k-\\frac{1}{n}\\sum^n_{k=1}E(X_k)\\bigg|\\geq\\varepsilon\\bigg)=0 \\]\n辛钦大数定律\n设\\(X_1,X_2,\\cdots,X_n,\\cdots\\)是相互独立且同分布的随机变量序列，具有有限的数学期望，记为\\(\\mu\\)。则对于任意\\(\\varepsilon\u003e0\\)，有\n\\[\\lim_{n\\to\\infty}P\\bigg(\\bigg|\\frac{1}{n}\\sum^n_{k=1}X_k-\\mu\\bigg|\\geq\\varepsilon\\bigg)=0 \\]\n伯努利大数定律\n设\\(n_A\\)是\\(n\\)次独立重复实验（\\(n\\)重伯努利实验）事件\\(A\\)发生的次数，\\(p\\)是事件\\(A\\)在每次试验中发生的概率，即\\(P(A)=p\\)，则对任意的\\(\\varepsilon\u003e0\\)，有\n\\[\\lim_{n\\to\\infty} P\\bigg(\\bigg|\\frac{n_A}{n}-p\\bigg|\\geq\\varepsilon\\bigg)=0 \\]\n中心极限定理 定理1\n设\\(X_1,X_2,\\cdots,X_n,\\cdots\\)为独立同分布的随机变量，\\(E(X_i)=\\mu,Var(X_i)=\\sigma^2(0\u003c\\sigma^2\u003c\\infty)\\)。则对任何实数\\(x\\)，有\n\\[\\lim_{n\\to\\infty}P\\bigg(\\frac{1}{\\sqrt{n} \\sigma}(X_1+\\cdots+X_n-n\\mu)\\leq x\\bigg)=\\varPhi(x) \\]\n这里，\\(\\varPhi(x)\\)是标准正态分布\\(N(0,1)\\)的分布函数。\n也就是说，当\\(n\\)充分大时，有\n\\[\\sum_{k=1}^n X_k\\sim N(n\\mu,n\\sigma^2),\\quad \\frac{\\sum_{k=1}^nX_k-n\\mu}{\\sqrt{n}\\sigma}\\sim N(0,1) \\]\n\\[P\\bigg(\\sum^n_{k=1}X_k\\leq x\\bigg)\\approx\\Phi\\bigg(\\frac{x-n\\mu}{\\sqrt n\\sigma}\\bigg),\\quad P\\bigg(a\u003c\\sum^n_{k=1}X_k\\leq b\\bigg)\\approx\\Phi\\bigg(\\frac{b-n\\mu}{\\sqrt n\\sigma}\\bigg)-\\Phi\\bigg(\\frac{a-n\\mu}{\\sqrt n\\sigma}\\bigg) \\]\n\\[\\bar X\\approx N(\\mu,\\sigma^2/n),\\quad \\frac{\\bar X-\\mu}{\\sigma/\\sqrt{n}}\\approx N(0,1) \\]\n李雅普诺夫中心极限定理\n设\\(X_1,X_2,\\cdots,X_n,\\cdots\\)相互独立，其具有如下数学期望和方差：\\(E(X_k)=\\mu_k,D(X_k)=\\sigma_k^2\u003e0\\)，记\\(B_n^2=\\sum^n_{k=1}\\sigma^2_k\\)\n若存在正数\\(\\delta\\)使得当\\(n\\to\\infty\\)时\n\\[\\frac{1}{B^{2+\\delta}}\\sum^n_{k=1}E\\bigg[|X_i-\\mu_i|^{2+\\delta}\\bigg]\\to 0 \\]\n则\n\\[\\lim_{n\\to\\infty}P\\bigg(\\frac{\\sum^n_{k=1}X_k-\\sum^n_{k=1}\\mu_k}{B_n}\\leq x\\bigg)=\\Phi(x) \\]\n棣莫弗-拉普拉斯中心极限定理\n设\\(n_A\\)是\\(n\\)次独立重复实验（\\(n\\)重伯努利实验）事件\\(A\\)发生的次数，\\(p\\)是事件\\(A\\)在每次试验中发生的概率，即\\(P(A)=p\\)，\n\\[\\lim_{n\\to\\infty}P\\bigg(\\frac{n_A-np}{\\sqrt{np(1-p)}}\\leq x\\bigg)=\\Phi(x) \\]\n即，若\\(X\\sim B(n,p)\\)，\\(n\\)充分大时\n\\[X\\sim N(np,np(1-p)) \\]\n\\[P(X\\leq x)\\approx\\Phi\\bigg(\\frac{x-np}{\\sqrt{np(1-p)}}\\bigg),\\quad P(a \u003c X\\leq b)\\approx\\Phi\\bigg(\\frac{b-np}{\\sqrt{np(1-p)}}\\bigg)-\\Phi\\bigg(\\frac{a-np}{\\sqrt{np(1-p)}}\\bigg) \\]\n参数估计 数理统计学的基本概念 总体 总体是指与所研究的问题有关的对象（个体）的全体所构成的集合。\n赋有一定概率分布的总体就称为统计总体。\n在数理统计学中，“总体”这个基本概念的要旨——总体就是一个概率分布，当总体分布为指数分布时，称为指数分布总体；当总体分布为正态分布时，称为正态分布总体，或简称正态总体。\n总体分布是一个概率分布族。这个分布族包含一个参数时，称为单参数分布族，例如指数分布。包含两个参数时，称为两参数分布族，例如正态分布。如果总体分布不能通过若干个未知参数表达出来，这种情况称为非参数总体。\n样本 样本是按一定的规定从总体中抽出的一部分个体，所谓“按一定的规定”，就是指总体中的每一个个体有同等的被抽出的机会。\n样本表现为若干个数据\\(X_1,\\cdots,X_n,n\\)称为“样本大小”或“样本容量”、“样本量”，样本\\(X_1,\\cdots,X_n\\)中的每一个\\(X_i\\)也称为样本。有时\\(X_1,\\cdots,X_n\\)称为一组样本，而\\(X_i\\)称为其中的第\\(i\\)个样本。\n统计量 完全由样本所决定的量叫做统计量。统计量只以来于样本，而不能依赖于任何其他未知的量。\n简单随机样本 设\\(X\\)是具有分布函数\\(F\\)的随机变量，若\\(X_1,\\cdots,X_n\\)是相互独立，且与\\(X\\)具有相同分布函数\\(F\\)的随机变量，则称\\(X_1,\\cdots,X_n\\)是一个来自总体\\(X\\)的容量为\\(n\\)的简单随机样本，简称样本。\n一个样本\\(X_1,\\cdots,X_n\\)的观察值\\(x_1,\\cdots,x_n\\)，称为样本值。\n联合分布函数为\n\\[F^*(x_1,x_2,\\cdots,x_n) = \\prod^n_{i=1}F(x_i) \\]\n如果是离散型，有\n\\[p^*(X_1=x_1,X_2=x_2,\\dots,X_n=x_n)=\\prod^n_{i=1}p(x_i) \\]\n如果是连续型，有\n\\[f^*(x_1,x_2,\\cdots,x_n) = \\prod^n_{i=1}f(x_i) \\]\n经验分布函数 设\\(X_1,\\cdots,X_n\\)是来自总体\\(X\\)的一个样本，\\(x_1,\\cdots,x_n\\)，是样本\\(X_1,\\cdots,X_n\\)的一组样本值，将其从小到大排列，并且重新编号为\\(x_1,\\cdots,x_n\\)，则称函数\n\\[F_n(x)=\\frac{x_1,\\cdots,x_n中小于等于x的样本值的个数}{n} = \\left\\{\\begin{matrix} 0,\u0026x \u003c x_1 \\\\ k/n,\u0026x_k \u003c x_{k+1} \\\\ 1,\u0026x\\geq x_n \\end{matrix}\\right. \\]\n为总体\\(X\\)的经验分布函数。\n常用统计量 样本均值\n\\[\\overline{X} = \\frac{1}{n}\\sum^n_{i=1}X_i \\]\n其样本值为\n\\[\\overline{x} = \\frac{1}{n}\\sum^n_{i=1}x_i \\]\n样本方差\n\\[S^2 = \\frac{1}{n-1}\\sum^n_{i=1}(X_i-\\overline{X})^2 = \\frac{1}{n-1}\\bigg(\\sum^n_{i=1}X_i^2-n\\overline{X}^2\\bigg) \\]\n其样本值为\n\\[s^2 = \\frac{1}{n-1}\\sum^n_{i=1}(x_i-\\overline{x})^2 = \\frac{1}{n-1}\\bigg(\\sum^n_{i=1}x_i^2-n\\overline{x}^2\\bigg) \\]\n样本标准差\n\\[S = \\sqrt{\\frac{1}{n-1}\\sum^n_{i=1}(X_i-\\overline{X})^2} \\]\n其样本值为\n\\[s = \\sqrt{\\frac{1}{n-1}\\sum^n_{i=1}(x_i-\\overline{x})^2} \\]\n样本\\(k\\)阶原点矩\n\\[a_k = \\frac{1}{n}\\sum^n_{i=1}X_i^k \\]\n样本值略。\n样本\\(k\\)阶中心矩\n\\[m_k = \\frac{1}{n}\\sum^n_{i=1}(X_i-\\overline{X})^k \\]\n样本值略\n定理1\n设总体\\(X\\)均值为\\(\\mu\\)，方差为\\(\\sigma^2\\)（无论何种分布），\\(X_1,X_2,\\cdots,X_n\\)是来自总体\\(X\\)的一个样本，\\(\\overline{X}\\)和\\(S^2\\)分别是样本均值和样本方差，则有\n\\[E(\\overline{X})=\\mu,D(\\overline{X})=\\sigma^2/n,E(S^2) = \\sigma^2 \\]\n矩估计、极大似然估计和贝叶斯估计 参数的点估计问题 设总体的分布为\\(f(x;\\theta_1,\\cdots,\\theta_k)\\)，其形式已知（我们这里不区分连续和离散，具体情况具体处理就行），而有\\(k\\)个未知参数\\(\\theta_1,\\cdots,\\theta_k\\)。例如对正态总体\\(N(\\mu,\\sigma^2)\\)，有\\(\\theta_1=\\mu,\\theta_2=\\sigma^2\\)\n参数估计一般的方法就是使用总体中抽出的样本\\(X_1,\\cdots,X_n\\)，去对参数\\(\\theta_1,\\cdots,\\theta_k\\)的未知值做出估计。\n为了估计\\(\\theta_1\\)，我们需要构造出适当的统计量\\(\\hat \\theta_1=\\hat \\theta_1(X_1,\\cdots,X_n)\\)，每当有了样本\\(X_1,\\cdots,X_n\\)，就代入函数\\(\\hat \\theta_1(X_1,\\cdots,X_n)\\)中算出一个值，用来作为\\(\\theta_1\\)的估计值。\n为这样的特定目的而构造的统计量\\(\\hat\\theta_1\\)叫做\\(\\theta_1\\)的估计量。由于未知参数\\(\\theta_1\\)是数轴上的一个点，用\\(\\hat\\theta_1\\)去估计\\(\\theta_1\\)，等于用一个点去估计另一个点，所以这样的估计叫做点估计。\n矩估计法 设总体分布为\\(f(x;\\theta_1,\\cdots,\\theta_k)\\)，则它的矩（原点矩和中心矩都可以，此处以原点矩为例）\n\\[\\alpha_m = \\int^\\infty_{-\\infty}x^mf(x;\\theta_1,\\cdots,\\theta_k)dx \\]\n或\n\\[\\sum_i x^m_if(x_i;\\theta_1,\\cdots,\\theta_k) \\]\n依赖于\\(\\theta_1,\\cdots,\\theta_k\\)。另一方面，至少样本大小\\(n\\)较大时，\\(\\alpha_m\\)又应接近于样本的原点矩\\(a_m\\)；于是\n\\[\\alpha_m = \\alpha_m(\\theta_1,\\cdots,\\theta_k)\\approx a_m = \\sum^n_{i=1}X_i^m/n \\]\n取\\(m=1,\\cdots,k\\)，并将上面的近似式改为等式，就得到一个方程组\n\\[\\alpha_m(\\theta_1,\\cdots,\\theta_k)= a_m\\quad (m=1,\\cdots,k) \\]\n解此方程组，得到根\\(\\hat\\theta_i=\\hat\\theta_i(X_1,\\cdots,X_n)(i=1,\\cdots,k)\\)，就以\\(\\hat\\theta_i\\)作为\\(\\theta_i\\)的估计。如果要估计的是\\(\\theta_1,\\cdots,\\theta_k\\)的某函数\\(\\theta_1,\\cdots,\\theta_k\\)，则用\\(\\hat g = \\hat g(X_1,\\cdots,X_k) = g(\\hat\\theta_1,\\cdots,\\hat\\theta_k)\\)去估计它。这样定出的估计量叫做矩估计。\n正态总体的估计\n例如，设\\(X_1,\\cdots,X_n\\)是从正态总体\\(N(\\mu,\\sigma^2)\\)中抽出的样本，要估计\\(\\mu\\)和\\(\\sigma^2\\)。可以用样本的一阶原点矩即样本均值\\(\\overline{X}\\)去估计\\(\\mu\\)，而用样本的二阶中心距\\(m_2\\)去估计\\(\\sigma^2\\)。\n这确实是可以的，但是我们更常用的是使用样本方差\\(S^2\\)而不是使用\\(m_2\\)，即做出了一定修正，理由之后介绍。\n估计标准差也可以用\\(\\sqrt{m_2}\\)，但更常用\\(S\\)。\n有时要估计\\(\\sigma/\\mu\\)，称为总体的变异系数，其是以均值为单位去恒量的总体的标准差。可以用\\(\\sqrt{m_2}/\\overline X\\)，一般用\\(S/\\overline X\\)\n指数分布总体的估计\n又如指数分布的参数\\(\\lambda\\)，因为\\(1/\\lambda\\)是总体分布的均值，所以我们可以用\\(\\overline X\\)去估计。\n又因为其总体方差为\\(1/\\lambda^2\\)，所以\\(1/\\lambda\\)也可以用\\(\\sqrt{m_2}\\)或\\(S\\)去估计，具体哪种好之后回去讨论。但通常我们能用低阶矩就不用高阶矩。\n极大似然估计法 设总体分布为\\(f(x;\\theta_1,\\cdots,\\theta_k)\\)，\\(X_1,\\cdots,X_n\\)为自这个总体中抽出的样本，则样本\\((X_1,\\cdots,X_n)\\)的分布（即其概率密度函数或概率密度）为\n\\[f(x_1;\\theta_1,\\cdots,\\theta_k)f(x_2;\\theta_1,\\cdots,\\theta_k)\\cdots f(x_n;\\theta_1,\\cdots,\\theta_k) \\]\n记为\\(L(x_1,\\cdots,x_n;\\theta_1,\\cdots,\\theta_k)\\)\n当把\\(\\theta_1,\\cdots,\\theta_k\\)而看作\\(x_1,\\cdots,x_n\\)的函数时，\\(L\\)是一个概率密度函数或概率函数。\\(L(Y_1,\\cdots,Y_n;\\theta_1,\\cdots,\\theta_k)\u003eL(X_1,\\cdots,X_n;\\theta_1,\\cdots,\\theta_k)\\)意味着在观察时出现\\(Y_1,\\cdots,Y_n\\)这个点的概率比出现\\(X_1,\\cdots,X_n\\)这个点的可能性大。\n而反过来，\\(L(X_1,\\cdots,X_n;\\theta_1',\\cdots,\\theta_k')\u003eL(X_1,\\cdots,X_n;\\theta_1'',\\cdots,\\theta_k'')\\)，则被估计的参数\\(\\theta_1,\\cdots,\\theta_k\\)是\\(\\theta_1',\\cdots,\\theta_k'\\)的可能性比它是\\(\\theta_1'',\\cdots,\\theta_k''\\)的可能性大。此时\\(L\\)称作似然函数。\n所以我们的极大似然估计法就是用似然程度最大的那个点\\((\\theta_1^*,\\cdots,\\theta_k^*)\\)，即满足条件\n\\[L(X_1,\\cdots,X_n;\\theta^*_1,\\cdots,\\theta^*_k)=\\underset{\\theta_1,\\cdots,\\theta_k}{\\max}L(X_1,\\cdots,X_n;\\theta_1,\\cdots,\\theta_k) \\]\n的\\((\\theta_1^*,\\cdots,\\theta_k^*)\\)作为\\((\\theta_1,\\cdots,\\theta_k)\\)的估计值。这个估计值就叫做极大似然估计，估计函数\\(g(\\theta_1,\\cdots,\\theta_n)\\)就用\\(g(\\theta_1^*,\\cdots,\\theta_n^*)\\)\n因为\n\\[\\ln L = \\sum^n_{i=1}\\ln f(X_i;\\theta_1,\\cdots,\\theta_k) \\]\n为使\\(L\\)最大，则建立似然方程组如下\n\\[\\dfrac{\\partial\\ln L}{\\partial\\theta_i} = 0\\quad(i=1,\\cdots,k) \\]\n如果有唯一解，且是极大值点，则它必是使\\(L\\)达到最大的点。但有时候解不唯一，并且判断哪个使\\(L\\)达到极大也不容易。\n有时\\(f\\)不连续，或者不可导，这时就不能列方程，要回到最原始的定义。\n正态总体\n作为例子，正态总体用极大似然估计是可以的，它连续，并且可导，计算后得到的是\\(\\mu^*=\\overline X,\\sigma^{*2}=m_2\\)\n指数分布总体\n估计得\\(\\lambda=1/\\overline X\\)\n上面的两个例子，其和矩估计恰好一致，但这只是一种巧合，更多时候是不一致的。但这两种估计方法结果一致，说明这些估计是良好的。\n另外我们也可以应用样本中位数\\(\\hat m\\)去估计正态总体的\\(\\mu\\)，这个统计量可以在矩估计不能使用（主要体现为矩为无限大等场景）和极大似然法求根不容易等场景。\n贝叶斯法 在矩估计和极大似然估计时，在我们心目中，未知参数\\(\\theta\\)就简单地是一个未知数，在抽取样本之前，我们对\\(\\theta\\)没有任何了解，所有的信息全来自样本。\n贝叶斯学派则不然，它的出发点是：在进行抽样之前，我们已对\\(\\theta\\)有一定的知识，叫做先验知识，即试验之前的知识，也叫做验前知识。\n贝叶斯学派进一步要求：这种先验知识必须用\\(\\theta\\)的某种概率分布表达出来，这个概率分布就叫做\\(\\theta\\)的“先验分布”或“验前分布”。这个分布总结了我们在试验之前对未知参数\\(\\theta\\)的知识。\n比如我们可以使用工厂以前制造的产品废品率来作为先验知识。以\\(h(\\theta)\\)代表先验密度。但如果这个工厂是新开的，无法得到\\(h(\\theta)\\)，则我们必须设法定出一个\\(h(\\theta)\\)，甚至是自己的主观估计也可以。\n当我们确定先验密度后，设总体有概率密度\\(f(X,\\theta)\\)，从这个总体中抽样本\\(X_1,\\cdots,X_n\\)，则这组样本的密度为\\(f(X_1,\\theta)\\cdots f(X_n,\\theta)\\)。它可视为在给定\\(\\theta\\)时\\((X_1,\\cdots,X_n)\\)的密度，\\((\\theta,X_1,\\cdots,X_n)\\)的联合密度为\n\\[h(\\theta)f(X_1,\\theta)\\cdots f(X_n,\\theta) \\]\n由此，算出\\((X_1,\\cdots,X_n)\\)的边缘密度为\n\\[p(X_1,\\cdots,X_n) = \\int h(\\theta)f(X_1,\\theta)\\cdots f(X_n,\\theta)d\\theta \\]\n积分的范围依\\(\\theta\\)的具体范围而定。然后有\n\\[h(\\theta|X_1,\\cdots,X_n) = h(\\theta)f(X_1,\\theta)\\cdots f(X_n,\\theta)/p(X_1,\\cdots,X_n) \\]\n按照贝叶斯学派的观点，这个条件密度代表了我们现在取得样本\\(X_1,\\cdots,X_n\\)后对\\(\\theta\\)的知识，它综合了先验知识和样本的信息。这个式子称为后验（验后）密度。\n贝叶斯学派也指出，在得出后验分布后，对参数\\(\\theta\\)的任何统计推断都只能基于这个后验分布。\n点估计的优良性准则 估计量的无偏性 设某统计总体的分布包含未知参数\\(\\theta_1,\\cdots,\\theta_k\\)，\\(X_1,\\cdots,X_n\\)是从该总体中抽出的样本，要估计\\(g(\\theta_1,\\cdots,\\theta_k)\\)，\\(g\\)为一已知函数，设\\(\\hat g(X_1,\\cdots,X_n)\\)是一个估计量。如果对任何可能的\\(\\theta_1,\\cdots,\\theta_k\\)都有\n\\[E_{\\theta_1,\\cdots,\\theta_k}[\\hat g(X_1,\\cdots,X_n)]=g(\\theta_1,\\cdots,\\theta_k) \\]\n则称\\(\\hat g\\)是\\(g(\\theta_1,\\cdots,\\theta_k)\\)的一个无偏估计量。\n估计量的无偏性有两个含义：\n没有系统性的误差 根据大数定理，若估计量有无偏性，则在大量次数使用取平均时，能以接近于\\(100\\%\\)的把握无限逼近被估计的量。如果没有无偏性，那么估计值会和真值保持一定距离，这个距离就是系统误差。 可以证明\n例1\n设\\(X_1,\\cdots,X_n\\)是从总体中抽出的样本，则样本均值\\(\\overline X\\)是总体分布均值\\(\\theta\\)的无偏估计。\n例2\n样本方差\\(S^2\\)是总体分布方差\\(\\sigma^2\\)的无偏估计。（而不是二阶中心矩）\n最小方差无偏估计 一个参数往往有不止一个无偏估计，我们要从中调出一个最优的。\n均方误差 设\\(X_1,\\cdots,X_n\\)是从某一带参数\\(\\theta\\)的总体中抽出的样本，要估计\\(\\theta\\)。若我们采用估计量\\(\\hat\\theta = \\hat\\theta(X_1,\\cdots,X_n)\\)，则其误差为\\(\\hat\\theta(X_1,\\cdots,X_n)-\\theta\\)。这个误差随样本的具体值而定，也是随机的，无法作为优良性的指标。我们取\n\\[M_{\\hat\\theta}(\\theta)=E_\\theta[\\hat\\theta(X_1,\\cdots,X_n)-\\theta]^2 \\]\n作为\\(\\hat\\theta\\)的误差大小从整体角度的一个衡量。这个量越小，就表示\\(\\hat\\theta\\)的误差平均来讲比较小，因而也就越优。\\(M_{\\hat\\theta}\\)就称为估计量\\(\\theta\\)的“均方误差”\n最小方差无偏估计 从前面的讨论看到：若局限于无偏估计的范围，且采用均方误差的准则，则两个无偏估计\\(\\hat\\theta_1\\)和\\(\\hat\\theta_2\\)的比较归结为其方差的比较：方差小者为优。\n最小方差无偏估计简记为MVU估计。\n克拉美-劳不等式 TODO\n估计量的相合性与渐近正态性 相合性 设总体分布依赖于参数\\(\\theta_1,\\cdots,\\theta_k,g(\\theta_1,\\cdots,\\theta_k)\\)是\\(\\theta_1,\\cdots,\\theta_k\\)的一个给定函数，设\\(X_1,\\cdots,X_n\\) 为自该总体中抽出的样本，\\(T(X_1,\\cdots,X_n)\\)是\\(g(\\theta_1,\\cdots,\\theta_k)\\)的一个估计量，如果对任给\\(\\varepsilon\u003e0\\)有\n\\[\\lim_{n\\to\\infty}P_{\\theta_1,\\cdots,\\theta_k}(|T(X_1,\\cdots,X_n)-g(\\theta_1,\\cdots,\\theta_k)|\\geq\\varepsilon) = 0 \\]\n而且这对\\((\\theta_1,\\cdots,\\theta_k)\\)一切可能取的值都成立，则称\\(T(X_1,\\cdots,X_n)\\)是\\(g(\\theta_1,\\cdots,\\theta_k)\\)的一个相合估计。\n渐近正态性 正如在中心极限定理中所显示的，当\\(n\\)很大时，和的分布渐近于正态分布。理论上可以证明，这不只是和所独有的，许多形状复杂的统计量，当样本大小\\(n\\to\\infty\\)时，其分布都渐近于正态分布。这称为统计量的“渐近正态性”。\n区间估计 基本概念 点估计是用一个点去估计未知参数。区间估计就是用一个区间去估计未知参数，即未知参数的值也会估计在一个区间之内。\n设\\(X_1,\\cdots,X_n\\)是从该总体中抽出的样本。所谓\\(\\theta\\)的区间估计，就是以满足条件\\(\\hat\\theta_1(X_1,\\cdots,X_n)\\leq\\hat\\theta_2(X_1,\\cdots,X_n)\\)的两个统计量\\(\\hat\\theta_1,\\hat\\theta_2\\)为端点的区间\\([\\hat\\theta_1,\\hat\\theta_2]\\)。一旦有了样本\\(X_1,\\cdots,X_n\\)，就把\\(\\theta\\)估计在区间\\([\\hat\\theta_1(X_1,\\cdots,X_n),\\hat\\theta_2(X_1,\\cdots,X_n)]\\)之内。有两个要求\n\\(\\theta\\)要以很大的可能性落在\\([\\hat\\theta_1,\\hat\\theta_2]\\)之内，也就是说 \\[P_\\theta(\\hat\\theta_1\\leq\\theta\\leq\\hat\\theta_2) \\]\n要尽可能大。\n估计的精密度要尽可能高。比方说，要求区间的长度\\(\\hat\\theta_2-\\hat\\theta_1\\)尽可能小，或某种能体现这个要求的其他准则。 置信系数、置信区间、置信水平\n给定一个很小的数\\(\\alpha\u003e0\\)。如果对参数\\(\\theta\\)的任何值，\\(P_\\theta(\\hat\\theta_1\\leq\\theta\\leq\\hat\\theta_2)\\)都等于\\(1-\\alpha\\)，则层区间估计\\([\\hat\\theta_1,\\hat\\theta_2]\\)的置信系数为\\(1-\\alpha\\)，而这个区间叫做置信区间。\n有时，我们无法证明恰好等于\\(1-\\alpha\\)，但我们能证明它大于等于\\(1-\\alpha\\)，那我们称\\(1-\\alpha\\)是\\([\\hat\\theta_1,\\hat\\theta_2]\\)的置信水平。当然，如果\\(0.8\\)是，那么\\(0.7,0.6\\)等等也都是，置信系数就是置信水平中的最大者。\n枢轴变量法 找一个与要估计的参数\\(g(\\theta)\\)有关的统计量\\(T\\)，一般是其一个良好的点估计 设法找出\\(T\\)和\\(g(\\theta)\\)的某一函数\\(S(T,g(\\theta))\\)，其分布\\(F\\)要与\\(\\theta\\)无关，\\(S\\)称为枢轴变量。 对任何常数\\(a\u003c b\\)，不等式\\(a\\leq S(T,g(\\theta))\\leq b\\)要能改写为等价的形式\\(A\\leq g(\\theta)\\leq B\\)，\\(A,B\\)只与\\(T,a,b\\)有关，而与\\(\\theta\\)无关 取分布\\(F\\)的上\\(\\alpha/2\\)分位点\\(w_{\\alpha/2}\\)和上\\(1-\\alpha/2\\)分位点\\(w_{1-\\alpha/2}\\)，则有\\(F(w_{\\alpha/2})-F(w_{1-\\alpha/2})=1-\\alpha\\)，因此 \\[P(w_{1-\\alpha/2}\\leq S(T,g(\\theta))\\leq w_{\\alpha/2})=1-\\alpha \\]\n然后根据第三条改写为\\(A\\leq g(\\theta)\\leq B\\)，则\\([A,B]\\)就是\\(g(\\theta)\\)的一个置信系数为\\(1-\\alpha\\)的区间估计。\n上\\(\\beta\\)分位点的含义是，对于任何分布\\(F\\)，满足条件\\(F(v_\\beta)=1-\\beta\\)的点\\(v_\\beta\\)就是分布函数\\(F\\)的上\\(\\beta\\)分位点。\n下面给出一些常见的枢轴量\n单正态总体\n检验均值\\(\\mu\\)\n若\\(\\sigma^2\\)已知，则枢轴量\n\\[U = \\dfrac{\\overline X-\\mu}{\\sigma/\\sqrt n}\\sim N(0,1) \\]\n若\\(\\sigma^2\\)未知，则枢轴量\n\\[t = \\dfrac{\\overline X-\\mu}{S/\\sqrt n}\\sim t(n-1) \\]\n检验方差\\(\\sigma^2\\)\n若\\(\\mu\\)已知，则枢轴量\n\\[\\mathcal{X}^2 = \\dfrac{\\displaystyle\\sum^n_{i=1}(X_i-\\mu)^2}{\\sigma^2}\\sim \\mathcal{X}^2_n \\]\n若\\(\\mu\\)未知，则枢轴量\n\\[\\mathcal{X}^2 = \\dfrac{(n-1)S^2}{\\sigma^2}\\sim \\mathcal{X}^2_{n-1} \\]\n两个相互独立的正态总体\n检验均值差\\(\\mu_1-\\mu_2\\)\n若\\(\\sigma^2_1,\\sigma^2_2\\)已知，则枢轴量\n\\[U = \\dfrac{(\\overline X-\\overline Y)-(\\mu_1-\\mu_2)}{\\sqrt{\\sigma^2_1/n_1+\\sigma^2_2/n_2}}\\sim N(0,1) \\]\n若\\(\\sigma^2_1=\\sigma^2_2=\\sigma^2\\)未知，则枢轴量\n\\[t = \\dfrac{(\\overline X-\\overline Y)-(\\mu_1-\\mu_2)}{S_W\\sqrt{1/n_1+1/n_2}}\\sim t(n_1+n_2-2) \\]\n检验方差比\\(\\sigma_1^2/\\sigma_2^2\\)\n若\\(\\mu_1,\\mu_2\\)已知，则枢轴量\n\\[F = \\dfrac{n_2\\sigma_2^2\\sum^{n_1}_{i=1}(X_i-\\mu_1)^2}{n_1\\sigma_1^2\\sum^{n_2}_{i=1}(Y_i-\\mu_2)^2}\\sim F(n_1,n_2) \\]\n若\\(\\mu_1,\\mu_2\\)未知，则枢轴量\n\\[F = \\dfrac{\\sigma^2_2S_1^2}{\\sigma_1^2S_2^2}\\sim F(n_1-1,n_2-1) \\]\n枢轴量的使用方法\n我们最终要从枢轴量中得到置信区间，例如检验均值\\(\\mu\\)\n若\\(\\sigma^2\\)已知，则枢轴量\n\\[U = \\dfrac{\\overline X-\\mu}{\\sigma/\\sqrt n}\\sim N(0,1) \\]\n也就是我们要\n\\[P(w_{1-\\alpha/2}\\leq U\\leq w_{\\alpha/2}) = P(-w_{\\alpha/2}\\leq U\\leq w_{\\alpha/2})=1-\\alpha \\]\n我们就将\\(\\mu\\)的表达式写出来为\\([\\overline X - \\dfrac{\\sigma}{\\sqrt n}w_{\\alpha/2},\\overline X + \\dfrac{\\sigma}{\\sqrt n}w_{\\alpha/2}]\\)\n其他的使用办法也是类似的。\n大样本法 TODO\n置信界 设\\(X_1,\\cdots,X_n\\)是从某一总体中抽出的样本，总体分布包含未知参数\\(\\theta\\)，\\(\\overline{\\theta}=\\overline{\\theta}(X_1,\\cdots,X_n)\\)和\\(\\underline{\\theta}=\\underline{\\theta}(X_1,\\cdots,X_n)\\)都是统计量，则\n若对\\(\\theta\\)的一切可取的值，有 \\[P_\\theta(\\overline{\\theta}(X_1,\\cdots,X_n)\\geq\\theta)=1-\\alpha \\]\n则称\\(\\overline\\theta\\)是\\(\\theta\\)的一个置信系数为\\(1-\\alpha\\)的置信上界。\n若对\\(\\theta\\)的一切可取的值，有 \\[P_\\theta(\\underline{\\theta}(X_1,\\cdots,X_n)\\leq\\theta)=1-\\alpha \\]\n则称\\(\\underline\\theta\\)是\\(\\theta\\)的一个置信系数为\\(1-\\alpha\\)的置信下界。\n单侧置信区间使用枢轴量的方法类似，只不过要将\\(P\\)函数代成单侧的情况的。对于置信上界，置信区间的下限为\\(-\\infty\\)，对于置信下界，置信区间的上限为\\(+\\infty\\)\n贝叶斯法 TODO\n假设检验 基本概念 在显著性水平\\(\\alpha\\)之下，检验假设\\(H_0\\)和\\(H_1\\)。\\(H_0\\)称为原假设或零假设，\\(H_1\\)称为备择假设，备择假设是指与原假设相矛盾的假设。\n双边假设检验\n\\[H_0 : \\mu=\\mu_0\\quad H_1 : \\mu\\neq\\mu_0 \\]\n单边假设检验\n右边假设\n\\[H_0 : \\mu\\leq\\mu_0\\quad H_1 : \\mu\u003e\\mu_0 \\]\n左边假设\n\\[H_0 : \\mu\\geq\\mu_0\\quad H_1 : \\mu\u003c\\mu_0 \\]\n仅涉及总体分布未知参数的假设称为参数假设。而对总体分布类型或分布的某些特征提出的假设称为非参数假设。\n能够对原假设\\(H_0\\)是真或不真做出回答的统计量称为假设检验统计量。\n使得原假设\\(H_0\\)为真的假设检验统计量取值范围称为假设检验的接受域；拒绝原假设\\(H_0\\)的假设检验统计量取值范围称为拒绝域；拒绝域的边界点称为临界点。\n由于样本的随机性，进行判断时，可能会发生错误，发生错误也是一个随机事件\n第I类错误（弃真）：\\(H_0\\)为真但拒绝\\(H_0\\)\n\\[P(拒绝H_0/H_0为真时) = \\alpha \\]\n第II类错误（存伪）：\\(H_0\\)不真但接受\\(H_0\\)\n\\[P(接受H_0/H_0不真时) = \\beta \\]\n给定样本容量，如果减小第I类错误的概率，则第II类错误的概率往往增大。如果要使两类错误的概率都减小，需要增大样本容量。\n我们一般控制第I类错误的概率使其不大于\\(\\alpha\\)，通常取\\(\\alpha\\)为\\(0.1,0.05,0.01,0.005\\)\n只控制第I类错误的概率，而不考虑第II类错误的概率的假设检验称为显著性检验，称\\(\\alpha\\)为显著性水平。\n正态总体假设检验的接受域\n设总体\\(X\\sim N(\\mu,\\sigma^2),\\mu\\)未知，\\(\\sigma^2\\)已知，设\\(X_1,X_2,\\cdots,X_n\\)是来自总体的样本，给定显著性水平为\\(\\alpha\\)\n双边假设\n接受域为\n\\[|u| = \\bigg|\\dfrac{\\bar x-\\mu_0}{\\sigma/\\sqrt n}\\bigg| \u003c z_{\\alpha/2} \\]\n左边假设\n接受域为\n\\[u = \\dfrac{\\bar x-\\mu_0}{\\sigma/\\sqrt n}\u003e-z_\\alpha \\]\n右边假设\n接受域为\n\\[u = \\dfrac{\\bar x-\\mu_0}{\\sigma/\\sqrt n} \u003c z_\\alpha \\]\n求未知参数假设检验的步骤\n根据实际问题，提出原假设\\(H_0\\)和备择假设\\(H_1\\) 确定检验统计量及其在\\(H_0\\)为真时的分布 根据显著性水平\\(\\alpha\\)和样本容量\\(n\\)，按照\\(P(当H_0为真时拒绝H_0)=\\alpha\\)求出临界点，确定接受域或拒绝域 计算检验统计量的样本观测值 根据样本观测值做出决策，是接受原假设\\(H_0\\)还是拒绝\\(H_0\\) 双边假设的两个临界点：上\\(\\alpha/2\\)分位点、上\\(1-\\alpha/2\\)分位点\n左边假设的一个临界点：上\\(1-\\alpha\\)分位点\n右边假设的一个临界点：上\\(\\alpha\\)分位点\n单正态总体和双正态总体参数的假设检验 可以直接用之前提到枢轴量，以及其分位点来计算，具体形式和“正态总体假设检验的接受域”一小节类似，不再介绍。\n","date":"2022-08-30T10:41:24+08:00","image":"https://kegalas.top/inferior/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E6%95%B4%E7%90%86/cover_hu60f44b771e1522f4fa1d5246713b9a75_57927_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E6%95%B4%E7%90%86/","title":"概率论与数理统计整理"},{"content":"\r1.jpg\r情况如图所示，_ZSt28__throw_bad_array_new_lengthv无法被定位。\n经过检查，通过mingw64.exe运行的g++版本是12.1.0。这也是通过官网的教程安装的版本。并且我们通常会把msys2\\mingw64\\bin\\作为环境变量。\n而通过安装gcc（命令是pacman -S gcc，而不是官网的教程提供的命令），然后用msys2.exe运行的g++版本是11.3.0。将环境变量换为msys2\\usr\\bin\\，此时编译的程序可以正常运行不报错。\n推测原因是版本问题，或者是msys2和mingw64有什么差别。\n另外，通过mingw64打开的命令行来运行编译出来的exe文件不会报错。\n另外，如果遇到failed to synchronize all databases (unable to lock database)，而经过检查又没有发现/var/lib/pacman/db.lck这个文件的存在，可以考虑用管理员身份打开msys2.exe。如果能够打开就说明是权限问题，可以将整个msys2的权限进行修改，允许非管理员用户完全控制。\n2023.5.7 后记，msys2和mingw确实有区别，新博客文章见链接。另外本文上述办法没法完美解决，如果发给别人，他电脑上没有msys-2.0.dll，那么没法运行msys2编译的程序。\n","date":"2022-08-28T16:18:50+08:00","image":"https://kegalas.top/inferior/msys2-g++-%E8%BF%90%E8%A1%8C%E6%8A%A5%E9%94%99%E6%97%A0%E6%B3%95%E6%89%BE%E5%88%B0%E5%85%A5%E5%8F%A3/1_hu8fe568a15a37a7bd8c510c832a970168_16486_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/msys2-g++-%E8%BF%90%E8%A1%8C%E6%8A%A5%E9%94%99%E6%97%A0%E6%B3%95%E6%89%BE%E5%88%B0%E5%85%A5%E5%8F%A3/","title":"Msys2中使用mingw64的G++编译，运行报错无法找到入口"},{"content":"动画原理 根据视觉暂留现象，只要离散的画面切换的足够快，在人眼看起来就是连续的。\n一般电影是24fps，一般视频是30fps以上，VR是90fps以上。\n关键帧动画 重要的动作节点，会作为关键帧。而中间的帧会作为动作间的过渡。\n关键帧一般是画出来的。过渡帧也可以画，现在也有不少的软件可以自动生成过渡帧。\n关键帧插值 自动生成过渡帧就用到了关键帧插值。\n有线性插值，也有更光滑的插值。\n物理模拟 将各种各样的物理公式用来计算物体的运动，称为物理模拟、物理仿真。\n质点弹簧系统 最简单的单位是：一个弹簧连接了两个质点。\n假设两个点为\\(a,b\\)\n则\n\\[\\bm f_{a\\to b}=k_s(\\bm{b}-\\bm{a})\\\\ \\bm f_{b\\to a}=-\\bm f_{a\\to b} \\]\n上述情况的条件是弹簧长度为\\(0\\),若弹簧原始长度为\\(l\\)，则\n\\[\\bm f_{a\\to b}=k_s\\frac{\\bm b-\\bm a}{||\\bm b-\\bm a||}(||\\bm b-\\bm a||-l) \\]\n上述情况假设没有能量损失，如果假设存在阻力，如\\(b\\)物体的阻力是\n\\[\\bm f=-k_d\\dot{\\bm b} \\]\n其中\\(\\dot{\\bm b}\\)是\\(\\bm b\\)的一阶导数，即速度。\n考虑整个物体，此时要考虑两个物体的相对速度，则施加在\\(b\\)上面的阻力为\n\\[\\bm f_b=-k_d\\frac{\\bm b-\\bm a}{||\\bm b-\\bm a||}\\cdot(\\dot{\\bm b}-\\dot{\\bm a})\\cdot\\frac{\\bm b-\\bm a}{||\\bm b-\\bm a||} \\]\n弹簧组成的结构 例如组成一个网状结构、立方体结构等等。\n结构的行为更多的取决于弹簧的连接方式。\n粒子系统 直接定义众多小粒子，来描述更宏观的运动现象。通常可能比物理意义上的粒子（如原子）要大得多。\n它便于理解和实现，并且有较好的扩展性。\n但是有时需要大量粒子，如模拟流体；还需要加速结构。\n对于每一帧动画：\n如果需要，创造新的粒子 计算每个粒子上收到的力 更新粒子的位置和速度 如果需要，移除一些粒子 渲染粒子 粒子系统中的力：引力、电磁力、摩擦力、空气阻力等等。粒子系统还有碰撞。\n单粒子模拟 速度场\n描述了在某个位置，某个时间上的粒子的速度。（这里的x我推测是向量）\n\\[v(x,t) \\]\n然后有常微分方程(ODE)\n\\[\\frac{dx}{dt}=\\dot{x}=v(x,t) \\]\n欧拉方法\n用前一帧的量去估计下一帧的量\n\\[x_{t+\\Delta t}=x_t+\\Delta t\\dot{x}_t\\\\ \\dot{x}_{t+\\Delta t}=\\dot{x}_t+\\Delta t\\ddot{x}_t \\]\n问题：非常不准确，非常不稳定。主要是步长\\(\\Delta t\\)的存在导致的问题。这其实也是用数值方法来计算的共有问题。\n解决（降低）不稳定性的方法有：中点法、自适应步长法、隐式欧拉方法、基于位置的方法等等。\n中点法\n\\[x_{mid}=x(t)+\\Delta t/2\\cdot v(x(t),t)\\\\ x(t+\\Delta t)=x(t)+\\Delta t\\cdot v(x_{mid},t) \\]\n自适应步长法\n定义一个threshold 计算以\\(T\\)为步长，计算一次欧拉方法，得到\\(x_T\\) 以\\(T/2\\)为步长，计算两次欧拉方法，得到\\(x_{T/2}\\) 计算error，即\\(x_T-x_{T/2}\\) 如果error\u0026gt;threshold，则减小步长\\(T\\)，重试。 隐式欧拉方法\n\\[x_{t+\\Delta t}=x_t+\\Delta t\\dot{x}_{t+\\Delta t}\\\\ \\dot{x}_{t+\\Delta t}=\\dot{x}_t+\\Delta t\\ddot{x}_{t+\\Delta t} \\]\n解这个非线性方程，求出\\(x_{t+\\Delta t},\\dot{x}_{t+\\Delta t}\\)。用求根的算法，例如牛顿迭代法或者下述Runge-Kutta方法。隐式欧拉方法稳定性很好。\nRunge-Kutta 方法\n非常擅长解非线性方程。其中RK4最常被使用。\n首先，我们知道\n\\[\\frac{dy}{dt}=f(t,y),\\quad y(t_0)=y_0 \\]\n则\n\\[y_{n+1}=y_n+\\frac{1}{6}h(k_1+2k_2+2k_3+k_4)\\\\ t_{n+1}=t_n+h \\]\n其中\\(h\\)是步长\n\\[k_1=f(t_n,y_n)\\\\ k_2=f(t_n+h/2,y_n+hk_1/2)\\\\ k_3=f(t_n+h/2,y_n+hk_2/2)\\\\ k_4=f(t_n+h,y_n+hk_3) \\]\n基于位置的方法\n在修正欧拉方法的步长后，约束粒子的位置以防止其不稳定 使用约束位置计算速度 但是这会导致能量损失。\n刚体模拟 和粒子的模拟相似。\n需要考虑转角，角速度等。仍然可以使用欧拉方法。\n流体模拟 基于位置的方法 假设水都是由很多刚体小球组成的。\n假设水是不可压缩的。\n拉格朗日方法和欧拉方法 对于处理大量的物体\n拉格朗日方法是将每个物体看成质点去处理。\n欧拉法发是将空间切分为网格，对格子进行处理。\nMaterial Point Method 混合了欧拉方法和拉格朗日方法。\n正向运动学 关节骨骼模型\n拓扑的（什么连向了什么） 关节的几何关系 树状结构 关节的类型：\n类似于钉子的关节（只有一维旋转） 类似于球的关节（可以在两个维度内旋转） 平移关节 只要提供骨骼的长度和关节旋转的角度，就能知道尖端处于什么位置。\n逆向运动学 控制尖端的位置，然后自动计算合理的关节、骨骼位置。\n有时候解不唯一，并且解很难以求得。\nRigging 类似于提线木偶，也可以说是逆向运动学的一种应用。\n主要是给角色的一些部分以更高级的控件（控制点），可以进行鼠标拖动位置等修改。像是贝赛尔曲线。\n动作捕捉 把现实中的数据应用到Rigging上的操作。\n","date":"2022-08-10T12:54:34+08:00","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E5%8A%A8%E7%94%BB%E4%B8%8E%E6%A8%A1%E6%8B%9F/","title":"计算机图形学基础学习笔记-动画与模拟"},{"content":"全光函数 \\[P(\\theta,\\phi,\\lambda,t,V_x,V_y,V_z) \\]\n记录了在某个位置，往某个方向看，在某个时间，某种颜色的的光的强度\n其中\\(\\theta,\\phi\\)决定了看的方向，\\(\\lambda\\)决定光的频率，也即颜色，\\(t\\)决定时间，\\(V_x,V_y,V_z\\)决定了相机位置。\n光线 \\[P(\\theta,\\phi,V_x,V_y,V_z) \\]\n五个变量，了，两个描述了方向，三个描述了起点，这样就描述了一条射线。\n在非色散介质中，一个二维的点和一个二维的方向能定义光线。见光场。\n光场 一个物体发出的光可以映射到包围盒上。对于摄影机来说，看到的样子是不会改变的。（实际上应该是映射到和摄像机方向垂直的平面上）\n光场就是在任何一个位置，往任何一个方向去的光的强度。（实际上听上去和光线就是一个意思，只不过可能是将光线由物体表面发出换到了某个等效平面上发出）\n由于三维物体的表面是一个二维的。所以可以从物体表面发出一个二维方向来定义光线。\n好处在于，从任何位置看向这个物体，可以用四个变量得到光的信息。\n另外，可以把包围盒当成一个发光的盒子，看向这个物体直接查询盒子的光场，而不用考虑物体本身。\n如果只采用一个包围盒，则可以用平面上的一个点和其与法线的夹角定义光场。\n如果采用两个包围盒(一大一小，大的包含小的)，可以用两个点来描述光场。对于里面的平面上有一个点\\((u,v)\\)，外面的平面上有一个点\\((s,t)\\)，连接两点就是光场。\n光场相机 普通的透镜相机记录的是Irradiance，而光场相机通过将传感器上的像素替换为透镜，对不同颜色的光进行分光记录，就能够达到记录光场的效果。也就是记录Radiance。\n这样就可以先拍照，在后期处理的时候再聚焦。\n缺点：分辨率不足、成本高。\n可见光光谱 可见光光谱分布在400nm到700nm之间。\n谱功率密度（SPD） 可以通过SPD，描述某种东西发出的光在各个波长上的能量。\n其具有线性性质。可以直接相加。\n颜色的生物学基础 颜色是人的感知，而不是某一波长光的属性。\n视网膜上的感光细胞有两种，一种是棒状的视杆细胞，感觉光的强度。一种是锥形的视锥细胞，感觉光的颜色。视锥细胞要更少一点。\n视锥细胞分为三类：S、M、L；S感知较短波长的光，M感知中间波长的，L感知较长波长的。\n不同的人，三种细胞的分布会不一样，差异有时很大。\n实际上感知到的光，是每个细胞所能感知的波长范围内，每个波长乘以其强度再相加得到的结果（亦或者积分）。总共得到\\(S,M,L\\)三个数传输给大脑。\n同色异谱现象 不同的光谱，其进过积分后得到的三个数可能是相同的，也意味着在人看来是同一个颜色。\n颜色混合 通过将RGB三种颜色加起来来获得其他颜色。\n颜色空间 标准RGB 先让一个机器做好，其他机器以此为标准 广泛采用 色域有限 Gamut（色域） Gamut是一个原色集生成的所有色度。\n不同的颜色空间表示不同范围的颜色，同时也就具有不同的色域。\nHSV 由色调（各种颜色）、饱和度（决定接近白色还是接近某个特定颜色）和亮度组成\n","date":"2022-08-09T12:14:21+08:00","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E5%85%89%E5%9C%BA%E5%92%8C%E9%A2%9C%E8%89%B2%E5%92%8C%E6%84%9F%E7%9F%A5/","title":"计算机图形学基础学习笔记-光场、颜色和感知"},{"content":"小孔成像 和初中介绍的一致。以此原理做成的相机叫做针孔相机。\n透镜成像 通过透镜进行成像，和初中介绍的一致。现在大多数相机都是透镜成像的。\n快门 控制曝光时间。\n运动模糊 在快门打开的时间内，物体已经发生了明显移动（或者相机动了），就会导致模糊。\n果冻效应 如果某个物体的运动速度非常快，在快门时间内曝光就会产生扭曲效果。仅存在于卷帘快门相机中。\n传感器 捕捉光，并记录的部件。记录的实际上是Irradiance。\n为什么不能用传感器直接收集光，而非要加一个透镜？\n因为传感器上的每一个点都会采集物体上每一个点发出的光，然后所有的像素就会因此变得相似。换言之因为传感器记录的是Irradiance\n针孔相机 没有深度可言，换言之，每个区域都是清晰地。而不像透镜相机，会出现景深效果等等。而光线追踪是以针孔相机的模型来做的，也不会得到景深效果。\n视场(FOV,Field of View) 设传感器的垂直长度为\\(h\\)，透镜到传感器的距离为\\(f\\)，则\n\\[FOV=2arctan\\left(\\frac{h}{2f}\\right) \\]\n由此定义了垂直FOV。同理可以定义水平FOV。\n通常，以35mm格式的胶片为传感器标准大小，通过焦距的不同得到不同的FOV。\n例如17mm的胶片FOV是104°，50mm的是47°，200mm的是12°。\n但是对于手机摄像机，传感器并不是35mm格式的，要经过等效来换算焦距。\n当视场越窄，看到的东西越远。\n当然传感器尺寸也会影响FOV。想要保持FOV而减小传感器尺寸，则焦距也要变小。\n曝光 \\[H=T\\times E\\\\ Exposure = time\\times irradiance \\]\n其中time由快门控制，irradiance由物体自己和光圈控制。\n总结，物体亮度，或者说曝光由以下东西控制：\n光圈大小 快门速度 ISO增益，这是后期的处理，而不是原始的数据。有软件和硬件的实现。 光圈 F-Number 描述光圈的大小。通常写作FN或F/N。\n一个不太正式的理解，N是直径的倒数。N越大，光圈越小。\n景深 成像最锐利的点在像距平面上，但是传感器的平面并不总会在像距上，因此会导致模糊。\n理论上，物距上一个点发出的光会在像距上形成一个点，但是如果传感器不在像距上，像就会在传感器上形成一个圈（CoC）。\n设光圈直径为\\(A\\)，CoC直径为\\(C\\)，像距为\\(z_i\\)，透镜到传感器的距离为\\(z_s\\)，则有\n\\[\\frac{C}{A}=\\frac{|z_s-z_i|}{z_i} \\]\n而通常我们改变的是光圈大小，也即，大光圈导致模糊，小光圈成像清晰。\nF-Number的明确定义：焦距除以光圈直径。\n所以有\n\\[C=A\\frac{|z_s-z_i|}{z_i}=\\frac{f}{N}\\frac{|z_s-z_i|}{z_i} \\]\n如果CoC足够小，从相机中还是不容易看得出模糊。也就是说在CoC的一小个范围内，成像都是清晰的。这也对应了一个距离，称为Depth of focus。也可以知道物体能够清晰成像的距离范围，称为Depth of field。\n高速摄影 非常快的快门时间。也会因此降低亮度。为了抵消这种影响，就需要用更大的光圈，或者用ISO。\n低速摄影 非常慢的快门时间。可以出现“拉丝效果”。\n透镜 理想薄凸透镜 物距\\(z_o\\)，像距\\(z_i\\)，焦距\\(f\\)有如下关系\n\\[\\frac{1}{f}=\\frac{1}{z_i}+\\frac{1}{z_o} \\]\n模拟薄凸透镜的光线追踪 初始化：\n定义传感器大小，定义凸透镜的焦距、光圈大小。 设置物距，并计算像距。 渲染：\n对传感器上的每个像素x' 随机在透镜上选择点x'' 通过凸透镜定理得到物距平面上的点x\u0026rsquo;'' 计算x\u0026rsquo;\u0026rsquo;-\u0026gt;x\u0026rsquo;\u0026lsquo;\u0026lsquo;上的Radiance ","date":"2022-08-08T12:12:03+08:00","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%9B%B8%E6%9C%BA%E4%B8%8E%E9%80%8F%E9%95%9C/","title":"计算机图形学基础学习笔记-相机与透镜"},{"content":"非表面模型 参与介质(Participating Media) 例如云、雾等。\n其中的小晶体、小分子等会吸收光、反射光等。\n使用相位函数(Phase Function)来描述如何反射等。\n渲染思路：\n随机选择一个方向来反射 随机选择一个距离来传播 在每个反射点来连接光源进行着色 头发材质 Kajiya-Kay 模型\n效果不是很好，只考虑了头发上的反射。\nMarschner 模型\n广泛应用，更进一步地考虑了光线透过头发。\n但是这个模型不能很好地表现动物毛发。\n这个模型将头发认为是有颜色的实心圆柱体。\n但实际上头发中不是均一的某种物质，其中还有一个更小的圆柱体含有髓质。头发的髓质较少，但是其他毛发的髓质较多。\n双圆柱模型\n同上文描述，即考虑了髓质的存在。\n颗粒(Granular)材质 例如盐、白砂糖、米、沙子等。\n表面模型 半透明(Translucent)材质 例如玉石、水母等。\n次表面反射\n也就是，在材质内部反射，然后从某个方向离开表面。\nBSSRDF：作为BRDF的延伸，决定了光从某个方向进来，某个点进来，某个方向出去，某个点出去时光照。也会改变渲染方程。\nDipole Approximation\n通过在物体内部加一个虚拟光源来达到次表面反射的效果\n布料 可以当做表面来渲染，用BRDF进行。\n也可以当做参与介质来渲染，效果比当做平面要好，但是慢。\n也可以直接暴力地将每一根纤维渲染出来，类似头发，效果好，速度慢。\n有细节的材质 例如遍布金属表面的小划痕。\n可以用法线贴图，以及微表面模型来渲染，虽然效果很好，但是十分的慢。\n解决办法：在像素意义上使用BRDF。\n有时候，物体表面反射出来的是各种颜色。例如照射一块铝片，反射出来的宏观上是银色，但是细细的观察会发现有很多不同的颜色。这需要波动光学的帮助。\n程序化生成表面 不用纹理而是用一个噪声函数定义表面。\n可以生成地形、木纹、铁锈等等。\n","date":"2022-08-07T15:46:35+08:00","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E9%AB%98%E7%BA%A7%E5%A4%96%E8%A7%82%E6%A8%A1%E5%9E%8B/","title":"计算机图形学基础学习笔记-高级外观模型"},{"content":"无偏差(Unbiased)光传播方法 无偏差的蒙特卡洛方法不会造成任何系统误差。其求出的期望值永远会是正确的值，无论有多少采样点。\n双向路径追踪(Bidirectional Path Tracing, BDPT) 即通过从相机和光同时发出光线，然后让其在某一表面相遇的办法。\n如果光源发出的光传播很复杂，比如一束光直接达到天花板来照亮整个环境。那么双向的效果会比单向的好。\n问题在于实现困难和速度较慢。\nMetropolis光传播(MLT) 在蒙特卡洛积分中使用马尔科夫链。从当前样本估计周围的样本。\n给一条路径可以生成很多相似的路径。以处理局部光路复杂的情况。例如镜面反射-漫反射-镜面反射的情况。\n问题在于：难以估计收敛速度；每个像素的收敛速度不同，导致图面比较脏；不适合用于动画渲染。\n有偏差(Biased)光传播方法 有偏差的蒙特卡洛方法，其期望值随着采样点的增加会趋向正确的值。\n光子映射 特别适合处理镜面反射-漫反射-镜面反射的情况，以及生成焦散线(Caustics)，或者说由于聚焦作用形成的各种图案。\n有众多实现办法，其中一种：\n从光源处射出光子，经过各种反射、折射，直到打到漫反射材料，并记录。 从摄像机射出路径，经过各种反射、折射，直到打到漫反射材料，并记录。 对第二次打到的点，取周围的最近的\\(n\\)个光子，算其密度，来计算亮度。 其有偏的原因是\n\\[\\frac{dN}{dA}\\neq\\frac{\\Delta N}{\\Delta A} \\]\n当光子趋近于无限时，上式趋于相等。\n\\(N\\)比较小时，图片有很多噪声。\\(N\\)比较大时，图片比较模糊。如果足够多，就可以收敛到不模糊的结果。\nVertex Connection and Merging 其实就是双向路径追踪和光子映射的结合。\n实时辐射度 有时也叫做多光源方法。\n光源发出来的光线，打到某些地方，则把这些地方看做新的光源。\n渲染场景时将这些虚拟光源看作是光源。\n好处是：速度快，并且对于漫反射处理比较好。\n问题是：有些地方莫名的会发光；不 能做金属材质（Glossy）的渲染。\n","date":"2022-08-07T14:57:59+08:00","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E9%AB%98%E7%BA%A7%E5%85%89%E7%BA%BF%E4%BC%A0%E6%92%AD/","title":"计算机图形学基础学习笔记-高级光线传播"},{"content":"题意：有\\(N\\)个方块，初始时站在\\(1\\)方块上。每个方块上有一个数\\(a_i\\)，等概率地随机选一个\\(0\\sim a_i\\)的数，假设在\\(x\\)方块上选到了\\(y\\)，则跳到\\(x+y\\)方块。求跳到\\(N\\)上时，选取次数的期望值。\n设\\(dp[i]\\)是从\\(i\\)走到\\(N\\)的期望，那么\\(dp[N]=0\\)。\n记\n\\[s = dp[i+1]+dp[i+2]+\\cdots+dp[i+a_i] \\]\n然后有\n\\[dp[i] = \\frac{s+a_i}{a_i+1}+\\frac{1}{a_i+1}\\left(\\frac{s+2a_i}{a_i+1}\\right)+\\cdots \\]\n\\[=\\sum_{n=1}^\\infty\\left(\\frac{1}{a_i+1}\\right)^{n-1}\\left(\\frac{s+na_i}{a_i+1}\\right) \\]\n\\[=\\sum_{n=1}^\\infty\\frac{s}{(a_i+1)^n}+\\sum_{n=1}^\\infty\\frac{na_i}{(a_i+1)^{n}} \\]\n\\[=\\frac{s}{1-\\frac{1}{a_i+1}}-s+1+\\frac{1}{a_i} \\]\n\\[=\\frac{s+1}{a_i}+1 \\]\n最终\n\\[dp[i]=\\frac{dp[i+1]+dp[i+2]+\\cdots+dp[i+a_i]+1+a_i}{a_i} \\]\n其中\\(s\\)可以用前缀和优化。\n\\[\\frac{s+a_i}{a_i+1}=\\frac{dp[i+1]+1+dp[i+2]+1+\\cdots+dp[i+a_i]+1}{a_i+1} \\]\n其实就是非常朴素的选择次数除以概率再相加。然后如果某一次选中了0就再往下算。\n最终的代码如下\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cmath\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;map\u0026gt; #include \u0026lt;set\u0026gt; #include \u0026lt;queue\u0026gt; #include \u0026lt;stack\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;cstdint\u0026gt; #include \u0026lt;cstdio\u0026gt; #include \u0026lt;bitset\u0026gt; #include \u0026lt;deque\u0026gt; #define LL long long #define ULL unsigned long long #define i128 __int128 #define debug(a) std::cout\u0026lt;\u0026lt;#a\u0026lt;\u0026lt;\u0026#34;=\u0026#34;\u0026lt;\u0026lt;a\u0026lt;\u0026lt;std::endl #define lth(i,x,y) for(int i=x;i\u0026lt;=y;i++) #define htl(i,x,y) for(int i=x;i\u0026gt;=y;i--) #define mms(x) memset(x, 0, sizeof(x)) const int MAXN = 200005; const int INF = 0x7fffffff; const double EPS = 1e-8; const int MOD = 998244353; const double PI = acos(-1); LL arr[MAXN]; LL inv[MAXN]; LL sum[MAXN]; LL dp[MAXN]; LL qPowMod(LL a, LL n, LL b){ LL ans = 1; while(n){ if(n\u0026amp;1){ ans = ans%b*a%b; } a = a%b*a%b; n\u0026gt;\u0026gt;=1; } return ans; } LL fermat_inv(LL a, LL b){ return qPowMod(a,b-2,b); } void init(int n){ for(int i=1;i\u0026lt;=n;i++){ inv[i] = fermat_inv(i,MOD); } } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n; std::cin\u0026gt;\u0026gt;n; init(n); for(int i=1;i\u0026lt;=n-1;i++){ std::cin\u0026gt;\u0026gt;arr[i]; } dp[n] = 0; sum[n] = 0; for(int i=n-1;i\u0026gt;=1;i--){ dp[i] = (((sum[i+1]-sum[i+arr[i]+1]+arr[i]+1+MOD)%MOD)*(inv[arr[i]]%MOD))%MOD; sum[i] = (sum[i+1]+dp[i])%MOD; } std::cout\u0026lt;\u0026lt;dp[1]\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 其中第74行的\ndp[i] = (((sum[i+1]-sum[i+arr[i]+1]+arr[i]+1+MOD)%MOD)*(inv[arr[i]]%MOD))%MOD; 不能写为\ndp[i] = (((sum[i+1]-sum[i+arr[i]+1]+arr[i]+1)%MOD)*(inv[arr[i]]%MOD))%MOD; 原因应当是，会出现负数。虽然按照原本的想法，sum[i+1]肯定是大于等于sum[i+arr[i]]。但是sum本身也在进行取余运算，可能会导致小于的情况，导致负数的出现。此时要加一个998244353。\n","date":"2022-08-07T12:57:17+08:00","permalink":"https://kegalas.top/p/atcoder-beginner-conteset-263-e%E6%A6%82%E7%8E%87dp/","title":"Atcoder Beginner Conteset 263 E（概率DP）"},{"content":" 注：本文内容可能不再推荐使用，因为pandoc无法生成正确的代码高亮，也没有更多的参数可以选择。并且添加目录的方式比较DIY，而我本人暂时不会Go语言相关的东西，无法进一步跟进官方版本的更新。\n现在推荐去给Hugo默认的goldmark引擎添加mathjax支持。\n详情见这篇文章为Hugo安装goldmark-mathjax插件来更好地支持输入公式\n根据https://github.com/olOwOlo/hugo-theme-even/issues/139，hugo无法正确生成目录的原因是，没有加入\u0026ndash;toc参数。\n其中@jdhao所说的https://github.com/gohugoio/hugo/blob/master/helpers/content.go#L735这一部分代码现在（编辑日期时）已经转移到了https://github.com/gohugoio/hugo/blob/master/markup/pandoc/convert.go#L67。按他的办法来说应该改成\nargs := []string{\u0026#34;--mathjax\u0026#34;,\u0026#34;--toc\u0026#34;} 实际上并没有那么简单，即使是加入了\u0026ndash;toc参数也不能生成目录。笔者又找到一份他人修改的版本https://github.com/bigshans/hugo。这个版本的convert.go明显是修改过的，能够正确生成目录。\n将其克隆、编译，然后替换掉原来的hugo.exe。经测试可以正常使用。目前发现的唯一可以称得上是一个问题的是，代码没有高亮。\n编译方法见hugo的github readme。\n如果因为网络问题无法编译，可以给powershell设置代理，见之前的文章。\n如果cgo exit status 2，那么可能是g++的问题，笔者的电脑上g++是msys2滚动更新的，更换为8.1.0版本成功编译了。（后注：要区分msys环境和mingw64环境，见这篇文章MSYS2,MinGW64,Cygwin的使用区别浅谈）\n","date":"2022-08-06T16:41:53+08:00","permalink":"https://kegalas.top/p/%E9%87%8D%E6%96%B0%E7%BC%96%E8%AF%91hugo%E6%9D%A5%E4%BD%BF%E5%BE%97pandoc%E5%8F%AF%E4%BB%A5%E7%94%9F%E6%88%90%E7%9B%AE%E5%BD%95/","title":"重新编译hugo来使得pandoc可以生成目录"},{"content":"通常，v2rayN设置中的ip是127.0.0.1，http协议的端口是10809，在PowerShell中临时使用代理，需要输入如下命令\n$env:HTTP_PROXY=\u0026#34;http://127.0.0.1:10809\u0026#34; $env:HTTPS_PROXY=\u0026#34;http://127.0.0.1:10809\u0026#34; 之后输入\ncurl www.google.com 来检验是否成功。如果v2rayN本身是能够连接到谷歌的，那么得到的结果应该类似于下方：\nStatusCode : 200 StatusDescription : OK Content : \u0026lt;!doctype html\u0026gt;\u0026lt;html itemscope=\u0026#34;\u0026#34; itemtype=\u0026#34;http://schema.org/WebPage\u0026#34; lang=\u0026#34;en\u0026#34;\u0026gt;\u0026lt;head\u0026gt;\u0026lt;meta conten t=\u0026#34;Search the world\u0026#39;s information, including webpages, images, videos and more. Google has many spe ci... RawContent : HTTP/1.1 200 OK ...... 另外不要使用ping命令去测试，虽然不明原因但是确实无法ping到谷歌。\n","date":"2022-08-06T16:33:44+08:00","permalink":"https://kegalas.top/inferior/%E5%9C%A8powershell%E4%B8%AD%E4%BD%BF%E7%94%A8v2rayn%E4%BB%A3%E7%90%86/","title":"在PowerShell中使用v2rayN代理"},{"content":"材质 某种意义上来说，材质就是决定双向反射分布函数(BRDF)的东西。\n漫反射材质 漫反射，代表着光均匀地反射到每一个方向。\n假设入射光也是均匀的。\n则\\(f_r,L_i(\\omega_i)\\)就是常数。那么渲染方程：\n\\[L_o(\\omega_o)=\\int_{H^2}f_rL_i(\\omega_i)cos\\theta_i d\\omega_i \\]\n\\[=f_rL_i\\int_{H^2}cos\\theta_i d\\omega_i \\]\n\\[=\\pi f_rL_i \\]\n所以有\n\\[f_r=\\frac{\\rho}{\\pi} \\]\n其中\\(\\rho\\)是反射率。\n有光泽的(Glossy)材质 金属材质是一类，金属材质的反射较为集中，但又不是镜子那样的镜面反射。\n折射材质 有时会有像玻璃这样的材质，既有反射又有折射。\n反射定律 反射角\\(\\theta_o\\)等于入射角\\(\\theta_i\\)。\\(\\theta=\\theta_o=\\theta_i\\)\n并且反射光线和入射光线在同一平面呢。\n或者入射光线的立体角\\(\\omega_i\\)与反射光线的立体角\\(\\omega_o\\)与反射面的法单位向量\\(\\bm n\\)之间的关系是\n\\[\\omega_i+\\omega_o=2cos\\theta\\cdot\\bm n \\]\n折射定律 入射角\\(\\theta_i\\)、入射材质的折射率\\(\\eta_i\\)和折射角\\(\\theta_t\\)、折射材质的折射率\\(\\eta_t\\)有如下关系\n\\[\\eta_i sin\\theta_i=\\eta_t sin\\theta_t \\]\n并且入射光线和折射光线在同一平面内。\n如果发生全反射，要从光密介质射到光疏介质里。并且因为：\n\\[cos\\theta_t=\\sqrt{1-sin^2\\theta_t}=\\sqrt{1-\\left(\\frac{n_i}{n_t}\\right)^2sin^2\\theta_i} \\]\n所以全反射时满足\n\\[1-\\left(\\frac{n_i}{n_t}\\right)^2sin^2\\theta_i\u003c0 \\]\n菲涅尔反射 经常观察到一些现象，比如木桌子上，低角度看过去有反射，高角度看过去没有反射。或者正对玻璃能看到外面，斜对着玻璃可能只能看到反射。\n这说明反射率和入射角有关。实际上这和光的偏振有关。\n一定功率的入射光被界面反射的比例称为反射比\\(R\\)；折射的比例称为透射比\\(T\\)。有\n\\[R+T=1 \\]\n如果入射光的电矢量垂直于光平面（由入射、反射、折射光线构成的平面）（即\\(s\\)偏振），则反射比为：\n\\[R_s=\\left[\\frac{sin(\\theta_t-\\theta_i)}{sin(\\theta_t+\\theta_i)}\\right]^2 \\]\n如果入射光的电矢量在光平面内（即\\(p\\)偏振），反射比为：\n\\[R_p=\\left[\\frac{tan(\\theta_t-\\theta_i)}{tan(\\theta_t+\\theta_i)}\\right]^2 \\]\n这两个式子都可以用折射定律和三角恒等式展开。透射比无论如何都满足\\(T=1-R\\)\n如果入射光是无偏振的，即含有等量的\\(s,p\\)偏振，那么\n\\[R=\\frac{R_s+R_p}{2} \\]\n显然近垂直入射时\n\\[R=\\left(\\frac{n_i-n_t}{n_i+n_t}\\right)^2 \\]\n在图形学中，这个计算过于麻烦，通常会采用Schlick近似\n\\[R(\\theta)=R_0+(1-R_0)(1-cos\\theta)^5 \\]\n\\[R_0=\\left(\\frac{n_i-n_t}{n_i+n_t}\\right)^2 \\]\n微表面材质 假设物体表面是粗糙的。从远处看是平的、粗糙的；从近处看能看到凹凸不平，每一个小平面都是镜面反射。\n如果没有凹凸，则是镜面材质。\n如果凹凸变化不是很剧烈（法线分布比较均匀），那么会得到一个Glossy的材质。\n如果凹凸变化的比较剧烈（法线分布不均匀），那么会得到一个漫反射材质。\n微表面材质的BRDF可以如下写\n设\\(\\omega_i\\)是入射光线的立体角，\\(\\omega_o\\)是反射光线的立体角，\\(h\\)是它们的半程向量。\\(n\\)是宏观表面的法向量，则\n\\[f_r(\\omega_i,\\omega_o)=\\frac{F(w_i,h)G(\\omega_i,\\omega_o,h)D(h)}{4(n\\cdot\\omega_i)(n\\cdot\\omega_o)} \\]\n其中\\(F\\)是菲涅尔项；\\(G\\)是几何项（阴影遮挡函数），光线可能会被微平面互相遮挡而影响，所以引入此函数；\\(D\\)是微表面分布函数，决定了有多少微表面的法线朝向\\(h\\)\n各向同性/异性材料 各向异性的材料，由于观察的方位角不同，BRDF不同（即使入射角和反射角相对不变）。\nBRDF的性质 非负\n\\[f_r\\geq 0 \\]\n线性性质\n可以把各个方向的BRDF加起来，得到的结果和对这些方向和的BRDF一样。反之也可以拆分BRDF。\n可逆性\n\\[f_r(\\omega_r\\to\\omega_i)=f_r(\\omega_i\\to\\omega_r) \\]\n能量守恒\n能量不会变多，如果物体没有吸收，那么入射多少就会反射多少。\n对于各向同性材质\nBRDF与方位角无关；方位角指的是光线投影到材质平面上，在材质平面上的角。\nBRDF的测量 由于图形学中的公式有估计的成分，BRDF可能与实际值相差很大，有时会用到测量的办法。\n","date":"2022-08-06T10:57:51+08:00","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%89%A9%E4%BD%93%E6%9D%90%E8%B4%A8/","title":"计算机图形学基础学习笔记-物体材质"},{"content":"为什么需要光线追踪 光栅化不能很好地处理全局效果。例如软阴影，以及光照的多次反射。\n虽然光栅化很快，但是质量不非常好、不真实。\n相比之下光线追踪效果会好很多，但是也非常慢。在过去算力不发达的时候，光栅化是一个实时的算法，而光线追踪是一个离线的算法。\n基础的光线追踪算法 光线投射 对每一个像素投射一条光线来生成一张图 对光源发射一条光线来检查阴影 Pinhole Camera Model\n首先从眼睛，或者说相机发出一条光线，穿过图像平面上的一个像素。然后和空间中的一个物体边缘相交。当然可以和一个物体多次、或者和多个物体相交，我们需要的是最近的。\n然后对最近的这个交点进行着色计算。例如使用Blinn-Phong模型。\nRecursive(Whitted-Style) Ray Tracing\n仍然从相机发出一条光线，穿过图像平面上的一个像素。然后和空间中的一个物体边缘相交。当然，如果是较为镜面的物体，会继续反射光线的路径和下一个物体边缘相交。直到不出现镜面反射。如果是玻璃等透射物质，则要沿着折射光线继续，直到不透明物体。\n光线的数学表示 光线由光源点和方向向量表示。\n\\[\\bm r(t) = \\bm o+t\\bm d\\quad 0\\leq t\u003c\\infty \\]\n其中\\(t\\)是时间，\\(\\bm o\\)是光源向量，\\(\\bm d\\)是方向向量。\n光线相交 对于隐式表示的物体\n判断是否相交，例如一个球面：\n\\[(\\bm{p}-\\bm{c})^2-R^2=0 \\]\n其中\\(\\bm p\\)是球面上的点，\\(\\bm c\\)是球心，和\n\\[\\bm r(t) = \\bm o+t\\bm d\\quad 0\\leq t\u003c\\infty \\]\n相交，则要满足\n\\[(\\bm o+t\\bm d-\\bm c)^2-R^2=0 \\]\n只有\\(t\\)一个未知数，解即可。\n其他的隐式表示的，或者说用代数形式表示的物体都可以这么判断相交。\n对于三角形网格\n首先，三角形一定能够确定一个平面。所以先判断光线和平面的相交，以及计算交点。再计算交点是否在三角形内。\n一个平面可以表述为上面的一点和平面的法向量。\n所有在平面上的点满足如下等式\n\\[(\\bm p-\\bm p')\\cdot \\bm N = 0 \\]\n其中，\\(\\bm p'\\)是平面上已知一点，\\(\\bm N\\)是平面法向量。\n判断光线和平面的交点：\n和\n\\[\\bm r(t) = \\bm o+t\\bm d\\quad 0\\leq t\u003c\\infty \\]\n联立，得\n\\[(\\bm o+t\\bm d-\\bm p')\\cdot \\bm N = 0 \\]\n解得\n\\[t = \\frac{(\\bm p'-\\bm o)\\cdot \\bm N}{\\bm d\\cdot\\bm N} \\]\n应确保\\(0\\leq t\u003c\\infty\\)\n直接计算出交点重心坐标的方法\nMoller Trumbore Algorithm:\n\\[\\bm O+t\\bm D = (1-b_1-b_2)\\bm P_0+b_1\\bm P_1+b_2\\bm P_2 \\]\n\\[\\begin{bmatrix} t \\\\ b_1 \\\\ b_2 \\end{bmatrix}= \\frac{1}{\\bm S_1\\cdot\\bm E_1} \\begin{bmatrix} \\bm S_2\\cdot\\bm E_2 \\\\ \\bm S_1\\cdot\\bm S \\\\ \\bm S_2\\cdot\\bm D \\end{bmatrix} \\]\n其中：\n\\[\\bm E_1=\\bm P_1 - \\bm P_0 \\]\n\\[\\bm E_2=\\bm P_2 - \\bm P_0 \\]\n\\[\\bm S=\\bm O - \\bm P_0 \\]\n\\[\\bm S_1=\\bm D \\times \\bm E _2 \\]\n\\[\\bm S_2=\\bm S \\times \\bm E _1 \\]\n光线追踪加速 包围盒 一个物体被完整地包含在一个长方体中，这个长方体称之为包围盒。有时有多个物体在内。\n显然如果光线没有击中包围盒，光线也就不会击中物体。\n由于长方体的六个面确定了六个平面，长方体又可以看作是三组平行平面的交叉。\n我们通常会使用轴对齐的包围盒。即三组平面都平行于坐标面。\n对每一组平面都求光线和其交点，都会求出一个近点和远点。将三组近点和远点比较，求出最远的近点和最近的远点，就是和包围盒的交点。当然同时注意\\(t\\geq 0\\)\n使用轴对齐的包围盒可以减少算法常数\n例如对齐x轴时\n\\[t = \\frac{(\\bm p'-\\bm o)\\cdot \\bm N}{\\bm d\\cdot\\bm N}=\\frac{\\bm p'_x-\\bm o_x}{\\bm d_x} \\]\n空间均匀分割 找到一块区域，均匀地划分成正方形（三维情况为正方体）网格。在每个网格记录物体边缘的重叠情况。\n对于光线穿过的每个网格中，枚举和网格有交集的所有物体，检测是否和光线相交。\n网格划分太少，则很难于无划分区分开来。划分太多，则会有很多和网格的计算。\n一个启发式的算法是，网格数等于C乘以物体数。在三维中C为27.\n处理较好的情况是，有很多物体的情况。而处理不好的情况是，一个体育馆中心有一个茶壶等类似情况时。\n不均匀的分割 见数据结构笔记KD-Tree。\n下面讲解光线和KD-Tree中的小空间的相交处理。\n首先从根节点开始。光线首先会和根节点表述的空间有两个交点。\n然后判断和两个子节点是否有相交。如果没有则忽略。如果有，则持续往下分割。直到没有子节点，就判断小空间内的物体是否和光线相交。\n层次包围盒(BVH) 见数据结构笔记。\n辐射度量学 辐射能量 辐射能量是电磁辐射的能量。以焦耳（J）做单位，\\(Q\\)为符号。\n辐射通量(Radiant Flux) 辐射通量是每单位时间接收、发射、反射、传输的能量。\n\\[\\Phi\\equiv\\frac{dQ}{dt} \\]\n单位是瓦特（W），或流明（lm）。\n但流明和瓦特略有不同，流明作为光通量的单位，只考虑了可见光的通量，而瓦特作为辐射通量考虑了电磁波的全部通量。\n辐射强度(Radiant Intensity) 辐射强度是每单位立体角所能从点光源接收到的辐射通量。\n\\[I(\\omega)\\equiv\\frac{d\\Phi}{d\\omega} \\]\n对于可见光单位是坎德拉（cd），对于一般电磁波是\\(W/sr\\)。\n立体角 圆的角：\n\\[\\theta = \\frac{l}{r} \\]\n其中\\(l\\)是弧长，以弧度制计算，总共有\\(2\\pi\\)\n对于球体的立体角\n\\[\\Omega = \\frac{A}{r^2} \\]\n其中\\(A\\)是球面上的面积，以弧度制计算，总共有\\(4\\pi\\)\n其微分如下\n\\[dA=(rd\\theta)(rsin\\theta d\\phi)=r^2sin\\theta d\\theta d\\phi \\]\n其中\\(\\theta\\)是与\\(z\\)轴的夹角，\\(\\theta\\)是与\\(x\\)轴的夹角。\n\\[d\\omega=\\frac{dA}{r^2}=sin\\theta d\\theta d\\phi \\]\n所以有\n\\[\\Phi = \\int_{S^2}Id\\omega=4\\pi I \\]\n\\[I = \\frac{\\Phi}{4\\pi} \\]\n从实践上来看，立体角是一个单位向量\n辐射通量密度、辐照度(Irradiance) 指辐射通量对每单位面积的量，注意传播方向，或者分量传播方向与那个单位平面垂直。或者说每投影单位面积。\n\\[E(x)\\equiv\\frac{d\\Phi(x)}{dA} \\]\n对于可见光，单位为\\(lm/m^2=lux\\)，对于一般电磁波，单位为\\(W/m^2\\)\n要求传播方向与平面垂直，和前面提到的Lambert\u0026rsquo;s Cosine Law是相应的。\n辐射率(Radiance) 是辐射强度对于每投影单位面积的量。\n\\[L(p,\\omega) = \\frac{d^2\\Phi(p,\\omega)}{d\\omega dAcso\\theta} \\]\n其中\\(\\theta\\)是传播方向与平面法线的夹角。\n对于可见光，单位是\\(cd/m^2=lm/(sr\\cdot m^2)=nit\\)。对于一般电磁波，单位是\\(W/(sr\\cdot m^2)\\)\n显然可以推断出，辐射率是辐射通量在每立体角和每投影面积的量，也是辐照度每立体角的量。\n入射辐射率(Incident Radiance) 是辐射度对每单位立体角的量，其中辐射是到达平面。\n\\[L(p,\\omega)=\\frac{dE(p)}{d\\omega cos\\theta} \\]\n出射辐射率(Exiting Radiance) 是辐射强度对每单位投影面积的量，其中辐射是从平面发出\n\\[L(p,\\omega) = \\frac{dI(p,\\omega)}{dAcos\\theta} \\]\nRadiance和Irradiance \\[dE(p,\\omega) = L_i(p,\\omega)cos\\theta d\\omega \\]\n\\(dE(p,\\omega)\\)，指的就是每个立体角的Irradiance，也即\\(dA\\)接收到\\(d\\omega\\)发来的能量。而计算各个方向上的\\(dE\\)之和，算出来的就是Radiance，也即\\(dA\\)从各个方向接收的能量。这个各个方向通常指的是单位半球的各个立体角。单位半球记作\\(H^2\\)。\n\\[E(p)=\\int_{H^2}L_i(p,\\omega)cos\\theta d\\omega \\]\n双向反射分布函数(Bidirectional Reflectance Distribution Function) 在某一点的反射过程 首先，从某个立体角\\(\\omega_i\\)射过来的Radiance，变为了某个面积\\(dA\\)的能量。\n然后，这个能量从这个面积再辐射出Radiance到任意其他立体角\\(\\omega\\)\n入射的Radiance是\\(dE(\\omega_i)=L(\\omega_i)cos\\theta(i)d\\omega_i\\)\n出射的Radiance，对于某个立体角是\\(dL_r(\\omega_r)\\)\n而BRDF就是描述了，会有多少光从每个入射光线，反射到某个立体角\\(\\omega_r\\)。\n\\[f_r(\\omega_i\\to\\omega_r)=\\frac{dL_r(\\omega_r)}{dE_i(\\omega_i)}=\\frac{dL_r(\\omega_r)}{L(\\omega_i)cos\\theta(i)d\\omega_i} \\]\n单位是\\(1/sr\\)\n反射方程 \\[L_r(p,\\omega_r)=\\int_{H^2}f_r(p,\\omega_i\\to\\omega_r)L_i(p,\\omega_i)cos\\theta_i d\\omega_i \\]\n这个方程会遇到一些问题：如果入射光也有其他物体的反射光，会导致递归方程。\n渲染方程 如果一个物体自己会发光，反射方程需要添加一项。\n\\[L_o(p,\\omega_o)=L_e(p,\\omega_o)\\\\ +\\int_{\\Omega^+}L_i(p,\\omega_i)f_r(p,\\omega_i,\\omega_o)(n\\cdot w_i) d\\omega_i \\]\n简化的写法可以写作\n\\[L(u)=e(u)+\\int L(v)K(u,v)dv \\]\n再进一步可以写作算子形式\nL = E+KL\n可以被离散化成一个简单的矩阵方程，\\(L,E\\)是向量，\\(K\\)是光传播矩阵。\n如果考虑物体的反射作为新的入射光线，就会导致递归方程。将算子做如下运算\n\\[L=E+KL\\\\ (I-K)L=E\\\\ L=(I-K)^{-1}E \\]\n将中间的\\((I-K)^{-1}\\)展开成幂级数\n\\[L=(I+K+K^2+K^3+\\cdots)E\\\\ L=E+KE+K^2E+K^3E+\\cdots \\]\n其中第一项代表光源直接射过来的光，第二项表示光源经过一次反射过来的光，第三项表示光源经过一次反射过来的光。以此类推。这也是全局光照的基础。\n路径追踪 Whitted-Style Ray Tracing的错误之处：无法正确处理略有磨砂感的金属表面，无法正确处理漫反射。\n但是渲染方程是正确的。但缺陷是，要在半球面上解定积分，以及有递归运算。\n一个简单情况下的蒙特卡罗积分 假设我们要渲染一个像素(点)，只考虑直接照射的光线。假设这个点不发光。渲染方程如下：\n\\[L_o(p,\\omega_o)=\\int_{\\Omega^+}L_i(p,\\omega_i)f_r(p,\\omega_i,\\omega_o)(n\\cdot \\omega_i) d\\omega_i \\]\n蒙特卡洛积分中的\\(f(x)\\)为：\n\\[L_i(p,\\omega_i)f_r(p,\\omega_i,\\omega_o)(n\\cdot \\omega_i) \\]\n蒙特卡洛积分中的pdf是（假设均匀采样）：\n\\[p(\\omega_i)=\\frac{1}{2\\pi} \\]\n所以最终：\n\\[L_o(p,\\omega_o)=\\int_{\\Omega^+}L_i(p,\\omega_i)f_r(p,\\omega_i,\\omega_o)(n\\cdot \\omega_i) d\\omega_i \\]\n\\[\\approx\\frac{1}{N}\\sum_{i=1}^N\\frac{L_i(p,\\omega_i)f_r(p,\\omega_i,\\omega_o)(n\\cdot \\omega_i)}{p(\\omega_i)} \\]\n这对于直接光照来说是一个正确的光栅化算法。\n伪代码如下\nshade(p,wo) Randomly choose N directions wi~pdf Lo=0.0 For each wi Trace a ray r(p,wi) If ray r hit the light Lo+=(1/N)*L_i*f_r*cosine/pdf(wi) Return Lo 全局光照情况下 解决反射导致的光线数量爆炸 间接光照也要考虑的情况下，我们很容易得到一个伪代码：\nshade(p,wo) Randomly choose N directions wi~pdf Lo=0.0 For each wi Trace a ray r(p,wi) If ray r hit the light Lo+=(1/N)*L_i*f_r*cosine/pdf(wi) Else If ray r hit an object at q Lo+=(1/N)*shade(q,-wi)*f_r*cosine/pdf(wi) Return Lo 这会导致一个问题，如果是一个不太光滑的物体，第一次反射后有100个方向的漫反射，一直递归下去，就有\\(100^n\\)条光线，这是不能接受的。而且，显然只有在，反射后只有1个方向的光线时，才不会出现指数爆炸。此时叫做路径追踪。伪代码如下：\nshade(p,wo) Randomly choose ONE directions wi~pdf Trace a ray r(p,wi) If ray r hit the light Return L_i*f_r*cosine/pdf(wi) Else if ray r hit an object at q Return shade(q,-wi)*f_r*cosine*pdf(wi) 如果反射后的光线方向不止一个，那么称作分布式光线追踪，这已经是一个过时的想法了。\n虽然解决了指数爆炸问题，但是，这会导致很多的噪声。\n解决噪声的办法是，对于每一个像素，发出更多的光线，最后取Radiance的平均。伪代码如下\nray_generation(camPos, pixel) Uniformly choose N sample position within the pixel pixel_radiance = 0.0 For each sample in the pixel Shoot a ray r(camPos, cam_to_sample) If ray r hit the scene at p pixel_radiance+=1/N*shade(p,sample_to_cam) Return pixel_radiance 解决光线反射次数无限的问题 多次反射导致指数爆炸的问题解决了，还有一个问题是递归问题。\nshade函数并没有给出明确的函数停止的条件，这会导致无限递归。且粗暴的设定一个硬性条件则会导致能量的丢失。\n有一个俄罗斯转盘（RR）算法。\n之前，我们总是对一个像素射出光线来得到着色结果\\(Lo\\)。\n现在，假设我们手动设定了一个概率\\(P(0\u003c P\u003c1)\\)。\n当我们遇到概率为\\(P\\)的情况时，射出一个光线，并且返回着色结果，再讲这个结果除以\\(P\\)，得到\\(Lo/P\\)\n遇到概率为\\(1-P\\)的情况时，不射出光线，得到的结果为\\(0\\)。\n最后的能量为：\n\\[E=P*(Lo/P)+(1-P)*0=Lo \\]\n伪代码如下\nshade(p,wo) Manually specify a probability P_RR Randomly select ksi in a uniform dist. in[0,1] If (ksi\u0026gt;P_RR) Return 0.0 Randomly choose ONE directions wi~pdf Trace a ray r(p,wi) If ray r hit the light Return L_i*f_r*cosine/pdf(wi)/P_RR Else if ray r hit an object at q Return shade(q,-wi)*f_r*cosine*pdf(wi)/P_RR 提升效率 在着色点上反射光线，如果光源面积很大，则几根光线就可以打到光源。如果光源很小、接近点光源，则要很多光线才能打到。因为我们是均匀地往四周反射光线，或者说，我们的pdf是一个常数。\n可以考虑将在半球上的积分转化为在光源上的积分。\n需要找到\\(d\\omega\\)（半球立体角）和\\(dA\\)（光源上的面积）的关系。\n显然，这是一个投影关系，又因为半球的半径是\\(1\\)，有如下关系\n\\[d\\omega = \\frac{dAcos\\theta'}{||x'-x||^2} \\]\n其中\\(x'\\)是光源微平面的坐标，\\(x\\)是着色点的坐标，\\(\\theta'\\)是光源微平面法向量和\\(x-x'\\)向量的夹角。\n渲染方程重写为\n\\[L_o(x,\\omega_o)= \\int_{\\Omega^+}L_i(x,\\omega_i)f_r(x,\\omega_i,\\omega_o)cos\\theta d\\omega_i\\\\ \\]\n\\[=\\int_A L_i(x,\\omega_i)f_r(x,\\omega_i,\\omega_o)\\frac{cos\\theta cos\\theta'}{||x'-x||^2} dA \\]\n\\(\\theta\\)是着色点微平面的法向量和\\(x'-x\\)向量的夹角。\n蒙特卡洛积分的\\(f(x)\\)变为\n\\[L_i(x,\\omega_i)f_r(x,\\omega_i,\\omega_o)\\frac{cos\\theta cos\\theta'}{||x'-x||^2} \\]\npdf变为\\(1/A\\)\n之后，我们对光源不使用RR，对其他反射使用RR。\n另外，转化为\\(dA\\)后，要考虑中间是否有物体挡住光源。\n最终伪代码如下\nshade(p,wo) # Contribution from the light source. L_dir = 0.0 Uniformly sample the light at x\u0026#39; (pdf_light = 1/A) Shoot a ray from p to x\u0026#39; If the ray is not blocked in the middle L_dir = L_i*f_r*cos1*cos2/|x\u0026#39;-p|^2/pdf_light # Contribution from other reflectors L_indir = 0.0 Test Russian Roulette with probability P_RR Uniformly samplethe hemisphere toward wi(pdf_hemi = 1/2pi) Trace a ray r(p,wi) If ray r hit a non-emitting object at q L_indir = shade(q,-wi)*f_r*cos1/pdf_hemi/P_RR Return L_dir+L_indir ","date":"2022-07-28T17:36:32+08:00","image":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA/cover_huee16c3054c7900bea9817aac8584ab5c_32954_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA/","title":"计算机图形学基础学习笔记-光线追踪"},{"content":"基础乐理部分 和声小调与旋律小调 为了制造导音，和声小调需要在自然小调的基础上升高\\(\\hat{7}\\)音。\n为了加强和声小调的旋律平滑性，旋律小调在上行时需要在和声小调的基础上升高\\(\\hat{6}\\)音，下行时则是在自然小调的基础上不做改动。\n关系大小调的推断 享有共同调号的两个调。\n一个小调的关系大调位于该小调主音上方三个-半音级。反之可以推大调的关系小调。\n平行大小调 享有共同的主音的大小调。\n近关系调 调号只相差一个升号或降号的两个调。也是五度循环圈中相邻的两个调。\n通过调号判断主音 大调意义上，调号中最后一个升号向上半级的音是主音。例如最后一个升号是#F，则主音是G。最后一个升号是#B，则主音是#C。（C大调没有升号，主音C）\n大调意义上，调号中倒数第二个降号是主音。例如调号中有♭B,♭E,♭A,♭D，主音就是♭A。（C大调没有降号，主音C，F大调有一个降号，♭B，主音是F）\n然后可以根据关系大小调推出相应的关系小调。\n音程的协和与不协和 完全协和音程：P1(纯一度),P5,P8\n不完全协和音程：M3（大三度）,m3（小三度）,M6,m6\n不协和音程：各种二度、七度、四度（有时四度是协和的），所有的增、减音程。\n旋律的写作 对于初学者给出了如下建议\n以主三和弦的成分开始（即\\(\\hat{1},\\hat{3},\\hat{5}\\)音），用\\(\\hat{2}-\\hat{1}\\)或\\(\\hat{7}-\\hat{1}\\)结束。这也称为旋律终止。 旋律的音区限制在10度以内，尽量保持基本音域在6度。 旋律进行主要是级进，有时可以小跳（三度）或大跳（四度及以上）。 不要含有太多跳进，最好跳进也不要超过小六度。以三度跳进为主。 不用不协和的跳进，如减四度。和声小调中的\\(\\hat{6}-\\hat{7}\\)是增二度，避免出现。 导音必须上行到主音，除非是\\(\\hat{1}-\\hat{7}-\\hat{6}-\\hat{5}\\)的一部分。 跳进后最好反向进行。 可以连用两个小跳，第二个小跳后变向。 避免反复音与重复音型，或模进（如1-2-3,2-3-4,3-4-5），显得无趣。如果要用应控制次数，最多一次。 旋律应当有拱形，缓慢的抬升到高点，再折返到起点。 关于调性是否有色彩 这不在本书的讨论范围内，但是根据资料搜索，十二平均律使得大调之间以及小调之间的差异被抹除了。(大小调之间（和声小调）由于其和弦性质不同，存在色彩差异。)可以说各大调之间和各小调之间的色彩没有差异。但是乐器可能在各个频率发出的音色是不同的，这在某种情况下确实导致了听感的不同。另外作曲家选择调性时，通常也会考虑到乐器在某个调演奏是否方便，或者歌手的音域是否能够较为轻松的达到。\n音级的别名 \\(\\hat{1}\\)主音，\\(\\hat{2}\\)上主音，\\(\\hat{1}\\)中音，\\(\\hat{4}\\)下属音，\\(\\hat{5}\\)属音，\\(\\hat{6}\\)下中音，\\(\\hat{7}\\)导音，\n拍号 对于简单拍号，\n上方数字 含义 2 每小节两拍 3 每小节三拍 4 每小节四拍 下方数字 含义 2 以二分音符为一拍 4 以四分音符为一拍 8 以八分音符为一拍 以此类推 当我们要用带附点的音符作为一拍时，我们就引入了复拍子\n上方数字 含义 6 每小节两个附点拍 9 每小节三个附点拍 12 每小节四个附点拍 下方数字 含义 2 以三个二分音符为一拍（也就是带附点的全音符） 4 以三个四分音符为一拍（也就是带附点的二分音符） 8 以三个八分音符为一拍（也就是带附点的四分音符） 以此类推 注意到都是三倍关系\n非对称节拍 如果小节中的拍数（上方数字）既不是二的倍数（简单拍子），也不是三的倍数（复拍子），或者小节中的拍数不在上面给出的表中，则可能是非对称节拍。\\({}^5_8\\)可能是3+2，也有可能是2+3，而\\({}^{10}_4\\)经常会是2+3+3+2。注意，有些时候\\({}^9_8\\)拍可能也不是复拍子，而是由2+3+2+2组合而来，看作曲家的标注决定。\n切分 音乐上的重音出现在节奏上非强拍或拍子的弱势部位，称之为切分。\n这里，音乐上的重音，根据我的理解，举个例子，比如使用了重音记号，或者其他让你觉得这里很重的奏法记号。也有可能是乐器在这里突然一起发声。这些叫做音乐上的重音，而节拍上的重音就是指例如四四拍的强、弱、次强、弱。强拍是重音，当然如果把强拍分为两个八分音符，则第一个八分音符是重音，第二个的不是。切分就是在弱势部位放了音乐上的重音。\n三对二 举个例子，四三拍的音乐中，音乐重音是每两拍一个，也就是说，拍子的重音是强、弱、弱、强、弱、弱，强、弱、弱；而音乐重音是强、弱、强、弱、强、弱、强、弱、强。这样的交错形式叫做三对二。\n对位法部分 第一类对位法 规则：\n两声部间只允许P5、P8、M3、m3、M6、m6、P1。不允许P4。 反向进行最具有独立性。平行进行削弱独立性。同向进行能使对位更有效果。为了能在平行进行中尽量多地保持独立性和能动性，可以使用3、6度平行，但不能平行进行超过三次。 两个声部之间由纯音程进行到另一种纯音程是禁止的，例如纯五到纯八。也不能从一个完全协和音程平行进行到同一种完全协和音程。同样也不能用同向进行去处置完全协和音程。 不能同向进行到纯音程，进入到纯音程一般采取反向进行。有一种情况除外：上方声部级进时，可以同向进行到纯音程. 为了保持旋律平滑，避免两个声部同时进行跳进。 对位的开始与结束都是在\\(\\hat{1}\\)上。固定旋律是下方声部时，可以从\\(\\hat{5}\\)开始。 小调中，使用自然小调。只在最后升高\\(\\hat{7}\\)创建导音，如果前面有\\(\\hat{6}\\)也要升高。 指南\n对位声部尽可能级进，偶尔有跳进以增加趣味性。跳进后反向级进。 尽可能多用反向进行。 第二类对位法 规则\n强拍必须是协和音程。 避免下列情况的平行纯音程： 连续的两个强拍之间。 弱拍和强拍之间。 从弱拍到强拍的进行要避免同向进入到纯音程（定向性进行）。 唯一允许的不协和音是弱拍经过音（不协和音必须在两个强拍间通过级进的方式填补旋律三度的空间）。 对位声部在CF（固定旋律）下方时必须从\\(\\hat{1}\\)开始。在上方时可以从\\(\\hat{1},\\hat{3},\\hat{5}\\)开始。可以用二分休止符开始。倒数第二小节可以有一或两个音，最后一小节必须有一个全音。 同第一类对位法规则7。 指南\n尽可能多结合运用不协和经过音。 运用和弦跳进平衡不协和经过音。 大跳安排在小节内，不要出现在小节间。 弱拍上的协和音程\n只有一种方式构建协和的级进运动：\\(\\hat{5}-\\hat{6}\\)或\\(\\hat{6}-\\hat{5}\\)。称为5-6技术。\n和声学部分 三和弦概论 三和弦分为四种：\n大三和弦：大三度+小三度 小三和弦：小三度+大三度 减三和弦：小三度+小三度 增三和弦：大三度+大三度 大小三和弦都是协和的。增减三和弦都是不协和的。\n共性写作时期的音乐中，只有大三和弦、小三和弦与减三和弦用作和声的单元。增三和弦并不具有独立的音响性，但它是对位旋律线汇聚的结果。其功能可见增六和弦部分。\n三和弦的转位\n根音是最低音称为原位；三音是最低音称为第一转位，数字低音为\\({}_3^6\\)或\\({}^6\\)；五音是最低音称为第二转位，数字低音为\\({}_4^6\\)。其稳定性依次递减。\n数字低音中的符号\n首先是数字，数字几就代表在根音上方几度有音，这个几度并没有明显的区分出音程的性质，它指的是在调内的音程。\n其次是数字旁边的符号：\n♭ 代表该数字对应的音临时降低。其指的不是把某个音变成带♭号的音，而是指调内的这个音降低半音。 # 代表该数字对应的音临时升高。同上。 /、+ 代表升高一个半音。 ♮ 代表还原一个音。而且并不是还原成调内的音，而是还原成白键上的音。 - 代表某个音延长或者进行。 自然大调中的三和弦性质\n如下：I、ii、iii、IV、V、vi、vii°\n和声小调中三和弦的性质\n如下：i、ii°、III、iv、V、VI、vii°\n偶尔能见到IV,v,VII，不过并不是和声小调中的。\n三和弦的重复音\n四个声部显然要重复三和弦中的某个音，最常重复的是根音。其他规则见后。\n流行中的表示\n性质\nC大三和弦：C C小三和弦：c、C- C减三和弦：C° C增三和弦：C+ 转位\n如C的第一转位C/E，C°的第一转位C°/♭E。前面写和弦性质，后面写低音。\n七和弦概论 七和弦都是不协和的。\n七和弦分类\n大七和弦：大三和弦+大七度 大-小七和弦：大+小 小七和弦：小+小 半-减七和弦：减+小 减七和弦：减+减 其中大-小七和弦通常称为属七和弦，因为它通常出现在属音上。\n七和弦转位\n根音为最低音，第一转位，\\({}^7\\);根音为三音，第二转位，\\({}_5^6\\);根音为五音，第二转位，\\({}_3^4\\);根音为七音，第三转位，\\({}_2^4\\)或\\({}^2\\);\n大调中的三和弦的性质\n如下：I\\({}^7\\)大七，ii\\({}^7\\)小七，iii\\({}^7\\)小七，IV\\({}^7\\)大七，V\\({}^7\\)属七，vi\\({}^7\\)小七，vii\\({}^{\\phi7}\\)半减七。\n和声小调中的三和弦的性质\n如下：i\\({}^7\\)小七，ii\\({}^{\\phi7}\\)半减七，III\\({}^7\\)大七，iv\\({}^7\\)小七，V\\({}^7\\)属七，VI\\({}^7\\)大七，vii°\\({}^7\\)减七。\n流行中的表示\n性质\nC大小七和弦：C7 C大七和弦：CM7、C\\(\\Delta\\) 7 C小七和弦：cm7、c7、c-7，Cm7 C半减七和弦：C7dim5,C\\(^{\\phi}\\) 7 C减七和弦：C°7 转位\n类似于三和弦。\nT-D-T进行 即I-V-I的和声进行，它是整个调性和声的基础。有时导和弦可以代替V。\nT-PD-D-T进行与乐句模式 主-预属-属-主。不可反向。这是二级分析意义上的。\n当预属和弦的低音是以级进接入属时，高音声部要反向进行。\n小调中，属功能中的导音要从上方级进。从下方会导致增二度。\n一个乐句中一般要包含T-PD-D-T或T-D-T以形成正格终止，T-PD-D或T-D形成半终止。其中主到预属的长度通常远远长于预属到属。而属持续的时间通常也要长于预属。有时可以用大量的和弦装饰扩展来延长主和属。\n有时会在主和弦中内嵌T-PD-D-T来扩展主和弦，这也称为嵌入乐句模式（EPMs）。为了防止听众误以为是结构上的、二级分析意义上的，需要弱化终止。例如将V7的七音放到根音位置，I使用第一转位。\nI-ii、IV-V、ii6-V中两个外声部反向进行。\n终止式 正格终止 原位的属和弦到原位的主和弦，叫正格终止，或叫完全终止，标注为AC。\n完全正格终止，PAC：高音声部是\\(\\hat{2}-\\hat{1}\\)或\\(\\hat{7}-\\hat{8}\\)，低音是\\(\\hat{5}-\\hat{1}\\)。\n不完全正格终止，IAC：如果高音声部结束在\\(\\hat{5},\\hat{3}\\)。\n对位终止，IAC的一种特定类型：低音不是\\(\\hat{5}-\\hat{1}\\)的IAC。\n皮卡迪三度：小调中结束全曲的主和弦不是小三和弦，而是使用升高三音的大三和弦。此风格被称作皮卡迪三度。\n半终止 结束在原位属和弦上的终止，标注为HC。\n弗里吉亚终止 这是一种特殊的半终止。由下属六和弦进行到原位属三和弦。通常小调更有效果。标注为PHRY。低音进行为\\(\\hat{6}-\\hat{5}\\)。\n巴洛克时期的作曲家都倾向于用其结束多乐章作品中的慢乐章，给听众留下一种强烈的预感，主和弦将在下一乐章的开始出现。\n规避终止 防止在主和弦的扩展中出现较强的终止，或者阻止听众对强烈终止的预期。常常将V-I的正格终止改为V2-I6等。\n变格终止 IV-I的终止。通常出现在教堂音乐中，又叫阿门终止。比正格终止弱得多，前面通常已经出现了一个正格终止。\n对位终止 使用V或I的转位或同时使用，所成的终止式叫对位终止。有时用到vii°6参与终止。一般会用在EPMs中。\n规避终止 V进行到vi。再之后回到预属或者主，再之后接正格终止。\n可以留下悬念以及对主和弦的期待。\n声部进行概论 合唱风格 女高音、女中音、男高音、男低音（SATB）\n使用四行五线谱（开放总谱）、或者使用两行五线谱（缩编谱）中，男低男高在低音谱表，女中女高在高音谱表的风格。\n注意缩编谱中，S、T符干始终向上，另外两个始终向下。\n键盘风格 SAT三声部在高音谱表，B在低音谱表。S符干向上，AT符干向下。\n声部进行规则 解决趋向音（如导音与和弦的不协和音）要用级进。导音在内声部中不一定要上行解决，可以下到\\(\\hat{5}\\)解决。和弦的七音在V\\({}^7\\)中总是下行解决。 不要有平行进行的同度、五度、八度。也不要在这三个音程中反向进行。 不要重复趋向音。如导音、不协和音、半音变音。 上方三声部，两个相邻的声部间不要超过八度。最下方两个声部可以超过八度。 不要四部同向。 声部进行的建议 一般可以保留两个和弦的共同音 上方三个声部的进行主要是二度、三度；大跳后要反向级进。 避免增音程跳进。可以跳进到减音程，随后要反向级进。 上方任意两个声部同时出现大于三度的跳进，有可能会出现问题。尽量使用转位音高。 避免出现声部交叉，如男高比女中高。避免出现声部重叠，如男高音走到了女中音前一个音的上方。 高音声部与低音声部间避免八度与五度的同向进行，除非高音声部是级进进行（称为定向八度与五度）。 总体上讲，用完整的和弦。有时可以省略五音。 通常重复根音。为了声部进行正确也可以重复其他音。重复五音比三音好。但是绝对不能重复导音。 先写两个外声部。 上声部的运行与低音成反向。高音声部基本级进。 和声、节奏、旋律、节拍的互动 和声变换节奏 变换到一个新的和声上，会产生一个重音。最好在重拍上切换和弦。避免切分的和声节奏。\n但在四三拍上经常遇到在第3拍上切换和声，有助于强化三拍子。切分的和声节奏在四三拍的终止式中第2拍为属和弦并持续到第3拍时是允许的。\n装饰和弦与和声的二级分析 旋律中会有装饰音，为装饰音配和弦，这个和弦不具有功能，只是作为原和声的扩展。\n和声的一级分析就是将和弦标注出来。而二级分析就是区分重要的、功能性的和声和装饰的和声。\n结构性和声与从属性和声 结构性和声\n是进行性 具有和声功能（主、属、下属） 通常在强拍 通常是原位 是和声序进的组成成分 第二等级分析中保留罗马数字 从属性和声\n是延伸性 具有旋律功能 通常在弱拍 通常是转位 是对位进行的组成部分 第二等级分析中标注为装饰音 主和弦 主三和弦(I) 功能\n主功能，一般不用做装饰。\n主六和弦(I6) 功能\n主功能（较少） 作为低音的跳进和弦：I-I6-V，扩展I，低音由五度变成两个三度。 作为经过和弦：ii-I6-ii6，扩展ii。 主四六和弦(I46) 功能\n主功能（较少，不和谐），属功能（终止四六和弦时）。 作为弱位置上的持续四六和弦：V-I46-V，扩展V。其中属和弦的低音可以保持住，只改动三音五音。在一级分析中记为I\\({}_4^6\\)。二级分析中记为V-Ped\\({}^6_4\\)-V，或者V\\({}^{5-6-5}_{3-4-3}\\) 作为弱位置上的经过四六和弦：IV-i46-IV6，扩展IV。二级分析中记为P\\({}^6_4\\) 作为弱位置上的琶音四六和弦：I-I46-I6下行，扩展I。二级分析中记为Arp\\({}^6_4\\) 作为强位置上的终止四六和弦：I46-V-I，成为正格终止。也能I46-V成为半终止。二级分析记为V\\({}^{6-5}_{4-3}\\) 准备\n准备终止四六和弦的两种方式：\n用共同音做准备。I46前面是I(共同音为\\(\\hat{1}、\\hat{3}\\))或者IV（共同音是\\(\\hat{1}\\)）。 用级进准备。I46前面是预属和声。通常表现为ii6-I46-V-I。 解决\n终止四六和弦解决总是表现为级进下行到V。\n其他\n终止四六和弦在V7前，其进行为\\(\\hat{8}-\\hat{7},\\hat{6}-\\hat{5},\\hat{4}-\\hat{3}\\) 终止四六和弦可以参与到规避终止中，例如I46-V-V2-I6。 终止四六和弦绝对不会接在属功能之后。这会削弱其效果。 终止四六和弦出现在节奏强拍上。（部分书籍会要求不能比后面接的V弱，且不能比后面接的V时间短） 四六和弦重复低音。 四六和弦的进出都是共同音或者级进。 属和弦 属三和弦(V) 功能\n属功能，一般不用做装饰。\n解决\n解决到主三和弦。\n\\(\\hat{7}\\)到\\(\\hat{1}\\)，\\(\\hat{2}\\)到\\(\\hat{1}\\)或\\(\\hat{3}\\)，\\(\\hat{5}\\)到\\(\\hat{1}\\)\n属七和弦（V7） 功能\n属功能，一般不用做装饰。\n准备\n不协和音需要准备，有多种方式，级进的准备是首选的方式。\n解决\n不协和音只有一种解决的方式：三音出现在高音声部时上行，七音总是下行。\n由于三音和七音构成三全音，当为减五度时解决到三度，为增四度时解决到六度。除非选择不解决内部的导音。\n一般来说，完整的属七解决到不完整的主三和弦，不完整的属七解决到完整的主三和弦。也有完整到完整的情况，即内声部的导音进行到\\(\\hat{5}\\)。\n转位的解决类似。\n其他\nV可以进行到V7，但是不能反向。\n属六和弦(V6) 功能\n属功能（较少） 作为低音的跳进和弦：V-V6-I，扩展V，低音由四度变成三度与二度。 作为低音的邻音和弦：I-V6-I，扩展I，低音进行为\\(\\hat{1}-\\hat{7}-\\hat{1}\\)。通常\\(\\hat{5}\\)在高音声部。 作为不完整邻音和弦：I6-V6-I，扩展I，由下行三度变为下行四度再上行二度。 属四六和弦(V46) 功能\n属功能（较少） 作为弱位置上的经过和弦：I-V46-I6，扩展I。二级分析中可以标记为P\\({}^6_4\\) 作为弱位置上的琶音四六和弦：V-V46-V6下行，扩展V。二级分析中记为Arp\\({}^6_4\\) 其他\n四六和弦重复低音。 四六和弦的进出都是共同音或者级进。 属五六和弦(V56) 功能\n属功能（较少）。 作为邻音和弦：I-V56-I，扩展I。 跟随在V或者V6之后，扩展V，随后解决到I。 属三四和弦（V34） 功能\n属功能（较少）。 作为邻音和弦：I-V34-I，扩展I。 作为经过和弦：I-V34-I6，扩展I。 属二和弦（V2） 功能\n属功能（较少）。 作为不完整邻音和弦：I-V2-I6，扩展I，低音由上行3度变为上行4度再下行2度。 作为邻音和弦：I6-V2-I6，扩展I。 属七和弦转位的注意事项 解决与准备同原位和弦。 V7转位必须作为完整的形式出现。 V7转位往往在弱拍，通常连接到强拍上较稳定的主三和弦。 这些修饰和弦可以连用。 返回相关的属和弦 延伸了前面的主和弦却没有解决到主和弦。例如I-V-vi（不作为规避终止时），I-V-ii\n下属和弦 下属和弦经常被选作预属和弦，因为I-IV的进行是五度下行，是调性和声中最强劲的原位进行。\n下属三和弦（IV或iv） 功能\n预属功能。 作为邻音和弦：I6-IV-I6，扩展I。（较少） 其他\n进行到属和弦时注意低音和其他声部反向。 最好重复根音。 下属六和弦(IV6或iv6) 功能\n预属功能。（较少） 作为低音琶音和弦：I-IV6-I6，扩展I，由下行六度变为三度和四度。 作为经过音和弦：V-IV6-V6，扩展V，由三度变为两个二度。注意小调中要升高\\(\\hat{6}\\)以防止增二度。上方声部要与低音反向，防止平行五八。 进行到V形成弗里吉亚终止。 下属四六和弦(IV46或iv46) 功能\n预属功能。（较少） 作为弱位置上的持续四六和弦：I-IV46-I，扩展I。其中主和弦的低音可以保持住，只改动三音五音。在一级分析中记为IV\\({}_4^6\\)。二级分析中记为I-Ped\\({}^6_4\\)-I，或者I\\({}^{5-6-5}_{3-4-3}\\) 作为弱位置上的琶音四六和弦：IV-IV46-IV6下行，扩展IV。二级分析中记为Arp\\({}^6_4\\) 其他\n四六和弦重复低音。 四六和弦的进出都是共同音或者级进。 下属七和弦(IV7或iv7) 不如ii7常见，但也颇具色彩\n功能\n预属功能。 声部进行\n见后\n其他\n为了避免平行五度，通常不接V，而接V7，或者终止四六和弦。如果省略五音重复根音可以借V，既避免平行五度又准备了七音。\n下属五六和弦(IV56或iv56) 功能\n预属功能 声部进行\n见后\n其他\n通常后面接V56。\n导和弦 导减三和弦（vii°） 远不如第一转位常用，因为它有三全音，而第一转位会削弱三全音。\n导减六和弦（vii°6） 功能\n代替属和弦作为属功能（较少）。 作为低音中的经过音和弦：I-vii°6-I6，扩展I，由三度变为两个二度。ii不适合做这个经过和弦的原因是，ii是一个更强势的和声。 作为低音中的邻音和弦：I-vii°6-I，扩展I。 解决\n如果有可能，解决三全音。除非：\n走向完整的主和弦。 没有涉及低音。尤其是三全音表现为增四度。 低音与高音是平行十度。 其他\n不要重复导音。重叠三音(\\(\\hat{2}\\))时走向\\(\\hat{1}\\)或\\(\\hat{3}\\)，有时也可以重叠五音。 导减七和弦(vii°7) 功能\n代替属和弦作为属功能。（较少） 像V56，作为邻音和弦：I-vii°7-I，扩展I。 准备\n七音（\\(\\hat{6}\\)）用级进进入或共同音进入。 解决\n\\(\\hat{6}-\\hat{5}\\) \\(\\hat{4}-\\hat{3}\\) \\(\\hat{2}-\\hat{3}\\)（通常，尽管会重复主和弦的三音），有时也能\\(\\hat{2}-\\hat{1}\\) \\(\\hat{7}-\\hat{1}\\) 转位的准备与解决类似。\n导减五六和弦(vii°56) 功能\n属功能（较少）。 像V34，作为经过和弦：I-vii°56-I6，扩展I。 导减三四和弦(vii°34) 功能\n属功能（较少）。 像V2，作为经过和弦：V-vii°34-I6，扩展V。 像V2，作为邻音和弦：I6-vii°34-I6，扩展I。 导减二和弦(vii°2) 这个和弦比较罕见。\n功能\n属功能（较少）。 作为原位V的邻音和弦：V-vii°2-V，扩展V。 导半减七和弦(viiø7) 在大调中出现的概率要远低于在小调中出现导减七和弦的概率。并且大多以原位出现，很少有转位。\n功能\n作为邻音和弦：I-viiø7-I，扩展I。 作为和弦跳进：V-viiø7-V6，扩展V。 上主音和弦 上主音和弦是最常见的预属和弦。因为：\nii-V是五度下行，是调性和声中最强劲的原位进行。 形成对比。大调中ii是小三和弦，I与V是大三和弦；小调中ii°是减三和弦，i是小三和弦，而V是大三和弦。 ii-V-I的序进中高音声部时常为\\(\\hat{2}-\\hat{7}-\\hat{1}\\)，力度比IV-V-I的\\(\\hat{1}-\\hat{7}-\\hat{1}\\)弱。也是围绕\\(\\hat{1}\\)的双重邻音的旋律性进行，使得终止尤为强烈。 上主音小三和弦(ii) 即大调中的形式。\n功能\n预属功能。一般不用作装饰。\n其他\n最好重复根音。\n上主音减三和弦（ii°） 即小调中的形式。建议不用，因为存在三全音。更常用的是第一转位的形式，可以削弱三全音。\n上主音减六和弦(ii°6) 即小调中的形式。\n功能\n预属功能。一般不用作装饰。\n其他\n最好重复低音。\n上主音七和弦(ii°7或iiø7) 功能\n预属功能 声部进行\n见后\n上主音五六和弦(ii°56或iiø56) 比其他转位常见得多\n功能\n预属功能 声部进行\n见后\n下中音和弦 下中音三和弦（vi或VI） 功能\n作为琶音和弦：I-vi-IV，扩展I，或者是准备IV或ii。二级分析中视为从属于T。 作为五度圈下行中的和弦：VI-ii-V-I五度下行。 取代主和弦，作为规避终止：在V-I的终止中替代I，形成上行二度的V-vi，这是一种虚假运动。二级分析中写作“T”。其后跟着预属和弦或者主和弦，然后跟着正格终止。 预属功能。（较少） 属和弦修饰下中音和弦：I-V-vi的进行中，vi会使得V黯然失色，尤其是vi强拍而V弱拍时。 主和弦修饰下中音和弦：类似于上条，尤其是vi强拍而I弱拍。 貌似下中音和弦：不具有结构性意义而是声部进行的附属品。 声部进行\n按照之前的共同规则即可。\n规避终止中，高音宜采用\\(\\hat{2}-\\hat{1}\\)或\\(\\hat{7}-\\hat{1}\\)。注意小调中\\(\\hat{7}-\\hat{6}\\)会形成增二度，从而VI和弦必须重复三音。\n中音和弦 中音三和弦(iii或III) 功能\n作为琶音和弦：I-iii-V或I-iii-IV-V，扩展I。 五度下行中的中音和弦：iii-vi-ii-V-I。 声部进行\n进出iii时尽量将上访声部与低音反向。 iii用于支撑\\(\\hat{7}\\)时，高音采用\\(\\hat{1}-\\hat{7}-\\hat{6}\\)的旋律线条。 其他规则同一般规则。 其他\n小调中使用比大调多 中音和弦的准备：V/III-III，会在小调中出现VII和弦。并且更多时候用的是V6/III。 非属七和弦概论 有些七和弦不具备属音或导音七和弦的属功能性质，被归类到非属七和弦。它们用途宽广，富有色彩，易于实施。\n声部写作注意事项\n必须准备和弦的七音，同音（首选）或者高半音的方式接入 必须解决七音，级进下行到下一个和弦 转位和弦必须是完整的。原位和弦可以省略五音重复根音来避免平行五八。 装饰音 分为两类，弱拍装饰音和强拍装饰音。\n弱拍装饰音有：和弦大跳进、经过音、邻音、先现音等。还将进一步细化为协和的（和弦大跳进）与不协和的（大多数经过音与邻音）。协和的无须准备和解决。不协和的几乎总是出现在协和音之间并且是级进运动。\n强拍装饰音有：强经过音、强邻音、延留音、持续音和倚音等。他们是音乐中最富有情感的元素。\n琶音(ARP)\n如果连续出现了三个或以上以上的和弦音(CS)，那么可以称为琶音。\n经过音(P、PT)\n弥补和弦的音程。通常是三度。\n邻音(N)、上邻音(UN)、下邻音(LN)、不完整邻音(IN)、双重邻音(DN)\n邻音指从和弦音上行或下行二度后又回到原来的音。\n不完整邻音指跳进到与和弦音相邻的音，然后级进解决到和弦音。\n双重邻音指同时出现了上邻音和下邻音再解决到和弦音。\n和弦大跳(CL)\n从一个和弦音跳到另一个和弦音。允许不协和跳进，如三全音。\n强经过音(APT)\n弱拍强位上的经过音。通常发生在下行线条中。7-6、4-3最常用。\n半音经过音(CPT)\n用半音弥补两个自然音中的间隙。\n强邻音(AN)\n强拍上的邻音。\n半音邻音(CN)\n含一个或数个非自然音高。\n倚音(APP)、亦或不完整强邻音\n未准备的不协和音出现在强拍上，实质上是不完整的强邻音。由级进解决，通常与跳进方向相反。最常用的是4-3、9-8\n延留音(SUS)\n最重要的强拍装饰音，其中短暂地延缓了级进式的旋律下行，并在该线条继续之前构成一个不协和音 展开的三阶段 准备：弱拍和弦音 延留：延留准备音持续到强拍上的和弦变换。它此时变成了和弦外音 解决：延留音通过向下级进到弱拍上的和弦音 上声部的常见类型：9-8，7-6，4-3 低音的常见类型：2-3（9-10） 先现音(ANT)\n不协和音，即将出现的和弦的结构音提前进入。\n持续音(PED)\n大多数是在低音中，具有主功能或属功能；表面的和声序进往往是在其上方展开。\n调性音乐中的三种基本根音运动 五度下行(D5)。是调性音乐中最强劲的原位进行。如V-I 二度上行(A2)。如IV-V。 三度下行(D3)。如I-vi。 低音级进下行 例如低音为\\(\\hat{1}-\\hat{7}-\\hat{6}-\\hat{5}\\)，则可以配I-V6-IV6-V。小调（旋律小调）则是i-v6-iv6-V。\n级进下行低音经常有在作品中不断重复，形成一个坚实的和声基础。这样的重复叫做固定音型。以此为基础的作品叫固定低音或恰空。\n隐伏和声 通过复合旋律的分析可以分析出三和弦或者七和弦。但少部分情况仍然不完整，这就需要推断出确实的和弦音。\n和声模进 书上的定义不是很直白，简单说就是和弦级数（根音级数）按某一特定规律变化的进行。例如先下降五级在上升四级（也可以理解为连续下降五级），变成I-IV-vii°-III-vi-ii-V-I。\n分为两类，延伸模进（扩展一种功能，如T-T），离调模进（从一种功能到另一种功能，如T-PD）。总的来讲，模进是在主和弦扩展之后并在PD与D功能之前出现。\n下行二度(D2)模进 D2(-5/+4)模进，即先下行五度在上行四度，称为下行二度模进。毫无疑问也可以先上行四度再下行五度。\nI-IV-vii°-III-vi-ii-V-I中，间隔的两个和弦会有声部进行问题，而插入的那一个和弦正好解决了这个问题。称作声部进行和弦。另外IV-vii和vi-ii的进行中根音会出现三全音跳进，但在模进中是可以接受且必须的。\n在这个模进中，出现原位的减和弦是允许的。\n下行二度模进转位\n原位模进的低音有些跳进。通常会将模进中的每第二个和弦使用第一转位。\n下行三度(D3)模进 D3(-4/+2)模进与D2模进形成鲜明对比。\n同样有声部进行和弦避免平行问题。\n大调中I-V-vi-iii-IV-vii°-I。小调中i-v-VI-III-iv-V7-i。这是书中给出的例子，关于为什么会有倒数第二个属和弦，书中没给出解释，我认为是为了保持乐句模式。注意小调中第二个是小和弦，防止出现增二度。\n帕赫贝尔的卡农的形式是：I-V-vi-iii-IV-I-ii56-V-I。可以认为三度下行只有I-V-vi-iii-IV-I，后面接终止式以保持乐句模式。\n下行三度模进转位\n同样给每第二个和弦使用第一转位来平滑低音的运动。也称之为下行5-6模进，因为往往每第一个和弦每第二个和弦之间，有一个声部保持稳定，而低音下行二度，形成了5度-6度的关系。它的转位比原位更常用。\n上行二度(A2)模进 A2(+5/-4)比D2罕见，它几乎没有目标导向。常见的只发生在原位，I-V-ii-vi-iii-。然后通常接到预属。小调中为i-v-ii°-Vi-III-。注意小v。\n另一种A2(-3/+4)，同样也是引导向预属功能。通常每第二个和弦使用第一转为，也称作上行5-6模进。\n写和声模进的指南 确保前三个和弦的声部进行是正确的，后面的都是复制，不会导致新的问题。 是种都是用低音与高音声部开始；尽量使两个外声部之间成反向级进。 模句中的两个外声部之间至少要有一个不完全协和的音程。 在乐句模式中写作模进 比如要在四小节的乐句中确立主和弦，用D2模进，并且PAC结束。\n可以采用很快的节奏来处理模进和弦。 可以只采用模进的一部分。可以不用前几个，也可以提前结束模进。 加长乐句。 自然音七和弦的模进 可以将自然七音添加到每一个D2(-5/+4)模进中，也可以隔一个和弦添加一个七音。两个都可以使每个七音都有共同音准备并级进下行解决。前者叫带连锁七和弦的D2(-5/+4)\n写作指南\n设计好前三个和弦的链接。注意每个七音都要准备和解决。 交替出现的七和弦可以是完整的。 连锁七和弦中，相邻的两个七和弦一个是完整的一个是不完整的。 转位\n第一转位、第三转位较为常见。转位一定要是完整的和弦。\n平行第一转位三和弦 写作一连串平行运动的和弦，只有采用三和弦的第一转位一种方式。用于延长和声或者和声功能之间的离调。\n四声部写作时，三个声部平行运动，一个内声部重复高音、重复低音、重复高音、重复低音进行（也可以从低音开始）。\n副属和弦 概论 作为副属功能的和弦，必须表现得像个属和弦。也就是，必须是大三和弦或是属七和弦，并且通常要进行到其主和弦上。\n推断副属和弦，例如c小调中V的副属和弦。首先V是G大三和弦，就确定G大和弦（或者说G大调）的副属和弦，G大和弦的副属和弦是D大和弦。标注为V的V，即V/V。在预属和属前面增加其副属和弦是常见的。小调中在III前面加副属也常见。\n注意减和弦不能有副属和弦。副属和弦在二级分析中标注为其主和弦相同的功能。\n转位\n可以通过转位平滑低音线条。\n声部进行\n不能重复导音和七音。 导音在外声部要向上级进解决。 七音总是向下解决。 副导和弦 由vii°6和vii°7（以及少见的viiø7）是属和弦的替代品。他们也能参与到副属和弦中，作为副导和弦。比如说vii°6/ii。\n副属和弦运用在乐句中 没有新的规则。不过副属和弦布局在弱位置上是很常见的，因为含有导音，参与的运动是通往强位置的目标。\n带副属和弦的模进 D2(-5/+4)\n显然，这样有五度下行的结构，是可以运用副属和弦的。并且可以交替使用副属和弦，也可以连锁使用。\nD3(-4/+2)\n将每第二个和弦换为下一个和弦的副属和弦，从D3(-4/+2)变为D3(+3/-5)。可以用转位来平滑低音。也可以用副导七和弦变为D3(-4/+1)。\nA2(-3/+4)\n比A2(+5/-4)结合副属和弦常见。\n每第二个和弦采用第一转位时，只要低音升高半音就可以构建副属和弦。\n离调与转调 扩展离调 用副属和弦就是一种离调。副属和弦解决到其主和弦的过程是可以扩展的，使用那个调上的和弦进行扩展。在二级分析中这些都是该调主和弦的功能。罗马数字分析中，可以将离调的部分写作该调的和弦级数，再将离调的部分括号括起来标注临时主和弦。\n转调 长久的离调，其能占据作品的一整个段落，被称之为转调。虽然没有一条明确的分界线。但是：\n离调通常出现在乐句之中。 转调含有新调中强烈的终止式，并且新调在终止式之后还在延续。 近关系调 总体上讲，调性音乐中转调是从本调进行到任何其近关系调。\n有两种方式确定近关系调：\n本调上各音级上构筑自然音三和弦。所有的协和三和弦（大三和弦和小三和弦）都构成了主调的近关系调。 调号与原调号只差一个升降号的大调和小调。 虽然可以转到任何大小自然调，但是最常见的是（有先后）：\n大调转到V、vi和iii 小调转到III，v和VI 转调分析 有三种重要信息：\n新调在原调中的位置 新调在作品或作品段落中整体和声序进中的功能 新调与原调瞬间融合的点位 采用如下方式分析转调：\n在原调中开始处写罗马数字 一直分析和弦，直到罗马数字因调性变化而变得复杂或没有意义 为新调标出罗马数字，从终止式往回写，直到出现两个调中都用简单的罗马数字标记的第一个和弦。即中介和弦。 中介和弦转调 在理解中这和共同和弦转调是一个意思。\n中介和弦在两个调中都是自然音和弦。终止四六和弦不是优选，因为它们在新调中是强烈终止的一部分。中介和弦通常在新调中是PD功能的。\n写作指南\n新调和原调的两个调域的持续时间段是均衡的。中介和弦配置在转调乐句的中间位置，各调中都至少要用数个和弦。 找出两个调中的所有中介和弦。最佳的中介和弦应该能作为新调的PD和弦。为了避免刺耳音响，不能用新调的属和弦作为中介和弦。 中介和弦之后不要立刻冲进完全正格终止。插入一段对位终止或EPM。 在新调中采用级进式高音线条进行到最强的终止，即终止四六和弦的PAC。 较大音乐语境中的转调 几乎没有什么作品开始的与结束的调不同。考虑到作品的整体性，转调从未取代过主调。调性音乐中的转调只是参与到单一的整体和声运动中。\n例如，c小调的作品在引导向属和声并返回到c小调结束前可以转调到♭E大调与f小调。这构成了一个大型序进：i-III-iv-V-i。\n在模进中转调 在和声模进中，提早放弃模进并将其和弦之一重新解释成进行到属的预属，就可以有效地进入到一个新调。\n混合调式 18世纪晚期到19世纪初期的音乐，经常会有一种半音的类型，无法说成是附属功能以及离调所派生的。事实上只是非功能的出现，来为音乐的旋律与和声外表增添色彩。\n借用平行调式和声的技术称之为混合调式，简称混合。\n皮卡迪三度也是一种混合调式，大调中使用减七和弦也属于混合调式。\n虽然平行大小调之间可以借用和声，但是一般常见的是从小调中借用和弦给大调使用。因为小调中\\(\\hat{6},\\hat{7}\\)会根据情况有两种形式。在大调中引入这样的变化音非常特别。\n变音的预属和声 涉及ii°与iv\n涉及混合调式的最常见的音级是\\(\\hat{6}\\)，因为：\n\\(\\hat{6}\\)最不可能破坏本调与调式的完整性 降低\\(\\hat{6}\\)就能产生强力的半音级进运动到属和弦 混合调式援引\\(\\hat{6}\\)为所有的PD和声增添了色彩 主三和弦外唯一能用\\(\\hat{1}\\)级音位于低音的和声协和支撑的音级就是\\(\\hat{6}\\)。因此，是5-6运动的成分。 改变了和弦性质但没有改变根音的半音变化，称之为混合旋律。\n变音的下中音和声 涉及♭VI，和上一个一样变的是\\(\\hat{6}\\)，但这次是在根音情况。这种变化根音的情况叫做混合和声。\n只将\\(\\hat{6}\\)降低会形成增三和弦，通常也要同时降低\\(\\hat{3}\\)来形成大三和弦。\n它仍是作为下中音和弦的功能：\n参与到下行琶音 参与到下行五度运动 作为预属功能至于属和弦前 虚假运动中接到属和弦后代替主和弦 由于降低的\\(\\hat{6}\\)和属和弦仅相差半音，可以用作扩展V的上邻音。 变音的主音和声 涉及i，即降低\\(\\hat{3}\\)。将大调主和弦转换成小调主和弦，但是这种并置会引发整首作品的调式问题，所以i只能用于暗示而不能用作正式的陈述。\n十九世纪，有些作曲家，如舒伯特，大量使用小调元素，使得24个大小调融入到12个大-小调中。如果一首作品中D大调和d小调的音出现的数量差不多，就只能说成是D调作品。\n变音的中音和声 涉及♭III，降低了\\(\\hat{3}\\)和\\(\\hat{7}\\)构成大三和弦。功能仍然是中音和弦的功能：\nI和V之间的，将五度划分成两个三度的和弦。 T与PD之间的过渡。 参与到下行五度运动中，尽管比ii少见许多。 作为PD，引导向V34。 其之前添加副属和弦。 作为I6的替代品，不如iii常见。 混合和声的声部进行 避免重复变音，除非变音是根音 ♭\\(\\hat{6}\\)可以做邻音和下行经过音，要由级进运动做准备并解决。并且应该保持在同一声部中。 只要引入了混合调式，就必须一直持续到抵达属功能。 半音级进式低音下行 小调中\\(\\hat{6},\\hat{7}\\)有两种形式，所以半音级进式低音下行是可能的。\n有了混合调式，就能将其引入到大调中。\n变格运动 指下属和弦、上主音和弦与下中音和弦直接进行到主和弦。二级分析中缩写为PL功能。\n混合调式与副属和弦 离调与属功能密切相关 混合调式通常出现在预属功能中 半音转调 最常见的是转到♭VI和♭III，较少到VI和III。\n半音中介和弦转调 往往半音转调的时候，两个调没有共同和弦。但是本调的关系调和新调有中介和弦。也就是说，这个中介和弦必须是本调的混合和弦。\n写作指南\n在新调中添加必要的临时符号，或者调号。 中介和弦必须总是原子混合调式。通常由很好效果的是用i来作为新调的vi或iii。 尽量构建浑然一体的音乐进行，在新调中扩展PD，可通过转位或短暂的离调。 无准备的半音转调 即直接在某个停顿后突然进入到另一个调。\n半音共同音转调 例如D大调的\\(\\hat{1}\\)和♭B大调的\\(\\hat{3}\\)是同一个音，彼此间隔三度，进行转调。从书上给的例子看，舒伯特写了两小节长度的纯D音，不含别的成分，然后再进行到新调。\n那不勒斯和弦 概论 建立在♭\\(\\hat{2}\\)上的大三和弦称为那不勒斯和弦。\n通常以第一转位出现，为♭II6，重复低音，有时也可以重复\\(\\hat{6}\\)，不能重复♭\\(\\hat{2}\\)。\n作为预属功能强力推向V。出现在小调中比大调多，在大调中是混合调式的结果，大调中同时也要降低\\(\\hat{6}\\)，并且要避免增二度进行，\\(\\hat{1}\\)-♭\\(\\hat{2}\\)，而不是\\(\\hat{3}\\)-♭\\(\\hat{2}\\)。\n通常出现在终止式中，也能用于EPM。\n♭II6-V的序进是高音声部中有♭\\(\\hat{2}$-\\)\\hat{7}\\(的进行，这个减三度是可以接受的。也可以添加\\)\\hat{1}$作为经过音，此时配置终止四六和弦或者为V配置副减导七和弦。\n扩展 低音中的和弦跳进来延长，♭II-♭II6 作品的第一分句配置在主和声上，随后上移半音级进到♭II。 加入副属和弦，小调中的VI，大调中的♭VI。 无论怎么扩展，始终都是作为预属功能。\n模进 在模进中结合那不勒斯和弦，好处是，小调时二级和弦是减和弦，不能使用副属和弦。换成那不勒斯和弦后可以使用副属和弦。\n用作中介和弦的那不勒斯和弦 转调到自然音以及半音调时，那不勒斯和弦是一个有效的中结合线。如c小调转到♭A大调，则c小调中的♭II6和♭A大调中的IV6是共同和弦。\n增六和弦 概论 书上虽然没说，但是指的不是增三和弦的第一转位，而是含有增六度的和弦。\n通常是\\(\\hat{4}\\)上的和弦，升高\\(\\hat{4}\\)，然后第一转位。（小调上）\n同大多数半音和弦一样，作为预属功能。它更多地出现在小调中\n解决到属和弦，低音♭\\(\\hat{6}\\)级进下行到\\(\\hat{5}\\)，#\\(\\hat{4}\\)上行到\\(\\hat{5}\\)。内声部重复\\(\\hat{1}\\)，并且反向运动。（书上虽然说的是降六级，但是我怀疑打错了，小调中的五六级就是半音。大调中要降六级）\n如果直接解决到V7，会出现省略式解决。#\\(\\hat{4}\\)没有上行到\\(\\hat{5}\\)，而是到\\(\\hat{4}\\)并到\\(\\hat{3}\\).\n类型 基本成分是：\n\\(\\hat{6}\\)位于低音声部（书上没说，但是大调降六级） #\\(\\hat{4}\\)位于上声部（通常是高音声部） \\(\\hat{1}\\)是重复音 意大利增六和弦\n就是只含有基本成分的增六和弦，标注为It6\n德意志增六和弦\n意大利增六和弦是重复\\(\\hat{1}\\)。德国增六和弦不重复，而是增加了一个\\(\\hat{3}\\)音，大调♭\\(\\hat{3}\\)。标注为Ger56。\n法兰西增六和弦\n不重复，而是增加\\(\\hat{2}\\)音，形成增四度。大调也是增加\\(\\hat{2}\\)。标注为Fr34。\n瑞士增六和弦\n只存在于大调，就是法国增六和弦增加的是#\\(\\hat{2}\\)，构成倍增四度。也称为瑞士倍增六和弦。标注为Sw34。\nVI与增六和弦 通常(♭)VI是进行到预属。但有时也会直接作为预属，进行到V，来利用富有戏剧性的半音运动(♭)\\(\\hat{6}-\\hat{5}\\)。由于直接用(♭)VI-V有声部问题，所以经常会将(♭)VI转化为德国增六和弦。因为它们有三个共同音。\n作为预属扩展部分的增六和弦 鉴于两个声部都具有明确的到\\(\\hat{5}\\)的目标导向，增六和弦通常也就成为了到属和弦之前的最后一个环节，紧跟着前置的iv(6)或VI。\n在极为罕见的情况下，德国增六和弦会用到\\(\\hat{4}\\)低音位置，此时构成了德国减三和弦。记作Ger7。\n增六和弦与转调 由于有两个半音趋向于\\(\\hat{5}\\)，它比一般PD更富有同向属和弦的线性驱动力。因此，当其出现在中介和弦之后尤其有助于稳固新调。\n增六和弦作为转调的中介和弦 意大利增六和弦实际上和某个调的不完整V7（缺5音）是同音异名的关系。德意志增六和弦则和某个完整的V7是同音异名关系。一般是在降二级上的调。\n从而，有时会用这个和弦去进行中介和弦转调。\n曲式学部分 动机 最出名的动机之一就是命运交响曲的开头。\n动机类型 分为两种：独立的音型和主题的构件。具体如何区分书中并没有说得太清楚，疑似也不重要。\n动机的重复 严格重复 在动机的称述之间保持同样的音高-节奏结构。\n通常相对少见，但是在作品刚开始时进行严格重复是很适合的，可以帮助听众迅速掌握动机。\n为了避免枯燥，可以进行模仿，即在一个声部首先陈述动机，然后在另外的声部中重复（通常指八度模仿，不改变动机的音级）。也可以对动机进行重配和声。\n修饰重复 常见的修饰办法有：加入装饰音、将动机进行移位等。\n移位有很多种，可以把整个动机移位，也可以把动机中的几个音移位（比如把某个音提高八度，这很有效果）。\n移位分为两种，调内移位（这会改变音程性质）和完全移位（不改变音程性质的移位，会用到非自然音）。\n两次及以上的，同度的移位成为模进。\n修饰重复意义下，模仿不限于八度，可以在任意音程内，不过五度较为常见。\n如果动机的两次重复有时间上的重叠，则称为密接和应。\n镜像（或倒影）\n即将动机以某个音为水平面，将整个动机上下镜像翻转。节奏对于旋律来说可能比音高更为重要，即使翻转了，节奏不变还是能够有较强关联。\n逆行\n将动机左右翻转，第一个音变成最后一个音，依次进行。不如镜像常见，因为会改变节奏，难以辨认关系。\n逆行倒影\n即将倒影和逆行结合，更加难以辨认关系。\n节奏变形\n前文提到节奏比音高稍微重要，变化节奏容易导致动机难以辨认。更多情况下，会对整个动机扩增时值或者缩减时值。\n展开重复 这会导致动机的重大改变，虽然不容易听出来，但是某种意义上更为重要。\n插补\n可以说是加了很多音在动机之中，从而与添加装饰音的修饰重复区分开来。\n裂变\n将动机的一部分拿出来使用。通常会使用动机的头部。\n隐含重复\n十分重要。例如可以隐含在和声的轨迹中。能从一个乐章跨越到另一个乐章。\n单音程动机 只有一个音程的动机，具有高度的可塑性。\n乐句 通常是展示一小段完整的音乐的最短单位（不是书上的定义），通常具有四小节、六小节、八小节长度。每个乐句只有一个功能性的和声进行。可以理解为只有一个终止式。\n分乐句 一个完整的乐句是由两个或更多分乐句组成的，特点是具有断句（句读）。但是有句读不能保证有分乐句，有分乐句也可以没有句读。\n复合乐句 由三个分乐句组成的乐句成为复合乐句。和乐句一样，只有一个结构性的和声进行。\n有两种类型：各分句的和声功能不同；前几个分句都是主和声，最后一个分句是PD、D、T。\n乐段 当一个结论性不强的乐句搭配一个有很强结论意味的乐句时，我们将这种组配单位称之为乐段。通常起句是半终止，结句是正格终止。\n相似乐句、对比乐句\n乐段中的两个乐句彼此间有旋律的相似性，称之为相似乐句。而旋律不同的，称之为对比乐句。\n阻碍乐段\n如果第一乐句的半终止在第二乐句的开头解决到主和弦，则称为阻碍乐段。\n延续乐段\n如果第一乐句的半终止在第二乐句中没有解决，而是延续属功能直到正格终止，则称为延续乐段。\n当然有时也会在半终止后，第二乐句中接预属功能，形成返回相关的属和弦。\n有时也会让第一乐句结束在预属和弦的正格终止上，后接属功能在第二乐句。比如第一乐句结束在ii、IV、vi上（书上没有提到和声的正格终止是什么，估计是vi-ii的终止）。\n分段式乐段\n第一乐句结束在IAC上（亦即旋律未结束在\\(\\hat{1}\\)上），而第二乐句结束在PAC上（亦即旋律结束在\\(\\hat{1}\\)上）。\n进行式乐段\n第二乐句结束在另外一个调上，称为进行式乐段。第一乐句可以是HC或IAC。\n分类与使用频率\n相似阻碍乐段（PIP，常用），对比阻碍乐段（CIP，少用），相似分段乐段（PSP，有时用），对比分段乐段（CSP，有时用），相似延续乐段（PCP，少用），对比延续乐段（CCP，有时用），相似进行乐段（PPP，常用），对比进行乐段（CPP，常用）。\n句式结构 通常由三个更小的部分组成，形成短-短-长（通常比例为1：1：2）的结构，称为句式结构。比如2小节+2小节+4小节的结构。通常是a-a\u0026rsquo;-b的结构。\n如果b中嵌套了另一个句式，比如4小节的B中嵌套了另一套a-a\u0026rsquo;-b（1+1+2），那么称为嵌套句式。\n这种句式结构可以替换乐句在乐段中使用。\n复乐段 当一个乐段的起句和结句都能在更小的层面上划分起句与结句，那么称之为复乐段。\n例如一个乐段由4+4的两个乐句组成。而一个复乐段可能更长，由8+8的两个乐句组成，而这两个乐句又可以分为4+4的部分。这个更小的乐句的终止式有很多组合，常见的有HC-HC-HC-PAC、IAC-HC-IAC-PAC等。\n至于为什么不分成两个乐段处理，即是因为只有正格终止足以结束乐段，如果划分为两个乐段可能有一个无法真正的结束。\n非对称乐段 3乐句、5乐句等单数乐句的乐段，称为非对称乐段。\n非对称乐段的各乐句都要用终止式结束，但要弱于最后的终止式。如果最后的终止太弱，都不能称为乐段，只能称为乐句组。\n构建方式：\n立刻重复起句或结句，如aab和abb。 应用新的材料，如abc。 结合上述两种，如aabbc、aabcc。 二段曲式（二部曲式） 二段曲式，说的是一部完整的作品能够解析为两个段落。二段曲式中的两个段落几乎总是标写了重复标记，因此又叫二段-重复曲式。\n虽然书上没有明说，但是这个两个段落指的应该通常是乐段。\n简单式\n当两个段落并未共享旋律材料时，称为简单式。\n分段式\n当第一段结尾的终止式是结束在主和弦上，称为分段式。\n延续式\n第一段结束游离了主和弦，紧接着的段落又延续了这个和弦，称为延续式。\n回旋式\n第二段的旋律材料在开始时与第一段不同，或者称为游离。但在之后又全部或部分的重复第一段的材料，称之为再现。这种结构叫做回旋式。\n平衡式\n可以看作是简单式或者回旋式的修改，第二段的材料不同，但是在最后终止时，采用了第一段的结尾。这称作平衡式。\n变奏曲式 延续变奏 延续变奏组曲中，主题相对简短（通常为一个乐句），留下不完整的效果是为了让每段变奏能浑然一体地接入到下一段变奏。并且往往通过（在时间上）重叠变奏来实现，一段变奏结束的主和弦同时作为下一变奏的开始。或者固定低音趋向V，而下一段变奏解决。\n延续变奏大多是用重复的乐思，称为固定音型，而不是一段抒情的曲调。固定音型为变奏的骨架，在此基础上改变音区、织体以及动机设计。\n固定音型一半出现在下方声部，并能直接作为重复的低音音型，称之为固定低音；重复和声音型，称之为恰空；既重复低音同时又重复和声音型的称之为帕萨卡利亚。通常情况下这三个术语可以互换使用。\n分段变奏 在分段变奏组曲中，主题与各变奏常常是用二段曲式（往往是回旋延续式二段曲式。）结束在本调上，因此他们是彼此分离的。\n在分段变奏组曲中，变奏之间往往会有很大的改变。\n三部曲式 三部曲式具有三部分旋律的设计（ABA或ABA\u0026rsquo;）以及三部分的调性结构（本调-对比调-本调）。回旋二段曲式虽然也有三部分旋律设计，但是调性结构只有两个部分（实际上书中给的图例说只有一个调）。\n分类 收拢性三部曲式\n假设三部曲式的三个段落各自都结束在其主和弦上，则称为收拢性三部曲式。\n分段性三部曲式\n当A段（不常见）或B段（常见）未在其主和弦上结束且这种收拢性结尾为该段调性运动不可或缺的一部分时，称之为分段性三部曲式。\n延续性三部曲式\n当AB都未结束在主和弦上，称之为延续性三部曲式。\n有时很难区分它和回旋二段曲式。要考虑B部在多大程度上依附于A部。假设没多少关联，则是三部曲式。假如主题或动机有关联且调性很少变化或不变，则二段曲式更合适。\n连接部与回头过渡 为了形成连续感，会写作过门段落。主调与新调之间的过门材料（A到B）称之为连接部。从对比掉返回主调的过门材料称之为回头过渡。\n再现的曲式：复三部曲式 在复三部曲式中，每一段都可以被分为小的二段曲式。\n书上给出的两个例子，两者都是收拢性三部曲式，小的二段曲式都是回旋二段曲式。\n返始咏叹调 是巴洛克时期最重要的三部曲式结构。给出的例子是分段性三部曲式。\n小步舞曲-三声中部曲式 ABA，A是小步舞曲，B是三声中部。\n回旋曲式 概论 可以看做是扩展的三部曲式。\n五段回旋曲式的结构为A1-B-A2-C-A3\n七段的为A1-B1-A2-C-A3-B2-A4\n其中交替循环的A1、A2、A3称为叠部。对比性材料如B、C称为插部。\n通常插部的调和原调不一样。\n古典主义晚期的五段回旋曲式的调性结构为：i-III-i-v-i。书上还给出的结构有I-V-I-i-I。\n七段回旋曲式的典型调性布局：\n大调\nI-V、i或IV-I-i、IV或vi-I-I或i-I\n小调\ni-III或v-i-iv、IV、III、VI或I-i-I-i\n尾声、连接部与回头过渡 在最后可能会出现一个新的段落，并不像是叠部，而仅仅只是用于确认本调并提供一个完美的结束。这一段称之为尾声。\n连接部与回头过渡同三部曲式。\n复回旋曲式 同三部曲式，是在回旋曲式的每一段内部嵌入二段曲式。书上的例子同样嵌入了回旋二段曲式。\n奏鸣曲式 概论 奏鸣曲式不是一套刚性规则，它是一种基本的作曲方式：\n开始的材料在主调上陈述（呈示部） 在对比调上陈述附加材料（展开部） 在主调上重述所有的材料（再现部） 奏鸣曲式的二段模式 奏鸣曲式可以看作是平衡与回旋延续式二段曲式的结合。\n呈示部与再现部根据和声的定义划分成两个部分。\n在第一调域（FTA）中，材料在主调上呈示；在第二调域（STA）中，初始呈示的材料是在对比调中（通常为大调中的V和小调中的III）。\nFTA是基于回旋二段曲式的特性，原材料在游离（展开部）之后返回（再现部），并用半终止中断。\nSTA是基于平衡二段曲式的特点，第二段（STA，往往用新的主题）在第一段（呈示部）结尾处出现，在这首作品（再现部）的结尾处返回主调。\n这就是奏鸣曲原则。\n和声布局是I(FTA)-V(STA)-HC(半终止)-I(FTA)-I(STA)。\n其中呈示部主要成分是FTA，末尾会出现STA（不在本调）。然后进入展开部，继续发展STA，直到一个半终止。之后切换到FTA开始再现部，FTA完成后要在本调上写STA。\n连接部 FTA到STA中往往会有一小段，称之为连接部（Tr），有两种类型：\n非独立连接部（DTr），用重述FTA的初始主题开始。 独立连接部（ITr），用新的主题材料。 这两种类型都是转调到STA并结束在新的主调或新的属调上。\n在再现部中，FTA和STA都保持在主调中，但是连接部可以不用保持，但连接部往往会重现于再现部。\n结尾段 用于结束呈示部。STA后紧接着的终止段，称之为结尾段（Cl）。这个结尾段紧跟着出现了STA中对比性的主体材料，并且是那段和声材料的结论性终止。目的是为了加强新调。结尾段往往长于STA。\n展开部与回头过渡 展开部通常是奏鸣曲式中最自由的段落，类似于二段曲式中的游离。\n回头过渡（RTr）是展开部的最后一个部分，属调准备在再现部中折返到属调。\n再现部与尾声 通常，再现部都会重复许多呈示部的音乐，但它会有一些重要的变化，其中最重要的不仅仅只是FTA的材料，而且还有STA与结尾段的材料并返回到主调。\n尾声出现在再现部之后。它们也可出现在呈示部的结尾，它们在那里被称之为小尾声。\n奏鸣曲式的其他特点与要素 单主题奏鸣曲式\nFTA开始的主题又在STA中出现了。\n缓慢的引子\n有些用奏鸣曲式塑造的乐章带有缓慢的引子，它涉及外来的和声领域、半音调、并结合了混合调式。尤其常见于交响曲中。缓慢的引子通常是开始在主调上（尽管I不太好确立），并最终进行到半终止结束。这种引子听上去像一个巨大的弱拍，要解决到FTA的主调上。\n和声的变异\n假再现\nFTA的主题出现在错误的调中；而真正的再现部是用主调，通常紧随其后。假再现实际上还是发展部的一部分。\n下属返回\n再现部没有从I而是从IV上开始。\n其他各种调性策略 三调呈示部\n常见于大调作品。STA进行到自然三度音的关系调，将传统的I-V分为了两步走，传统意义的属调是在呈示部的结尾才被确立。\n不便于分类的部分 对位转位 从书上看起来和对位法没有关系，故放在这个部分。\n对位转位指的是，声部之间的旋律互相交换出现在后续部分。这能使得作曲家从单一乐思中得到双倍的音乐价值。并且能使音乐保持明晰的统一。\n主要有：八度转位（音程的协和性质不变，并且不协和音的处理在转位中也是正确的。除了五度会被转成四度。）、十二度等等。\n复合旋律 有时会遇到只有一个或两个声部的作品，没有明晰表现的三和弦与七和弦。比如巴赫的作品。\n而不采用完整的和弦也能隐含和声的功效的重要技术之一就是复合旋律。\n通过依靠旋律在音区中的跳进，就能使得一条单线的隐伏配置到有音域划分的多个声部中。比如阿尔贝替低音这样的分解和弦就是一种方法。\n","date":"2022-07-24T13:25:42+08:00","permalink":"https://kegalas.top/inferior/%E5%AE%8C%E5%85%A8%E9%9F%B3%E4%B9%90%E7%90%86%E8%AE%BA%E6%95%99%E7%A8%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","title":"《完全音乐理论教程》读书笔记"},{"content":"不均匀分割空间的数据结构 有Oct-Tree，KD-Tree，BSP-Tree。\nOct-Tree是均匀地将一个正方体分为八个小正方体的结构。可以根据物体在某一部分的密度来决定是否往下分。\nKD-Tree是将空间分为两部分，可以是不均匀的。但是分的时候是轴对齐的。\nBSP-Tree也是分为两部分，但分的时候可以不轴对称。\nKD-Tree KD-Tree的要求如下\n对于中间节点，存储：\n分割空间的平面垂直的坐标轴 分割空间的平面在坐标轴上的坐标 指向儿子节点的指针 不存储任何物体的信息 对于叶子节点，存储\n包含的物体列表 层次包围盒(BVH) 这也是一种树，根节点是所有物体的包围盒。\n然后对节点进行分割，使得该节点划分为两个部分，每个部分都是一个包围盒，一个物体仅在一个包围盒中。\n如果一个节点被分割了，它就不再作为含有物体的包围盒。只有叶子节点含有包围盒。\n其中有几个注意事项：\n选择节点中的最长轴，如果物体有沿\\(x\\)轴分布的形状，则在\\(x\\)轴上将物体分为两部分。 分割节点选择在中间的物体。 当一个节点只有很少物体时停止分割 ","date":"2022-07-20T15:09:04+08:00","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","title":"计算机图形学基础学习笔记-数据结构"},{"content":"三角形网格的细分 Loop细分 Loop Subdivision分为两步\n创建更多三角形（顶点） 改变三角形顶点的位置 创建更多的三角形非常简单，只用将三角形每条边的中点相连，我们就得到了四个三角形。\n对于顶点的位置，新的顶点和老的顶点都需要更改。\n对于新的顶点：\n1.jpg\r对于老的顶点\n2.jpg\r更一般的网格的细分 Catmull-Clark细分 对于不是方形的面和度数（所连边数）不等于4的点要进行细分\n步骤如下：\n在每个面的上添加顶点 在每条边的上添加顶点 连接新顶点 添加的规则如下\n3.jpg\r网格简化 二次误差度量 4.jpg\r对于如上图的情况，不应该对顶点求平均值，而应该使得新的顶点到原来顶点的平方距离之和最小\n坍缩边的方法 通过坍缩某些边，然后使边的端点重合在一起，使得三角形减少。\n一个想法是将边的中点进行二次误差度量。\n5.jpg\r一个更好地想法是选择那些拥有最小二次误差的点。可以用优先队列来维护。\n","date":"2022-07-20T15:08:04+08:00","image":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E6%9B%B2%E9%9D%A2%E7%BB%86%E5%88%86/cover_hu9da4564469e95373a7893edcdf989008_27817_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E6%9B%B2%E9%9D%A2%E7%BB%86%E5%88%86/","title":"计算机图形学基础学习笔记-曲面细分"},{"content":"有两种方法描述几何：隐式的、显式的。\n几何的隐式表示 取决于某些点是否符合表达式。\n例如描述一个球面\\(x^2+y^2+z^2=1\\)，所有符合这个表达式的点就是一个球面。\n更一般的情况：满足\\(f(x,y,z)=0\\)的所有点。\n它的特点是，采样比较困难，但判断一个点在集合体内外或者在几何体上非常方便。\n隐式表示包含：\n代数方程表示(Algebraic Surfaces) 通过布尔表达式对几何体进行运算(Constructive Solid Geometry) 距离函数(Distance Functions) Blending Distance Functions 水平集(Level Set) 分形(Fractals) 几何的显式表示 所有的点直接给出，或者通过参数映射地给出。\n比如从二维映射到三维\n\\[f:\\mathbb{R^2\\to R^3};(u,v)\\to(x,y,z) \\]\n特点是，采样简单，但是判断关系较为困难。\n显式表示包含：\n点云(Point Cloud) 多边形网格(Polygon Mesh) 贝赛尔曲线(Bezier Curves) 贝塞尔曲线 Casteljau算法\n考虑平面上的三个点\\(b_0,b_1,b_2\\)，用线性差值的办法插入一个点到每一条边上。\n1.jpg\r将新增的两个点再利用相同的办法插入一个点。\n2.jpg\r然后对于插值的比例值\\([0,1]\\)上的所有点进行这个算法。\n3.jpg\r对于更多点，因为每次在边上进行插值后，新的点比原来的点少一个，反复进行这个算法直到只有一个点。\n4.jpg\r将这个过程公式化，对于三个点的情况，即为\n\\[b_0^1(t)=(1-t)b_0+tb_1\\\\ b_1^1(t)=(1-t)b_1+tb_2\\\\ b_0^2(t)=(1-t)b_0^1+tb_1^1 \\]\n\\[\\therefore b_0^2(t) = (1-t)^2b_0+2t(1-t)b_1+t^2b_2 \\]\n对于更多点的情况：\n\\[b^n(t) = b^n_0(t)=\\sum^n_{j=0}b_jB^n_j(t) \\]\n其中\n\\[B^n_i(t)=\\binom{n}{i}t^i(1-t)^{n-1} \\]\n也可以用递归的方法计算，比较简便。\n贝赛尔曲线的一些性质\n\\(t=0\\)是起点，\\(t=1\\)是终点。 曲线与端点段相切 仿射变换中，对控制点仿射变换再画曲线，和对已经画出来的曲线做仿射变换，得到的曲线是一样的。 曲线一定在控制点的凸包内 分段的贝赛尔曲线及其算法\n四个顶点构成的贝赛尔曲线为一段，再将许多贝赛尔曲线接到一起。\n这样的曲线一定是连续的，但光滑还有一个条件。即第一条曲线的第3、4个点的线段和第二条曲线的第1、2个点的线段长度、方向均相同。\n样条(Spline) TODO\n贝塞尔曲面 对于\\(4\\times 4\\)的控制点，首先在\\(u\\)方向上画出四条贝赛尔曲线，然后再在\\(v\\)方向上，根据四条贝塞尔曲线计算出四个控制点，再计算出曲面上的点。\n","date":"2022-07-20T13:47:39+08:00","image":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E5%87%A0%E4%BD%95%E7%9A%84%E8%A1%A8%E7%A4%BA%E6%96%B9%E6%B3%95/cover_hu6f2ff40bfc84c7f47df65f54ecbd43e8_39003_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E5%87%A0%E4%BD%95%E7%9A%84%E8%A1%A8%E7%A4%BA%E6%96%B9%E6%B3%95/","title":"计算机图形学基础学习笔记-几何的表示方法"},{"content":"纹理映射 纹理映射流程如下\n对于每个光栅化的屏幕采样点\\((x,y)\\)（通常是像素的中心点）\n令\\((u,v)\\)为纹理上对应于\\((x,y)\\)的坐标 对纹理上\\((u,v)\\)进行采样 将采样得到的颜色作为光栅化需要使用的颜色 纹理映射函数 从世界坐标\\((x,y,z)\\)映射到纹理坐标\\((u,v)\\)的函数。\n平面投影\n直接忽略掉\\(z\\)坐标（或者根据理解，是忽略掉法向量那个方向的坐标）（世界空间是\\([-1,1]^3\\)）：\n\\[\\phi(x,y,z)=(u,v)\\quad where\\quad \\begin{bmatrix} u \\\\ v \\\\ * \\\\ 1 \\end{bmatrix}=M_t \\begin{bmatrix} x \\\\ y \\\\ z \\\\ 1 \\end{bmatrix} \\]\n其中，\\(M_t\\)是一个仿射变换矩阵，而星号代表我们不在乎这个坐标。\n这个映射对于比较平的面的效果较好，但是对于一些闭合曲面（例如一个正方体）效果不佳。\n用透视投影替代正交投影，我们可以得到一个投影的纹理坐标\n\\[\\phi(x,y,z)=(\\tilde{u}/\\omega,\\tilde{v}/\\omega)\\quad where\\quad \\begin{bmatrix} \\tilde{u} \\\\ \\tilde{v} \\\\ * \\\\ \\omega \\end{bmatrix}=P_t \\begin{bmatrix} x \\\\ y \\\\ z \\\\ 1 \\end{bmatrix} \\]\n其中矩阵\\(P_t\\)代表着一个投影变换。这个投影纹理坐标在阴影贴图中有重要的作用。\n球体坐标\n从球体上的点\\((x,y,z)\\)映射到纹理上\\((u,v)\\)，假设球心在原点，并且世界空间是\\([-1,1]^3\\)，则因为\n\\[x = rcos\\phi sin\\theta\\\\ y = rsin\\phi sin\\theta\\\\ z = rcos\\theta \\]\n有\n\\[\\theta = acos(z/\\sqrt{x^2+y^2+z^2})\\\\ \\phi = atan2(y,x) \\]\n再转化为\\((u,v)\\)的形式，有：\n\\[\\phi(x,y,z) = ([\\pi+atan2(y,x)]/2\\pi,[\\pi-acos(z/||x||)]/\\pi) \\]\n圆柱体坐标\n世界空间是\\([-1,1]^3\\)，圆柱体中心在原点\n\\[\\phi(x,y,z)=([\\pi+atan2(y,x)]/2\\pi,[1+z]/2) \\]\n注，Fundamentals Of Computer Graphics中写的是\\(\\phi(x,y,z)=(\\frac{1}{2\\pi}[\\pi+atan2(y,x)]/2\\pi,\\frac{1}{2}[1+z])\\)，怀疑有误。\n纹理放大 双线性插值 现在假设纹理上需要采样的点的坐标为(x,y)，显然这个点会落在某个\\(2\\times2\\)的像素矩形中。\n设左下角的像素为\\(u_{00}\\)，左上\\(u_{01}\\)，右下\\(u_{10}\\)，右上\\(u_{11}\\)\n设左下角像素中心点为原点建立坐标系。横轴记为\\(s\\),纵轴记为\\(t\\)。则\\(u_{00}=(0,0)\\)，\\(u_{10}=(1,0)\\)，\\(u_{01}=(0,1)\\)，\\(u_{11}=(1,1)\\)\n记采样点(x,y)在这个坐标系下的坐标为\\((s,t)\\)\n设函数\\(lerp(x,v_0,v_1)=v_0+x(v_1-v_0)\\)\n这个函数的意义是，假设直线上两个点的值为\\(v_0,v_1\\)，\\(x\\)为这两个点间的坐标，\\(x\\)在\\(x_0\\)处等于\\(0\\)，在\\(x_1\\)处等于\\(1\\)。此时所得的函数值为\\(x\\)处的插值。\n现在我们可以对\\((s,t)\\)这个点进行插值，首先定义\n\\[u_0 = lerp(s,u_{00},u_{10}) u_1 = lerp(s,u_{01},u_{11}) \\]\n得到这两个点后再进行一次插值得\n\\[f(x,y) = lerp(t,u_0,u_1) \\]\n当然也可以先进行垂直的插值，再水平插值。\n双立方插值 TODO\n纹理缩小 Mipmap 当一个像素代表了纹理中的一大块时，需要进行纹理缩小。\n之前介绍的超采样等是可以使用的，只不过这样会导致开销过大。\n我们需要找到一种办法直接对区间求平均值。\n引入Mipmap的概念。它允许快速的、近似的（而非准确的）、方形的范围均值查询。\n假设第0层是原纹理图像（方形）。\n则第1层是将长宽各缩小为一半，所所放出来的纹理。第2层则为第1层缩小一半，以此类推直到只有一个像素。\n额外占用的存储空间只有原纹理的\\(1/3\\)。\n我们要计算应该使用第几层，首先确定我们要光栅化的像素的坐标(x,y)，然后将其对应到纹理上的坐标记为\\((u,v)\\)。\n找到它的邻居像素，例如右边像素，然后如图进行计算。\n1.jpg\r存在的一个问题就是，层数是不连续的，但我们的空间是连续的。所以每一层mipmap在纹理映射时会出现块状的、不连续的现象。\n三线性插值 为了解决mipmap不连续的现象，引入三线性插值。\n在\\(D\\)层进行双线性插值 在\\(D+1\\)层进行双线性插值 对\\(D,D+1\\)层进行一次线性插值 Mipmap的缺陷 相较于超采样，在远处会出现模糊现象。原因在于，只能查询一个方形取余、近似的、以及是插值得到的。\n解决（部分的）办法：各向异性过滤。\n比各向异性过滤更好的：EWA过滤。\n纹理的应用 环境光贴图 将整个环境做成贴图，可以给比较镜面光滑的物体使用，使之反射出环境的样子。\n除了保存成方形的贴图，还可以保存在球面上。\n保存在球面上带来的问题是，越靠近上下的地方，越会出现变形。此时可以将球上的点映射到一个立方体上，来解决这种变形。\n2.jpg\r法线贴图 储存一个相对高度，从而改变某一点的法线，从而改变光照效果，从而实现凹凸不平的视觉效果。\n新的法向量的计算方法：\n二维情况：\n假设原来\\(p\\)点的法向量\\(n(p)=(0,1)\\)。\n将\\(p\\)点通过法线贴图的相对高度移到对应位置，则\\(p\\)点此时的导数为\\(dp=c[h(p+1)-h(p)]\\)，其中\\(c\\)是常数，\\(h(x)\\)是高度函数。\n则新的法向量为\\(n(p)=(-dp,1).normalized()\\)\n三维情况\n原始法向量为\\(n(p)=(0,0,1)\\)\n导数为\n\\[\\frac{dp}{du} = c_1[h(u+1)-h(u)] \\]\n\\[\\frac{dp}{dv} = c_2[h(v+1)-h(v)] \\]\n新的法向量为\\((-dp/du,-dp/dv,1)\\)\n法向量的一般情况\n对于原法向量为\\(\\bm n=(x,y,z)\\)的，首先令\n\\[\\bm t = \\left(\\frac{xy}{\\sqrt{x^2+z^2}},\\sqrt{x^2+z^2},\\frac{zy}{\\sqrt{x^2+z^2}}\\right) \\]\n\\[\\bm b = \\bm n\\times\\bm t \\]\n\\[TBN = [\\bm{t,b,n}] \\]\n\\[dU = kh\\cdot kn\\cdot(h(u+1/w,v)-h(u,v)) \\]\n\\[dV = kh\\cdot kn\\cdot(h(u,v+1/h)-h(u,v)) \\]\n其中\\(kh,kn\\)是常数，\\(h(u,v)\\)是高度函数,\\(h,w\\)是纹理的高度和宽度。\n\\[\\bm{ln} = (-dU,-dV,1) \\]\n那么最终得到的法向量为\n\\[\\bm n = normalize(TBN\\cdot \\bm{ln}) \\]\n将法线的XYZ坐标以RGB的形式存储\n有些法线贴图会将法线的xyz坐标以RGB的形式存储。要得到\\([-1,1]\\)上的法线方向坐标，要经过两次转换。首先将\\(0\\sim 255\\)的\\(RGB\\)换到\\([0,1]\\)的形式，然后再转换到\\([0,1]*2-1=[-1,1]\\)。\n这在有些时候比从模型中顶点的法向量来插值计算内部点的法向量要更有细节。\n切线空间存储法向量\n在切线空间存储法向量时，会直接存储某个值的值作为颜色（当然也要转化到\\([-1,1]\\)），我们要做的就是计算出切线空间的基，然后将其转化为世界坐标中的法向量。\n对于一个三角形上的三个点\\(p_0,p_1,p_2\\)，以及这个三角形的法向量\\(\\bm n\\)。设\\(u_0,u_1,u_2\\)分别为三个点的纹理上的\\(u\\)坐标，\\(v_0,v_1,v_2\\)为\\(v\\)坐标。那么就有\n\\[\\bm i = A^{-1}\\begin{pmatrix} u_1-u_0 \\\\ u_2-u_0 \\\\ 0 \\end{pmatrix} \\]\n\\[\\bm j = A^{-1}\\begin{pmatrix} v_1-v_0 \\\\ v_2-v_0 \\\\ 0 \\end{pmatrix} \\]\n其中\n\\[A = \\begin{pmatrix} \\overrightarrow{p0p1} \\\\ \\overrightarrow{p0p2} \\\\ \\bm n \\end{pmatrix} \\]\n之后切线空间的基就是\\((\\bm i,\\bm j,\\bm n)\\)，将其乘以纹理中提取到的值，就得到世界坐标中的法向量。\n位移贴图 与法线贴图类似，但是位移贴图真正地移动了顶点的位置，很多时候比法线贴图真实。\n噪声 TODO\n对纹理进行环境光预处理 TODO\n3D贴图和体积渲染 TODO\n阴影贴图 将光源也当作一个相机，进行光栅化，只计算zbuffer的信息。\n然后在相机光栅化时，判断两个zbuffer是否相等，相等才能被相机和光源看见。不相等的则在阴影中。\n","date":"2022-07-14T16:53:03+08:00","image":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E8%B4%B4%E5%9B%BE/cover_hu19fc7c044e05b48ede368f76a4a534a3_160946_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E8%B4%B4%E5%9B%BE/","title":"计算机图形学基础学习笔记-贴图"},{"content":"点光源 假设点光源的光的强度（能流密度）是\\(E=I\\)，由于点光源向外发送能量是以球面波的形式发送。在距离光源\\(r\\)处的波面上，光的强度是\\(E=\\frac{I}{r^2}\\)。这一点与大学物理相同。\nBlinn-Phong反射模型 首先给出以下定义：\n对于某个物体上需要被着色的某一点。其单位法向量为\\(\\bm n\\)，这一点指向相机的单位向量为\\(\\bm v\\)，指向光源的向量为\\(\\bm l\\)。\n漫反射 漫反射意味着，从四面八方看过来，这个位置的颜色是一致的。\n我们主要关注，这个位置与光源的角度关系，从而得出这个点的颜色。\nLambert\u0026rsquo;s cosine law\n假设光源到达这个点的强度是\\(E=I\\)，那么经过漫反射后，其强度变为\\(E=Icos\\theta\\)，即\\(E=I\\cdot\\bm l\\cdot\\bm n\\)\n结合点光源，以及漫反射系数，可得\n\\[L_d=k_d(\\frac{I}{r^2})max(0,\\bm n\\cdot\\bm l) \\]\n其中，\\(k_d\\)是漫反射系数，与材质有关。\\(I\\)是点光源的强度，\\(r\\)是点光源到需要着色的点的距离。后面max的作用是，防止从“内部”或者“下面”射来的光线影响了“表面”的颜色。\n通常，\\(k_d\\)是一个三维向量，如果将纹理颜色赋值给\\(k_d\\)，则会起到给模型贴纹理的效果。\n\\(L_d\\)和\\(I\\)也是三维向量，\\(I\\)不仅可以代表光的强度，也可以表示光的颜色。\\(k_d\\)与\\(I\\)的乘法是元素之间相乘。在Eigen中使用cwiseProduct函数。\n镜面反射 即，某些材质中，反射角等于入射角，或者反射角很接近入射角时，出现的光强明显大于其他角度的情况。\n此时\\(\\bm v\\)非常接近反射角，或者有，半程向量非常接近于法向量\\(\\bm n\\)。\n半程向量即是\\(\\bm l,\\bm v\\)的角平分线的单位向量。有\n\\[\\bm h = \\frac{\\bm v+\\bm l}{||\\bm v+\\bm l||} \\]\n此时相机收到的光强为\n\\[L_s = k_s(\\frac{I}{r^2})max(0,\\bm n\\cdot\\bm h)^p \\]\n其中\\(k_s\\)是镜面反射系数，\\(p\\)决定了\\(\\bm v\\)和反射角有多接近才算能触发镜面反射。\\(p\\)越大触发镜面反射的角度范围越小。通常会取到\\(100\\)以上。\n\\(k_s,L_s,I\\)仍然是三维向量，乘法规则同前，只不过这里的\\(k_s\\)通常会采用比较亮的白色，而不会采用其他颜色。\n环境光反射 即通过整个环境其他物体的反射，再次射入该物体，给该物体提供亮度。\n在Blinn-Phong模型中，我们选择添加常数的亮度。\n\\[L_a = k_aI_a \\]\n\\(k_a\\)是环境光反射常数。\n\\(k_a,L_a,I_a\\)仍然是三维向量，乘法规则同前，只不过这里的\\(k_s\\)通常会采用比较暗的白色，而不会采用其他颜色。\n注意，有多个光源时，不要重复添加环境光反射。\n三个反射混合 \\[L = L_a+L_d+L_s \\]\n","date":"2022-07-13T21:49:11+08:00","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B/","title":"计算机图形学基础学习笔记-光照模型"},{"content":"光栅化 线段绘制 对于一条给定线段\n\\[f(x,y)\\equiv(y_0-y_1)x+(x_1-x_0)y+x_0y_1-x_1y_0=0 \\]\n假设\\(x_0\\leq x_1\\)，否则交换两个点。\n设\n\\[m=\\frac{y_1-y_0}{x_1-x_0} \\]\n下面的讨论建立在\\(m\\in (0,1]\\)上，其他的取值情况类似。\n给出伪代码如下\ny=y0 for x=x0 to x1 do draw(x,y) if(some condition) then y = y+1 其中\\(x,y\\)都取整数。\n一种判断\\(y=y+1\\)的方法是，假设当前画出来的点的坐标（而不是序号下标）是\\((x,y)\\)（根据本书的规则，左下角的像素的中心点是原点），则下一个要画的点只有两种情况，要么是右边的点，要么是右上角的点。即\\((x+1,y),(x+1,y+1)\\)，我们取中点，即\\((x+1,y+0.5)\\)，如果直线在这个点的下方，则画右边的点；如果直线在这个点的上方，则画右上方的点。\n如果直线在上方（或者点在下方），那么\\(f(x+1,y+0.5)\u003c0\\)，在下方则大于0.如果刚好等于零，可以任意画。\n所以可以写伪代码如下\nif f(x+1,y+0.5)\u0026lt;0 then y=y+1 对于这个算法有优化的办法。主要是针对每次都要调用\\(f\\)计算来进行的优化。\n注意到我们可能计算过\\(f(x-1,y+0.5),f(x-1,y-0.5)\\)，并且我们有\n\\[f(x+1,y)=f(x,y)+(y_0-y_1) \\]\n\\[f(x+1,y+1) = f(x,y)+(y_0-y_1)+(x_1-x_0) \\]\n有如下伪代码\ny = y0 d = f(x0+1,y0+0.5) for x = x0 to x1 do draw(x,y) if d\u0026lt;0 then y = y+1 d = d+(x1-x0)+(y0-y1) else d = d+(y0-y1) 三角形绘制 高洛德插值(Gouraud Interpolation)\n运用重心坐标系，我们可以对颜色进行插值。\n假设三个点的颜色值分别为\\(\\bm c_0,\\bm c_1,\\bm c_2\\)。假设我们要绘制的点的重心坐标为\\((\\alpha,\\beta,\\gamma)\\)，则其颜色为\n\\[\\bm c = \\alpha\\bm c_0+\\beta\\bm c_1+\\gamma\\bm c_2 \\]\n暴力光栅化算法\n伪代码如下\nfor all x do for all y do compute(alpha,beta,gamma) for (x,y) if(alpha,beta,gamma in [0,1]) then c = alpha*c0+beta*c1+gamma*c2 drawpixel(x,y) with color c 优化后的算法\nxMin = floor(xi) xMax = ceiling(xi) yMin = floor(yi) yMax = ceiling(yi) for y = yMin to yMax do for x = xMin to xMax do alpha = f12(x,y)/f12(x0,y0) beta = f20(x,y)/f20(x1,y1) gamma = f01(x,y)/f01(x2,y2) if(alpha,beta,gamma\u0026gt;0) then c=alpha*c0+beta*c1+gamma*c2 drawpixel(x,y) with color c 其中的\\(f_{ij}\\)为\n\\[f_{01}(x,y) = (y_0-y_1)x+(x_1-x_0)y+x_0y_1-x_1y_0\\\\ f_{12}(x,y) = (y_1-y_2)x+(x_2-x_1)y+x_1y_2-x_2y_1\\\\ f_{20}(x,y) = (y_2-y_0)x+(x_0-x_2)y+x_2y_0-x_0y_2 \\]\n对于公共边上的点的处理\nxMin = floor(xi) xMax = ceiling(xi) yMin = floor(yi) yMax = ceiling(yi) fAlpha = f12(x0,y0) fBeta = f20(x1,x1) fGamma = f01(x2,y2) for y = yMin to yMax do for x = xMin to xMax do alpha = f12(x,y)/fAlpha beta = f20(x,y)/fBeta gamma = f01(x,y)/fGamma if(alpha,beta,gamma\u0026gt;=0) then if(alpha\u0026gt;0 or fAlpha*f12(-1,-1)\u0026gt;0)and (beta\u0026gt;0 or fBeta*f20(-1,-1)\u0026gt;0)and (gamma\u0026gt;0 or fGamma*f01(-1,-1)\u0026gt;0) then c=alpha*c0+beta*c1+gamma*c2 drawpixel(x,y) with color c 用Z-Buffer处理覆盖问题 为了处理方便，假设\\(z\\)始终为正，且更小的\\(z\\)意味着更近，更大的\\(z\\)意味着更远。\n算法如下\n首先给\\(z-buffer\\)赋值无限大。\n在光栅化过程中，执行如下伪代码\nfor (each triangle T) for (each sample (x,y,z) in T) if(z\u0026lt;zbuffer[x,y]) framebuffer[x,y] = rgb; zbuffer[x,y] = z; else ; 即为，对每个三角形的采样像素，如果他的深度坐标，即\\(z\\)更小，那么在缓冲区更新这个像素的颜色，并且更新最小的\\(z\\)。\n该算法的复杂度是\\(O(n)\\)，对于\\(n\\)个三角形。\n着色频率的问题（Shading Frequencies） 对每个平面着色 又叫Flat着色。\n对每个顶点着色 又叫Gouraud着色。\n一个顶点的单位法向量，可以由以这个点为顶点的所有三角形的法向量求出。\n\\[N_v=\\frac{\\sum_iN_i}{||\\sum_iN_i||} \\]\n然后这个单位法向量可以用于Blinn-Phong反射模型中。\n再之后，对于平面内的点的着色，需要使用插值算法。\n对每个片元（像素）着色 又称Phong着色。\n对于每个像素的单位法向量，假设我们已经知道顶点的法向量，我们可以采用重心坐标插值的算法来计算出每个像素的单位法向量。\n图形管线的工作流程 程序输入顶点 将顶点在屏幕中定位 根据顶点在屏幕中定位三角形 根据三角形进行光栅化 对于光栅化后的片元进行着色 输出到帧缓冲，最后输出到屏幕。 ","date":"2022-07-03T15:21:12+08:00","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E5%85%89%E6%A0%85%E5%8C%96%E4%B8%8E%E7%9D%80%E8%89%B2%E9%A2%91%E7%8E%87/","title":"计算机图形学基础学习笔记-光栅化与着色频率"},{"content":"分辨率与坐标 假设屏幕分辨率是\\(n_x\\times n_y\\)，则，按照本书的规则，左下角的像素的中心点定为原点，那么有坐标范围为\\([-0.5,n_x-0.5]\\times [-0.5,n_y-0.5]\\)。若按照games101的规则，则坐标范围为\\([0,n_x]\\times[0,n_y]\\)。\nRGB格式 出于方便目的，RGB的三个分量的取值范围都是\\([0,1]\\)。在具体实现时，如8-bit图片，每个分量的所有可能的取值为\\(0,1/255,2/255,\\cdots,254/255,1\\)。\n","date":"2022-07-03T15:05:15+08:00","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E5%85%89%E6%A0%85%E5%8C%96%E5%9B%BE%E5%83%8F%E7%9A%84%E6%A0%87%E5%87%86/","title":"计算机图形学基础学习笔记-光栅化图像的标准"},{"content":"在MSYS2中安装程序时遇到如下问题：\nerror: mingw-w64-x86_64-mpc: signature from \u0026#34;David Macek \u0026lt;david.macek.0@gmail.com\u0026gt;\u0026#34; is unknown trust 尝试通过https://packages.msys2.org/中提供的方法，安装了key，解决问题。\n或者直接输入pacman -S msys2-keyring\n","date":"2022-07-01T12:05:59+08:00","permalink":"https://kegalas.top/inferior/msys2%E6%8A%A5%E9%94%99davidmacek%E6%9C%AA%E7%9F%A5%E4%BF%A1%E4%BB%BB/","title":"MSYS2报错David Macek is unknown trust"},{"content":"Viewing Transformations 视口变换（Viewport Transformation） 将\\([-1,1]^2\\)的正方形映射到屏幕上。这个屏幕宽\\(n_x\\)像素，高\\(n_y\\)像素。并且由于左下角像素中心点位置为原点，我们要有负0.5个像素，即映射到\\([-0.5,n_x-0.5]\\times[-0.5,n_y-0.5]\\)。（注，在games101中映射到的是\\([0,n_x]\\times[0,n_y]\\)）\n需要如下变换\n\\[\\begin{bmatrix} x_{screen} \\\\ y_{screen} \\\\ 1 \\end{bmatrix}= \\begin{bmatrix} n_x/2 \u0026 0 \u0026 (n_x-1)/2\\\\ 0 \u0026 n_y/2 \u0026 (n_y-1)/2\\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} x_{canonical}\\\\ y_{canonical}\\\\ 1 \\end{bmatrix} \\]\n三维形式有\n\\[M_{vp}= \\begin{bmatrix} n_x/2 \u0026 0 \u0026 0 \u0026 (n_x-1)/2\\\\ 0 \u0026 n_y/2 \u0026 0 \u0026 (n_y-1)/2\\\\ 0 \u0026 0 \u0026 1 \u00260\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n正交投影变换（Orthographic Projection Transformation） 将一个\\([l,r]\\times[b,t]\\times[f,n]\\)矩阵变换到\\([-1,1]^3\\)。\n其中\\(l\\)即left是\\(x\\)坐标小的平面，\\(r\\)即right是\\(x\\)坐标大的平面。\n其中\\(b\\)即bottom是\\(y\\)坐标小的平面，\\(t\\)即top是\\(y\\)坐标大的平面。\n其中\\(f\\)即far是\\(z\\)坐标小的平面，\\(n\\)即near是\\(z\\)坐标大的平面。\n注意\\(z\\)可能与常识不太相同，因为我们的相机所看的方向是\\(-z\\)方向。\n这也导致了OpenGL使用左手坐标系。\n完成这个变换的矩阵是\n\\[\\begin{bmatrix} \\frac{2}{r-l} \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 \\frac{2}{t-b} \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 \\frac{2}{n-f} \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 -\\frac{r+l}{2}\\\\ 0 \u0026 1 \u0026 0 \u0026 -\\frac{t+b}{2}\\\\ 0 \u0026 0 \u0026 1 \u0026 -\\frac{n+f}{2}\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix}= \\]\n\\[\\begin{bmatrix} \\frac{2}{r-l} \u0026 0 \u0026 0 \u0026 -\\frac{r+l}{r-l}\\\\ 0 \u0026 \\frac{2}{t-b} \u0026 0 \u0026 -\\frac{t+b}{t-b}\\\\ 0 \u0026 0 \u0026 \\frac{2}{n-f} \u0026 -\\frac{n+f}{n-f}\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n相机变换（Camera Transformation） 首先知道三个向量：\n\\(\\bm e\\)，相机位置（eye position）向量 \\(\\hat{\\bm g}\\)，相机视线（gaze）方向。 \\(\\hat{\\bm t}\\)，相机头顶方向。（和视线方向正交） 我们要将相机位置变换到原点，将视线方向定为\\(-z\\)方向，头顶方向为\\(y\\)方向。同时所有物体都跟随相机变换，最终结果相机看到的画面不变。\n首先，显然的，将相机位置变换到原点的矩阵是\n\\[T_{view} \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 -x_e\\\\ 0 \u0026 1 \u0026 0 \u0026 -y_e\\\\ 0 \u0026 0 \u0026 1 \u0026 -z_e\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n然后对两个另外两个向量进行旋转，直接想不太方便，可以反过来由\\(z\\)和\\(y\\)变换到\\(-\\hat g\\)和\\(\\hat t\\)，\\(x\\)变换到\\(\\hat g\\times \\hat t\\)\n\\[R_{view}^{-1}= \\begin{bmatrix} x_{\\hat g\\times \\hat t} \u0026 x_{\\hat t} \u0026 x_{-\\hat{g}} \u0026 0\\\\ y_{\\hat g\\times \\hat t} \u0026 y_{\\hat t} \u0026 y_{-\\hat{g}} \u0026 0\\\\ z_{\\hat g\\times \\hat t} \u0026 z_{\\hat t} \u0026 z_{-\\hat{g}} \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n然后再得到逆变换，由于这是个正交矩阵，逆矩阵就是转置矩阵\n\\[R_{view}= \\begin{bmatrix} x_{\\hat g\\times \\hat t} \u0026 y_{\\hat g\\times \\hat t} \u0026 z_{\\hat g\\times \\hat t} \u0026 0\\\\ x_{\\hat t} \u0026 y_{\\hat t} \u0026 z_{\\hat t} \u0026 0\\\\ x_{-\\hat{g}} \u0026 y_{-\\hat{g}} \u0026 z_{-\\hat{g}} \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n另一种算法\n假设我们初始时相机在\\((0,0,0)\\)，相机视线方向为\\((0,0,1)\\)，相机的上方向为\\((0,1,0)\\)。\n此时相机变换到\\(e\\)，我们保持相机上向量相对不变，而左向量\\(x\\)轴方向就为\\(\\hat r=((\\hat g-e)\\times (0,1,0)).normalized\\)，从而新的上方向则变为\\(\\hat t=(\\hat g-e)\\times\\hat r\\)。\n如果想改变上方向，则就把初始的上方向改变即可，整个变换矩阵同上。\n透视投影（Perspective Projection） 由正交投影变换到透视投影，矩阵如下\n\\[P= \\begin{bmatrix} n \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 n \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 n+f \u0026 -fn\\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\end{bmatrix} \\]\n直观上的理解就是，将视锥中远平面压小到等于近平面。\n以上是games101的解释。\n在Real-Time Rendering的解释中，假设我们的相机在原点，我们想将任意一个点\\(p\\)，映射到平面\\(z=-d(d\u003e0)\\)上，得到一个新点\\(q=(q_x,q_y,-d)\\)。显然根据相似三角形，我们有\n\\[\\frac{q_x}{p_x}=\\frac{-d}{p_z}\\Rightarrow q_x = -d\\frac{p_x}{p_z} \\]\n对于\\(y\\)坐标也是同样的，所以能得到矩阵\n\\[P_p = \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 1 \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \u0026 0\\\\ 0 \u0026 0 \u0026 -1/d \u0026 0 \\end{bmatrix} \\]\n因为\n\\[q=P_pp= \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 1 \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \u0026 0\\\\ 0 \u0026 0 \u0026 -1/d \u0026 0 \\end{bmatrix} \\begin{bmatrix} p_x \\\\ p_y \\\\ p_z \\\\ 1 \\end{bmatrix}= \\begin{bmatrix} p_x \\\\ p_y \\\\ p_z \\\\ -p_z/d \\end{bmatrix}\\Rightarrow \\begin{bmatrix} -dp_x/p_z \\\\ -dp_y/p_z \\\\ -d \\\\ 1 \\end{bmatrix} \\]\n但我们通常要做的不是把点都映射到一个平面上，而是要把视锥压缩到一个\\([-1,1]^3\\)的立方体上。\n这个视锥体是一个四棱椎，相机在椎顶，近平面\\(n\\)，远平面\\(f\\)，有\\(0\u003en\u003ef\\)。因此四棱锥被截成了四棱台。以相机的角度，上下侧面分别为\\(t,b\\)，左右侧面分别为\\(l,r\\)。\n对于近平面，左下角是\\((l,b,n)\\)，右上角是\\((r,t,n)\\)，决定了我们能看到的画面的大小，或称作视野范围。\n将这样的视锥变为\\([-1,1]^3\\)的矩阵是\n\\[P_p=\\begin{bmatrix} \\frac{2n}{r-l} \u0026 0 \u0026 -\\frac{r+l}{r-l} \u0026 0\\\\ 0 \u0026 \\frac{2n}{t-b} \u0026 -\\frac{t+b}{t-b} \u0026 0\\\\ 0 \u0026 0 \u0026 \\frac{f+n}{f-n} \u0026 -\\frac{2fn}{f-n}\\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\end{bmatrix} \\]\n也正好和上方games101的正交投影矩阵*透视投影矩阵相同。\n然后，不在\\(n,f\\)平面之间的物体将会被剔除，不被渲染。\n如果远平面是无穷远，那么有\n\\[P_p=\\begin{bmatrix} \\frac{2n}{r-l} \u0026 0 \u0026 -\\frac{r+l}{r-l} \u0026 0\\\\ 0 \u0026 \\frac{2n}{t-b} \u0026 -\\frac{t+b}{t-b} \u0026 0\\\\ 0 \u0026 0 \u0026 1 \u0026 -2n\\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\end{bmatrix} \\]\nOpenGL中的透视矩阵\n虽然都是右手系，但是OpenGL中zNear和zFar都是正数，透视矩阵就变为\n\\[P_p=\\begin{bmatrix} \\frac{2n}{r-l} \u0026 0 \u0026 \\frac{r+l}{r-l} \u0026 0\\\\ 0 \u0026 \\frac{2n}{t-b} \u0026 \\frac{t+b}{t-b} \u0026 0\\\\ 0 \u0026 0 \u0026 -\\frac{f+n}{f-n} \u0026 -\\frac{2fn}{f-n}\\\\ 0 \u0026 0 \u0026 -1 \u0026 0 \\end{bmatrix} \\]\n另外，OpenGL默认（指glm库）有\\(r=-l,t=-d\\)，就有\n\\[P_p=\\begin{bmatrix} c/a \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 c \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 -\\frac{f+n}{f-n} \u0026 -\\frac{2fn}{f-n}\\\\ 0 \u0026 0 \u0026 -1 \u0026 0 \\end{bmatrix} \\]\n其中\\(a\\)是显示分辨率的宽高比，\\(c\\)是\\(1/tan(fovY/2)\\)\n另外，将\\(z\\)轴上的\\([-0.1,-100]\\)映射到\\([-1,1]\\)上，不是均匀的，不精确的说，可能\\([-0.1+,1.0]\\)这一段映射到了\\([-1,0.5]\\)上，剩下的\\([1.0,100]\\)映射到了\\([0.5,1]\\)上，这在zbuffer、深度值中可能是需要注意的事。\n可以看https://learnopengl-cn.github.io/04 Advanced OpenGL/01 Depth testing/#_3了解具体的关系。\n视野（Field-of-View） 通常，对于近平面，我们可以用\\(l,r,b,t\\)描述（假设\\(l=-r,b=-t\\)，即平面中心位于\\(-z\\)轴上，且平面与\\(-z\\)垂直），也可以用垂直视野\\(fovY\\)和近平面的宽高比来表示。\n首先相机到近平面的距离为\\(|n|\\)，则有如下关系\n\\[tan\\frac{fovY}{2} = \\frac{t}{|n|} \\]\n\\[aspect = \\frac{r}{t} \\]\n","date":"2022-06-28T12:14:24+08:00","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E8%A7%86%E8%A7%92/","title":"计算机图形学基础学习笔记-视角"},{"content":"放缩 \\[scale(s_x,s_y)= \\begin{bmatrix} s_x \u0026 0\\\\ 0 \u0026 s_y \\end{bmatrix} \\]\n\\[\\begin{bmatrix} s_x \u0026 0\\\\ 0 \u0026 s_y \\end{bmatrix} \\begin{bmatrix} x\\\\ y \\end{bmatrix}= \\begin{bmatrix} s_xx\\\\ s_yy \\end{bmatrix} \\]\n例如长宽各缩小为0.5倍，有\n\\[scale(0.5,0.5)= \\begin{bmatrix} 0.5 \u0026 0\\\\ 0 \u0026 0.5 \\end{bmatrix} \\]\n切变 切变，想象一个由四根木条和四个钉子组装而成的正方形，我们可以将其“推”成一个平行四边形。但是在图形学中，长和高不变，意味着有两条边的长度会发生变化。\n\\[shear-x(s)=\\begin{bmatrix} 1 \u0026 s\\\\ 0 \u0026 1 \\end{bmatrix}, shear-y(s)=\\begin{bmatrix} 1 \u0026 0\\\\ s \u0026 1 \\end{bmatrix} \\]\n另外一种关于切变的理解是，仅仅对着x坐标或者y坐标进行了旋转操作，例如正向旋转（逆时针）\\(\\phi\\)，则有\n\\[\\begin{bmatrix} 1 \u0026 tan\\phi\\\\ 0 \u0026 1 \\end{bmatrix} or \\begin{bmatrix} 1 \u0026 0\\\\ tan\\phi \u0026 1 \\end{bmatrix} \\]\n旋转 逆时针转过\\(\\phi\\)，则\n\\[rotate(\\phi) = \\begin{bmatrix} cos\\phi \u0026 -sin\\phi\\\\ sin\\phi \u0026 cos\\phi \\end{bmatrix} \\]\n镜像 即关于\\(x\\)轴或\\(y\\)轴将整个图像颠倒过来，有\n\\[reflect-y = \\begin{bmatrix} -1 \u0026 0\\\\ 0 \u0026 1 \\end{bmatrix}, reflect-x = \\begin{bmatrix} 1 \u0026 0\\\\ 0 \u0026 -1 \\end{bmatrix} \\]\n线性变换的复合 对于两个变换\\(\\bm S,R\\)\n\\[first,\\bm v_2=\\bm{Sv}_1,then,\\bm v_3=\\bm{Sv}_2 \\]\n那么就可以写作\n\\[\\bm v_3=\\bm R(\\bm{Sv}_1) \\]\n根据结合律，写作\n\\[\\bm v_3=(\\bm{RS})\\bm{v}_1 \\]\n则\\(\\bm{M=RS}\\)就是复合变换，其中变换顺序是从右到左的。\n线性变换的拆分 例如，有一个\\(2\\times 2\\)正方形的左下角在点\\((1,1)\\)处，我们想要将它绕\\((1,1)\\)旋转\\(\\phi\\)度，我们就可以拆分成三个变换。首先，左下角平移到原点；然后，进行旋转；最后再平移回去。\n三维线性变换 总体来说，三维线性变换就是二维的扩展\n\\[scale(s_x,s_y,s_z)= \\begin{bmatrix} s_x \u0026 0 \u0026 0\\\\ 0 \u0026 s_y \u0026 0\\\\ 0 \u0026 0 \u0026 s_z \\end{bmatrix} \\]\n\\[rotate-z(\\phi)= \\begin{bmatrix} cos\\phi \u0026 -sin\\phi \u0026 0\\\\ sin\\phi \u0026 cos\\phi \u0026 0\\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n\\[rotate-x(\\phi)= \\begin{bmatrix} 1 \u0026 0 \u0026 0\\\\ 0 \u0026 cos\\phi \u0026 -sin\\phi\\\\ 0 \u0026 sin\\phi \u0026 cos\\phi \\end{bmatrix} \\]\n\\[rotate-y(\\phi)= \\begin{bmatrix} cos\\phi \u0026 0 \u0026 sin\\phi\\\\ 0 \u0026 1 \u0026 0\\\\ -sin\\phi \u0026 0 \u0026 cos\\phi \\end{bmatrix} \\]\n\\[shear-x(d_y,d_z)= \\begin{bmatrix} 1 \u0026 d_y \u0026 d_z\\\\ 0 \u0026 1 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n如果要绕过原点的固定轴\\(\\bm n\\)旋转，可以有罗德里格斯公式如下\n\\[\\bm R(\\bm n,\\alpha) = cos(\\alpha)\\bm I+(1-cos(\\alpha))\\bm{nn}^T+sin(\\alpha)\\bm N \\]\n其中\\(\\bm I\\)是单位矩阵，\n\\[\\bm N= \\begin{bmatrix} 0 \u0026 -n_z \u0026 n_y\\\\ n_z \u0026 0 \u0026 -n_x\\\\ -n_y \u0026 n_x \u0026 0 \\end{bmatrix} \\]\n平移 平移不能被写作矩阵的形式，所以它不是线性变换。\n\\[\\begin{bmatrix} x'\\\\ y' \\end{bmatrix}= \\begin{bmatrix} a \u0026 b\\\\ c \u0026 d \\end{bmatrix} \\begin{bmatrix} x\\\\ y \\end{bmatrix}+ \\begin{bmatrix} t_x\\\\ t_y \\end{bmatrix} \\]\n但是我们仍然有办法用矩阵来表示平移，这需要转化为齐次矩阵。\n为坐标（二维坐标）添加第三维，\n对于二维点，\\((x,y,1)^T\\) 对于二维向量，\\((x,y,0)^T\\) 于是我们有平移变换如下\n\\[\\begin{bmatrix} x'\\\\ y'\\\\ w' \\end{bmatrix}= \\begin{bmatrix} 1 \u0026 0 \u0026 t_x\\\\ 0 \u0026 1 \u0026 t_y\\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix}\\cdot \\begin{bmatrix} x\\\\ y\\\\ 1 \\end{bmatrix}= \\begin{bmatrix} x+t_x\\\\ y+t_y\\\\ 1 \\end{bmatrix} \\]\n并且这样定义点和向量有好处，向量加向量是向量，点减点是向量，点加向量是向量。\n平移一个向量，对于自由向量来说，起点都是远点，所以平移向量不会改变向量的坐标表示。为此设置第三维为0是合理的。\n同样地，在复合变换时，用矩阵乘法来复合。\n如果一个向量仅仅代表方向，例如法向量、平行光方向向量，不希望平移变换影响到这些向量，那么可以把第三维（对于三维向量是第四维）设置为零。此时除了平移，其他变换仍然能正常工作。\n三维平移 \\[\\bm T(t_x,t_y,t_z)=\\ \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 t_x\\\\ 0 \u0026 1 \u0026 0 \u0026 t_y\\\\ 0 \u0026 0 \u0026 1 \u0026 t_z\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n仿射变换 即线性变换加上一个平移\n\\[\\begin{bmatrix} x'\\\\ y' \\end{bmatrix}= \\begin{bmatrix} a \u0026 b\\\\ c \u0026 d \\end{bmatrix}\\cdot \\begin{bmatrix} x\\\\ y \\end{bmatrix}+ \\begin{bmatrix} t_x\\\\ t_y \\end{bmatrix} \\]\n\\[\\begin{bmatrix} x'\\\\ y'\\\\ 1 \\end{bmatrix}= \\begin{bmatrix} a \u0026 b \u0026 t_x\\\\ c \u0026 d \u0026 t_y\\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix}\\cdot \\begin{bmatrix} x\\\\ y\\\\ 1 \\end{bmatrix} \\]\n显然知道，这个矩阵先进行线性变换，再进行平移。\n逆变换 变换\\(\\bm M^{-1}\\)是变换\\(\\bm M\\)在矩阵和几何意义上的逆变换。\n显然，根据变换的复合，变换和其逆变换的复合相当于没变，两个变换矩阵的乘积是单位矩阵。故逆变换矩阵是变换矩阵的逆矩阵。\n坐标变换 TODO\n","date":"2022-06-27T16:25:19+08:00","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E5%8F%98%E6%8D%A2%E7%9F%A9%E9%98%B5/","title":"计算机图形学基础学习笔记-变换矩阵"},{"content":"本章内容为线性代数，在线性代数整理中涵盖了大部分内容，不再重复，介绍一些那篇文章没有覆盖的内容。\nSVD（奇异值分解） 与对角化不同的是，计算SVD时，两边的正交矩阵不要求相同。例如：\n\\[\\bm A=\\bm{USV}^T \\]\n其中\\(\\bm S\\)是一个对角阵，并且对角线上的元素就是奇异值。当\\(\\bm A\\)是对称的并且都是非负特征值，此时SVD和对角化相同。\n有一个特征值和奇异值之间的关系可以帮助我们计算奇异值\n\\[M = \\bm{AA}^T=(\\bm{USV}^T)(\\bm{USV}^T)^T = \\bm{US}(\\bm V^T\\bm V)\\bm{SU}^T \\]\n\\[=\\bm{US}^2\\bm U^T \\]\n","date":"2022-06-27T15:29:29+08:00","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/","title":"计算机图形学基础学习笔记-线性代数"},{"content":"Cartesian Product（笛卡尔积） 内容同离散数学。\n几个特别的集合 \\(S^2\\)，在单位球面上的三维点的集合。\n映射、函数、反函数 内容同离散数学。\n三角学 书中提到的正弦余弦定理、半角公式、和差公式都已在高中学过，记录一些没学过的。\n正切定理\n\\[\\frac{a+b}{a-b}=\\frac{tan\\left(\\frac{A+B}{2}\\right)}{tan\\left(\\frac{A-B}{2}\\right)} \\]\n海伦公式\n\\[S = \\frac{1}{4}\\sqrt{(a+b+c)(-a+b+c)(a-b+c)(a+b-c)} \\]\n重心坐标系 可以用三个点\\(\\bm{a,b,c}\\)表示三角形。\n假设三点不共线，则\\(\\bm{c-a},\\bm{b-a}\\)线性无关，即可以作为二维坐标的一组基底。\n二维空间中任何一点都可以由\n\\[\\bm{p}=\\bm a+\\beta(\\bm{b-a})+\\gamma(\\bm{c-a}) \\]\n表示\n整理得\n\\[\\bm{p}=(1-\\beta-\\gamma)\\bm a+\\beta\\bm{b}+\\gamma\\bm{c} \\]\n令\n\\[\\alpha\\equiv 1-\\beta-\\gamma \\]\n则有\n\\[\\bm p(\\alpha,\\beta,\\gamma)=\\alpha\\bm a+\\beta\\bm{b}+\\gamma\\bm{c} \\]\n其中\n\\[\\alpha+\\beta+\\gamma = 1 \\]\n一个点在三角形内部当且仅当\n\\[0\u003c\\alpha\u003c1,0\u003c\\beta\u003c1,0\u003c\\gamma\u003c1 \\]\n同时成立。也可以用向量叉乘的办法判断是否在内部。\n对于三角形三个点\\(A,B,C\\)，平面中一点\\((x,y)\\)可以表示为\n\\[(x,y) = \\alpha A+\\beta B+\\gamma C \\]\n\\[\\alpha+\\beta+\\gamma=1 \\]\n其中有\n\\[\\alpha = \\frac{-(x-x_B)(y_C-y_B)+(y-y_B)(x_C-x_B)}{-(x_A-x_B)(y_C-y_B)+(y_A-y_B)(x_C-x_B)} \\]\n\\[\\beta = \\frac{-(x-x_C)(y_A-y_C)+(y-y_C)(x_A-x_C)}{-(x_B-x_C)(y_A-y_C)+(y_B-y_C)(x_A-x_C)} \\]\n\\[\\gamma = 1-\\alpha-\\beta \\]\n运用重心坐标系进行颜色插值见第九章笔记。\n另外，从另一个角度思考\n\\[\\bm p = \\alpha\\bm a+\\beta\\bm b+\\gamma\\bm c\\\\ \\alpha+\\beta+\\gamma = 1 \\]\n有\n\\[\\bm p = (1-\\beta-\\gamma)\\bm a+\\beta\\bm b+\\gamma\\bm c \\]\n\\[\\bm p = \\bm a+\\beta\\overrightarrow{AB}+\\beta\\overrightarrow{AC} \\]\n\\[0 = \\overrightarrow{PA}+\\beta\\overrightarrow{AB}+\\gamma\\overrightarrow{AC} \\]\n也就是说，\n\\[\\begin{bmatrix} 1 \u0026 \\beta \u0026 \\gamma \\end{bmatrix} \\begin{bmatrix} PA_x \\\\ AB_x \\\\ AC_x \\end{bmatrix}=0 \\]\n\\[\\begin{bmatrix} 1 \u0026 \\beta \u0026 \\gamma \\end{bmatrix} \\begin{bmatrix} PA_y \\\\ AB_y \\\\ AC_y \\end{bmatrix}=0 \\]\n也就是说，向量\\((1,\\beta,\\gamma)\\)是向量\\((PA_x,AB_x,AC_x)\\)和\\((PA_y,AB_y,AC_y)\\)的叉积。根据向量第一位是1可以转变一下符号。\n这个方法代码相较于上一个方法比较简单。\n向量 同高中和线性代数\n积分 内容同高数。不过在计算机图形学里我们更注重数值而不是分析。\n曲线、曲面 内容同高数。\nLinear Interpolation（线性内插） \\[f(x)=y_i+\\frac{x-x_i}{x_{i+1}-x_i}(y_{i+1}-y_i) \\]\n概率论 随机变量 \\(X\\)，表示任意一个可能取值。\n概率密度函数(PDF) \\(X\\sim p(x)\\)，表示随机过程取值为\\(x\\)的相对概率。\n概率的一些属性 \\(p_i\\geq 0\\) \\(\\sum_{i=1}^np_i=1\\) 期望 \\[E[X] = \\sum_{i=1}^nx_ip_i \\]\n连续的情况 当随机变量\\(X\\)可以取一个连续的区间上的值。\n显然此时也会有连续的概率密度函数。\n并且\n\\[p(x)\\geq 0,\\int p(x)dx=1 \\]\n\\[E[x]=\\int xp(x)dx \\]\n随机变量的函数 随机变量的函数也是一个随机变量。\n\\[X\\sim p(x)\\\\ Y=f(X) \\]\n\\[E[Y]=E[f(X)]=\\int f(x)p(x)dx \\]\n蒙特卡罗积分 蒙特卡洛积分的目的：想计算一个定积分，但是难以从分析意义上解出，希望在数值上求解。\n方法：通过平均函数值的随机样本来估计函数的积分。\n定义定积分如下：\n\\[\\int_a^b f(x)dx \\]\n随机变量如下\n\\[X_i\\sim p(x) \\]\n则蒙特卡洛估计值是：\n\\[F_N=\\frac{1}{N}\\sum_{i=1}^N\\frac{f(X_i)}{p(X_i)} \\]\n如果随机变量是均匀的，或者说\n\\[X_i\\sim p(x)=C \\]\n\\(C\\)是一个常数\n那么，\n\\[\\int_a^b p(x)dx=1 \\]\n\\[\\int_a^b Cdx=1 \\]\n\\[C=\\frac{1}{b-a} \\]\n此时基础蒙特卡洛估计值(Basic Monte Carlo Estimator)为\n\\[F_N=\\frac{b-a}{N}\\sum_{i=1}^N f(X_i) \\]\n","date":"2022-06-27T15:17:29+08:00","permalink":"https://kegalas.top/inferior/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/","title":"计算机图形学基础学习笔记-数学基础"},{"content":"以Hugo站点为根目录，首先将\\themes\\hugo-theme-stack\\layouts\\partials\\sidebar\\中的left.html复制到\\layouts\\partials\\sidebar\\中。\n然后修改复制后的文件，如下图。\n1.jpg\r第41行中选中的部分原来是relLangURL，改成absURL。\n不过这个方法是否会导致其他问题还有待观察。\n","date":"2022-06-25T23:46:57+08:00","image":"https://kegalas.top/p/hugo%E7%9A%84stack%E7%9A%AE%E8%82%A4%E4%B8%AD%E4%BD%BF%E5%BE%97mailto%E8%B6%85%E9%93%BE%E6%8E%A5%E8%83%BD%E5%A4%9F%E7%9B%B4%E6%8E%A5%E6%89%93%E5%BC%80%E7%94%B5%E5%AD%90%E9%82%AE%E4%BB%B6%E5%AE%A2%E6%88%B7%E7%AB%AF/cover_hu378ddc8c04e53c565ec514b2115f7fb1_40855_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/hugo%E7%9A%84stack%E7%9A%AE%E8%82%A4%E4%B8%AD%E4%BD%BF%E5%BE%97mailto%E8%B6%85%E9%93%BE%E6%8E%A5%E8%83%BD%E5%A4%9F%E7%9B%B4%E6%8E%A5%E6%89%93%E5%BC%80%E7%94%B5%E5%AD%90%E9%82%AE%E4%BB%B6%E5%AE%A2%E6%88%B7%E7%AB%AF/","title":"Hugo的Stack皮肤中使得mailto超链接能够直接打开电子邮件客户端"},{"content":"加减法 \\[(a\\pm b)\\%p = [(a\\%p)\\pm (b\\%p)]\\%p \\]\n乘法 \\[(a\\times b)\\%p = [(a\\%p)\\times (b\\%p)]\\%p \\]\n除法 \\[(a/b)\\%p = (a\\times b^{-1})\\%p=[(a\\%p)\\times (b^{-1}\\%p)]\\%p \\]\n其中，\\(b^{-1}\\)是\\(b\\)在模\\(p\\)意义下的乘法逆元。\n","date":"2022-06-25T23:37:59+08:00","permalink":"https://kegalas.top/inferior/%E5%8F%96%E4%BD%99%E8%BF%90%E7%AE%97%E7%9A%84%E5%88%86%E9%85%8D%E5%BE%8B/","title":"取余运算的分配律"},{"content":"[TOC]\n运动学 位移 位移：\\(\\Delta\\bm{r}\\)\n位移的大小：\\(|\\Delta\\bm{r}|\\)\n位矢大小的增量：\\(|\\Delta r|\\)\n其中后两者一般是不相等的，不能搞混。\n速度 平均速度 \\[\\overline{\\bm{v}}=\\frac{\\bm{r}(t+\\Delta t)-\\bm{r}(t)}{\\Delta t}=\\frac{\\Delta\\bm{r}}{\\Delta t} \\]\n平均速度的大小 \\[|\\overline{\\bm{v}}|=\\left|\\frac{\\Delta\\bm{r}}{\\Delta t}\\right| \\]\n同样的一般有\n\\[|\\overline{\\bm{v}}|\\neq\\left|\\frac{\\Delta r}{\\Delta t}\\right| \\]\n瞬时速度 \\[\\bm{v}=\\frac{d\\bm{r}}{dt} \\]\n速度的大小常称速率。\n\\[|\\bm{v}|=\\left|\\frac{d\\bm{r}}{dt}\\right| \\]\n同样一般有\n\\[|\\bm{v}|\\neq \\left|\\frac{dr}{dt}\\right| \\]\n加速度 平均加速度 \\[\\overline{\\bm{a}}=\\frac{\\Delta\\bm{v}}{\\Delta t} \\]\n瞬时加速度 \\[\\bm{a}=\\frac{d\\bm{v}}{dt} \\]\n关于加速度的大小和一般不相等与（）的性质类似于速度，不再介绍。\n直角坐标表示运动 其位移、速度、加速度都可以分成几个坐标分量来计算，总的位移、速度、加速度则是勾股定理的形式，不再介绍。\n自然坐标法表示运动 \\[\\bm{v}=\\frac{ds}{dt}\\bm{\\tau} \\]\n其中\\(\\bm{\\tau}\\)是切向量。\n\\[\\bm{a}_n=a_n\\bm{n}=\\frac{v^2}{r}\\bm{n} \\]\n其中\\(n\\)是法向量，\\(r\\)是曲率半径，曲率半径计算见高数上整理。\n\\[\\bm{a}_\\tau=a_\\tau\\bm{\\tau}=\\frac{dv}{dt}\\bm{\\tau} \\]\n\\[\\bm{a=a}_n+\\bm{a}_\\tau \\]\n圆周运动的角量表示 角坐标 \\[\\theta=\\theta(t) \\]\n角速度和角平均速度 \\[\\overline{\\omega}=\\frac{\\Delta\\theta}{\\Delta t} \\]\n\\[\\omega=\\frac{d\\theta}{dt} \\]\n角加速度和角平均加速度 \\[\\overline{\\beta}=\\frac{\\Delta\\omega}{\\Delta t} \\]\n\\[\\beta=\\frac{d\\omega}{dt}=\\frac{d^2\\theta}{dt^2} \\]\n线速度、加速度与角速度的关系 \\[v=r\\omega\\\\ a_\\tau=r\\beta\\\\ a_n=r\\omega^2 \\]\n坐标系变换 \\[\\bm{v}_a=\\bm{v}_r+\\bm{u} \\]\n即绝对速度等于相对于坐标系的速度与坐标系的绝对速度的矢量和。\n\\[\\bm{a}_a=\\bm{a}_r+\\bm{a}_e \\]\n类似。\n牛顿运动定律 第一定律 \\[R=\\sum_i\\bm{F}_i=0 \\]\n也可以将\\(\\bm{F}\\)写成坐标分量的形式。\n第二定律 \\[\\bm{R}=\\sum_i\\bm{F}_i=\\frac{d(m\\bm{v})}{dt} \\]\n质量为常量时\n\\[\\bm{R}=m\\frac{d\\bm{v}}{dt}=m\\bm{a} \\]\n可以写作坐标分量和切向量、法向量分量的形式。\n第三定律 \\[\\bm{F}_1=\\bm{F}_2 \\]\n刚体的平动 任意时刻，平动刚体上个点的速度、加速度都相同。\n力学 常见的几种力 万有引力 \\[\\bm{F}_{21}=-G\\frac{m_1m_2}{r^2}\\bm{r}^0\\\\ G=6.67\\times10^{-11}\\quad m^2/(kg\\cdot s^2) \\]\n弹性力 \\[F_x=-kx \\]\n摩擦力 静摩擦力\n\\[f_{max}=\\mu_0N \\]\n前者为静摩擦系数，后者为支持力。\n滑动摩擦力\n\\[f=\\mu N \\]\n前者为滑动摩擦系数。\n力矩 \\[M_O=\\bm{r}\\times\\bm{F} \\]\n单位：\\(N\\cdot m\\)\n转动惯量 \\[J_z=\\int_Vr^2dm \\]\n常见物体的转动惯量计算公式 5.2\r平行轴定理 5.11\r\\[J_z'=J_z+Mh^2 \\]\n转动惯量和力矩的关系 \\[M_z=J_z\\beta \\]\n功和能 功 恒力做功 \\[A=\\bm{F}\\cdot\\bm{s}=Fscos\\theta \\]\n变力做功 \\[A=\\int^b_{a(L)}\\bm{F}\\cdot d\\bm{r} \\]\n通常会拆分成对坐标系求曲线积分。\n平均功率 \\[P=\\frac{\\Delta A}{\\Delta t} \\]\n瞬时功率 \\[P=\\frac{dA}{dt} \\]\n\\[P=\\frac{\\bm{F}\\cdot d\\bm{r}}{dt}=\\bm{F}\\cdot \\bm{v}=Fvcos\\theta \\]\n几种常见力的功 重力的功 \\[A=mg(z_1-z_2) \\]\n万有引力的功 \\[A=GmM(\\frac{1}{r_2}-\\frac{1}{r_1}) \\]\n弹性力的功 \\[A=\\frac{1}{2}k\\lambda_1^2-\\frac{1}{2}k\\lambda_2^2 \\]\n动能定理 质点动能定理 \\[dA=d(\\frac{1}{2}mv^2) \\]\n\\[A=\\frac{1}{2}mv_1^2-\\frac{1}{2}mv_2^2 \\]\n质点系动能定理 \\[\\sum_i A_i=E_{k2}-E_{k1} \\]\n势能、机械能守恒定律 保守力 做功只与始末位置有关而与路径无关的力。\n势能 零势能点\\(M_0\\)，空间中的某个点\\(M\\)\n\\[E_p=\\int_M^{M_0}\\bm{F}\\cdot d\\bm{r} \\]\n重力势能 \\[E_p=mgz \\]\n万有引力势能 \\[E_p=-G\\frac{mM}{r} \\]\n弹性势能 \\[A=\\frac{1}{2}kx_1^2-\\frac{1}{2}kx_2^2 \\]\n绕定轴转动刚体的动能、动能定理 动能 \\[E=\\frac{1}{2}J_z\\omega^2 \\]\n力矩的功 \\[A=\\int_{\\theta_1}^{\\theta_2}M_z(\\bm{F})d\\theta \\]\n动能定理 \\[A=\\frac{1}{2}J_z\\omega_2^2-\\frac{1}{2}J_z\\omega_1^2 \\]\n冲量、动量、角动量 质点系动量定理 \\[d(m\\bm{v})=\\bm{F}dt \\]\n\\[\\bm{I}=m\\bm{v}_2-m\\bm{v}_1=\\int^{t_2}_{t_1}\\bm{F}dt \\]\n如果是恒力\n\\[m\\bm{v}_2-m\\bm{v}_1=\\bm{F}(t_2-t_1) \\]\n质点系动量定理 \\[\\sum_i m_i\\bm{v}_i-\\sum_i m\\bm{v}_{i0}=\\sum_i\\int^{t}_{t_0}\\bm{F}_i dt \\]\n质点系动量守恒定律 作用在质点系上的所有外力的矢量和为零，则该质点系的动量保持不变。\n如果某个方向的矢量和为零，则这个方向上的动量保持不变。\n\\[\\sum_i m_i\\bm{v}_{ix}=C \\]\n\\(C\\)是常量\n质心、质心运动定理 质心位置 见高数下整理\n质心运动定理 质点系质心的运动，可以看成为一个质点的运动，这个质点集中了整个质点系的质量，也集中了质点系收到的所有外力。\n动量矩和动量矩守恒定律 动量矩 \\[\\bm{L}_O=\\bm{r}\\times m\\bm{v} \\]\n\\[L_z=J_z\\omega \\]\n动量矩定理 \\[\\frac{d\\bm{L_O}}{dt}=\\bm{r}\\times\\bm{F}=\\bm{M}_O \\]\n动量矩守恒定律 当作用在质点上的合理对固定点之矩总是为零时，质点动量对该点的矩为常矢量。即\n\\[\\bm{M}_O=0\\Rightarrow \\bm{L}_O=\\bm{C} \\]\n\\(\\bm{C}\\)是常矢量。\n刚体绕定轴转动的动量矩定理 \\[(J_z\\omega)_t-(J_z\\omega)_{t_0}=\\int^t_{t_0}M_zdt \\]\n刚体绕定轴转动的动量矩守恒定律 \\[M_z=0\\Rightarrow J_z\\omega=C \\]\n机械振动 简谐振动 \\[x=Acos(\\omega t+\\varphi) \\]\n\\[v=\\overset{\\cdot}{x}=-A\\omega sin(\\omega t+\\varphi) \\]\n\\[a=\\overset{\\cdot\\cdot}{x}=-A\\omega^2 cos(\\omega t+\\varphi) \\]\n对于弹簧振子的周期：\n\\[T=\\frac{2\\pi}{\\omega}=2\\pi\\sqrt{\\frac{m}{k}} \\]\n对于单摆的周期：\n\\[T=2\\pi\\sqrt{\\frac{l}{g}} \\]\n弹簧串联并联和弹性系数 串联 \\[k=\\frac{k_1k_2}{k_1+k_2} \\]\n并联 \\[k=k_1+k_2 \\]\n注：有一种两根弹簧中间连了物体的，是一种并联。\n谐振动的能量 \\[E=\\frac{1}{2}kA^2 \\]\n一个周期内，动能和势能的平均大小：\n\\[\\overline{E_p}=\\frac{1}{4}kA^2 \\]\n\\[\\overline{E_k}=\\frac{1}{4}kA^2 \\]\n谐振动的合成 同方向，同频率的合成 频率不变\n\\[A=\\sqrt{A_1^2+A_2^2+2A_1A_2cos(\\varphi_2-\\varphi_1)} \\]\n\\[\\varphi = arctan\\frac{A_1sin\\varphi_1+A_2sin\\varphi_2}{A_1cos\\varphi_1+A_2cos\\varphi_2} \\]\n同方向不同频率的合成 \\[A=\\sqrt{A_1^2+A_2^2+2A_1A_2cos(\\omega_2-\\omega_1)t} \\]\n\\[\\tau=\\frac{2\\pi}{|\\omega_2-\\omega_1|} \\]\n\\[\\nu=\\frac{|\\omega_2-\\omega_1|}{2\\pi}=|\\nu_2-\\nu_1| \\]\n\\(\\nu\\)为拍频。\n两个相互垂直谐振动的合成 根据参数方程求出平面解析式。\n机械波 机械波的产生和传播 拉紧的绳子，横波的波速为\n\\[u_t=\\sqrt{\\frac{T}{\\mu}} \\]\n其中\\(T\\)是绳子的张力，\\(\\mu\\)是线密度。\n平面简谐波 波函数 正向传播：\n\\[y(x,t)=Acos\\left[\\omega\\left(t-\\frac{x}{u}\\right)+\\varphi_0\\right] \\]\n或者写成\n\\[y(x,t)=Acos\\left[2\\pi\\left(\\frac{t}{T}-\\frac{x}{\\lambda}\\right)+\\varphi_0\\right] \\]\n负向传播：\n\\[y(x,t)=Acos\\left[\\omega\\left(t+\\frac{x}{u}\\right)+\\varphi_0\\right] \\]\n波的能量 能量 设绳子每单位长度的质量为\\(\\mu\\)，线元总机械能：\n\\[W=W_k+W_p=\\mu\\Delta xA^2\\omega^2sin^2\\left[\\omega\\left(t-\\frac{x}{u}\\right)+\\varphi_0\\right] \\]\n能量密度 把单位体积中波的能量称为波的能量密度：\n\\[w=\\frac{W}{\\Delta V}=\\frac{W}{\\Delta x\\Delta S}=\\rho A^2\\omega^2sin^2\\left[\\omega\\left(t-\\frac{x}{u}\\right)+\\varphi_0\\right] \\]\n能流密度（波的强度） \\[I=\\overline{w}u \\]\n\\[I=\\frac{1}{2}\\rho A^2\\omega^2u \\]\n\\[\\bm{I}=\\overline{w}\\bm{u} \\]\n\\[w_{max}=2\\overline{w} \\]\n\\[I=\\frac{P}{S} \\]\n其中\\(P\\)是功率，\\(S\\)是波面面积。\n平面波和球面波的振幅 平面简谐波在理想无吸收的、均匀媒质中传播时振幅不变。\n球面波在均匀、无吸收媒质中传播，有\n\\[\\frac{A_1}{A_2}=\\frac{r_2}{r_1} \\]\n即该点的振幅和到波源的距离成反比\n波的吸收 \\[I=I_0e^{-ax} \\]\n波的干涉 干涉条件：频率相同、振动方向相同、相位差恒定。\n\\[A^2=A_1^2+A_2^2+2A_1A_2cos\\Delta\\varphi \\]\n\\[I=I_1+I_2+2\\sqrt{I_1I_2}cos\\Delta\\varphi \\]\n其中上面两式中\n\\[\\Delta\\varphi=(\\varphi_2-\\varphi_1)-2\\pi\\frac{r_2-r_1}{\\lambda} \\]\n如果两个波源的初相位相同，则\\(\\Delta\\varphi\\)只取决于波程差\\(\\delta=r_1-r_2\\)，于是干涉相长的条件为：\n\\[\\delta=r_1-r_2=\\pm k\\lambda,\\quad k=0,1,2,\\cdots \\]\n干涉相消的条件为：\n\\[\\delta=r_1-r_2=\\pm (2k+1)\\frac{\\lambda}{2},\\quad k=0,1,2,\\cdots \\]\n驻波 形成驻波的条件： \\[L=n\\frac{\\lambda}{2},\\quad n=1,2,3,\\cdots \\]\n驻波波函数 \\[y=2Acos2\\pi\\frac{x}{\\lambda}\\cdot cos2\\pi\\nu t \\]\n多普勒效应 波源\\(S\\)静止，观察者相对于波源的速度为\\(v_O\\)，靠近为正值，远离为负值。则观察者接收到的频率为： \\[\\nu=(1+\\frac{v_O}{u})\\nu_0 \\]\n观察者静止，波源相对于观察者的速度为\\(v_S\\)，靠近为正值，远离为负值。则观察者接收到的频率为： \\[\\nu=\\frac{u}{u-v_S}\\nu_0 \\]\n波动光学 光的干涉 相干叠加的条件：频率相同、光矢量振动方向平行、相位差恒定。\n杨氏双缝干涉 干涉加强的条件：\n\\[\\delta=\\pm 2k\\frac{\\lambda}{2} \\]\n干涉相消的条件：\n\\[\\delta=\\pm(2k+1)\\frac{\\lambda}{2} \\]\n屏上相邻明条纹或相邻暗条纹之间的间距为\n\\[\\Delta x=\\frac{D\\lambda}{d} \\]\n\\(D\\)是双缝到屏的距离，\\(d\\)是双缝间距。\n洛埃镜 半波损失的条件：\n波从波疏介质射向波密介质时反射过程中，反射波会相对于入射波有相位突变\\(\\pi\\)\n光程与光程差 数值上，光程等于介质折射率乘以光在介质中传播的路程，经过多重介质时，光程\\(=\\sum_in_ir_i\\)\n光程差：\n\\[\\delta=n_2r_2-n_1r_1 \\]\n薄膜干涉 等厚干涉 干涉图样中同一干涉条纹对应于薄膜上厚度相同点的连线，这种条纹称为等厚干涉条纹。\n劈尖干涉 显然要考虑半波损失，假设为垂直入射，则明条纹的条件为\n\\[\\delta=2d+\\frac{\\lambda}{2}=2k\\frac{\\lambda}{2},\\quad k=1,2,3,\\cdots \\]\n暗条纹的条件是\n\\[\\delta=2d+\\frac{\\lambda}{2}=(2k+1)\\frac{\\lambda}{2},\\quad k=0,1,2,\\cdots \\]\n牛顿环 \\(R\\)是平凸透镜的曲率半径，\\(r\\)是条纹半径。\n明条纹：\n\\[r=\\sqrt{(2k-1)\\frac{R\\lambda}{2}},\\quad k=1,2,3,\\cdots \\]\n暗条纹：\n\\[r=\\sqrt{k\\lambda R} \\]\n等倾干涉 因干涉图样中同一干涉条纹是来自薄膜表面的等倾角光纤经透镜聚焦后的轨迹，故称为等倾干涉条纹。\n迈克尔逊干涉仪 若视场从最亮到第\\(N\\)次最亮出现时，反光镜移动的距离为\n\\[\\Delta d=N\\frac{\\lambda}{2} \\]\n相干长度 两个分光束产生干涉效应的最大光程差\\(\\delta_m\\)为波列长度\\(L\\)，称为相干长度\n相干时间 \\[\\Delta t=\\frac{\\delta_m}{c} \\]\n惠更斯-菲涅尔原理 同一波前上各点发出的次波是相干波，经过传播在空间某点相遇时的叠加是相干叠加。\n单缝的夫琅禾费衍射 菲涅尔半波带法研究分布 \\(a\\)是夹缝宽度\n暗条纹：\n\\[asin\\varphi = \\pm 2k\\frac{\\lambda}{2},\\quad k=1,2,3,\\cdots \\]\n明条纹：\n\\[asin\\varphi=\\pm(2k+1)\\frac{\\lambda}{2},\\quad k=1,2,3,\\cdots \\]\n其中中央零级明条纹：\n\\[asin\\varphi=0 \\]\n中央明纹的宽度是\n\\[-\\lambda \u003c asin \\varphi \u003c \\lambda \\]\n当\\(\\varphi\\)很小时，有\\(sin\\varphi\\approx\\varphi\\approx\\frac{\\lambda}{a}\\)\n振幅矢量合成法研究强度 假设中央明纹的光强为\\(I_0\\)，则某一点\\(P\\)的光强为\n\\[I=I_0\\left(\\frac{sinu}{u}\\right)^2 \\]\n艾里斑 \\[\\theta_0\\approx sin\\theta_0=1.22\\frac{\\lambda}{D} \\]\n\\(D\\)是圆孔直径。\n衍射光栅及光栅光谱 刻痕间距为\\(a\\)，刻痕宽度为\\(b\\)，则\\(d=a+b\\)称为光栅常数。\\(N\\)是光栅的缝数，\\(n\\)是光栅一定长度内的缝数，单位通常为条/\\(mm\\)。并且有\\(d=1/n\\)\n光栅方程 光栅方程，或衍射明条纹的条件如下（只考虑干涉而不考虑各个缝的衍射的情况）\n\\[(a+b)sin\\varphi=\\pm k\\lambda,\\quad k=0,1,2,\\cdots \\]\n主极大条纹 满足光栅方程的明条纹称为主极大条纹。\n缺级 现在来考虑各个缝的衍射。\n同时满足\n\\[(a+b)sin\\varphi=\\pm k\\lambda \\]\n和\n\\[asin\\varphi=\\pm k'\\lambda,\\quad k'=1,2,\\cdots \\]\n的为光谱线的缺级\n缺级的级数为\n\\[k=k'\\frac{a+b}{a} \\]\n暗纹条件 \\[N(a+b)sin\\varphi=\\pm m\\lambda \\]\n其中\\(m=1,2,\\cdots,(N-1),(N+1),\\cdots,(2N-1),(2N+1),\\cdots\\)，即除去\\(N\\)的整倍数。\n易知，两个主极大条纹间有\\((N-1)\\)条暗纹，以及\\((N-2)\\)条次级大。\n线偏振光、自然光 线偏振光 光矢量只限于单一方向振动的光。\n自然光 无论哪一个方向的振动都不比其他方向占优势。\n偏振片的起偏和检偏、马吕斯定律 起偏和检偏 自然光获得偏振光的过程叫起偏。\n对偏振光透过偏振片的角度的观察叫检偏。\n马吕斯定律 \\[I=I_0cos^2\\alpha \\]\n对于自然光透过偏振片\n\\[I=I_0/2 \\]\n反射和折射产生的偏振、布儒斯特定律 反射和折射产生的偏振 反射光为偏振方向垂直入射面成分较多的部分偏振光。\n布儒斯特定律 当入射角\\(i\\)与反射角\\(\\gamma\\)之和为\\(90\\degree\\)时，反射光称为光矢量与入射面垂直的完全偏振光。\n公式表示为\n\\[tani=\\frac{n_2}{n_1} \\]\n双折射现象 晶体的双折射现象：\n其中一束折射光始终在入射面内，并遵守折射定律，称为寻常光，简称\\(o\\)光。另一束折射光一般不在入射面内，且不遵守折射定律，称为非常光，简称为\\(e\\)光。\n热力学 平衡态、理想气体状态方程 \\[t=T-273.15 \\]\n理想气体状态方程（克拉伯龙方程）：\n\\[pV=\\nu RT \\]\n注，大学物理一般用\\(n\\)表示分子数密度，而用\\(\\nu\\)表示物质的量\n功、热量、内能、热力学第一定律 绝热过程中外界对系统做功，则内能变化为\n\\[E_2-E_1=A_Q \\]\n假设外界不对系统做功，系统内能变化和外界给系统的热量的关系：\n\\[E_2-E_1=Q \\]\n热力学第一定律\n\\[Q=(E_2-E_1)+A \\]\n即系统从外界吸收能力，一部分转化为内能，一部分则对外界做功\n对于无限小的变化过程\n\\[dQ=dE+dA \\]\n准静态过程中功和热量的计算 功 在一个有限的准静态过程中，当气体的体积变化时，气体对外界所做的功为\n\\[A=\\int_{V_1}^{V_2}pdV \\]\n应用上述结果，热力学第一定律可以表示为\n\\[Q=(E_2-E_1)+\\int_{V_1}^{V_2}pdV \\]\n热量、热容 \\[Q=mc(T_2-T_1) \\]\n\\(c\\)是物体的比热容。不同物质的比热容值不同，并且同一物质的比热容值一般随温度而变。但在温度变化不大时，可以看做常量。\n假定\\(1mol\\)气体在等体过程中温度升高\\(\\Delta T\\)时，吸收的热量为\\(Q_V\\)，则气体的摩尔定体热容定义为\n\\[C_V=\\lim\\limits_{\\Delta T\\to 0}\\frac{Q_V}{\\Delta T}=\\left(\\frac{dE}{dT}\\right)_V \\]\n假定\\(1mol\\)气体在等压过程中温度升高\\(\\Delta T\\)时，吸收的热量为\\(Q_p\\)，则气体的摩尔定压热容定义为\n\\[C_V=\\lim\\limits_{\\Delta T\\to 0}\\frac{Q_p}{\\Delta T}=\\left(\\frac{dE}{dT}\\right)_p+p\\left(\\frac{dV}{dT}\\right)_p \\]\n理想气体的内能和\\(C_V\\)、\\(C_p\\) 气体的内能仅仅是其温度的函数，与体积等无关\n\\[E=E(T) \\]\n\\[C_p=C_V+R \\]\n即迈耶公式，单位一般为\\(J/(mol\\cdot K)\\)，\\(R=8.31\\)\n比热容比：\n\\[\\gamma=\\frac{C_p}{C_V} \\]\n对单原子分子\n\\[C_V\\approx \\frac{3}{2}R \\]\n对双原子气体分子\n\\[C_V\\approx \\frac{5}{2}R \\]\n热力学第一定律对理想气体在典型准静态过程中的应用 等体过程 \\[Q_V=E_2-E_1=\\nu C_V(T_2-T_1) \\]\n由克拉伯龙公式\n\\[Q_V=\\frac{V}{R}C_V(p_2-p_1) \\]\n等压过程 \\[A=p(V_2-V_1)=\\nu R(T_2-T_1) \\]\n\\[Q_p=vC_p(T_2-T_1) \\]\n\\[E_2-E_1=Q_p-A=\\nu C_V(T_2-T_1) \\]\n等温过程 等温膨胀过程中，吸收的热量全部用来对外做功\n\\[Q_T=A=\\nu RTln\\frac{p_1}{p_2} \\]\n绝热过程 绝热过程中\\(Q=0\\)，所以有\\(A=E_1-E_2=-vC_V(T_2-T_1)\\)\n\\[A=\\frac{1}{\\gamma-1}(p_1V_1-p_2V_2)=-\\frac{\\nu R}{\\gamma-1}(T_2-T_1) \\]\n循环过程 循环过程 \\[A=Q_1-Q_2 \\]\n循环效率 \\[\\eta=\\frac{A}{Q_1}=1-\\frac{Q_2}{Q_1} \\]\n制冷系数 \\[w=\\frac{Q_2}{A} \\]\n绝对零度不可达原理 不可能用有限的步骤使物体达到绝对零度。\n热力学第二定律 开尔文表述 不可能只从单一热源吸收热量，使之完全转化为功而不引起其他变化。\n克劳修斯表述 不可能使热量从低温物体传向高温物体而不引起其他变化。\n可逆与不可逆过程 如果过程的每一步都可沿相反的方向进行，同时不引起外界的任何变化，则称可逆过程。对于某一过程，用任何方法都不能使系统和外界恢复到原来状态，称为不可逆过程。\n热力学第二定律揭示了，自然界的一切自发过程都是单方向进行的不可逆过程。\n卡诺热机 卡诺循环 两个等温过程和两个绝热过程组成。\n\\[\\eta = 1-\\frac{T_2}{T_1} \\]\n\\[w=\\frac{T_2}{T_1-T_2} \\]\n卡诺定理 温度为\\(T_1,T_2\\)的两个给定热源之间工作的一切可逆热机，效率相同，都等于理想气体可逆卡诺热机的效率。这两个热源之间工作的一切不可逆热机，其效率都不可能大于卡诺热机。\n气体动理论 气体分子的热运动 平衡状态下，平均速度\n\\[\\overline{v_x}=\\overline{v_y}=\\overline{v_z}=0 \\]\n统计平均值为\n\\[\\overline{v^2_j}=\\frac{\\sum_i\\Delta N_iv^2_{ij}}{N},\\quad j=x,y,z \\]\n且有\n\\[\\overline{v^2_x}=\\overline{v^2_y}=\\overline{v^2_z}=\\overline{v^2}/3 \\]\n大量分子平均平动动能的统计平均值为\n\\[\\overline{\\varepsilon}=\\frac{1}{2}\\mu\\overline{v^2}=\\frac{\\mu\\sum_i\\Delta N_iv^2_{i}}{2N} \\]\n其中\\(\\mu\\)为一个分子的质量\n理想气体的压强公式 \\[p=\\frac{2}{3}n(\\frac{1}{2}\\mu\\overline{v^2})=\\frac{2}{3}n\\overline{\\varepsilon} \\]\n麦克斯韦速度分布定律 麦克斯韦速度分布定律 \\[f(v)=4\\pi\\left(\\frac{\\mu}{2\\pi kT}\\right)^{3/2}v^2e^{-\\frac{\\mu v^2}{2kT}} \\]\n其中\n\\[k=\\frac{R}{N_A}=\\frac{8.31}{6.022\\times 10^{23}}=1.38\\times 10^{-23} J/K \\]\n称为玻尔兹曼常数。\n\\[\\frac{dN}{N}=f(v)dv \\]\n\\[\\int_0^\\infty f(v)dv=1 \\]\n分子速率的三种统计平均值 \\[\\overline{v}=\\sqrt\\frac{8kT}{\\pi\\mu}=1.59\\sqrt{\\frac{RT}{M}} \\]\n\\[\\sqrt{\\overline{v^2}}=\\sqrt\\frac{3kT}{\\mu}=1.73\\sqrt{\\frac{RT}{M}} \\]\n\\[v_p=\\sqrt\\frac{2kT}{\\mu}=1.41\\sqrt{\\frac{RT}{M}} \\]\n温度的微观本质 \\[\\overline{\\varepsilon}=\\frac{1}{2}\\mu\\overline{v^2}=\\frac{3}{2}kT \\]\n能量按自由度均分定理 能量按自由度均分定理 处于平衡态的理想气体分子，无论作何种运动，相应于分子每个自由度的平均动能都相等，并且都等于\\(kT/2\\)。\n如果气体分子有\\(i\\)个自由度，那么每个分子的平均总动能为\\(ikT/2\\)\n理想气体的内能 \\(1mol\\)气体中有\\(N_0\\)个分子，若不考虑振动能量，则\\(1mol\\)理想气体的内能为\n\\[E=N_0\\frac{i}{2}kT=\\frac{i}{2}RT \\]\n气体的摩尔热容 \\[C_V=\\frac{i}{2}R \\]\n\\[C_p=\\frac{(i+2)}{2}R \\]\n\\[\\gamma=\\frac{i+2}{i} \\]\n玻尔兹曼分布律 \\[n=n_0e^{-\\frac{\\varepsilon_p}{kT}} \\]\n\\(n_0\\)是零势能面的分子数密度。\n可以推知\n\\[p=nkT=p_0e^{-\\frac{\\varepsilon_p}{kT}} \\]\n分子的平均自由程 平均碰撞频率 \\[\\overline{z}=\\sqrt{2}\\pi d^2\\overline{v}n \\]\n分子的平均自由程 \\[\\overline{\\lambda}=\\frac{\\overline{v}}{\\overline{z}}=\\frac{1}{\\sqrt{2}\\pi d^2n}=\\frac{kT}{\\sqrt{2}\\pi d^2p} \\]\n静电场 电荷、库仑定律 电荷守恒定律\n在一个封闭系统内，不论进行怎样的变化过程，系统内正负电荷量的代数和保持不变。\n基尔霍夫第一定律\n根据电荷守恒定律，在稳恒电路中，节点处各支路电流的代数和应该为零。\n库伦定律\n在真空中两个静止点电荷之间的静电作用力为：\n\\[F=\\frac{1}{4\\pi\\varepsilon_0}\\frac{q_1q_2}{r^2} \\]\n作用力的方向沿着两个点电荷的连线。\n其中\\(q_1,q_2\\)是两个点电荷的电量，\\(r\\)是它们之间的距离。\\(\\varepsilon_0\\)是真空电容率，或者叫真空介电常数。其值为\\(8.854187817\\times 10^{-12} F/m\\)\n用向量来表示，则有\n\\[\\bm F = \\frac{1}{4\\pi\\varepsilon_0}\\frac{q_1q_2}{r^2} \\bm r^0 \\]\n电场 静电力是通过电场来传递的。电荷\\(q_1\\)对\\(q_2\\)施加的力是通过\\(q_1\\)产生的电场来传播的。并且这个电场不会对自身有作用力。\n电场的传播速度是光速。\n电场中某点的电场强度E的大小等于单位电荷在该点受力的大小，其方向为正电荷在该点受力的方向。\n\\[\\bm E=\\frac{\\bm F}{q_0} \\]\n电场强度叠加原理\n点电荷系在某点\\(P\\)产生的电场的电场强度等于各点电荷单独在该点产生的电场强度的矢量和。\n电偶极矩\n两个大小相等的异号点电荷\\(+q\\)和\\(-q\\)，相距为\\(l\\)，如果要计算电场强度的各场点相对这一对电荷的距离\\(r\\)比\\(l\\)大很多（\\(r\u003e\u003el\\)），这样一对点电荷称为电偶极子。定义\n\\[\\bm p = q\\bm l \\]\n为电偶极子的电偶极矩，\\(\\bm l\\)的方向规定为由负电荷指向正电荷。\n一些常见带电体产生的电场强度 10.1-1.jpg\r10.1-2.jpg\r电通量、高斯定理 电场线 形象描述场强分布的空间曲线。\n曲线上每一点的切斜方向为电场方向\n通过垂直于电场方向单位面积电场线数为该点电场强度的大小。\n特点\n始于正电荷（或无穷远），终于负电荷（或无穷远），不会在没有电荷的地方中断 若体系正负电荷一样多，则正电荷发出的电场线全部终止与负电荷 电场线不是闭合曲线，电场线不会相交。 电通量 穿过某一有向曲面的电场线条数，称为通过该面的电通量，用\\(\\varPhi_e\\)表示。\n\\[d\\varPhi_e=E_ndS=Ecos\\theta dS \\]\n直观上理解，就是将这个微小平面投影到垂直于电场线的平面上。用向量表示为\n\\[d\\varPhi_e = \\bm E\\cdot d\\bm S \\]\n积分得\n\\[\\varPhi_e=\\int d\\varPhi_e = \\int_S\\bm E\\cdot d\\bm S \\]\n高斯定理 真空中的任何静电场中，穿过任一闭合曲面的电通量，在数值上等于该闭合曲面内包围的电量的代数和乘以\\(1/\\varepsilon_0\\)。\n显然可以推知，如果高斯面内不包围电荷，电荷在它的外面，则电通量为0.\n对于不连续分布的源电荷\n\\[\\varPhi_e=\\oint_S\\bm E\\cdot d\\bm S=\\frac{1}{\\varepsilon_0}\\sum_{(内)}q_i \\]\n对于连续分布的源电荷\n\\[\\varPhi_e=\\oint_S\\bm E\\cdot d\\bm S=\\int_V\\frac{1}{\\varepsilon_0}\\rho dV \\]\n很容易联想到能否用这个公式反过来求电场强度。对于一般的电场很难来求，但是对于一些对称的电荷分布来说，是可以使用的。具体案例见教材。\n静电场的环路定理、电势能 静电力的功\n设一正的实验电荷\\(q_0\\)在静止的点电荷\\(q\\)产生的电场中，由\\(a\\)点经过某一路径\\(L\\)移动到\\(b\\)点，则静电力对\\(q_0\\)做功为\n\\[A_{ab}=\\int^b_{a(L)}\\bm F\\cdot d\\bm l=\\int^b_{a(L)}q_0\\bm E\\cdot d\\bm l \\]\n\\[=\\frac{qq_0}{4\\pi\\varepsilon_0}\\int^{r_b}_{r_a}\\frac{1}{r^2}dr=\\frac{qq_0}{4\\pi\\varepsilon_0}\\left(\\frac{1}{r_a}-\\frac{1}{r_b}\\right) \\]\n显然可知，这个功只取决于初末位置，而与路径无关。\n可以扩展到任何静电场。\n静电场的环路定理\n从上文可以得知，在静电场中，电场强度沿任一闭合路径的线积分（或称电场强度的环流）恒为零。静电场是无旋有源场，静电场的电场线不可能是闭合的。静电场是保守场。\n电势能\n电荷在电场中某点的电势能，在量值上等于把电荷从该点移动到电势能零参考点时，静电力所做的功\n\\[W_a=A_{a\"0\"}=\\int^{\"0\"}_aq_0\\bm E\\cdot d\\bm l \\]\n电势、电势差 电场中某点的电势，其量值等于单位正电荷在该点所具有的电势能。\n\\[u_a=\\frac{W_a}{q_0} \\]\n电场中某点的电势，其量值等于把单位正电荷从该点沿任意路径移动到电势能零参考点时，静电力所做的功。\n\\[u_a = \\frac{A_{a\"0\"}}{q_0}=\\int^{\"0\"}_a\\bm E\\cdot d\\bm l \\]\n由电势的定义可知，电势差可以表示为\n\\[U_{ab}=\\frac{W_a}{q_0}-\\frac{W_b}{q_0}=\\frac{A_{ab}}{q_0}=\\int^b_a\\bm E\\cdot d\\bm l \\]\n电场中\\(a,b\\)两点的电势差，在量值上等于把单位正电荷从\\(a\\)移动到\\(b\\)时，静电力所做的功。电势差与电势的零参考点的选择无关。\n可以计算电势能如下\n\\[W_a=qu_a \\]\n可以计算电场做功如下\n\\[A_{ab}=q(u_a-u_b) \\]\n电势叠加原理\n在点电荷系产生的电场中，某点的电势是各个点电荷单独存在时，在该点产生的电势的代数和。\n常见带电体产生的电势（以无穷远为电势零点） 10.2.jpg\r等势面 类似于用电场线来描绘电场强度的空间分布，也可以用等势面来描绘电势的空间分布。\n电势值相等的点联成的面称为等势面。\n在静电场中，电场线与等势面处处正交。\n电势与电场强度的关系 \\[E=-\\frac{du}{dn} \\]\n此式说明在任意一场点\\(P\\)处，电场强度的大小等于沿过该点等势面法线方向上电势的变化率。\n而\n\\[E_l=-\\frac{du}{dl} \\]\n表明，电场强度在\\(d\\bm l\\)方向的投影等于电势沿该方向变化率的负值。\n而显然有\\(dl\\geq dn\\)，所以\n\\[\\frac{du}{dl}\\leq\\frac{du}{dn} \\]\n即电势沿等势面法线方向的变化率最大。\n电场强度也可以表示为\n\\[\\bm E = E_x+E_y+E_z = -\\left(\\frac{\\partial u}{\\partial x}\\bm i+\\frac{\\partial u}{\\partial y}\\bm j+\\frac{\\partial u}{\\partial z}\\bm k\\right) \\]\n导体的静电平衡 当导体内部的电场强度处处为零，导体上的电势处处相等时，导体达到静电平衡状态。\n静电平衡的导体有以下性质\n其表面上任意一点的电场强度方向与该点处导体表面垂直。并且设该处导体表面上电荷面密度为\\(\\sigma\\)，则 \\[\\bm E = \\frac{\\sigma}{\\varepsilon_0}\\bm n \\]\n对于静电平衡状态的带电导体，未被抵消的净电荷只能分布在导体的表面上。 处于静电平衡状态的孤立导体，其表面上电荷密度的大小与表面的曲率有关。 电介质 电介质是指在通常条件下导电性能极差的物质，例如云母、变压器油等。电工中一般认为电阻率超过\\(10^8\\Omega\\cdot m\\)的物质为电介质。\n除了具有电气绝缘性能外，在电场作用下的电极化是它的一个重要特性。\n电容为\\(C_0\\)的平行板电容器（边缘效应不计），充电后两基板间电势差为\\(U_0\\)，这时极板上的电荷量为\\(Q_0=C_0U_0\\)。断开电源，并在两极板间注满各向同性的均匀电介质，再测量两极板间电势差，发现\n\\[U = \\frac{U_0}{\\varepsilon_r} \\]\n并且同时有\n\\[E = \\frac{E_0}{\\varepsilon_r} \\]\n由于电荷量\\(Q_0\\)不变。所以有\n\\[C = \\frac{Q_0}{U} = \\frac{\\varepsilon_rQ_0}{U_0}=\\varepsilon_rC_0 \\]\n其中\\(\\varepsilon_r\\)对于各向同性的均匀电介质为一常数，称为该介质的相对介电常数，是无量纲量。\n电介质分子的电结构 根据分子电结构的不同，可把电介质分为两类：\n无极分子。指分子中负电荷对称地分布在正电荷周围，以致在无外电场作用时，分子的正负电荷中心重合，分子无电偶极矩。无外电场作用时，对外呈现电中性。 有极分子。在无外电场作用时，分子的正负电荷中心不重合。这时，等量的分子正负电荷形成电偶极子，具有电偶极矩\\(\\bm p\\)。在无外电场作用时，由于分子的不规则热运动，各分子电偶极矩取向杂乱无章，因此宏观上也呈现电中性。 电介质的极化、束缚电荷 将有极分子电介质放在均匀外电场中，各分子的电偶极子受到外电场力偶的作用，都要转向外电场方向，并有序地排列起来。\n由于分子的热运动，这种分子电偶极子的排列不可能是整齐的。然而，从总体来看，这种转向排列的结果，使电介质沿电场方向前后两个侧面分别出现正负电荷。\n这种不能在电介质内自由移动，也不能离开电介质表面的电荷，称为束缚电荷。\n在外电场作用下，电介质分子的电偶极矩趋于外电场方向排列，结果在电介质的侧面出现束缚电荷的现象称为电介质的极化现象。有极分子电介质的极化常称为取向极化。\n将无极分子电介质放在外电场中，由于分子中的正负电荷受到相反方向的电场力，因而正负电荷中心将发生微小的相对位移，从而形成电偶极子，其电偶极矩将沿外电场方向排列起来。\n这时，沿外电场方向电介质的前后两侧面也将分别出现正负束缚电荷，这也是一种电介质的极化现象。无极分子电介质的极化常称为位移极化。\n一般来说，外电场越强，极化现象越显著，电介质两侧面束缚电荷的面密度也就越大，电极化程度也就越高。\n另外，在各向同性均匀电介质内部的任何体积元内，都不会有净束缚电荷。\n电介质内的电场强度 在电介质内部，合电场强度\\(E\\)总是小于自由电荷产生的电场强度\\(E_0\\)\n电介质内任意一点的电场强度\\(\\bm E\\)，应等于极板上自由电荷在该点产生的电场强度\\(\\bm E_0\\)与分布在电介质两平行端面上的束缚电荷在该点产生的电场强度\\(\\bm E'\\)的矢量和，即\n\\[\\bm E = \\bm E_0+\\bm E' \\]\n\\[E = \\frac{\\sigma_0}{\\varepsilon_0}-\\frac{\\sigma '}{\\varepsilon_0} \\]\n如果电介质满足\n\\[E=\\frac{E_0}{\\varepsilon_r} \\]\n则一定要有该各向同性的均匀电介质要充满电场所在空间。进一步研究表明，各向同性均匀电介质虽未充满电场所在空间，但只要电介质的表面是等势面，上式就成立。\n另外上式和上上式可以得出\n\\[\\sigma'=(1-\\frac{1}{\\varepsilon_r})\\sigma_0 \\]\n电介质中的高斯定理、电位移矢量D 在平板电容器中，作一封闭圆柱形高斯面，使得面积为\\(S\\)的两个端面平行于电容器极板，且一个端面在导体极板内，另一个在电介质中。\n设自由电荷和束缚电荷面密度分别为\\(\\sigma_0,\\sigma'\\)，对所作高斯面应用高斯定理，有\n\\[\\oiint_S \\bm E\\cdot d\\bm S = \\frac{1}{\\varepsilon_0}(\\sigma_0-\\sigma')S \\]\n但是\\(\\sigma'\\)通常难以预先知道，所以上式不方便使用。\n而（电介质充满时）\n\\[\\sigma'=(1-\\frac{1}{\\varepsilon_r})\\sigma_0 \\]\n所以有\n\\[\\frac{1}{\\varepsilon_0}(\\sigma_0-\\sigma')=\\frac{\\sigma_0}{\\varepsilon_0\\varepsilon_r} \\]\n代入得\n\\[\\oiint_S \\bm E\\cdot d\\bm S = \\frac{\\sigma_0}{\\varepsilon_0\\varepsilon_r}S \\]\n或者写成\n\\[\\oiint_S \\varepsilon_0\\varepsilon_r\\bm E\\cdot d\\bm S = \\sigma_0S = q_0 \\]\n令\n\\[\\bm D = \\varepsilon_0\\varepsilon_r\\bm E \\]\n称为电位移矢量（又称电通密度）\n最后可以写成\n\\[\\oiint_S\\bm D\\cdot d\\bm S = q_0 \\]\n通过任意闭合曲面\\(S\\)的总电位移通量，等于该比和曲面所包围的自由电荷量的代数和，与束缚电荷以及闭合曲面之外的自由电荷无关。\n孤立导体的电容 一个带电量为\\(q\\)的孤立导体，在静电平衡时，具有一定的电势\\(u\\)。当带电量增加时，电势也增加，且比值不变\n\\[C=\\frac{q}{u} \\]\n其中\\(C\\)是和\\(u,q\\)无关的常量，值只取决于导体的大小形状等因素。\n电容器的电容 若电容器两极板上分别带电量为\\(+q,-q\\)，两极板间的电势差为\\(u_1-u_2\\)，则\n\\[C=\\frac{q}{u_1-u_2} \\]\n并且可以推导出，若两极板相对面积为\\(S\\)，相距\\(d\\)，则有\n\\[C=\\frac{\\varepsilon_0 S}{d} \\]\n如果充入电介质，其相对介电常数为\\(\\varepsilon_r\\)\n\\[C=\\frac{\\varepsilon_0\\varepsilon_r S}{d} \\]\n电容器的串并联 串联\n\\[\\frac{1}{C} = \\frac{1}{C_1}+\\frac{1}{C_2}+\\frac{1}{C_3}+\\cdots \\]\n电容越串越小，但是耐压值提高了\n并联\n\\[C=C_1+C_2+C_3+\\cdots \\]\n电容越并越大，但是耐压值不会改变。\n静电能 电极板上迁移电荷，需要做功\n\\[dA=U(t)dq=\\frac{q(t)}{C}dq \\]\n\\[A = \\int dA = \\int^Q_0\\frac{q(t)}{C}dq=\\frac{Q^2}{2C} \\]\n另外因\\(Q=CU\\)，上式也可以写作\n\\[A=\\frac{1}{2}CU^2=\\frac{1}{2}QU \\]\n也就是电容器中储存的能量\n\\[W = \\frac{Q^2}{2C} = \\frac{1}{2}CU^2=\\frac{1}{2}QU \\]\n在平行板电容器中，如果忽略边缘效应，两极板间的电场是均匀的。因此，单位体积内储存的能量（能量密度）\\(\\omega\\)也应该是均匀的。因\\(U=Ed,C=\\varepsilon_0S/d\\)，有\n\\[W = \\frac{1}{2}\\varepsilon_0E^2Sd=\\frac{1}{2}\\varepsilon_0E^2V \\]\n而\n\\[\\omega=\\frac{W}{V}=\\frac{1}{2}\\varepsilon_0E^2 \\]\n只要空间任一处存在着电场，电场强度为\\(E\\)，该处单位体积中就储藏着\\(\\varepsilon_0E^2/2\\)的能量。\n恒定电流的磁场 磁感应强度 当\\(Id\\bm l\\)与磁感应强度方向垂直时，所受的磁场力最大，\n\\[B = \\frac{dF_{max}}{Idl} \\]\n力的方向由左手定则确定。\n电流元\\(Id\\bm l\\)在磁场中受到的磁场力\\(d\\bm F\\)如下\n\\[d\\bm F = Id\\bm l\\times \\bm B \\]\n毕奥-萨伐尔定律 电流元\\(Id\\bm l\\)在空间某点\\(P\\)出产生的磁感应强度为\n\\[dB = \\frac{\\mu_0}{4\\pi}\\frac{Idl\\sin\\theta}{r^2} \\]\n其中\\(r\\)是距离，\\(\\theta\\)是矢量\\(\\bm r\\)和\\(d\\bm l\\)的夹角。\\(\\mu_0=4\\pi\\times 10^{-7}N/A^2\\)，称为真空磁导率。\n\\(d\\bm B\\)的方向由右手螺旋法则确定。写成矢量形式如下\n\\[d\\bm B = \\frac{\\mu_0}{4\\pi}\\frac{Id\\bm l\\times \\bm r^0}{\\bm r^2} \\]\n运动电荷的磁场\n因为\\(I=nqvS\\)，代入有\n\\[d\\bm B = \\frac{\\mu_0}{4\\pi}\\frac{nqvSd\\bm l\\times \\bm r^0}{\\bm r^2} \\]\n因为\\(\\bm v\\)和\\(d\\bm l\\)方向相同，又令\\(dN = nSdl\\)，故有\n\\[d\\bm B = \\frac{\\mu_0}{4\\pi}\\frac{(dN)q\\bm v\\times \\bm r^0}{\\bm r^2} \\]\n此时，对于单个带电\\(q\\)的粒子，有\n\\[\\bm B = \\frac{d\\bm B}{dN} = \\frac{\\mu_0}{4\\pi}\\frac{q\\bm v\\times \\bm r^0}{\\bm r^2} \\]\n常用的磁感应强度公式 11.2.jpg\r磁通量 类似于电场线，可以用磁感应线描绘恒定磁场，规定\n磁力线上各点的切线方向与该点处的磁感应强度\\(\\bm B\\)的方向一致 在磁场中的某点处，垂直于该点\\(\\bm B\\)的单位面积上，穿过磁力线的数目等于该点处\\(\\bm B\\)的大小 磁场是无源场，磁力线既无起点又无终点。磁力线的环绕方向与电流的方向及环形电流绕行方向与磁力线方向都遵守右手螺旋法则。\n磁通量定义为\n\\[d\\varPhi_m=\\bm B\\cdot d\\bm S=Bcos\\theta dS \\]\n也就有\n\\[\\varPhi_m=\\int_S \\bm B\\cdot d\\bm S \\]\n磁场的高斯定理 穿过任一闭合曲面的总磁通量恒等于零，即\n\\[\\oint_S\\bm B\\cdot d\\bm S = 0 \\]\n安培环路定理 磁场中\\(B\\)矢量沿闭合路径的线积分和闭合路径的形状大小无关，只与闭合路径包围的电流有关 当电流的方向与闭合路径绕行方向之间满足右螺旋法则时，I取正值；反之取负值 \\[\\oint_L \\bm B\\cdot d\\bm l=\\mu_0\\sum_{内}I_i \\]\n磁场对电流的作用 磁场对载流导线的作用力\n\\[\\bm F = \\int_L Id\\bm l\\times \\bm B \\]\n如果导线上各电流源的受力方向不一致，就要沿坐标轴分解力来计算。\n另外闭合载流线圈在匀强磁场中受到的安培力矢量和为零\n均匀磁场对载流线圈的作用\n磁力矩为\n\\[\\bm M=\\bm p_m\\times B = IS\\bm n\\times \\bm B \\]\n其中\\(I\\)是线圈的电流，\\(S\\)是线圈面积，\\(\\bm n\\)是线圈法向量。\n磁力的功\n当回路中电流不变时，磁力所作的供等于电流乘以通过回路所包围面积内的磁通量的增量\n\\[A=I\\Delta\\varPhi \\]\n带电粒子在电场和磁场中的运动 在电场中\n\\[q\\bm E = m\\bm a=m\\frac{d\\bm v}{dt} \\]\n在磁场中\n\\[\\bm F=q\\bm v\\times \\bm B \\]\n洛伦兹力\\(F\\)的一个重要特点是它始终垂直于速度\\(v\\)，因此洛伦兹力只改变带电运动粒子的运动方向，而不改变它的速度的大小。\n霍尔效应\n霍尔元件上下两面的电势差为\n\\[U_{ab}=\\frac{IB}{nqd}=K\\frac{IB}{d} \\]\n其中\\(B\\)是与电流\\(I\\)垂直的，如果把电流方向记为霍尔元件的长度方向，那么宽度记为\\(d\\)（也就是\\(B\\)方向的长度），\\(n\\)为单位体积内载流子的数量，\\(q\\)为载流子的电荷量。\n如果载流子是电子，则称为\\(n\\)型半导体。如果是空穴，则为\\(p\\)型。\n磁介质 磁介质的分类\n磁介质是指放在磁场中经磁化后能反过来影响原来磁场的物质\n原来的磁场记作\\(\\bm B_0\\)，磁介质产生的记作\\(\\bm B'\\)，则磁介质中的磁感应强度是其矢量和\n\\[\\bm B=\\bm B_0+\\bm B' \\]\n相对磁导率定义为\n\\[\\mu_r=\\frac{B}{B_0} \\]\n顺磁质。顺磁质的\\(\\mu_r\u003e1\\)。产生的磁场和原来的磁场同方向 抗磁质。抗磁质的\\(\\mu_r\u003c1\\)。产生的磁场和原来的磁场反方向 铁磁质。铁磁质的\\(\\mu_r\u003e\u003e1\\)。产生的磁场和原来的磁场同方向 铁磁质是强磁性物质，其他称为弱磁性物质（非磁性）物质\n对于非磁性物质，其相对磁导率接近\\(1\\)，通常用磁化率来替代表示，即\n\\[\\mathcal{X}_m=\\mu_r-1 \\]\n磁介质中的环路定理\n将安培环路定理应用到磁介质中，并取以\\(r\\)为半径的闭合同心圆周为积分路径，则有\n\\[\\oint_L \\bm B\\cdot d\\bm l = \\mu_0(NI+I_s) \\]\n其中\\(I_s\\)是束缚电流，是线圈电流导致的在磁介质中产生的电流。顺磁质电流方向相同，抗磁质则相反。\n通常我们无法预先知道\\(I_s\\)，所以我们代换得\n\\[\\oint_L \\bm B\\cdot d\\bm l = \\mu_0\\mu_rNI \\]\n令\\(\\mu=\\mu_0\\mu_r\\)称为磁导率,则\n\\[\\oint_L \\frac{\\bm B}{\\mu}\\cdot d\\bm l = \\sum_{内}I \\]\n令\\(\\frac{\\bm B}{\\mu}=\\bm H\\)称为磁场强度，则\n\\[\\oint_L \\bm H\\cdot d\\bm l = \\sum_{内}I \\]\n电磁感应与电磁场 电动势 法拉第通过研究发现，不论用什么办法，只要使穿过道题闭合回路的磁通量发生变化，此回路中就会产生电流。\n电动势的定义为：非静电力把单位正电荷从负极通过电荷内部搬移到正极所做的功，用\\(\\varepsilon\\)表示。如果用\\(A_k\\)表示在电源内非静电力把正电荷\\(q\\)从负极搬到正极所做的功，则\n\\[\\varepsilon = \\frac{A_k}{q} \\]\n同样的，我们定义单位正电荷所受的非静电力定义为非静电性电场强度。若用\\(F_k\\)表示正电荷\\(q\\)所受的非静电力，用符号\\(E_k\\)表示非静电性电场强度，则\n\\[\\bm E_k=\\frac{\\bm F_k}{q} \\]\n结合两式，有\n\\[A_k = \\int^+_- \\bm F_k\\cdot d\\bm l = q\\int^+_- \\bm E_k\\cdot d\\bm l \\]\n\\[\\varepsilon = \\int^+_- \\bm E_k\\cdot d\\bm l \\]\n如果一个闭合回路\\(L\\)上处处都有非静电力\\(F_k\\)存在，这时整个闭合回路内的总电动势是\n\\[\\varepsilon = \\oint \\bm E_k\\cdot d\\bm l \\]\n对于有非静电力\\(F_k\\)存在的一段电路\\(ab\\)上的电动势为\n\\[\\varepsilon = \\int^b_a \\bm E_k\\cdot d\\bm l \\]\n法拉第电磁感应定律 导体回路中产生的感应电动势\\(\\varepsilon_i\\)的大小与穿过回路的磁通量的变化率\\(d\\varPhi/dt\\)成正比\n\\[\\varepsilon_i =-\\frac{d\\varPhi}{dt} \\]\n具体方向由右手螺旋定则确定。\n如果有多匝线圈，并且穿过各线圈的磁通量相同，则总磁通量\\(\\varPsi=N\\varPhi\\)\n楞次定律\n闭合回路中，感应电流的方向总是使得它自身所产生的磁通量反抗引起感应电流的磁通量的变化。\n动生电动势 由于导体或导体回路在恒定磁场中运动，导体或导体回路内产生的感应电动势。\n若长为\\(l\\)的导体棒\\(ab\\)，在恒定的均匀磁场中以匀速\\(\\bm v\\)沿垂直于磁场\\(\\bm B\\)的方向运动。\n导体棒\\(ab\\)上的动生电动势为\n\\[\\varepsilon_i = \\int^b_a \\bm E_k\\cdot d\\bm l = \\int^b_a (\\bm v\\times \\bm B)\\cdot d\\bm l \\]\n可以根据左手定则判断电动势方向。\n感生电动势 导体或导体回路不动，由于磁场随时间变化，导体或导体回路中产生的感应电动势。\n变化的磁场在周围空间激发出电场线为闭合曲线的电场，称其为感生电场或有旋电场。有旋电场的出现与是否存在导体没有关系。\n当回路固定不动，磁通量\\(\\varPsi\\)的变化仅来自磁场的变化时，电动势为\n\\[\\varepsilon_i = \\oint_L \\bm E_V\\cdot \\bm l=-\\iint_S\\frac{\\partial\\bm B}{\\partial t}\\cdot d\\bm S \\]\n自感现象 导体回路中由于自身电流的变化，而在自身回路中产生感应电动势的现象。产生的电动势称为自感电动势。\n设一回路通有电流\\(I\\)，根据毕奥-萨伐尔定律，总磁通\n\\[\\varPsi = LI \\]\n式中比例系数\\(L\\)称为该回路的自感系数，简称自感。如果回路周围不存在铁磁质，自感\\(L\\)是与电流\\(I\\)无关，仅由回路的匝数、几何形状、大小，以及周围介质的磁导率决定的物理量。\n若回路的自感\\(L\\)保持不变，则通过回路的总磁通\\(\\varPsi\\)仅随回路中电流的变化而变化，根据法拉第电磁感应定律，自感电动势为\n\\[\\varepsilon_L = -\\frac{d\\varPsi}{dt} = -L\\frac{dI}{dt} \\]\n式中的负号表明自感电动势产生的感应电流的方向总是反抗回路中电流\\(I\\)的变化。\n互感现象 由于某一个导体回路中的电流发生变化，而在邻近导体回路内产生感应电动势的现象，称为互感现象。\n类似于自感系数。设\\(\\varPsi_{21}\\)表示回路\\(1\\)中通有电流\\(I_1\\)时，它激发的磁场在回路\\(2\\)中产生的总磁通。\n\\[\\varPsi_{21} = M_{21}I_1 \\]\n同样也有\n\\[\\varepsilon_M = -\\frac{d\\varPsi}{dt} = -M\\frac{dI}{dt} \\]\n磁能 一个自感为\\(L\\)通有电流\\(I\\)的线圈，其中所储存的磁能\n\\[W_m=\\frac{1}{2}LI^2 \\]\n称为自感磁能。\n储存在线圈中的能量可以用描述磁场的物理量\\(B\\)或\\(H\\)来表示。长直螺线管的自感为\\(L=\\mu n^2 V\\)，其磁能为\n\\[W_m = \\frac{1}{2}\\mu n^2 I^2V \\]\n对于长直螺线管，有\n\\[H = nI;B=\\mu n I \\]\n有\n\\[W_m = \\frac{1}{2}BHV=\\frac{1}{2}\\mu H^2V=\\frac{1}{2}\\frac{B^2}{\\mu} V \\]\n其中\\(\\mu\\)是其磁导率，\\(n\\)是每单位长度的匝数，\\(V\\)是螺线管的体积，所以能量密度为\n\\[w_m = \\frac{1}{2}BH \\]\n进一步的研究表明，某点磁场的能量密度只与该点的磁感应强度\\(B\\)和介质的性质有关。\n\\[dW_m = w_mdV = \\frac{1}{2}BHdV \\]\n\\[W_m = \\int_V dW_m=\\frac{1}{2}\\int_V BHdV \\]\n位移电流 对于非恒定电流，例如电路中加一个电容器，那么原始的安培环路定理则不再适用，因为将曲面穿过两极板之间得到的结果是0. 不符合事实。\n于是麦克斯韦提出了位移电流的概念，即在电容器的两个极板中也有电流。定义为\n\\[I_D=\\frac{d\\varPhi_D}{dt} \\]\n设极板的面积为\\(S\\)，某时刻极板上自由电荷面密度为\\(\\sigma\\)，则电位移为\\(D=\\sigma\\)，于是极板间的电位移通量\\(\\varPhi_D=DS=\\sigma S\\)。电位移通量的时间变化率为\n\\[\\frac{d\\varPhi_D}{dt} = \\frac{d}{dt}\\sigma S=\\frac{dq}{dt} \\]\n其中\\(dq/dt\\)就是导线中的传到电流。\n于是可以把安培环路定理推广为\n\\[\\oint_L \\bm H\\cdot d\\bm l=I+I_D \\]\n麦克斯韦方程组的积分形式，电磁场 \\[\\oint_S \\bm D\\cdot d\\bm S = \\sum_i q_i \\]\n\\[\\oint_L \\bm E\\cdot d\\bm l = -\\iint_S\\frac{\\partial \\bm B}{\\partial t}\\cdot d\\bm S \\]\n\\[\\oint_S \\bm B\\cdot d\\bm S = 0 \\]\n\\[\\oint_L \\bm H\\cdot d\\bm l = \\sum(I_D+I) \\]\n狭义相对论基础 力学相对性原理 在彼此作匀速直线运动的所有惯性系中，物体运动所遵循的力学规律是完全相同的，应具有完全相同的数学表达形式。也就是说，对于描述力学现象的规律而言，所有惯性系都是等价的。这称为力学相对性原理\n绝对时空观 狭义相对论之前，科学家们普遍认为时间和空间都是绝对的，可以脱离物质运动而存在，并且时间和空间也没有任何联系。\n这就是经典力学的时空观，也称为绝对时空观。\n伽利略坐标变换式 设有两个惯性参考系\\(S,S'\\)，取坐标系\\(Oxyz,O'x'y'z'\\)，简单起见他们的坐标轴相互平行且\\(x,x'\\)相互重合，设\\(S'\\)沿\\(x\\)轴方向以恒定速度\\(\\bm u\\)相对\\(S\\)运动，并且\\(O,O'\\)重合时\\(t=t'=0\\)\n则在\\(S\\)中一点\\((x,y,z)\\)在\\(S'\\)中的坐标为\n\\[\\left.\\begin{matrix} x'=\u0026x-ut \\\\ y'=\u0026y \\\\ z'=\u0026z \\end{matrix}\\right\\} \\]\n根据绝对时间概念，有\n\\[t' = t \\]\n这就是这两个坐标系间的伽利略坐标变换式。\n牛顿运动定律具有伽利略变换的不变性 经典力学所有的基本定律都满足经典力学相对性原理，但是之后发现麦克斯韦方程组并不满足。\n狭义相对论的两个基本假设 光速的伽利略变换未能被实验证实\n光是电磁波，由麦克斯韦方程组可知\n\\[c=\\frac{1}{\\sqrt{\\varepsilon_0\\mu_0}}=2.998\\times 10^8 m/s \\]\n也就是说光速是恒定的，与传播方向和参考系的选择无关。\n如果伽利略变换是正确的，则在\\(S'\\)中光速应该是\\(c-u\\)，但迈克耳孙-莫雷实验证实了光速都是\\(c\\)，发现了经典力学和光速的不相容性。\n假设1\n在所有惯性系中，一切物理学定律都相同，即具有相同的数学表达形式。或者说，对于描述一切物理现象的规律来说，所有惯性系都是等价的。这也称为狭义相对论的相对性原理。\n假设2\n在所有惯性系中，真空中光沿各个方向传播的速率都等于同一个恒量\\(c\\)，与光源和观察者的运动状态无关。这也称为光速不变原理。\n“同时性”的相对性 在\\(S'\\)系中异地同时发生的两个事件，在\\(S\\)系看来并不同时。反过来也是这样。\n需要说明的是，在一个惯性系同一地点发生的两个同时事件，对于其他惯性系也是同时的。\n产生“同时性”的相对性的原因是，光在不同惯性系中具有相同的速率和光的速率是有限的。\n时间延缓 将在一个惯性系中测得的、发生在该惯性系中同一地点的两个事件之间的时间间隔称为原时。\n时间的测量具有相对性，在不同惯性系中测量给定的两个事件之间的时间间隔，测得的结果以原时最短，这一现象称为时间延缓效应。\n时间延缓效应还可陈述为，运动时钟走的速率比静止时钟走的速率要慢。\n时间延缓效应也是相对的，运动的\\(S'\\)的时钟相对于静止的\\(S\\)的时钟要慢。反过来也是这样。\n以公式来说，设两件事发生的间隔在静止的\\(S\\)看来是\\(\\tau\\)，而在运动的\\(S'\\)看来是\\(\\tau_0\\)（即原时，事件是在\\(S'\\)中同一地点发生的），\\(S'\\)相对于\\(S\\)以\\(\\bm u\\)的速率运动则\n\\[\\tau = \\frac{\\tau_0}{\\sqrt{1-\\beta^2}}=\\gamma\\tau_0 \\]\n其中\\(\\beta=u/c,\\gamma = 1/\\sqrt{1-\\beta^2}\\)\n长度收缩 设地面上有一静止的尺子，车（\\(S'\\)系）以速度\\(\\bm u\\)相对地面（\\(S\\)系）沿尺子长度方向运动。\n若地面上的人观察到尺子长为\\(L\\)，也称为原长，则车上的人观察到\n\\[L'=L\\sqrt{1-\\bigg(\\frac{u}{c}\\bigg)^2} \\]\n其表明，沿尺长度方向运动的观测者测得的尺长，较相对尺静止观测者测得的同一尺的原长\\(L\\)要短，或者说，各惯性系中测量同一尺长，以原长为最长。\n洛伦兹坐标和时间变换式 条件设置和伽利略坐标变换式一致，只是增加了第四维时间，即\\(S\\)系中坐标为\\((x,y,z,t)\\)，\\(S'\\)系中为\\((x',y',z',t')\\)，洛伦兹坐标和事件变换式为\n\\[x'=\\frac{x-ut}{\\sqrt{1-\\beta^2}},\\quad t'=\\frac{t-\\frac{u}{c^2}x}{\\sqrt{1-\\beta^2}} \\]\n\\[y'=y,\\quad z'=z \\]\n逆变换为\n\\[x=\\frac{x'+ut'}{\\sqrt{1-\\beta^2}},\\quad t=\\frac{t'+\\frac{u}{c^2}x'}{\\sqrt{1-\\beta^2}} \\]\n\\[y=y',\\quad z=z' \\]\n在低速时，即\\(u\u003c\u003c c\\)时，\\(\\beta\\approx0\\)，此时洛伦兹变换与伽利略变换几乎一致，也就是说低速情况我们可以使用伽利略变换。\n真空中的光速\\(c\\)是一切物体运动速率的极限。\n空间间隔和时间间隔是紧密联系着的，即\n\\[\\Delta x'=\\frac{\\Delta x-u\\Delta t}{\\sqrt{1-\\beta^2}},\\quad \\Delta t'=\\frac{\\Delta t-\\frac{u}{c^2}\\Delta x}{\\sqrt{1-\\beta^2}} \\]\n逆变换\n\\[\\Delta x=\\frac{\\Delta x'+u\\Delta t'}{\\sqrt{1-\\beta^2}},\\quad \\Delta t=\\frac{\\Delta t'+\\frac{u}{c^2}\\Delta x'}{\\sqrt{1-\\beta^2}} \\]\n洛伦兹变换与狭义相对论时空观 “同时性”的相对性\n设在\\(S'\\)系中不同地点、同时发生了两个事件，则在\\(S\\)看来发生的时间间隔为\n\\[\\Delta t= \\bigg(\\frac{u}{c^2}\\Delta x'\\bigg)\\bigg/\\sqrt{1-\\beta^2} \\]\n时间延缓\n\\(S'\\)中在同一地点、不同时间发生的两个事件，对于\\(S\\)来说事件间隔为\n\\[\\Delta t = \\frac{\\Delta t'}{\\sqrt{1-\\beta^2}}=\\frac{\\tau_0}{\\sqrt{1-\\beta^2}} \\]\n长度收缩\n设尺沿\\(x'\\)方向静止在\\(S'\\)系中，\\(S'\\)系中观测者测得尺长\\(L_0=\\Delta x'\\)为尺的原长，\\(S\\)系中观测者要测量运动尺的长度\\(L\\)，必须要在\\(S\\)系中同时确定尺两端的坐标\\(x_1,x_2\\)，这样\\(L=x_2-x_1\\)\n\\[L=\\Delta x=L_0\\sqrt{1-\\beta^2} \\]\n爱因斯坦速度相加定律 \\[v_x' = \\frac{v_x-u}{1-\\frac{u}{c^2}v_x} \\]\n\\[v_y' = \\frac{v_y\\sqrt{1-\\beta^2}}{1-\\frac{u}{c^2}v_x} \\]\n\\[v_z' = \\frac{v_z\\sqrt{1-\\beta^2}}{1-\\frac{u}{c^2}v_x} \\]\n相对论动量和质量 质量是一个和速率有关的量\n\\[m(v) = \\frac{m_0}{\\sqrt{1-(\\frac{v}{c})^2}} \\]\n式中\\(m_0\\)是质点静止时的质量，即由相对该质点静止的观察者测得的质量，称为静止质量。\n于是动量为\n\\[\\bm p = m\\bm v = \\frac{m_0}{\\sqrt{1-(\\frac{v}{c})^2}}\\bm v \\]\n同时，力为\n\\[\\bm F = \\frac{d\\bm p}{dt} = \\frac{d}{dt}\\bigg(\\frac{m_0}{\\sqrt{1-(\\frac{v}{c})^2}}\\bm v\\bigg) \\]\n相对论动能 \\[E_k = \\int\\bm F\\cdot d\\bm r = \\int_0^v d(mv)\\cdot \\bm v \\]\n\\[E_k = \\int^m_{m_0}c^2dm = mc^2-m_0c^2 \\]\n质能关系式 \\[E=mc^2\\\\ E_0=m_0c^2 \\]\n光子的静质量为零，而频率为\\(\\nu\\)的光子所对应的能量为\\(E=h\\nu\\)，所以光子的动质量为\n\\[m_\\varphi = \\frac{E}{c^2} = \\frac{h\\nu}{c^2} \\]\n相对论能量和动量的关系 \\[E^2 = p^2c^2 + E_0^2 \\]\n对于光子\n\\[p = \\frac{h\\nu}{c} = \\frac{h}{\\lambda} \\]\n量子物理基础 普朗克量子假设 物体由其温度所决定的电磁辐射称为热辐射\n当辐射和吸收达到平衡时，物体的温度不再变化而处于热平衡状态，这时的热辐射称为平衡热辐射。\n物体的辐射本领越大，其吸收本领也越大，反之亦然\n为描述物体热辐射能量按波长的分布规律，引入单色辐射出射度（简称单色辐出度）。其定义为：物体单位表面积在单位时间内发射的，波长在\\(\\lambda\\to\\lambda+d\\lambda\\)范围内的辐射能\\(dM_\\lambda\\)与波长间隔\\(\\lambda\\)的比值\n\\[M_\\lambda(T) = \\frac{dM_\\lambda}{d\\lambda} \\]\n能够全部吸收各种波长的辐射能而完全不发生反射和透射的物体称为绝对黑体，简称黑体。\n维恩公式在短波部分和实验曲线吻合的很好，但在长波部分相差较大。\n瑞利金斯公式在波长很长的部分与实验曲线吻合，但在短波部分，随着波长的减小，理论结果会趋于无穷大，这被称作紫外灾难。\n普朗克找到一个经验公式，在一定温度\\(T\\)下，黑体单色辐出度为\n\\[M_{B\\lambda}(T) = 2\\pi hc^2\\lambda^{-5}\\frac{1}{exp(\\frac{hc}{k\\lambda T})-1} \\]\n其中\\(c\\)是光速，\\(k\\)是玻尔兹曼常数，\\(h\\)是普朗克常量，其值为\\(h=6.6260755\\times 10^{-34} J\\cdot s\\)\n普朗克发现，要导出这个公式，必须引进一个假设：腔壁中带电谐振子的能量不能连续变化，频率为\\(\\nu\\)的振子的能量\\(\\varepsilon\\)只能取\\(h\\nu\\)的整数倍，即\\(\\varepsilon = nh\\nu,n\\)称为量子数。谐振子和腔内辐射场交换能量（即发射和吸收辐射能）也只能是\\(h\\nu\\)的整数倍。谐振子能量的这个最小单位称为能量子，上述假设称为普朗克的量子假设。\n光电效应的实验规律 金属及其化合物在光照射下发射电子的现象称为光电效应。\n研究表明光电效应有如下规律\n阴极\\(K\\)在单位时间内所发射的光电子数与照射光的光强\\(I\\)成正比。 存在截止频率。当照射光频率\\(\\nu\\)小于某个最小值\\(\\nu_0\\)时，不管光强多大，照射时间多长，都没有光电子溢出。这个最小频率就叫做截止频率，也叫做红限。 光电子的最大初动能与照射光的强度无关，而与其频率成线性关系。给光电子施加反向电势差，使得光电流为零，此时反向电势差的绝对值称为遏止电压。 遏止电压和最大初动能的关系为\n\\[\\frac{1}{2}mv_m^2=eU_a \\]\n与频率的关系为\n\\[U_a = K(\\nu-\\nu_0) \\]\n式中\\(K\\)为\\(U_a-\\nu\\)图线的斜率。\\(K\\)是一个与材料性质无关的普适常量。\\(\\nu_0\\)是图线在横轴上的截距，它等于该种金属的光电效应红限。\n光子是即时发射的，滞后时间不超过\\(10^{-9}s\\) 经典物理难以解释光电效应 根据波动理论作出的预言和上述实验规律不符。例如它预言不存在红限、初动能和光强正相关而和频率无关、发射不是即时的等等。\n爱因斯坦光子假说和光电效应方程 爱因斯坦假设说，一束光就是一束以光速运动的粒子流，这些粒子称为光子；频率为\\(\\nu\\)的每一光子所具有的能量为\\(h\\nu\\)，它不能再分割，而只能整个地被吸收或产生出来。\n光电效应方程为\n\\[h\\nu = A + \\frac{1}{2}mv^2_m \\]\n式中\\(\\frac{1}{2}mv_m^2\\)是光电子的最大初动能。也就是电子从金属表面逸出时所具有的最大初动能，内部电子逸出时所需做的功大于逸出功\\(A\\)，因而初动能较小。\n显然我们可以解释最低频率\\(\\nu_0\\)为\n\\[\\nu_0 = \\frac{A}{h} \\]\n另外照射光的光强就是单位时间到达被照物单位垂直表面积的能量，是由单位时间内到达单位垂直面积的光子数\\(N\\)决定的，即\\(I = Nh\\nu\\)\n光（电磁辐射）的波粒二象性 光子的质量为\n\\[m_\\varphi = \\frac{E}{c^2} = \\frac{h\\nu}{c^2} = \\frac{h}{c\\lambda} \\]\n动量为\n\\[p = m_{\\varphi}c=\\frac{h}{\\lambda} \\]\n康普顿效应 康普顿发现，单色\\(X\\)射线被物质散射时，散射线中有两种波长，其中一种波长比入射线的长，且波长改变量与入射线波长无关，而随散射角的增大而增大，这种波长变大的散射现象称为康普顿散射，或康普顿效应。\n实验结果显示，对任一散射角\\(\\theta\\)都测量到两种波长\\(\\lambda_0\\)和\\(\\lambda\\)的散射线，且\\(\\Delta\\lambda = \\lambda - \\lambda_0\\)随\\(\\theta\\)增大而增大，而与\\(\\lambda_0\\)及散射物质无关。\n实验还表明对轻元素，波长变大的散射线相对较强，而对重元素，波长变大的散射线相对较弱。\n康普顿效应的微观机制是：自由电子吸收一个入射光子后发射一个波长较长的光子，且电子与光子沿不同方向运动，由于动量和能量都守恒，因此康普顿散射过程可以看成是入射光子与自由电子的弹性碰撞。\n波长改变量为\n\\[\\Delta\\lambda = \\lambda-\\lambda_0 = \\frac{c}{\\nu}-\\frac{c}{\\nu_0} = \\frac{h}{m_0c}(1-cos\\theta) \\]\n也通常写为\n\\[\\lambda-\\lambda_0 = \\frac{2h}{m_0c}sin^2\\frac{\\theta}{2} = 2\\lambda_C\\sin^2\\frac{\\theta}{2} \\]\n其中\\(\\lambda_C = \\frac{h}{m_0c}\\)\n氢原子光谱 实验发现，各种元素的原子光谱都由分立的谱线所组成，并且谱线所组成，并且谱线的分布具有确定的规律。氢原子的是最简单的，其实验规律如下\n氢原子光谱是彼此分立的线状光谱，每一条谱线具有确定的波长（或频率） 每一条光谱线的波数\\(\\~\\nu=1/\\lambda\\)都可以表示为两项之差，即 \\[\\~\\nu = \\dfrac{1}{\\lambda} = T(k) - T(n) = R_H\\left(\\dfrac{1}{k^2}-\\dfrac{1}{n^2}\\right) \\]\n式中\\(k\\)和\\(n\\)均为正整数，且\\(n\u003ek\\)。\\(R_H\\)称为氢光谱的里伯德常数，近代测量值为\\(R_H=1.0973731\\times 10^7m^{-1},T(n)=R_H/n^2\\)称为氢的光谱项。上式称为里德伯-里兹并和原则。\n当整数\\(k\\)取一定值时，\\(n\\)取大于\\(k\\)的各整数所对应的各条谱线构成一谱线系；每一谱线系都有一个线系的极限，对应于\\(n\\to\\infty\\)的情况。\\(k=1(n=2,3,\\cdots)\\)的谱线系称为赖曼系，\\(k=2(n=3,4,\\cdots)\\)的谱线系称为巴耳末系。 玻尔理论对氢原子光谱的解释是：\n原子只能处在一系列具有不连续能量的稳定状态，简称定态。所以核外电子只能在一系列不连续的圆轨道上运动，但并不辐射电磁波。 当原子从一个能量为\\(E_k\\)的定态跃迁到另一个能量为\\(E_n\\)的定态时，会发射或吸收一个频率为\\(\\nu_{kn}\\)的光子 \\[\\nu_{kn}=\\dfrac{|E_k-E_n|}{h} \\]\n电子在稳定圆轨道上运动时，其轨道角动量\\(L=mvr\\)必须等于\\(\\dfrac{h}{2\\pi}\\)的整数倍，即 \\[L = mvr = n\\dfrac{h}{2\\pi} = n\\hbar (n=1,2,3,\\cdots) \\]\n其中\\(\\hbar = \\dfrac{h}{2\\pi}\\)，称为约化普朗克常数。上式称为角动量量子化条件，\\(n\\)称为量子数。\n玻尔还推出，原子处于第\\(n\\)个定态时的电子轨道半径为\n\\[r_n = n^2r_1 \\]\n其中\\(r_1\\)是氢原子中电子的最小轨道半径，称为玻尔半径，其值为\n\\[r_1=\\dfrac{\\varepsilon_0h^2}{\\pi me^2}=0.529\\times 10^{-10}m \\]\n\\(n=1\\)的定态称为基态，\\(n=2,3,4,\\cdots\\)各态均称为受激态。\n氢原子能量等于电子的动能和电势能之和，处在量子数为\\(n\\)的定态时，能量为\n\\[E_n = -\\dfrac{1}{8\\pi\\varepsilon_0}\\dfrac{e^2}{r_n} = -\\dfrac{1}{n^2}\\left(\\dfrac{me^4}{8\\varepsilon_0^2h^2}\\right)\\quad n=1,2,3,\\cdots \\]\n这称为能量量子化，这种量子化的能量叫做能级。令\\(n=1\\)，则\n\\[E_1 = -\\left(\\dfrac{me^4}{8\\varepsilon_0^2h^2}\\right) = -13.6 eV \\]\n这个能量是基态能级的能量，也是氢原子的电离能。\n微观粒子的波粒二象性 德布罗意假设：不仅光具有波粒二象性，一切实物粒子如电子、原子、分子等也都具有波粒二象性。他给出如下公式\n\\[E = mc^2 = h\\nu \\]\n\\[p = mv = \\dfrac{h}{\\lambda} \\]\n上二式可写成\n\\[\\nu = \\dfrac{E}{h} = \\dfrac{mc^2}{h} = \\dfrac{m_0c^2}{h\\sqrt{1-v^2/c^2}} \\]\n\\[\\lambda = \\dfrac{h}{p} = \\dfrac{h}{mv} = \\dfrac{h}{m_0v}\\sqrt{1-\\dfrac{v^2}{c^2}} \\]\n上面的\\(\\lambda\\)称为德布罗意波或物质波的波长，该式称为德布罗意关系式。\n德布罗意指出，电子在玻尔轨道上运动与这个电子的物质波沿轨道传播相联系，满足驻波条件\n\\[2\\pi r = n\\lambda \\]\n代入\\(\\lambda = \\dfrac{h}{mv}\\)就可以得到玻尔理论中的角动量量子化条件。\n物质波的实验证明 德布罗意关于物质波的假设，首先在1927年由戴维孙-革末实验证实。\n二人在做电子束在晶体表面散射实验时，观察到了和\\(X\\)射线在晶体表面衍射想类似的电子衍射现象。\n1961年他人还做了电子束的单缝、双缝等等实验。\n除了电子，也有人做了中子、原子的实验。\n不确定关系 在经典力学中，质点在任何时刻都有完全确定的位置、动量、能量、角动量等。与此不同，微观粒子具有明显的波动性，以致它的某些成对物理量不可能同时具有确定的量值。例如，位置坐标和动量、角坐标和角动量等，其中一个量确定越准确，另一个量的不确定程度就越大。\n海森堡根据量子力学推出，一个粒子的位置坐标的不确定量\\(\\Delta x\\)和其同一时刻的动量不确定量\\(\\Delta p_x\\)，满足\n\\[\\Delta x\\Delta p_x \\geq \\dfrac{\\hbar}{2} \\]\n称为海森堡坐标和动量的不确定关系式。\n不确定关系不仅存在于坐标和动量之间，也存在于能量和时间之间，如果微观体系处于某一状态的时间为\\(\\Delta t\\)，则其能量必有一个不确定量\\(\\Delta E\\)，由量子力学可推出\n\\[\\Delta E\\Delta t\\geq\\dfrac{\\hbar}{2} \\]\n上式称为能量和时间不确定关系式。\n将其应用于原子系统可以讨论原子各受激态能级宽度\\(\\Delta E\\)和该能级平均寿命\\(\\Delta t\\)之间的关系。\n原子通常处于能量最低的基态，在受激发后将跃迁到各个能量较高的受激态，停留一段时间后又自发跃迁进入能量较低的定态。大量同类原子在同一高能级上停留时间长短不一，但平均停留时间为一定值，称为该能级的平均寿命。\\(\\Delta t\\)越长的能级越稳定，宽度\\(\\Delta E\\)越小。由于能级有一定宽度，光谱线也就有一定宽度了。\n有些原子具有一种特殊的受激态，寿命可长达\\(10^{-3}s\\)或更长，这类受激态称为亚稳态。\n波函数及其统计解释 波函数是时间和空间坐标的函数，表示为\n\\[\\varPsi(\\bm r,t) \\]\n假设粒子只沿\\(x\\)轴正方向运动，且不受外力（即自由粒子）。则其德布罗意波的波函数可以表示为\n\\[\\varPsi(x,t) = \\psi_0e^{-i2\\pi(\\nu t-\\frac{x}{\\lambda})} = \\psi_0e^{-\\frac{i}{\\hbar}(Et-px)} \\]\n其中\\(\\nu\\)是其物质波的频率，\\(\\lambda\\)是波长，\\(E\\)是能量，\\(p\\)是动量。\\(\\psi_0\\)是一个待定常数，\\(\\psi_0e^{\\frac{i}{\\hbar}px}\\)相当于\\(x\\)处波函数的复振幅，而\\(e^{-\\frac{i}{\\hbar}Et}\\)则反映波函数随时间的变化。\n玻恩指出，实物粒子的德布罗意波是一种概率波；\\(t\\)时刻粒子在空间\\(\\bm r\\)处附近的体积元\\(dV\\)中出现的概率\\(dW\\)与该处波函数绝对值的平方成正比，可以写成\n\\[dW = |\\varPsi(\\bm r,t)|^2dV = \\varPsi(\\bm r,t)\\varPsi^*(\\bm r,t) dV \\]\n其中\\(\\varPsi^*(\\bm r,t)\\)是\\(\\varPsi(\\bm r,t)\\)的共轭复数。\n波函数绝对值平方\\(|\\varPsi(\\bm r,t)|^2\\)代表\\(t\\)时刻粒子在空间\\(r\\)处的单位体积中出现的概率，又称为概率密度。\n波函数必须单值、有限、连续，不符合这三个条件的波函数是没有物理意义的。又因为粒子必定要在空间中的某一点出现，因此粒子在空间各点出现的概率总和等于\\(1\\)，即应有\n\\[\\iiint|\\varPsi(\\bm r,t)|^2dxdydz = 1 \\]\n上式又称为波函数的归一化条件，其中积分区域遍及粒子可能到达的整个空间。\n定态薛定谔方程 薛定谔建立了适用于低速情况的、描述微观粒子在外力场中运动的微分方程，也就是物质波波函数\\(\\varPsi(\\bm r,t)\\)满足的方程，称为薛定谔方程。\n质量为\\(m\\)的粒子在外力场中运动时，一般情况下，其势能\\(V\\)可能是空间坐标和时间的函数，即\\(V=V(\\bm r,t)\\)，薛定谔方程为\n\\[\\bigg[-\\dfrac{\\hbar^2}{2m}\\bigg(\\dfrac{\\partial^2}{\\partial x^2}+\\dfrac{\\partial^2}{\\partial y^2}+\\dfrac{\\partial^2}{\\partial z^2}\\bigg)+V(\\bm r,t)\\bigg]\\varPsi(\\bm r,t) = i\\hbar\\dfrac{\\partial \\varPsi(\\bm r,t)}{\\partial t} \\]\n粒子在稳定力场中运动时，势能函数\\(V\\)与时间无关，\\(V=V(\\bm r)\\)。此时也有\\(|\\varPsi(\\bm r,t)|^2=|\\varPsi(\\bm r)|^2\\)，即概率密度与时间无关。定态波函数的空间部分\\(\\varPsi(\\bm r)\\)也叫做定态波函数。其满足\n\\[\\bigg(\\dfrac{\\partial^2}{\\partial x^2}+\\dfrac{\\partial^2}{\\partial y^2}+\\dfrac{\\partial^2}{\\partial z^2}\\bigg)\\varPsi(\\bm r)+\\dfrac{2m}{\\hbar^2}(E-V)\\varPsi(\\bm r) = 0 \\]\n上式称为定态薛定谔方程，也称不含时间的薛定谔方程。\n如果粒子在一维空间中运动，则\n\\[\\dfrac{d^2\\varPsi(x)}{dx^2}+\\dfrac{2m}{\\hbar^2}(E-V)\\varPsi(x)=0 \\]\n上式称为一维定态薛定谔方程。\n在关于微观粒子的各种定态问题中，把势能函数\\(V(\\bm r)\\)的具体形式代入薛定谔方程中即可求解，得到定态波函数。\n一维无限深势阱中的粒子 以金属中电子的运动为例，讨论薛定谔方程的应用。实际情况是相当复杂的，为简单起见，假定电子只能作沿\\(x\\)轴的一维运动，且其势能函数具有如下的形式\n\\[\\left.\\begin{align*} V(x) = 0,\u0026\\quad 0 \u003c x \u003c a\\\\ V(x) = \\infty,\u0026\\quad x \u003c 0\\ or\\ x \u003e a \\end{align*}\\right\\} \\]\n这种形式的力场叫做一维无限深（方）势阱。由于力和势能的关系\\(F_x = -\\dfrac{\\partial V}{\\partial x}\\)，在金属内部，电子不受力的作用；在金属表面处势能突变，受到指向金属内部的无限大作用力，因此不可能越出金属表面。不过这个模型过于简单和粗略。\n我们可以推知，一维无限深势阱中粒子能量为\n\\[E_n = \\dfrac{\\hbar^2k^2}{2m} = n^2\\dfrac{h^2}{8ma^2},\\quad n = 1,2,3,\\cdots \\]\n由此可见，一维无限深势阱中粒子能量是量子化的，\\(n\\)称为量子数。\\(E_1\\)是最小能量，也称为零点能。其余各级能量可以表示为\\(E_n = n^2E_1\\)\n量子数为\\(n\\)的定态波函数为\n\\[\\varPsi_n(x) = \\pm\\sqrt{\\dfrac{2}{a}}\\sin\\dfrac{n\\pi}{a}x,\\quad n=1,2,3,\\cdots \\]\n束缚在无限深势阱中的粒子的定态波函数具有驻波的形式，且波长\\(\\lambda_n\\)满足\n\\[a = n\\dfrac{\\lambda_{n}}{2},\\quad,n=1,2,3,\\cdots \\]\n氢原子的量子力学结论 能量量子化 \\[E_n = -\\dfrac{1}{n^2}\\dfrac{me^4}{8\\varepsilon_0^2h^2},\\quad,n=1,2,3,\\cdots \\]\n这是氢原子的总能量，\\(n\\)称为主量子数。\n角动量量子化 \\[L = \\sqrt{l(l+1)}\\hbar,\\quad l = 0,1,2,\\cdots,n-1 \\]\n式中的\\(l\\)为小于\\(n\\)的正整数，称为副量子数。\n角动量空间量子化 电子绕核运动的角动量\\(\\bm L\\)在外磁场\\(\\bm B\\)方向的投影\\(L_z\\)，量子力学给出的结果是\n\\[L_z = m_l\\hbar,\\quad m_l = 0,\\pm1,\\pm2,\\cdots,\\pm l \\]\n式中的\\(m_l\\)称为磁量子数。上式说明\\(\\bm L\\)在空间的取向也是量子化的，称为空间量子化。\n施特恩-盖拉赫实验、电子自旋 电子自旋角动量的大小\\(S\\)及其在外磁场方向的投影\\(S_z\\)分别为\n\\[S = \\sqrt{\\dfrac{1}{2}\\bigg(\\dfrac{1}{2}+1\\bigg)}\\hbar = \\sqrt{\\dfrac{3}{4}}\\hbar \\]\n\\[S_z = \\pm \\dfrac{1}{2}\\hbar \\]\n自旋磁量子数\\(m_s=\\pm\\dfrac{1}{2}\\)，它决定了电子自旋角动量\\(\\bm S\\)在外磁场中的取向。\n原子的电子壳层结构 泡利不相容原理 在一个原子中不能有两个或两个以上的电子处在完全相同的量子态。也就是说，任何两个电子都不可能具有一组完全相同的量子数\\((n,l,m_l,m_s)\\)。\n根据泡利不相容原理不难算出各壳层上最多可容纳的电子数为\n\\[Z_n = \\sum_{l=0}^{n-1}2(2l+1) = 2n^2 \\]\n在\\(n=1,2,3,4,\\cdots\\)的\\(K,L,M,N,\\cdots\\)各壳层上，最多可容纳\\(2,8,18,32,\\cdots\\)个电子。而在\\(l=0,1,2,3,\\cdots\\)的各支壳层上，最多可容纳\\(2,6,10,14,\\cdots\\)个电子。\n能量最小原理 原子处于正常状态时，每个电子都趋向占据可能的最低能级。\n固体物理 固体 固体是具有确定形状和体积的物体。\n通常分为两类：晶体和非晶体。\n晶体具有规则的几何形状，在晶体内，其构成微粒周期性重复排列，这种排列称为晶格，或空间点阵。\n规则排列、长程有序是晶体最基本的特征。\n此外，晶体具有确定的熔点，在宏观上各向异性。\n而非晶体没有确定的几何形状和熔点，宏观上各向同性，微观上原子无序排列。\n电子共有化 价电子不再为单个原子所有而为整个晶体所共有的现象，称为电子的共有化。\n两个氢原子相距较远时，电子的势能曲线如同势阱。\n两个氢原子靠近时，势能曲线会出现一个势垒。由于隧道效应，电子可穿透势垒，在两原子之间运动，被两个原子所共有。\n当大量同类原子在晶体内作规则排列时，将形成周期性势场\n能带和能带中电子的分布 理论结果表明，当\\(N\\)个相同原子组成晶体时，由于电子在周期性势场中运动，晶体里每个原子的每一能级都分裂为\\(N\\)个能级。分裂后新能级间的间距及位置取决于点阵间距\\(r\\).\n组成晶体的原子数\\(N\\)越多，分裂后的能级数也越多，能级越密集，一个能级分裂后者密集的能量范围\\(\\Delta E\\)叫做能带。\n能级分裂程度的大小不仅与原子间距离有关，还与能级的级数有关。原子间距离越小，能级分裂的程度越大。晶体点阵间距越小，能带越宽，越大。外层电子共有化显著，能带越宽。\n价电子能量高，势垒宽度小，其穿透势垒概率大，可在整个晶体内运动，被整个晶体所共有，能级分裂程度较高。\n内层电子能量低，势垒宽度大，其穿透势垒概率小，被束缚在母原子核周围运动，共有化程度低，能级分裂程度低。\n由于原子数巨大，分裂后各能级的间距非常小，可以认为能带中电子的能量是连续变化的。\n由于能带是由原子能级分裂而形成的，因此可以沿用原子能级的符号\\(s,p,d,\\cdots\\)来表示能带。\n能带中的电子填充方式同样服从泡利不相容原理以及能量最小原理。\n能带的分类\n两个相邻的能带之间，可能有一个能量间隔，在这个能量间隔中，不存在电子的稳定能态，这个能量间隔称为禁带。\n如果一个能带中的各能级都被电子填满，这样的能带称为满带。\n由价电子能级分裂而形成的能带称为价带。\n与各原子的激发能级相应的能带，在未被激发的正常情况下没有电子填入，称为空带。\n未被电子填满的能带也称为导带。空带也是导带。\n能带的性质决定物质导电特性\n满带中的电子不参与导电过程，不具备导电特性。因为满带中的电子都处于束缚态，只能在母原子核周围运动，不能在晶体内自由运动。\n绝缘体、导体、半导体 绝缘体的能带结构\n有些晶体，它的价带都被价电子所填满，形成满带。此满带与它上面最近空带（即激发能带）间的禁带宽度\\(\\Delta E_g\\)较大（通常为几个电子伏特）。一般的热激发、光照、外电场作用不强时，满带中的电子只有极个别能被激发到空带中，没什么导电作用。\n半导体的能带结构\n导电性介于导体与绝缘体之间的一大类物质称为半导体。\n半导体的能带结构和绝缘体的能带结构很相似，只是禁带宽度比绝缘体小得多。\n导体的能带结构\n各种金属都是导体，它们的能带结构大致有三种形式。\n价带中只填入部分电子，称为导带 价带填满并与空带重叠，没有禁带 价带未满并且也和空带重叠 本征半导体 本征半导体是没有杂质和缺陷的理想半导体。参与导电的电子和空穴称为本征载流子。其中满带中是空穴导电，空带中是电子导电，整体是它们的混合导电。\n本征半导体的导电率很低，一般没有多少使用价值。\n半导体中载流子的数目对光和热极其敏感，这称为半导体的光敏性和热敏性。\n杂质半导体 在纯净的半导体晶体中掺入微量其他元素的原子，将会显著地改变半导体的导电性能。\n由于是不同的原子，杂质原子不参与晶体中的电子共有化。杂质原子的能级处于禁带之中，所以会对导电性能产生重要影响。\nn型半导体\n在通常所用的本征半导体四价元素硅（或锗）的晶体中，用扩散等方法掺入少量的五价元素如砷（或磷）等杂质，就形成n型半导体。\n五价原子在晶体中替代四价原子的位置，构成与硅相同的四电子结构，而多出的一个价电子在杂质离子的电场范围内运动。\n处在杂质能级上的杂质价电子在受到激发时，很容易跃迁到导带上去，所以这种杂质能级又称为施主能级。\np型半导体\n在四价元素中掺入少量三价元素，如硼或镓，替代原来四价原子的位置，构成四电子结构时，缺少一个电子，形成了空穴。空穴也在禁带中。\n在温度不很高的情况下，满带中的电子很容易被激发而跃迁到杂质能级上去，同时在满带汇总形成空穴。由于这样的杂质能级接受从满带跃迁来的电子，所以又称为受主能级。\n激光 定义\n极光是基于受激辐射放大原理产生的一种相干光辐射。\n粒子从能级\\(E_2\\)跃迁到能级\\(E_1(E_2\u003eE_1)\\)（辐射过程）和从\\(E_1\\)跃迁到\\(E_2\\)（吸收过程），都应满足频率条件\n\\[\\nu = \\dfrac{|E_2-E_1|}{h} \\]\n自发辐射、受激辐射、受激吸收 自发辐射\n处于高能级的粒子，在没有外界影响的情况下，有一定概率自发地向低能级跃迁，并发出一个光子，这种过程称为自发辐射。\n自发辐射的特点是发生辐射的各粒子互不相关，自发辐射的光波是非相干的。\n单位时间内自发辐射的粒子数只与高能级上的粒子数\\(N_2\\)成正比，可写成\n\\[\\bigg(\\dfrac{dN_{21}}{dt}\\bigg)_{自发}=A_{21}N_2 \\]\n\\(A_{21}\\)称为自发辐射系数，对给定粒子的两个确定能级，\\(A_{21}\\)为常数。\n粒子在某激发态停留时间的平均值称为该激发态的平均寿命，用\\(\\tau\\)表示。一般\\(\\tau\\)为\\(10^{-8}s\\)数量级。也有一些激发能级可达\\(10^{-3}s\\)或更长，这样的激发态称为亚稳态。亚稳态在形成激光的过程中有着重要的意义。\n受激辐射\n处于高能级\\(E_2\\)的粒子，在频率为\\(\\nu=(E_2-E_1)/h\\)、光强为\\(I\\)的入射光照射激励下，跃迁到低能级\\(E_1\\)上去，同时发射一个与入射光子完全相同的光子，这种过程称为受激辐射。\n与自发辐射不同，受激辐射发出的是相干光。\n显然，单位时间内发生受激辐射的粒子数，与高能级\\(E_2\\)上的粒子数\\(N_2\\)及入射单色光的光强\\(I\\)成正比，可写成\n\\[\\bigg(\\dfrac{dN_{21}}{dt}\\bigg)_{受激}=kN_2IB \\]\n式中\\(k\\)为比例系数，\\(B\\)称为受激辐射系数。对给定粒子的两个确定能级，\\(B\\)是常数。\n受激吸收\n处于低能级\\(E_1\\)的粒子，在频率为\\(\\nu = (E_2-E_1)/h\\)，光强为\\(I\\)的入射光照射下，吸收一个光子而跃迁到高能级\\(E_2\\)，这种过程称为受激吸收。\n单位时间内发生受激吸收的粒子数，应与低能级\\(E_1\\)上的粒子数\\(N_1\\)及入射单色光的光强\\(I\\)成正比，可写成\n\\[\\bigg(\\dfrac{dN_{12}}{dt}\\bigg)_{吸收} = kN_1IB' \\]\n式中\\(k\\)为比例系数，\\(B'\\)称为受激吸收系数。当\\(E_2\\)和\\(E_1\\)两能级的简并度相同（相同温度和光照条件）时，受激辐射系数与受激吸收系数相等，即\\(B=B'\\)。\n\\(B=B'\\)时，受激吸收、受激辐射的强弱由\\(N_1,N_2\\)决定。\n若\\(N_1\u003eN_2\\)，则受激吸收\\(\u003e\\)受激辐射，只能使光强减弱。 若\\(N_2\u003eN_1\\)，则受激辐射\\(\u003e\\)受激吸收，可形成受激辐射光放大。 粒子数翻转和光放大 1. 粒子数正常分布\n温度为\\(T\\)的热平衡状态下，粒子数按能级的分布规律遵从玻尔兹曼分布律，即处于能级\\(E_i\\)的原子数\\(N_i\\)满足如下关系\n\\[N_i\\propto \\exp\\bigg(-\\dfrac{E_i}{kT}\\bigg) \\]\n所以有\n\\[\\dfrac{N_2}{N_1} = \\exp\\bigg(-\\dfrac{E_2-E_1}{kT}\\bigg)\u003c1 \\]\n热平衡状态下，低能级原子数\\(N_1\u003e\\)高能级原子数\\(N_2\\)\n当原子在热平衡状态正常分布时，受激吸收\\(\u003e\\)受激辐射，即\\(\\Delta I\u003c0\\)，不可能产生激光。\n2. 粒子数反转分布\n产生激光的必要条件：高能级原子数\\(N_2\u003e\\)低能级原子数\\(N_1,\\Delta I\u003e0\\)\n如何实现粒子数反转分布？\n激活物质（工作物质）——必须存在寿命较长的亚稳态能级 能量输入系统——使物质中有尽可能多的粒子吸收能量后跃迁到高能态。该能量输入过程称为激励或泵浦。激励的方式有：光激励、气体放电激励、化学激励等。 根据运行过程中所涉及的能级数，激活介质可分为三能级系统和四能级系统。\n三能级的缺点：因基态总是有大量的原子，因此实现粒子数反转需要有非常强的光泵浦（光抽运能力）\n激光器的基本构成 基本构成 工作物质（激活介质） 激励能源 光学谐振腔 激光的形成：光束在谐振腔内来回震荡，在激活介质中的传播，通过占主导的受激辐射使光得以放大，并输出激光。 光学谐振腔的作用 产生和维持振荡 提高光强 选择光束的传播方向 选择光振荡的频率 激光的特性和作用 激光的主要特性 方向性好 单色性好，氪灯单色性最好 能量集中亮度高 高相干性 激光的应用 方向性好：可用于定位、准直、定向、测距、导航等领域 相干性好：可广泛用于光学干涉测量和全息摄影、全息防伪等领域 能量集中度高：已被广泛应用于打孔、切割、焊接等精密机械加工；在医学上用于激光外科手术；在军事上用于作激光武器等 ","date":"2022-06-13T19:13:12+08:00","image":"https://kegalas.top/inferior/%E5%A4%A7%E5%AD%A6%E7%89%A9%E7%90%86%E5%85%AC%E5%BC%8F%E6%95%B4%E7%90%86/cover_huc6be90ba175cec12cafc892e1709e648_57796_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E5%A4%A7%E5%AD%A6%E7%89%A9%E7%90%86%E5%85%AC%E5%BC%8F%E6%95%B4%E7%90%86/","title":"大学物理公式整理"},{"content":"命题逻辑 联结词 否定联结词 \\(P\\) \\(\\neg P\\) 0 1 1 0 合取联结词 \\(P\\) \\(Q\\) \\(P\\wedge V\\) 0 0 0 0 1 0 1 0 0 1 1 1 析取联结词 \\(P\\) \\(Q\\) \\(P\\vee V\\) 0 0 0 0 1 1 1 0 1 1 1 1 条件联结词 \\(P\\) \\(Q\\) \\(P\\to V\\) 0 0 1 0 1 1 1 0 0 1 1 1 双条件联结词 \\(P\\) \\(Q\\) \\(P\\leftrightarrow V\\) 0 0 1 0 1 0 1 0 0 1 1 1 联结词的运算优先级 从高到低依次为，否定、合取、析取、条件、双条件\n命题公式 一些定义 定义1，命题变元与常元\n用于代表取值为真\\((T、1)\\)或假\\((F、0)\\)之一的变量，称为命题变元，通常用大写字母或带下标或上标的大写字母表示，如\\(P、Q、R、P_1、P_2\\)等。将\\(T\\)和\\(F\\)称为命题常元。\n通常把由命题常元、命题变元、联结词以及括弧组成的式子称为表达式,但是只有按照特定组合规则所形成的表达式才有实际意义。\n定义2，命题公式\n命题合式公式(简称命题公式):\n(1)(基础)单个命题常元或命题变元是命题合式公式\n(2)(归纳)如果A和B是命题公式,则\\(\\neg A\\)、\\((A\\wedge B)\\)、\\((A\\vee B)\\)、\\((A\\to B)\\)、\\((A\\leftrightarrow B)\\)是命题合式公式。\n(3)(极小性)只有有限次地应用条款(1)和(2)生成的表达式オ是命题合式公式\n定义3，子公式\n若\\(B\\)是命题公式\\(A\\)的一个连续段且\\(B\\)也是命题公式,则称\\(B\\)是\\(A\\)的个子公式。\n命题公式的赋值 对于有\\(n\\)个变元的公式，有\\(2^n\\)种不同赋值。\n永真式（重言式）\n一个命题公式在任何赋值下，其真值都为\\(T\\)，则称这个公式为永真式（重言式）\n永假式（矛盾式）\n一个命题公式在任何赋值下，其真值都为\\(F\\)，则称这个公式为永假式（矛盾式）\n偶然式\n既不是永真式也不是永假式，则为偶然式\n可满足式\n一个命题公式至少有一个赋值，使其真值为\\(T\\)，则称这个公式为可满足式。也即永真式和偶然式都是可满足式。不是可满足式的称为矛盾式。\n逻辑等价与蕴含 等价 定义\n给定两个命题公式\\(A\\)和\\(B4\\),设\\(P_1,P_2,\\cdots,P_n\\)为所有出现在A和B中的命题变元，但\\(P_i\\)不一定在\\(A\\)和\\(B\\)中同时出现，若对于\\(P_1,P_2,\\cdots,P_n\\)的任一赋值,\\(A\\)和\\(B\\)的真值都相同，则称\\(A\\)和\\(B\\)逻辑等价，记做\\(A\\Leftrightarrow B\\),读做“\\(A\\)等价于\\(B\\)”。\n下面列出常见的命题等价公式\n1.3.3-1\r1.3.3-2\r几个定理\n定理1（代入规则）\n设\\(A\\)、\\(B\\)是命题公式，其中\\(A\\)是重言式，\\(P\\)是\\(A\\)中的命题变元，如果将\\(A\\)中每一处出现的P均用B代入，则所得命题公式\\(A\\)仍然是一个重言式\n定理2\n设\\(A\\)、\\(B\\)是命题公式，则\\(A\\)和\\(B\\)逻辑等价,当且仅当\\(A\\leftrightarrow B\\)是一个重言式。\n定理3（替换规则）\n设\\(A\\)、\\(X\\)、\\(Y\\)是命题公式，\\(X\\)是\\(A\\)的子公式,且有\\(X\\Leftrightarrow Y\\)。如果将\\(A\\)中的\\(X\\)用\\(Y\\)来替换(不必每一处都替换)，则所得到的公式\\(B\\)与\\(A\\)等价,即\\(B\\Leftrightarrow A\\)。\n定理4（传递规则）\n设\\(A\\)、\\(B\\)、\\(C\\)是命题公式，若\\(A\\Leftrightarrow B\\)且\\(B\\Leftrightarrow C\\),则有\\(A\\Leftrightarrow C\\)。\n蕴含 设\\(A\\)、\\(B\\)是命题公式，如果\\(A\\to B\\)是一个重言式,则称\\(A\\)蕴含\\(B\\),记做\\(A\\Rightarrow B\\)。\n一些常见的蕴含公式\n1.3.7-1\r1.3.7-2\r证明蕴含式\\(A\\Rightarrow B\\)的一些方法：\n肯定前件法。假设\\(A\\)为\\(T\\)，如果能够推出\\(B\\)为\\(T\\)，则有\\(A\\Rightarrow B\\) 否定后件法。假设\\(B\\)为\\(F\\)，如果能够推出\\(A\\)为\\(F\\)，则有\\(A\\Rightarrow B\\) 几个定理\n定理1\n设\\(A\\)和\\(B\\)是任意两个命题公式，\\(A\\Leftrightarrow B\\)当且仅当\\(A\\Rightarrow B\\)且\\(B\\Rightarrow A\\).\n几个性质\n性质1\n设\\(A\\)、\\(B\\)是命题公式，如果\\(A\\Rightarrow B\\)且\\(A\\)是重言式，则\\(B\\)也是重言式\n性质2\n蕴含关系是传递的，即\\(A\\Rightarrow B\\)且\\(B\\Rightarrow C\\)，则\\(A\\Rightarrow C\\).\n性质3\n如果\\(A\\Rightarrow B\\)且\\(A\\Rightarrow C\\)，则\\(A\\Rightarrow B\\wedge C\\)\n性质4\n如果\\(A\\Rightarrow C\\)且\\(B\\Rightarrow C\\)，则\\(A\\vee B\\Rightarrow C\\)\n对偶式 定义\n设有命题公式\\(A\\)，其中仅含有联结词\\(\\neg,\\vee,\\wedge\\)，如果将\\(A\\)中的\\(\\vee\\)替换为\\(\\wedge\\)，\\(\\wedge\\)替换为\\(\\vee\\)，常元\\(T,F\\)也互相替换，所得到的公式记为\\(A^*\\)，则称\\(A^*\\)为\\(A\\)的对偶式。\n显然有，\\(A\\)也是\\(A^*\\)的对偶式，并且\\((A^*)^*=A\\)\n几个定理\n定理1\n设\\(A\\)和\\(A^*\\)是对偶公式，其中仅含有联结词\\(\\neg,\\vee,\\wedge\\)；\\(P_1,P_2,\\cdots,P_n\\)是出现在\\(A\\)和\\(A^*\\)中的所有命题变元，于是有\n\\[\\neg A(P_1,P_2,\\cdots,P_n)\\Leftrightarrow A^*(\\neg P_1,\\neg P_2,\\cdots,\\neg P_n) \\]\n\\[A(\\neg P_1,\\neg P_2,\\cdots,\\neg P_n)\\Leftrightarrow\\neg A^*(P_1,P_2,\\cdots,P_n) \\]\n定理2\n设\\(A,B\\)是命题公式，则有\n如果\\(A\\Leftrightarrow B\\)，则\\(A^*\\Leftrightarrow B^*\\) 如果\\(A\\Rightarrow B\\)，则\\(B^*\\Rightarrow A^*\\) 范式 析取范式和合取范式 析取式\n仅由若干命题变元和若干命题变元之否定通过联结词\\(\\vee\\)构成的命题公式。\n合取式\n仅由若干命题变元和若干命题变元之否定通过联结词\\(\\wedge\\)构成的命题公式。\n析取范式\n一个命题公式被称为析取范式，当且仅当它具有如下形式\n\\[A_1\\vee A_2\\vee\\cdots\\vee A_n \\]\n其中\\(A_1,A_2,\\cdots,A_n\\)是合取式。\n合取范式\n一个命题公式被称为合取范式，当且仅当它具有如下形式\n\\[A_1\\wedge A_2\\wedge\\cdots\\wedge A_n \\]\n其中\\(A_1,A_2,\\cdots,A_n\\)是析取式。\n主析取范式 极小项\n一个含\\(n\\)个命题变元的合取式，如果其中每个变元和其否定不同时存在，但两者之一必须出现且仅出现一次，则称该合取式为极小项。\n\\(n\\)个命题变元\\(P_1,P_2,\\cdots,P_n\\)可构成\\(2^n\\)个不同的极小项，其形式为：\n\\[\\tilde{P_1}\\wedge \\tilde{P_2}\\wedge\\cdots\\wedge \\tilde{P_n} \\]\n其中\\(\\tilde{P_i}\\)或者是\\(P_i\\)，或者是\\(\\neg P_i\\)\n可以用\\(n\\)位二进制编码表示极小项，例如\n\\[m_{010}=\\neg P_1\\wedge P_2\\wedge\\neg P_3 \\]\n有如下三个性质：\n每一个极小项当其编码与赋值相同时，其真值为\\(T\\)，在其余\\(2^n-1\\)种赋值下其真值均为\\(F\\). 任意两个不同的极小项的合取式永假。 所有极小项的析取式永真。 主析取范式\n设\\(P_1,P_2,\\cdots,P_n\\)是命题公式\\(A\\)中包含的所有命题变元，若由\\(P_1,P_2,\\cdots,P_n\\)的若干极小项析取所构成的析取范式与\\(A\\)等价，则称该析取范式是\\(A\\)的主析取范式。\n有如下定理\n定理1\n在一个命题公式\\(A\\)的真值表中，使\\(A\\)的真值为\\(T\\)的所有赋值所对应的极小项构成的析取范式即为\\(A\\)的主析取范式。\n主合取范式 极大项\n一个含\\(n\\)个命题变元的析取式，如果其中每个变元和其否定不同时存在，但两者之一必须出现且仅出现一次，则称改合取式为极大项。\n\\(n\\)个命题变元\\(P_1,P_2,\\cdots,P_n\\)可构成\\(2^n\\)个不同的极小项，其形式为：\n\\[\\tilde{P_1}\\vee \\tilde{P_2}\\vee\\cdots\\vee \\tilde{P_n} \\]\n其中\\(\\tilde{P_i}\\)或者是\\(P_i\\)，或者是\\(\\neg P_i\\)\n可以用\\(n\\)位二进制编码表示极大项，例如\n\\[M_{101}=\\neg P_1\\vee P_2\\vee\\neg P_3 \\]\n（编码注意与极小项意义相反）\n有如下三个性质：\n每一个极大项当其真值赋值与编码相同时，其真值为\\(F\\)，在其余\\(2^n-1\\)种赋值下其真值均为\\(T\\). 任意两个不同的极大项的析取式永真。 所有极大项的合取式永假。 主合取范式\n设\\(P_1,P_2,\\cdots,P_n\\)是命题公式\\(A\\)中包含的所有命题变元，若由\\(P_1,P_2,\\cdots,P_n\\)的若干极大项合取所构成的合取范式与\\(A\\)等价，则称该合取范式是\\(A\\)的主合取范式。\n有如下定理\n定理1\n在一个命题公式\\(A\\)的真值表中，使\\(A\\)的真值为\\(F\\)的所有赋值所对应的极大项构成的合取范式即为\\(A\\)的主合取范式。\n定理\n设\\(A\\)的主析取范式的各个极小项的下标转为十进制，组成的集合为\\(S_1\\{i_1,i_2,\\cdots,i_k\\}\\)；主合取范式的各个极大项的下标转为十进制，组成的集合为\\(S_2=\\{j_1,j_2,\\cdots,j_t\\}\\)，则有\n\\[S_1\\cap S_2=\\phi \\]\n\\[S_1\\cup S_2=\\{0,1,2,\\cdots,2^n-1\\} \\]\n范式的计算 除了可以用真值表来算，还可以通过德摩根定律等将“\\(\\to\\)”等不是析取、合取、否定的联结词转化，直到只剩析取、合取、否定。再通过添加、删除括号转化为主合取范式或主析取范式。\n命题逻辑的推理理论 推理规则 P规则：在推导过程中，前提可以在任何步骤引入。 T规则：在推导过程中，如果由已经推出的一个或多个公式蕴含\\(S\\)，则公式\\(S\\)可以引入到推导过程中。 证明方法 无义证明法。如果能证明\\(P\\)恒为假，则有\\(P\\to Q\\)恒为真，即\\(P\\Rightarrow Q\\) 平凡证明法。如果能证明\\(Q\\)恒为真，则有\\(P\\to Q\\)恒为真，即\\(P\\Rightarrow Q\\) 直接证明法。从一组前提出发，利用公认的推理规则，逻辑演绎得到有效结论。 归谬法（即反证法）。 定理\n\\(H_1,H_2,\\cdots,H_m,C\\)是公式，如果存在公式\\(R\\)，使得\\(H_1,H_2,\\cdots,H_m,\\neg C\\Rightarrow R\\wedge\\neg R\\)，则有\\(H_1,H_2,\\cdots,H_m\\Rightarrow C\\)\nCP规则法。 \\(H_1,H_2,\\cdots,H_n,R,C\\)是命题公式，根据输出律\\(E_{22}\\)推知\n\\[(H_1\\wedge H_2\\wedge\\cdots\\wedge H_n)\\to(R\\to C)\\Leftrightarrow(H_1\\wedge H_2\\wedge\\cdots\\wedge H_n\\wedge R)\\to C \\]\n因此，如果能够证明\\(H_1,H_2,\\cdots,H_n,R\\Rightarrow C\\)，则有\\(H_1,H_2,\\cdots,H_n\\Rightarrow R\\to C\\)\n谓词逻辑 谓词和量词 谓词 刻画单个个体的特性或者多个个体间关系的模式称为谓词。\n量词 全称量词\\(\\forall\\) 存在量词\\(\\exist\\) 几个规则\n应当使用\\(\\forall x(H(x)\\to D(x))\\)，而不能表示为\\(\\forall x(H(x)\\wedge D(x))\\)。\n应当使用\\(\\exist x(H(x)\\wedge D(x))\\)，而不能表示为\\(\\exist x(H(x)\\to D(x))\\)。\n谓词公式 定义\n谓词逻辑的合式公式（简称谓词公式）可由以下步骤生成\n原子公式（不出现联结词和量词的单个谓词）是谓词公式。 如果\\(A\\)和\\(B\\)是谓词公式，则\\(\\neg A,(A\\wedge B),(A\\vee B),(A\\to B),(A\\leftrightarrow B)\\)是谓词公式 如果\\(A\\)是谓词公式，并且\\(A\\)中有未被量化的个体变元\\(x\\)，则\\(\\forall xA(x)\\)和\\(\\exist xA(x)\\)是谓词公式。 只有有限次应用步骤1、2、3所得到的的公式才是谓词公式。 子公式\n若\\(B\\)是谓词公式\\(A\\)的一个连续段且\\(B\\)也是谓词公式，则称\\(B\\)是\\(A\\)的一个子公式。\n辖域\n紧跟\\(\\forall x\\)和\\(\\exist x\\)之后的最小的子公式称为该量词的辖域。\n约束变元\n在\\(\\forall x\\)和\\(\\exist x\\)辖域内\\(x\\)的一切出现称之为约束出现，这个\\(x\\)叫做约束变元。\n自由变元\n个体变元的非约束出现称为自由出现，自由出现的个体变元称为自由变元。\n约束变元的换名规则\n对某个约束变元换名时，需对量词的作用变元以及该量词辖域内所有受该量词约束的约束变元一起换名。 换名后的变元符号应是量词辖域内未出现的符号，最好是整个公式中未出现的符号。 谓词验算的永真公式 谓词公式的赋值 定义1\n对于一个谓词公式，若给它指定一个个体域\\(E\\)，再给所有谓词符均指派出确定的关系(具体的特性或关系)，给所有命题变元指派出确定命题(或者指定\\(T\\)或\\(F\\))，并为所有自由变元（注意不包含约束变元）分别指派\\(E\\)上确定的个体，则称为对谓词公式的一个赋值(指派或结识)。谓词公式经过赋值之后就变成了具有确定真值的命题。\n定义2\n设\\(A\\)是谓词公式，如果对于特定论域\\(E\\)上的任何赋值，\\(A\\)的真值都为真，则称谓词公式\\(A\\)在\\(E\\)上永真;如果对于特定论域\\(E\\)上的任何赋值，\\(A\\)的真值都为假，则称谓词公式\\(A\\)在\\(E\\)上永假;若特定论域\\(E\\)上存在一种赋值，使得\\(A\\)的真值都为真，则称谓词公式\\(A\\)在\\(E\\)上可满足。\n定义3\n设\\(A\\)是谓词公式，如果对于任何赋值，\\(A\\)的真值都为真，则称谓词公式\\(A\\)是永真式;如果对于任何赋值，\\(A\\)的真值都为假，则称谓词公式\\(A\\)是永假式;若存在一种赋值，使得\\(A\\)的真值为真，则称谓词公式\\(A\\)是可满足式。\n谓词演算的基本永真式 命题逻辑的等价式和蕴含式可在谓词逻辑中推广使用 量词的否定律 \\[\\neg\\forall xP(x)\\Leftrightarrow \\exist x\\neg P(x) \\]\n\\[\\neg\\exist xP(x)\\Leftrightarrow \\forall x\\neg P(x) \\]\n量词辖域的扩张与收缩律 2.3.2.3\r量词的分配律 2.3.2.4-1\r2.3.2.4-2\r多重量词律 2.3.2.5-1\r2.3.2.5-2\r其他 \\(\\forall xP(x)\\Rightarrow P(y)\\)，\\(y\\)是论域中的任一确定个体。\n\\(P(y)\\Rightarrow\\exist xP(x)\\)，\\(y\\)是论域中的某个确定个体。\n\\(\\forall xP(x)\\Rightarrow\\exist xP(x)\\)\n谓词逻辑的推理理论 存在指定原则（ES） \\[\\frac{\\exist xP(x)}{\\therefore P(a)} \\]\n\\(a\\)是个体常元，注意所指定的个体常元要使得谓词为真。\n全称指定原则（US） \\[\\frac{\\forall xP(x)}{\\therefore P(y)} \\]\n\\(y\\)是自由变元，也可以指定到个体常元\\(a\\)\n\\[\\frac{\\forall xP(x)}{\\therefore P(a)} \\]\n注意如果同时指定\\(\\exist xP(x)\\)和\\(\\forall xQ(x)\\)，应当先指定\\(P(a)\\)，再指定\\(Q(a)\\)，才能保证两者都为真。\n存在推广原则（EG） \\[\\frac{P(a)}{\\therefore\\exist xP(x) } \\]\n全称推广原则（UG） \\[\\frac{\\Gamma\\Rightarrow P(x)}{\\therefore\\Gamma\\Rightarrow\\forall xP(x)} \\]\n\\(\\Gamma\\)是已知公理和前提的合取，\\(\\Gamma\\)中没有自由变元\\(x\\)的出现。\n集合 集合的表示方法 列举法 描述法：用自然语言或谓词描述集合中元素的共同特征。 归纳定义法（见后） 集合间的关系 外延性公理\n两个集合\\(A,B\\)相等，记为\\(A=B\\)，当且仅当它们有相同的元素，即\n\\[A=B\\Leftrightarrow \\forall x(x\\in A\\leftrightarrow x\\in B) \\]\n两个集合不相等，通常记为\\(A\\neq B\\)\n子集\n设\\(A、B\\)是任意的两个集合，若集合\\(A\\)的每个元素都是集合\\(B\\)的元素，则称\\(A\\)为\\(B\\)的子集或称\\(B\\)包含\\(A\\),记为\\(A\\subseteq B\\)或\\(B\\supseteq A\\)，用逻辑公式表示为\n\\[A\\subseteq B\\Leftrightarrow\\forall x(x\\in A\\to x\\in B) \\]\n如果\\(A\\)不是\\(B\\)的子集，通常记为\\(A\\nsubseteq B\\)\n真子集\n如果集合\\(A\\)的每一个元素都属于\\(B\\)，但集合\\(B\\)中至少有一个元素不属于\\(A\\)，则称\\(A\\)为\\(B\\)的真子集，记为\\(A\\subset B\\)，用逻辑公式表示为\n\\[A\\subset B\\Leftrightarrow\\forall x(x\\in A\\to x\\in B)\\wedge \\exist y(y\\in B\\wedge y\\notin A)\\Leftrightarrow(A\\subseteq B)\\wedge(A\\neq B) \\]\n全集\n在一定范围内所有事物组成的集合称为该范围内的全集记为\\(U\\)，用逻辑公式表示为\n\\[U = \\{x|P(x)\\vee\\neg P(x)\\} \\]\n其中，\\(P(x)\\)是任意的谓词\n空集\n不含任何元素的集合称为空集，记为\\(\\phi\\)，用逻辑公式表示为\n\\[\\phi = \\{x|P(x)\\wedge\\neg P(x)\\} \\]\n其中，\\(P(x)\\)是任意的谓词，并且显然有\\(|\\phi|=0\\)\n几个定理\n定理1\n空集是任一集合的子集，并且是任何非空集合的真子集。\n定理2\n设\\(A,B,C\\)是集合，若\\(A\\subseteq B\\)且\\(B\\subseteq C\\)，则\\(A\\subseteq C\\)。\n定理3\n集合\\(A,B\\)相等的充要条件是\\(A,B\\)互为子集。\n定理3.1\n对于任何集合\\(A\\)，有\\(A\\subseteq A\\)\n定理4\n空集是唯一的。\n集合的运算 集合的交，交集\n\\[A\\cap B = \\{x|x\\in A\\wedge x\\in B\\} \\]\n集合的并，并集\n\\[A\\cup B = \\{x|x\\in A\\vee x\\in B\\} \\]\n集合的差，相对补集\n\\[A-B=\\{x|x\\in A\\wedge x\\notin B\\} \\]\n集合的补，绝对补集\n\\[\\bar{A}=U-A=\\{x|x\\in U\\wedge x\\notin A\\} \\]\n集合的对称差\n\\[A\\oplus B=(A-B)\\cup(B-A)=\\{x|(x\\in A\\wedge x\\notin B)\\vee(x\\in B\\wedge x\\notin A)\\} \\]\n集合的环积\n\\[A\\otimes B=\\overline{A\\oplus B}=(A\\cap B)\\cup(\\bar{A}\\cap\\bar{B})=\\{x|(x\\in A\\wedge x\\in B)\\vee(x\\notin A\\wedge x\\notin B)\\} \\]\n满足如下运算律\n3.2.1\r幂集\n给定集合\\(A\\)，由\\(A\\)所有子集为元素构成的集合，称为\\(A\\)的幂集，记作\\(\\rho(A)\\)。若\\(|A|=n\\)，则有\\(|\\rho(A)=2^n|\\)\n容斥原理 定理1\n设\\(A_1,A_2\\)是有限集合，其元素个数分别为\\(|A_1|,|A_2|\\)，则\\(|A_1\\cup A_2|=|A_1|+|A_2|-|A_1\\cap A_2|\\)\n容斥原理\n将上式推广，得\n\\[|A_1\\cup A_2\\cup\\cdots\\cup A_n|=\\sum_{i=1}^n|A_i|-\\sum_{1\\leq i \u003c j\\leq n}|A_i\\cap A_j|+\\\\ \\sum_{1\\leq i \u003c j \u003c k\\leq n}|A_i\\cap A_j\\cap A_k|-\\cdots+(-1)^{n+1}|A_1\\cap A_2\\cap\\cdots\\cap A_n| \\]\n归纳证明 集合的归纳定义 基础条款：指出某些事物属于\\(S\\)，其功能是给集合\\(S\\)指定初始元素使其不为空。 归纳条款：指出由集合\\(S\\)中的已有元素构造新元素的办法。 极小性条款：断言一个事物除非能有限次应用基础条款和归纳条款构成，否则它不在集合\\(S\\)中。 归纳法证明 基础步骤。对于基础条款中的指定的每个初始元素\\(t\\)，证明命题\\(P(t)\\)为真。 归纳步骤。证明如果事物\\(x,y,\\cdots\\)有\\(P\\)性质，那么用归纳条款指定的方法组合它们所得的新元素也具有性质\\(P\\) 数学归纳法 第一原理\n（归纳基础）证明\\(P(0)\\)为真（可以用任何办法） （归纳假设）任取\\(n(n\\ge0)\\)，假设\\(P(n)\\)为真。 （归纳推理）由\\(P(n)\\)为真，推出\\(P(n+1)\\)也为真。 第二原理\n（归纳基础）证明\\(P(0)\\)为真（可以用任何办法） （归纳假设）假设对任意的\\(n \u003c k\\)，均有\\(P(k)\\)为真。 （归纳推理）证明\\(P(n)\\)也为真。 集合的笛卡尔积 序偶\n两个元素\\(a\\)和\\(b\\)组成的具有固定次序的序列称为序偶或二元组，记为\\(\u003c a,b\u003e\\)。对于序偶\\(\u003c a,b\u003e\\)，\\(a\\)称为第\\(1\\)元素，\\(b\\)称为第\\(2\\)元素。\n序偶的相等\n两个序偶\\(\u003c a,b\u003e\\)和\\(\u003c c,d\u003e\\)相等，记为\\(\u003c a,b\u003e=\u003c c,d\u003e\\)，当且仅当\\(a=c\\)且\\(b=d\\)。\n笛卡尔积（叉积）\n\\[A\\times B=\\{\u003c a,b\u003e|a\\in A,b\\in B\\} \\]\n对于多个集合，有\n\\[A_1\\times A_2\\times\\cdots\\times A_n=\\{\u003c a_1,a_2, \\cdots,a_n\u003e|a_i\\in A_i,1\\leq i\\leq n\\} \\]\n其中\\(A\\times A\\times\\cdots\\times A\\)（\\(n\\)个）可以记作\\(A^n\\)\n规定\\(\u003c a_1,a_2, \\cdots,a_n\u003e=\u003c\u003c a_1,a_2, \\cdots,a_{n-1}\u003e,a_n\u003e\\)，而不等于\\(\u003c a_1,\u003c a_2, \\cdots,a_n\u003e\u003e\\)等等其他序偶。\n关于笛卡尔积有如下定理\n定理1\n\\(A\\times(B\\cup C)=(A\\times B)\\cup(A\\times C)\\) \\(A\\times(B\\cap C)=(A\\times B)\\cap(A\\times C)\\) \\((A\\cup B)\\times C=(A\\times C)\\cup(B\\times C)\\) \\((A\\cap B)\\times C=(A\\times C)\\cap(B\\times C)\\) 定理2\n如果\\(A_i(i=1,2,\\cdots,n)\\)都是有限集合，那么\n\\[|A_1\\times A_2\\times\\cdots\\times A_n|=|A_1|\\cdot|A_2|\\cdot\\cdots\\cdot|A_n| \\]\n二元关系 关系的定义 两个集合\\(A\\)和\\(B\\)的笛卡儿积\\(A\\times B\\)的任一子集\\(R\\),称为集合\\(A\\)到\\(B\\)上的二元关系。二元关系\\(R\\)是由序偶构成的集合，若\\(\u003c x,y\u003e\\in R\\)，则称\\(x\\)与\\(y\\)有\\(R\\)关系，也记为\\(xRy\\);否则,\\(\u003c x,y\u003e\\notin R\\)，称\\(x\\)与\\(y\\)没有\\(R\\)关系，也记为\\(x\\cancel{R}y\\)。\n设\\(R\\)是集合\\(A\\)到\\(B\\)的二元关系。集合\\(A\\)称为\\(R\\)的前域，集合\\(B\\)称为\\(R\\)的陪域。集合\\(\\{x|(\\exist y)(\u003c x,y\u003e\\in R)\\}\\)称为\\(R\\)的定义域，记为\\(domR\\)。集合\\(\\{y|(\\exist x)(\u003c x,y\u003e)\\in R)\\}\\)称为\\(R\\)的值域，记为\\(ranR\\)。显然, \\(domR\\subseteq A\\)和\\(ranR\\subseteq B\\)。\n关系的表示 关系矩阵 \\[r_{ij}= \\left\\{\\begin{matrix} 1, if\u003c a_i,b_j\u003e\\in R\\\\ 0, if\u003c a_i,b_j\u003e\\notin R \\end{matrix}\\right. \\]\n关系图 3.6.2\r关系的运算 所有集合的运算对于二元关系同样适用。\n复合运算\n设\\(R\\)为集合\\(A\\)到\\(B\\)的二元关系，\\(S\\)为\\(B\\)到\\(C\\)的二元关系，令\n\\[R\\circ S=\\{\u003c a,c\u003e|a\\in A\\wedge c\\in C\\wedge(\\exist b)(b\\in B\\wedge\u003c a,b\u003e\\in R\\wedge \u003c b,c\u003e\\in S)\\} \\]\n称\\(R\\circ S\\)为\\(R\\)与\\(S\\)的复合关系。\n复合运算可以通过关系的矩阵的运算来实现\n\\[\\bm{M}_{R\\circ S}=\\bm{M}_R\\odot\\bm{M}_S \\]\n其中\\(\\odot\\)是布尔乘法运算，\\(c_{ij}=\\bigvee_{k=1}^{n}(a_{ik}\\wedge b_{kj})\\)\n复合运算有如下定理\n定理1\n\\((R\\circ S)\\circ T=R\\circ(S\\circ T)\\)\n关系的逆，逆关系\n\\[R^{-1}=\\{\u003c b,a\u003e|\u003c a,b\u003e\\in R\\} \\]\n关系矩阵即为原矩阵的转置\n关系图即将箭头反向\n有如下定理\n定理1\n\\((R^{-1})^{-1}=R\\) \\((R_1\\cup R_2)^{-1}=R_1^{-1}\\cup R_2^{-1}\\) \\((R_1\\cap R_2)^{-1}=R_1^{-1}\\cap R_2^{-1}\\) \\((\\overline{R})^{-1}=\\overline{R^{-1}}\\)，其中\\(\\overline{R}=(A\\times B)-R\\)，\\(\\overline{R^{-1}}=(B\\times A)-R^{-1}\\)。 \\((R_1-R_2)^{-1}=R_1^{-1}-R_2^{-1}\\) 定理2\n\\[(R\\circ S)^{-1}=S^{-1}\\circ R^{-1} \\]\n集合上的二元关系及其特性 集合上的二元关系 集合\\(A\\)与\\(A\\)的笛卡尔积\\(A\\times A\\)的子集称为\\(A\\)上的二元关系。\n相等关系\n\\[I_A=\\{\u003c a,a\u003e|a\\in A\\} \\]\n\\(R\\)的幂次\n设\\(R\\)是\\(A\\)上的二元关系，\\(n\\in Z^+\\)，称\\(R\\circ R\\circ\\cdots\\circ R\\)(n个)为\\(R\\)的\\(n\\)次幂。记为\\(R^n\\)\n约定\\(R^0=I_A\\)\n有如下定理\n定理1\n\\(R^m\\circ R^n=R^{m+n}\\) \\((R^m)^n=R^{mn}\\) 定理2\n设存在\\(i,j\\in R\\)，使得\\(R^i=R^j\\)，则有\n对任意\\(k\\ge 0, R^{i+k}=R^{j+k}\\) 对任意\\(k,m\\ge 0, R^{i+md+k}=R^{i+k}\\)，其中\\(d=j-i\\) 记\\(S=\\{R_0,R^1,\\cdots,R^{j-1}\\}\\)，对于任意\\(n\\in N\\)，均有\\(R^n\\in S\\) 二元关系的特性 自反性。对于\\(A\\)中的每个元素\\(a\\)，都有\\(aRa\\)，则称\\(R\\)在\\(A\\)上是自反的。 反自反性。对于\\(A\\)中的每个元素\\(a\\)，都有\\(a\\cancel{R}a\\)。空集上的空关系即是自反的也是反自反的。 对称性。对于任意\\(a,b\\in A\\)，若有\\(aRb\\)，则必有\\(bRa\\)。 反对称性。对于任意\\(a,b\\in A\\)，若有\\(aRb\\)且\\(bRa\\)，则必有\\(a=b\\)。若关系图上只有零个或多个自回路，则既是对称的，又是反对称的。 传递性。对于任意\\(a,b,c\\in A\\)，若\\(aRb,bRc\\)则必有\\(aRc\\)。 关系的闭包运算 设\\(R\\)是集合\\(A\\)上的二元关系，如果\\(A\\)上另外一个二元关系\\(R'\\)满足：\n\\(R'\\)是自反的（对称的，传递的） \\(R'\\subseteq R\\) 对于\\(A\\)上任何自反的（对称的，传递的）关系\\(R''\\)，若\\(R''\\subseteq R\\)，有\\(R''\\subseteq R'\\)，则称\\(R'\\)是\\(R\\)的自反（对称，传递）闭包，记为\\(r(R)(s(R),t(R))\\)。 有如下定理\n定理1\n\\(R\\)是自反的当且仅当\\(r(R)=R\\) \\(R\\)是对称的当且仅当\\(s(R)=R\\) \\(R\\)是传递的当且仅当\\(t(R)=R\\) 定理2\n\\(r(R)=R\\cup I_A\\) \\(s(R)=R\\cup R^{-1}\\) \\(t(R)=\\bigcup_{i=1}^{\\infty}R^i\\) 定理3\n假设\\(|A|=n\\)，那么\\(t(R)=\\bigcup_{i=1}^{n}R^i\\)\n定理4\n如果\\(R\\)是自反的，那么\\(s(R),t(R)\\)也是自反的。 如果\\(R\\)是对称的，那么\\(r(R),t(R)\\)也是对称的。 如果\\(R\\)是传递的，那么\\(r(R)\\)也是传递的。 定理5\n\\(sr(R)=rs(R)\\)，（\\(sr(R)=s(r(R))\\)以下运算顺序相同）。 \\(tr(R)=rt(R)\\) \\(ts(R)\\subseteq st(R)\\) 等价关系 集合的划分 给定非空集合\\(A\\)和集合簇\\(\\pi=\\{A_1,A_2,\\cdots,A_m\\}\\)，如果\n\\(A_i\\subseteq A\\)且\\(A_i\\neq\\phi\\) \\(A=\\bigcup_{i=1}^{m}A_i\\) \\(A_i\\cap A_j=\\phi, i\\neq j\\) 那么称\\(\\pi\\)是\\(A\\)的一个划分，若\\(\\pi\\)满足1.2.则称\\(\\pi\\)是\\(A\\)的一个覆盖。\n等价关系和等价类 等价关系\n\\(R\\)是\\(A\\)上的二元关系，若\\(R\\)是自反的、对称的、传递的，则称\\(R\\)是等价关系。\n等价类\n设\\(R\\)是非空集合\\(A\\)上的等价关系，对于任意\\(a\\in A\\)，称集合\\([a]_R=\\{x|x\\in A,xRa\\}\\)为\\(a\\)关于\\(R\\)的等价类，\\(a\\)称为等价类\\([a]_R\\)的代表元素。如果等价类个数有限，则\\(R\\)的不同等价类的个数叫做\\(R\\)的秩，否则秩是无限的。\n有如下定理\n定理1\n设\\(R\\)是非空集合\\(A\\)上的等价关系，对于\\(a,b\\in A\\)有\\(aRb\\)，当且仅当\\([a]_R=[b]_R\\)\n商集\n设\\(R\\)是集合\\(A\\)上的等价关系，由\\(R\\)确定的所有等价类组成的集合，称为集合\\(A\\)上关于\\(R\\)的商集，记为\\(A/R\\)\n\\[A/R = \\{[x]_R|x\\in A\\} \\]\n有如下定理\n定理1\n任取\\(x\\in A\\)，\\([x]_R\\neq\\phi\\) 任取\\(x,y\\in A\\)，要么\\([x]_R=[y]_R\\)，要么\\([x]_R\\cap[y]_R=\\phi\\) \\(\\bigcup_{x\\in A}[x]_R=A\\) 定理2\n设\\(\\pi\\)是非空集合\\(A\\)的一个划分，则\\(A\\)上的二元关系\\(R=\\bigcup_{B\\in\\pi} B\\times B\\)是\\(A\\)上的等价关系（称为由划分\\(\\pi\\)诱导的\\(A\\)上的等价关系）。\n定理3\n设\\(R_1\\)和\\(R_2\\)是非空集合\\(A\\)上的等价关系，则\\(R_1=R_2\\Leftrightarrow A/R_1=A/R_2\\)\n定理4\n设\\(R\\)是非空集合\\(A\\)上的任意一个等价关系,\\(\\pi\\)是\\(A\\)的任意一个划分，那么\\(R\\)诱导出\\(\\pi\\)当且仅当\\(\\pi\\)诱导出\\(R\\)。即说明等价关系和集合的划分是一一对应的。\n序关系 偏序集合的概念与表示 偏序\n如果\\(A\\)上的关系\\(R\\)是自反的，反对称的和传递的，那么\\(R\\)是\\(A\\)上的偏序，通常用符号\\(\\preceq\\)表示，称序偶\\(\u003c A,\\preceq\u003e\\)为偏序集合。通常用\\(x\\prec y\\)表示\\(x\\preceq y\\)且\\(x\\neq y\\)\n可比与不可比\n在偏序集合\\(\u003c A,\\preceq\u003e\\)中，对于元素\\(a,b\\in A\\)，如果\\(a\\preceq b\\)或者\\(b\\preceq a\\)，那么称\\(a\\)或\\(b\\)是可比的，否则不可比的。\n盖住\n在偏序集合\\(\u003c A,\\preceq\u003e\\)中，对于\\(x,y\\in A\\)，如果\\(x\\prec y\\)且没有其他元素\\(z\\in A\\)满足\\(x\\prec z\\prec y\\)，则称\\(y\\)盖住\\(x\\)\n哈斯图\n3.10.1\r链\n设\\(\u003c A,\\preceq\u003e\\)是一个偏序集合，\\(B\\subseteq A\\)。如果\\(B\\)中的任意两个元素都是可比的，那么称\\(B\\)为\\(\u003c A，\\preceq\u003e\\)中的链，\\(B\\)中元素的个数称为该链的长度。如果\\(B\\)中的任意两个不同的元素都是不可比的，那么称\\(B\\)为\\(\u003c A，\\preceq\u003e\\)中的反链。\n偏序集合中的特殊元素 极大元\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。如果\\(b\\in B\\)，且\\(B\\)中不存在元素\\(x\\)，使得\\(x\\neq b\\)且\\(b\\preceq x\\)，那么\\(b\\)称为\\(B\\)的极大元。\n极小元\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。如果\\(b\\in B\\)，且\\(B\\)中不存在元素\\(x\\)，使得\\(x\\neq b\\)且\\(x\\preceq b\\)，那么\\(b\\)称为\\(B\\)的极小元。\n最大元\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。如果\\(b\\in B\\)，对于任意元素\\(x\\in B\\)，均有\\(x\\preceq b\\)，那么\\(b\\)称为\\(B\\)的最大元。\n最小元\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。如果\\(b\\in B\\)，对于任意元素\\(x\\in B\\)，均有\\(b\\preceq x\\)，那么\\(b\\)称为\\(B\\)的最小元。\n有如下定理\n定理1\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。如果\\(B\\)有最大（最小元），那么它是唯一的。\n上界\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。如果\\(a\\in A\\)，对于任意元素\\(b\\in B\\)，均有\\(b\\preceq a\\)，那么\\(a\\)称为\\(B\\)的上界。\n下界\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。如果\\(a\\in A\\)，对于任意元素\\(b\\in B\\)，均有\\(a\\preceq b\\)，那么\\(a\\)称为\\(B\\)的下界。\n最小上界（上确界）\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。\\(a\\)为\\(B\\)的上界，若对\\(B\\)的任意上界\\(a'\\)均有\\(a\\preceq a'\\)，则称\\(a\\)为\\(B\\)的最小上界或上确界。\n最大下界（下确界）\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。\\(a\\)为\\(B\\)的下界，若对\\(B\\)的任意下界\\(a'\\)均有\\(a'\\preceq a\\)，则称\\(a\\)为\\(B\\)的最大下界或下确界。\n有如下定理\n定理1\n若\\(B\\)有最小上界（最大下界），那么它是唯一的。\n定理2\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。\n若\\(b\\)是\\(B\\)的最大元，则\\(b\\)是\\(B\\)的极大元。 若\\(b\\)是\\(B\\)的最大元，则\\(b\\)是\\(B\\)的最小上界。 \\(b\\in B\\)，若\\(b\\)是\\(B\\)的上界，当且仅当\\(b\\)是\\(B\\)的最小上界。 若\\(b\\)是\\(B\\)的最小元，则\\(b\\)是\\(B\\)的极小元。 若\\(b\\)是\\(B\\)的最小元，则\\(b\\)是\\(B\\)的最大下界。 \\(b\\in B\\)，若\\(b\\)是\\(B\\)的下界，当且仅当\\(b\\)是\\(B\\)的最大下界。 定理3\n设\\(\u003c A,\\preceq\u003e\\)是非空有限偏序集，则\\(A\\)中必存在极大元和极小元。\n定理4\n设\\(\u003c A,\\preceq\u003e\\)是偏序集合，如果\\(A\\)中最长链的长度为\\(n\\)，则\\(A\\)中元素能划分为\\(n\\)个互不相交的反链。\n线序和良序 设\\(\u003c A, \\preceq\u003e\\)是偏序集合，如果任取\\(a,b\\in A\\)，都有\\(a\\preceq b\\)或者\\(b\\preceq a\\)，那么称\\(\\preceq\\)为\\(A\\)上的线序或全序。称\\(\u003c A. \\preceq\u003e\\)为线序集合，称\\(A\\)为链。\n如果\\(A\\)上的一个二元关系\\(R\\)是一个线序，且\\(A\\)的每一非空子集都有最小元，那么称\\(R\\)为\\(A\\)上的良序，称\\(\u003c A,R\u003e\\)为良序集合。\n有如下定理\n定理\n每一有限线序集合都是良序集合。\n函数与无限集合 函数的定义 注意对于每个\\(x\\in A\\)，都只和唯一一个\\(y\\in Y\\)有\\(f\\)关系。\\(y\\)是\\(x\\)的函数值或像，\\(x\\)是\\(y\\)的原像。\n定义域必须是整个前域，值域可以不是整个陪域。一般\\(X,Y\\)指的是前域和陪域。\n函数相等\n\\(f:A\\to B\\), \\(g:C\\to D\\)，如果\\(A=C,B=D\\)，且对于所有的\\(x\\in A\\)有\\(f(x)=g(x)\\)，则称\\(f,g\\)相等，记作\\(f=g\\)\n多元函数\n前域是\\(n\\)个集合的笛卡尔积，称为\\(n\\)元函数，像记作\\(f(x_1,x_2,\\cdots,x_n)\\)\n递归定义的函数 前域是归纳定义的集合时，可以采用递归定义方法来定义函数。规则是：用已经得到的元素函数值和给定的函数来计算新元素的函数值。\n特殊函数 单射\n任取\\(x_1,x_2\\in X\\)，如果\\(x_1\\neq x_2\\)，那么\\(f(x_1)\\neq f(x_2)\\)，则称\\(f\\)为单射函数，也称一对一函数。\n满射\n若任取\\(y\\in Y\\)，存在\\(x\\in X\\)，使得\\(f(x)=y\\)，则称为满射函数。\n双射\n既是单射又是满射，称为双射函数。也称一一对应函数。\n有如下定理\n定理1\n设\\(X,Y\\)是有限集合，\\(f:X\\to Y\\)\n若\\(f\\)是单射，则必有\\(|X|\\leq|Y|\\) 若\\(f\\)是满射，则必有\\(|X|\\ge|Y|\\) 若\\(f\\)是双射，则必有\\(|X|=|Y|\\) 定理2\n设\\(X\\)和\\(Y\\)是有限集合，\\(f\\)是从集合\\(X\\)到\\(Y\\)的函数。若\\(|X|=|Y|\\)，则\\(f\\)是单射，当且仅当\\(f\\)是满射。\n常数函数\n存在\\(c\\in Y\\)，对任意\\(x\\in X\\)，\\(f(x)=c\\)\n恒等函数\n\\(f(x)=x\\)\n置换（排列）\n对于函数\\(f:X\\to X\\)，若\\(f\\)是双射的，则称\\(f\\)为\\(X\\)上的置换或排列。\\(X\\)上的恒等函数称为恒等置换或者幺置换。\\(|X|=n\\)时称为\\(n\\)次置换，\\(|X|\\)无限时称为无限次置换。\n通常写成\n\\[P= \\begin{pmatrix} x_1 \u0026 x_2 \u0026 \\cdots \u0026 x_n\\\\ f(x_1) \u0026 f(x_2) \u0026 \\cdots \u0026 f(x_n) \\end{pmatrix} \\]\n复合函数和逆函数 类似于关系的复合运算\n但是注意书写顺序。\\(g\\diamond f\\)和\\(f\\circ g\\)的顺序正好相反\n定理1\n\\(f:X\\to Y,g:Y\\to Z\\)，那么\\(g\\diamond f\\)是\\(X\\)到\\(Z\\)的函数。\n定理2\n\\(h\\diamond(g\\diamond f)=(h\\diamond g)\\diamond f\\)\n\\(f^0=I_x\\) \\(f^{n+1}=f\\diamond f^n\\) 定理3\n\\(f:X\\to Y,g:Y\\to Z\\)\n若\\(f,g\\)满射，则\\(g\\diamond f\\)满射。 若\\(f,g\\)单射，则\\(g\\diamond f\\)单射。 若\\(f,g\\)双射，则\\(g\\diamond f\\)双射。 若\\(g\\diamond f\\)满射，则\\(g\\)满射 若\\(g\\diamond f\\)单射，则\\(f\\)单射 若\\(g\\diamond f\\)双射，则\\(g\\)满射，\\(f\\)单射。 逆函数 设\\(f\\)是双射函数，则\\(f^{-1}=\\{\u003c y,x\u003e|\u003c x,y\u003e\\in f\\}\\)。显然逆函数也是双射函数。\n定理1\n\\((f^{-1})^{-1}=f\\) \\(f^{-1}\\diamond f=I_X\\) \\(f\\diamond f^{-1}=I_X\\) 定理2\n\\((g\\diamond f)^{-1}=f^{-1}\\diamond g^{-1}\\)\n可数与不可数集合 集合的基数 基数\n度量\\(A\\)大小的数称为基数或势，记为\\(|A|\\)。\n等势\n若\\(A\\)到\\(B\\)能建立起双射函数，则称\\(A,B\\)等势，记为\\(A\\sim B\\)，或\\(|A|=|B|\\)\n定理1\n等势是任何集合簇上的等价关系。即是自反的、对称的、传递的。\n有限集合、无限集合\n含有有限个（包含0）元素的集合称为有限集合，不是有限集合的称为无限集合。\n定理1\n有限集合的任意子集是有限集合。无限集合的超集是无限集合。\n定理2\n无限集合存在与其等势的真子集。\n可数集 与自然数集\\(N\\)等势的集合称为可数无限集合，简称可数集。可数集的基数用\\(\\alef_0\\)表示。\n有限集和可数集通称为至多可数集。\n枚举\n设\\(A\\)是一个集合，如果\\(f\\)是从\\(N\\)或从\\(N_k=\\{0,1,2,\\cdots,k-1\\}\\)到\\(A\\)的一个满射函数，则称\\(f\\)为\\(A\\)的一个枚举。如果\\(f\\)是双射的，则称为无重复枚举，否则称为重复枚举。\n定理1\n一个无限集合\\(A\\)是可数集，当且仅当存在\\(A\\)的枚举。\n定理2\n可数无限集的任一无限子集是可数集。\n定理3\n任意两个可数集的并是可数集。\n定理4\n\\(N\\times N\\)是可数集。\n定理5\n可数个可数集的并是可数集。\n不可数集 与自然数集不等势的无限集称为不可数集\n定理1\n实数集的子集\\((0,1)\\)是不可数集\n基数的比较 Zemelo三歧性定理\n以下三条恰有一条成立\n|A|\u0026lt;|B| |A|\u0026gt;|B| |A|=|B| Cantor-Schroder-Bernstein定理\n\\(|A|\\leq|B|\\)且\\(|A|\\ge|B|\\)，则\\(|A|=|B|\\)\n定理3\n设\\(A\\)是任意有限集合，则\\(|A|\u003c\\alef_0\u003c\\alef\\)\n定理4\n任意无限集合必定存在可数无限子集\n定理5\n\\(\\alef_0\\)是最小的无限集基数\nCantor定理\n\\(|M|\u003c|\\rho (M)|\\)\n图论 图的基本概念 按边是否有方向，图可以分为有向图、无向图和混合图。\n设\\(G\\)是一个有向图，如果将\\(G\\)中的每条边的方向去掉就能得到一个无向图\\(G'\\)，则称\\(G'\\)为\\(G\\)的底图。\n邻接点\n关联于同一条边的两个结点被称为邻接点。\n邻接边\n关联于一个结点的两条边被称为邻接边。\n孤立结点\n不与任何结点邻接的结点称之为孤立节点\n零图\n仅由若干个孤立节点构成的图称为零图。\n平凡图\n仅由单个孤立节点组成的图称为平凡图。\n平行边\n\\(e_1=e_2=\\{u,v\\}\\)，若\\(e_1,e_2\\)是两条不同的边，则称\\(e_1,e_2\\)为平行边。\n自回路（环）\n\\(e=\\{u,u\\}\\)\n多重图\n有平行边的图。\n线图\n不含平行边的图。\n简单图\n不含自回路的图。\n结点的度数 与结点\\(v\\)关联的边数称为结点\\(v\\)的度数（无向图），记为\\(deg(v)\\)。\n如果是有向图，则以结点\\(v\\)为终点的边数称为入度\\(deg^-(v)\\)，为始点的边数称为出度\\(deg^+(v)\\)。显然有\\(deg(v)=deg^-(v)+deg^+(v)\\)\n有如下定理\n握手定理\n任何图中，所有节点的度数之和等于边数的两倍。\n定理2\n任何图中，奇数度的节点必有偶数个。\n定理3\n任何有向图中，所有节点的入度等于所有节点的出度。\n特殊图 无向完全图\n无向简单图中，任何两个不同结点间都恰有一条边相连。\\(n\\)个结点的无向完全图记为\\(K^n\\)。\n有向完全图\n有向图\\(G=\u003c V,E\u003e\\)满足\\(E=V\\times V\\)。记为\\(D_n\\)。\n二部图\n非零图，节点集合\\(V\\)可以划分成两个不相交的子集\\(X\\)和\\(Y\\)，使\\(G\\)中的每一条边的一个端点在\\(X\\)中而另一个端点在\\(Y\\)中，则称\\(G\\)为二部图，记为\\(G=\u003c X,E,Y\u003e\\)\n可以通过标号法确定一个图是不是二部图。\n二部图必无自回路，但可以有平行边。\n子图与补图 子图\n设\\(G=\u003c V,E\u003e\\)，\\(G'=\u003c V',E'\u003e\\)，若有\\(E'\\subseteq E\\)且\\(V'\\subseteq V\\)，则称\\(G'\\)是\\(G\\)的子图。\n生成子图\n\\(V'=V\\)时，\\(G'\\)是\\(G\\)的生成子图。\n导出子图\n设\\(G'\\)是\\(G\\)的子图，\\(V'\\)仅由\\(E'\\)中边相关联的结点组成，则称\\(G'\\)为由边集\\(E'\\)导出的子图。\n补图\n给定一个图\\(G\\)，由\\(G\\)中所有的结点及所有能使\\(G\\)成为完全图的添加边组成的图，称为\\(G\\)相对于完全图的补图，简称为\\(G\\)的补图，记为\\(\\bar{G}\\)。\n图的同构 设\\(G=\u003c V,E\u003e,G'=\u003c V',E'\u003e\\)，如果存在双射函数\\(f:V\\to V',g:E\\to E'\\)，对于任何\\(e\\in E,e=[v_i, v_j]\\)当且仅当\\(g(e)=[f(v_i),f(v_j)]\\)。则称\\(G,G'\\)同构，记作\\(G\\cong G'\\)。\n相互同构的图只是画法不同或者结点与边的命名不同而已。\n两幅图同构的必要条件\n结点数相同 边数相同 度数相同的结点数目相同 图的连通性 路和回路 通路\n经过的结点不重复的路。\n迹\n经过的边不重复的路。回路为闭迹，非回路为开迹。\n圈\n除始点和终点外没有相同结点的闭迹称为圈。长度为\\(k\\)的圈称为\\(k\\)圈，又可根据\\(k\\)分为奇圈和偶圈。\n定理1\n在一个具有\\(n\\)个节点的图中，如果两个结点连通，则两个结点间必有一条长度小于\\(n\\)的路（也存在小于\\(n\\)的通路）。\n定理2\n在一个具有\\(n\\)个节点的图中，如果存在闭迹，则必存在一条长度小于等于\\(n\\)的圈。\n定理3\n设\\(G\\)是一个无向图，若\\(G\\)中每个结点的度数大于等于\\(2\\)，\\(G\\)中必含有圈。\n定理4\n\\(G=\u003c V,E\u003e\\)是无向图，\\(|E|\u003e0\\)，\\(G\\)是二部图当且仅当\\(G\\)中不含有奇圈。\n无向图的连通性 割点与割点集\n删除某个结点和其相连边后，图变成不连通的，则称为割点。删除某个点集中的所有点和所连接边，图变成不连通的，并且删除该点集的任意真子集图仍然连通，则称这个点集为割点集。\nk连通\n由\\(G\\)产生一个不连通子图最少需要删去\\(k\\)个结点。则称\\(G\\)为\\(k\\)连通图。\n定理1\n无向图中，一个结点是割点，当且仅当存在两个结点间的每条路都要通过该节点。\n割边与割边集\n与割点相似。\nk边连通\n与\\(k\\)连通相似。\n定理1\n无向图中，一条边是割边，当且仅当它不包含在任一圈中。\n有向图的连通性 强连通，单侧连通，弱连通\n强连通则是两个结点双向可达。单侧连通则是单向可达。若联通则是看成无向图。\n定理1\n有向图是强连通的，当且仅当它存在一条回路，至少包含每个结点一次。\n最短路 见算法竞赛模板。\n图的矩阵表示 邻接矩阵 \\(AA^T\\)\n\\(G\\)中刚好有\\(b_{ij}\\)个结点，从\\(v_i\\)和\\(v_j\\)均有边引出到这些节点。\n\\(A^TA\\)\n\\(G\\)中刚好有\\(b_{ij}\\)个结点，以这些节点为始边，既有边到\\(v_i\\)又有边到\\(v_j\\)。\n\\(A\\times A\\)\n从\\(v_i\\)到\\(v_j\\)的路，长度为2的有\\(b_{ij}\\)条。\n同理可知\\(A^{(m)}\\)的含义。\n可达矩阵 \\(P(G)=A^{(0)}\\vee A^{(1)}\\vee\\cdots\\vee A^{(n-1)}\\)\n定理\n无向图是连通图，当且仅当可达矩阵所有元素都为1. 有向图是强连通图，当且仅当可达矩阵所有元素都为1. 有向图是单侧连通图，当且仅当\\(P\\vee P^T\\)所有元素都为1. 有向图是弱连通图，当且仅当以\\(A\\vee A^T\\)作为邻接矩阵求出来的可达矩阵\\(P'\\)所有元素都为1. 求传递闭包的快速算法 设\\(R\\)是集合\\(V\\)上的二元关系，\\(n\\in \\bm{Z}^+\\)，对于任意\\(a,b\\in V,\u003c a,b\u003e\\in R^n\\)，当且仅当\\(R\\)的关系图\\(G=\u003c V,E\u003e\\)中存在从\\(a\\)到\\(b\\)有长度为\\(n\\)的有向路。\n设\\(\\bm{M}_R\\)是\\(V\\)上二元关系\\(R\\)的关系矩阵，则\n\\[\\bm{M}_{t(R)}=\\bm{M}_R\\vee\\bm{M}_R^{(2)}\\vee\\cdots\\vee\\bm{M}_R^{(n)} \\]\n欧拉图与汉密尔顿图 欧拉图 欧拉路（欧拉迹）\n包含图中所有边的开迹。\n欧拉回路\n包含图中所有边的闭迹。\n欧拉图\n包含欧拉回路的图称为欧拉图。\n定理1\n无向图是欧拉图当且仅当图是连通的并且每个结点的度均为偶数。\n无向图中存在一条欧拉路，当且仅当图是联通的，并且图中恰有两个奇数度的点。并且这两个点是起点和终点。\n定理2\n有向图是欧拉图，当且仅当它是联通的，并且每个结点的出度等于入度。\n有向图有欧拉路，当且仅当它是联通的，并且除了两个结点以外都出度等于入度，这两个结点必须一个出度比入度大一，另一个入度比出度大一。\n汉密尔顿图 包含图中每个结点一次且仅一次的通路称为汉密尔顿路。包含图中每个结点一次且仅一次的圈叫汉密尔顿回路。含汉密尔顿回路的图叫做汉密尔顿图。\n定理1（必要条件）\n若\\(G\\)是汉密尔顿图，则对于结点集\\(V\\)的每一个非空子集\\(S\\)都有\n\\[\\omega(G-S)\\leq|S| \\]\n其中\\(\\omega(G-S)\\)表示\\(G\\)删除\\(S\\)中所有结点后得到的连通分支的个数。\n定理2（必要条件）\n设\\(G=\u003c X,E,Y\u003e\\)是无向连通二部图，其中\\(|X|=m,|Y|=n\\)，若\\(m\\neq n\\)，则必不是汉密尔顿图。\n若\\(|m-n|\u003e1\\)，则必不存在汉密尔顿路。\n定理3（充分条件）\n设\\(G=\u003c V,E\u003e\\)是含有\\(n(n\\ge3)\\)个节点的简单无向图，如果\\(G\\)中的任何两个不同结点的度数之和都大于等于\\(n-1\\)，则\\(G\\)中存在汉密尔顿路。\n如果都大于等于\\(n\\)，则存在汉密尔顿回路。\n平面图 平面嵌入\n将一个平面图\\(G\\)重新排列得到边不相交的图\\(G'\\)，\\(G'\\)称为一个平面嵌入。\n面的次数\n面\\(r\\)的边界回路长度称为面的次数，记作\\(deg(r)\\)\n定理1\n连通平面图，所有面的次数之和等于边数的两倍\n定理2\n连通平面图，有\\(n\\)个节点，\\(m\\)条边，\\(r\\)个面，则有\\(n-m+r=2\\)成立。\n若\\(n\\ge3\\)，则\\(m\\leq3n-6\\)\n若每个面至少由\\(k\\)边围成，则有\\(m\\leq\\frac{k(n-2)}{k-2}\\)\n同胚\n给定两个图\\(G_1\\)和\\(G_2\\)，如果它们本身是同构的，或者通过反复插入度为2的结点(在某边上嵌入结点)或反复删除度为2的结点(仅去除结点,其关联边拼接)后，能够使\\(G_1\\)和\\(G_2\\)同构，则称\\(G_1\\)和\\(G_2\\)在\\(2\\)度结点内同构，亦称同胚。\n库拉托夫斯基定理\n一个图是平面图，当且仅当它不包含与\\(K_{3,3}\\)和\\(K_5\\)同胚的子图。\n图的着色 图的结点着色 正常着色\n无向图，给每个结点指定一种颜色，若满足邻接的两个结点颜色不同，则称为正常着色。\n可k-着色\n可以用\\(k\\)种不同的颜色给无向图正常着色。\nk色图\n对无向图正常着色所需要的最少的颜色数，称为顶着色数，简称色数，记为\\(\\mathcal{X}(G)\\)。色数为\\(k\\)的图称为\\(k\\)色图\nWelch Powell着色法\n将图\\(G\\)中的结点按度数递减的次序进行排列。 用一种与已着色结点所着颜色不同的新的颜色\\(C\\)对排列最前的尚未着色的节点着色，并按排列次序对与前面已着上颜色\\(C\\)的结点均不相邻的每一结点着同样的颜色\\(C\\)。 重复2知道着色结束。 定理1\n任何图均满足\\(\\mathcal{X}(G)\\leq \\Delta(G)+1\\)。\\(\\Delta(G)=max\\{d(u)|u\\in V\\}\\)\n定理2\n\\(\\mathcal{X}(G)=2\\)，当且仅当\\(G\\)是二部图。\n平面图的着色 对偶图\n设\\(G=\u003c V,E\u003e\\)是平面图，\\(G'\\)是\\(G\\)的一个平面嵌入，\\(F(G')\\)是\\(G'\\)的面集合。构造图\\(G^*\\)，若\\(G^*\\)的结点集合\\(V(G^*)=F(G')\\)，且任取两个结点\\(f_1,f_2\\in V(G^*)\\)，\\(f_1\\)和\\(f_2\\)之间存在边\\(e\\)当且仅当\\(f_1\\)和\\(f_2\\)在\\(G'\\)中有一条公共边，则称\\(G^*\\)是\\(G\\)的对偶图。\n定理\n设\\(G=\u003c V,E\u003e\\)是一个连通简单平面图，且\\(|V|\\ge 3,|E|=m\\)，则\\(G\\)中必存在结点\\(u\\in V\\)，满足\\(deg(u)\\leq 5\\)。\n希伍德五色定理\n任何一个连通简单平面图都是5可着色的。\n四色定理\n平面图的色数不超过4。\n树 无向树的定义 平凡树\n只有一个孤立节点的树。\n定理1\n对于一个含有\\(n\\)个结点\\(m\\)条边的无向树，以下定义等价\n无圈且连通 无圈且\\(m=n-1\\) 连通且\\(m=n-1\\) 无圈，但任意新增一条边，恰得到一个圈 连通，且每条边都是割边 每一对结点有且只有一条通路 定理2\n任何一颗非平凡树中至少有两片树叶\n生成树 定理1\n任何一个无向连通图至少有一颗生成树\n定理2\n连通图中的一个圈与其任何一棵生成树的补至少有一条公共边。\n定理3\n一个边割集和任何一棵生成树至少有一条公共边。\n最小生成树及其算法\n见竞赛模板。\n根树及其应用 根树\n一棵有向树，恰有一个节点入度为0，其余节点入度都为1。\nm元树\n每个结点的出度均小于等于\\(m\\)的根树。\n每个节点的出度均等于\\(0\\)或\\(m\\)的根树称为正则\\(m\\)元树。\n定理1\n正则\\(m\\)元树\\(T\\)，其树叶数为\\(t\\)，分支结点数为\\(i\\)，则有\\((m-1)i=t-1\\)\n带权树\n如果一颗二元树\\(T\\)共有\\(n\\)片树叶，分别带权\\(\\omega_1,\\omega_2,\\cdots,\\omega_n\\)。定义这棵二元树\\(T\\)的权值为，\n\\[W(T)=\\sum_{i=1}^{n}\\omega_iL(\\omega_i) \\]\n其中\\(L(\\omega_i)\\)为带权\\(\\omega_i\\)的树叶的深度（根深度为0）。在所有带这些权的二元树中，具有最小权的二元树称为最优二元树。\n定理1\n最优二元树是一颗正则二元树。\n定理2\n最优二元树中，层数最大的分支节点的两个儿子所带权分别为最小的两个权。\n最优二元树的构造方法\n7.7.12\r前缀码\n给定一个以\\(0,1\\)组成序列为元素的集合，若没有一个序列是另一个序列的前缀，则该集合称为前缀码。\n利用有序正则二元树解决前缀码问题\n7.7.13\r","date":"2022-06-06T08:44:57+08:00","image":"https://kegalas.top/inferior/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6%E6%95%B4%E7%90%86/cover_huf80a3777f066c3f01437aeed10211fe1_29240_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6%E6%95%B4%E7%90%86/","title":"离散数学整理"},{"content":"[TOC]\n矩阵 几个特殊矩阵 方阵 行数与列数相同的矩阵\\(\\bold{A}_{n\\times n}\\)称为\\(n\\)阶矩阵或\\(n\\)阶方阵\n零矩阵 元素都是零的矩阵称为零矩阵，记作\\(\\bold O\\)\n三角矩阵 上三角矩阵\n主对角线以下的元素全为零的方阵，即\n\\[\\bold{A}_n=\\begin{bmatrix} a_{11} \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n}\\\\ 0 \u0026 a_{22} \u0026 \\cdots \u0026 a_{2n}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ 0 \u0026 0 \u0026 \\cdots \u0026 a_{nn} \\end{bmatrix} \\]\n下三角矩阵\n主对角线以上的元素全为零的方阵，即\n\\[\\bold{A}_n=\\begin{bmatrix} a_{11} \u0026 0 \u0026 \\cdots \u0026 0\\\\ a_{21} \u0026 a_{22} \u0026 \\cdots \u0026 0\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{n1} \u0026 a_{n2} \u0026 \\cdots \u0026 a_{nn} \\end{bmatrix} \\]\n对角阵 主对角线（左上到右下的对角线；右上到左下的是副对角线）以外的元素全为零的方阵，即\n\\[\\bold{A}_n=\\begin{bmatrix} a_{11} \u0026 \u0026 \u0026 \\\\ \u0026 a_{22} \u0026 \u0026 \\\\ \u0026 \u0026 \\ddots \u0026 \\\\ \u0026 \u0026 \u0026 a_{nn} \\end{bmatrix} \\]\n对角矩阵常记为\\(\\Lambda\\)或\\(diag(a_{11},a_{22},\\cdots,a_{nn})\\)\n单位矩阵 主对角线上全为1的对角矩阵称为单位矩阵，记作\\(\\bold{E}_n\\)，即\n\\[\\bold{E}_n=\\begin{bmatrix} 1 \u0026 \u0026 \u0026 \\\\ \u0026 1 \u0026 \u0026 \\\\ \u0026 \u0026 \\ddots \u0026 \\\\ \u0026 \u0026 \u0026 1 \\end{bmatrix} \\]\n系数矩阵 对于线性方程组\n\\[\\left\\{\\begin{matrix} 2x_1-2x_2+6x_4=-2 \\\\ 2x_1-x_2+2x_3+4x_4=-2 \\\\ 3x_1-x_2+4x_3+4x_4=-3 \\\\ x_1+x_2+x_3+8x_4=2 \\end{matrix}\\right. \\]\n其系数矩阵为\n\\[\\bold{A}=\\begin{bmatrix} 2 \u0026 -2 \u0026 0 \u0026 6\\\\ 2 \u0026 -1 \u0026 2 \u0026 4\\\\ 3 \u0026 -1 \u0026 4 \u0026 4\\\\ 1 \u0026 1 \u0026 1 \u0026 8 \\end{bmatrix} \\]\n增广矩阵 由线性方程组所有系数和常数项所构成的矩阵称为线性方程组的增广矩阵，并记为\\(\\tilde{\\bold{A}}=(\\bold{A,b})\\)或\\(\\tilde{\\bold{A}}=[\\bold{A,b}]\\)\n\\[\\tilde{\\bold{A}}=[\\bold{A,b}]=\\begin{bmatrix} 2 \u0026 -2 \u0026 0 \u0026 6 \u0026 -2\\\\ 2 \u0026 -1 \u0026 2 \u0026 4 \u0026 -2\\\\ 3 \u0026 -1 \u0026 4 \u0026 4 \u0026 -3\\\\ 1 \u0026 1 \u0026 1 \u0026 8 \u0026 2 \\end{bmatrix} \\]\n对称矩阵 满足\\(\\bold{A}^T=\\bold{A}\\)的矩阵称为对称矩阵，满足\\(\\bold{A}^T=-\\bold{A}\\)的矩阵称为反对称矩阵。\n行阶梯型矩阵 满足以下两个条件\n如果有零行（元素全为0的行），则零行位于非零行的下方 非零行（元素不全为0的行）的首个非零元素，其前面零元素的个数逐行增加。 最简行阶梯型矩阵：进一步满足非零行的首非零元均为1，且所在列的其余元素为0.\n初等矩阵 由\\(n\\)阶单位矩阵\\(\\bold{E}\\)经过一次初等变换所得到的矩阵称为初等矩阵或初等方阵。\n奇异矩阵 行列式为0的矩阵称为奇异矩阵。不为0的称为非奇异矩阵。\n可逆矩阵 见后\n伴随矩阵 矩阵\\(\\bold{A}\\)的各个元素的代数余子式\\(A_{ij}\\)所构成的如下矩阵\n\\[\\bold{A}^*= \\begin{bmatrix} A_{11} \u0026 A_{21} \u0026 \\cdots \u0026 A_{n1}\\\\ A_{12} \u0026 A_{22} \u0026 \\cdots \u0026 A_{n2}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ A_{1n} \u0026 A_{2n} \u0026 \\cdots \u0026 A_{nn} \\end{bmatrix} \\]\n即\\(\\bold{A}^*=(A_{ij})^T_{n\\times n}\\)，称为\\(A\\)的伴随矩阵。\n并且伴随矩阵满足\\(\\bold{AA^*}=\\bold{A^*A}=\\bold{|A|E}\\)\n并且可推知，当\\(\\bold{|A|}\\ne 0\\)时，有\\(\\bold{|A^*|}=\\bold{|A|}^{n-1}\\)\n另外注意，伴随矩阵的序号和原矩阵的序号相当于进行了转置。\n正交矩阵 见后\n矩阵的运算 加减法 对于矩阵\\(\\bold{A}=(a_{ij})_{m\\times n},\\bold{B}=(b_{ij})_{m\\times n}\\)，定义\n\\[\\bold{A\\pm B}=\\begin{bmatrix} a_{11}\\pm b_{11} \u0026 a_{12}\\pm b_{12} \u0026 \\cdots \u0026 a_{1n}\\pm b_{1n}\\\\ a_{21}\\pm b_{21} \u0026 a_{22}\\pm b_{22} \u0026 \\cdots \u0026 a_{2n}\\pm b_{2n}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{m1}\\pm b_{m1} \u0026 a_{m2}\\pm b_{m2} \u0026 \\cdots \u0026 a_{mn}\\pm b_{mn} \\end{bmatrix} \\]\n数乘 \\[\\lambda\\bold{A}=\\begin{bmatrix} \\lambda a_{11} \u0026 \\lambda a_{12} \u0026 \\cdots \u0026 \\lambda a_{1n}\\\\ \\lambda a_{21} \u0026 \\lambda a_{22} \u0026 \\cdots \u0026 \\lambda a_{2n}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ \\lambda a_{m1} \u0026 \\lambda a_{m2} \u0026 \\cdots \u0026 \\lambda a_{mn} \\end{bmatrix} \\]\n线性运算的运算规律 矩阵的加减法和数乘统称为矩阵的线性运算，满足以下运算律\n\\(\\bold{A+B=B+A}\\) \\(\\bold{(A+B)+C=A+(B+C)}\\) \\(\\bold{A+O=A}\\) \\(\\bold{A+(-A)=O}\\) \\(1\\bold{A=A}\\) \\((\\lambda\\mu)\\bold{A}=\\lambda(\\mu\\bold{A})=\\mu(\\lambda\\bold{A})\\) \\((\\lambda+\\mu)\\bold{A}=\\lambda\\bold{A}+\\mu\\bold{A}\\) \\(\\lambda(\\bold{A+B})=\\lambda \\bold{A}+\\lambda \\bold{B}\\) 乘积 设矩阵\\(\\bold{A}=(a_{ij})_{m\\times s},\\bold{B}=(b_{ij})_{s\\times n}\\)，其乘积是一个\\(m\\times n\\)矩阵，记为\\(\\bold{C}=(c_{ij})_{m\\times n}\\)\n\\[c_{ij}=\\sum^{s}_{k=1}a_{ik}b_{kj}=a_{i1}b_{1j}+a_{i2}b_{2j}+\\cdots+a_{is}b_{sj} \\]\n\\[(i=1,2,\\cdots,m;j=1,2,\\cdots,n) \\]\n由定义知，只有左边矩阵的列数等于右边矩阵的行数时，两个矩阵才能相乘。\n矩阵乘法满足如下运算规律\n\\(\\bold{(AB)C=A(BC)}\\) \\(\\bold{A(B+C)=AB+AC,(A+B)C=AC+BC}\\) \\(\\lambda(\\bold{AB})=(\\lambda\\bold{A)B}=\\bold{A}(\\lambda\\bold{B})\\) \\(\\bold{A}_{m\\times n}\\bold{E}_n=\\bold{E}_m\\bold{A}_{m\\times n}=\\bold{A}_{m\\times n}\\) \\(\\bold{A}^k\\bold{A}^l=\\bold{A}^{k+l},(\\bold{A}^k)^l=\\bold{A}^{kl}\\) 注意，由于矩阵乘法不满足交换律，故一般情况下，\\((\\bold{AB})^k\\ne\\bold{A}^k\\bold{B}^k\\)\n转置 将矩阵\\(\\bold{A}\\)中的行换成同序数的列而得到的矩阵，称之为\\(\\bold{A}\\)的转置矩阵，记作\\(\\bold{A}^T\\)或\\(\\bold{A}'\\)，即若\n\\[\\bold{A}=\\begin{bmatrix} a_{11} \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n}\\\\ a_{21} \u0026 a_{22} \u0026 \\cdots \u0026 a_{2n}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{m1} \u0026 a_{m2} \u0026 \u0026 a_{mn} \\end{bmatrix} \\]\n\\[\\bold{A}^T=\\begin{bmatrix} a_{11} \u0026 a_{21} \u0026 \\cdots \u0026 a_{m1}\\\\ a_{12} \u0026 a_{22} \u0026 \\cdots \u0026 a_{m2}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{1n} \u0026 a_{2n} \u0026 \u0026 a_{mn} \\end{bmatrix} \\]\n转置满足以下运算律\n\\((\\bold{A}^T)^T=\\bold{A}\\) \\((\\bold{A+B})^T=\\bold{A}^T+\\bold{B}^T\\) \\((\\lambda\\bold{A})^T=\\lambda\\bold{A}^T\\) \\((\\bold{AB})^T=\\bold{B}^T\\bold{A}^T\\) 可逆矩阵 设\\(\\bold{A}\\)为\\(n\\)阶方阵，若存在\\(n\\)阶方阵\\(\\bold{B}\\)，使得\\(\\bold{AB=BA=E}_n\\)，则称\\(\\bold{A}\\)为可逆矩阵，或称其为可逆的。称\\(\\bold{B}\\)为\\(\\bold{A}\\)的逆矩阵。\\(\\bold{B}=\\bold{A}^{-1}\\).\n设\\(\\bold{A},\\bold{B}\\)都为\\(n\\)阶方阵，若\\(\\bold{AB=E}_n\\)，则\\(\\bold{A},\\bold{B}\\)都可逆，并且\n\\[\\bold{A}^{-1}=\\bold{B},\\bold{B}^{-1}=\\bold{A} \\]\n可逆矩阵的性质 若\\(\\bold{A}\\)可逆，则\\(\\bold{A}\\)的逆矩阵唯一. 若\\(\\bold{A}\\)可逆，则\\(\\bold{A}^{-1}\\)也可逆，并且\\(\\bold{A}=(\\bold{A}^{-1})^{-1}\\) 若\\(\\bold{A}\\)可逆，数\\(\\lambda\\ne0\\)，则\\(\\lambda\\bold{A}\\)可逆，并且\\((\\lambda\\bold{A})^{-1}=\\frac{1}{\\lambda}\\bold{A}^{-1}\\) 若\\(\\bold{A}\\)、\\(\\bold{B}\\)均为\\(n\\)阶可逆方阵，则\\(\\bold{A}\\bold{B}\\)也可逆，且\\((\\bold{A}\\bold{B})^{-1}=\\bold{B}^{-1}\\bold{A}^{-1}\\) 若\\(\\bold{A}\\)可逆，则\\(\\bold{A}^{T}\\)也可逆，并且\\((\\bold{A}^T)^{-1}=(\\bold{A}^{-1})^{T}\\) 逆矩阵的求法 借用伴随矩阵和行列式，见行列式一章 初等变换法 设有方阵\\(\\bm A\\)，将其和同阶单位阵写在一起\\((A,E)\\)，然后通过初等行变换（只能是行变换），化成\\((E,A')\\)的形式，然后\\(A'\\)就是逆矩阵。\n分块矩阵 加减法、数乘、乘法与普通矩阵相似。转置时除了将整个矩阵，还要将每个元素本身转置。\n初等变换 下面三种变换称之为初等行变换\n交换两行的位置 以非零数\\(k\\)乘某行 把某一行的\\(k\\)倍加到另一行上 初等列变换只用把上述的行换成列即可。两种变换通称初等变换。显然初等变换是可逆的。\n矩阵等价 如果矩阵\\(\\bold{A}\\)经有限次初等变换成矩阵\\(\\bold{B}\\)，那么称这两个矩阵等价，记作\\(\\bold{A} \\sim \\bold{B}\\)\n等价关系具有：自反性、对称性、传递性。\n相似一定等价，等价不一定相似。 合同一定等价，等价不一定合同。 合同不一定相似，相似不一定合同。\n矩阵的秩 设\\(\\bold{A}\\)为\\(m\\times n\\)矩阵，\\(\\bold{B}\\)是与\\(\\bold{A}\\)等价的行阶梯型矩阵，若矩阵\\(\\bold{B}\\)的非零行数为\\(r\\)，则称矩阵\\(\\bold{B}\\)的秩为\\(r\\)，矩阵\\(\\bold{A}\\)的秩也为\\(r\\)，记作\\(R(\\bold{A})=R(\\bold{B})=r\\)\n矩阵的秩的性质 \\(0\\leq R(\\bold{A}_{m\\times n})\\leq min\\{m,n\\}\\) \\(R(\\bold{A})=0\\Leftrightarrow \\bold{A=O}\\) \\(R(\\bold{A}^T)=R(\\bold{A})\\) 若\\(\\bold{A}\\sim\\bold{B}\\)，则\\(R(\\bold{A})=R(\\bold{B})\\) 若\\(\\bold{P},\\bold{Q}\\)可逆，则\\(R(\\bold{A})=R(\\bold{PA})=R(\\bold{AQ})=R(\\bold{PAQ})\\)（可逆矩阵不影响矩阵的秩）（初等变换不影响矩阵的秩） \\(max\\{R(\\bold{A}),R(\\bold{B})\\}\\leq R(\\bold{A,B})\\leq R(\\bold{A})+R(\\bold{B})\\) \\(R(\\bold{A\\pm B})\\leq R(\\bold{A})+R(\\bold{B});R(\\bold{AB})\\leq min\\{R(\\bold{A}),R(\\bold{B})\\}\\) 若\\(\\bold{A}_{m\\times n}\\bold{B}_{n\\times l}=\\bold{O}\\)，则\\(R(\\bold{A})+R(\\bold{B})\\leq n\\) \\(\\bold{A}_{m\\times n}\\)行满秩\\(\\Leftrightarrow R(\\bold{A})=m\\Leftrightarrow\\bold{A}\\)的等价标准型为\\((\\bold{I}_m,\\bold{O})\\)（\\(\\bold{I}\\)是单位矩阵）。\\(\\bold{A}_{m\\times n}\\)列满秩\\(\\Leftrightarrow R(\\bold{A})=n\\Leftrightarrow\\bold{A}\\)的等价标准型为\\((\\bold{I}_n,\\bold{O})^T\\)。 若\\(\\bold{A}\\)为\\(n\\)阶方阵，则\\(R(\\bold{A})=n\\Leftrightarrow \\bold{A}\\)是可逆矩阵 若\\(\\bold{A},\\bold{B}\\)均为\\(n\\)阶方阵，则\\(R(\\bold{AB})\\ge R(\\bold{A})+R(\\bold{B})-n\\) \\(R(\\bold{ABC})\\ge R(\\bold{AB})+R(\\bold{BC})-R(\\bold{B})\\) \\(R(\\bold{A}_{m\\times n})=n\\Leftrightarrow\\)齐次线性方程组\\(\\bold{Ax=0}\\)只有零解。 \\[R\\begin{pmatrix} \\bold{A} \u0026 0\\\\ 0 \u0026 \\bold{B} \\end{pmatrix}=R(\\bold{A})+R(\\bold{B}) \\]\n矩阵的秩等于矩阵的行秩也等于矩阵的列秩 对于一个矩阵一些相互等价的命题 第一组 设\\(\\bold{A}\\)为\\(n\\)阶方阵，那么下列命题等价\n满秩 非奇异 可逆 \\(\\bold{Ax=0}\\)只有零解 \\(|\\bold{A}|\\ne0\\) \\(\\bold{A}\\)可以经过有限次初等行变换化为单位矩阵\\(\\bold{E}_n\\) \\(\\bold{A}\\)可以表示为有限个初等矩阵的乘积。 特征值均非零 第二组 设\\(\\bold{A}\\)为\\(n\\)阶方阵，那么下列命题等价\n降秩 奇异 不可逆 \\(\\bold{Ax=0}\\)不只有零解 \\(|\\bold{A}|=0\\) \\(\\bold{A}\\)不可以经过有限次初等行变换化为单位矩阵\\(\\bold{E}_n\\) \\(\\bold{A}\\)不可以表示为有限个初等矩阵的乘积。 特征值至少有一个为零 第三组 设\\(f(x_1,\\cdots,x_n)=\\bm{x}^T\\bm{Ax}\\)是\\(n\\)元实二次型，则下列命题等价\n\\(f=\\bm{x}^T\\bm{Ax}\\)是正定二次型，即\\(\\bm{A}\\)是正定矩阵 \\(\\bm{A}\\)的特征值均为正数 \\(f=\\bm{x}^T\\bm{Ax}\\)的正惯性指数为\\(n\\) \\(\\bm{A}\\)与单位矩阵\\(\\bm{E}\\)合同 存在可逆矩阵\\(\\bm B\\)，使得\\(\\bm{A=B}^T\\bm B\\) 顺序主子式均大于零 第四组 设\\(f(x_1,\\cdots,x_n)=\\bm{x}^T\\bm{Ax}\\)是\\(n\\)元实二次型，则下列命题等价\n\\(f\\)是负定二次型 \\(f\\)的负惯性指数为\\(n\\) \\(\\bm A\\)的特征值全为负数 \\(\\bm A\\)合同于\\(-\\bm E\\) \\(\\bm A\\)的奇数阶顺序主子式均为负数，偶数阶顺序主子式均为负数 行列式 二阶行列式 \\[D=\\begin{vmatrix} a_{11} \u0026 a_{12} \\\\ a_{21} \u0026 a_{22} \\end{vmatrix}=a_{11}a_{22}-a_{12}a_{21} \\]\nn阶行列式 余子式与代数余子式 在\\(n\\)阶行列式\n\\[D=\\begin{vmatrix} a_{11} \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n}\\\\ a_{21} \u0026 a_{22} \u0026 \\cdots \u0026 a_{2n}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{n1} \u0026 a_{n2} \u0026 \\cdots \u0026 a_{nn} \\end{vmatrix} \\]\n中划掉元素所在的第\\(i\\)行与第\\(j\\)列后，剩下的\\((n-1)^2\\)个元素按原来的次序构成的\\(n-1\\)阶行列式称为元素\\(a_{ij}\\)的余子式，记为\\(M_{ij}\\)，并称\\((-1)^{i+j}M_{ij}\\)为元素\\(a_{ij}\\)的代数余子式，记为\\(A_{ij}\\)。\n计算 \\[D=\\begin{vmatrix} a_{11} \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n}\\\\ a_{21} \u0026 a_{22} \u0026 \\cdots \u0026 a_{2n}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{n1} \u0026 a_{n2} \u0026 \\cdots \u0026 a_{nn} \\end{vmatrix} \\]\n\\[=a_{11}A_{11}+a_{12}A_{12}+\\cdots+a_{1n}A_{1n}=\\sum_{k=1}^{n}a_{k1}A_{k1} \\]\n上式为该行列式按第一行的展开定义。也可以按其他行（或者列）展开。\n易知对于对角矩阵和上下三角矩阵，其行列式为对角线上元素的乘积。对次三角矩阵则不等于副对角线上元素的乘积。单位矩阵的行列式等于\\(1\\).\n行列式的性质 行列式与其转置行列式相等，\\(|\\bold{A}|=|\\bold{A}^T|\\)\n行列式中某行（或列）元素的公因子可以提到行列式之外\n某行（或列）元素全为零的行列式等于0 对于\\(n\\)阶矩阵\\(\\bold{A}\\)，有\\(|k\\bold{A}|=k^n|\\bold{A}|\\) 交换某两行（或列）的位置，行列式的值变号.\n如果行列式中有两行（或两列）元素相同，则行列式为0. 行列式中若有两行（或两列）对应元素成比例，则行列式为0 若行列式某一行（或列）的元素是两项之和，则该行列式可以写成两个行列式之和，即\n\\[\\begin{vmatrix} a_{11} \u0026 \\cdots \u0026 a_{1j} \u0026 \\cdots \u0026 a_{1n}\\\\ \\vdots \u0026 \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{i1}+b_{i1} \u0026 \\cdots \u0026 a_{ij}+b_{ij} \u0026 \\cdots \u0026 a_{in}+b_{in}\\\\ \\vdots \u0026 \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{n1} \u0026 \\cdots \u0026 a_{nj} \u0026 \\cdots \u0026 a_{nn} \\end{vmatrix} \\]\n\\[=\\begin{vmatrix} a_{11} \u0026 \\cdots \u0026 a_{1j} \u0026 \\cdots \u0026 a_{1n}\\\\ \\vdots \u0026 \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{i1} \u0026 \\cdots \u0026 a_{ij} \u0026 \\cdots \u0026 a_{in}\\\\ \\vdots \u0026 \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{n1} \u0026 \\cdots \u0026 a_{nj} \u0026 \\cdots \u0026 a_{nn} \\end{vmatrix}+ \\begin{vmatrix} a_{11} \u0026 \\cdots \u0026 a_{1j} \u0026 \\cdots \u0026 a_{1n}\\\\ \\vdots \u0026 \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ b_{i1} \u0026 \\cdots \u0026 b_{ij} \u0026 \\cdots \u0026 b_{in}\\\\ \\vdots \u0026 \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{n1} \u0026 \\cdots \u0026 a_{nj} \u0026 \\cdots \u0026 a_{nn} \\end{vmatrix} \\]\n将某一行（或列）的任意\\(k\\)倍加到另一行（或列）上去，行列式的值不变 对于\\(n\\)阶行列式D，有 \\[\\sum_{j=1}^na_{ij}A_{kj}= \\left\\{\\begin{matrix} D,i=k\\\\ 0,i\\ne k \\end{matrix}\\right. \\]\n\\[\\sum_{i=1}^na_{ij}A_{ik}= \\left\\{\\begin{matrix} D,j=k\\\\ 0,j\\ne k \\end{matrix}\\right. \\]\n设\\(\\bold{A,B}\\)均为\\(n\\)阶方阵，则\\(|\\bold{AB}|=\\bold{|A||B|}\\) 范德蒙行列式 \\[V_n=\\begin{vmatrix} 1 \u0026 1 \u0026 1 \u0026 \\cdots \u0026 1\\\\ x_1 \u0026 x_2 \u0026 x_3 \u0026 \\cdots \u0026 x_n\\\\ x_1^2 \u0026 x_2^2 \u0026 x_3^2 \u0026 \\cdots \u0026 x_n^2\\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ x_1^{n-1} \u0026 x_2^{n-1} \u0026 x_3^{n-1} \u0026 \\cdots \u0026 x_n^{n-1} \\end{vmatrix} \\]\n有\n\\[V_n=\\prod_{1\\leq j \u003c i\\leq n}(x_i-x_j) \\]\n行列式求逆矩阵 \\(\\bold{A}\\)为可逆矩阵的充分必要条件是\\(|\\bold{A}|\\ne 0\\)，且有\n\\[\\bold{A}^{-1}=\\frac{1}{|\\bold{A}|}\\bold{A}^* \\]\n行列式求解非齐次线性方程组（克莱默法则） 对于线性方程组\\(\\bold{Ax=b}\\)，定义\n\\[D=|\\bold{A}|\\\\ D_1=|[\\bold{b},\\bold{a}_2,\\bold{a}_3,\\cdots,\\bold{a}_n]|\\\\ D_2=|[\\bold{a}_1,\\bold{b},\\bold{a}_3,\\cdots,\\bold{a}_n]|\\\\ \\cdots\\\\ D_n=|[\\bold{a}_1,\\bold{a}_2,\\bold{a}_3,\\cdots,\\bold{b}]|\\\\ \\]\n当\\(D\\ne0\\)时，该方程组有唯一解，其解为\n\\[x_1=\\frac{D_1}{D},x_2=\\frac{D_2}{D},\\cdots,x_n=\\frac{D_n}{D} \\]\nn维向量与向量空间 前提：本章默认为列向量。\n向量的运算 线性运算 加减法和数乘和矩阵一样，不再介绍。\n向量乘法 也和矩阵一样，但只有两种情况\n\\[\\bm{\\alpha}^T\\bm{\\beta}= \\begin{bmatrix} a_1\u0026a_2\u0026\\cdots\u0026a_n \\end{bmatrix}\\begin{bmatrix} b1\\\\b2\\\\\\vdots\\\\b3 \\end{bmatrix}= a_1b_1+a_2b_2+\\cdots+a_nb_n \\]\n\\[\\bm{\\alpha}\\bm{\\beta}^T= \\begin{bmatrix} a_1\\\\a_2\\\\\\vdots\\\\a_n \\end{bmatrix}\\begin{bmatrix} b1\u0026b2\u0026\\cdots\u0026b3 \\end{bmatrix}= \\begin{bmatrix} a_1b_1 \u0026 a_1b_2 \u0026 \\cdots \u0026 a_1b_n\\\\ a_2b_1 \u0026 a_2b_2 \u0026 \\cdots \u0026 a_2b_n\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_nb_1 \u0026 a_nb_2 \u0026 \\cdots \u0026 a_nb_n \\end{bmatrix} \\]\n向量运算的性质 和矩阵相同，看成行或列为1的矩阵即可。\n向量组的线性相关性 向量组的线性表示 设\\(n\\)维向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_s\\)，对于任何一组实数\\(k_1,k_2,\\cdots,k_s\\)，称\\(k_1\\bm{\\alpha}_1,k_2\\bm{\\alpha}_2,\\cdots,k_s\\bm{\\alpha}_s\\)为向量组的一个线性组合。\n设\\(\\bm{b}\\)为\\(n\\)维向量，若存在一组数\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_s\\)使得\\(\\bm{b}=\\lambda_1\\bm{\\alpha}_1,\\lambda_2\\bm{\\alpha}_2,\\cdots,\\lambda_s\\bm{\\alpha}_s\\)，则称\\(\\bm{b}\\)可由\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_s\\)线性表示。\n线性方程组\\(\\bm{Ax=b}\\)有解的充分必要条件是\\(\\bm{b}\\)可由\\(\\bm{A}\\)的列向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_n\\)线性表示.\n向量组的线性相关性定义及性质 设有\\(n\\)维向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)，如果存在不全为零的数\\(k_1,k_2,\\cdots,k_m\\)，使得\n\\[k_1\\bm{\\alpha}_1+k_2\\bm{\\alpha}_2+\\cdots+k_m\\bm{\\alpha}_m=0 \\]\n则称向量组线性相关，否则称线性无关。\n可以得到如下结论：\n包含零向量的向量组必线性相关 当向量组只包含一个向量时，若为零向量，则线性相关；否则线性无关。 非零向量组若只有两个向量，则线性相关的充要条件是两个向量的对应分量成比例。 向量组线性相关的充要条件是至少存在其中的一个向量可由其余向量线性表示 当\\(t\u003en\\)，含有\\(t\\)个\\(n\\)维向量的向量组必线性相关。 向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)线性无关，而向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m,\\bm{b}\\)线性相关，则\\(\\bm{b}\\)可由\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)唯一线性表示 \\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)线性无关，则任一部分组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r(r\u003c m)\\)必线性无关 \\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)线性相关，则增加向量后的向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_s(s\u003em)\\)必线性相关。 设\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)为\\(m\\)个\\(m\\)维列向量。则\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)线性无关\\(\\Leftrightarrow\\)行列式\\(|[\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m]|\\ne0\\) ； \\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)线性相关\\(\\Leftrightarrow\\)行列式\\(|[\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m]|=0\\) 从几何角度理解：设\\(\\bm{\\alpha,\\beta,\\gamma}\\)为三维向量，向量组\\(\\bm{\\alpha,\\beta}\\)线性相关\\(\\Leftrightarrow\\bm{\\alpha,\\beta}\\)共线;向量组\\(\\bm{\\alpha,\\beta,\\gamma}\\)线性相关\\(\\Leftrightarrow\\bm{\\alpha,\\beta,\\gamma}\\)共面 向量组的秩和极大无关组 设有两个向量组，每个向量组中的每一个向量都可以由另一个向量组线性表示，则称两个向量组等价。\n设有向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_s\\)，而\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)是向量组中的\\(r\\)个向量\\((r\\leq s)\\)，若满足\n向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)线性无关; 向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_s\\)中的任\\(r+1\\)个向量（如果有）线性相关 则称向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)是向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_s\\)的一个极大无关组，极大无关组所含向量个数\\(r\\)称为向量组的秩，记作\\(R(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_s)=r\\).\n只含零向量的向量组，规定秩为0；向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_s\\)线性无关时，其秩为\\(s\\).\n有如下定理\n阶梯型矩阵\\(J\\)的行秩和列秩相等，恰等于\\(J\\)的非零行数，并且\\(J\\)的主元（非零行的首个元素）所在的列构成列向量组的一个极大无关组。 矩阵的初等行（列）变换不改变矩阵的列（行）（注意与前一句相反）向量组的线性相关性，从而不改变矩阵的列（行）秩。 矩阵的秩等于矩阵的行秩等于矩阵的列秩。 设\\(\\bm{A}\\)是\\(m\\times n\\)矩阵，则 矩阵\\(A\\)的列向量组线性相关（无关）的充要条件为\\(R(\\bm{A})\u003c n(R(\\bm{A})=n)\\)\n矩阵\\(A\\)的行向量组线性相关（无关）的充要条件为\\(R(\\bm{A})\u003c m(R(\\bm{A})=m)\\)\n若向量组\\(I\\)可由向量组\\(II\\)线性表示，则\\(I\\)的秩不超过\\(II\\)的秩； 等价向量组的秩相等。 极大无关组表示其他向量 1.jpg\r转化为行最简形为\n2.jpg\r显然极大无关组是\\(\\alpha_1,\\alpha_3,\\alpha_5\\)。\n并且有\\(\\alpha_2=3\\alpha_1,\\alpha_4=-2\\alpha_1+\\alpha_3,\\alpha_6=\\alpha_1+2\\alpha_3-\\alpha_5\\)\n向量空间 向量空间的定义 设\\(\\bm{V}\\)是非空\\(n\\)维向量的集合，如果\\(\\bm{V}\\)对向量的加法和数乘封闭，即\n若\\(\\bm{a,b\\in V}\\)，有\\(\\bm{a+b}\\in V\\); 若\\(\\bm{a\\in B},\\lambda\\in R\\)，有\\(\\lambda\\bm{a\\in V}\\)（特别注意\\(\\lambda=0\\)的情况） 则称\\(\\bm{V}\\)为一个向量空间\n向量空间必须含有零向量。\n子空间的定义\n设\\(\\bm{V}\\)和\\(\\bm{H}\\)都是向量空间，若\\(\\bm{H}\\subset V\\)，则称\\(\\bm{H}\\)是\\(\\bm{V}\\)的子空间。\n线性变换的定义\n已知\\(\\bm{A}\\)为\\(n\\)阶方阵，则称映射\\(f:\\bm{R}^n\\to \\bm{R}^n,\\bm{x}\\to \\bm{y},\\bm{y}=\\bm{Ax}\\)为\\(\\bm{R}^n\\)上的线性变换，\\(\\bm{A}\\)称为线性变换矩阵.\n向量的内积与正交矩阵 向量的内积\n设\\(n\\)维向量\\(\\bm{x}=[x_1,x_2,\\cdots,x_n]^T\\)，\\(\\bm{y}=[y_1,y_2,\\cdots,y_n]^T\\)，称\n\\[\u003c\\bm{x},\\bm{y}\u003e=x_1y_1+x_2y_2+\\cdots+x_ny_n \\]\n为向量\\(\\bm{x,y}\\)的内积。\n内积具有以下性质\n\\(\u003c\\bm{x},\\bm{y}\u003e=\u003c\\bm{y},\\bm{x}\u003e\\) \\(\u003c k\\bm{x},\\bm{y}\u003e=\u003c\\bm{x},k\\bm{y}\u003e=k\u003c\\bm{x},\\bm{y}\u003e\\)，\\(k\\)是实数 \\(\u003c\\bm{x+y},\\bm{z}\u003e=\u003c\\bm{x},\\bm{z}\u003e+\u003c\\bm{y},\\bm{z}\u003e\\) \\(\u003c\\bm{x},\\bm{x}\u003e\\ge0,\u003c\\bm{x},\\bm{x}\u003e=0\\)当且仅当\\(\\bm{x}=\\bm{0}\\) 柯西-施瓦茨不等式：\\(\u003c\\bm{x},\\bm{y}\u003e^2\\leq\u003c\\bm{x},\\bm{x}\u003e\u003c\\bm{y},\\bm{y}\u003e\\) 向量的范数\n设\\(n\\)维向量\\(\\bm{x}=[x_1,x_2,\\cdots,x_n]^T\\)，称\n\\[||\\bm{x}||=\\sqrt{\\bm{x}^T\\bm{x}}=\\sqrt{\u003c\\bm{x},\\bm{x}\u003e}=\\sqrt{x_1^2+x_2^2+\\cdots+x_n^2} \\]\n为向量\\(\\bm{x}\\)的范数。\n范数具有以下性质\n\\(||\\bm{x}||\\ge0,||\\bm{x}||=0\\)当且仅当\\(\\bm{x}=\\bm{0}\\) \\(||k\\bm{x}||=|k|||\\bm{x}||\\)，k为实数 \\(||\\bm{x}+\\bm{y}||\\leq||\\bm{x}||+||\\bm{y}||\\) 向量的夹角与正交\n设\\(\\bm{x,y}\\)是\\(n\\)维非零向量，称\n\\[\\theta=\\arccos\\frac{\\bm{x}^T\\bm{y}}{||\\bm{x}||||\\bm{y}||}=\\arccos\\frac{\u003c\\bm{x},\\bm{y}\u003e}{||\\bm{x}||||\\bm{y}||} \\]\n为向量\\(\\bm{x,y}\\)的夹角。特别的，当\\(\u003c\\bm{x},\\bm{y}\u003e=0时\\)，\\(\\theta=\\pm\\frac{\\pi}{2}\\)，称两向量正交（或垂直）。\n两两正交的向量组称为正交向量组。由单位向量构成的正交向量组称为标准（规范）标准正交组\n有如下定理：\n不含零向量的正交向量组必线性无关。 施密特正交化方法\n设向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)线性无关，令\n\\[\\bm{\\beta}_1=\\bm{\\alpha}_1\\\\ \\bm{\\beta}_2=\\bm{\\alpha}_2-\\frac{\u003c\\bm{\\alpha}_2,\\bm{\\beta}_1\u003e}{\u003c\\bm{\\beta}_1,\\bm{\\beta}_1\u003e}\\bm{\\beta}_1\\\\ \\bm{\\beta}_3=\\bm{\\alpha}_3-\\frac{\u003c\\bm{\\alpha}_3,\\bm{\\beta}_1\u003e}{\u003c\\bm{\\beta}_1,\\bm{\\beta}_1\u003e}\\bm{\\beta}_1-\\frac{\u003c\\bm{\\alpha}_3,\\bm{\\beta}_2\u003e}{\u003c\\bm{\\beta}_2,\\bm{\\beta}_2\u003e}\\bm{\\beta}_2\\\\ \\cdots\\\\ \\bm{\\beta}_m=\\bm{\\alpha}_m-\\sum_{j=1}^{m-1}\\frac{\u003c\\bm{\\alpha}_m,\\bm{\\beta}_j\u003e}{\u003c\\bm{\\beta}_j,\\bm{\\beta}_j\u003e}\\bm{\\beta}_j \\]\n则\\(\\bm{\\beta}_1,\\bm{\\beta}_2,\\cdots,\\bm{\\beta}_m\\)是与\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)等价的正交向量组\n若进一步单位化，即令\\(\\bm{\\eta}_j=\\frac{\\bm{\\beta}j}{||\\bm{\\beta}_j||}\\)，则\\(\\bm{\\eta}_1,\\bm{\\eta}_2,\\cdots,\\bm{\\eta}_m\\)是一个与\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)等价的标准正交向量组.\n正交矩阵\n设\\(\\bm{A}\\)为\\(n\\)阶方阵，若满足\\(\\bm{A}^T\\bm{A}=\\bm{E}\\)，则称\\(\\bm{A}\\)为正交矩阵。\n有如下性质：\n若\\(\\bm{A}\\)为正交矩阵，则\\(\\bm{A}^T=\\bm{A}^{-1}\\) 若\\(\\bm{A}\\)为正交矩阵，则\\(\\bm{A}^T\\)和\\(\\bm{A}^{-1}\\)和\\(\\bm{A}^{*}\\)也为正交矩阵 若\\(\\bm{A},\\bm{B}\\)为\\(n\\)阶正交矩阵，则\\(\\bm{AB}\\)也为正交矩阵 若\\(\\bm{A}\\)为正交矩阵，则\\(|\\bm{A}|=\\pm1\\) 有如下定理：\n\\(n\\)阶方阵\\(\\bm{A}\\)为正交矩阵的充要条件是\\(\\bm{A}\\)的列（行）向量组是标准向量组。\n基、维数与坐标 向量空间的基与维数 设\\(\\bm{V}\\)是向量空间，如果向量\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\in\\bm{V}\\)，满足\n\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)线性无关 \\(\\bm{V}\\)中任一向量都可以由\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)线性表示 则称向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)是向量空间\\(\\bm{V}\\)的一组基，\\(r\\)称为向量空间的维数，记为\\(dim\\bm{V}=r\\)，规定零向量构成的向量空间的维数为0.\n类似的还有正交基和标准（规范）正交基的概念。\n向量的坐标 设\\(\\bm{V}\\)是\\(r\\)维向量空间，\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)是\\(\\bm{V}\\)的一组基，则\\(\\bm{V}\\)中的任一向量\\(\\bm{x}\\)可由\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)唯一线性表示为\\(\\bm{x}=x_1\\bm{\\alpha}_1+\\cdots+x_r\\bm{\\alpha}_r\\)，数组\\(x_1,x_2,\\cdots,x_r\\)称为向量\\(\\bm{x}\\)在基\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)下的坐标。\n过渡矩阵与基变换公式\n设\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)和\\(\\bm{\\beta}_1,\\bm{\\beta}_2,\\cdots,\\bm{\\beta}_r\\)是\\(r\\)维向量空间\\(\\bm{V}\\)的两组基，则两个向量组等价，从而有\\(\\bm{\\beta}_j=k_{1j}\\bm{\\alpha}_1+\\cdots+k_{rj}\\bm{\\alpha}_r\\)，即\n\\[[\\bm{\\beta}_1,\\cdots,\\bm{\\beta}_r]=[\\bm{\\alpha}_1,\\cdots,\\bm{\\alpha}_r] \\begin{bmatrix} k_{11} \u0026 \\cdots \u0026 k_{1r}\\\\ \\vdots \u0026 \u0026 \\vdots\\\\ k_{r1} \u0026 \\cdots \u0026 k_{rr} \\end{bmatrix} =[\\bm{\\alpha}_1,\\cdots,\\bm{\\alpha}_r]\\bm{K} \\]\n称\\(\\bm{K}\\)是由\\(\\bm{A}\\)到\\(\\bm{B}\\)的过度矩阵，上式为基变换公式。另外\\(\\bm{K}\\)一定是可逆矩阵。\n坐标变换公式\n设\\(\\bm{\\alpha}\\)在两组基\\(\\bm{A,B}\\)下的坐标分别为\\([x_1,\\cdots,x_r]^T\\)和\\([y_1,\\cdots,y_r]^T\\)，则有\n\\[\\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_r \\end{bmatrix} =\\bm{K} \\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_r \\end{bmatrix} or \\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_r \\end{bmatrix} =\\bm{K}^{-1} \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_r \\end{bmatrix} \\]\n一般有\\(\\bm{K}=\\bm{A}^{-1}\\bm{B}\\)\n线性方程组 解法 高斯消元法 即通过对增广矩阵进行初等行变换（只能是行变换），化为简单的形式进行求解。\n克莱默法则 见前\n性质定理 齐次线性方程组\\(\\bold{A}_{m\\times n}\\bold{x=0}\\)有非零解的充要条件是\\(R(\\bold{A})=r\u003c n\\)，且有无穷多解，自由量为\\(n-r\\)个（解空间的维数为\\(n-r\\)）。这个充要条件可以替换为\\(|\\bm A|=0\\)及其他等价命题。\n非齐次线性方程组\\(\\bold{A}_{m\\times n}\\bold{x=b}\\)有解的充要条件是\\(R(\\bold{A})=R(\\~\\bold{A})=r\\)，且当\n\\(r=n\\)时有唯一解，称为适定线性方程组 \\(r\u003c n\\)时有无穷多解，自由量是\\(n-r\\)个，称为欠定线性方程组 线性方程组解的结构 齐次情况 设\\(\\bm{\\xi}_1,\\bm{\\xi}_2,\\cdots,\\bm{\\xi}_t\\)是\\(\\bm{Ax=0}\\)的解，则\\(c_1\\bm{\\xi}_1+c_2\\bm{\\xi}_2+\\cdots+c_t\\bm{\\xi}_t\\)也是解，\\(c_i\\)为任意常数。\n齐次线性方程组\\(\\bm{Ax=0}\\)的解空间的一组基\\(\\bm{\\xi}_1,\\bm{\\xi}_2,\\cdots,\\bm{\\xi}_{n-r}\\)也称为方程组的一个基础解系。\n换言之，基础解系\\(\\bm{\\xi}_1,\\bm{\\xi}_2,\\cdots,\\bm{\\xi}_{n-r}\\)是\\(\\bm{Ax=0}\\)的解向量，且满足\n\\(\\bm{\\xi}_1,\\bm{\\xi}_2,\\cdots,\\bm{\\xi}_{n-r}\\)线性无关 \\(\\bm{Ax=0}\\)的任一解都可由\\(\\bm{\\xi}_1,\\bm{\\xi}_2,\\cdots,\\bm{\\xi}_{n-r}\\)线性表示 通过基础解系可以写出通解为\\(\\bm{x}=c_1\\bm{\\xi}_1+c_2\\bm{\\xi}_2+\\cdots+c_{n-r}\\bm{\\xi}_{n-r}\\)，\\(c_i\\)为任意常数。\n非齐次情况 有如下性质：\n设\\(\\bm{x}=\\bm{\\eta}_1+\\bm{\\eta}_2+\\cdots+\\bm{\\eta}_{t}\\)为\\(\\bm{Ax=b}\\)的解，令\\(\\bm{\\eta}=c_1\\bm{\\eta}_1+c_2\\bm{\\eta}_2+\\cdots+c_{t}\\bm{\\eta}_{t}\\)，当\\(c_1+\\cdots+c_t=0\\)时，\\(\\bm{\\eta}\\)为\\(\\bm{Ax=0}\\)的解，当\\(c_1+\\cdots+c_t=1\\)时\\(\\bm{\\eta}\\)为\\(\\bm{Ax=b}\\)的解 设\\(\\bm\\xi\\)为\\(\\bm{Ax=0}\\)的解，\\(\\bm\\eta\\)为\\(\\bm{Ax=b}\\)的解，则\\(\\bm{x=\\xi+\\eta}\\)仍为\\(\\bm{Ax=b}\\)的解。 非齐次线性方程组的解集关于加法和数乘不封闭，因此不构成向量空间 由此可知，\\(\\bm{Ax=b}(R(\\bm{A})=R(\\~{\\bm{A}})=r\\)的通解为\n\\[\\bm x=k_1\\bm{\\xi}_1+\\cdots+k_{n-r}\\bm{\\xi}_{n-r}+\\bm\\eta^* \\]\n其中\\(\\bm{x}=\\bm{\\xi}_1+\\bm{\\xi}_2+\\cdots+\\bm{\\xi}_{n-r}\\)为导出组\\(\\bm{Ax=0}\\)的一个基础解系，\\(\\bm\\eta^*\\)为\\(\\bm{Ax=b}\\)的任意一个解，称为特解。\n相似矩阵与二次型 特征值和特征向量 设\\(\\bm{A}\\)为\\(n\\)阶矩阵，如果存在数\\(\\lambda\\)和\\(n\\)维非零（注意非零）列向量\\(\\bm\\alpha\\)使得\n\\[\\bm A\\bm\\alpha=\\lambda\\bm\\alpha \\]\n则称\\(\\lambda\\)为\\(\\bm A\\)的特征值，\\(\\bm\\alpha\\)为\\(\\bm A\\)对于这个\\(\\lambda\\)的特征向量。\n由上式可知，\\(\\bm\\alpha\\)必是如下方程的非零解\n\\[(\\lambda\\bm E-\\bm A)\\bm x=\\bm 0 \\]\n显然有非零解当且仅当\\(|\\lambda\\bm E-\\bm A|=0\\)，\\(\\lambda\\bm E-\\bm A\\)称为特征矩阵，\\(|\\lambda\\bm E-\\bm A|\\)称为特征多项式，\\(|\\lambda\\bm E-\\bm A|=0\\)称为特征方程。\n特征值和特征向量的求解步骤\n求\\(|\\lambda\\bm E-\\bm A|=0\\)的全体根，记为\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_n\\) 对于每个特征值\\(\\lambda_i\\)，求出对应其次线性方程组\\((\\lambda_i\\bm E-\\bm A)\\bm x=\\bm0\\)的一个基础解系\\(\\bm{\\alpha}_1,\\cdots,\\bm{\\alpha}_s\\)，并以此求出\\(\\lambda_i\\)对应的全部特征向量\\(k_1\\bm{\\alpha}_1,\\cdots,k_s\\bm{\\alpha}_s\\)。其中\\(k_1,\\cdots,k_s\\)是任意不全为零的常数。 特征值和特征向量的性质 设\\(\\lambda\\)为\\(\\bm A\\)的任一特征值，\\(\\bm\\alpha\\)为其对应的特征向量，则\\(f(\\lambda)\\)是\\(f(\\bm A)\\)的特征值，其对应的特征向量还是\\(\\bm\\alpha\\)，其中\\(f(x)\\)是\\(x\\)的\\(m\\)次多项式。\n设\\(\\lambda\\)为\\(\\bm A\\)的任一非零特征值，\\(\\bm\\alpha\\)为其对应的特征向量，则\\(\\bm A^*\\)的特征值为\\(|\\bm A|/\\lambda\\)。特征向量仍为\\(\\bm\\alpha\\)\n若矩阵\\(\\bm A\\)可逆，则\\(1/\\lambda\\)是\\(A^{-1}\\)的特征值。特征向量仍为\\(\\bm\\alpha\\)\n转置矩阵由于行列式不变，所以特征值不变。但是特征向量并不一定一样。\n设\\(n\\)阶矩阵\\(\\bm A\\)的\\(n\\)个特征值为\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_n\\)（重根按重数计算），则\n\\(\\lambda_1+\\lambda_2+\\cdots+\\lambda_n=a_{11}+a_{22}+\\cdots+a_{nn}=tr(\\bm A)\\)，\\(tr(\\bm A)\\)称之为矩阵的迹 \\(\\lambda_1\\lambda_2\\cdots\\lambda_n=|\\bm A|\\) 矩阵可逆\\(\\Leftrightarrow\\)所有特征值均非0\n若\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_m\\)是\\(\\bm A\\)的互不相同的特征值，\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)是对应的特征向量，则\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)线性无关\n设\\(\\lambda\\)是\\(k\\)重特征值，对于\\(\\lambda\\)的线性无关的特征向量的最大个数为\\(l\\)，则\\(k\\ge l\\)\n相似矩阵 相似矩阵的定义和性质 设\\(\\bm{A,B}\\)为\\(n\\)阶矩阵，若存在\\(n\\)阶可逆矩阵\\(\\bm P\\)，使得\n\\[\\bm P^{-1}\\bm A\\bm P=\\bm B \\]\n则称\\(\\bm A\\)与\\(\\bm B\\)相似，记作\\(\\bm A\\sim \\bm B\\)\n具有以下性质：自反性、传递性、对称性。\n以及\n如果两矩阵相似，则具有相同的特征多项式，从而有相同的特征值。但特征向量不一定相同。并且特征多项式相同并不能推出两矩阵相似。 两矩阵相似，则具有相同的秩。 两矩阵相似，则具有相同的迹。 两矩阵相似，则具有相同的行列式。 若\\(\\bm A\\sim \\bm B\\)，且\\(\\bm A\\)可逆，则\\(\\bm B\\)可逆，并且有\\(\\bm A^{-1}\\sim \\bm B^{-1}\\) 若\\(\\bm A\\sim \\bm B\\)，则对任一多项式\\(g(x)\\)，有\\(g(\\bm A)\\sim g(\\bm B)\\) 矩阵可对角化的条件 设\\(\\bm A\\)为\\(n\\)阶矩阵，如果存在一个\\(n\\)阶可逆矩阵\\(\\bm P\\)，使得\\(\\bm P^{-1}\\bm A\\bm P\\)为对角矩阵，则称\\(\\bm A\\)可对角化。\n有如下定理：\n\\(\\bm A\\)可对角化的充要条件是\\(\\bm A\\)有\\(n\\)个线性无关的特征向量。 \\(n\\)阶矩阵\\(\\bm A\\)的\\(n\\)个特征值互不相同\\(\\Rightarrow\\bm A\\)可对角化 \\(\\bm A\\)可对角化的充要条件是对于\\(\\bm A\\)的每个\\(k\\)重特征值\\(\\lambda\\)，都有\\(R(\\lambda\\bm E-\\bm A)=n-k\\) 实对称矩阵的对角化 实对称矩阵一定能对角化\n并且有如下定理：\n实对称矩阵的特征值都为实数 实对称矩阵的不同特征值所对应的特征向量必正交 设\\(\\bm A\\)为\\(n\\)阶实对称矩阵，则存在正交矩阵\\(\\bm Q\\)使得 \\[\\bm Q^T\\bm{AQ}=\\bm Q^{-1}\\bm{AQ}= \\begin{bmatrix} \\lambda_1 \u0026 \u0026 \u0026 \\\\ \u0026 \\lambda_2 \u0026 \u0026 \\\\ \u0026 \u0026 \\ddots \u0026 \\\\ \u0026 \u0026 \u0026 \\lambda_n \\end{bmatrix} \\]\n其中\\(\\lambda_i\\)为\\(\\bm A\\)的特征值。\n设\\(\\bm A\\)为\\(n\\)阶实对称矩阵，\\(\\lambda\\)为\\(\\bm A\\)的\\(k\\)重特征值，则\\(\\bm A\\)必有\\(k\\)个对于特征值\\(\\lambda\\)的线性无关的特征向量 求解对角阵的方法\n求\\(\\bm A\\)的全部不同特征值\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_s\\) 对于每个不同的特征值，求出齐次线性方程组\\((\\lambda_i\\bm E-\\bm A)\\bm x=\\bm 0\\)的基础解系，将其正交化、单位化 将所得的正交单位特征向量作为列向量组构成正交矩阵（注意特征向量和特征值的顺序）\\(\\bm Q\\)，则\\(\\bm Q^T\\bm{AQ}=\\bm Q^{-1}\\bm{AQ}=diag(\\lambda_1,\\lambda_2,\\cdots,\\lambda_n)\\) 二次型及其标准型 n元二次型的定义如下 \\[f(x_1,\\cdots,x_n)=a_{11}x_1^2+2a_{12}x_1x_2+\\cdots+2a_{1n}x_1x_n+a_{22}x_2^2+2a_{2n}x_2x_n+\\cdots+a_{nn}x_{n}^2\\\\= (x_1,\\cdots,x_n) \\begin{bmatrix} a_{11}x_1+a_{12}x_2+\\cdots+a_{1n}x_n\\\\ a_{21}x_1+a_{22}x_2+\\cdots+a_{2n}x_n\\\\ \\vdots\\\\ a_{n1}x_1+a_{n2}x_2+\\cdots+a_{nn}x_n \\end{bmatrix}\\\\= (x_1,\\cdots,x_n) \\begin{bmatrix} a_{11} \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n}\\\\ a_{21} \u0026 a_{22} \u0026 \\cdots \u0026 a_{2n}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{n1} \u0026 a_{n2} \u0026 \\cdots \u0026 a_{nn} \\end{bmatrix} \\begin{bmatrix} x_1\\\\ x_2\\\\ \\vdots\\\\ x_n \\end{bmatrix} \\]\n亦可表示为\\(f(\\bm x)=\\bm x^T\\bm {Ax}\\)。其中\\(\\bm A^T=\\bm A\\)为实对称矩阵。\\(\\bm A\\)称为二次型式的矩阵，其秩称为二次型式的秩。\n仅含平方项的二次型称之为标准型。\n显然\\(\\bm x^T\\bm {Ax}\\)为标准型的充要条件是\\(\\bm A\\)为对角矩阵。\n\\(\\bm A\\)可以直接读出，先写一个对角矩阵，对角线的元素值即为平方项的系数，对角线以上的元素找对应项的系数除以2，之后再将对角线以上的元素“对称地”写到对角线以下的元素\n矩阵的合同 设\\(\\bm{A,B}\\)为\\(n\\)阶矩阵，若存在\\(n\\)阶可逆矩阵\\(\\bm C\\)，使得\\(\\bm C^{T}\\bm A\\bm C=\\bm B\\)则称\\(\\bm A\\)与\\(\\bm B\\)合同，记作\\(\\bm A\\simeq \\bm B\\)\n具有以下性质：自反性、传递性、对称性。\n以及若\\(\\bm{A,B}\\)合同，且\\(\\bm A\\)为对称矩阵，则\\(\\bm B\\)也为对称矩阵，且\\(R(\\bm A)=R(\\bm B)\\)\n化二次型为标准型 有三种方法\n1.正交变换法\n若\\(\\bm Q\\)为正交矩阵，则称线性变换\\(\\bm{x=Qy}\\)为正交变换。\n对于任意\\(n\\)元二次型\n\\[f(x_1,x_2,\\cdots,x_n)=\\bm{x}^T\\bm{Ax} \\]\n总存在正交变换\\(\\bm{x=Qy}\\)，使得\n\\[f(x_1,x_2,\\cdots,x_n)\\xlongequal{\\bm{x=Qy}}\\lambda_1y_1^2+\\lambda_2y_2^2+\\cdots+\\lambda_ny_n^2 \\]\n其中\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_n\\)为\\(\\bm A\\)的全部特征值。\n\\(\\bm Q\\)的计算方法：\n求\\(\\bm A\\)的特征向量 将所有特征向量正交化、单位化 再将得到的向量组成列向量组，即为\\(\\bm Q\\)。注意组合的顺序 2.配方法\n例如：\n\\[f(x_1,x_2.x_3)=2(x_1^2+2x_1x_2+4x_1x_3)+x_2^2+14x_2x_3-x_3^2\\\\ =2(x_1+x_2+2x_3)^2-(x_2-3x_3)^2 \\]\n令\n\\[\\left\\{\\begin{matrix} y_1=x_1+x_2+2x_3 \\\\ y_2=x_2-3x_3 \\\\ y_3=x_3 \\end{matrix}\\right. \\]\n则有\n\\[\\left\\{\\begin{matrix} x_1=y_1-y_2-5y_3 \\\\ x_2=y_2+3y_3 \\\\ x_3=y_3 \\end{matrix}\\right. \\]\n即\n\\[\\bm x= \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} 1 \u0026 -1 \u0026 -5 \\\\ 0 \u0026 1 \u0026 3 \\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix} =\\bm{Qy} \\]\n3.初等变换法\n对\\(2n\\times n\\)矩阵实施一次初等列变换及相应的初等行变换，直至把\\(\\bm A\\)化为对角矩阵\\(\\bm \\Lambda\\)，即\n\\[\\begin{bmatrix} \\bm A \\\\ \\bm E \\end{bmatrix} \\sim \\begin{bmatrix} \\bm \\Lambda \\\\ \\bm Q \\end{bmatrix} \\]\n且有\\(\\bm{Q}^T\\bm{AQ}=\\bm\\Lambda\\)\n二次型的规范型 设实二次型\\(f(x_1,x_2,\\cdots,x_n)\\)经过可逆线性变换转化为标准型\n\\[f(x_1,x_2,\\cdots,x_n)=d_1y_1^2+\\cdots+d_py_p^2-d_{p+1}y_{p+1}^2-\\cdots-d_ry_r^2 \\]\n其中\\(r\\)是二次型的秩，\\(d_i\u003e0\\)，则可以再做一次线性变换\n\\[\\left\\{\\begin{matrix} y_1=\\frac{1}{\\sqrt{d_1}}z_1 \\\\ \\vdots \\\\ y_r = \\frac{1}{\\sqrt{d_r}}z_r \\\\ y_{r+1}=z_{r+1} \\\\ \\vdots\\\\ y_n=z_n \\end{matrix}\\right. \\]\n则得到\n\\[f(x_1,x_2,\\cdots,x_n)=z_1^2+\\cdots+z_p^2-z_{p+1}^2-\\cdots-z_r^2 \\]\n称为规范标准型，简称规范型。\n二次型的标准型是不唯一的，但规范标准型是唯一的（并且对于实二次型来说一定存在规范型）。这也被称作惯性定律。\n标准型中正平方项的个数\\(p\\)称为正惯性指数，负平方项的个数\\(q\\)称为负惯性指数。\\(p-q\\)称为二次型的符号差。\n并且有如下定理\n定理\n任何实对称矩阵必合同于如下形式的对角矩阵\n\\[\\begin{bmatrix} \\bm{E}_p \u0026 \u0026 \\\\ \u0026 -\\bm{E}_q \u0026 \\\\ \u0026 \u0026 \\bm{0} \\end{bmatrix} \\]\n正定二次型 对于任何非零（强调非零）向量\\(\\bm{x}=(x_1,\\cdots,x_n)\\)都有\n\\[f(x_1,\\cdots,x_n)=\\bm{x}^T\\bm{Ax}\u003e0(\u003c0) \\]\n则称\\(f\\)是正定（负定）二次型，\\(\\bm{A}\\)称为正定（负定）矩阵。\n如果上式取\\(\\ge(\\leq)\\)，则为半正定（半负定）二次型。\n如果\\(f\\)既不是半正定的，也不是半负定的，则称为不定的。\n有如下定理\n定理1\n可逆的线性变换不改变二次型的正定性\n定理2\n\\(\\bm{A,B}\\)合同，则\\(\\bm{A}\\)正定的充要条件是\\(\\bm{B}\\)正定。\n定理3\n若\\(\\bm A\\)是\\(n\\)阶正定矩阵，则\n\\(\\bm A\\)的主对角线元\\(a_{ii}\u003e0\\) \\(|\\bm A|\u003e0\\) \\(k\\)阶顺序主子式\n设\\(\\bm A\\)为\\(n\\)阶方阵，依次取\\(\\bm A\\)的前\\(k\\)行与前\\(k\\)列所构成的子式的行列式称为矩阵\\(\\bm A\\)的\\(k\\)阶顺序主子式。\n显然\\(n\\)阶方阵\\(\\bm A\\)的顺序主子式有且只有\\(n\\)个。\n有如下定理\n霍尔维茨定理\n\\(n\\)元实二次型\\(f=\\bm{x}^T\\bm{Ax}\\)正定的充要条件是\\(\\bm A\\)的\\(n\\)个顺序主子式均大于零。\n","date":"2022-06-04T12:11:53+08:00","image":"https://kegalas.top/inferior/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E6%95%B4%E7%90%86/cover_hu670730d9bdf70a44294ca8d2a00a2ced_185066_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E6%95%B4%E7%90%86/","title":"线性代数整理"},{"content":"[TOC]\n向量代数与空间解析几何 方向角与方向余弦 非零向量\\(\\bold{r}\\)与三条坐标轴的夹角\\(\\alpha\\)、\\(\\beta\\)、\\(\\gamma\\)称为向量\\(\\bold{r}\\)的方向角。设\\(\\overrightarrow{OM}=\\bold{r}=(x,y,z)\\)，则有\n\\[(cos\\alpha,cos\\beta,cos\\gamma)=\\left(\\frac{x}{|\\bold{r}|},\\frac{y}{|\\bold{r}|},\\frac{z}{|\\bold{r}|}\\right)=\\frac{1}{|\\bold{r}|}(x,y,z)=\\frac{\\bold{r}}{|\\bold{r}|}=\\bold{e} \\]\n\\(cos\\alpha,cos\\beta,cos\\gamma\\)称为向量\\(\\bold{r}\\)的方向余弦。并且有\n\\[cos^2\\alpha+cos^2\\beta+cos^2\\gamma = 1 \\]\n数量积的运算规律 交换律 \\(\\bold{a}\\cdot\\bold{b}=\\bold{b}\\cdot\\bold{a}\\)\n分配律 \\((\\bold{a+b})\\cdot \\bold{c}=\\bold{a\\cdot c+b\\cdot c}\\)\n如下的结合律 \\((\\lambda \\bold{a})\\cdot\\bold{b}=\\lambda(\\bold{a\\cdot b})\\)，\\(\\lambda\\)为数\n向量积的运算规律 \\(\\bold{b\\times a=-a\\times b}\\)\n分配律 \\(\\bold{(a+b)\\times c=a\\times c+b\\times c}\\)\n如下的结合律 \\((\\lambda \\bold{a})\\times \\bold{b}=\\lambda(\\bold{a\\times b})\\)，\\(\\lambda\\)为数\n平面的点法式方程 当平面\\(\\Pi\\)上一点\\(M_0(x_0,y_0,z_0)\\)和它的一个法线向量\\(\\bold{n}=(A,B,C)\\)已知时，有平面的点法式方程：\n\\[A(x-x_0)+B(y-y_0)+C(z-z_0)=0 \\]\n平面的一般方程 \\[Ax+By+Cz+D=0 \\]\n其中这个平面的法向量为\\(\\bold{n}=(A,B,C)\\)\n平面的截距式方程 \\[\\frac{x}{a}+\\frac{y}{b}+\\frac{z}{c}=1 \\]\n其中\\(a,b,c\\)分别为\\(x,y,z\\)轴上的截距\n两平面夹角 \\[cos\\theta=\\frac{|A_1A_2+B_1B_2+C_1C_2|}{\\sqrt{A_1^2+B_1^2+C_1^2}\\sqrt{A_2^2+B_2^2+C_2^2}} \\]\n点到平面距离公式 点\\(P_0(x_0,y_0,z_0)\\)到平面\\(Ax+By+Cz+D=0\\)的距离公式\n\\[d=\\frac{|Ax_0+By_0+Cz_0+D|}{\\sqrt{A^2+B^2+C^2}} \\]\n空间直线的一般方程 \\[\\left\\{\\begin{matrix} A_1x+B_1y+C_1z+D_1=0\\\\ A_2x+B_2y+C_2z+D_2=0 \\end{matrix}\\right. \\]\n即两个平面的交线\n另外两个平面的法向量的向量积可以算出直线的切向量\n平面束方程 由上述空间直线方程可知，通过这一直线的平面还有\n\\[\\lambda(A_1x+B_1y+C_1z+D_1)+\\mu(A_2x+B_2y+C_2z+D_2)=0 \\]\n其中\\(\\lambda=1\\)时\n\\[(A_1x+B_1y+C_1z+D_1)+\\mu(A_2x+B_2y+C_2z+D_2)=0 \\]\n表示除了\\(A_2x+B_2y+C_2z+D_2=0\\)，之外的过直线的平面束。\n空间直线的对称式方程(点向式方程) 若已知直线过一点\\(M_0(x_0, y_0, z_0)\\)和它的一个方向向量\\(\\bold{s}=(m,n,p)\\)。则有方程\n\\[\\frac{x-x_0}{m}=\\frac{y-y_0}{n}=\\frac{z-z_0}{p} \\]\n空间直线的参数方程 若设\n\\[\\frac{x-x_0}{m}=\\frac{y-y_0}{n}=\\frac{z-z_0}{p}=t \\]\n则有\n\\[\\left\\{\\begin{matrix} x=x_0+mt \\\\ y=y_0+nt \\\\ z=z_0+pt \\end{matrix}\\right. \\]\n两直线的夹角 设两直线方向向量分别为\\(\\bold{s_1}=(m_1,n_1,p_1)\\)和\\(\\bold{s_2}=(m_2,n_2,p_2)\\)\n\\[cos\\varphi = \\frac{|m_1m_2+n_1n_2+p_1p_2|}{\\sqrt{m_1^2+n_1^2+p_1^2}\\sqrt{m_2^2+n_2^2+p_2^2}} \\]\n直线与平面的夹角 设直线方向向量和平面法向量分别为\\(\\bold{s}=(m,n,p)\\)和\\(\\bold{n}=(A,B,C)\\)\n\\[sin\\varphi = \\frac{|Am+Bn+Cp|}{\\sqrt{A^2+B^2+C^2}\\sqrt{m^2+n^2+p^2}} \\]\n旋转曲面 设在\\(yOz\\)坐标面上有一已知曲线\\(f(y,z)=0\\)\n则把这个曲线绕z轴旋转一周，得到的曲面为\\(f(\\pm\\sqrt{x^2+y^2},z)=0\\)\n绕y轴旋转则为\\(f(y,\\pm\\sqrt{x^2+z^2})=0\\)\n在其他坐标面上的曲线类似。\n二次曲面举例 椭圆锥面 \\[\\frac{x^2}{a^2}+\\frac{y^2}{b^2}=z^2 \\]\n8-47.jpg\r椭球面 \\[\\frac{x^2}{a^2}+\\frac{y^2}{b^2}+\\frac{z^2}{c^2}=1 \\]\n8-49.jpg\r单叶双曲面 \\[\\frac{x^2}{a^2}+\\frac{y^2}{b^2}-\\frac{z^2}{c^2}=1 \\]\n8-40.jpg\r双叶双曲面 \\[\\frac{x^2}{a^2}-\\frac{y^2}{b^2}-\\frac{z^2}{c^2}=1 \\]\n8-41.jpg\r椭圆抛物面 \\[\\frac{x^2}{a^2}+\\frac{y^2}{b^2}=z \\]\n8-50\r双曲抛物面 \\[\\frac{x^2}{a^2}-\\frac{y^2}{b^2}=z \\]\n8-51\r空间曲线及其方程 一般方程 即两个曲面的交线\n\\[\\left\\{\\begin{matrix} F(x,y,z) = 0 \\\\ G(x,y,z) = 0 \\end{matrix}\\right. \\]\n参数方程 \\[\\left\\{\\begin{matrix} x=x(t) \\\\ y=y(t) \\\\ z=z(t) \\end{matrix}\\right. \\]\n多元函数微分法及其应用 多元函数的极限 注意极限存在，当且仅当从各个方向趋近那个点时得到的值存在并相等。\n例如\\(f(x,y)=\\frac{xy}{x^2+y^2},x^2+y^2\\neq 0;f(x,y)=0,x^2+y^2=0\\)，有沿x轴y轴趋近\\((0,0)\\)极限都为0，但沿直线\\(y=kx\\)趋近时极限随\\(k\\)变化。故极限不存在。\n偏导数 注意有时利用定义求解偏导数会更优\n例如关于\\(x\\)的偏导数\n\\[\\lim_{\\Delta x \\to 0}\\frac{f(x_0+\\Delta x,y_0)-f(x_0,y_0)}{\\Delta x} \\]\n在如\\(x_0=0,y_0=0\\)或者其他性质比较好的点，会更容易求。\n高阶偏导数 注意分母上，求导顺序为从左到右。\n如果函数\\(z=f(x,y)\\)的两个二阶混合偏导数\\(\\frac{\\partial^2z}{\\partial y\\partial x}\\)及\\(\\frac{\\partial^2z}{\\partial x\\partial y}\\)在区域\\(D\\)内连续，那么在该区域内这两个二阶混合偏导数必相等。\n全微分 必要条件 如果函数\\(z=f(x,y)\\)在点\\((x,y)\\)可微分（蕴含着函数在该点上连续），那么该函数在点\\((x,y)\\)的偏导数\\(\\frac{\\partial z}{\\partial x}\\)与\\(\\frac{\\partial z}{\\partial y}\\)必定存在，且该函数在该点的全微分为\n\\[dz=\\frac{\\partial z}{\\partial x}\\Delta x+\\frac{\\partial z}{\\partial y}\\Delta y \\]\n但这只是必要条件。\n形式上的全微分\\(\\Delta z\\)(和上文的\\(dz\\)一个意思)应该满足\n\\[\\frac{\\Delta z-[f_x(x_0,y_0)\\cdot\\Delta x+f_y(x_0,y_0)\\cdot\\Delta y]}{\\rho} \\]\n随着\\(\\rho\\to0\\)而趋于\\(0\\)。\n其中\n\\[\\rho=\\sqrt{(\\Delta x)^2+(\\Delta y)^2} \\]\n才能可微。\n充分条件 如果函数\\(z=f(x,y)\\)的偏导数\\(\\frac{\\partial z}{\\partial x}\\)、\\(\\frac{\\partial z}{\\partial y}\\)在\\((x,y)\\)连续，那么该函数在该点可微分。\n多元复合函数的求导法则 一元函数与多元函数复合的情形 如果函数\\(u=\\varphi(t)\\)及\\(v=\\psi(t)\\)都在点\\(t\\)可导，函数\\(z=f(u,v)\\)在对应点\\((u,v)\\)具有连续偏导数，那么复合函数\\(z=f[\\varphi(t),\\psi(t)]\\)在t可导，且有\n\\[\\frac{dz}{dt}=\\frac{\\partial z}{\\partial u}\\frac{du}{dt}+\\frac{\\partial z}{\\partial v}\\frac{dv}{dt} \\]\n多元函数与多元函数复合的情形 \\[u=\\varphi(x,y),v=\\psi(x,y),z=f(u,v) \\]\n若都在对应点\\((x,y)\\)具有连续偏导数，则\n\\[\\frac{\\partial z}{\\partial x}=\\frac{\\partial z}{\\partial u}\\frac{\\partial u}{\\partial x}+\\frac{\\partial z}{\\partial v}\\frac{\\partial v}{\\partial x} \\]\n\\[\\frac{\\partial z}{\\partial y}=\\frac{\\partial z}{\\partial u}\\frac{\\partial u}{\\partial y}+\\frac{\\partial z}{\\partial v}\\frac{\\partial v}{\\partial y} \\]\n混合复合 根据每个复合函数是否含有自变量\\(x,y\\)进行偏导，例如\n\\[u=\\varphi(x,y),v=\\psi(y),z=f(u,v) \\]\n则\n\\[\\frac{\\partial z}{\\partial x}=\\frac{\\partial z}{\\partial u}\\frac{\\partial u}{\\partial x} \\]\n\\[\\frac{\\partial z}{\\partial y}=\\frac{\\partial z}{\\partial u}\\frac{\\partial u}{\\partial y}+\\frac{\\partial z}{\\partial v}\\frac{d v}{d y} \\]\n如果有两层复合函数，则要求导至将\\(x,y\\)这样的自变量暴露出来。\n全微分形式的不变性 设函数\\(z=f(u,v)\\)具有连续偏导数，则有全微分\n\\[dz=\\frac{\\partial z}{\\partial u}du+\\frac{\\partial z}{\\partial v}dv \\]\n若有\\(u=\\varphi(x,y),v=\\psi(x,y)\\)，有\n\\[dz=\\frac{\\partial z}{\\partial x}dx+\\frac{\\partial z}{\\partial y}dy \\]\n显然可以算出\\(\\frac{\\partial z}{\\partial x},\\frac{\\partial z}{\\partial y}\\)，代入有\n\\[dz=\\frac{\\partial z}{\\partial u}du+\\frac{\\partial z}{\\partial v}dv \\]\n此为全微分形式的不变性。\n隐函数的求导公式 一个方程的情形 \\[F(x,y)=0 \\]\n\\[\\frac{dy}{dx}=-\\frac{F_x}{F_y} \\]\n条件：F在某点的某一邻域内具有连续偏导数，\\(F_y\\)在该点不为0\n\\[F(x,y,z)=0 \\]\n\\[\\frac{\\partial z}{\\partial x}=-\\frac{F_x}{F_z},\\frac{\\partial z}{\\partial y}=-\\frac{F_y}{F_z} \\]\n条件类似于上条。\n方程组的情形 考虑如下方程组\n\\[\\left\\{\\begin{matrix} F(x,y,u,v)=0\\\\ G(x,y,u,v)=0 \\end{matrix}\\right. \\]\n一般四个变量只能有两个变量独立变化\n即\n\\[u(x,y),v(x,y) \\]\n两边应用求导法则得\n\\[F_x+F_u\\frac{\\partial u}{\\partial x}+F_v\\frac{\\partial v}{\\partial x}=0 \\]\n\\[G_x+G_u\\frac{\\partial u}{\\partial x}+G_v\\frac{\\partial v}{\\partial x}=0 \\]\n解方程求出偏导数，求关于\\(y\\)的偏导数同理。\n多元函数积分学的几何应用 一元向量值函数及其导数 空间曲线\\(\\Gamma\\)的参数方程为\n\\[\\left\\{\\begin{matrix} x=\\varphi(t), \\\\ y=\\psi(t), \\\\ z=\\omega(t) \\end{matrix}\\right. t\\in[\\alpha,\\beta] \\]\n写成向量形式，则为\n\\[\\bold{r}=x\\bold{i}+y\\bold{j}+z\\bold{k} \\]\n\\[\\bold{f}(t)=\\varphi(t)\\bold{i}+\\psi(t)\\bold{j}+\\omega(t)\\bold{k} \\]\n所以有\\(\\bold{r=f}(t)\\)， \\(\\bold{r}\\)称为向量函数\n向量值导数如下：\n\\[\\bold{f}'(t_0)=\\lim_{\\Delta t\\to 0}\\frac{\\Delta \\bold{r}}{\\Delta t} =\\lim_{\\Delta t\\to 0}\\frac{\\bold{f}(t_0+\\Delta t)-\\bold{f}(t_0)}{\\Delta t} \\]\n或者如下计算：\n\\[\\bold{f}'(t_0)=\\bold{f_1}'(t_0)\\bold{i}+\\bold{f_2}'(t_0)\\bold j+ \\bold{f_3}'(t_0)\\bold k \\]\n空间曲线的切线与法平面 还是上面那个曲线\\(\\Gamma\\)，则切线方程为\n\\[\\frac{x-x_0}{\\varphi'(t_0)}= \\frac{y-y_0}{\\psi'(t_0)}= \\frac{z-z_0}{\\omega'(t_0)} \\]\n法平面方程为\n\\[\\varphi'(t_0)(x-x_0)+ \\psi'(t_0)(y-y_0)+ \\omega'(t_0)(z-z_0)=0 \\]\n若\\(\\Gamma\\)变为\n\\[\\left\\{\\begin{matrix} x=x \\\\ y=\\varphi(x) \\\\ z=\\psi(x) \\end{matrix}\\right. \\]\n则切线方程变为\n\\[\\frac{x-x_0}{1}= \\frac{y-y_0}{\\varphi'(x_0)}= \\frac{z-z_0}{\\psi'(x_0)} \\]\n法平面方程变为\n\\[(x-x_0)+ \\varphi'(x_0)(y-y_0)+ \\psi'(x_0)(z-z_0)=0 \\]\n曲线为方程组情形时（三个变量一般只有一个自由变量，所以直接将\\(y,z\\)替换为\\(\\varphi(x),\\psi(x)\\)）\n\\[F[x,\\varphi(x),\\psi(x)]=0 \\]\n\\[G[x,\\varphi(x),\\psi(x)]=0 \\]\n两边求对\\(x\\)的全导数\n\\[\\frac{\\partial F}{\\partial x}+\\frac{\\partial F}{\\partial y} \\frac{dy}{dx}+\\frac{\\partial F}{\\partial z}\\frac{dz}{dx}=0 \\]\n\\[\\frac{\\partial G}{\\partial x}+\\frac{\\partial G}{\\partial y} \\frac{dy}{dx}+\\frac{\\partial G}{\\partial z}\\frac{dz}{dx}=0 \\]\n解出\\(\\bold{T}=(1,\\frac{dy}{dx},\\frac{dz}{dx})\\)，即\\(\\bold{T}=(1,\\varphi'(x_0),\\psi'(x_0))\\)，就是在此点的切向量，代入可知切线与法平面方程\n曲面的切平面与法线 若曲面由\\(F(x,y,z)=0\\)隐性给出，则在点\\(M(x_0,y_0,z_0)\\)切平面方程为\n\\[F_x(x-x_0)+F_y(y-y_0)+F_z(z-z_0)=0 \\]\n其中各个偏导数都是在M点的偏导数，法线方程如下\n\\[\\frac{x-x_0}{F_x}=\\frac{y-y_0}{F_y}=\\frac{z-z_0}{F_z} \\]\n考虑曲面方程为\\(z=f(x,y)\\)，则可令\\(F(x,y,z)=f(x,y)-z\\)\n显然有\n\\[F_x(x,y,z)=f_x(x,y),F_y(x,y,z)=f_y(x,y),F_z(x,y,z)=-1 \\]\n切平面、法线方程类似于上。\n方向导数与梯度 方向导数：\n\\[\\frac{\\partial f}{\\partial l}\\bigg|_{(x_0,y_0)}= \\lim _{t\\to 0^+}\\frac{f(x_0+tcos\\alpha,y_0+tcos\\beta)-f(x_0,y_0)}{t} \\]\n如果函数\\(f(x,y)\\)在点\\(P_0(x_0,y_0)\\)可微分，那么函数在该点沿任一方向\\(l\\)的方向导数存在，且有\n\\[\\frac{\\partial f}{\\partial l}\\bigg|_{(x_0,y_0)}= f_x(x_0,y_0)cos\\alpha+f_y(x_0,y_0)cos\\beta \\]\n其中\\(cos\\alpha,cos\\beta\\)是方向\\(l\\)的方向余弦。\n梯度：\n\\[\\bold{grad}f(x_0,y_0)=\\nabla f(x_0,y_0)=f_x(x_0,y_0)\\bold{i}+ f_y(x_0,y_0)\\bold{j} \\]\n如果方向导数存在，则\n\\[\\frac{\\partial f}{\\partial l}\\bigg|_{(x_0,y_0)}= f_x(x_0,y_0)cos\\alpha+f_y(x_0,y_0)cos\\beta =\\nabla f(x_0,y_0)\\cdot \\bold{e}_l=|\\nabla f|cos\\theta \\]\n其中\n\\[\\theta=\u003c\\nabla f,\\bold{e}_l\u003e \\]\n多元函数的极值及其求法 必要条件 设函数\\(z=f(x,y)\\)在点\\((x_0,y_0)\\)具有偏导数，且在点\\((x_0,y_0)\\)处有极值，则有\n\\[f_x(x_0,y_0)=0,f_y(x_0,y_0)=0 \\]\n充分条件 设函数\\(z=f(x,y)\\)在点\\((x_0,y_0)\\)的某领域内连续且有一阶和二阶连续偏导数，又\\(f_x(x_0,y_0)=0,f_y(x_0,y_0)=0\\)，令\n\\[f_{xx}(x_0,y_0)=A,f_{xy}(x_0,y_0)=B,f_{yy}(x_0,y_0)=C \\]\n若\n\\(AC-B^2\u003e0\\)时具有极值，\\(A\u003c0\\)时有极大值，\\(A\u003e0\\)时有极小值；\n\\(AC-B^2\u003c0\\)时没有极值\n\\(AC-B^2=0\\)时可能有也可能没有，需要另作讨论。\n拉格朗日乘数法 要找函数\\(z=f(x,y)\\)在附加条件\\(\\varphi(x,y)=0\\)下的可能极值点，先设\n\\[L(x,y)=f(x,y)+\\lambda\\varphi(x,y) \\]\n令\n\\[\\left\\{\\begin{matrix} L_x=f_x+\\lambda\\varphi_x=0 \\\\ L_y=f_y+\\lambda\\varphi_y=0 \\\\ L_{\\lambda}=\\varphi=0 \\end{matrix}\\right. \\]\n解出\\(x,y,\\lambda\\)，代入函数\\(f\\)中求得可能的极值点。\n多个条件时，如多加一个\\(\\psi(x,y)=0\\)，则设方程\n\\[L(x,y)=f(x,y)+\\lambda\\varphi(x,y)+\\mu\\psi(x,y) \\]\n分别求\\(L_x=0,L_y=0,L_\\lambda=0,L\\mu=0\\)，代入原函数中求可能的极值点。\n重积分 二重积分的概念与性质 性质：\n设\\(\\alpha,\\beta\\)为常数，则 \\[\\iint\\limits_{D}[\\alpha f(x,y)+\\beta g(x,y)]d\\sigma= \\alpha\\iint\\limits_{D}f(x,y)d\\sigma+\\beta\\iint\\limits_{D}g(x,y)d\\sigma \\]\n如果闭区域\\(D\\)被有限条曲线分为有限个部分闭区域，那么在\\(D\\)上的二重积分等于在各部分闭区域上的二重积分的和 \\[\\iint\\limits_{D}f(x,y)d\\sigma= \\iint\\limits_{D_1}f(x,y)d\\sigma+\\iint\\limits_{D_2}f(x,y)d\\sigma \\]\n如果在\\(D\\)上，\\(f(x,y)=1\\)，\\(\\sigma\\)为\\(D\\)的面积，那么 \\[\\sigma=\\iint\\limits_{D}1\\cdot d\\sigma=\\iint\\limits_{D}d\\sigma \\]\n如果在\\(D\\)上，\\(f(x,y)\\leq g(x,y)\\)，那么有 \\[\\iint\\limits_{D}f(x,y)d\\sigma\\leq\\iint\\limits_{D}g(x,y)d\\sigma \\]\n特别的，有\n\\[\\left|\\iint\\limits_{D}f(x,y)d\\sigma\\right|\\leq \\iint\\limits_{D}|f(x,y)|d\\sigma \\]\n设\\(M\\)和\\(N\\)分别是\\(f(x,y)\\)在闭区域\\(D\\)上的最大值和最小值，\\(\\sigma\\)是\\(D\\)的面积，则有 \\[m\\sigma\\leq\\iint\\limits_{D}f(x,y)d\\sigma\\leq M\\sigma \\]\n设函数\\(f(x,y)\\)在闭区域D上连续，\\(\\sigma\\)是\\(D\\)的面积，则在\\(D\\)上至少存在一点\\((\\xi,\\eta)\\)，使得 \\[\\iint\\limits_{D}f(x,y)d\\sigma=f(\\xi,\\eta)\\sigma \\]\n二重积分的计算法 利用直角坐标计算二重积分 10-4\r在如图的区域中，积分上限为上方曲线，积分下限为下方曲线。\n\\[\\iint\\limits_{D}f(x,y)d\\sigma=\\int_a^bdx\\int_{\\varphi_1(x)} ^{\\varphi_2(x)}f(x,y)dy \\]\n10-6\r如图则，积分上限为右侧曲线，下限为左侧曲线。\n\\[\\iint\\limits_{D}f(x,y)d\\sigma=\\int_c^ddy\\int_{\\psi_1(y)} ^{\\psi_2(y)}f(x,y)dx \\]\n利用极坐标计算二重积分 有\n\\[x=\\rho cos\\theta \\]\n\\[y=\\rho sin\\theta \\]\n且有对于下图\n10-18\r\\[\\iint\\limits_{D}f(x,y)d\\sigma=\\iint\\limits_{D}f(\\rho cos\\theta, \\rho sin\\theta)\\rho d\\rho d\\theta \\]\n\\[=\\int_\\alpha^\\beta d\\theta\\int_{\\varphi_1(\\theta)} ^{\\varphi_2(\\theta)}f(\\rho cos\\theta, \\rho sin\\theta)\\rho d\\rho \\]\n三重积分的计算 利用直角坐标计算三重积分 “先1后2法”，即先以\\(z\\)为积分变量计算 \\[\\iiint\\limits_\\Omega f(x,y,z)dv=\\int_a^bdx\\int_{y_1(x)}^{y_2(x)} dy\\int_{z_1(x,y)}^{z_2(x,y)}f(x,y,z)dz \\]\n\u0026ldquo;先2后1法\u0026rdquo;，即先以\\(xy\\)为积分变量计算 \\[\\iiint\\limits_\\Omega f(x,y,z)dv=\\int_{c_1}^{c_2}dz\\iint\\limits_{D_z} f(x,y,z)dxdy \\]\n利用柱面坐标计算 有\n\\[\\left\\{\\begin{matrix} x=\\rho cos\\theta \\\\ y=\\rho sin\\theta \\\\ z=z \\end{matrix}\\right. \\]\n有\n\\[\\iiint\\limits_{\\Omega}f(x,y,z)dxdydz= \\iiint\\limits_{\\Omega}F(\\rho,\\theta,z)\\rho d\\rho d\\theta dz \\]\n利用球面坐标计算 有\n\\[\\left\\{\\begin{matrix} x=rsin\\varphi cos\\theta \\\\ y=rsin\\varphi sin\\theta \\\\ z=rcos\\varphi \\end{matrix}\\right. \\]\n有\n\\[\\iiint\\limits_{\\Omega}f(x,y,z)dxdydz= \\iiint\\limits_{\\Omega}F(r,\\varphi,\\theta)r^2sin\\varphi drd\\varphi d\\theta \\]\n拆分被积函数 详细的证明没有在书中和老师的教学中找到，互联网搜索也较难\n书上有许多例子，如当\n\\[\\rho ^2\\leq z\\leq4,0\\leq\\rho\\leq2,0\\leq\\theta\\leq2\\pi \\]\n有\n\\[\\iiint\\limits_{\\Omega}zdxdydz=\\iiint\\limits_{\\Omega}z\\rho d\\rho d\\theta dz=\\int_0^{2\\pi}d\\theta\\int_0^2\\rho d\\rho\\int_{\\rho^2}^4zdz \\]\n推断为，首先被积函数要是\\(f(z)g(\\rho)\\)等用乘法连接的，如\\(z\\rho\\)，而不能是加法如\\(z+\\rho\\)，才能拆分。另外跟积分上下限的关系不明。\n如果是加法，如\\(x+y+z\\)可以从轮换对称性考虑（如果有）\n重积分的应用 曲面面积 设曲面为\\(z=f(x,y)\\)，则\n\\[A=\\iint\\limits_D\\sqrt{1+f_x^2(x,y)+f_y^2(x,y)}dxdy \\]\n质心 设有一平面薄片，占据\\(xOy\\)面上的闭区域\\(D\\)，在点\\((x,y)\\)处的面密度为\\(\\mu(x,y)\\)\n则有\n\\[M_y=\\iint\\limits_Dx\\mu(x,y)d\\sigma, M_x=\\iint\\limits_Dy\\mu(x,y)d\\sigma \\]\n\\[M=\\iint\\limits_D\\mu(x,y)d\\sigma \\]\n质心坐标为\n\\[\\bar{x}=\\frac{M_y}{M}= \\frac{\\iint\\limits_Dx\\mu(x,y)d\\sigma}{\\iint\\limits_D\\mu(x,y)d\\sigma} \\]\n\\[\\bar{y}=\\frac{M_x}{M}=\\frac{\\iint\\limits_Dy\\mu(x,y)d\\sigma}{\\iint\\limits_D\\mu(x,y)d\\sigma} \\]\n转动惯量 \\[I_x=\\iint\\limits_Dy^2\\mu(x,y)d\\sigma,I_y=\\iint\\limits_Dx^2\\mu(x,y)d\\sigma \\]\n引力 空间一物体对物体外一点\\(P_0(x_0,y_0,z_0)\\)的单位质量的质点的引力\n物体密度\\(\\rho(x,y,z)\\)，\n\\[\\bold{F}=(F_x,F_y,F_z) \\]\n\\[=\\left ( \\iiint\\limits_\\Omega\\frac{G\\rho(x,y,z)(x-x_0)}{r^3}dv, \\iiint\\limits_\\Omega\\frac{G\\rho(x,y,z)(y-y_0)}{r^3}dv, \\iiint\\limits_\\Omega\\frac{G\\rho(x,y,z)(z-z_0)}{r^3}dv \\right ) \\]\n曲线积分与曲面积分 对弧长的曲线积分 性质 设\\(\\alpha,\\beta\\)为常数，则 \\[\\int_L[\\alpha f(x,y)+\\beta g(x,y)]ds=\\alpha\\int_L f(x,y)ds+\\beta \\int_Lg(x,y)ds \\]\n若积分弧段\\(L\\)课分成两段光滑曲线弧\\(L_1\\)和\\(L_2\\)，则 \\[\\int_Lf(x,y)ds=\\int_{L_1}f(x,y)ds+\\int_{L_2}f(x,y)ds \\]\n设在\\(L\\)上\\(f(x,y)\\leq g(x,y)\\), 则 \\[\\int_L f(x,y)ds\\leq\\int_L g(x,y)ds \\]\n特别地，有\n\\[\\left|\\int_L f(x,y)ds\\right|\\leq\\int_L|f(x,y)|ds \\]\n对弧长的曲线积分的计算法 设\\(f(x,y)\\)在曲线弧\\(L\\)上有定义且连续，\\(L\\)的参数方程为\n\\[\\left\\{\\begin{matrix} x=\\varphi(t) \\\\ y=\\psi(t) \\end{matrix}\\right. (\\alpha\\leq t\\leq\\beta) \\]\n若\\(\\varphi(t)\\)、\\(\\psi(t)\\)在\\([\\alpha,\\beta]\\)上具有一阶连续导数，且\\(\\varphi'^2(t)+\\psi'^2(t)\\neq0\\)，则曲线积分\\(\\int_Lf(x,y)ds\\)存在，且\n\\[\\int_Lf(x,y)ds=\\int_\\alpha^\\beta f[\\varphi(t),\\psi(t)] \\sqrt{\\varphi'^2(t)+\\psi'^2(t)}dt (a\u003c\\beta) \\]\n注意\\(\\alpha\u003c\\beta\\)是一定要有的。\n对坐标的曲线积分 \\[\\int_LP(x,y)dx+Q(x,y)dy \\]\n也可以写作向量形式\n\\[\\int_L\\bold{F(x,y)}\\cdot d\\bold{r} \\]\n其中\\(\\bold{F}=P\\bold{i}+Q\\bold{j}\\)，\\(d\\bold{r}=dx\\bold{i}+dy\\bold{j}\\).\n性质 与上节相同\n与上节相同\n设\\(L\\)是有向光滑曲线弧，\\(L^-\\)是\\(L\\)的反向曲线弧，则\n\\[\\int_{L^-}\\bold F(x,y)d\\bold r = -\\int_L\\bold F(x,y)d\\bold r \\]\n对坐标的曲线积分的计算方法 条件相似，不再重复，查阅书籍\n\\[\\left\\{\\begin{matrix} x=\\varphi(t) \\\\ y=\\psi(t) \\end{matrix}\\right. \\]\n\\(t\\)单调地由\\(\\alpha\\)变到\\(\\beta\\)\n\\[\\int_LP(x,y)dx+Q(x,y)dy \\]\n\\[=\\int_\\alpha^\\beta\\{P[\\varphi(t),\\psi(t)]\\varphi'(t)+ Q[\\varphi(t),\\psi(t)]\\psi'(t)\\}dt \\]\n不需要\\(\\alpha\u003c\\beta\\)，有时有\\(x=x,y=y(x)\\)，类似的替换公式即可。\n两类曲线积分之间的联系 \\[\\int_LPdx+Qdy=\\int_L(Pcos\\alpha+Qcos\\beta)ds \\]\n易推广至三维\n也可以写成向量形式\n\\[\\int_L\\bold A\\cdot d\\bold r = \\int_L\\bold A\\cdot\\bm{\\tau}ds= \\int_LA_{\\tau}ds \\]\n格林公式 定理1，设闭区域\\(D\\)由分段光滑的曲线\\(L\\)围成，若函数\\(P(x,y)\\)及\\(Q(x,y)\\)在\\(D\\)上具有一阶连续偏导数，则有\n\\[\\iint\\limits_D(\\frac{\\partial Q}{\\partial x}-\\frac{\\partial P}{\\partial y}) dxdy=\\oint_LPdx+Qdy \\]\n其中\\(L\\)是\\(D\\)的取正向的边界曲线。\n对平面区域\\(D\\)的边界曲线\\(L\\)，规定正向如下：当观察者沿着\\(L\\)的这个方向行走时，\\(D\\)总在他的左边。\n定理2，设区域\\(G\\)是一个单连通域（复连通不是充要条件），若函数\\(P(x,y),Q(x,y)\\)在\\(G\\)内具有一阶连续偏导数，则曲线积分\\(\\int_LPdx+Qdy\\)在\\(G\\)内与路径无关（或沿着\\(G\\)内任意闭曲线的曲线积分为0）的充分必要条件是\n\\[\\frac{\\partial P}{\\partial y}=\\frac{\\partial Q}{\\partial x} \\]\n在\\(G\\)内恒成立。\n定理3，设区域\\(G\\)是一个单连通域（复连通不是充要条件，若函数\\(P(x,y),Q(x,y)\\)在\\(G\\)内具有一阶连续偏导数，则\\(P(x,y)dx+Q(x,y)dy\\)在\\(G\\)内为某一函数\\(u(x,y)\\)的全微分的充分必要条件是\n\\[\\frac{\\partial P}{\\partial y}=\\frac{\\partial Q}{\\partial x} \\]\n在\\(G\\)内恒成立。\n对面积的曲面积分 \\[\\iint\\limits_{\\Sigma}f(x,y,z)dS \\]\n\\[=\\iint\\limits_{D_{xy}}f[x,y,z(x,y)]\\sqrt{1+z_x^2(x,y)+z_y^2(x,y)}dxdy \\]\n对坐标的曲面积分 关于方向 假设某块小曲面\\(\\Delta S\\)与\\(z\\)轴的夹角为\\(\\gamma\\)角，在\\(xOy\\)面上的投影是\\((\\Delta\\sigma)_{xy}\\)，则规定\\(\\Delta S\\)在\\(xOy\\)面上的投影\\((\\Delta S)_{xy}\\)为\n\\[(\\Delta S)_{xy}=\\left\\{\\begin{matrix} (\\Delta\\sigma)_{xy}, cos\\gamma\u003e0 \\\\ -(\\Delta\\sigma)_{xy}, cos\\gamma\u003c0 \\\\ 0, cos\\gamma\\equiv 0 \\end{matrix}\\right. \\]\n投影到其他坐标面类似，总而言之向上、向右、向前是正向曲面。\n对坐标的曲面积分的计算法 如果曲面积分是在曲面\\(\\Sigma\\)上侧的，那么\n\\[\\iint\\limits_\\Sigma R(x,y,z)dxdy=\\iint\\limits_{D_{xy}}R[x,y,z(x,y)]dxdy \\]\n若在下侧，则\n\\[\\iint\\limits_\\Sigma R(x,y,z)dxdy=-\\iint\\limits_{D_{xy}}R[x,y,z(x,y)]dxdy \\]\n同理有\n\\[\\iint\\limits_\\Sigma P(x,y,z)dydz=\\pm\\iint\\limits_{D_{yz}}P[x(y,z),y,z]dydz \\]\n\\[\\iint\\limits_\\Sigma Q(x,y,z)dzdx=\\pm\\iint\\limits_{D_{zx}}Q[x,y(z,x),z]dzdx \\]\n两类曲面积分之间的联系 \\[\\iint\\limits_\\Sigma Pdydz+Qdzdx+Rdxdy=\\iint\\limits_\\Sigma(Pcos\\alpha+Qcos\\beta+Rcos\\gamma)dS \\]\n写成向量形式\n\\[\\iint\\limits_\\Sigma \\bold{A}\\cdot d\\bold{S}=\\iint\\limits_\\Sigma \\bold{A}\\cdot\\bold{n}dS \\]\n高斯公式 通量与散度 高斯公式 设空间闭区域\\(\\Omega\\)是由分片光滑的闭曲面\\(\\Sigma\\)所围成，若函数\\(P(x,y,z),Q(x,y,z),R(x,y,z)\\)在\\(\\Omega\\)上具有一阶连续偏导数，则有\n\\[\\iiint\\limits_\\Omega(\\frac{\\partial P}{\\partial x}+\\frac{\\partial Q}{\\partial y}+\\frac{\\partial R}{\\partial z})dv=\\oiint\\limits_\\Sigma Pdydz+Qdzdx+Rdxdy \\]\n或\n\\[\\iiint\\limits_\\Omega(\\frac{\\partial P}{\\partial x}+\\frac{\\partial Q}{\\partial y}+\\frac{\\partial R}{\\partial z})dv=\\oiint\\limits_\\Sigma(Pcos\\alpha+Qcos\\beta+Rcos\\gamma)dS \\]\n这里\\(\\Sigma\\)是\\(\\Omega\\)的整个边界曲面的外侧，\\(cos\\alpha、cos\\beta、cos\\gamma\\)是\\(\\Sigma\\)在点\\((x,y,z)\\)处的法向量的方向余弦。\n沿任意闭曲面的曲面积分为零的条件 设\\(G\\)是空间二维单连通区域，若\\(P(x,y,z),Q(x,y,z),R(x,y,z)\\)在\\(G\\)内具有一阶连续偏导数，则曲面积分\n\\[\\iint\\limits_\\Sigma Pdydz+Qdzdx+Rdxdy \\]\n在\\(G\\)内所取曲面\\(\\Sigma\\)无关而只取决于\\(\\Sigma\\)的边界曲线(或沿\\(G\\)内任一闭曲面的曲面积分为零)的充分必要条件是\n\\[\\frac{\\partial P}{\\partial x}+\\frac{\\partial Q}{\\partial y}+\\frac{\\partial R}{\\partial z}=0 \\]\n在\\(G\\)内恒成立。\n通量与散度 设有向量场\n\\[\\bold{A}(x,y,z) = P(x,y,z)\\bold i+Q(x,y,z)\\bold j+R(x,y,z)\\bold k \\]\n其中函数\\(P,Q,R\\)均有一阶连续偏导数，\\(\\Sigma\\)是场内的一片有向曲面，\\(\\bold n\\)是\\(\\Sigma\\)在点\\((x,y,z)\\)处的单位法向量，则积分\n\\[\\iint\\limits_\\Sigma \\bold A\\cdot \\bold ndS \\]\n称为向量场\\(\\bold A\\)通过曲面\\(\\Sigma\\)向着指定侧的通量（或流量）。 又可表达为\n\\[\\iint\\limits_\\Sigma \\bold A\\cdot \\bold ndS=\\iint\\limits_\\Sigma \\bold Ad\\bold S=\\iint\\limits_\\Sigma Pdydz+Qdzdx+Rdxdy \\]\n对于这个向量场，其散度记作\\(div\\bold A\\)，即\n\\[div\\bold A=\\frac{\\partial P}{\\partial x}+\\frac{\\partial Q}{\\partial y}+\\frac{\\partial R}{\\partial z} \\]\n利用向量微分算子\\(\\nabla\\)，也可以表示为\n\\[div\\bold A = \\nabla\\cdot\\bold A \\]\n利用向量场的通量和散度，高斯公式可以写成\n\\[\\iiint\\limits_{\\Omega}div\\bold Adv=\\iint\\limits_\\Sigma A_ndS \\]\n斯托克斯公式 环流量与旋度 斯托克斯公式 设\\(\\Gamma\\)为分段光滑的空间有向闭曲线，\\(\\Sigma\\)是以\\(\\Gamma\\)为边界的分片光滑的有向曲面，\\(\\Gamma\\)的正向与\\(\\Sigma\\)的侧符合右手规则，若函数\\(P(x,y,z),Q(x,y,z),R(x,y,z)\\)在曲面\\(\\Sigma\\)(连同边界\\(\\Gamma\\))上具有一阶连续偏导数，则有\n\\[\\iint\\limits_\\Sigma\\left(\\frac{\\partial R}{\\partial y}-\\frac{\\partial Q}{\\partial z}\\right)dydz+\\left(\\frac{\\partial P}{\\partial z}-\\frac{\\partial R}{\\partial x}\\right)dzdx+\\left(\\frac{\\partial Q}{\\partial x}-\\frac{\\partial P}{\\partial y}\\right)dxdy \\]\n\\[=\\oint_\\Gamma Pdx+Qdy+Rdz \\]\n空间曲线积分与路径无关的条件 设空间区域\\(G\\)是一维单连通域，若函数\\(P(x,y,z),Q(x,y,z),R(x,y,z)\\)在\\(G\\)内具有一阶连续偏导数，则空间曲线积分\\(\\int_\\Gamma Pdx+Qdy+Rdz\\)在\\(G\\)内与路径无关（或沿\\(G\\)内任意闭合曲线的曲线积分为零）的充分必要条件是\n\\[\\frac{\\partial P}{\\partial y}=\\frac{\\partial Q}{\\partial x},\\frac{\\partial Q}{\\partial z}=\\frac{\\partial R}{\\partial y},\\frac{\\partial R}{\\partial x}=\\frac{\\partial P}{\\partial z} \\]\n在\\(G\\)内恒成立\n环流量与旋度 设有向量场\n\\[\\bold{A}(x,y,z) = P(x,y,z)\\bold i+Q(x,y,z)\\bold j+R(x,y,z)\\bold k \\]\n其中函数\\(P,Q,R\\)均连续，\\(\\Gamma\\)是\\(\\bold A\\)的定义域内的一条分段光滑的有向闭曲线，\\(\\bm\\tau\\)是\\(\\Gamma\\)在点\\((x,y,z)\\)处的单位切向量，则积分\n\\[\\oint_L\\bold A\\cdot\\bm {\\tau}ds \\]\n称为向量场\\(\\bold A\\)沿有向闭曲线\\(\\Gamma\\)的环流量。\n又可表述为\n\\[\\oint_L\\bold A\\cdot\\bm {\\tau}ds=\\oint_L\\bold Ad\\bold r = \\oint_\\Gamma Pdx+Qdy+Rdz \\]\n向量场\\(\\bold A\\)的旋度，记作\\(\\bold{rotA}\\)，即\n\\[\\bold{rotA} = \\left(\\frac{\\partial R}{\\partial y}-\\frac{\\partial Q}{\\partial z}\\right)\\bold i+\\left(\\frac{\\partial P}{\\partial z}-\\frac{\\partial R}{\\partial x}\\right)\\bold j+\\left(\\frac{\\partial Q}{\\partial x}-\\frac{\\partial P}{\\partial y}\\right)\\bold k \\]\n\\[\\bold{rotA}=\\nabla\\times\\bold A \\]\n同样的，斯托克斯公式可以写成\n\\[\\iint\\limits_\\Sigma\\bold{rotA}\\cdot\\bold{n}dS=\\oint_\\Gamma\\bold{A}\\cdot\\bm{\\tau}ds \\]\n\\[\\iint\\limits_\\Sigma(\\bold{rotA})_ndS=\\oint_{\\Gamma}\\bold{A}_{\\tau} ds \\]\n无穷级数 常数项级数的概念和性质 常数项级数的概念 如果级数\\(\\sum^{\\infty}_{i=1}u_i\\)的部分和数列\\(\\{s_n\\}\\)有极限s，即\n\\[\\lim\\limits_{n\\to\\infty}s_n=s \\]\n那么称无穷级数\\(\\sum^{\\infty}_{i=1}u_i\\)收敛，这时极限\\(s\\)叫做这级数的和，并写成\n\\[s=u_1+u_2+\\dots+u_n+\\cdots \\]\n如果\\(\\{s_n\\}\\)没有极限，那么称无穷级数\\(\\sum^{\\infty}_{i=1}u_i\\)发散\n收敛级数的基本性质 性质1 如果级数\\(\\sum^{\\infty}_{n=1}u_n\\)收敛于和\\(s\\)，那么级数\\(\\sum^{\\infty}_{i=1}ku_i\\)也收敛，且其和为\\(ks\\).\n性质2 如果级数\\(\\sum^{\\infty}_{n=1}u_n\\)与\\(\\sum^{\\infty}_{n=1}v_n\\)分别收敛于\\(s,\\sigma\\)，那么级数\\(\\sum^{\\infty}_{n=1}(u_n\\pm v_n)\\)也收敛，且其和为\\(s\\pm\\sigma\\)\n性质3 在级数中去掉、加上或改变有限项，不会改变级数的收敛性\n性质4 如果级数\\(\\sum^{\\infty}_{n=1}u_n\\)收敛，那么对于这级数的项任意加括号后所成的级数仍收敛，且其和不变\n性质5（级数收敛的必要条件） 如果级数\\(\\sum^{\\infty}_{n=1}u_n\\)收敛，那么它的一般项\\(u_n\\)趋于0，即\n\\[\\lim\\limits_{n\\to\\infty}u_n=0 \\]\n常数项级数的审敛法 正项级数及其审敛法 定理1 正项级数\\(\\sum^{\\infty}_{n=1}u_n\\)收敛的充分必要条件是：它的部分和数列\\(\\{s_n\\}\\)有界\n定理2（比较审敛法） 设\\(\\sum^{\\infty}_{n=1}u_n\\)和\\(\\sum^{\\infty}_{n=1}v_n\\)都是正项级数，且\\(u_n\\leq v_n\\).若级数\\(\\sum^{\\infty}_{n=1}v_n\\)收敛，则级数\\(\\sum^{\\infty}_{n=1}u_n\\)收敛，若级数\\(\\sum^{\\infty}_{n=1}u_n\\)发散，则级数\\(\\sum^{\\infty}_{n=1}v_n\\)发散.\n推论 设\\(\\sum^{\\infty}_{n=1}u_n\\)和\\(\\sum^{\\infty}_{n=1}v_n\\)都是正项级数，如果级数\\(\\sum^{\\infty}_{n=1}v_n\\)收敛，且存在正整数\\(N\\)使当\\(n\\ge N\\)时有\\(u_n\\leq kv_n(k\u003e0)\\)成立，那么级数\\(\\sum^{\\infty}_{n=1}u_n\\)收敛；如果级数\\(\\sum^{\\infty}_{n=1}v_n\\)发散，且存在正整数\\(N\\)使当\\(n\\ge N\\)时有\\(u_n\\ge kv_n(k\u003e0)\\)成立，那么级数\\(\\sum^{\\infty}_{n=1}u_n\\)发散.\n定理3（比较审敛法的极限形式） 设\\(\\sum^{\\infty}_{n=1}u_n\\)和\\(\\sum^{\\infty}_{n=1}v_n\\)都是正项级数，\n如果\\(\\lim\\limits_{n\\to\\infty}\\frac{u_n}{v_n}=l(0\\leq l\u003c+\\infty)\\)，且级数\\(\\sum^{\\infty}_{n=1}v_n\\)收敛，那么级数\\(\\sum^{\\infty}_{n=1}u_n\\)收敛； 如果\\(\\lim\\limits_{n\\to\\infty}\\frac{u_n}{v_n}=l\u003e0\\)或\\(\\lim\\limits_{n\\to\\infty}\\frac{u_n}{v_n}=+\\infty\\)，且级数\\(\\sum^{\\infty}_{n=1}v_n\\)发散，那么级数\\(\\sum^{\\infty}_{n=1}u_n\\)发散； 定理4（比值审敛法，达朗贝尔判别法） 设\\(\\sum^{\\infty}_{n=1}u_n\\)是正项级数，如果\n\\[\\lim\\limits_{n\\to\\infty}\\frac{u_{n+1}}{u_n}=\\rho \\]\n那么当\\(\\rho\u003c1\\)时级数收敛，\\(\\rho\u003e1\\)(或\\(\\lim\\limits_{n\\to\\infty}\\frac{u_{n+1}}{u_n}=\\infty\\))时级数发散，\\(\\rho=1\\)时级数可能收敛也可能发散。\n定理5（根值审敛法，柯西判别法） 设\\(\\sum^{\\infty}_{n=1}u_n\\)是正项级数，如果\n\\[\\lim\\limits_{n\\to\\infty}\\sqrt[n]{u_n}=\\rho \\]\n那么当\\(\\rho\u003c1\\)时级数收敛，\\(\\rho\u003e1\\)(或\\(\\lim\\limits_{n\\to\\infty}\\sqrt[n]{u_n}=+\\infty\\))时级数发散，\\(\\rho=1\\)时级数可能收敛也可能发散。\n定理6（极限审敛法） \\(\\sum^{\\infty}_{n=1}u_n\\)是正项级数，\n如果\\(\\lim\\limits_{n\\to\\infty}nu_n=l\u003e0\\)(或\\(\\lim\\limits_{n\\to\\infty}nu_n=+\\infty\\))，那么该级数发散； 如果\\(p\u003e1\\)，而\\(\\lim\\limits_{n\\to\\infty}n^pu_n=l\u003e0(0\\leq l\u003c+\\infty)\\)，那么该级数收敛. 交错级数及其审敛法 定理7（莱布尼茨定理） 如果交错级数\\(\\sum^{\\infty}_{n=1}(-1)^{n-1}u_n\\)满足条件：\n\\(u_n\\ge u_{n+1}\\) \\(\\lim\\limits_{n\\to\\infty}u_n=0\\) 那么级数收敛，且其和\\(s\\leq u_1\\)，其余项\\(r_n\\)的绝对值小于等于\\(u_{n+1}\\)\n绝对收敛与条件收敛 对于级数\\(\\sum^{\\infty}_{n=1}u_n\\)，若\\(\\sum^{\\infty}_{n=1}|u_n|\\)收敛，那么称\\(\\sum^{\\infty}_{n=1}u_n\\)绝对收敛；如果\\(\\sum^{\\infty}_{n=1}u_n\\)收敛，而\\(\\sum^{\\infty}_{n=1}|u_n|\\)发散，则成\\(\\sum^{\\infty}_{n=1}u_n\\)条件收敛。\n定理8 如果级数\\(\\sum^{\\infty}_{n=1}u_n\\)绝对收敛，那么\\(\\sum^{\\infty}_{n=1}u_n\\)必定收敛。\n绝对收敛级数的性质 定理9 绝对收敛级数经改变项的位置后构成的级数也收敛，且与原级数有相同的和.\n定理10 （绝对收敛级数的乘法） 设\\(\\sum^{\\infty}_{n=1}u_n\\)和\\(\\sum^{\\infty}_{n=1}v_n\\)都是绝对收敛，其和分别为\\(s,\\sigma\\)，则它们的柯西乘积\n\\[u_1v_1+(u_1v_2+u_2v_1)+\\dots+(u_1v_n+u_2v_{n-1}+\\dots+u_nv_1)+\\cdots \\]\n也是绝对收敛的，且其和为\\(s\\sigma\\)\n幂级数 收敛域：开区间；收敛区间：要判断边界点\n定理1（阿贝尔定理) 如果级数\\(\\sum^{\\infty}_{n=0}a_nx^n\\)当\\(x=x_0\\neq0\\)时收敛，那么适合不等式\\(|x|\u003c|x_0|\\)的一切\\(x\\)使这幂级数绝对收敛，反之，如果级数\\(\\sum^{\\infty}_{n=0}a_nx^n\\)当\\(x=x_0\\neq0\\)当\\(x=x_0\\)时发散，那么适合不等式\\(|x|\u003e|x_0|\\)的一切\\(x\\)使这幂级数发散.\n推论 如果幂级数\\(\\sum^{\\infty}_{n=0}a_nx^n\\)不仅在\\(x=0\\)一点收敛，也不是在整个数轴上都收敛，那么必有一个确定的正数\\(R\\)存在，使得\n当\\(|x|\u003c R\\)时，幂级数绝对收敛\n当\\(|x|\u003eR\\)时，幂级数发散\n当\\(|x|=R\\)时，幂级数可能收敛也可能发散，如果收敛可能是绝对或条件收敛。\n正数\\(R\\)通常叫做收敛半径。\n定理2 如果\n\\[\\lim\\limits_{n\\to\\infty}\\left|\\frac{a_{n+1}}{a_n}\\right|=\\rho \\]\n其中\\(a_n,a_{n+1}\\)是幂级数\\(\\sum^{\\infty}_{n=0}a_nx^n\\)的相邻两项的系数，那么这幂级数的收敛半径\n\\[R=\\left\\{\\begin{matrix} \\frac{1}{\\rho}, \\rho\\ne0\\\\ +\\infty, \\rho=0 \\\\ 0, \\rho=+\\infty \\end{matrix}\\right. \\]\n注意如果级数的项中为\\(x^{2n}\\)等不能化为\\(x^n\\)的，不能用这个定理，只能用比值审敛法等通用手段。\n幂级数的运算 设\\(\\sum^{\\infty}_{n=0}a_nx^n\\)和\\(\\sum^{\\infty}_{n=0}b_nx^n\\)分别在区间\\((-R,R),(-R',R')\\)内收敛，则对于这两个幂级数，\n\\(\\sum^{\\infty}_{n=0}a_nx^n\\pm\\sum^{\\infty}_{n=0}b_nx^n=\\sum^{\\infty}_{n=0}(a_n\\pm b_n)x^n\\)在\\((-R,R),(-R',R')\\)中较小的区间内成立. \\(\\sum^{\\infty}_{n=0}a_nx^n\\sum^{\\infty}_{n=0}b_nx^n=a_0b_0+(a_0b_1+a_1b_0)x+\\dots+(a_0b_n+a_1b_{n-1}+\\dots+a_nb_0)x^n+\\cdots\\)，\\((-R,R),(-R',R')\\)中较小的区间内成立. \\(\\frac{\\sum^{\\infty}_{n=0}a_nx^n}{\\sum^{\\infty}_{n=0}b_nx^n}=\\sum^{\\infty}_{n=0}c_nx^n\\)，假设\\(b_0\\ne0\\)，\\(c\\)可以由下式求出 \\[a_0=b_0c_0\\\\ a_1=b_1c_0+b_0c_1\\\\ a_2=b_2c_0+b_1c_1+b_0c_2\\\\ \\cdots \\]\n幂级数\\(\\sum^{\\infty}_{n=0}c_nx^n\\)的收敛区间可能比原来两级数的收敛区间小得多。\n幂级数的和函数的性质\n性质1 幂级数\\(\\sum^{\\infty}_{n=0}a_nx^n\\)的和函数\\(s(x)\\)在其收敛域\\(I\\)上连续\n性质2 幂级数\\(\\sum^{\\infty}_{n=0}a_nx^n\\)的和函数\\(s(x)\\)在其收敛域\\(I\\)上可积，并有逐项积分公式\n\\[\\int_0^xs(x)dt=\\int_0^x[\\sum^{\\infty}_{n=0}a_nt^n]dt=\\sum^{\\infty}_{n=0}\\int_0^xa_nt^ndt=\\sum^{\\infty}_{n=0}\\frac{a_n}{n+1}x^{n+1}(x\\in I), \\]\n逐项积分后所得到的幂级数和原级数有相同的收敛半径。\n性质3 幂级数\\(\\sum^{\\infty}_{n=0}a_nx^n\\)的和函数\\(s(x)\\)在其收敛域\\(I\\)上可导，且有逐项求导公式\n\\[s'(x)=(\\sum^{\\infty}_{n=0}a_nx^n)'=\\sum^{\\infty}_{n=0}(a_nx^n)'=\\sum^{\\infty}_{n=1}na_nx^{n-1} \\]\n逐项求导后所得到的幂级数和原级数有相同的收敛半径.\n反复应用上述结论可得：\\(s(x)\\)在其收敛区间\\((-R,R)\\)内具有任意阶导数。\n函数展开成幂级数 泰勒级数和麦克劳林级数不再重复，见上册整理。\n\\(f(x)\\)能在某个邻域展开成泰勒级数的充要条件是\n\\[\\lim\\limits_{n\\to\\infty}R_n(x)=0, x\\in U(x_0) \\]\n除了直接展开外，通常也会有间接展开的办法。即通过四则运算、求导、积分、变量替换等等运算转化为一些常见的函数，再代入这些常见函数的展开式。\n下面给出一些常见函数的展开式\n\\[\\frac{1}{1-x}=\\sum_{n=0}^{\\infty}x^n,x\\in(-1,1) \\]\n\\[\\frac{1}{1+x}=\\sum_{n=0}^{\\infty}(-1)^nx^n,x\\in(-1,1) \\]\n\\[e^x=\\sum_{n=0}^{\\infty}\\frac{x^n}{n!},x\\in(-\\infty,\\infty) \\]\n\\[sinx=\\sum_{n=0}^{\\infty}\\frac{(-1)^n}{(2n+1)!}x^{2n+1},x\\in(-\\infty,\\infty) \\]\n\\[cosx=\\sum_{n=0}^{\\infty}\\frac{(-1)^n}{(2n)!}x^{2n},x\\in(-\\infty,\\infty) \\]\n\\[ln(1+x)=\\sum_{n=0}^{\\infty}\\frac{(-1)^n}{n+1}x^{n+1}= \\sum_{n=1}^{\\infty}\\frac{(-1)^{n-1}}{n}x^{n},x\\in(-1,1] \\]\n\\[(1+x)^m=1+mx+\\frac{m(m-1)}{2!}x^2+\\cdots+\\frac{m(m-1)\\cdots(m-n+1)}{n!}x^n+\\cdots \\]\n傅里叶级数 一个定义在\\((-\\infty,\\infty)\\)上周期为\\(2\\pi\\)的函数\\(f(x)\\)，如果它在一个周期上可积，那么一定可以做出\\(f(x)\\)的傅里叶级数\n\\[f(x) = \\frac{a_0}{2}+\\sum_{n=1}^{\\infty}(a_ncosnx+b_nsinnx) \\]\n其中\n\\[a_n=\\frac{1}{\\pi}\\int^\\pi_{-\\pi}f(x)\\cos nxdx,(n=0,1,2,3,\\cdots) \\]\n\\[b_n=\\frac{1}{\\pi}\\int^\\pi_{-\\pi}f(x)\\sin nxdx,(n=1,2,3,\\cdots) \\]\n定理 设\\(f(x)\\)是周期为\\(2\\pi\\)的周期函数，如果它满足：\n在一个周期内连续或只有有限个第一类间断点 在一个周期内至多只有有限个极值点 那么\\(f(x)\\)的傅立叶级数收敛，并且\n当\\(x\\)是\\(f(x)\\)的连续点时，级数收敛于\\(f(x)\\);\n当\\(x\\)是\\(f(x)\\)的间断点时，级数收敛于\\(\\frac{1}{2}[f(x^-)+f(x^+)]\\)\n如果函数只在\\([-\\pi,\\pi]\\)上有定义，可以使用周期延拓来展开成傅里叶级数。\n正弦级数和余弦级数 当\\(f(x)\\)为奇函数时，可以展开为正弦级数\n\\[\\sum_{n=1}^\\infty b_n\\sin nx \\]\n当\\(f(x)\\)为偶函数时，可以展开为余弦函数\n\\[\\frac{a_0}{2}+\\sum_{n=1}^\\infty a_n\\cos nx \\]\n一般周期的傅里叶级数 周期为\\(2l\\)\n\\[f(x)=\\frac{a_0}{2}+\\sum^\\infty_{n=1}\\left(a_ncos\\frac{n\\pi x}{l}+b_nsin\\frac{n\\pi x}{l}\\right)(x\\in C) \\]\n其中\n\\[a_n=\\frac{1}{l}\\int_{-l}^lf(x)cos\\frac{n\\pi x}{l}dx\\quad (n=0,1,2,\\cdots) \\]\n\\[b_n=\\frac{1}{l}\\int_{-l}^lf(x)sin\\frac{n\\pi x}{l}dx\\quad (n=1,2,3,\\cdots) \\]\n\\[C=\\left\\{x\\left|f(x)=\\frac{1}{2}[f(x^-) +f(x^+)]\\right. \\right\\} \\]\n","date":"2022-05-25T21:43:40+08:00","image":"https://kegalas.top/inferior/%E6%88%91%E7%9A%84%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E4%B8%8B%E5%86%8C%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/8-51_hu1c49316b400cd781c785bbdbc8d18c16_11689_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E6%88%91%E7%9A%84%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E4%B8%8B%E5%86%8C%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/","title":"我的高等数学下册资料整理"},{"content":"第一部分 第一篇 协和和弦——三和弦 第一章 大调式三和弦 自然大调的七个三和弦中，I、IV、V是大三和弦，II、III、VI是小三和弦，VII是减三和弦。\nI级上的三和弦称之为主和弦，IV上的为下属和弦，V上的称为属和弦。\n按功能分，主和弦组：I、VI；属和弦组：V、III；下属和弦组：IV、II；\n第二章 大调式三和弦的连接 对于初学者来说，根据低音写出另外三个声部的音，应当重复根音。\n除相邻的音级上建立的三和弦，任意两个三和弦至少有一个共同音。\n对于初学者，链接两个三和弦应当将共同音保持，不是共同音的音按照最近的方式排列；\n显然旋律音的位置受到共同音的影响，但是根音可以较为自由的上行或下行，如果一定要在六度跳进或是三度进行中做出选择，那后者应该更好。\n第三章 无共同音的三和弦连接 不允许有两个声部间出现平行五度和平行八度。按照之前的共同音保持法链接，显然不会出现平行五八。但如果两个和弦间没有共同音，则上方声部的音应当和根音做反向进行。并且上方声部的两个和弦之间，音的排列顺序不能相同。\n第四章 打破三和弦连接规则 打破规则的原因：如果坚持规则可能会导致某一声部的音太高。\n要注意的有：\n两个三和弦，上方声部连接时不能保持同样的音的排列顺序，否则必然出现平行五八。\n最上方声部不能跳进超过四度。\n低声部和高声部要反向进行，防止出现隐伏五八度。当两个声部通向进行到五度或八度，则会构成隐伏五八度。（注意高声部内部也不要出现隐伏五度）。\n不允许违背规则的情况：\n属和弦进行到主和弦时，如果属和弦的三音即导音位于最高声部，必须上行到主音。如果导音在内声部，可以下行三度进行。\n主和弦到下属和弦时，主和弦的三音类似导音，处理方式同上。\n第五章 和声模进 模进动机保持相同的声部排列位置。\nVII是减三和弦，使用的时候要特别谨慎，但在和弦模进中，它是允许的，因为可以作为动机重复和模进进行。\n当然减三和弦还可以作为两个和弦的经过和弦。这种连接必须同一声部保留共同音。\n第六章 小调式和声 小调式和声建立在和声小调之上。除七音升高半音外，其他与平行大调音阶上的音相同。\n和声小调上的三和弦：小三和弦：I、IV；大三和弦V、VI；减三和弦：II、VII；增三和弦：III。\n和声小调的和弦连接也应当遵从前面的规则。\n不协和和弦（除小三和大三）要有预备，可以与两个相邻的三和弦作正确连接，或是作为一个动机内的和弦。\n不协和和弦连接具体如下：\nVII级通常连到V级，而不连到II和IV级，因为此时会出现增二度进行，及其不悦耳。\nII级可以与IV、V、VI连接，但要避免隐伏五八、增二度进行；减三和弦与属三和弦连接时，上方三声部与低声部作反向进行就不会出现增二度。\nIII级与I、V、VI连接不会有问题。\n任何时候都要避免使用增二度。因此，导音（属和弦三音）要上行解决到VI级三和弦时，VI级三和弦应当重复三音。当VI进行到V时（比较少见），也应当重复VI的三音。\n第七章 密集排列与开放排列 声部之间的音排列比较密集，成为密集排列。否则称为开放排列。\n将密集排列改写为开放排列时，注意要一个声部整体移动八度，不能出现声部更换，也不能出现声部超越。\n第八章 三和弦的转位 将根音转移到上方其他声部，低声部不是根音的三和弦，被称为和弦的转位。\n第一转位，即最低声部为三音，被称为三六和弦，简称六和弦。\n第二转位，即最低声部为五音，被称为四六和弦。\n原位和弦因为具有纯五度，音响协和程度要高于两个转位和弦。\n和弦通常重复根音或者五音，重复三音不够自然，仅用在一些特殊位置（如可以获得更好的声部进行）。\n我们常常会碰到连续的六和弦级进进行。这种情况最好让两个声部与低音作同向进行，另一声部作反向进行。如果低音上行，首先重复五音；如果低音下行，首先重复根音。\n如果是属六和弦进行到主和弦，那么属六和弦的三音不能重复，因为其是导音。\n第九章 减三和弦与增三和弦的转位 减三和弦的第一转为接近协和和弦，所以用的比原位多。\n减六和弦与其他和弦的连接分为两种情况\n在主和弦之前。减三和弦的根音，即导音，必须上行解决，因为它不能重复。最好重复五音，偶尔可以重复三音。由于导音在任何时候都必须解决到主音，因此减三和弦中的五音位于根音上方时，不能上行，否则必定会出现禁止进行（平行五度）(所以必须让在根音上方的五音下行)。因此，我们必须避免减六和弦中的两个五音都位于根音上方(这样会导致两个五音之后一个上行一个下行)。\n除主和弦外的其他和弦之前。大多数重复根音（就像其他六和弦一样），因为这里根音不作为导音。\n小调中II级上的减六和弦也遵从这些规则。\n第二篇 不协和和弦——七和弦和九和弦 七和弦和九和弦都不是独立的和弦，都需要有准备，并要合理地进行到后面的和弦。不协和和弦进行到协和和弦，被称为“解决”。每一个七和弦都必须要解决到三和弦上。\n第十章 属七和弦 所有七和弦中，最重要，最常用的是V级上的七和弦，即属七和弦。属七和弦解决到主和弦。\n属七和弦的解决方式：七音级进下行解决到主和弦的三音。五音级进上行或下行解决到主和弦的三音或根音，更多解决到根音。三音（即导音）级进上行到主音，根音四度上行或五度下行到主和弦的根音。\n属七和弦的解决会产生缺五音的不完全主和弦。\n停更 ","date":"2021-12-31T22:44:43+08:00","permalink":"https://kegalas.top/inferior/%E5%AE%9E%E7%94%A8%E5%92%8C%E5%A3%B0%E5%AD%A6%E6%8C%87%E5%8D%97%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","title":"《实用和声学指南》读书笔记"},{"content":"函数与极限 等价无穷小 当\\(x\\to 0\\)时，有\n\\[sinx\\sim x\\qquad tanx\\sim x\\qquad ln(1+x)\\sim x\\qquad e^x-1\\sim x \\]\n\\[arcsinx\\sim x\\qquad arctanx\\sim x\\qquad log_a(1+x)\\sim \\frac{x}{lna} \\]\n\\[x-ln(1+x)\\sim \\frac{1}{2}x^2\\qquad 1-cosx\\sim\\frac{1}{2}x^2\\qquad ln(x+\\sqrt{1+x^2})\\sim x \\]\n\\[x-sinx\\sim \\frac{1}{6}x^3\\qquad tanx-x\\sim \\frac{1}{3}x^3\\qquad (1+x)^a-1\\sim ax \\]\n\\[arcsinx-x\\sim \\frac{1}{6}x^3\\qquad x-arctanx\\sim\\frac{1}{3}x^3\\qquad tanx-sinx\\sim\\frac{1}{2}x^3 \\]\n两个重要极限 \\[\\lim_{x\\to 0}\\frac{sinx}{x}=1 \\]\n\\[\\lim_{x\\to \\infty}(1+\\frac1x)^x=e \\]\n间断点的分类 第一类间断点 如果\\(x_0\\)是函数的间断点，且左极限\\(f(x_0^-)\\)及右极限\\(f(x_0^+)\\)都存在。\n若左极限和右极限相等，但不等于该点函数值或函数在该点无定义，则称为可去间断点。\n若左极限右极限不相等，则称为跳跃间断点。\n第二类间断点 不是第一类间断点的任何间断点称之为第二类间断点，包含震荡间断点，无穷间断点等。\n部分函数及其图像 双曲函数 \\[sh\\ x=\\frac{e^x-e^{-x}}{2}\\qquad ch\\ x=\\frac{e^x+e^{-x}}{2}\\qquad th\\ x=\\frac{sh\\ x}{ch\\ x}=\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\]\n函数图像如下\n其常用公式如下：\n\\[sh(x+y)=sh\\ xch\\ x+ch\\ xsh\\ y \\]\n\\[sh(x-y)=sh\\ xch\\ x-ch\\ xsh\\ y \\]\n\\[ch(x+y)=ch\\ xch\\ x+sh\\ xsh\\ y \\]\n\\[ch(x-y)=ch\\ xch\\ x-sh\\ xsh\\ y \\]\n\\[ch^2x-sh^2x=1\\qquad sh\\ 2x=2sh\\ xch\\ x\\qquad ch\\ 2x=ch^2x+sh^2x \\]\n反双曲函数如下\n\\[arsh\\ x=ln(x+\\sqrt{x^2+1}) \\]\n\\[arch\\ x=ln(x+\\sqrt{x^2-1}) \\]\n\\[arth\\ x=\\frac{1}{2}ln\\frac{1+x}{1-x} \\]\n部分三角函数和反三角函数 \\(cot\\ x,sec\\ x,csc\\ x\\)的函数图像如下\n反三角函数图像如下\n三角函数公式 和差化积 \\[sin\\alpha+sin\\beta=2sin\\dfrac{\\alpha+\\beta}{2}\\cdot cos\\dfrac{\\alpha-\\beta}{2} \\]\n​\n\\[sin\\alpha-sin\\beta=2cos\\frac{\\alpha+\\beta}{2}\\cdot sin\\frac{\\alpha-\\beta}{2} \\]\n​\n\\[cos\\alpha+cos\\beta=2cos\\frac{\\alpha+\\beta}{2}\\cdot cos\\frac{\\alpha-\\beta}{2} \\]\n​\n\\[cos\\alpha-cos\\beta=-2sin\\frac{\\alpha+\\beta}{2}\\cdot sin\\frac{\\alpha-\\beta}{2} \\]\n积化和差 \\[sin\\alpha cos\\beta=\\frac{1}{2}\\left[sin(\\alpha+\\beta)+sin(\\alpha-\\beta)\\right] \\]\n​\n\\[cos\\alpha sin\\beta=\\frac{1}{2}\\left[sin(\\alpha+\\beta)-sin(\\alpha-\\beta)\\right] \\]\n​\n\\[cos\\alpha cos\\beta=\\frac{1}{2}\\left[cos(\\alpha+\\beta)+cos(\\alpha-\\beta)\\right] \\]\n​\n\\[sin\\alpha sin\\beta=-\\frac{1}{2}\\left[cos(\\alpha+\\beta)-cos(\\alpha-\\beta)\\right] \\]\n半角公式 \\[sin\\frac{\\theta}{2}=\\pm \\sqrt{\\frac{1-cos\\alpha}{2}} \\]\n​\n\\[sin\\frac{\\theta}{2}=\\pm \\sqrt{\\frac{1+cos\\alpha}{2}} \\]\n​\n\\[tan\\frac{\\theta}{2}=\\pm \\sqrt{\\frac{1-cos\\alpha}{1+cos\\alpha}}=\\frac{sin\\alpha}{1+cos\\alpha}=\\frac{1-cos\\alpha}{sin\\alpha} \\]\n辅助角公式 \\[asin\\theta\\pm bcos\\theta=\\sqrt{a^2+b^2}sin(\\theta\\pm\\varphi),\\quad tan\\varphi=\\frac{b}{a} \\]\n\\(sin\\ x\\)和\\(cos\\ x\\)的\\(tan\\ \\frac x2\\)有理式表示 \\[sin\\ x=\\frac{2tan\\frac x2}{1+tan^2\\frac x2} \\]\n\\[cos\\ x=\\frac{1-tan^2\\frac x2}{1+tan^2\\frac x2} \\]\n导数与微分 反函数求导 如果函数\\(x=f(y)\\)在区间\\(I_y\\)内单调、可导且\\(f'(y)\\ne 0\\)，那么它的反函数\\(y=f^{-1}(x)\\)在区间\\(I_x = \\\\{ x | x = f(y) , y\\in I_y \\\\}\\)内也可导，且\n\\[[f^{-1}(x)]'=\\frac{1}{f'(y)}\\quad or \\quad \\frac{dy}{dx}=\\frac{1}{\\frac {dx}{dy}} \\]\n部分常用导数 \\[(tan\\ x)'=sec^2x\\qquad (cot\\ x)'=-csc^2x \\]\n\\[(sec\\ x)'=sec\\ xtan\\ x\\qquad (csc\\ x)'=-csc\\ xcot\\ x \\]\n\\[(a^x)'=a^xlna(a\u003e0,a\\ne 1)\\qquad (log_ax)'=\\frac{1}{xlna} \\]\n\\[(arcsin\\ x)'=\\frac{1}{\\sqrt{1-x^2}}\\qquad (arccosx)'=-\\frac{1} {\\sqrt{1-x^2}} \\]\n\\[(arctan\\ x)'=\\frac{1}{1+x^2}\\qquad (arccotx)'=-\\frac{1}{1+x^2} \\]\n\\[(sh\\ x)'=ch\\ x,\\ (ch\\ x)'=sh\\ x,\\ (th\\ x)'=\\frac{1}{ch^2x} \\]\n\\[(arsh\\ x)'=\\frac{1}{\\sqrt{x^2+1}},\\ (arch\\ x)'=\\frac{1}{\\sqrt{x^2-1}}, \\ (arth\\ x)'=\\frac{1}{1-x^2} \\]\n参数方程求导 对如下参数方程\n\\[x = \\varphi (t),\\ y = \\psi (t) \\]\n求导得\n\\[\\frac{dy}{dx}=\\frac{dy}{dt}\\cdot \\frac{1}{\\frac{dx}{dt}}= \\frac{\\psi'(t)}{\\varphi'(t)} \\]\n中值定理 罗尔定理 如果函数\\(f(x)\\)满足\n（1）在闭区间\\([a,b]\\)上连续\n（2）在开区间\\((a,b)\\)内可导\n（3）在区间端点处的函数值相等，即\\(f(a)=f(b)\\),\n那么在\\((a,b)\\)内至少有一点\\(\\xi\\ (a\u003c\\xi\u003c b)\\)，使得\\(f'(\\xi)=0.\\)\n拉格朗日中值定理 如果函数\\(f(x)\\)满足\n（1）在闭区间\\([a,b]\\)上连续；\n（2）在开区间\\((a,b)\\)内可导，\n那么在\\((a,b)\\)内至少有一点\\(\\xi (a\u003c\\xi\u003c b)\\)，使等式\n\\[f(b)-f(a)=f'(\\xi)(b-a) \\]\n成立\n柯西中值定理 如果函数\\(f(x)\\)及\\(F(x)\\)满足\n（1）在闭区间\\([a,b]\\)上连续\n（2）在开区间\\((a,b)\\)内可导\n（3）对任一\\(x\\in(a,b),F'(x)\\ne0\\)\n那么在\\((a,b)\\)内至少有一点\\(\\xi\\)，使等式\n\\[\\frac{f(b)-f(a)}{F(b)-F(a)}=\\frac{f'(x)}{F'(x)} \\]\n成立\n泰勒公式 在\\(x_0\\)处展开如下\n\\[f(x)=f(x_0)+f'(x_0)(x-x_0)+\\frac{f''(x_0)}{2!}(x-x_0)^2+\\dots+ \\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n+R_n(x) \\]\n皮亚诺余项 \\[R_n(x)=o((x-x_0)^n) \\]\n拉格朗日余项 \\[R_n(x)=\\frac{f^{(n+1)}(\\xi)}{(n+1)!}(x-x_0)^{(n+1)} \\]\n这里\\(\\xi\\)是\\(x_0\\)与\\(x\\)之间的某个值\n曲率 弧微分公式 \\[ds=\\sqrt{1+y'^2}dx \\]\n曲率表达式 对于\\(y=f(x)\\)，曲率\\(K\\)为\n\\[K=\\frac{|y''|}{(1+y'^2)^{3/2}} \\]\n对于\\(x = \\varphi (t),y = \\psi (t)\\)，有\n\\[K=\\frac{|\\varphi'(t)\\psi''(t)-\\varphi''(t)\\psi'(t)|}{[\\varphi'^2(t)+ \\psi'^2(t)]^{3/2}} \\]\n曲率圆与曲率半径 曲率半径与曲率的关系\n\\[\\rho = \\frac{1}{K},\\ K=\\frac{1}{\\rho} \\]\n曲率中心\\(D(\\alpha,\\beta)\\)\n\\[\\alpha = x-\\frac{y'(1+y'^2)}{y''},\\quad \\beta = y+\\frac{1+y'^2}{y''} \\]\n不定积分 常用积分表 \\[\\int\\frac{dx}{1+x^2}=arctan\\ x+C,\\quad \\int\\frac{dx}{\\sqrt{1-x^2}} =arcsin\\ x+C \\]\n\\[\\int\\frac{dx}{cos^2x}=\\int{sec^2x}dx=tan\\ x+C,\\quad\\int\\frac{dx}{sin^2x}= \\int csc^2xdx=-cot\\ x+C \\]\n\\[\\int sec\\ xtan\\ xdx=sec\\ x+C,\\quad \\int csc\\ xcot\\ xdx=-csc\\ x+C \\]\n\\[\\int sh\\ xdx=ch\\ x+C,\\quad \\int ch\\ xdx=sh\\ x+C \\]\n\\[\\int tan\\ xdx=-ln|cos\\ x|+C,\\quad \\int cot\\ xdx=ln|sin\\ x|+C \\]\n\\[\\int sec\\ xdx=ln|sec\\ x+tan\\ x|+C,\\quad \\int csc\\ xdx=ln|csc\\ x-cot\\ x|+C \\]\n\\[\\int \\frac{dx}{a^2+x^2}=\\frac{1}{a}arctan\\frac{x}{a}+C,\\quad \\int \\frac{dx}{x^2-a^2}=\\frac{1}{2a}ln\\left |\\frac{x-a}{x+a}\\right |+C \\]\n\\[\\int \\frac{dx}{\\sqrt{a^2-x^2}}=arcsin\\frac xa+C,\\quad \\int \\frac{dx}{\\sqrt{x^2+a^2}}=ln(x+\\sqrt{x^2+a^2})+C \\]\n\\[\\int \\frac{dx}{\\sqrt{x^2-a^2}}=ln|x+\\sqrt{x^2-a^2}|+C \\]\n换元积分法 第一类换元法 设\\(f(u)\\)具有原函数，\\(u=\\varphi(x)\\)可导，则有换元公式\n\\[\\int f[\\varphi(x)]\\varphi'(x)dx=\\left[\\int f(u)du \\right]_{u=\\varphi(x)} \\]\n设要求\\(\\int g(x)dx\\)，如果\\(g(x)\\)可以化为\\(g(x)=f[\\varphi(x)]\\varphi'(x)\\)的形式，那么\n\\[\\int g(x)dx= \\int f[\\varphi(x)]\\varphi'(x)dx=\\left[\\int f(u)du \\right]_{u=\\varphi(x)} \\]\n第二类换元法 设\\(x=\\psi(t)\\)是单调的可导函数，并且\\(\\psi'(t)\\ne 0\\).又设\\(f[\\psi(x)]\\psi'(x)dx\\)具有原函数 ，则有换元公式\n\\[\\int f(x)dx= \\left[\\int f[\\psi(t)]\\psi'(t)dt\\right]_{t=\\psi^{-1}(x)} \\]\n分部积分法 设函数\\(u=u(x)\\)及\\(v=v(x)\\)具有连续导数，则有\n\\[\\int uv'dx=uv-\\int u'vdx \\]\n定积分 积分上限的函数的导数 若\n\\[\\Phi(x)=\\int_{a}^{x}f(t)dt \\]\n则\n\\[\\Phi'(x)=f(x) \\]\n若\n\\[\\Phi(x)=\\int_{a}^{g(x)}f(t)dt \\]\n则\n\\[\\Phi'(x)=f(g(x))g'(x) \\]\n定积分在几何学上的应用 平面图形的面积 直角坐标 例如，以\\(x\\)为积分变量，求\\(f(x)\\)及直线\\(x=a\\), \\(x=b\\)与\\(x\\)轴围成的曲边梯形的面积\n\\[A=\\int_a^bf(x)dx \\]\n以y为积分变量，则求的是两直线、函数、与\\(y\\)轴围成的曲边梯形的面积\n极坐标 \\[dA=\\frac12(\\rho(\\theta))^2d\\theta \\]\n\\[A=\\int_\\alpha^\\beta\\frac12[\\rho(\\theta)]^2d\\theta \\]\n体积 旋转体的体积 \\[V=\\int_a^b\\pi[f(x)]^2dx \\]\n平行截面面积为已知的立体的体积 \\[V=\\int_a^bA(x)dx \\]\n平面曲线的弧长 参数方程 \\(x=\\varphi(t),\\quad y=\\psi(t).\\quad(\\alpha\\leq t\\leq\\beta)\\)\n\\[s=\\int_\\alpha^\\beta\\sqrt{\\varphi'^2(t)+\\psi'^2(t)}dt \\]\n直角坐标 \\[s=\\int_a^b\\sqrt{1+y'^2}dx \\]\n极坐标 \\[s=\\int_\\alpha^\\beta\\sqrt{\\rho^2(\\theta)+\\rho'^2(\\theta)}d\\theta \\]\n微分方程 齐次方程 如果一阶微分方程可化成\n\\[\\frac{dy}{dx}=\\varphi\\left(\\frac yx\\right) \\]\n的形式，那么就称这方程为齐次方程。在齐次方程中，引入新的未知函数\\(u=\\frac{y}{x}\\)，有\n\\[y=ux,\\ \\frac{dy}{dx}=u+x\\frac{du}{dx} \\]\n\\[u+x\\frac{du}{dx}=\\varphi(u) \\]\n用分离变量的办法求出关于\\(u\\)的积分，最后再以\\(\\frac yx\\)代替\\(u\\).\n一阶线性微分方程 方法一 方程\n\\[\\frac{dy}{dx}+P(x)y=Q(x) \\]\n的通解为\n\\[y=Ce^{-\\int P(x)dx}+e^{-\\int P(x)dx}\\int Q(x)e^{\\int P(x)dx}dx \\]\n方法二 先求对应齐次方程\n\\[\\frac{dy}{dx}+P(x)y=0 \\]\n的解，得到\n\\[y=Ce^{-\\int P(x)dx} \\]\n将\\(C\\)替换为\\(u\\)，再对上解求导得\\(\\frac{dy}{dx}\\)，将其代入原非齐次方程，解出\\(u\\)，则\n\\[y=ue^{-\\int P(x)dx} \\]\n可降阶的高阶微分方程 \\(y''=f(x,y')\\)型的微分方程\n设\\(y'=p\\)则\\(y''=\\frac{dp}{dx}=p'\\)，代入原方程中求解\\(p\\)，再求解\\(y\\)\n\\(y''=f(y,y')\\)型的微分方程\n设\\(y'=p\\)\n\\[y''=\\frac{dp}{dx}=\\frac{dp}{dy}\\cdot\\frac{dy}{dx}=p\\frac{dp}{dy} \\]\n代入原方程中求解\\(p\\)，再求解\\(y\\)\n高阶线性微分方程 定理1 如果函数\\(y_1(x)\\)与\\(y_2(x)\\)是方程\n\\[y''+P(x)y'+Q(x)y=0 \\]\n的两个特解，那么\n\\[y=C_1y_1(x)+C_2y_2(x) \\]\n也是方程的解\n定理2 如果函数\\(y_1(x)\\)与\\(y_2(x)\\)是方程的两个线性无关的特解，那么\n\\[y=C_1y_1(x)+C_2y_2(x) \\]\n就是 方程的通解\n定理3 设\\(y^*(x)\\)是方程\n\\[y''+P(x)y'+Q(x)y=f(x) \\]\n的一个特解，\\(Y(x)\\)是该方程对应的齐次方程的通解，则\n\\[y=Y(x)+y^*(x) \\]\n是该非齐次方程的通解\n定理4 设定理三种的非齐次线性方程的右端\\(f(x)\\)是两个函数之和，即\n\\[y''+P(x)y'+Q(x)y=f_1(x)+f_2(x) \\]\n而\\(y_1^* (x)\\)与\\(y_2^*(x)\\)分别是方程\n\\[y''+P(x)y'+Q(x)y=f_1(x) \\]\n与\n\\[y''+P(x)y'+Q(x)y=f_2(x) \\]\n的特解，则\\(y_1^*(x)+y_2^ *(x)\\)就是原方程的特解\n常系数齐次线性微分方程 二阶形式如下 \\[y''+py'+qy=0 \\]\n先求解如下方程\n\\[r^2+pr+q=0 \\]\n分为三种情况\n有两个不等实根\\(r_1,r_2\\)\n则通解为\n\\[y=C_1e^{r_1x}+C_2e^{r_2x} \\]\n有两个相等实根\\(r_{1,2}\\)\n则通解为\n\\[y=(C_1+C_2x)e^{r_1x} \\]\n有一对共轭复根\n\\[r_1=\\alpha+\\beta i,\\quad r_2=\\alpha-\\beta i \\]\n\\[\\alpha=-\\frac{p}{2},\\quad \\beta=\\frac{\\sqrt{4q-p^2}}{2} \\]\n则通解为\n\\[y=e^{\\alpha x}(C_1cos\\ \\beta x+C_2sin\\ \\beta x) \\]\nn阶形式如下 \\[y^{(n)}+p_1y^{(n-1)}+p_2y^{(n-2)}+\\dots+p_{n-1}y'+p_ny=0 \\]\n其中\\(p_1\\dots p_n\\)都是常数。\n其特征方程如下\n\\[r^n+p_1r^{n-1}+\\dots+p_{n-1}r+p_n=0 \\]\n分四种情况\n单实根\\(r\\)，给出一项：\\(Ce^{rx}\\)\n一对单复根\\(r_{1,2}=\\alpha\\pm\\beta i\\)，给出两项：\\(e^{\\alpha x}(C_1cos\\beta x+C_2sin\\beta x)\\)\nk重实根r，给出\\(k\\)项：\\(e^{rx}(C_1+C_2x+\\dots+C_kx^{k-1})\\)\n一对k重复根\\(r_{1,2}=\\alpha\\pm\\beta i\\)，给出\\(2k\\)项：\\(e^{\\alpha x}[(C_1+C_2x+\\dots+C_kx^{k-1})cos\\beta x+(D_1+D_2x+\\dots+D_kx^{k-1})sin\\beta x]\\)\n常系数非齐次线性微分方程 二阶常系数非齐次线性微分方程的一般形式是\n\\[y''+py'+qy=f(x) \\]\n求其通解只用求该方程的一个特解和上一节学到的求其对应齐次方程的通解，高数上册只介绍了\\(f(x)\\)的两种形式\n\\(f(x)=e^{\\lambda x}P_m(x)\\)，其中\\(\\lambda\\)是常数，\\(P_m(x)\\)是\\(x\\)的一个\\(m\\)次多项式\n\\[P_m(x)=a_0x^m+a_1x^{m-1}+\\dots+a_{m-1}x+a_{m} \\]\n\\(f(x)=e^{\\lambda x}[P_l(x)cos\\omega x+Q_n(x)sin\\omega x]\\)，其中\\(\\lambda,\\omega\\)是常数，\\(\\omega\\ne0\\)，\\(P_l(x),Q_n(x)\\)分别是\\(x\\)的\\(l\\)次、\\(n\\)次多项式，且仅有一个可为零.\n\\(f(x)=e^{\\lambda x}P_m(x)\\)型 \\[y^*=x^kR_m(x)e^{\\lambda x} \\]\n其中 \\(R_m(x)\\)是与\\(P_m(x)\\)同次的多项式，而\\(k\\)按\\(\\lambda\\)不是特征方程(即\\(r^2+pr+q=0\\))的根，是特征方程的单根或是特征方程的重根依次取值为0,1,2.\n其中\\(R_m(x)\\)中的每一个系数，应当代入原方程中进行计算。\n\\(f(x)=e^{\\lambda x}[P_l(x)cos\\omega x+Q_n(x)sin\\omega x]\\)型 \\[y^*=x^ke^{\\lambda x}[R^{(1)}_m(x)cos\\omega x+R^{(2)}_m(x)sin\\omega x] \\]\n其中\\(R^{(1)}_m(x)\\)、\\(R^{(2)}_m(x)\\)是\\(m\\)次多项式，\\(m=max\\\\{l,n\\\\}\\)，而\\(k\\)按\\(\\lambda+\\omega i\\)(或\\(\\lambda-\\omega i\\))不是特征方程的根、或是特征方程的单根依次取0或1\n","date":"2021-12-27T16:45:49+08:00","image":"https://kegalas.top/inferior/%E6%88%91%E7%9A%84%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E4%B8%8A%E5%86%8C%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/sec_huc4e91e2fedcb5d4446570ef1353d17fa_50913_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/inferior/%E6%88%91%E7%9A%84%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E4%B8%8A%E5%86%8C%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/","title":"我的高等数学上册资料整理"},{"content":"#include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cmath\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;map\u0026gt; #include \u0026lt;set\u0026gt; #include \u0026lt;queue\u0026gt; #include \u0026lt;stack\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;cstdint\u0026gt; #include \u0026lt;cstdio\u0026gt; #include \u0026lt;bitset\u0026gt; #include \u0026lt;deque\u0026gt; #include \u0026lt;regex\u0026gt; #include \u0026lt;list\u0026gt; #include \u0026lt;unordered_map\u0026gt; #include \u0026lt;unordered_set\u0026gt; #define debug(a) std::cout\u0026lt;\u0026lt;#a\u0026lt;\u0026lt;\u0026#34;=\u0026#34;\u0026lt;\u0026lt;(a)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34; #define rep(i,x,y) for(int i=(x);i\u0026lt;=(y);i++) #define rrep(i,x,y) for(int i=(x);i\u0026gt;=(y);i--) #define mms(x) memset((x), 0, sizeof(x)) #define pb push_back #define mkp std::make_pair #define fi first #define se second using LL = long long; using ULL = unsigned long long; using DB = double; using LD = long double; using ui = unsigned; using i128 = __int128; using pii = std::pair\u0026lt;int,int\u0026gt;; using pll = std::pair\u0026lt;LL,LL\u0026gt;; int const MAXN = 200005; int const INF = 0x7fffffff; DB const EPS = 1e-8; int const MOD = 998244353; DB const PI = acos(-1); int arr[MAXN]; void solve(){ int n; std::cin\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;arr[i]; } } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int T; std::cin\u0026gt;\u0026gt;T; //T=1; while(T--){ solve(); } return 0; } 字符串 KMP //复杂度n //kmp,luogu3375 std::vector\u0026lt;int\u0026gt; prefixFunc(std::string const \u0026amp; str){ //输入一个字符串，输出该字符串的前缀函数表 //前缀函数pi[i]是满足s[0...x-1]==s[i-x+1...i]的最大的x //如果输入不是字符串而是一个数组，也可以很方便的修改为vector int n = str.length(); std::vector\u0026lt;int\u0026gt; ans(n); for(int i=1, j=0;i\u0026lt;n;i++){ //ans[0]=0，因为只看真前缀和真后缀 while(j \u0026amp;\u0026amp; str[i]!=str[j]) j = ans[j-1]; if(str[i]==str[j]) j++; ans[i] = j; } return ans; } std::vector\u0026lt;int\u0026gt; KMP(std::string const \u0026amp; s, std::string const \u0026amp; p){ //输入主串和模式串，返回所有匹配的开始下标，下标从0开始 std::vector\u0026lt;int\u0026gt; vec; std::vector\u0026lt;int\u0026gt; pf = prefixFunc(p); int ns = s.size(), np = p.size(); for(int i=0, j=0;i\u0026lt;ns;i++){ while(j \u0026amp;\u0026amp; s[i]!=p[j]) j = pf[j-1]; if(s[i]==p[j]) j++; if(j==np){ vec.push_back(i-j+2); j = pf[j-1]; } } return vec; } //我们可以通过把模式串和主串拼在一起，p+#+s，然后求这个字符串的前缀函数表（#代表不在主串、模式串字符集内的一个符号），然后pi[i]如果等于模式串的长度，那么i是匹配模式串的子串的起点。 //关于最小循环结，设字符串下标从1开始，长度为n，则如果n%(n-pf[n])==0，则有循环节，并且长度为n-pf[n]（当然长度可以为n） 字典树(Trie) //复杂度 插入或查找一次 模板串长度 //luogu p8306 class Trie{ public: int nxt[MAXM][26]; int cnt; void init(){ for(int i=0;i\u0026lt;=cnt;i++) for(int j=0;j\u0026lt;26;j++) nxt[i][j] = 0; cnt = 0;//起始节点编号为0 } void insert(std::string const \u0026amp; s){ int cur = 0; for(auto c:s){ if(!nxt[cur][c-\u0026#39;a\u0026#39;]){ nxt[cur][c-\u0026#39;a\u0026#39;]=++cnt; } cur = nxt[cur][c-\u0026#39;a\u0026#39;]; } } bool find_prefix(std::string const \u0026amp; s){ int cur=0; for(auto c:s){ if (!nxt[cur][c-\u0026#39;a\u0026#39;]){ return false; } cur = nxt[cur][c-\u0026#39;a\u0026#39;]; } return true; } }; Trie trie; 字符串哈希 主要是用于判断两个字符串是否相等。通常我们的Hash函数会把字符串看成是某个进制下的自然数。把这个自然数对某个大质数取模得到Hash值。\n求Hash的复杂度是\\(O(n)\\)，如果我们要比较一大群字符串里有多少不同的，我们不应该两两比较，而要把它们的Hash全部记录下来，再去排序Hash、比较。\n这种哈希函数的性质为：\n设已知字符串\\(S\\)的Hash值为\\(H(S)\\)，那么添加一个字符\\(c\\)后的新字符串的Hash值为\\(H(S+c)=(H(S)*base+value[c])\\%MOD\\)。其中\\(value[c]\\)表示\\(c\\)代表的数值，如果用char类型直接把\\(c\\)转换为int或者ULL什么的就行了 已知\\(H(S)\\)和\\(H(S+T)\\)，则\\(H(T)=(H(S+T)-H(S)*base^{length(T)})\\%MOD\\)，直观理解的话，就是在\\(base\\)进制下，在S后面补\\(0\\)，把\\(S\\)左端和\\(S+T\\)左端对齐，相减得到\\(H(T)\\)。利用这个性质可以方便地先预处理字符串所有前缀的Hash，然后查询连续子串的Hash。 //自然溢出法，相当于对2^64取模的单哈希，是比较容易被特殊数据卡掉的 //luogu P3370 using ULL = unsigned long long; ULL H(std::string const \u0026amp; str){ ULL ret = 0; ULL const base = 131;//ascii也就128个字符，质数131作为底数足够 for(auto c:str){ ret = ret*base+(ULL)c; } return ret; } //双哈希法，两个字符串的两个哈希必须分别相同，才会被考虑为相同的字符串 //比起单哈希，更不容易被卡 //luogu P3370 ULL const MOD1 = 998244353; ULL const MOD2 = 1e9+7; ULL const base = 131; struct Data{//把字符串的两个哈希捆起来，便于排序比较等操作 ULL x,y; }; ULL H1(std::string const \u0026amp; str){ ULL ret = 0; for(auto c:str){ ret = (ret*base+(ULL)c)%MOD1; } return ret; } ULL H2(std::string const \u0026amp; str){ ULL ret = 0; for(auto c:str){ ret = (ret*base+(ULL)c)%MOD2; } return ret; } AC自动机 //复杂度 文本串长度+模板串长度之和 //AC自动机，luogu P3808 //AC自动机会把Trie修改掉，并不是插入时候的字典树了，实际上变成了一张图+fail指针。 //trie数组表示从当前状态添加一个字符后到达的状态，fail数组表示，目前为止匹配，但是添加下一个字符后不匹配了，跳转至最长的后缀状态（不包括添加的下一个字符）。可以反复跳转。 //注意，一个状态是可行状态，当且仅当它自己可行，或者fail指针指向的状态可行，或者fail[fail]可行，以此类推 class AC{ public: int trie[MAXN][26], total; int end[MAXN],fail[MAXN]; void init(int m){ for(int i=0;i\u0026lt;=m;i++){ end[i] = 0; fail[i] = 0; for(int j=0;j\u0026lt;26;j++) trie[i][j] = 0; } total = 0; } void insert(std::string const \u0026amp; str){ //插入模式串 int u = 0; for(auto c:str){ if(!trie[u][c-\u0026#39;a\u0026#39;]){ trie[u][c-\u0026#39;a\u0026#39;] = ++total; } u = trie[u][c-\u0026#39;a\u0026#39;]; } end[u]++; } void buildFail(){ //构建fail指针 std::queue\u0026lt;int\u0026gt; qu; for(int i=0;i\u0026lt;26;i++){ if(trie[0][i]) qu.push(trie[0][i]); } while(!qu.empty()){ int u = qu.front(); qu.pop(); for(int i=0;i\u0026lt;26;i++){ if(trie[u][i]){ fail[trie[u][i]] = trie[fail[u]][i];\tqu.push(trie[u][i]); } else{ trie[u][i] = trie[fail[u]][i]; } } } } int query(std::string const \u0026amp; str){ //查询主串str中出现了几个模式串 int u = 0, res = 0; for(auto c:str){ u = trie[u][c-\u0026#39;a\u0026#39;]; for(int j = u ; j \u0026amp;\u0026amp; end[j] != -1 ; j = fail[j]){ res += end[j]; end[j] = -1; } } return res; } }; 最小表示法 例如S = bcda, 则S的循环同构有cdab, dabc, abcd，其中字典序最小的是abcd，最小表示法就是求这个字典序最小的。当然题目里面可能是算数组里面字典序最小的。\n//最小表示法 //luogu P1368 //复杂度 O(n) int arr[MAXN]; int minStr(int n){//数组下标从0开始，共n个；返回最小表示的开始下标 int i=0, j=1, k=0; while(i\u0026lt;n \u0026amp;\u0026amp; j\u0026lt;n \u0026amp;\u0026amp; k\u0026lt;n){ if(arr[(i+k)%n]==arr[(j+k)%n]){ k++; } else if(arr[(i+k)%n]\u0026gt;arr[(j+k)%n]){//最大表示法时就把这一段和下一段换一下 i += k+1; k = 0; } else{ j += k+1; k = 0; } if(i==j) j++; } return std::min(i,j); } Manacher //manacher 算法 //luogu P3805 //复杂度O(n) std::vector\u0026lt;int\u0026gt; getD1(std::string const \u0026amp; str){ //返回字符串以某一位为中心的，最长的（奇数长度）回文子串的长度半径 //例如abcba中，d1[2] = 3 int n = str.size(); std::vector\u0026lt;int\u0026gt; d(n); for(int i=0,l=0,r=-1;i\u0026lt;n;i++){ int j = l+r-i; int dj = j\u0026gt;=0?d[j]:0; d[i] = std::max(std::min(dj,j-l+1),0); if(j-dj\u0026lt;l){ while(i-d[i]\u0026gt;=0 \u0026amp;\u0026amp; i+d[i]\u0026lt;n \u0026amp;\u0026amp; str[i-d[i]]==str[i+d[i]]) d[i]++; l = i-d[i]+1, r = i+d[i]-1; } } return d; } std::vector\u0026lt;int\u0026gt; getD2(std::string const \u0026amp; str){ //返回字符串以某一位的左边间隙为中心的，最长的（偶数长度）回文子串的长度半径 //例如abba中，d2[2] = 2 int n = str.size(); std::vector\u0026lt;int\u0026gt; d(n); for(int i=0,l=0,r=-1;i\u0026lt;n;i++){ int j = l+r-i; int dj = j\u0026gt;=0?d[j]:0; d[i] = std::max(std::min(dj,j-l),0); if(j-dj-1\u0026lt;l){ while(i-d[i]-1\u0026gt;=0 \u0026amp;\u0026amp; i+d[i]\u0026lt;n \u0026amp;\u0026amp; str[i-d[i]-1]==str[i+d[i]]) d[i]++; l = i-d[i], r = i+d[i]-1; } } return d; } Z函数 //Z函数，复杂度O(n) //luogu P5410 std::vector\u0026lt;int\u0026gt; zFunc(std::string const \u0026amp; str){ //求出一个字符串的z函数，即满足z[i]是s[0...x-1]==s[i...i+x-1]的最大的x，这个子串也叫做LCP //特别的z[0]=0，也有些题目是等于串长，需要自行调整 //kmp里面添加字符集外字符的操作在这里也可以用 int n = str.size(); std::vector\u0026lt;int\u0026gt; z(n); for(int i=1,l=0,r=0;i\u0026lt;n;i++){ if(z[i-l]\u0026lt;r-i+1) z[i] = z[i-l]; else{ z[i] = std::max(r-i+1,0); while(i+z[i]\u0026lt;n \u0026amp;\u0026amp; str[z[i]]==str[i+z[i]]) z[i]++; l = i, r = i + z[i] - 1; } } return z; } 后缀数组 首先是\\(O(n\\log^2n)\\)的，没有用到基数排序（因为我不排除会求某种只给出偏序关系的后缀数组）\n//求后缀数组，复杂度O(nlog^2n) //luogu p3809 int rk[MAXN\u0026lt;\u0026lt;1],sa[MAXN],tarr[MAXN\u0026lt;\u0026lt;1]; //rk[i]表示后缀i（从1开始，后缀i代表字符串从i开始到结束的子串）的排名，sa[i]表示所有后缀第i小的起点序号，排名和编号都从1开始 void getSA(std::string const \u0026amp; s){ int n = s.size(); if(n==1){ rk[1] = sa[1] = 1; return; } for(int i=1;i\u0026lt;=n;i++) sa[i] = i, rk[i] = s[i-1]; for(int w=1;w\u0026lt;n;w\u0026lt;\u0026lt;=1){ auto rp = [\u0026amp;](int x){return std::make_pair(rk[x],rk[x+w]);}; std::sort(sa+1,sa+n+1,[\u0026amp;](int x, int y){return rp(x)\u0026lt;rp(y);}); for(int i=1,p=0;i\u0026lt;=n;i++) tarr[sa[i]] = rp(sa[i-1])==rp(sa[i]) ? p:++p; std::copy(tarr+1,tarr+n+1,rk+1); } } 再给出\\(O(n\\log n)\\)的\n//求后缀数组，复杂度O(nlogn) //luogu p3809 int rk[MAXN\u0026lt;\u0026lt;1],sa[MAXN],tarr[MAXN\u0026lt;\u0026lt;1],cnt[MAXN],rkt[MAXN]; //rk[i]表示后缀i（从1开始，后缀i代表字符串从i开始到结束的子串）的排名，sa[i]表示所有后缀第i小的起点序号，排名和编号都从1开始 void getSA(std::string const \u0026amp; s){ int n = s.size(); if(n==1){ rk[1] = sa[1] = 1; return; } int m = 128; for(int i=1;i\u0026lt;=n;i++) ++cnt[rk[i]=s[i-1]]; for(int i=1;i\u0026lt;=m;i++) cnt[i] += cnt[i-1]; for(int i=n;i\u0026gt;=1;i--) sa[cnt[rk[i]]--] = i; for(int w=1;;w\u0026lt;\u0026lt;=1){ for(int i=n;i\u0026gt;n-w;i--) tarr[n-i+1] = i; for(int i=1,p=w;i\u0026lt;=n;i++) if(sa[i]\u0026gt;w) tarr[++p]=sa[i]-w; std::fill(cnt+1,cnt+m+1,0); for(int i=1;i\u0026lt;=n;i++) cnt[rkt[i] = rk[tarr[i]]]++; for(int i=1;i\u0026lt;=m;i++) cnt[i]+=cnt[i-1]; for(int i=n;i\u0026gt;=1;i--) sa[cnt[rkt[i]]--] = tarr[i]; m = 0; auto rp = [\u0026amp;](int x){return std::make_pair(rk[x],rk[x+w]);}; for(int i=1;i\u0026lt;=n;i++) tarr[sa[i]] = rp(sa[i-1])==rp(sa[i]) ? m:++m; std::copy(tarr+1,tarr+n+1,rk+1); if(n==m) break; } } 后缀自动机 //后缀自动机，构建SAM的复杂度为O(n)，空间复杂度为O(|S|n)，|S|为字符集的大小 //luogu p3804 //SAM是动态构建的，每次插入一个字符即可 struct State{ int fa,len,next[26];//似乎有些编译器next是保留字，需要注意 }; //endpos(p)为模式串p在s中所有出现的结束位置的集合，例如aababc中，ab出现了两次，结束位置是{3,5}。endpos等价类即，endpos相同的子串构成的集合。例如b和ab都是结束在{3,5}，则它们是等价类。这说明它们总是一起出现，可以归到一个节点，并且长度小的一定是长度大的的后缀。 //next[ch]表示接受ch后的状态；fa表示该状态在parent tree上的父节点；len表示该状态对应的endpos等价类中最长串的长度。 //假设b是a的fa，a等价类的最长字符串为s，则b的最长字符串为，s的所有后缀中，不在等价类a里的，最长的字符串。 //SAM可以接受字符串的所有后缀，但是它包含了所有子串的信息。也就是从任意一个状态开始的路径，都是字符串的子串。 //可行状态是last状态，以及fa[last]、fa[fa[last]]直到根节点（空字符串）。 //除了等价类的最长字符串长度len，我们也可以计算minlen。等价类里所有字符串的长度恰好覆盖[minlen,len]之间的每一个整数。除了根节点，st[i].minlen = st[fa[i]].len+1; //每个状态i对应的子串数量是st[i].len-st[st[i].fa].len //算法并没有维护endpos等效类中，字符串出现的位置个数，需要自己去树形dp。 //注意，aababb中，ab的等价类为{3,5}，根据ab前面一个字符不同可以划分不同的等价类，例如aab和bab划分为{3},{5}。但是a的等价类为{1,2,4}，因为第一个的前面一个字符是空字符，只能划分出两个，即aa{2},ba{4}，树形DP需要在parent tree上注意缺少的这一部分。在建SAM时预处理dp[cur] = 1 class SAM{ public: State st[MAXN\u0026lt;\u0026lt;1];//SAM总状态数不会超过2n-1，总转移数不超过3n-4 int cnt = 1, last = 1; //起始节点编号为1；last表示加入新字符前整个字符串所在的等价类 void insert(int ch){ ch = ch-\u0026#39;a\u0026#39;; int cur = ++cnt; int p = 0; st[cur].len = st[last].len + 1; for(p=last;p\u0026amp;\u0026amp;!st[p].next[ch];p=st[p].fa) st[p].next[ch] = cur; //对于每一个father状态，如果不存在ch的转移边，则连到cur int q = st[p].next[ch]; if(q==0){ //加入了从未加入的字符 st[cur].fa = 1; } else if(st[p].len + 1 == st[q].len){ //p到q是连续的转移 st[cur].fa = q; } else{ //不连续的转移 //会新增一个节点r,拥有q的所有出边，father与q相同 int r = ++cnt; st[r] = st[q]; st[r].len = st[p].len + 1; for(;p\u0026amp;\u0026amp;st[p].next[ch]==q;p=st[p].fa){ st[p].next[ch]=r; } st[cur].fa = st[q].fa = r; } last = cur; } }; SAM sam; 广义后缀自动机 //广义后缀自动机，其实就是插入多个字符串的后缀自动机，但只能离线build //luogu p6139 //后缀自动机的性质都可以用过来 struct State{ int fa,len,next[26];//似乎有些编译器next是保留字，需要注意 }; class GSA{ public: State st[MAXN\u0026lt;\u0026lt;1]; int cnt = 1;//起始节点编号为1 int insert(int last, int ch){ //传入的是即将插入的字符的父节点编号，以及该字符 //只用在build里，不要直接把字符串插入，应该先insertTrie再build int cur = st[last].next[ch]; int p = 0; st[cur].len = st[last].len + 1; for(p=st[last].fa;p \u0026amp;\u0026amp; !st[p].next[ch];p=st[p].fa) st[p].next[ch] = cur; int q = st[p].next[ch]; if(q==0){ st[cur].fa = 1; } else if(st[p].len+1==st[q].len){ st[cur].fa = q; } else{ int r = ++cnt; st[r].fa = st[q].fa; for(int i=0;i\u0026lt;26;i++) if(st[st[q].next[i]].len) st[r].next[i] = st[q].next[i]; st[r].len = st[p].len+1; for(;p \u0026amp;\u0026amp; st[p].next[ch]==q;p=st[p].fa) st[p].next[ch] = r; st[cur].fa = st[q].fa = r; } return cur; //返回插入节点编号 } void build(){ std::queue\u0026lt;pii\u0026gt; qu; for(int i=0;i\u0026lt;26;i++){ if(st[1].next[i]) qu.push({1,i}); } while(!qu.empty()){ int fa = qu.front().first; int ch = qu.front().second; qu.pop(); int p = insert(fa,ch); for(int i=0;i\u0026lt;26;i++){ if(st[p].next[i]) qu.push({p,i}); } } } void insertTrie(std::string const \u0026amp; str){ int cur = 1; for(auto c:str){ if(!st[cur].next[c-\u0026#39;a\u0026#39;]){ st[cur].next[c-\u0026#39;a\u0026#39;]=++cnt; } cur = st[cur].next[c-\u0026#39;a\u0026#39;]; } } }; GSA gsa; int main(){ int n; std::cin\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ std::string str; std::cin\u0026gt;\u0026gt;str; gsa.insertTrie(str); } gsa.build(); return 0; } 回文字动机 //回文字动机，复杂度：线性 //luogu p5496 struct State{ int len, fail, next[26]; }; //PAM的每一个状态代表原字符串的一个回文子串，每一个转移代表从当前状态字符串的前后同时加一个相同字符后的状态。可以接受其所有回文子串。除了奇根都是可行状态（当然不能为空时偶根不可行） //fail指针指向该状态的最长回文真后缀。例如ayawaya就指向aya。总体和AC自动机的fail转移很像，都是没有ch的转移，则看fail有没有ch的转移，若fail没有则看fail[fail]的，以此类推。 //回文串分为奇长度和偶长度的，所以PAM有奇根和偶根，偶根的fail指向奇根，奇根不可能失配。 //PAM和SAM一样是动态构建的。 class PAM{ public: int last,cnt,pos; //last代表上个前缀的最长回文后缀的状态 State st[MAXN];//最多有n+2个状态和n个转移 std::string str; void init(std::string const \u0026amp; s){ last = 1,pos = -1; cnt = 2;//起始两个根为1奇根，2偶根，len分别为-1和0 st[1].len = -1, st[2].len = 0, st[2].fail = 1; str = s; } int up(int p){ while(str[pos-1-st[p].len]!=str[pos]) p = st[p].fail; return p; } void insert(int ch){ pos++; ch = ch-\u0026#39;a\u0026#39;; int p = up(last); int \u0026amp; q = st[p].next[ch]; if(!q){ q=++cnt; st[q].len = st[p].len+2; st[q].fail = p==1 ? 2 : st[up(st[p].fail)].next[ch]; } last = q; } }; PAM pam; int main(){ std::string str std::cin\u0026gt;\u0026gt;str; pam.init(str); for(auto c:str){ pam.insert(c); } return 0; } 序列自动机 //序列自动机，复杂度 O(n|S|) //luogu p5826 //字符集很大时需要用可持久化线段树维护next struct State{ int next[26]; }; //SQA接受字符串的所有子序列（不需要连续，可以为空） class SQA{ public: State st[MAXN]; void build(std::string const \u0026amp; str){ int nxt[26]; std::fill(nxt,nxt+26,0); int n = str.size(); for(int i=n-1;i\u0026gt;=0;i--){ nxt[str[i]-\u0026#39;a\u0026#39;] = i+2;//1号节点是起始空节点 for(int ch=0;ch\u0026lt;26;ch++){ st[i+1].next[ch] = nxt[ch]; } } } bool query(std::string const \u0026amp; str){ //查询str是否是子序列（可以不连续） int p = 1, n=str.size(); for(int i=0;i\u0026lt;n;i++){ p = st[p].next[str[i]-\u0026#39;a\u0026#39;]; if(p==0) return false; } return true; } }; SQA sqa; 数论 欧几里得算法 //复杂度 logn //luogu B3736 //gcd是可重复贡献的，gcd(x,x)=x，可以用st表维护区间gcd //x*y=gcd(x,y)*lcm(x,y)，lcm是最小公倍数 #include \u0026lt;iostream\u0026gt; inline int gcd(int a,int b){ return b==0 ? a : gcd(b, a%b); } int main(){ int x,y,z; std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y\u0026gt;\u0026gt;z; std::cout\u0026lt;\u0026lt;gcd(gcd(x,y),z)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 扩展欧几里得 //复杂度 logn //求解ax+by=c的一组解，c不是gcd(a,b)的倍数则无解 //扩展欧几里得 //luogu P5656 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cmath\u0026gt; using LL = long long; LL exgcd(LL a,LL b,LL\u0026amp; x,LL\u0026amp; y){ //求出的是ax+by=gcd(a,b)的一组解，等于c的需要转换一下 if(b==0){ x = 1; y = 0;//此时ax+by=gcd(a,b)中b=0，任何数与0的最大公约数是他本身，所以ax+0y=a，x=1 y=0 return a; } LL d = exgcd(b,a%b,y,x); y -= (a/b)*x; return d; } int main(){ int T; std::cin\u0026gt;\u0026gt;T; while(T--){ LL a,b,c; std::cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b\u0026gt;\u0026gt;c; LL x0=0, y0=0; LL d = exgcd(a,b,x0,y0);//d=gcd(a,b) if(c%d!=0){//c不是gcd(a,b)的倍数则无解 std::cout\u0026lt;\u0026lt;\u0026#34;-1\\n\u0026#34;; continue; } LL x1 = x0*c/d, y1 = y0*c/d;//ax+by=gcd(a,b)的一组解转化为ax+by=c的一组解 //通解的形式为x=x1+s*dx, y=y1-s*dy //其中s为任意整数，dx=b/d, dy = a/d; LL dx = b/d, dy = a/d; LL l = std::ceil((-x1+1.0)/dx); LL r = std::floor((y1-1.0)/dy); //x\u0026gt;0,y\u0026gt;0时，s的取值为[l,r]中的整数，若l\u0026gt;r，则说明不存在正整数解 if(l\u0026gt;r){ std::cout\u0026lt;\u0026lt;x1+l*dx\u0026lt;\u0026lt;\u0026#34; \u0026#34;;//所有解中x的最小正整数值 std::cout\u0026lt;\u0026lt;y1-r*dy\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;;//所有解中y的最小正整数值 } else{ std::cout\u0026lt;\u0026lt;r-l+1\u0026lt;\u0026lt;\u0026#34; \u0026#34;;//正整数解的个数 std::cout\u0026lt;\u0026lt;x1+l*dx\u0026lt;\u0026lt;\u0026#34; \u0026#34;;//正整数解中x的最小值 std::cout\u0026lt;\u0026lt;y1-r*dy\u0026lt;\u0026lt;\u0026#34; \u0026#34;;//正整数解中y的最小值 std::cout\u0026lt;\u0026lt;x1+r*dx\u0026lt;\u0026lt;\u0026#34; \u0026#34;;//正整数解中x的最大值 std::cout\u0026lt;\u0026lt;y1-l*dy\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;;//正整数解中y的最大值 } } return 0; } 欧拉筛 TODO: 用模板元编程实现编译期算素数\n//复杂度 n //欧拉筛, luogu p3383 int const MAXN = 1e8+5; std::vector\u0026lt;int\u0026gt; prime; bool isnp[MAXN]; void sieve(int n){ isnp[1] = 1; isnp[0] = 1; for(int i=2;i\u0026lt;=n;i++){ if(!isnp[i]) prime.push_back(i); for(auto p:prime){ if(i*p\u0026gt;n) break; isnp[i*p] = 1; if(i%p==0) break; } } } Miller-Rabin素数测试 //对数 n 进行 k 轮测试的时间复杂度是 klog^3(n) //miller-rabin //loj 143 //通过测试的有可能是素数，不通过的一定不是素数 #include \u0026lt;iostream\u0026gt; #include \u0026lt;ctime\u0026gt; #include \u0026lt;cstdio\u0026gt; #include \u0026lt;cstdint\u0026gt; using LL = __int128;//本题数据范围过大，防止运算中爆掉 LL const test_time = 10; LL qPowMod(LL n, LL p, LL m){ LL res = 1; while(p\u0026gt;0){ if(p\u0026amp;1){ res = (res * n)%m; } n = (n*n)%m; p\u0026gt;\u0026gt;=1; } return res; } bool millerRabin(LL n) { if (n \u0026lt; 3 || n % 2 == 0) return n == 2; LL a = n - 1, b = 0; while (a % 2 == 0) a /= 2, ++b; // test_time 为测试次数,建议设为不小于 8 // 的整数以保证正确率,但也不宜过大,否则会影响效率 for (LL i = 1, j; i \u0026lt;= test_time; ++i) { LL x = rand() % (n - 2) + 2; LL v = qPowMod(x, a, n); if (v == 1) continue; for (j = 0; j \u0026lt; b; ++j) { if (v == n - 1) break; v = v * v % n; } if (j == b) return 0; } return 1; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); srand(time(NULL)); long long n; while(std::cin\u0026gt;\u0026gt;n){ if(millerRabin(n)){ std::cout\u0026lt;\u0026lt;\u0026#34;Y\\n\u0026#34;; } else{ std::cout\u0026lt;\u0026lt;\u0026#34;N\\n\u0026#34;; } } return 0; } 乘法逆元 //复杂度 扩展欧几里得法和费马小定理法都是logn //乘法逆元 //ax≡1(mod b)，x为a在乘法意义上的逆元，记作a^(-1)，或者inv(a) //用扩展欧几里得法的角度看，就是求ax+by=1的整数解 //快速幂法利用费马小定理，需要b为素数，并且疑似比exgcd常数大 //luogu P3811，会TLE，需要线性求逆元 //但loj 110不会TLE int exgcd(int a,int b,int\u0026amp; x,int\u0026amp; y){ if(b==0){ x = 1; y = 0; return a; } int d = exgcd(b,a%b,y,x); y -= (a/b)*x; return d; } int exgcd_inv(int a, int b){ //a在模b意义下的逆元 int x,y; int d = exgcd(a,b,x,y); if(d!=1){//显然a，b要互质才会有逆元 return -1; } else{ return (x+b)%b;//实际上是为了防止出现x为负数的情况 } } int qPowMod(int x, int p, int mod){ //x^p % m int ans = 1; while(p){ if(p\u0026amp;1){ ans = (ans*x)%mod; } x = (x*x)%mod; p\u0026gt;\u0026gt;=1; } return ans; } int fermat_inv(int a, int b){//a在模b意义下的逆元 return qPowMod(a,b-2,b); } 线性求逆元 //线性求逆元，对于1~n这些数，复杂度总共n //luogu p3381, loj 110 #include \u0026lt;iostream\u0026gt; using LL = long long; int const MAXN = 3000005; LL inv[MAXN]; void getinv(LL n, LL m){ //求1~n中，每个数在模m意义下的乘法逆元 inv[1] = 1; for(LL i=2;i\u0026lt;=n;i++){ //inv[i] = -(b/i)*inv[b%i]; //这样写会出现负数 inv[i] = (LL)(m-m/i)*inv[m%i]%m; } } 线性同余方程 //复杂度 logn //ax≡c (mod b)求解x //和ax+by=c等价 //luogu p1082 #include \u0026lt;iostream\u0026gt; using namespace std; int exgcd(int a,int b,int\u0026amp; x,int\u0026amp; y){ if(b==0){ x = 1; y = 0; return a; } int d = exgcd(b,a%b,y,x); y -= (a/b)*x; return d; } int linearEquation(int a, int b, int c, int \u0026amp;x, int \u0026amp;y){ int d = exgcd(a,b,x,y); if(c%d!=0) return -1; x = x*c/d; y = y*c/d; return d; } int main(){ int a,b,c,x,y; cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b; c=1; int d = linearEquation(a,b,c,x,y); //d是a,b的最大公约数，如果无解d==-1 //下面输出的是最小整数解 int t = b/d; x = (x%t+t)%t; cout\u0026lt;\u0026lt;x\u0026lt;\u0026lt;endl; return 0; } 中国剩余定理 求解如下方程中的\\(x\\)\n\\[\\left\\{\\begin{matrix} x \\equiv a_1(mod\\quad r_1) \\\\ x \\equiv a_2(mod\\quad r_2) \\\\ \\vdots \\\\ x \\equiv a_k(mod\\quad r_k) \\end{matrix}\\right. \\]\n其中\\(r_i\\)两两互质，如果不满足则需要扩展CRT。\n设\\(n=r_1r_2\\cdots r_k\\)，计算\\(m_i=n/r_i\\)，计算\\(m_i\\)在模\\(r_i\\)意义下的逆元，计算\\(c_i=m_im_i^{-1}\\)（不要对\\(r_i\\)取模）。方程组在模\\(n\\)意义下有唯一解\\(x=\\sum^k_i a_ic_i\\)（也就意味着\\(x\\)在\\(1\\sim n\\)中必有一解）\n//中国剩余定理 复杂度 klogk //luogu p1495 typedef long long ll; const int MAXN = 10005; ll exgcd(ll a, ll b, ll \u0026amp;x, ll \u0026amp;y){ if(!b){ x=1; y=0; return a; } ll d = exgcd(b,a%b,x,y); ll tmp = x; x = y; y = tmp - (a/b)*y; return d; } ll exgcd_inv(ll a, ll b){ ll x,y; ll d = exgcd(a,b,x,y); return (x+b)%b; } class CRT{ public: ll ax[MAXN],rx[MAXN];//每个方程的形式为x≡ai(mod ri)，要求ri互质 int k=0;//k个方程 void add(ll a, ll r){ ax[++k] = a; rx[k] = r; } ll solve(){ ll n=1, ans=0; for(int i=1;i\u0026lt;=k;i++){ n = n * rx[i]; } for(int i=1;i\u0026lt;=k;i++){ ll m = n/rx[i]; ans = (ans+ax[i]*m*exgcd_inv(m,rx[i]))%n; } return ans; } }; CRT crt; 积性函数 积性函数是数论函数的一种。数论函数则是定义域为正整数的函数。\n若函数\\(f(n)\\)满足\\(f(1)=1\\)且\\(\\forall x,y\\in N^*,gcd(x,y)=1\\)都有\\(f(xy)=f(x)f(y)\\)，则\\(f(n)\\)为积性函数\n如果不要求\\(gcd(x,y)=1\\)也有这个性质的函数叫完全积性函数。同理可知加性函数的定义。\n性质\n若\\(f(x),g(x)\\)均为积性函数，则以下函数也是积性函数 \\(h(x)=f(x^p)\\) \\(h(x)=f^p(x)\\) \\(h(x)=f(x)g(x)\\) \\(h(x)=\\sum_{d|x}f(d)g(x/d)\\)（即狄利克雷卷积） 其逆元 若\\(f\\)是积性函数，且在算术基本定理中\\(n=\\prod^{m}_{i=1}p_i^{c_i}\\)，则\\(f(n)=\\prod^{m}_{i=1}f(p_i^{c_i})\\)。如果\\(f\\)是完全积性函数，则\\(f(n)=\\prod^{m}_{i=1}f(p_i)^{c_i}\\) 例子\n\\(\\varepsilon(n)=[n=1]\\)，单位函数，括号是艾弗森括号，是完全积性。 \\(id_k(n)=n^k\\)，幂函数，是完全积性。\\(k=1\\)是恒等函数\\(id(n)=n\\)，\\(k=0\\)是常数函数\\(1(n)=1\\) \\(\\sigma_k(n)=\\sum_{d/n}d^k\\)，除数函数。当\\(k=1\\)时，为因数和函数\\(\\sigma(n)\\)，当\\(k=0\\)时为因数个数函数\\(\\sigma_0(n)\\) 欧拉函数 莫比乌斯函数 欧拉函数 TODO：习题 \\(1\\sim N\\)中与\\(N\\)互质的数的个数被称为欧拉函数，记为\\(\\varphi(N)\\)\n若在算数基本定理中，\\(N=p_1^{c_1}p_2^{c_2}\\cdots p_m^{c_m}\\)，则\n\\[\\varphi(N)=N\\times\\dfrac{p_1-1}{p_1}\\times\\dfrac{p_2-1}{p_2}\\times\\cdots\\times\\dfrac{p_m-1}{p_m} \\]\n欧拉函数也可以写成艾弗森括号的形式为\n\\[\\sum^n_{i=1}[\\gcd(i,n)=1] \\]\n//复杂度 根号n int phi(int n){ int ans = n; for(int i=2;i*i\u0026lt;=n;i++){ if(n%i==0){ ans = ans/i*(i-1); while(n%i==0) n/=i; } } if(n\u0026gt;1) ans = ans/n*(n-1); return ans; } 欧拉函数有以下性质\n\\(\\forall n\u003e1\\)，\\(1\\sim n\\)中与\\(n\\)互质的数的和为\\(n\\times\\varphi(n)/2\\) 若\\(a,b\\)互质，则\\(\\varphi(ab)=\\varphi(a)\\varphi(b)\\)。也就是说欧拉函数是积性函数 设\\(p\\)为质数，若\\(p|n\\)且\\(p^2|n\\)，则\\(\\varphi(n)=\\varphi(n/p)\\times p\\) 设\\(p\\)为质数，若\\(p|n\\)但不满足\\(p^2|n\\)，则\\(\\varphi(n)=\\varphi(n/p)\\times (p-1)\\) \\(\\sum_{d|n}\\varphi(d)=n\\) 若\\(p\\)是质数，则\\(\\varphi(p^n)=p^{n-1}(p-1)\\) 若\\(a|x\\)，则\\(\\varphi(ax)=a\\varphi(x)\\) //求1-N的所有欧拉函数值，使用筛法，埃氏筛复杂度NloglogN，线性筛复杂度N，这里是线性筛 std::vector\u0026lt;int\u0026gt; prime; bool isnp[MAXN]; int phi[MAXN]; void euler(int n){ phi[1] = 1; for(int i=2;i\u0026lt;=n;i++){ if(!isnp[i]){ prime.push_back(i); phi[i] = i-1; } for(auto p:prime){ if(i*p\u0026gt;n) break; isnp[i*p] = 1; if(i%p==0){ phi[i*p] = phi[i] * p; break; } else{ phi[i*p] = phi[i] * phi[p]; } } } } 狄利克雷卷积 两个数论函数\\(f(n),g(n)\\)的狄利克雷卷积定义为\n\\[(f\\ast g)(n) = \\sum_{xy=n}f(x)g(y) \\]\n也可以写作\n\\[(f\\ast g)(n) = \\sum_{d|n}f(d)g(n/d) \\]\n性质\n两个积性函数的卷积还是积性函数 \\((f\\ast 1)(n) = \\sum_{d|n}f(d)\\) \\((id_k\\ast 1)(n)=\\sum_{d|n}d^k=\\sigma_k\\) \\(\\varphi\\ast 1=id\\) 满足交换率、结合律、对加法的分配律 等式性质，\\(f=g\\)的充要条件是\\(f\\ast h = g\\ast h\\)，其中数论函数\\(h(1)\\neq 0\\) 幺元是\\(\\varepsilon\\)，即\\(f\\ast \\varepsilon=f\\) 逆元，即满足\\(f\\ast g=\\varepsilon\\)的函数\\(g\\)为（显然\\(f(1)\\neq 0\\)才有逆元） \\[g(x)=\\dfrac{\\varepsilon(x)-\\sum_{d|x,d\\neq 1}f(d)g(x/d)}{f(1)} \\]\n积性函数一定有逆元，且逆元也是积性函数。 莫比乌斯反演 TODO：习题 莫比乌斯函数是常数函数\\(1\\)的逆元。即\n\\[\\mu(n) = \\left\\{\\begin{matrix} 1, \u0026 n=1 \\\\ (-1)^m \u0026 n=p_1p_2\\cdots p_m\\\\ 0 \u0026 \\text{otherwise} \\end{matrix}\\right. \\]\n其中第二个条件就是\\(n\\)质因数分解后每个因子的次数是\\(1\\)\n莫比乌斯反演公式即为\n\\[g(n)=\\sum_{d|n}f(d)\\Leftrightarrow f(n) = \\sum_{d|n}\\mu(d)g(n/d) \\]\n用狄利克雷卷积来写就是\n\\[f\\ast 1=g\\Leftrightarrow f=g\\ast \\mu \\]\n还有一种形式（倍数形式，之前的叫因数形式）是\n\\[g(n) = \\sum_{n|N}f(N)\\Leftrightarrow f(n) = \\sum_{n|N}\\mu(N/n)g(N) \\]\n性质\n是积性函数 \\(\\sum_{d|n}\\mu(d)=\\varepsilon(n),\\mu\\ast 1=\\varepsilon\\) \\(\\sum_{d|\\gcd(i,j)}\\mu(d)=[\\gcd(i,j)=1]\\) //线性筛求莫比乌斯函数，复杂度n int mu[MAXN]; std::vector\u0026lt;int\u0026gt; prime; bool isnp[MAXN]; void mobius(int n){ mu[1] = 1; for(int i=2;i\u0026lt;=n;i++){ if(!isnp[i]){ prime.push_back(i); mu[i] = -1; } for(auto p:prime){ if(i*p\u0026gt;n) break; isnp[i*p] = 1; if(i%p==0){ mu[i*p] = 0; break; } else{ mu[i*p] = mu[i] * mu[p]; } } } } 数论分块 在计算形如\n\\[\\sum^n_{i=1}f(i)g(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor ) \\]\n的式子时，注意到\\(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor\\)的取值个数会比\\(n\\)小很多，我们可以将取值相同的合在一起计算。如果可以在\\(O(1)\\)内计算\\(f(l)+\\cdots+f(r)\\)（比如等差数列求和公式）或者有\\(f\\)的前缀和时，数论分块可以在\\(O(\\sqrt{n})\\)计算和式的值。\n定理1\n\\[\\forall a,b,c\\in Z, \\left \\lfloor \\dfrac{a}{bc} \\right \\rfloor=\\left \\lfloor \\dfrac{\\left \\lfloor \\dfrac{a}{b} \\right \\rfloor}{c} \\right \\rfloor \\]\n定理2\n当\\(i\\)取正整数且\\(i\\leq n\\)时，\\(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor\\)的不同取值的数量不超过\\(\\left \\lfloor 2\\sqrt n \\right \\rfloor\\)\n定理3\n使得式子\n\\[\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor = \\left \\lfloor \\dfrac{n}{j} \\right \\rfloor \\]\n成立的最大的满足\\(i\\leq j\\leq n\\)的\\(j\\)值是\\(\\left \\lfloor \\dfrac{n}{\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor} \\right \\rfloor\\)。也就是这个分块的右端点。\n//UVA 11526 //数论分块模板 复杂度sqrt n //要求计算i=1~n, ans = ans+n/i void solve(){ LL n; std::cin\u0026gt;\u0026gt;n; LL ans = 0; LL l = 1, r = 0; while(l\u0026lt;=n){ r = n/(n/l); ans += (r-l+1) * (n/l); l = r+1; } std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } 注意如果不是\\(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor\\)而是某个\\(\\left \\lfloor \\dfrac{k}{i} \\right \\rfloor\\)，要注意特判判\\(k/l\\)等于\\(0\\)，以及\\(r\\)要特判不能超过\\(n\\)。\n当有多个取整\\(\\left \\lfloor \\dfrac{a_1}{i} \\right \\rfloor,\\left \\lfloor \\dfrac{a_2}{i} \\right \\rfloor,\\cdots\\) 时，我们取的右端点就变成每一个块的右端点的最小值。\n杜教筛 杜教筛可以在\\(O(n^{2/3})\\)的时间复杂度下求得一类数论函数（不一定需要积性）\\(f(n)\\)的前缀和。\n我们需要找到一个数论函数\\(g(n)\\)，使得\\(g(n)\\)和\\(f\\ast g(n)\\)的前缀和都很容易求出（最好在\\(O(1)\\)），那我们就能以低于线性复杂度的算法求出\\(f(n)\\)的前缀和\\(S(n)\\)。证明略，结论为：\n\\[g(1)S(n) = \\sum^n_{i=1}(f\\ast g)(i)-\\sum^n_{i=2}g(i)S(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor) \\]\n筛莫比乌斯函数\n之前我们学到\\(\\mu\\ast 1=\\varepsilon\\)，所以我们自然的令\\(g(n)=1\\)，得到\n\\[S(n)=\\sum^n_{i=1}\\varepsilon(i)-\\sum^n_{i=2}S(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor) = 1-\\sum^n_{i=2}S(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor) \\]\n此时如果我们直接用数论分块去算\\(S(n)\\)，我们的算法复杂度是\\(O(n^{3/4})\\)，但是如果我们用线性筛预处理前\\(n^{2/3}\\)的\\(S(n)\\)的值，就可以优化复杂度到\\(O(n^{2/3})\\)，通常我们还会开一个哈希表去维护大于\\(n^{2/3}\\)的值来优化。\n筛欧拉函数\n同样取\\(g(n)=1\\)，有\\(\\varphi(n)\\ast 1=id\\)\n\\[S(n) = \\sum^n_{i=1}id-\\sum^n_{i=2}S(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor) = \\dfrac{n(1+n)}{2}-\\sum^n_{i=2}S(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor) \\]\n跟之前可以说没什么区别。\n给出求欧拉函数和莫比乌斯函数前缀和的例子代码。这里筛法一次把两个函数都筛了，其他不难理解。注意要用unordered_map以及数论分块的时候\\(l\\)从\\(2\\)开始。以及洛谷上这题数据范围为2^31，要筛出大概前170w个数。我筛了200w也过了，分类讨论，前200w直接返回，大于200w的如果在map里就返回，否则递归计算后放入map里。\n//杜教筛 复杂度n^(2/3) //luogu p4213 int const MAXN = 2000005; int mu[MAXN]; LL phi[MAXN]; std::vector\u0026lt;int\u0026gt; prime; bool isnp[MAXN]; LL sum_mu[MAXN],sum_phi[MAXN]; std::unordered_map\u0026lt;LL,LL\u0026gt; mp_mu,mp_phi; void sieve(int n=MAXN-1){ mu[1] = 1; phi[1] = 1; for(int i=2;i\u0026lt;=n;i++){ if(!isnp[i]){ prime.push_back(i); mu[i] = -1; phi[i] = i-1; } for(auto p:prime){ if(i*p\u0026gt;n) break; isnp[i*p] = 1; if(i%p==0){ mu[i*p] = 0; phi[i*p] = phi[i] * p; break; } else{ mu[i*p] = mu[i] * mu[p]; phi[i*p] = phi[i] * phi[p]; } } } for(int i=1;i\u0026lt;=n;i++){ sum_mu[i] = sum_mu[i-1]+mu[i]; sum_phi[i] = sum_phi[i-1]+phi[i]; } } LL sum1(LL n){ if(n\u0026lt;MAXN){ return sum_phi[n]; } if(mp_phi.count(n)){ return mp_phi[n]; } LL l=2, r=0; LL ret = n*(1+n)/2; while(l\u0026lt;=n){ r = n/(n/l); ret -= (r-l+1)*sum1(n/l); l = r+1; } mp_phi[n] = ret; return ret; } LL sum2(LL n){ if(n\u0026lt;MAXN){ return sum_mu[n]; } if(mp_mu.count(n)){ return mp_mu[n]; } LL l=2, r=0; LL ret = 1; while(l\u0026lt;=n){ r = n/(n/l); ret -= (r-l+1)*sum2(n/l); l = r+1; } mp_mu[n] = ret; return ret; } void solve(){ LL n; std::cin\u0026gt;\u0026gt;n; std::cout\u0026lt;\u0026lt;sum1(n)\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;sum2(n)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); sieve(); int T; std::cin\u0026gt;\u0026gt;T; //T=1; while(T--){ solve(); } return 0; } 图论 存图 邻接矩阵 int graph[MAXN][MAXN]; //加边删边、访问很方便，a-\u0026gt;b，权值为w，则graph[a][b]=w //空间占用大，并且不能存重边 邻接表（vector版） struct Edge{ int v,w;//下一点，权 }; std::vector\u0026lt;Edge\u0026gt; edges[MAXN]; //加边u-\u0026gt;v,权值w edges[u].push_back(w); //访问只能遍历u所连的出边 for(auto x:edges[u]){ std::cout\u0026lt;\u0026lt;x.v\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;x.w\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } //缺点是，删边难，以及清空边复杂度过高。快速清边见链式前向星传统数组版 链式前向星（vector版） struct Edge{ int v;LL w;//指向的点，容量 Edge(int v_, LL w_):v(v_),w(w_){} }; std::vector\u0026lt;Edge\u0026gt; edges; std::vector\u0026lt;std::vector\u0026lt;int\u0026gt; \u0026gt; graph(MAXN); //常用于网络流，例如加u-\u0026gt;v，权值为w，及其反向边v-\u0026gt;w，权值为0 graph[u].push_back(edges.size()); edges.push_back(Edge(v,w)); graph[v].push_back(edges.size()); edges.push_back(Edge(u,0)); //遍历u的边时 for(auto x:graph[u]){ auto e=edges[x]; auto v=e.v, w=e.w; //e的反向边就是edges[x^1] } //清空某个点连出的所有边时，graph[u].clear()，不需要管edges的size //清除整个图时edges.clear()，graph要对每个下标clear //这种清除方式复杂度比传统数组版高很多，需要反复建图时不推荐使用。 //好处是不需要让边编号从2开始，从0开始即可存反向边 链式前向星（传统数组版） struct Edge{ int v,w,next;//指向的点，边权，下一条边 }; Edge edges[MAXM];//存无向图记得开两倍 int head[MAXN],cnt;//如果要存反向边，并且用^1取反向边，应初始化cnt=1 //不应把后面add的逻辑改成最后再cnt++，因为我们遍历边的时候是判断e是否等于0，所以不应该有边的编号等于0 inline void add(int u, int v, int w){ edges[++cnt].w = w; edges[cnt].v = v; edges[cnt].next = head[u];//把下一条边设置为当前起点的第一条边 head[u] = cnt;//该边称为当前起点的第一条边 } //遍历，与vector版不同，vector版按加入先后顺序遍历，而这里是反向顺序遍历。绝大多数情况不影响 //例如遍历1号节点所连的边 for(int e=head[1];e;e=edges[e].next){ std::cout\u0026lt;\u0026lt;edges[e].v\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;edges[e].w\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } //当需要清空某个点的所有连出边时, head[u] = 0，不需要管cnt //清空全图时，cnt = 0, 对于所有点head = 0， 由于还可以用memset，比vector版更是快了不少 最短路 Dijkstra //复杂度 优先队列实现为mlogm //dijkstra，单源最短路 //luogu p4779 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; #define MAXN 500005 #define MAXINT 0x7fffffff struct Edge{ int v,w;//下一点，权 Edge(int v_, int w_):v(v_),w(w_){} }; struct Node { int dis, u;//存储起点到u点的距离 Node(int dis_, int u_):dis(dis_),u(u_){}; bool operator\u0026gt;(Node const \u0026amp; a) const { return dis \u0026gt; a.dis; } }; std::vector\u0026lt;Edge\u0026gt; graph[MAXN]; int dis[MAXN]; bool tag[MAXN]; std::priority_queue\u0026lt;Node, std::vector\u0026lt;Node\u0026gt;, std::greater\u0026lt;Node\u0026gt; \u0026gt; pq; void init(int n){ for(int i=1;i\u0026lt;=n;i++){ dis[i] = MAXINT; //初始化为无限远 tag[i] = 0; graph[i].clear(); } while(!pq.empty()) pq.pop(); } void dijk(int s){ dis[s]=0; pq.push(Node(0,s)); while (!pq.empty()) { int u = pq.top().u; pq.pop(); if(tag[u]) continue; tag[u]=1; for(auto g : graph[u]){ int v = g.v, w = g.w; if(dis[v]\u0026gt;dis[u]+w){ dis[v] = dis[u]+w; pq.push(Node(dis[v],v)); } } } } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m,s; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s; //点数，边数，起点 init(n); for(int i=1;i\u0026lt;=m;i++){ int u,v,w; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w;//起点，终点，边权 graph[u].push_back(Edge(v,w)); } dijk(s); for(int i=1;i\u0026lt;=n;i++){ std::cout\u0026lt;\u0026lt;dis[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } return 0; } Bellman-Ford //复杂度 nm //bellman-ford, 单源最短路 //luogu p4779，有一个点TLE #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;cstring\u0026gt; int const MAXN = 100005; int const INF = 0x6fffffff; struct Edge{ int v,w;//下一点,权 Edge(int v_, int w_):v(v_),w(w_){} }; int dis[MAXN]; std::vector\u0026lt;Edge\u0026gt; graph[MAXN]; void init(int n){ for(int i=1;i\u0026lt;=n;i++){ dis[i]=INF; graph[i].clear(); } } bool BF(int n, int s){ //如果不存在最短路就返回0，否则返回1 dis[s] = 0; bool flag = 1; for (int i=1;i\u0026lt;=n;i++){//松弛n-1轮，若第n轮还能松弛，就说明有负环 flag = 1; for(int u=1;u\u0026lt;=n;u++){//这里看似是两层循环，实际上总数是边数，整个算法的复杂度是mn for (auto e : graph[u]){ int w=e.w,v=e.v; if(dis[v]\u0026gt;dis[u]+w){ dis[v]=dis[u]+w; flag = 0; } } } if(flag){ break; } } return flag; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m,s;//点数，边数，起点 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s; init(n); for(int i=1;i\u0026lt;=m;i++){ int u,v,w; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w; //起点，终点，边权 graph[u].push_back(Edge(v,w)); } BF(n,s); for(int i=1;i\u0026lt;=n;i++){ std::cout\u0026lt;\u0026lt;dis[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } return 0; } SPFA //复杂度 nm /* bellman-ford的优化 只有上一次被松弛的结点，所连接的边， 才有可能引起下一次的松弛操作 */ //spfa 单源最短路 //luogu P3371 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; int const MAXN = 100005; int const INF = 0x5fffffff; struct Edge{ int v,w; Edge(int v_, int w_):v(v_),w(w_){} }; int dis[MAXN];//距离 int cnt[MAXN];//算到达本节点所要经过的边数，若cnt\u0026gt;=n，则说明有负权环 bool tag[MAXN];//用于判断是否为上次松弛过的节点的边所连的点 std::queue\u0026lt;int\u0026gt; qu; std::vector\u0026lt;Edge\u0026gt; graph[MAXN]; void init(int n){ while(!qu.empty()) qu.pop(); for(int i=1;i\u0026lt;=n;i++){ dis[i] = INF; cnt[i] = 0; tag[i] = 0; graph[i].clear(); } } bool SPFA(int n, int s){ //如果不存在最短路就返回0，否则返回1 dis[s] = 0; tag[s] = 1; qu.push(s); bool flag = 1; while(!qu.empty()){ if(!flag) break; int u = qu.front(); qu.pop(); tag[u]=0; for(auto e : graph[u]){ int v = e.v, w = e.w; if(dis[v]\u0026gt;dis[u]+w){ dis[v]=dis[u]+w; cnt[v]=cnt[u]+1; if(cnt[v]\u0026gt;=n) { flag = 0; break; } if(!tag[v]){ qu.push(v); tag[v]=1; } } } } return flag; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m,s; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s; init(n); for(int i=1;i\u0026lt;=m;i++){ int u,v,w; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w; //起点，终点，边权 graph[u].push_back(Edge(v,w)); } SPFA(n,s); for(int i=1;i\u0026lt;=n;i++){ if(dis[i]!=INF){ std::cout\u0026lt;\u0026lt;dis[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } else{ std::cout\u0026lt;\u0026lt;\u0026#34;2147483647 \u0026#34;;//根据luogu P3371要输出这个数 } } return 0; } Floyd //复杂度 n^3 //floyd全源最短路 //luogu p5905，由于不能判断负环和速度慢，会wa和tle一些 //floyd虽然不能处理负环但是可以接受负边 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; using LL = long long; int const MAXN = 3005; LL const INF = 1e17; //不能设置为int的最大值，否则后面加法可能导致溢出 LL graph[MAXN][MAXN]; int main(){ int n,m;//点数，边数 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; for(int i = 1;i\u0026lt;=n;i++){ for(int j = 1;j\u0026lt;=n;j++){ graph[i][j] = INF; } } for(int i=1;i\u0026lt;=m;i++){ int u,v;LL w; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w;//起点，终点，边权 graph[u][v] = std::min(graph[u][v], w);//处理重边 } for(int i = 1;i\u0026lt;=n;i++){ graph[i][i] = 0; } for(int k=1;k\u0026lt;=n;k++){ for(int i=1;i\u0026lt;=n;i++){ for(int j=1;j\u0026lt;=n;j++){ graph[i][j] = std::min(graph[i][j],graph[i][k]+graph[k][j]); } } } for(int i=1;i\u0026lt;=n;i++){ LL res=0; for(LL j=1;j\u0026lt;=n;j++){ if(graph[i][j]\u0026gt;1e9) graph[i][j] = 1e9; res += j*graph[i][j]; } std::cout\u0026lt;\u0026lt;res\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } Johnson TODO 差分约束 给出一组不等式\n\\[\\left\\{\\begin{matrix} x_{c_1}-x_{c_1'}\\leq y_1 \\\\ x_{c_2}-x_{c_2'}\\leq y_2 \\\\ \\vdots \\\\ x_{c_m}-x_{c_m'}\\leq y_m \\end{matrix}\\right. \\]\n其中一共有\\(n\\)个未知数\\(x_1,x_2,\\cdots,x_n\\)，\\(m\\)个不等式，求一组可行解。\n我们连边，连一条\\(x_{c_i'}\\)到\\(x_{c_i}\\)，权值为\\(y_i\\)的边。然后增加\\(n+1\\)号节点，从它到所有点连一条权值为\\(0\\)的边。然后以\\(n+1\\)为源点求到各点的最短路，这个最短距离dis[i]就是\\(x_i\\)的一个解。\n当然，出现负环就无解。\n不难理解，\\(x_1,x_2,\\cdots,x_n\\)全部加上或减去同一个数，仍然是可行解。\n之前我们假设dis[n+1]=0，如果我们设置dis[n+1] = w，那么我们求得的就是\\(x_1,x_2,\\cdots,x_n\\leq w\\)的一组解。实际上，可以证明这个解是满足\\(x_1,x_2,\\cdots,x_n\\leq w\\)的最大解（每个变量能取得的最大值）。\n如果题目上的约束条件全部变为\\(\\geq\\)型，我们要求满足\\(x_1,x_2,\\cdots,x_n\\geq w\\)的最小解，则只需要求最长路即可。对于Bellman-Ford和SPFA来说，初始化dis为-INF，然后颠倒比较符号即可。\n题目中不总是给出\\(x_1-x_2\\leq y\\)，但我们可以转化\n\\(x_1-x_2\\geq y\\Rightarrow x_2-x_1\\leq -y\\) \\(x_1-x_2=y\\Rightarrow x_1-x_2\\leq y \\wedge x_2-x_1\\leq -y\\) \\(x_1-x_2\u003c y\\Rightarrow x_1-x_2\\leq y-1\\)（要求取值只能是整数） \\(x_1-x_2\u003ey\\Rightarrow x_2-x_1\\leq -y-1\\)（要求取值只能是整数） //差分约束，复杂度同SPFA //luogu p5960 //使用介绍见markdown #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; int const MAXN = 5005; int const INF = 0x5fffffff; struct Edge{ int v,w; Edge(int v_, int w_):v(v_),w(w_){} }; int dis[MAXN];//距离 int cnt[MAXN];//算到达本节点所要经过的边数，若cnt\u0026gt;=n，则说明有负权环 bool tag[MAXN];//用于判断是否为上次松弛过的节点的边所连的点 std::queue\u0026lt;int\u0026gt; qu; std::vector\u0026lt;Edge\u0026gt; graph[MAXN]; void init(int n){ while(!qu.empty()) qu.pop(); for(int i=1;i\u0026lt;=n;i++){ dis[i] = INF; cnt[i] = 0; tag[i] = 0; graph[i].clear(); } } bool SPFA(int n, int s){ //如果不存在最短路就返回0，否则返回1 dis[s] = 0; tag[s] = 1; qu.push(s); bool flag = 1; while(!qu.empty()){ if(!flag) break; int u = qu.front(); qu.pop(); tag[u]=0; for(auto e : graph[u]){ int v = e.v, w = e.w; if(dis[v]\u0026gt;dis[u]+w){ dis[v]=dis[u]+w; cnt[v]=cnt[u]+1; if(cnt[v]\u0026gt;=n) { flag = 0; break; } if(!tag[v]){ qu.push(v); tag[v]=1; } } } } return flag; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; init(n+1); for(int i=1;i\u0026lt;=m;i++){ int v,u,w; std::cin\u0026gt;\u0026gt;v\u0026gt;\u0026gt;u\u0026gt;\u0026gt;w; graph[u].push_back(Edge(v,w)); } for(int i=1;i\u0026lt;=n;i++){ graph[n+1].push_back(Edge(i,0)); } n++; if(!SPFA(n,n)){ std::cout\u0026lt;\u0026lt;\u0026#34;NO\\n\u0026#34;; return 0; } for(int i=1;i\u0026lt;=n-1;i++){ std::cout\u0026lt;\u0026lt;dis[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } return 0; } 拓扑排序 //复杂度 n //拓扑排序, luogu B3644 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; int const MAXN = 105; std::vector\u0026lt;int\u0026gt; graph[MAXN]; int in[MAXN]; int main(){ int n; std::cin\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ while(true){ int v; std::cin\u0026gt;\u0026gt;v; if(v==0) break; graph[i].push_back(v); in[v]++; } } std::queue\u0026lt;int\u0026gt; qu; for(int i=1;i\u0026lt;=n;i++){ if(in[i]==0) qu.push(i); } while(!qu.empty()){ int u = qu.front(); qu.pop(); std::cout\u0026lt;\u0026lt;u\u0026lt;\u0026lt;\u0026#34; \u0026#34;; for(auto v:graph[u]){ in[v]--; if(in[v]==0) qu.push(v); } } return 0; } 最小生成树 Kruskal //复杂度 mlogm //最小生成树Kruskal，luogu p3366 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; int const MAXM = 200005; int const MAXN = 5005; struct Edge{ int u,v,w;//最小生成树是在无向图上跑的，由于要排序，所以记录uvw bool operator\u0026lt;(Edge const \u0026amp; x) const { return w\u0026lt;x.w; } }; Edge edges[MAXM]; int find_sets[MAXN];//并查集 int find(int x){return find_sets[x]==x ? x : find_sets[x] = find(find_sets[x]);} int main(){ int n,m;//点数和边数 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; for(int i=1;i\u0026lt;=m;i++){ std::cin\u0026gt;\u0026gt;edges[i].u\u0026gt;\u0026gt;edges[i].v\u0026gt;\u0026gt;edges[i].w; } std::sort(edges+1,edges+1+m); for(int i=1;i\u0026lt;=n;i++){ find_sets[i]=i; } int ans = 0; int cnt=0; for(int i=1;i\u0026lt;=m;i++){ int u = edges[i].u, v = edges[i].v; int x = find(u); int y = find(v); if(x!=y){ ans += edges[i].w; find_sets[x] = y; cnt++; } } //计数，如果小于n-1则不连通 if(cnt\u0026lt;n-1){ std::cout\u0026lt;\u0026lt;\u0026#34;orz\\n\u0026#34;; } else{ std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } Prim算法 //复杂度 (m+n)logn //最小生成树prim，luogu p3366 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; const int MAXN = 5005; const int MAXM = 200005; const int INF = 0x5fffffff; struct edge{ int v,w; edge(){}; edge(int v,int w):v(v),w(w){} bool operator\u0026gt;(const edge\u0026amp; x) const {return w\u0026gt;x.w;} }; std::vector\u0026lt;edge\u0026gt; graph[MAXN]; bool vis[MAXN]; std::priority_queue\u0026lt;edge, std::vector\u0026lt;edge\u0026gt;, std::greater\u0026lt;edge\u0026gt; \u0026gt; pq; int main(){ int n,m;//点数，边数 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; int ans = 0; int cnt = 1; for(int i=1;i\u0026lt;=m;i++){ int u,v,w;//起点，终点，边权 std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w; graph[u].push_back(edge(v,w)); graph[v].push_back(edge(u,w)); //无向图 } for(int i=0;i\u0026lt;graph[1].size();i++){ pq.push(graph[1][i]); } vis[1]=true; while(cnt!=n\u0026amp;\u0026amp;!pq.empty()){ edge minx=pq.top(); pq.pop(); while(vis[minx.v]){ if(pq.empty()){ std::cout\u0026lt;\u0026lt;\u0026#34;orz\\n\u0026#34;;//不连通 return 0; } minx=pq.top(); pq.pop(); } vis[minx.v] = true; ans+=minx.w; cnt++; for(int i=0;i\u0026lt;graph[minx.v].size();i++){ if(!vis[graph[minx.v][i].v]) pq.push(graph[minx.v][i]); } } if(cnt\u0026lt;n){ std::cout\u0026lt;\u0026lt;\u0026#34;orz\\n\u0026#34;; } else{ std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } 最小树形图（朱刘算法） //复杂度 nm //最小树形图，朱刘算法 //从根节点能到达其他所有点 //luogu4716 #include \u0026lt;iostream\u0026gt; const int MAXN = 105; const int MAXM = 10005; const int INF = 0x7fffffff; struct Edge{ int u,v,w; }; Edge edge[MAXM]; int vis[MAXN],id[MAXN]; int in[MAXN],pre[MAXN]; int zhuliu(int n, int m, int root){ //返回最小树形图的边权和，如果不存在则返回-1 int ans = 0; for(;;){ for(int i=1;i\u0026lt;=n;i++) in[i]=INF; for(int i=1;i\u0026lt;=m;i++){ int u = edge[i].u; int v = edge[i].v; if(u!=v \u0026amp;\u0026amp; edge[i].w\u0026lt;in[v]){//遍历所有边，找到对每个点的最短入边 in[v] = edge[i].w; pre[v] = u; } } for(int i=1;i\u0026lt;=n;i++){ if(i!=root \u0026amp;\u0026amp; in[i]==INF){ return -1;//无解 } } int cnt = 0;//记录环数以及下一次循环的点数 for(int i=1;i\u0026lt;=n;i++){ vis[i] = -1; id[i] = -1; } in[root] = 0; for(int i=1;i\u0026lt;=n;i++){ if(i==root) continue; ans += in[i]; int v=i; while(vis[v]!=i\u0026amp;\u0026amp;id[v]==-1\u0026amp;\u0026amp;v!=root){ vis[v] = i; v = pre[v]; } if(v!=root \u0026amp;\u0026amp; id[v]==-1){ id[v] = ++cnt; for(int u=pre[v];u!=v;u=pre[u]) id[u] = cnt; } } if(cnt==0){//无环，得到解 break; } for(int i=1;i\u0026lt;=n;i++){ if(id[i]==-1) id[i]=++cnt; } for(int i=1;i\u0026lt;=m;i++){ int u = edge[i].u; int v = edge[i].v; edge[i].u = id[u]; edge[i].v = id[v]; if(edge[i].u!=edge[i].v) edge[i].w -= in[v]; } n = cnt; root = id[root]; } return ans; } int main(){ int n,m,root; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;root; //点数，边数，根节点序号 for(int i=1;i\u0026lt;=m;i++){ std::cin\u0026gt;\u0026gt;edge[i].u\u0026gt;\u0026gt;edge[i].v\u0026gt;\u0026gt;edge[i].w; //起点，终点，边权 } std::cout\u0026lt;\u0026lt;zhuliu(n,m,root)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 二分图判定 一张无向图是二分图，当且仅当图中不存在长度为奇数的环。\n我们可以用染色法来判定。假设染成两种颜色，一个节点被染色后，所有相连节点都应该染成另一种颜色，如果有冲突，则说明不是二分图。\n二分图匹配 最大匹配（匈牙利算法） //复杂度 nm //luogu p3386 //求二分图最大匹配，根据定理，最大匹配=最小点覆盖，以及最小边覆盖=点数-最大匹配 //二分图是\u0026#34;可以将点集分为两个不相交的部分，所有边连接的两个顶点在不同的部分中\u0026#34;的图 //二分图的匹配：边集的任意子集的任意两条边都没有公共顶点，则这个子集是一个匹配 //二分图的最大匹配：所有匹配中边数最多的 //最小点覆盖：选最少的点，满足每条边至少有一个端点被选 //最大独立集：选最多的点，满足两两之间没有边相连 //这里的二分图是无向图 //如果最大匹配中所有点都被匹配，那么叫做完美匹配 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; const int MAXN = 505; bool graph[MAXN][MAXN]; bool vis[MAXN]; int toLeft[MAXN];//标记右边节点i连到了哪个左边界点，即toLeft[i] bool match(int const \u0026amp; i, int const \u0026amp; rightNum){ for(int j=1;j\u0026lt;=rightNum;j++){ if(graph[i][j]\u0026amp;\u0026amp;!vis[j]){ vis[j] = true; if(toLeft[j]==0 || match(toLeft[j], rightNum)){ toLeft[j] = i; return true; } } } return false; } int hungarian(int const \u0026amp; leftNum, int const \u0026amp; rightNum){ //返回最大的边数 int cnt = 0; for(int i=1;i\u0026lt;=leftNum;i++){ std::memset(vis,0,sizeof(vis)); if(match(i,rightNum)) cnt++; } return cnt; } int main(){ int n,m,e;//左边点数，右边点数，边数 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;e; for(int i=1;i\u0026lt;=e;i++){ int x,y; std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y; graph[x][y] = true; } std::cout\u0026lt;\u0026lt;hungarian(n,m)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 二分图的相关定理 Konig定理：一个二分图中的最大匹配数等于这个图中的最小点覆盖数。\n最大独立集=点数-最小点覆盖。\n最大匹配转换为网络流模型 将源点连上左边所有点，右边所有点连上汇点，容量都为1。原来的每条边从左往右连边（转成了有向有容量图），容量也为1，最大流即最大匹配。用Dinic算法求复杂度为\\(O(\\sqrt nm)\\)\n二分图最大权完美匹配（KM算法） TODO: BFS版 //luogu p6577 //二分图的最大权匹配，必须是完美匹配才能正确运行，即左右各n个点，最大匹配有n条边。虽然KM算法必须是完美匹配才可以运行而转化为费用流则不需要，但是KM算法在稠密图上的效率会高于费用流 //随机数据O(n^3)，最坏O(n^4)，所以luogu p6577上会超时一些数据 //这主要是他卡dfs版的，bfs版的可以通过。但luogu p3967不卡dfs //最大权匹配指二分图中边权和最大的匹配，最大权匹配不一定是最大匹配 //如果要跑多次KM算法记得把toLeft数组初始化 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; typedef long long LL; const int MAXN = 505; const LL INF = 1e17; LL graph[MAXN][MAXN]; LL labelL[MAXN], labelR[MAXN]; bool visL[MAXN],visR[MAXN]; int toLeft[MAXN]; LL upd[MAXN]; bool match(int const \u0026amp; i, int const \u0026amp; pointNum){ visL[i] = true; for(int j=1;j\u0026lt;=pointNum;j++){ if(!visR[j]){ if(labelL[i]+labelR[j]-graph[i][j]==0){ visR[j] = true; if(!toLeft[j]||match(toLeft[j],pointNum)){ toLeft[j] = i; return true; } } else{ upd[j] = std::min(upd[j],labelL[i]+labelR[j]-graph[i][j]); } } } return false; } LL KM(int const \u0026amp; pointNum){ for(int i=1;i\u0026lt;=pointNum;i++){ labelL[i] = -INF; labelR[i] = 0; for(int j=1;j\u0026lt;=pointNum;j++) labelL[i] = std::max(labelL[i], graph[i][j]); } for(int i=1;i\u0026lt;=pointNum;i++){ while(true){ std::memset(visL,0,sizeof(visL)); std::memset(visR,0,sizeof(visR)); for(int j=1;j\u0026lt;=pointNum;j++) upd[j] = INF; if(match(i,pointNum)) break; LL delta = INF; for(int j=1;j\u0026lt;=pointNum;j++) if(!visR[j]) delta = std::min(delta,upd[j]); for(int j=1;j\u0026lt;=pointNum;j++){ if(visL[j]) labelL[j] -= delta; if(visR[j]) labelR[j] += delta; } } } LL ans = 0; for(int i=1;i\u0026lt;=pointNum;i++) ans += graph[toLeft[i]][i]; return ans;//输出最大权匹配的权值和 } int main(){ int n,e;//一边的点数；边数 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;e; for(int i=1;i\u0026lt;=n;i++){ for(int j=1;j\u0026lt;=n;j++){ graph[i][j] = -INF; } } for(int i=1;i\u0026lt;=e;i++){ int x,y; std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y; std::cin\u0026gt;\u0026gt;graph[x][y];//这里是左边有n个点，右边有n个点 //左边第x个点到右边第y个点的边权，并不是双向边 } std::cout\u0026lt;\u0026lt;KM(n)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; for(int i=1;i\u0026lt;=n;i++){ std::cout\u0026lt;\u0026lt;toLeft[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } std::cout\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 最大权匹配转化为费用流 新增一个源点和一个汇点，从源点向二分图的每个左部点连一条流量为1，费用为0的边；从每个右部点向汇点连一条流量为1，费用为0的边；从左部点i向右部点j连一条流量为1，费用为c的边。然后这些边的反向边也要注意连上。然后求这个网络的最大费用最大流即可。\n具体而言，最大费用的求法最好不要去该内部算法实现。把费用取相反数，然后最后答案再取相反数即可。\n如果要输出方案，就遍历右边点到左边点的反向边，如果实际流量w变为1了，则说明走了这条边，也就是这两个点配对。\n目前为止还只能处理完美匹配的情况。因为最大费用最大流是在最大流的前提下采取计算最大费用，也就是说它会去计算最大匹配再去计算其中的最大权。而最大权匹配是只要求权最大而不用一定是最大匹配。\n解决方法是把左部点连一条边到汇点，容量为1，费用为0，再去求最大费用最大流。这样如果这条边有实际流量通过（即w变成0），他是失配的。\n动态维护二分图判定 TODO: 例题 只判定一次可以用涂色法。动态加边可以用扩展域并查集（可撤销）来实现。\nstd::stack\u0026lt;pii\u0026gt; stk; class DSU{ public: int fa[MAXN*2], rk[MAXN*2]; void init(int n){ for(int i=1;i\u0026lt;=n;i++) fa[i] = i, rk[i] = 1; } int find(int x){ return fa[x]==x ? x : find(fa[x]); } void merge(int x, int y){ x = find(x), y = find(y); if(x==y) return; if(rk[x]\u0026gt;rk[y]) std::swap(x,y); fa[x] = y; stk.push({x,rk[x]==rk[y]});//保存操作记录，也可以用stack以外的数据结构 if(rk[x]==rk[y]) rk[y]++; } void erase(pii p){ rk[find(p.first)]-=p.second; fa[p.first] = p.first; } }; bool add(int x, int y){ //设总共n个点，每次添加一条边\u0026lt;x,y\u0026gt;，注意没有边也算二分图 dsu.merge(x,y+n); dsu.merge(y,x+n); if(dsu.find(x)==dsu.find(x+n) || dsu.find(y)==dsu.find(y+n)){ //说明不是二分图 return false; } else{ //说明是二分图 return true; } } //删边的时候，需要注意用一个pii删（调用erase函数），first保存了\u0026lt;x,y\u0026gt;这条边的x（y可以用find函数找出来），second保存了秩的数据，在删边时有用。至于删完是不是二分图，我没有找到办法。我做过的题目都是，添加了这条边后不再是二分图，输出某个结果，然后撤销这条边（之后显然是二分图）。要不就是只有加边的。直接删去任意一条边的题目并没有遇到过。 网络流 最大流 DFS实现的Ford-Fulkerson //luogu 3376 //复杂度O(ef)，边数乘以最大流，所以在luogu上这题超时 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; typedef long long LL; const int MAXN = 205; const LL INF = 0xffffffff; struct Edge{ int v;LL w;//指向的点，容量 Edge(int v_, LL w_):v(v_),w(w_){} }; std::vector\u0026lt;Edge\u0026gt; edges; std::vector\u0026lt;std::vector\u0026lt;int\u0026gt; \u0026gt; graph(MAXN);//vector版的链式前向星 bool vis[MAXN]; LL DFS(int const \u0026amp; p, LL const \u0026amp; flow, int const \u0026amp; s, int const \u0026amp; t){ if(p==t) return flow; vis[p] = true; int size = graph[p].size(); for(int i=0 ; i\u0026lt;size ; i++){ int eg = graph[p][i]; int to = edges[eg].v; LL vol = edges[eg].w, c; if(vol\u0026gt;0 \u0026amp;\u0026amp; !vis[to] \u0026amp;\u0026amp; (c=DFS(to,std::min(flow,vol),s,t))!=-1){ edges[eg].w -= c; edges[eg^1].w += c; return c; } } return -1; } LL FF(int const \u0026amp; p, LL const \u0026amp; flow, int const \u0026amp; s, int const \u0026amp; t){ LL ans = 0, c; while((c=DFS(p,flow,s,t))!=-1){ std::memset(vis,0,sizeof(vis)); ans += c; } return ans; } int main(){ int n,m,s,t;//点数，边数，源点，汇点 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s\u0026gt;\u0026gt;t; for(int i=1;i\u0026lt;=m;i++){ int u,v;LL w; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w;//起点，终点，边容量 graph[u].push_back(edges.size()); edges.push_back(Edge(v,w)); graph[v].push_back(edges.size()); edges.push_back(Edge(u,0)); } std::cout\u0026lt;\u0026lt;FF(s,INF,s,t)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;;//输出最大流 return 0; } EdmondsKarp //luogu P3376 //EK算法的时间复杂度为O(nm^2)，这题不会超时 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; typedef long long LL; const int MAXN = 205; const LL INF = 0xffffffff; struct Edge{ int v;LL w;//指向的点，容量 Edge(int v_, LL w_):v(v_),w(w_){} }; std::vector\u0026lt;Edge\u0026gt; edges; std::vector\u0026lt;std::vector\u0026lt;int\u0026gt; \u0026gt; graph(MAXN);//vector版的链式前向星 int last[MAXN]; LL flow[MAXN]; bool BFS(int const \u0026amp; s, int const \u0026amp; t){ std::memset(last,-1,sizeof(last)); std::queue\u0026lt;int\u0026gt; qu; qu.push(s); flow[s] = INF; while(!qu.empty()){ int p = qu.front(); qu.pop(); if(p == t) break; int size = graph[p].size(); for(int i=0;i\u0026lt;size;i++){ int eg = graph[p][i]; int to = edges[eg].v; LL vol = edges[eg].w; if(vol\u0026gt;0 \u0026amp;\u0026amp; last[to] == -1){ last[to] = eg; flow[to] = std::min(flow[p], vol); qu.push(to); } } } return last[t] != -1; } LL EK(int const \u0026amp; s, int const \u0026amp; t){ LL ans = 0; while(BFS(s,t)){ ans += flow[t]; for(int i=t;i!=s;i=edges[last[i]^1].v){ edges[last[i]].w -= flow[t]; edges[last[i]^1].w += flow[t]; } } return ans; } int main(){ int n,m,s,t;//点数，边数，源点，汇点 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s\u0026gt;\u0026gt;t; for(int i=1;i\u0026lt;=m;i++){ int u,v;LL w; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w; graph[u].push_back(edges.size()); edges.push_back(Edge(v,w)); graph[v].push_back(edges.size()); edges.push_back(Edge(u,0)); } std::cout\u0026lt;\u0026lt;EK(s,t)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } Dinic TODO: 如果可能换成链式前向星 //luogu P3376 //Dinic算法的时间复杂度为O(n^2m)，这题不会超时 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; typedef long long LL; const int MAXN = 205; const LL INF = 0xffffffff; struct Edge{ int v;LL w;//指向的点，容量 Edge(int v_, LL w_):v(v_),w(w_){} }; std::vector\u0026lt;Edge\u0026gt; edges; std::vector\u0026lt;std::vector\u0026lt;int\u0026gt; \u0026gt; graph(MAXN);//vector版的链式前向星 std::vector\u0026lt;int\u0026gt; cur(MAXN); int level[MAXN]; bool BFS(int s, int t){//BFS分层 std::memset(level, -1, sizeof(level)); level[s] = 0; cur.assign(MAXN,0);//初始化当前弧 std::queue\u0026lt;int\u0026gt; qu; qu.push(s); while(!qu.empty()){ int p = qu.front(); qu.pop(); int size = graph[p].size(); for(int i=0;i\u0026lt;size;i++){ int eg = graph[p][i]; int to = edges[eg].v; LL vol = edges[eg].w; if(vol\u0026gt;0 \u0026amp;\u0026amp; level[to] == -1){ level[to] = level[p] + 1; qu.push(to); } } } return level[t] != -1; } LL DFS(int const \u0026amp; p, LL const \u0026amp; flow, int const \u0026amp; s, int const \u0026amp; t){ if(p==t) return flow; LL surplus = flow;//剩余流量 int size = graph[p].size(); for(int i=cur[p];i\u0026lt;size \u0026amp;\u0026amp; surplus;i++){ int eg = graph[p][i]; cur[p] = i;//更新当前弧 int to = edges[eg].v; LL vol = edges[eg].w; if(vol\u0026gt;0 \u0026amp;\u0026amp; level[to]==level[p]+1){ LL c = DFS(to, std::min(vol, surplus), s, t); surplus -= c; edges[eg].w -= c; edges[eg^1].w += c; } } return flow - surplus; } LL Dinic(int const \u0026amp; p, LL const \u0026amp; flow, int const \u0026amp; s, int const \u0026amp; t){ LL ans = 0; while(BFS(s,t)){ ans += DFS(p,flow,s,t); } return ans; } int main(){ int n,m,s,t;//点数，边数，源点，汇点 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s\u0026gt;\u0026gt;t; for(int i=1;i\u0026lt;=m;i++){ int u,v;LL w; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w; graph[u].push_back(edges.size()); edges.push_back(Edge(v,w)); graph[v].push_back(edges.size()); edges.push_back(Edge(u,0)); } std::cout\u0026lt;\u0026lt;Dinic(s,INF,s,t)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } ISAP算法 TODO 最大流最小割定理 网络流的最大流等于其所有割的最小容量。\n割：从网络中选择一些边，去掉这些边后，剩下恰好两个互相不连通的分别包含源点和汇点的点集（当然其他边不去掉）。去掉的这些边就是一个割。\n割的大小就是去掉的这些边的容量之和。\n最小费用最大流 即在使流最大的前提下，最小化费用。费用是一条边的属性，一条边的总费用等于它的单位费用\\(\\times\\)流过的流量。\n建边的时候，反向边的容量为0，费用为相反数。\nEK+SPFA //luogu P3381 //EK+SPFA的实现，复杂度为O(nmf)，即点数、边数、最大流 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; typedef long long LL; typedef std::pair\u0026lt;LL,LL\u0026gt; pll; const int MAXN = 5005; const LL INF = 0xffffffff; struct Edge{ int v;LL w;LL c;//指向的点，容量，费用 Edge(int v_, LL w_, LL c_):v(v_),w(w_),c(c_){} }; std::vector\u0026lt;Edge\u0026gt; edges; std::vector\u0026lt;std::vector\u0026lt;int\u0026gt; \u0026gt; graph(MAXN);//vector版的链式前向星 int last[MAXN]; LL flow[MAXN]; LL dis[MAXN]; bool inq[MAXN]; bool SPFA(int s, int t){ std::queue\u0026lt;int\u0026gt; qu; qu.push(s); std::memset(last,-1,sizeof(last)); std::memset(dis,127,sizeof(dis)); std::memset(inq,0,sizeof(inq)); flow[s] = INF; dis[s] = 0; inq[s] = 1; while(!qu.empty()){ int p = qu.front(); qu.pop(); inq[p] = 0; int size = graph[p].size(); for(int i=0;i\u0026lt;size;i++){ int eg = graph[p][i]; int to = edges[eg].v; LL vol = edges[eg].w; if(vol\u0026gt;0 \u0026amp;\u0026amp; dis[to]\u0026gt;dis[p]+edges[eg].c){ last[to] = eg; flow[to] = std::min(flow[p], vol); dis[to] = dis[p]+edges[eg].c; if(!inq[to]){ qu.push(to); inq[to] = 1; } } } } return last[t] != -1; } pll MCMF(int s, int t){ LL maxflow = 0, mincost = 0; while(SPFA(s,t)){ maxflow += flow[t]; mincost += dis[t] * flow[t]; for(int i=t;i!=s;i=edges[last[i]^1].v){ edges[last[i]].w -= flow[t]; edges[last[i]^1].w += flow[t]; } } return {maxflow,mincost}; } int main(){ int n,m,s,t;//点数，边数，源点，汇点 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s\u0026gt;\u0026gt;t; for(int i=1;i\u0026lt;=m;i++){ int u,v;LL w,c; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w\u0026gt;\u0026gt;c; graph[u].push_back(edges.size()); edges.push_back(Edge(v,w,c)); graph[v].push_back(edges.size()); edges.push_back(Edge(u,0,-c)); } pll ans = MCMF(s,t); std::cout\u0026lt;\u0026lt;ans.first\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;ans.second\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } Dinic+SPFA //luogu P3381 //Dinic+SPFA的实现，复杂度为O(nmf)，即点数、边数、最大流 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; typedef long long LL; typedef std::pair\u0026lt;LL,LL\u0026gt; pll; const int MAXN = 5005; const LL INF = 0xffffffff; struct Edge{ int v;LL w,c;//指向的点，容量，费用 Edge(int v_, LL w_, LL c_):v(v_),w(w_),c(c_){} }; std::vector\u0026lt;Edge\u0026gt; edges; std::vector\u0026lt;std::vector\u0026lt;int\u0026gt; \u0026gt; graph(MAXN);//vector版的链式前向星 std::vector\u0026lt;int\u0026gt; cur(MAXN); LL dis[MAXN]; bool inq[MAXN]; bool SPFA(int s, int t){//BFS分层 std::fill(dis,dis+MAXN,INF); std::memset(inq, 0, sizeof(inq)); dis[s] = 0; inq[s] = 1; cur.assign(MAXN,0);//初始化当前弧 std::queue\u0026lt;int\u0026gt; qu; qu.push(s); while(!qu.empty()){ int p = qu.front(); qu.pop(); inq[p] = 0; int size = graph[p].size(); for(int i=0;i\u0026lt;size;i++){ int eg = graph[p][i]; int to = edges[eg].v; LL vol = edges[eg].w; if(vol\u0026gt;0 \u0026amp;\u0026amp; dis[to] \u0026gt; dis[p]+edges[eg].c){ dis[to] = dis[p]+edges[eg].c; if(!inq[to]){ qu.push(to); inq[to] = 1; } } } } return dis[t] != INF; } LL DFS(int const \u0026amp; p, LL const \u0026amp; flow, int const \u0026amp; s, int const \u0026amp; t){ if(p==t) return flow; LL surplus = flow;//剩余流量 inq[p] = 1;//由于在SPFA中都会清零，可以复用 int size = graph[p].size(); for(int i=cur[p];i\u0026lt;size \u0026amp;\u0026amp; surplus;i++){ int eg = graph[p][i]; cur[p] = i;//更新当前弧 int to = edges[eg].v; LL vol = edges[eg].w; if(!inq[to] \u0026amp;\u0026amp; vol\u0026gt;0 \u0026amp;\u0026amp; dis[to]==dis[p]+edges[eg].c){ LL cx = DFS(to, std::min(vol, surplus), s, t); surplus -= cx; edges[eg].w -= cx; edges[eg^1].w += cx; } } inq[p] = 0; return flow - surplus; } pll MCMF(int const \u0026amp; p, LL const \u0026amp; flow, int const \u0026amp; s, int const \u0026amp; t){ LL maxflow = 0, mincost = 0; while(SPFA(s,t)){ LL ret = DFS(p,flow,s,t); maxflow += ret; mincost += ret * dis[t]; } return {maxflow,mincost}; } int main(){ int n,m,s,t;//点数，边数，源点，汇点 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s\u0026gt;\u0026gt;t; for(int i=1;i\u0026lt;=m;i++){ int u,v;LL w,c; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w\u0026gt;\u0026gt;c; graph[u].push_back(edges.size()); edges.push_back(Edge(v,w,c)); graph[v].push_back(edges.size()); edges.push_back(Edge(u,0,-c)); } pll ans = MCMF(s,INF,s,t); std::cout\u0026lt;\u0026lt;ans.first\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;ans.second\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 上下界流 无源汇上下界可行流 给定一个没有源点和汇点的网络，每条边的容量都有一个上界和下界，问是否有一个可行流使得流量平衡（即每个点的流入等于流出）。\n//loj 115 //前面的Dinic算法省略 LL in[MAXN]; int main() { int n, m, s, t; //点数，边数，源点，汇点 std::cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; m; s = n + 1;//虚拟源点 t = n + 2;//虚拟汇点 std::vector\u0026lt;LL\u0026gt; ans; for (int i = 1; i \u0026lt;= m; i++) { int u, v; LL w1, w2;//下界，上界 std::cin \u0026gt;\u0026gt; u \u0026gt;\u0026gt; v \u0026gt;\u0026gt; w1 \u0026gt;\u0026gt; w2; ans.push_back(w1); graph[u].push_back(edges.size()); edges.push_back(Edge(v, w2 - w1));//只用建立差网络即可 graph[v].push_back(edges.size()); edges.push_back(Edge(u, 0)); in[u] -= w1; in[v] += w1; } for (int i = 1; i \u0026lt;= n; i++) { if (in[i] \u0026gt; 0) {//在下界网络中，有净流入的节点，要从源点连一条边，大小等于净流入 graph[s].push_back(edges.size()); edges.push_back(Edge(i, in[i])); graph[i].push_back(edges.size()); edges.push_back(Edge(s, 0)); } else {//有净流出的节点，要向汇点连一条边，大小等于净流出 graph[i].push_back(edges.size()); edges.push_back(Edge(t, -in[i])); graph[t].push_back(edges.size()); edges.push_back(Edge(i, 0)); } } Dinic(s, INF, s, t); for (auto x : graph[s]) { if (edges[x].w != 0) { //如果源点的附加边没有满流，说明不存在可行流 //也可以换成判断汇点没有满流，二者等价 std::cout \u0026lt;\u0026lt; \u0026#34;NO\\n\u0026#34;; return 0; } } std::cout \u0026lt;\u0026lt; \u0026#34;YES\\n\u0026#34;; for (int i = 1; i \u0026lt; 2 * m; i += 2) { //反向边就是这条边的流量，再加之前输入的下界得到每条边的流量 ans[i / 2] += edges[i].w; } for (auto x : ans) { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; } return 0; } 有源汇上下界可行流 比起无源汇的情况，我们可以把图中的汇点向源点连一条下界0，上界无限大的边。然后就变成无源汇图了。处理的时候，新建附加源点汇点\\(S',T'\\)，原来的\\(S,T\\)就变成了普通点，思路一致。\n若有解，则\\(S\\)到\\(T\\)的可行流流量等于\\(T\\)到\\(S\\)的附加边的流量。\n有源汇上下界最大流 在有源汇上下界可行流有解的时候，\\(S\\)到\\(T\\)的可行流量就是\\(T\\)到\\(S\\)的附加边的流量。然后我们删去所有添加的附加边，包括\\(S',T'\\)连的以及\\(T-S\\)附加边，再在跑完的网络上再跑一次Dinic，得到的流加上可行流就是最后的答案。\n具体实践上，我们不需要真的把边删了，\\(S',T'\\)所连的边根本不会影响结果，可以不用管，至于\\(T-S\\)这条边，我们获取了流量之后，直接把正向、反向边置零即可。\n//loj 116 //前面的Dinic算法省略 LL in[MAXN]; int main() { int n, m, s, t; //点数，边数，源点，汇点 std::cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; m \u0026gt;\u0026gt; s \u0026gt;\u0026gt; t; for (int i = 1; i \u0026lt;= m; i++) { int u, v; LL w1, w2; std::cin \u0026gt;\u0026gt; u \u0026gt;\u0026gt; v \u0026gt;\u0026gt; w1 \u0026gt;\u0026gt; w2; graph[u].push_back(edges.size()); edges.push_back(Edge(v, w2 - w1)); graph[v].push_back(edges.size()); edges.push_back(Edge(u, 0)); in[u] -= w1; in[v] += w1; } graph[t].push_back(edges.size()); edges.push_back(Edge(s, INF * 4ll)); graph[s].push_back(edges.size()); edges.push_back(Edge(t, 0)); //T-S的边 int s2 = n + 1, t2 = n + 2; for (int i = 1; i \u0026lt;= n; i++) { if (in[i] \u0026gt; 0) { graph[s2].push_back(edges.size()); edges.push_back(Edge(i, in[i])); graph[i].push_back(edges.size()); edges.push_back(Edge(s2, 0)); } else { graph[i].push_back(edges.size()); edges.push_back(Edge(t2, -in[i])); graph[t2].push_back(edges.size()); edges.push_back(Edge(i, 0)); } } Dinic(s2, INF, s2, t2); for (auto x : graph[s2]) { if (edges[x].w != 0) { std::cout \u0026lt;\u0026lt; \u0026#34;please go home to sleep\\n\u0026#34;; return 0; } } LL flow = edges[2 * m + 1].w; edges[2 * m].w = 0, edges[2 * m + 1].w = 0; std::cout \u0026lt;\u0026lt; Dinic(s, INF, s, t) + flow \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; return 0; } 有源汇上下界最小流 和上面几乎一模一样，只需在拆掉附加边后，从汇点到源点跑一次Dinic，然后flow删去这个结果就得到最小流。Loj 117。\n割边（Tarjan算法） //复杂度 n+m //tarjan求割边，可以正确处理重边 //如果无向图中删掉某条边会使无向图的连通分量数增多，那么这条边叫割边 //luogu p1656 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;stack\u0026gt; #include \u0026lt;algorithm\u0026gt; const int MAXN = 20005; const int MAXM = 100005; int dfn[MAXN], low[MAXN], cnt=0; //dfn为对一个图进行dfs时，dfs的顺序序号 //low[x]为以下所有符合要求的节点的dfn中的最小值 //1.以x为根的子树的所有节点 //2.通过非dfs生成树上的边能够到达该子树的所有节点 struct Edge{ int v,next;//指向的点，边权，下一条边 }; Edge edges[MAXM*2];//存无向图记得开两倍 int head[MAXN],ecnt=1;//注意这个ecnt=1，这是用来方便in_edge判断的 bool bridges[MAXM*2];//判断一条边是不是割边 inline void add(int u, int v){ edges[++ecnt].v = v; edges[ecnt].next = head[u]; head[u] = ecnt; } void tarjan(int u, int in_edge){ low[u] = dfn[u] = ++cnt; for(int i=head[u];i;i=edges[i].next){ int v = edges[i].v; if(!dfn[v]){ tarjan(v,i); low[u] = std::min(low[u],low[v]); if(low[v]\u0026gt;dfn[u])//边u-v是割边的充要条件 bridges[i] = bridges[i^1] = true; } else if(i != (in_edge ^ 1)){ low[u] = std::min(low[u], dfn[v]); } } } int main(){ int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; //点数，边数 for(int i=1;i\u0026lt;=m;i++){ int a,b; std::cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b; //起点，终点 add(a,b); add(b,a); //无向图 } for(int i=1;i\u0026lt;=n;i++){ if(!dfn[i]) tarjan(i,0); } std::vector\u0026lt;std::pair\u0026lt;int,int\u0026gt; \u0026gt; ans; for(int i=2;i\u0026lt;ecnt;i+=2){ if(bridges[i]){ int u = edges[i].v; int v = edges[i^1].v; if(u\u0026gt;v) std::swap(u,v); ans.push_back({u,v}); } } std::sort(ans.begin(),ans.end()); for(auto x:ans) std::cout\u0026lt;\u0026lt;x.first\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;x.second\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 割点（Tarjan算法） //复杂度 n+m //tarjan求割点,luogu P3388 //如果无向图中删掉某个点和其所有相连的边边会使无向图的连通分量数增多，那么这个点叫割点 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;stack\u0026gt; #include \u0026lt;algorithm\u0026gt; const int MAXN = 20005; const int MAXM = 100005; int dfn[MAXN], low[MAXN], cnt=0; //含义见割边模板 struct Edge{ int v,next;//指向的点，边权，下一条边 }; Edge edges[MAXM*2];//存无向图记得开两倍 int head[MAXN],ecnt;//这个ecnt和割边那里不一样，但也可以等于1 bool cut[MAXN];//判断割点 inline void add(int u, int v){ edges[++ecnt].v = v; edges[ecnt].next = head[u]; head[u] = ecnt; } void tarjan(int u, int root){ int tot = 0; low[u] = dfn[u] = ++cnt; for(int i=head[u];i;i=edges[i].next){ int v = edges[i].v; if(!dfn[v]){ tarjan(v,root); low[u] = std::min(low[u],low[v]); //一个点x是割点的充要条件是，它至少一个子节点y满足dfn[x]\u0026lt;=low[y]，特别的，对于根节点，需要至少两个这样的子节点 if(low[v]\u0026gt;=dfn[u]){ tot++; if(u!=root || tot\u0026gt;1) cut[u] = true; } } else{ low[u] = std::min(low[u], dfn[v]); } } } int main(){ int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; //点数，边数 for(int i=1;i\u0026lt;=m;i++){ int a,b; std::cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b; //起点，终点 add(a,b); add(b,a); //无向图 } for(int i=1;i\u0026lt;=n;i++){ if(!dfn[i]) tarjan(i,i); } std::vector\u0026lt;int\u0026gt; ans; for(int i=1;i\u0026lt;=n;i++) if(cut[i]) ans.push_back(i); std::sort(ans.begin(),ans.end()); std::cout\u0026lt;\u0026lt;ans.size()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; for(auto x:ans) std::cout\u0026lt;\u0026lt;x\u0026lt;\u0026lt;\u0026#34; \u0026#34;; return 0; } 强连通分量（Tarjan算法） //强连通分量，复杂度 n+m //luogu P2863 //一个有向图是强连通的当且仅当其中任意两个顶点相互可达 //强连通分量是有向图中的极大的强连通子图。极大意味着把一个图分为若干个强连通分量，分量之间互相不可达。或者，不存在包含该子图的更大的子图也是强连通分量。 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;stack\u0026gt; const int MAXN = 10005; const int MAXM = 50005; int dfn[MAXN], low[MAXN], instk[MAXN], scci[MAXN], cnt=0, cscc=0; std::vector\u0026lt;int\u0026gt; edges[MAXN]; std::stack\u0026lt;int\u0026gt; stk; std::vector\u0026lt;int\u0026gt; scc[MAXN]; //dfn是dfs时的顺序的序号 //stk中存入两类点，访问到节点x时 //1.搜索树上x的祖先节点 //2.已经访问过，并且存在一条路径到达x祖先的节点 //low[x]定义为满足以下两个条件的节点的最小dfn //1.该点在stk中 //2.存在一条从subtree(x)出发的有向边，以该点为终点 //scci[x]代表，x这个结点在第几个分量中 //cscc代表有几个分量 //scc[j]中表示，第j个分量的所有节点 void tarjan(int u){ low[u] = dfn[u] = ++cnt; instk[u] = 1; stk.push(u); for(int i=0;i\u0026lt;edges[u].size();i++){ int v = edges[u][i]; if(!dfn[v]){ tarjan(v); low[u] = std::min(low[u],low[v]); } else if(instk[v]){ low[u] = std::min(low[u], dfn[v]); } } if(low[u]==dfn[u]){ int top; cscc++; do{ top = stk.top(); stk.pop(); instk[top] = 0; scci[top] = cscc; scc[cscc].push_back(top); }while(top!=u); } } int main(){ int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; for(int i=1;i\u0026lt;=m;i++){ int a,b; std::cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b; edges[a].push_back(b);//有向边 } for(int i=1;i\u0026lt;=n;i++){ if(!dfn[i]) tarjan(i);//注意遍历所有dfn为零的点 } int ans = 0; for(int i=1;i\u0026lt;=cscc;i++){ if(scc[i].size()\u0026gt;1) ans++; } std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 2-SAT问题 //2-SAT算法，复杂度n+m //luogu P4782 //2-SAT是用来解决一些条件是否能够满足的算法。 //每个条件都能转化为形如\u0026#34;若x赋值为a，则y必须赋值为b\u0026#34;的形式。其中a,b的取值只能有两个，通常是true和false。 //例如总共有m个这样的条件，我们要判断是否存在一种赋值情况满足所有的条件。如果有还要输出一种可行方案 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;stack\u0026gt; const int MAXN = 2e6+5; int dfn[MAXN], low[MAXN], instk[MAXN], scci[MAXN], cnt=0, cscc=0; std::vector\u0026lt;int\u0026gt; edges[MAXN]; std::stack\u0026lt;int\u0026gt; stk; std::vector\u0026lt;int\u0026gt; scc[MAXN]; //含义见强连通分量tarjan算法 bool ans[MAXN]; void tarjan(int u){ low[u] = dfn[u] = ++cnt; instk[u] = 1; stk.push(u); for(int i=0;i\u0026lt;edges[u].size();i++){ int v = edges[u][i]; if(!dfn[v]){ tarjan(v); low[u] = std::min(low[u],low[v]); } else if(instk[v]){ low[u] = std::min(low[u], dfn[v]); } } if(low[u]==dfn[u]){ int top; cscc++; do{ top = stk.top(); stk.pop(); instk[top] = 0; scci[top] = cscc; scc[cscc].push_back(top); }while(top!=u); } } int main(){ int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; //n个点，m个条件 while(m--){ int i,j; bool a,b; std::cin\u0026gt;\u0026gt;i\u0026gt;\u0026gt;a\u0026gt;\u0026gt;j\u0026gt;\u0026gt;b; //本题的条件为，i为a或（不是异或）j为b，其他题按情况处理 //每个点x拆为两个点y和y+n,y代表x为0，y+n代表x为1 //每条边x-\u0026gt;y代表着，如果x，那么一定有y //本题如“i为假或j为真”可以拆为两个条件，这个条件满足（为真）时 //i为真则j一定为真 //j为假则i一定为假 edges[i+(!a)*n].push_back(j+b*n); edges[j+(!b)*n].push_back(i+a*n);//逆否命题 //逆否命题是一定要插入的，不能只插入原命题，但是本题拆出来的两个条件正好互为逆否命题，所以只插入了两条边。其他题并不一定总会给出逆否命题 //这里的逻辑运算可能有些不容易理解，怕错可以写成很长的if else判断a和b的具体取值 } for(int i=1;i\u0026lt;=2*n;i++){ if(!dfn[i]) tarjan(i);//注意遍历所有dfn为零的点 } for(int i=1;i\u0026lt;=n;i++){ if(scci[i]==scci[i+n]){//如果i和i+n在一个强连通分量，则不可满足 std::cout\u0026lt;\u0026lt;\u0026#34;IMPOSSIBLE\\n\u0026#34;; return 0; } else if(scci[i]\u0026gt;scci[i+n]) ans[i] = 1; else ans[i] = 0; } std::cout\u0026lt;\u0026lt;\u0026#34;POSSIBLE\\n\u0026#34;; for(int i=1;i\u0026lt;=n;i++){ std::cout\u0026lt;\u0026lt;ans[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } return 0; } 边双联通分量 //复杂度 n+m //tarjan求边双联通分量 //luogu p8436 //如果一张无向连通图不存在割边，则称之为边双联通图 //双连通分量是图的极大双联通子图 //若u-v边双联通，v-w边双联通，则u-w边双联通 //一张图是边双联通，当且仅当每条边都在至少一个简单环中 //无向连通图中，对于任意两个点，如果无论删去哪条边（只能一条），都不能使它们不连通，则为边双联通 //同时这也意味着，把割边删去后的图，就是若干个双联通分量 /*这一段是求割边的核心代码，省略*/ int dcci[MAXN], cdcc;//记录点i属于双联通分量dcci[i]，以及总的dcc个数 std::vector\u0026lt;std::vector\u0026lt;int\u0026gt; \u0026gt; dcc(MAXN);//存储双联通分量dcc[i]中有哪些点 void getDCC(int u){ dcci[u] = cdcc; dcc[cdcc].push_back(u); for(int i=head[u];i;i=edges[i].next){ int v = edges[i].v; if(dcci[v] || bridges[i]) continue; getDCC(v); } } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; //点数，边数 for(int i=1;i\u0026lt;=m;i++){ int a,b; std::cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b; //起点，终点 add(a,b); add(b,a); //无向图 } for(int i=1;i\u0026lt;=n;i++){ if(!dfn[i]) tarjan(i,0); } //以上求完了割边 for(int i=1;i\u0026lt;=n;i++){ if(!dcci[i]){ cdcc++; getDCC(i); } } std::cout\u0026lt;\u0026lt;cdcc\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; for(int i=1;i\u0026lt;=cdcc;i++){ std::cout\u0026lt;\u0026lt;dcc[i].size()\u0026lt;\u0026lt;\u0026#34; \u0026#34;; for(auto x:dcc[i]){ std::cout\u0026lt;\u0026lt;x\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } std::cout\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } 边双联通缩点TODO 点双联通分量 //复杂度 n+m //tarjan求点双联通分量 //luogu p8435 //如果一张无向连通图不存在割点，则称之为点双联通图 //双连通分量是图的极大双联通子图 //极大指的是，不存在包含这个子图的更大的子图也是边双联通图 //若u-v点双联通，v-w点双联通，则u-w[并不一定]点双联通 //一张图是点双联通，当且仅当以下两个条件之一成立 //1. 图的顶点数不超过2 //2. 图中任意两点都同时包含在至少一个简单环中 //无向连通图中，对于任意两个点，如果无论删去哪个点（只能一个，且不能删除这两个点自己），都不能使它们不连通，则为点双联通 //但是，虽然边双联通中的割边不属于任何连通分量，但割点却可以属于多个点双联通分量 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;stack\u0026gt; #include \u0026lt;algorithm\u0026gt; const int MAXN = 500005; const int MAXM = 2000005; int dfn[MAXN], low[MAXN], cnt=0; //含义见割边模板 struct Edge{ int v,next;//指向的点，边权，下一条边 }; Edge edges[MAXM*2];//存无向图记得开两倍 int head[MAXN],ecnt;//这个ecnt和割边那里不一样，但也可以等于1 bool cut[MAXN];//判断割点 inline void add(int u, int v){ edges[++ecnt].v = v; edges[ecnt].next = head[u]; head[u] = ecnt; } std::stack\u0026lt;int\u0026gt; stk; int cdcc; std::vector\u0026lt;std::vector\u0026lt;int\u0026gt; \u0026gt; dcc(MAXN); void tarjan(int u, int root){ low[u] = dfn[u] = ++cnt; stk.push(u); if(u==root \u0026amp;\u0026amp; head[u]==0){ dcc[++cdcc].push_back(u); return; } int tot=0; for(int i=head[u];i;i=edges[i].next){ int v = edges[i].v; if(!dfn[v]){ tarjan(v,root); low[u] = std::min(low[u],low[v]); if(low[v]\u0026gt;=dfn[u]){ tot++; if(u!=root || tot\u0026gt;1) cut[u] = true; cdcc++; int z; do{ z = stk.top(); stk.pop(); dcc[cdcc].push_back(z); }while(z!=v); dcc[cdcc].push_back(u); } } else{ low[u] = std::min(low[u], dfn[v]); } } } int main(){ int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; //点数，边数 for(int i=1;i\u0026lt;=m;i++){ int a,b; std::cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b; //起点，终点 if(a==b) continue;//点双联通需要注意排除自环才能处理孤立点 add(a,b); add(b,a); //无向图 } for(int i=1;i\u0026lt;=n;i++){ if(!dfn[i]) tarjan(i,i); } std::cout\u0026lt;\u0026lt;cdcc\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; for(int i=1;i\u0026lt;=cdcc;i++){ std::cout\u0026lt;\u0026lt;dcc[i].size()\u0026lt;\u0026lt;\u0026#34; \u0026#34;; for(auto x:dcc[i]) std::cout\u0026lt;\u0026lt;x\u0026lt;\u0026lt;\u0026#34; \u0026#34;; std::cout\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } 点双联通缩点TODO 树的直径 //树的直径，复杂度n //poj1985，输出树上最长路径的长度，即树的直径 //两遍dfs版可以求出路径上的点，但树形dp的可以处理负边权问题 std::vector\u0026lt;pii\u0026gt; edges[MAXN];//first是v，second是w int dis[MAXN]; int far; void dfs(int u, int fa){ int size = edges[u].size(); for(int i=0;i\u0026lt;size;i++){ pii e = edges[u][i]; int v = e.first, w = e.second; if(v==fa) continue; dis[v] = dis[u]+w; if(dis[v]\u0026gt;dis[far]) far=v; dfs(v,u); } } void solve(){ int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; for(int i=1;i\u0026lt;=m;i++){ int u,v,w; char trash;//poj 1985的输入数据问题 std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w\u0026gt;\u0026gt;trash; edges[u].push_back(std::make_pair(v,w)); edges[v].push_back(std::make_pair(u,w)); } dfs(1,0); dis[far] = 0; dfs(far,0); std::cout\u0026lt;\u0026lt;dis[far]\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } //树的直径，复杂度n //poj1985，输出树上最长路径的长度，即树的直径 //两遍dfs版可以求出路径上的点，但树形dp的可以处理负边权问题 std::vector\u0026lt;pii\u0026gt; edges[MAXN];//first是v，second是w int dis[MAXN]; bool vis[MAXN]; int ans; void dp(int u){ vis[u] = 1; int size = edges[u].size(); for(int i=0;i\u0026lt;size;i++){ pii e = edges[u][i]; int v = e.first, w = e.second; if(vis[v]) continue; dp(v); ans = std::max(ans,dis[u]+dis[v]+w); dis[u] = std::max(dis[u],dis[v]+w); } } void solve(){ int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; for(int i=1;i\u0026lt;=m;i++){ int u,v,w; char trash;//poj 1985的输入数据问题 std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w\u0026gt;\u0026gt;trash; edges[u].push_back(std::make_pair(v,w)); edges[v].push_back(std::make_pair(u,w)); } dp(1); std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } 若树上所有边边权均为正，则树的所有直径中点重合。\n树的重心 计算无根树的每一个节点作为根时，其最大子树的大小。最大子树的大小最小的节点叫做树的重心。\n性质如下\n重心如果不唯一，则最多只有两个，且它们相邻。并且此时树有偶数个节点，可以被划分为两个大小相等的连通块，每个块各自包含一个重心。 以树的重心为根时，所有子树的大小都不超过整棵树的一半 树中所有点到某个点的距离之和中，到重心的距离之和是最小的。如果有两个重心，它们是并列最小的。反过来距离之和最小的点一定是重心。 两棵树通过一条边连成一棵树，则新树的重心在连接原来两颗树的重心的路径上。如果两棵树大小一样，那么重心就是两个连接点。 在一棵树上添加或删除一个叶节点，它的重心最多只移动一条边的距离。如果原树有奇数个节点，那么重心可能会增加一个，原重心仍然是重心。如果有偶数个节点，那么重心可能减少一个，另一个重心仍然是重心。 //复杂度 n //poj 1655 std::vector\u0026lt;int\u0026gt; edges[MAXN]; int sz[MAXN], mss[MAXN];//树的大小（含自己），最大子树大小（不含自己） std::vector\u0026lt;int\u0026gt; ctr;//存重心 void dfs(int u, int fa, int const n){//需要传入点的个数 sz[u] = 1, mss[u] = 0; int size = edges[u].size(); for(int e=0;e\u0026lt;size;e++){ int v = edges[u][e]; if(v==fa) continue; dfs(v,u,n); mss[u] = std::max(mss[u],sz[v]); sz[u] += sz[v]; } mss[u] = std::max(mss[u],n-sz[u]); if(mss[u]\u0026lt;=n/2) ctr.push_back(u); } 倍增求最近公共祖先 //复杂度 单次查询 logn 预处理 nlogn，常数小点的可以用重链剖分 //luogu P3379 //倍增求最近公共祖先 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;cstdio\u0026gt; int const MAXN = 500005; int const LOGN = 31; std::vector\u0026lt;int\u0026gt; edge[MAXN];//邻接表 int logn[MAXN]; int fa[MAXN][LOGN],deep[MAXN]; //fa[a][b]代表a的第2^b个祖先，deep是深度，根节点深度为1 void build(int u,int father){ fa[u][0] = father; deep[u] = deep[father]+1; for(int i=1;i\u0026lt;=logn[deep[u]];i++){ fa[u][i] = fa[fa[u][i-1]][i-1]; } for(auto v:edge[u]){ if(v==father) continue; build(v,u); } } int lca(int x,int y){ if(deep[x]\u0026gt;deep[y]) std::swap(x,y); //保证y比x深 while(deep[x]!=deep[y]){ y = fa[y][logn[deep[y]-deep[x]]]; } if(x==y) return x; for(int k=logn[deep[x]];k\u0026gt;=0;k--){ if(fa[x][k]!=fa[y][k]){ x = fa[x][k], y = fa[y][k]; } } return fa[x][0]; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m,s; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s; //点数，询问数，根节点序号 for(int i=2;i\u0026lt;=n;i++){ logn[i] = logn[i/2] + 1; //必须的初始化 } for(int i=1;i\u0026lt;=n-1;i++){ int a,b; std::cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b; //读入树 edge[a].push_back(b); edge[b].push_back(a); } build(s,0);//必须build才能用 for(int i=1;i\u0026lt;=m;i++){ int x,y; std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y; //查询x,y的最近公共祖先 std::cout\u0026lt;\u0026lt;lca(x,y)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } 虚树 TODO 点分治 //点分治 复杂度nlog^2n //poj 1741 //查询树上长度小于等于k的路径的数量 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cmath\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;map\u0026gt; #include \u0026lt;set\u0026gt; #include \u0026lt;queue\u0026gt; #include \u0026lt;stack\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;cstdio\u0026gt; int const MAXN = 10007; struct Edge{ int v,w,next;//指向的点，边权，下一条边 }; Edge edges[MAXN*2]; int head[MAXN],cnt; inline void add(int u, int v, int w){ edges[++cnt].w = w; edges[cnt].v = v; edges[cnt].next = head[u]; head[u] = cnt; } int sz[MAXN], mss[MAXN];//树的大小（含自己），最大子树大小（不含自己） int ctr=-1;//重心 bool del[MAXN];//这个点是否在分治的时候被删除 void dfsCtr(int u, int fa, int const n){//需要传入树的点的个数 //执行完后ctr为本子树的重心 sz[u] = 1, mss[u] = 0; for(int e=head[u];e;e=edges[e].next){ int v = edges[e].v; if(v==fa || del[v]) continue; dfsCtr(v,u,n); if(ctr!=-1) return; mss[u] = std::max(mss[u],sz[v]); sz[u] += sz[v]; } mss[u] = std::max(mss[u],n-sz[u]); if(mss[u]\u0026lt;=n/2) ctr = u, sz[fa] = n-sz[u];//注意要改编sz以保证复杂度正确 } int dis[MAXN];//dis[x]存储点x到根root的距离 int indexx[MAXN];//要对节点编号按照dis进行排序，indexx[0]代表元素个数 int belong[MAXN];//判断子树节点属于哪一个子子树 int cntsame[MAXN];//查询[l,r]时，维护[l+1,r]中belong与l的belong相同的个数，见calc函数 bool cmp(int x,int y){return dis[x]\u0026lt;dis[y];} void dfsDis(int u, int fa, int from){ //获得子树到根节点的距离，from用于计算belong indexx[++indexx[0]] = u; belong[u] = from; for(int e=head[u];e;e=edges[e].next){ int v = edges[e].v, w = edges[e].w; if(v==fa || del[v]) continue; dis[v] = dis[u] + w; cntsame[from]++; dfsDis(v,u,from); } } int calc(int u,int k){ indexx[0] = 0; indexx[++indexx[0]] = u; belong[u] = u; dis[u] = 0; cntsame[u] = 1; for(int e=head[u];e;e=edges[e].next){ int v = edges[e].v, w =edges[e].w; if(del[v]) continue; dis[v] = dis[u] + w; cntsame[v] = 1; dfsDis(v,u,v); } std::sort(indexx+1,indexx+1+indexx[0],cmp); int l=1, r=indexx[0],ans=0; while(l\u0026lt;r){ int x = indexx[l], y = indexx[r]; if(dis[x]+dis[y]\u0026gt;k){ cntsame[belong[y]]--;//把cntsame由[l,r]转移,r-1] r--; } else{ //显然，如果不考虑两个点在同一个子子树内，则l和l+1~r的每个点都满足dis[x]+dis[y]\u0026lt;=k //减去同子子树的情况，即减去[l+1,r]中和l拥有相同belong的点 cntsame[belong[x]]--;//把cntsame由[l,r]转移到[l+1,r]，一定要注意顺序 ans += r-l-cntsame[belong[x]]; l++; } } return ans; } int res = 0; void divide(int u, int k){ del[u] = 1; res += calc(u,k); for(int e=head[u];e;e=edges[e].next){ int v = edges[e].v, w = edges[e].w; if(del[v]) continue; ctr = -1; dfsCtr(v,0,sz[v]); divide(ctr,k); } } void solve(int n, int k){ for(int i=1;i\u0026lt;n;i++){ int u,v,w; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w; add(u,v,w); add(v,u,w); } dfsCtr(1,0,n); divide(ctr,k); std::cout\u0026lt;\u0026lt;res\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; ctr = -1; cnt = 0; res = 0; for(int i=1;i\u0026lt;=n;i++) head[i] = 0,del[i] = 0; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,k; while(std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;k){ if(n==0\u0026amp;\u0026amp;k==0) break; solve(n,k); } return 0; } 重链剖分 //树根节点的子节点中子树最大的为它的重子节点，其他的为轻子节点（整棵树的根节点是轻点，其他子树的根节点可轻可重） //节点连向其轻子节点的边叫轻边，否则叫重边 //节点数为n，则从任意节点向上到根节点，经过的轻边数不超过logn struct Node{ int fa, sz, dep, hson;//父节点、子树大小（包含自己）、深度、重子节点 int top;//链头，即所在的重链中深度最小的那个节点 }node[MAXN]; std::vector\u0026lt;int\u0026gt; edges[MAXN]; void dfs1(int u, int d=1){ //在dfs2之前先用dfs1 int size = 1, ma = 0; node[u].dep = d; for(auto v:edges[u]){ if(!node[v].dep){ dfs1(v,d+1); node[v].fa = u; size += node[v].sz; if(node[v].sz \u0026gt; ma){ node[u].hson = v, ma = node[v].sz; } } } node[u].sz = size; } void dfs2(int u){ //需要先把根节点的top设置为自己 for(auto v:edges[u]){ if(!node[v].top){ if(v==node[u].hson) node[v].top = node[u].top; else node[v].top = v; dfs2(v); } } } void cut(int r=1){ //进行树剖预处理 dfs1(r); node[r].top = r; dfs2(r); } 重链剖分求LCA //树剖求LCA，每次查询复杂度 logn，常数很小 //luogu p3379 int lca(int a, int b){ while(node[a].top!=node[b].top){ if(node[node[a].top].dep\u0026gt;node[node[b].top].dep) a = node[node[a].top].fa; else b = node[node[b].top].fa; } if(node[a].dep \u0026gt; node[b].dep) return b; return a; } 重链剖分+线段树维护树上路径点权和 //树剖维护树上路径的点权和，维护和查询一次复杂度 logn //luogu p3384 //树根节点的子节点中子树最大的为它的重子节点，其他的为轻子节点（整棵树的根节点是轻点，其他子树的根节点可轻可重） //节点连向其轻子节点的边叫轻边，否则叫重边 //节点数为n，则从任意节点向上到根节点，经过的轻边数不超过logn #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cmath\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; #define pb push_back #define mkp std::make_pair #define fi first #define se second using LL = long long; int const MAXN = 100005; int const INF = 0x7fffffff; LL MOD = 998244353; struct Node{ int fa, sz, dep, hson;//父节点、子树大小（包含自己）、深度、重子节点 int top;//链头，即所在的重链中深度最小的那个节点 int dfn, mdfn;//该节点的dfs序，该节点子树的最大dfs序 LL v;//点上的权 }node[MAXN]; int dfnmap[MAXN];//映射dfn对应的点编号 std::vector\u0026lt;int\u0026gt; edges[MAXN]; void dfs1(int u, int d=1){ //在dfs2之前先用dfs1 int size = 1, ma = 0; node[u].dep = d; for(auto v:edges[u]){ if(!node[v].dep){ dfs1(v,d+1); node[v].fa = u; size += node[v].sz; if(node[v].sz \u0026gt; ma){ node[u].hson = v, ma = node[v].sz; } } } node[u].sz = size; } int cnt=0; void dfs2(int u){ //需要先把根节点的top设置为自己 node[u].dfn = ++cnt; dfnmap[cnt] = u; if(node[u].hson!=0){ node[node[u].hson].top = node[u].top; dfs2(node[u].hson); } //采取这个改变的原因是，每棵子树的dfs序是连续的，根节点dfs序最小 //而如果我们强制先遍历重子节点，那么重链上的dfs序是连续的，并且链头dfs序最小。这样就能用线段树维护链上的信息了 for(auto v:edges[u]){ if(!node[v].top){ node[v].top = v; dfs2(v); } } node[u].mdfn = cnt; } void cut(int r){ dfs1(r); node[r].top = r; dfs2(r); } struct Nodest { int s,t;//该端点的起点和终点下标 LL tag, v; }; Nodest st[MAXN*4+2]; void build(int s, int t, int p){ st[p].s = s; st[p].t = t; if(s==t) { st[p].v = node[dfnmap[s]].v%MOD; st[p].tag = 0; return; } int m = s+((t-s)\u0026gt;\u0026gt;1); build(s,m,p*2); build(m+1,t,p*2+1); st[p].v = (st[p*2].v + st[p*2+1].v)%MOD; st[p].tag = 0; } void spreadTag(int p){ if(st[p].tag){ int s = st[p].s, t = st[p].t; int m = s+((t-s)\u0026gt;\u0026gt;1); st[p*2].v = (st[p*2].v + (m-s+1)*st[p].tag)%MOD; st[p*2+1].v = (st[p*2+1].v + (t-m)*st[p].tag)%MOD; st[p*2].tag = (st[p].tag + st[p*2].tag)%MOD; st[p*2+1].tag = (st[p].tag + st[p*2+1].tag)%MOD; st[p].tag=0; } } void update(int l, int r, int p, LL k){ int s = st[p].s, t = st[p].t; if(l\u0026lt;=s \u0026amp;\u0026amp; t\u0026lt;=r){ st[p].v = (st[p].v + (t-s+1) * k)%MOD; st[p].tag = (st[p].tag + k)%MOD; return; } spreadTag(p); int m = s+((t-s)\u0026gt;\u0026gt;1); if(l\u0026lt;=m) update(l, r, p*2, k); if(r\u0026gt;m) update(l, r, p*2+1, k); st[p].v = (st[p*2].v + st[p*2+1].v)%MOD; } LL query(int l, int r, int p){ int s = st[p].s, t = st[p].t; if(l\u0026lt;=s \u0026amp;\u0026amp; t\u0026lt;=r) return st[p].v%MOD; spreadTag(p); int m = s+((t-s)\u0026gt;\u0026gt;1); LL ret = 0; if(l\u0026lt;=m) ret = (ret + query(l,r,p*2))%MOD; if(r\u0026gt;m) ret = (ret + query(l,r,p*2+1))%MOD; return ret; } void update_path(int x, int y, LL k){ while(node[x].top != node[y].top){ if(node[node[x].top].dep \u0026gt; node[node[y].top].dep){ update(node[node[x].top].dfn, node[x].dfn, 1, k); x = node[node[x].top].fa; } else{ update(node[node[y].top].dfn, node[y].dfn, 1, k); y = node[node[y].top].fa; } } if(node[x].dep\u0026gt;node[y].dep){ update(node[y].dfn, node[x].dfn, 1, k); } else{ update(node[x].dfn, node[y].dfn, 1, k); } } LL query_path(int x, int y){ LL ans = 0; while(node[x].top != node[y].top){ if(node[node[x].top].dep \u0026gt; node[node[y].top].dep){ ans += query(node[node[x].top].dfn, node[x].dfn, 1); x = node[node[x].top].fa; } else{ ans += query(node[node[y].top].dfn, node[y].dfn, 1); y = node[node[y].top].fa; } } if(node[x].dep\u0026gt;node[y].dep){ ans += query(node[y].dfn, node[x].dfn, 1); } else{ ans += query(node[x].dfn, node[y].dfn, 1); } return ans%MOD; } void update_subtree(int x, LL k){ update(node[x].dfn, node[x].mdfn, 1, k); } LL query_subtree(int x){ return query(node[x].dfn, node[x].mdfn, 1)%MOD; } void solve(){ int n,m,r; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;r\u0026gt;\u0026gt;MOD;//节点个数，操作个数，根节点序号，取模数 for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;node[i].v; } for(int i=1;i\u0026lt;n;i++){ int x,y; std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y; edges[x].pb(y); edges[y].pb(x); } cut(r); build(1,n,1); while(m--){ int ope,x,y; LL z; std::cin\u0026gt;\u0026gt;ope; if(ope==1){ std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y\u0026gt;\u0026gt;z; update_path(x,y,z); } else if(ope==2){ std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y; std::cout\u0026lt;\u0026lt;query_path(x,y)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } else if(ope==3){ std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;z; update_subtree(x,z); } else if(ope==4){ std::cin\u0026gt;\u0026gt;x; std::cout\u0026lt;\u0026lt;query_subtree(x)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } } } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int T; T=1; while(T--){ solve(); } return 0; } 长链剖分 求K级祖先 //长链剖分定义子树最深深度最深的节点为重子节点 //任意节点p的k级祖先q所在的链长度一定大于k //任意节点p到根节点最多经过sqrt n级别的轻边 //luogu p5903 //求任意节点的第k级祖先，预处理nlogn，查询常数 #define pb push_back using LL = long long; int const MAXN = 500005; struct Node{ int fa, dep, hson;//父节点、深度、重子节点 int top;//链头，即所在的长链中深度最小的那个节点 int len,dfn,mdfn;//部分链长，dfs序，子树最大dfs序 }node[MAXN]; int dfnmap[MAXN];//dfs序对应节点 std::vector\u0026lt;int\u0026gt; edges[MAXN]; void dfs1(int u, int d=1){ node[u].len = 1, node[u].dep = d; for(auto v:edges[u]){ if(!node[v].dep){ dfs1(v,d+1); node[v].fa = u; if(node[v].len+1\u0026gt;node[u].len) node[u].hson = v, node[u].len = node[v].len+1; } } } int cnt = 0; void dfs2(int u, int tp){ node[u].dfn = ++cnt; node[u].top = tp; dfnmap[cnt] = u; if(node[u].hson) dfs2(node[u].hson, tp); for(auto v:edges[u]){ if(!node[v].top) dfs2(v,v); } node[u].mdfn = cnt; } void cut(int r=1){ dfs1(r); dfs2(r,r); } std::vector\u0026lt;int\u0026gt; anc[MAXN], des[MAXN]; //分别存储（链头）节点p的1,2,...,node[p].len-1级祖先节点和子孙节点 int const LOGN = 21; int fa[MAXN][LOGN]; int logn[MAXN]; void init(int r, int n){ cut(r); logn[1] = 0; logn[2] = 1; for(int i=3;i\u0026lt;MAXN;i++){ logn[i] = logn[i/2]+1; //预先计算logn } for(int i=1;i\u0026lt;=n;i++) fa[i][0] = node[i].fa; for(int j=1;j\u0026lt;LOGN;j++){ for(int i=1;i\u0026lt;=n;i++){ fa[i][j] = fa[fa[i][j-1]][j-1]; } } for(int i=1;i\u0026lt;=n;i++){ if(node[i].top==i){ for(int j=0,p=i;j\u0026lt;node[i].len;j++,p=fa[p][0]) anc[i].pb(p); for(int j=0;j\u0026lt;node[i].len;j++) des[i].pb(dfnmap[node[i].dfn+j]); } } } int query(int u, int k){ //查询节点u的k级祖先 if(k==0) return u; int i = logn[k]; int v = fa[u][i]; int tp = node[v].top; int d = k - (1\u0026lt;\u0026lt;i) + node[tp].dep - node[v].dep; if(d\u0026gt;0) return anc[tp][d]; else return des[tp][-d]; } 计算几何 基础板子 ///////////////////////////////////////////////// //数据类型定义 typedef double db; typedef long double LD; struct Point{db x,y;}; typedef Point Vec; struct Line{Point p; Vec v;};//点向式直线，不保证方向向量为单位向量 struct Seg{Point a,b;};//线段 struct Circle{Point o;db r;};//圆心和半径 ///////////////////////////////////////////////// //常数定义 Point const o{0.0,0.0};//原点 Line const ox{o,{1.0,0.0}}, oy{o,{0.0,1.0}};//横轴纵轴 db const PI = acos(-1); db const EPS = 1e-9; ///////////////////////////////////////////////// //可调整精度的比较 bool eq(db a, db b) {return std::abs(a - b)\u0026lt; EPS;}//等于 bool ge(db a, db b) {return a - b \u0026gt; EPS;}//大于 bool le(db a, db b) {return a - b \u0026lt; -EPS;}//小于 bool geq(db a, db b) {return a - b \u0026gt; -EPS;}//大于等于 bool leq(db a, db b) {return a - b \u0026lt; EPS;}//小于等于 int sgn(db x) { if (std::abs(x) \u0026lt; EPS) return 0; if (x \u0026lt; 0) return -1; return 1; } // 符号，等于零返回0，大于零返回1，小于零返回-1 ///////////////////////////////////////////////// //基础运算 Vec r90a(Vec v){return {-v.y, v.x};}//向量逆时针90度 Vec r90c(Vec v){return {v.y, -v.x};}//向量顺时针90度 Vec operator+(Vec a, Vec b){return {a.x+b.x, a.y+b.y};} Vec operator-(Vec a, Vec b){return {a.x-b.x, a.y-b.y};} Vec operator*(db k, Vec v){return {k*v.x, k*v.y};} Vec operator*(Vec v, db k){return {v.x*k, v.y*k};} db operator*(Vec a, Vec b){return a.x*b.x+a.y*b.y;} db operator^(Vec a, Vec b){return a.x*b.y-a.y*b.x;}//叉积 db len2(Vec v){return v.x*v.x+v.y*v.y;}//长度平方 db len(Vec v){return std::sqrt(len2(v));}//向量长度 db slope(Vec v){return v.y/v.x;}//斜率，不存在时，用后面的paral_y函数，不要判断是否是无穷 db radp(Point x, Point a, Point b){ // 返回xa, xb的夹角弧度 return fabs(atan2(fabs((a-x)^(b-x)), (a-x)*(b-x))); } ///////////////////////////////////////////////// //向量操作 db sin_v(Vec a, Vec b){return (a^b)/len(a)/len(b);}//向量内积，右手定则 db cos_v(Vec a, Vec b){return a*b/len(a)/len(b);}//向量夹角余弦 Vec norm(Vec v){return {v.x/len(v), v.y/len(v)};}//求其单位向量 Vec pnorm(Vec v){return (v.x\u0026lt;0?-1:1)/len(v)*v;}//与原向量平行且横坐标大于零的单位向量 Vec dvec(Seg l){return l.b-l.a;}//线段转化为向量（没有归一化） Vec trunc(Vec v, db r){ // v转化为长度为l的向量 db l = len(v); if(!sgn(l)) return v; r /= l; return v*r; } ///////////////////////////////////////////////// //直线操作 Line line(Point a, Point b){return {a,b-a};}//两点式直线 Line line(db k, db b){return {{0,b},{1,k}};}//斜截式直线y=kx+b Line line(Point p, db k){return {p,{1,k}};}//点斜式直线 Line line(Seg l){return {l.a, l.b-l.a};}//线段所在直线 db at_x(Line l, db x){return l.p.y+(x-l.p.x)*l.v.y/l.v.x;}//给定直线上的横坐标求纵坐标，要确保直线不与y轴平行 db at_y(Line l, db y){return l.p.x+(y+l.p.y)*l.v.x/l.v.y;}//与上相反 Point pedal(Point p, Line l){return l.p-(l.p-p)*l.v/(l.v*l.v)*l.v;}//求点到直线的垂足 Line perp(Line l, Point p){return {p,r90c(l.v)};}//过某点作直线的垂线 Line bisec(Point p, Vec a, Vec b){return {p,norm(a)+norm(b)};}//角平分线 ///////////////////////////////////////////////// //线段操作 Point midp(Seg l){return {(l.a.x+l.b.x)/2.0,(l.a.y+l.b.y)/2.0};}//线段中点 Line perp(Seg l){return {midp(l), r90c(l.b-l.a)};}//线段中垂线 ///////////////////////////////////////////////// //几何关系 bool verti(Vec a, Vec b){return eq(a*b,0.0);}//向量是否垂直 bool paral(Vec a, Vec b){return eq(a^b,0.0);}//向量是否平行 bool paral_x(Vec v){return eq(v.y,0.0);}//是否平行x轴 bool paral_y(Vec v){return eq(v.x,0.0);}//是否平行y轴 bool on(Point p, Line l){return eq((p.x-l.p.x)*l.v.y, (p.y-l.p.y)*l.v.x);}//点是否在直线上 bool on(Point p, Seg l){return eq(len(p-l.a)+len(p-l.b),len(l.a-l.b));}//点是否在线段上 //bool on(Point p, Seg l){return sgn((p-l.a)^(l.b-l.a))==0 \u0026amp;\u0026amp; sgn((p-l.a)*(p-l.b))\u0026lt;=0 ;}//点是否在线段上，无须len的判断法 int on(Point p, Circle c){//0圆外，1圆上，2圆内 db dst = len(p-c.o); if(sgn(dst-c.r)\u0026lt;0) return 2; if(sgn(dst-c.r)==0) return 1; return 0; } int on(Circle c1, Circle c2){ // 两圆关系，5相离、4外切、3相交、2内切、1内含 db d = len(c1.o-c2.o); if(sgn(d-c1.r-c2.r)\u0026gt;0) return 5; if(sgn(d-c1.r-c2.r)==0) return 4; db l = fabs(c1.r-c2.r); if(sgn(d-l)\u0026gt;0) return 3; if(sgn(d-l)==0) return 2; return 1; } bool operator==(Point a, Point b){return eq(a.x,b.x)\u0026amp;\u0026amp;eq(a.y,b.y);}//点重合 bool operator==(Line a, Line b){return on(a.p,b)\u0026amp;\u0026amp;on(a.p+a.v,b);}//直线重合 bool operator==(Seg a, Seg b){return ((a.a==b.a\u0026amp;\u0026amp;a.b==b.b)||(a.a==b.b\u0026amp;\u0026amp;a.b==b.a));}//线段（完全）重合 bool operator\u0026lt;(Point a, Point b){return le(a.x,b.x)||(eq(a.x,b.x)\u0026amp;\u0026amp;le(a.y,b.y));}//横坐标第一关键字，纵坐标第二关键字 bool tangency(Line l, Circle c){return eq(std::abs((c.o^l.v)-(l.p^l.v)),c.r*len(l.v));}//直线和圆是否相切 bool tangency(Circle c1, Circle c2){return eq(len(c1.o-c2.o),c1.r+c2.r);}//两个圆是否相切 ///////////////////////////////////////////////// //距离 db dis(Point a, Point b){return len(a-b);}//两点距离 db dis(Point p, Line l){return std::abs((p^l.v)-(l.p^l.v))/len(l.v);}//点到直线的距离 db dis(Line a, Line b){return std::abs((a.p^pnorm(a.v))-(b.p^pnorm(b.v)));}//两直线距离，需要确保平行 db dis(Point p, Seg s){ // 点到线段的距离 if(sgn(cos_v(p-s.a, s.b-s.a))\u0026lt;0 || sgn(cos_v(p-s.b, s.a-s.b))\u0026lt;0) return std::min(dis(p, s.a), dis(p, s.b)); return dis(p, line(s)); } db dis(Seg s1, Seg s2){ // 线段之间的距离，前提是不相交。相交时为0，需要自己判断 return std::min(std::min(dis(s1.a, s2), dis(s1.b, s2)), std::min(dis(s2.a, s1), dis(s2.b, s1))); } ///////////////////////////////////////////////// //平移 Line operator+(Line l, Vec v){return {l.p+v, l.v};}//直线平移 Seg operator+(Seg l, Vec v){return {l.a+v,l.b+v};}//线段平移 ///////////////////////////////////////////////// //旋转 Point rotate(Point p, db rad){return {cos(rad)*p.x-sin(rad)*p.y,sin(rad)*p.x+cos(rad)*p.y};}//绕原点旋转rad弧度 Point rotate(Point p, db rad, Point c){return c+rotate(p-c,rad);}//绕c旋转rad弧度 Line rotate(Line l, db rad, Point c=o){return {rotate(l.p,rad,c),rotate(l.v,rad)};}//直线绕c点旋转rad弧度 Seg rotate(Seg l, db rad, Point c=o){return {rotate(l.a,rad,c), rotate(l.b,rad,c)};}; ///////////////////////////////////////////////// //对称 Point reflect(Point a, Point p){return {p.x*2.0-a.x, p.y*2.0-a.y};}//a关于p的对称点 Line reflect(Line l, Point p){return {reflect(l.p,p),l.v};}//直线l关于p的对称直线 Seg reflect(Seg l, Point p){return {reflect(l.a,p),reflect(l.b,p)};}//线段l关于p的对称线段 Point reflect(Point a, Line ax){return reflect(a, pedal(a,ax));}//点a关于直线ax的对称点 Point reflect_v(Vec v, Line ax){return reflect(v,ax)-reflect(o,ax);}//向量v关于直线ax的对称向量 Line reflect(Line l, Line ax){return {reflect(l.p, ax),reflect_v(l.v, ax)};}//直线l关于直线ax的对称直线 Seg reflect(Seg l, Line ax){return {reflect(l.a, ax), reflect(l.b, ax)};} ///////////////////////////////////////////////// //交点 std::vector\u0026lt;Point\u0026gt; inter(Line a, Line b){ //两直线的交点，没有交点返回空vector，否则返回一个大小为1的vector // 不能重叠 db c = a.v^b.v; std::vector\u0026lt;Point\u0026gt; ret; if(eq(c,0.0)) return ret; Vec v = 1/c*Vec{a.p^(a.p+a.v), b.p^(b.p+b.v)}; ret.push_back({v*Vec{-b.v.x, a.v.x},v*Vec{-b.v.y, a.v.y}}); return ret; } std::vector\u0026lt;Point\u0026gt; inter(Seg s1, Seg s2) { // 两线段的交点，没有交点返回空vector，否则返回一个大小为1的vector // 这里特别规定，如果两条线段有重叠线段，会返回第一条线段的两个端点 std::vector\u0026lt;Point\u0026gt; ret; using std::max; using std::min; bool check = true; check = check \u0026amp;\u0026amp; geq(max(s1.a.x, s1.b.x), min(s2.a.x, s2.b.x)); check = check \u0026amp;\u0026amp; geq(max(s2.a.x, s2.b.x), min(s1.a.x, s1.b.x)); check = check \u0026amp;\u0026amp; geq(max(s1.a.y, s1.b.y), min(s2.a.y, s2.b.y)); check = check \u0026amp;\u0026amp; geq(max(s2.a.y, s2.b.y), min(s1.a.y, s1.b.y)); if (!check) return ret; db pd1 = (s2.a - s1.a) ^ (s1.b - s1.a); db pd2 = (s2.b - s1.a) ^ (s1.b - s1.a); if (sgn(pd1 * pd2) == 1) return ret; std::swap(s1, s2); // 双方都要跨立实验 pd1 = (s2.a - s1.a) ^ (s1.b - s1.a); pd2 = (s2.b - s1.a) ^ (s1.b - s1.a); if (sgn(pd1 * pd2) == 1) return ret; if (sgn(pd1) == 0 \u0026amp;\u0026amp; sgn(pd2) == 0) { ret.push_back(s2.a); ret.push_back(s2.a); return ret; } return inter(line(s2), line(s1)); } std::vector\u0026lt;Point\u0026gt; inter(Line l, Circle c){ //直线与圆的交点 Point p = pedal(c.o, l); db h = len(p-c.o); std::vector\u0026lt;Point\u0026gt; ret; if(ge(h,c.r)) return ret; if(eq(h,c.r)) {ret.push_back(p);return ret;}; db d = std::sqrt(c.r*c.r - h*h); Vec v = d/len(l.v)*l.v; ret.push_back(p-v);ret.push_back(p+v); return ret; } std::vector\u0026lt;Point\u0026gt; inter(Circle c1, Circle c2){ //两个圆的交点 Vec v1 = c2.o - c1.o, v2 = r90c(v1); db d = len(v1); std::vector\u0026lt;Point\u0026gt; ret; if(ge(d, c1.r+c2.r)||ge(std::abs(c1.r-c2.r),d)) return ret; if(eq(d, c1.r+c2.r)||eq(std::abs(c1.r-c2.r),d)){ret.push_back(c1.o+c1.r/d*v1);return ret;} db a = ((c1.r*c1.r-c2.r*c2.r)/d+d)/2.0; db h = std::sqrt(c1.r*c1.r-a*a); Vec av = a/len(v1)*v1, hv = h/len(v2)*v2; ret.push_back(c1.o+av+hv);ret.push_back(c1.o+av-hv); return ret; } ///////////////////////////////////////////////// //多边形相关 db area(std::vector\u0026lt;Point\u0026gt; const \u0026amp; ps){ // 逆时针排序的多边形的顶点，计算面积 db ret = 0.0; for(int i=0, sz=ps.size();i\u0026lt;sz;i++){ ret += (ps[i]^ps[(i+1)%sz])/2.0; } return ret; } bool isconvex(std::vector\u0026lt;Point\u0026gt; const \u0026amp; poly){ // 多边形是否为凸 std::vector\u0026lt;bool\u0026gt; s(3, false); for(int i=0, n=poly.size();i\u0026lt;n;i++){ int j = (i+1)%n; int k = (j+1)%n; s[sgn((poly[j]-poly[i])^(poly[k]-poly[i]))+1] = true; if(s[0] \u0026amp;\u0026amp; s[2]) return false; } return true; } int inpoly(std::vector\u0026lt;Point\u0026gt; const \u0026amp; poly, Point p){ // 一个点是否在多边形内？ // 0外部，1内部，2边上，3顶点上 int n=poly.size(); for(int i=0;i\u0026lt;n;i++){ if(poly[i]==p) return 3; } for(int i=0;i\u0026lt;n;i++){ if(on(p, Seg{poly[(i+1)%n],poly[i]})) return 2; } int cnt = 0; for(int i=0;i\u0026lt;n;i++){ int j = (i+1)%n; int k = sgn((p-poly[j])^(poly[i]-poly[j])); int u = sgn(poly[i].y-p.y); int v = sgn(poly[j].y-p.y); if(k\u0026gt;0 \u0026amp;\u0026amp; u\u0026lt;0 \u0026amp;\u0026amp; v\u0026gt;=0) cnt++; if(k\u0026lt;0 \u0026amp;\u0026amp; v\u0026lt;0 \u0026amp;\u0026amp; u\u0026gt;=0) cnt--; } return cnt != 0; } std::vector\u0026lt;Point\u0026gt; convexCut(std::vector\u0026lt;Point\u0026gt; const \u0026amp; ps, Point p1, Point p2){ // p1p2连成的直线，切开凸多边形，获得左半边的凸多边形 // 多边形逆时针，左半边指(p2-p1)向量的左半边 std::vector\u0026lt;Point\u0026gt; ret; int n = ps.size(); for(int i=0;i\u0026lt;n;i++){ Point q1 = ps[i], q2 = ps[(i+1)%n]; int d1 = sgn((p2-p1)^(q1-p1)), d2 = sgn((p2-p1)^(q2-p1)); if(d1\u0026gt;=0) ret.push_back(q1); if(d1*d2\u0026lt;0) ret.push_back(inter(line(q1,q2), line(p1,p2))[0]); } return ret; } ///////////////////////////////////////////////// //三角形四心 //可能都需要判断三点共线的情况 Point barycenter(Point a, Point b, Point c){ //重心 return {(a.x+b.x+c.x)/3.0, (a.y+b.y+c.y)/3.0}; } Point circumcenter(Point a, Point b, Point c){ //外心 db a2 = a*a, b2 = b*b, c2 = c*c; db d = 2.0*(a.x*(b.y-c.y)+b.x*(c.y-a.y)+c.x*(a.y-b.y)); return 1/d * r90c(a2*(b-c)+b2*(c-a)+c2*(a-b)); } Point incenter(Point a, Point b, Point c){ //内心 db a1 = len(b-c), b1 = len(a-c), c1 = len(a-b); db d = a1+b1+c1; return 1/d * (a1*a+b1*b+c1*c); } Point orthocenter(Point a, Point b, Point c){ //垂心 db n = b*(a-c), m = a*(b-c); db d = (b-c)^(a-c); return 1/d * r90c(n*(c-b)-m*(c-a)); } ///////////////////////////////////////////////// // 圆切线 std::vector\u0026lt;Line\u0026gt; tangentLine(Point p, Circle c){ // 过一点做圆的切线 std::vector\u0026lt;Line\u0026gt; ret; int x = on(p, c); if(x==2) return ret; if(x==1){ ret.push_back(line(p, p+r90a(p-c.o))); } db d = dis(p, c.o); db l = c.r*c.r/d; db h = std::sqrt(c.r*c.r-l*l); ret.push_back(line(p, c.o+(trunc(p-c.o,l)+trunc(r90a(p-c.o),h)))); ret.push_back(line(p, c.o+(trunc(p-c.o,l)+trunc(r90c(p-c.o),h)))); return ret; } std::vector\u0026lt;Seg\u0026gt; getTangent(Circle a, Circle b){ // 求两圆的公共切线，这里用切点的线段表示了 // 其中线段的a点代表圆a的切点 std::vector\u0026lt;Seg\u0026gt; ret; db dist=len(a.o-b.o); auto mul = [](Point a_, Point b_)-\u0026gt;Point{ return {a_.x*b_.x-a_.y*b_.y, a_.x*b_.y+a_.y*b_.x}; }; auto getInTangent = [\u0026amp;mul](Circle a_,Circle b_,db flg=1.0)-\u0026gt;Seg{ Point base=b_.o-a_.o; db w=a_.r+b_.r; db h=std::sqrt(len2(base)-w*w); Point k = mul(base, Point{w, h*flg})*(1.0/len2(base)); return Seg{a_.o+k*a_.r,b_.o-k*b_.r}; }; auto getOutTangent = [\u0026amp;mul](Circle a_,Circle b_,db flg=1.0)-\u0026gt;Seg{ Point base=b_.o-a_.o; db h=b_.r-a_.r; db w=std::sqrt(len2(base)-h*h); Point k = mul(mul(base, Point{w, h*flg})*(1.0/len2(base)), Point{0,flg}); return Seg{a_.o+k*a_.r,b_.o-k*b_.r}; }; if(dist\u0026gt;a.r+b.r+EPS) ret.push_back(getInTangent(a,b,1)); if(dist\u0026gt;a.r+b.r-EPS) ret.push_back(getInTangent(a,b,-1)); if(dist\u0026gt;std::abs(a.r-b.r)+EPS) ret.push_back(getOutTangent(a,b,1)); if(dist\u0026gt;std::abs(a.r-b.r)-EPS) ret.push_back(getOutTangent(a,b,-1)); return ret; } ///////////////////////////////////////////////// // 相交面积 db interArea(Circle c, Point a, Point b){ // 圆c和三角形c.o a b的相交面积 if(sgn((c.o-a)^(c.o-b))==0) return 0.0; Point q[5]; int len = 0; q[len++] = a; Line l = line(a, b); auto vec = inter(l, c); if(vec.size()==2){ if(sgn((a-vec[0])*(b-vec[0]))\u0026lt;0) q[len++] = vec[0]; if(sgn((a-vec[1])*(b-vec[1]))\u0026lt;0) q[len++] = vec[1]; } q[len++] = b; if(len==4 \u0026amp;\u0026amp; sgn((q[0]-q[1])*(q[2]-q[1]))\u0026gt;0) std::swap(q[1], q[2]); db res = 0.0; for(int i=0;i\u0026lt;len-1;i++){ if(on(q[i],c)==0||on(q[i+1],c)==0){ db arg = radp(c.o, q[i], q[i+1]); res += c.r*c.r*arg/2.0; } else{ res += fabs((q[i]-c.o)^(q[i+1]-c.o))/2.0; } } return res; } db interArea(Circle c, std::vector\u0026lt;Point\u0026gt; const\u0026amp; poly){ // 多边形和圆相交面积 db ans = 0.0; for(int i=0, sz=poly.size();i\u0026lt;sz;i++){ int j = (i+1)%sz; db ar = interArea(c, poly[i], poly[j]); if(sgn((poly[j]-c.o)^(poly[i]-c.o))\u0026gt;=0) ans += ar; else ans -= ar; } return fabs(ans); } db interArea(Circle c1, Circle c2){ // 两圆相交面积 int rel = on(c1, c2); if(rel\u0026gt;=4) return 0.0; if(rel\u0026lt;=2) return std::min(PI*c1.r*c1.r, PI*c2.r*c2.r); db d = len(c1.o-c2.o); db alpha = acos((c1.r*c1.r+d*d-c2.r*c2.r)/(2*c1.r*d)); db beta = acos((c2.r*c2.r+d*d-c1.r*c1.r)/(2*c2.r*d)); db h = c1.r*sin(alpha); db s1 = c1.r*c1.r*alpha, s2 = c2.r*c2.r*beta; db s3 = d*h; return s1+s2-s3; } 基本公式 正弦定理 在\\(\\triangle ABC\\)中，设角\\(A,B,C\\)对应的边为\\(a,b,c\\)，则\n\\[\\dfrac{a}{\\sin A} = \\dfrac{b}{\\sin B} = \\dfrac{c}{\\sin C} = 2R \\]\n其中\\(R\\)是外接圆半径\n余弦定理 \\[a^2 = b^2+c^2-2bc\\cos A \\]\n\\[b^2 = a^2+c^2-2ac\\cos B \\]\n\\[c^2 = a^2+b^2-2ab\\cos C \\]\n向量积 \\[\\vec{a}\\cdot\\vec{b} = a_1b_1+a_2b_2+\\cdots+a_nb_n =|\\vec{a}||\\vec{b}|\\cos\\theta \\]\n\\[\\vec{a}\\times\\vec{b} = |\\vec{a}||\\vec{b}|\\sin\\theta \\]\n实际上外积只在三维中有定义。用在二维向量上时，只能算出这个标量值，用右手定则判断正负。其也代表两个向量构成的平行四边形的面积。三维中的定义为\n\\[\\vec{s} = \\vec{u}\\times\\vec{v} = (u_2v_3-u_3v_2, u_3v_1-u_1v_3,u_1v_2-u_2v_1) \\]\n其中\\(\\vec{s}\\)垂直于\\(\\vec{u},\\vec{v}\\)构成的屏幕。\n求任意多边形的周长 使用我们提供的len函数计算所有边即可。\n求任意多边形的面积 将多边形上的点逆时针标记为\\(p_1, p_2,\\cdots,p_n\\)，再选一个辅助点\\(O\\)，记\\(v_i=p_i-O\\)，那么\n\\[S = \\dfrac{1}{2}\\sum^n_{i=1}v_i\\times v_{i\\%n+1} \\]\n二维凸包 Andrew扫描法 //复杂度 nlogn //luogu P2742，求凸包周长 //凸包即能包围住所有给定顶点的最小凸多边形 //注意题给条件，如果是整数坐标，务必切换到long long来避免误差 std::vector\u0026lt;Point\u0026gt; convexHull(std::vector\u0026lt;Point\u0026gt; const \u0026amp; poly){ // 返回凸包上的点，逆时针顺序 // 如果要判断一个多边形是不是凸包，也可以用其生成一个凸包，判断点数是否相同 // 此时要将下面的sgn(...)\u0026lt;=0改成sgn(...)\u0026lt;0 // 另外要特判所有点共线的情况，否则得不到正确的点数 int k = 0; int n = poly.size(); std::vector\u0026lt;Point\u0026gt; qs; for(int i=0;i\u0026lt;n;i++){ while(k\u0026gt;1\u0026amp;\u0026amp;sgn((qs[k-1]-qs[k-2])^(poly[i]-qs[k-1]))\u0026lt;=0){ qs.pop_back(); k--; } qs.push_back(poly[i]); k++; } for(int i=n-2,t=k;i\u0026gt;=0;i--){ while(k\u0026gt;t\u0026amp;\u0026amp;sgn((qs[k-1]-qs[k-2])^(poly[i]-qs[k-1]))\u0026lt;=0) { qs.pop_back(); k--; } qs.push_back(poly[i]); k++; } qs.pop_back(); return qs; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n; std::cin\u0026gt;\u0026gt;n; std::vector\u0026lt;Point\u0026gt; po(n); for(int i=0;i\u0026lt;n;i++){ std::cin\u0026gt;\u0026gt;po[i].x\u0026gt;\u0026gt;po[i].y; //输入点的横纵坐标 } std::sort(po.begin(), po.end()); std::vector\u0026lt;Point\u0026gt; ch = convexHull(po); db ans = 0.0; for(int i=0,sz=ch.size();i\u0026lt;sz;i++){ ans += len(ch[(i+1)%sz]-ch[i]); } std::cout\u0026lt;\u0026lt;std::fixed; std::cout.precision(2); std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 旋转卡壳求最远点对 //复杂度 nlogn，其中求凸包nlogn，旋转卡壳本身为n //Luogu P1452 //旋转卡壳和凸包 //注意题给条件，如果是整数坐标，务必切换到long long来避免误差 db rc(std::vector\u0026lt;Point\u0026gt; const \u0026amp; ch){ // 返回凸包直径的平方 int tn = ch.size(); int cnt=0; if(tn==2){ return len2(ch[0]-ch[1]); } int i=0,j=0; for(int k=0;k\u0026lt;tn;k++){ if(!(ch[i]\u0026lt;ch[k])) i=k; if(ch[j]\u0026lt;ch[k]) j=k; } db res = 0; int si=i,sj=j; while(i!=sj||j!=si){ res = std::max(res, len2(ch[i]-ch[j])); if(sgn((ch[(i+1)%tn]-ch[i])^(ch[(j+1)%tn]-ch[j]))\u0026lt;0){ i = (i+1)%tn; }else{ j = (j+1)%tn; } cnt++; } return res; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n; std::cin\u0026gt;\u0026gt;n; std::vector\u0026lt;Point\u0026gt; po(n); for(int i=0;i\u0026lt;n;i++){ std::cin\u0026gt;\u0026gt;po[i].x\u0026gt;\u0026gt;po[i].y; //输入点的横纵坐标 } std::sort(po.begin(), po.end()); std::vector\u0026lt;Point\u0026gt; ch = convexHull(po); std::cout\u0026lt;\u0026lt;rc(ch)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 平面最近点对 输入\\(n\\)个点的平面坐标，使用分治法计算最近点对，复杂度\\(O(nlogn)\\)\n//复杂度nlogn //Luogu P1257 int const MAXN = 100005; struct Point{db x,y;int id;}; // id为了记录最近点对是哪两个点 bool cmp(Point const \u0026amp; a, Point const \u0026amp; b){ return le(a.y, b.y); } // 除了这两个部分其他同基础板子 db minDist; int ansA, ansB; Point po[MAXN]; inline void updAns(Point const \u0026amp; a, Point const \u0026amp; b){ db dist = len(b-a); if(dist\u0026lt;minDist){ minDist = dist; //如果要记录节点 ansA = a.id; ansB = b.id; } } void calcMin(int l, int r){ if(r-l\u0026lt;=3){ for(int i=l;i\u0026lt;=r;i++){ for(int j=i+1;j\u0026lt;=r;j++){ updAns(po[i],po[j]); } } std::sort(po+l, po+r+1, cmp); // 只排序y return; } int m = (l+r)\u0026gt;\u0026gt;1; db midx = po[m].x; calcMin(l,m); calcMin(m+1,r); //归并排序的合并，两个有序数组合并，合并之后仍然有序 std::inplace_merge(po+l, po+m+1, po+r+1, cmp); // 只排序y static Point t[MAXN]; int tsz = 0; for (int i = l; i \u0026lt;= r; ++i){ if (le(std::abs(po[i].x - midx),minDist)) { for (int j = tsz - 1; j \u0026gt;= 0 \u0026amp;\u0026amp; le(po[i].y - t[j].y,minDist); --j) updAns(po[i], t[j]); t[tsz++] = po[i]; } } } int main(){ int n; std::cin\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;po[i].x\u0026gt;\u0026gt;po[i].y; po[i].id = i; } std::sort(po+1,po+1+n); // 按照x第一，y第二排序 minDist = 1e20; calcMin(1,n); std::cout\u0026lt;\u0026lt;std::fixed; std::cout.precision(4); std::cout\u0026lt;\u0026lt;minDist\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 扫描线算法 //Luogu P5490 //复杂度 nlogn //求平面所有平行于坐标轴的矩形的面积重叠和 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; using ll = long long; int const MAXN = 2000005; struct Line{ ll l,r,h; int tag; Line(){} Line(ll l, ll r, ll h, int tag):l(l),r(r),h(h),tag(tag){} bool operator\u0026lt;(Line const \u0026amp; rhs) const{ return h\u0026lt;rhs.h; } }line[MAXN*2]; ll st[MAXN*4+2];//对于一颗线段树，n个数所组成的树最多有4n-5个节点，开大了一点 ll posX[MAXN*2]; ll len[MAXN*4+2]; void update(int l, int r, int s, int t, int p, ll c){//c表示加减的数值 if(posX[t+1]\u0026lt;=l || r\u0026lt;=posX[s]) return; if(l\u0026lt;=posX[s] \u0026amp;\u0026amp; posX[t+1]\u0026lt;=r){ st[p] += c; if(st[p]){ len[p] = posX[t+1] - posX[s]; } else{ len[p] = len[p*2] + len[p*2+1]; } return; } int m = s + ((t-s)\u0026gt;\u0026gt;1); if(l\u0026lt;=posX[m]) update(l, r, s, m, p*2, c); if(r\u0026gt;posX[m]) update(l, r, m+1, t, p*2+1, c); if(st[p]){ len[p] = posX[t+1] - posX[s]; } else{ len[p] = len[p*2] + len[p*2+1]; } } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n; std::cin\u0026gt;\u0026gt;n;//矩形个数 ll x1,x2,y1,y2; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;x1\u0026gt;\u0026gt;y1\u0026gt;\u0026gt;x2\u0026gt;\u0026gt;y2;//输入每个矩形的左下角和右上角 posX[2*i-1] = x1, posX[2*i] = x2; line[2*i-1] = Line(x1,x2,y1,1), line[2*i] = Line(x1,x2,y2,-1); } n*=2;//方便起见 std::sort(line+1,line+n+1); std::sort(posX+1,posX+n+1); int sumSeg = std::unique(posX+1, posX+1+n) - posX - 1 - 1;//去重求出线段总数 ll ans = 0; for(int i=1;i\u0026lt;n;i++){//最后一条边不用管 update(line[i].l, line[i].r, 1, sumSeg, 1, line[i].tag); ans += len[1] * (line[i+1].h - line[i].h); } std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;;//输出矩形的并集的总面积 return 0; } 二维数点 //Luogu P2163 //时间复杂度 nlogn //给定平面上n个点，m次查询，查询一个矩阵内有多少点 //由于坐标范围很大，不能直接用前缀和 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; int const MAXN = 500005; struct Point{ int x,y; int tag;//用于区分实际的点和查询时的虚点 bool operator\u0026lt;(Point const \u0026amp; p){ if(x!=p.x) return x\u0026lt;p.x; if(y!=p.y) return y\u0026lt;p.y; return tag\u0026lt;p.tag; } }pts[MAXN*5];//实点和查询矩阵的点都放在这里面 int b[MAXN*5]; int bit[MAXN]; int ans[MAXN][5]; int tot[MAXN]; inline int lowbit(int n){ return n\u0026amp;(-n); } void update(int p, int k, int n){ for(;p\u0026lt;=n;p+=lowbit(p)){ bit[p]+=k; } } int query(int p){ int ret=0; for(;p;p-=lowbit(p)){ ret+=bit[p]; } return ret; } inline int lsh(int x, int cnt){//离散化函数 return std::lower_bound(b+1,b+cnt+1,x)-b; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m;//点数，查询数 for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;pts[i].x\u0026gt;\u0026gt;pts[i].y;//所有实点的坐标 pts[i].tag = 0; } for(int i=1;i\u0026lt;=m;i++){ int x1,x2,y1,y2; std::cin\u0026gt;\u0026gt;x1\u0026gt;\u0026gt;y1\u0026gt;\u0026gt;x2\u0026gt;\u0026gt;y2;//查询的长方形的左下角和右上角 pts[++n].x = x1-1, pts[n].y = y1-1, pts[n].tag = i; pts[++n].x = x2, pts[n].y = y2, pts[n].tag = i; pts[++n].x = x2, pts[n].y = y1-1, pts[n].tag = i; pts[++n].x = x1-1, pts[n].y = y2, pts[n].tag = i; } std::sort(pts+1,pts+1+n); for(int i=1;i\u0026lt;=n;i++) b[i] = pts[i].y; std::sort(b+1,b+1+n); int cnt = std::unique(b+1,b+1+n) - b - 1;//把所有y离散化 for(int i=1;i\u0026lt;=n;i++){ if(pts[i].tag){ ans[pts[i].tag][++tot[pts[i].tag]] = query(lsh(pts[i].y, cnt)); } else{ update(lsh(pts[i].y, cnt), 1, cnt); } } for(int i=1;i\u0026lt;=m;i++){ std::cout\u0026lt;\u0026lt;ans[i][4]-ans[i][3]-ans[i][2]+ans[i][1]\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } Pick定理 给定顶点均为整点的简单多边形，其面积\\(A\\)和内部格点数目\\(i\\)，边上格点数目\\(b\\)的关系为\n\\[A = i+\\dfrac{b}{2}-1 \\]\n半平面交 // 半平面交 luogu P4196 // 半平面即直线Ax+By+C=0分割平面坐标系的其中一半，这是一个点集 // 这里的板子是直线a-\u0026gt;b的左半边 // 半平面交即为众多半平面划分出的点集的交集 // 本题是计算半平面划分出的多边形的面积 struct halfplane { Point s, e; db angle; // 表示向量s-\u0026gt;e的左半平面 halfplane() {} halfplane(Point s_, Point e_) : s(s_), e(e_) {} halfplane(Line l) : s(l.p), e(l.p + l.v) {} void calcAngle() { angle = atan2(e.y - s.y, e.x - s.x); } bool operator\u0026lt;(halfplane const\u0026amp; b) const { return angle \u0026lt; b.angle; } }; struct halfplanes { int n; static int const MAXP = 1010; halfplane hp[MAXP]; Point p[MAXP]; int que[MAXP]; int st, ed; void push(halfplane tmp) { hp[n++] = tmp; } void unique() { // 去重 int m = 1; for (int i = 1; i \u0026lt; n; i++) { if (sgn(hp[i].angle - hp[i - 1].angle) != 0) hp[m++] = hp[i]; else if (sgn((hp[m - 1].e - hp[m - 1].s) ^ (hp[i].s - hp[m - 1].s)) \u0026gt; 0) hp[m - 1] = hp[i]; } n = m; } bool halfplaneInsert() { // 这里指的是处理hp数组中的元素 // 放入hp中需要使用push for (int i = 0; i \u0026lt; n; i++) hp[i].calcAngle(); std::sort(hp, hp + n); unique(); que[st = 0] = 0; que[ed = 1] = 1; p[1] = inter(line(hp[0].s, hp[0].e), line(hp[1].s, hp[1].e))[0]; for (int i = 2; i \u0026lt; n; i++) { while (st \u0026lt; ed \u0026amp;\u0026amp; sgn((hp[i].e - hp[i].s) ^ (p[ed] - hp[i].s)) \u0026lt; 0) ed--; while (st \u0026lt; ed \u0026amp;\u0026amp; sgn((hp[i].e - hp[i].s) ^ (p[st + 1] - hp[i].s)) \u0026lt; 0) st++; que[++ed] = i; if (line(hp[i].s, hp[i].e) == line(hp[que[ed - 1]].s, hp[que[ed - 1]].e)) return false; p[ed] = inter(line(hp[i].s, hp[i].e), line(hp[que[ed - 1]].s, hp[que[ed - 1]].e))[0]; } while (st \u0026lt; ed \u0026amp;\u0026amp; sgn((hp[que[st]].e - hp[que[st]].s) ^ (p[ed] - hp[que[st]].s)) \u0026lt; 0) ed--; while (st \u0026lt; ed \u0026amp;\u0026amp; sgn((hp[que[ed]].e - hp[que[ed]].s) ^ (p[st + 1] - hp[que[ed]].s)) \u0026lt; 0) st++; if (st + 1 \u0026gt;= ed) return false; return true; } std::vector\u0026lt;Point\u0026gt; getConvex() { // 返回半平面交出来的凸多边形 // 需要先调用halfplaneinsert()且返回true p[st] = inter(line(hp[que[st]].s, hp[que[st]].e), line(hp[que[ed]].s, hp[que[ed]].e))[0]; std::vector\u0026lt;Point\u0026gt; ret(ed - st + 1); for (int j = st, i = 0; j \u0026lt;= ed; i++, j++) ret[i] = p[j]; return ret; } } hps; void solve() { int n; std::cin \u0026gt;\u0026gt; n; // 多边形个数 while (n--) { int m; // 多边形点数，逆时针输入 std::cin \u0026gt;\u0026gt; m; std::vector\u0026lt;Point\u0026gt; ps(m); for (int i = 0; i \u0026lt; m; i++) std::cin \u0026gt;\u0026gt; ps[i].x \u0026gt;\u0026gt; ps[i].y; for (int i = 0; i \u0026lt; m; i++) hps.push(halfplane(ps[i], ps[(i + 1) % m])); } if (!hps.halfplaneInsert()) { std::cout \u0026lt;\u0026lt; \u0026#34;0.000\\n\u0026#34;; return; } auto vec = hps.getConvex(); std::cout \u0026lt;\u0026lt; std::fixed; std::cout.precision(3); std::cout \u0026lt;\u0026lt; area(vec) \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; } 组合数学 用乘法逆元计算组合数 TODO: 用模板元编程实现编译期算阶乘\n根据\n\\[(a/b)\\%p=(a\\times b^{-1})\\%p=[(a\\%p)\\times(b^{-1}\\%p)]\\%p \\]\n（如果加载不全，见取余运算的分配律）\n可以不用除法求出组合数。其中\\(b^{-1}\\)是\\(b\\)在模\\(p\\)意义下的逆元。\n注意阶乘和其逆元的预处理。\n//复杂度 初始化为nlogn 后续查询为O(1) //luogu P3414，只能过50%（因为这道题考的不是这个） using LL = long long; const int MAXN = 200005; const LL MOD = 6662333; LL fac[MAXN]; LL invFac[MAXN]; LL qPowMod(LL x, LL p, LL m){ //x^p % m LL ans = 1; while(p){ if(p\u0026amp;1){ ans = (ans*x)%m; } x = (x*x)%m; p\u0026gt;\u0026gt;=1; } return ans; } LL fermat_inv(LL a, LL b){ return qPowMod(a,b-2,b); } void init(int n){ fac[0] = 1; invFac[0] = 1; for(int i=1;i\u0026lt;=n;i++){ fac[i] = (fac[i-1]*i)%MOD; invFac[i] = fermat_inv(fac[i],MOD); } } LL comb(LL n, LL m){ //n里面选m个 if(n\u0026lt;0||m\u0026lt;0||m\u0026gt;n) return 0; return (((fac[n]*invFac[m])%MOD)*invFac[n-m])%MOD; } 组合数的性质 二项式定理\n\\[(a+b)^n = \\sum^n_{i=0}\\binom{n}{i}a^{n-i}b^i \\]\n对称性\n\\[\\binom{n}{m} = \\binom{n}{n-m} \\]\n递推式1\n\\[\\binom{n}{k}=\\dfrac{n}{k}\\binom{n-1}{k-1} \\]\n递推式2\n\\[\\binom{n}{m} = \\binom{n-1}{m}+\\binom{n-1}{m-1} \\]\n二项式定理的特例1\n\\[\\binom{n}{0}+\\binom{n}{1}+\\cdots+\\binom{n}{n} = 2^n \\]\n二项式定理的特例2\n\\[\\sum^n_{i=0}(-1)^i\\binom{n}{i} = [n=0] \\]\n组合数拆分\n\\[\\sum^m_{i=0}\\binom{n}{i}\\binom{m}{m-i} = \\binom{m+n}{m} (n\\geq m) \\]\n组合数拆分的特例\n\\[\\sum^m_{i=0}\\binom{n}{i}^2= \\binom{2n}{n} \\]\n带权和1\n\\[\\sum^n_{i=0}i\\binom{n}{i} = n2^{n-1} \\]\n带权和2\n\\[\\sum^n_{i=0}i^2\\binom{n}{i} = n(n+1)2^{n-2} \\]\n性质1\n\\[\\sum^n_{l=0}\\binom{l}{k} = \\binom{n+1}{k+1} \\]\n性质2\n\\[\\binom{n}{r}\\binom{r}{k} = \\binom{n}{k}\\binom{n-k}{r-k} \\]\n斐波那契数列性质\n\\[\\sum^n_{i=0}\\binom{n-i}{i} = F_{n+1} \\]\n圆排列 \\(n\\)个人全部来围成一圈，所有的排列数记为\\(Q^n_n\\)。考虑其中已经拍好的一圈，从不同位置断开可以变成不同的队列，则有\n\\[Q^n_n\\times n = A^n_n \\]\n由此可知\n\\[Q^r_n = \\dfrac{A^r_n}{r} \\]\n二项式反演 记\\(f_n\\)表示恰好使用\\(n\\)个不同元素形成特定结构的方案数，\\(g_n\\)表示从\\(n\\)个不同元素中选出\\(i\\geq 0\\)个元素形成特定结构的总方案数。有\n\\[g_n = \\sum^n_{i=0}\\binom{n}{i}f_i \\]\n二项式反演就是已知\\(g_n\\)求\\(f_n\\)\n\\[f_n = \\sum^n_{i=0}\\binom{n}{i}(-1)^{n-i}g_i \\]\n斐波那契数列的性质 通项公式\n\\[F_n = \\dfrac{\\left(\\dfrac{1+\\sqrt{5}}{2}\\right)^n-\\left(\\dfrac{1-\\sqrt{5}}{2}\\right)^n}{\\sqrt{5}} \\]\n\\[F_n = \\left[\\dfrac{\\left(\\dfrac{1+\\sqrt{5}}{2}\\right)^n}{\\sqrt{5}}\\right] \\]\n中括号表示取离他最近的整数。\n性质1\n\\[F_{n-1}F_{n+1}-F_n^2=(-1)^n \\]\n性质2\n\\[F_{n+k}=F_kF_{n+1}+F_{k-1}F_n \\]\n性质3\n\\[F_{2n}=F_{n}(F_{n+1}+F_{n-1}),\\quad F_{2n+1}=F^2_{k+1}+F^2_k \\]\n性质4\n\\[\\forall k\\in N,F_n|F_{nk} \\]\n性质5\n\\[\\forall F_a|F_b,a|b \\]\n性质6\n\\[\\gcd(F_m,F_n)=F_{\\gcd(m,n)} \\]\n性质7\n\\[F_{n+1}=\\sum_{0\\leq i\\leq n}\\binom{n-i}{i} \\]\n和式性质 基本性质 \\[\\sum_{k\\in K}ca_k=c\\sum_{k\\in K}a_k \\]\n\\[\\sum_{k\\in K}(a_k+b_k)=\\sum_{k\\in K}a_k+\\sum_{k\\in K}b_k \\]\n\\[\\sum_{k\\in K}a_k = \\sum_{p(k)\\in K}a_{p(k)} \\]\n此处\\(p(k)\\)是\\(k\\)的任意排列。\n多重和式分配律 \\[\\sum_{j\\in J,k\\in K}a_jb_k = (\\sum_{j\\in J}a_j)(\\sum_{k\\in K}b_k) \\]\n多重和式次序交换 \\[\\sum_{j\\in J}\\sum_{k\\in K}a_{j,k} = \\sum_{j\\in J,k\\in K}a_{j,k} = \\sum_{k\\in K}\\sum_{j\\in J}a_{j,k} \\]\n当\\(J,K\\)相互独立时成立。\n\\[\\sum_{j\\in J}\\sum_{k\\in K(j)}a_{j,k} = \\sum_{k\\in K'}\\sum_{j\\in J'(k)}a_{j,k} \\]\n这里\\(J,K\\)不独立，并且要满足\n\\[[j\\in J][k\\in K(j)]=[k\\in K'][j\\in J'(k)] \\]\n例如\n\\[\\sum_{j=1}^n\\sum_{k=j}^na_{j,k}=\\sum_{i\\leq j\\leq k\\leq n}a_{j,k}=\\sum_{k=1}^n\\sum_{j=1}^ka_{j,k} \\]\n卡特兰数 TODO: 用模板元编程实现编译期算卡特兰数\n第\\(n\\)个记作\\(C_n\\)\n\\(n\\)对括号形成的字符串，合法的情况数是\\(C_n\\)\n\\(n\\)个节点的二叉树，总共有\\(C_n\\)种\n\\(2n+1\\)个节点组成的满二叉树，有\\(C_n\\)种\n\\(n\\times n\\)的格点网中，从左下角格点出发，到达右上角格点，不穿过对角线（但可以碰到）的单调路径个数有\\(C_n\\)个。\n在圆上有\\(2n\\)个点，将这些点成对连接起来使得所得到的\\(n\\)条线段不相交的方法数为\\(C_n\\)种\n一个栈（无穷大）的进栈序列为\\(1,2,3,\\cdots,n\\)，合法的出栈序列有\\(C_n\\)个\n其计算公式为\n\\[C_n = \\frac{1}{n+1}\\binom{2n}{n} \\]\n\\[C_n=\\binom{2n}{n} - \\binom{2n}{n-1} \\]\n\\[C_0=1,C_{n+1}=\\sum^n_{i=0}C_iC_{n-i} \\]\n\\[C_0=1,C_{n+1}=\\frac{2(2n+1)}{n+2}C_n \\]\n//复杂度 n #include \u0026lt;iostream\u0026gt; //前几项：1, 1, 2, 5, 14, 42, 132, 429, 1430, 4862, 16796 //luogu p1044 using namespace std; typedef long long ll; const int MAXN = 3005; ll h[MAXN]; ll comb(ll a,ll b){ ll ans=1; for(ll i=1;i\u0026lt;=b;i++){ ans*=a;//数字太大会爆 a--; } for(ll i=1;i\u0026lt;=b;i++){ ans/=i; } return ans; } int main(){ ll n; cin\u0026gt;\u0026gt;n; for(ll i=1;i\u0026lt;=n;i++){ cout\u0026lt;\u0026lt;comb(2*i,i)/(i+1)\u0026lt;\u0026lt;endl;//n\u0026gt;=15的时候ll都能爆 } cout\u0026lt;\u0026lt;\u0026#34;###\u0026#34;\u0026lt;\u0026lt;endl; //下面是递推求法，不容易爆 h[1]=1; cout\u0026lt;\u0026lt;h[1]\u0026lt;\u0026lt;endl; for(ll i=2;i\u0026lt;=n;i++){ h[i] = h[i-1]*(4*i-2)/(i+1); cout\u0026lt;\u0026lt;h[i]\u0026lt;\u0026lt;endl; } return 0; } 生成函数 生成函数是一种形式幂级数\n\\[F(x) = \\sum_na_nx^n \\]\n\\(\\{a_i\\}\\)序列可以是有限的，也可以是无限的。\\(a_i\\)下标以\\(0\\)为起点。生成函数例如\n\\(a=\u003c1,2,3\u003e\\)的普通生成函数为\\(1+2x+3x^2\\) \\(a=\u003c1,1,1,\\cdots\u003e\\)的普通生成函数为\\(\\sum_{n\\geq 0}x^n\\) \\(a=\u003c2,4,6,8,\\cdots\u003e\\)的普通生成函数为\\(\\sum_{n\\geq 0}(2n+2)x^n\\) 加减运算\n设序列\\(a,b\\)的普通生成函数分别为\\(F(x),G(x)\\)，则\n\\[F(x)\\pm G(x) = \\sum_n(a_n\\pm b_n)x^n \\]\n乘/卷积运算\n\\[F(x)G(x) = \\sum_n x^n\\sum^n_{i=0}a_i b_{n-i} \\]\n给出一些常见封闭形式，这其实和幂级数收敛时的求和公式差不多（目前只会普通生成函数来应对组合问题，之后更新指数生成函数应对排列问题TODO）：\n\\[\\sum_{n\\geq 0}x^n = \\dfrac{1}{1-x} \\]\n\\[\\sum_{n\\geq 0}p^nx^n=\\dfrac{1}{1-px} \\]\n\\[\\sum_{n\\geq 1}x^n = \\dfrac{x}{1-x} \\]\n\\[\\sum_{n\\geq 0}x^{cn} = \\dfrac{1}{1-x^c} \\]\n\\[1+2x+3x^2+\\cdots = \\sum_{n\\geq 0}(n-1)x^n = \\dfrac{1}{(1-x)^2} \\]\n\\[\\sum_{n\\geq 0}\\binom{m}{n}x^n = (1+x)^m \\]\n\\[\\sum_{n\\geq 0}\\binom{m+n-1}{n}x^n = \\dfrac{1}{(1-x)^{m}} \\]\n其他有限项生成函数应该用等比数列求和公式，转化成分式形式。之后再来进行生成函数的计算。\n例题\n在许多不同种类的食物中选出\\(n\\)个，每种食物的限制如下（每种食物选出来的个数必须满足该限制）\n汉堡：偶数个 可乐：0或1个 鸡腿：0或1或2个 蜜桃多：奇数个（注：0个不满足条件） 鸡块：4的倍数个 包子，0、1、2、3个 土豆炒肉：不超过1个 面包：3的倍数个 所有食物选出来的总数加起来等于\\(n\\)就可以算作一种方案。计算方案总数模\\(10007\\)\n我们设\\(a_n\\)表示这种食物选\\(n\\)个的方案数，并求出其生成函数。显然，假设只选两个食品，如果食品1选了\\(i\\)个，那么食品2就只能选\\(n-i\\)个。这和我们之前的卷积形式是一样的。所以我们应该把各种食品的生成函数的封闭形式乘起来得到答案。生成函数构造如下\n\\(\\sum_{n\\geq 0}x^{2n}=\\dfrac{1}{1-x^2}\\) \\(1+x\\) \\(1+x+x^2=\\dfrac{1-x^3}{1-x}\\)（这里食品都是相同的，所以选1个只有1种方案。求法是等比数列求和。有些题的物品是不同的，这里就要变成其他序列） \\(\\dfrac{x}{1-x^2}\\) \\(\\dfrac{1}{1-x^4}\\) \\(\\dfrac{1-x^4}{1-x}\\) \\(1+x\\) \\(\\dfrac{1}{1-x^3}\\) 全部乘起来得到的生成函数为\n\\[F(x) = \\dfrac{(1+x)(1-x^3)x(1-x^4)(1+x)}{(1-x^2)(1-x)(1-x^2)(1-x^4)(1-x)(1-x^3)} = \\dfrac{x}{(1-x)^4} \\]\n再转化为展开形式\n\\[F(x) = \\sum_{n\\geq 0}\\binom{n+3}{n}x^{n+1}=\\sum_{n\\geq 1}\\binom{n+2}{n-1}x^n \\]\n可得答案就是\\(\\binom{n+2}{n-1}=\\binom{n+2}{3}\\)\n稳定婚姻问题(Gale-Shapley算法) TODO //POJ 3487 #include \u0026lt;iostream\u0026gt; #include \u0026lt;queue\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cstring\u0026gt; using namespace std; const int N = 30; const int inf = 1\u0026lt;\u0026lt;29; const int MOD = 2007; typedef long long ll; int couple; int maleLike[N][N], femaleLike[N][N]; int maleChoice[N], femaleChoice[N]; int maleName[N], femaleName[N]; char str[N]; queue\u0026lt;int\u0026gt;freemale;//目前单身的男人 int main(){ int t; scanf(\u0026#34;%d\u0026#34;,\u0026amp;t);//数据组数 while(t--){ scanf(\u0026#34;%d\u0026#34;,\u0026amp;couple);//男女对数 while(!freemale.empty()){ freemale.pop(); } for(int i=0;i\u0026lt;couple;i++){ scanf(\u0026#34;%s\u0026#34;,str); maleName[i]=str[0]-\u0026#39;a\u0026#39;;//题目中是以小写字母给男人名字，转化为数字 freemale.push(maleName[i]); } sort(maleName, maleName+couple);//名字排序，便于字典序 for(int i=0;i\u0026lt;couple;i++){ scanf(\u0026#34;%s\u0026#34;,str); femaleName[i]=str[0]-\u0026#39;A\u0026#39;;//女人名字是大写字母 } for(int i=0;i\u0026lt;couple;i++){ scanf(\u0026#34;%s\u0026#34;,str); for(int j=0;j\u0026lt;couple;j++){ maleLike[i][j]=str[j+2]-\u0026#39;A\u0026#39;;//男人喜好顺序由男人名字:女人名字列表给出;降序排列 } } //女士对男士的打分，添加虚拟人物，编号couple，为女士的初始对象 for(int i=0;i\u0026lt;couple;i++){ scanf(\u0026#34;%s\u0026#34;,str); for(int j=0;j\u0026lt;couple;j++){ femaleLike[i][str[j+2]-\u0026#39;a\u0026#39;]=couple-j;//排名越前打分越高 } femaleLike[i][couple]=0; } memset(maleChoice,0,sizeof(maleChoice)); //一开始男士的期望都是最喜欢的女士 for(int i=0;i\u0026lt;couple;i++){ femaleChoice[i]=couple; } while(!freemale.empty()){ int male=freemale.front(); //找出未配对的男士 int female=maleLike[male][maleChoice[male]]; //找出心意的女士 if(femaleLike[female][male]\u0026gt;femaleLike[female][femaleChoice[female]]){ //比现男友好 freemale.pop(); if(femaleChoice[female]!=couple){ //前男友再次单身，并且不能将虚拟人物加入队列 freemale.push(femaleChoice[female]); maleChoice[femaleChoice[female]]++; } femaleChoice[female]=male; //更换男友 } else maleChoice[male]++; //如果被拒绝，则选择下一位 } for(int i=0;i\u0026lt;couple;i++){ printf(\u0026#34;%c %c\\n\u0026#34;,maleName[i]+\u0026#39;a\u0026#39;, maleLike[maleName[i]][maleChoice[maleName[i]]]+\u0026#39;A\u0026#39;); } if(t) puts(\u0026#34;\u0026#34;); } return 0; } 数据结构 树状数组 //复杂度 单次查询 logn 单次修改 logn //树状数组，维护的是数组的前缀和，有大量的应用 //luogu P3374 //普通的树状数组要维护的信息，其运算要满足结合律和可差分 //结合律不难理解，可差分指的是若已知x op y和x，则可以求出y //这样的运算例如加，乘，异或。乘如果在模意义下可差分，需要保证每个数都有逆元，如果模数为质数则肯定有 //gcd,max这种是不可差分的 #include \u0026lt;iostream\u0026gt; int const MAXN = 1000005; using LL = long long; class Fenwick{ public: LL data[MAXN]; int size = 0; void init(int size_){size=size_;} inline int lowbit(int x){ return x\u0026amp;(-x); } void update(int p, LL k){//位置p的元素加k for(;p\u0026lt;=size;p+=lowbit(p)){ data[p]+=k; } } LL query(int p){//查询[1,p]的和 LL ret=0; for(;p;p-=lowbit(p)){ ret += data[p]; } return ret; } }; Fenwick fenwick; int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; //数组长度，查询数 fenwick.init(n); for(int i=1;i\u0026lt;=n;i++){ LL tmp; std::cin\u0026gt;\u0026gt;tmp; fenwick.update(i,tmp); } for(int i=1;i\u0026lt;=m;i++){ int op; int x,y; LL k; std::cin\u0026gt;\u0026gt;op\u0026gt;\u0026gt;x; if(op==1){ std::cin\u0026gt;\u0026gt;k; //将单点增加k，如果想要改成修改，则可以update(x,k-查询x位置上的数) fenwick.update(x,k); } else{ std::cin\u0026gt;\u0026gt;y; //输出[x,y]的数组和 std::cout\u0026lt;\u0026lt;fenwick.query(y)-fenwick.query(x-1)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } } return 0; } 树状数组求逆序对 //复杂度 nlogn //Luogu P1908 //逆序对\u0026lt;i,j\u0026gt;即，符合i\u0026lt;j且ai\u0026gt;aj的\u0026lt;i,j\u0026gt;的个数 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #define LL long long const int MAXN = 500005; LL arr[MAXN]; struct Par{ LL value,id; }par[MAXN]; bool cmp(const Par\u0026amp; a,const Par\u0026amp; b){ if(a.value!=b.value) return a.value\u0026lt;b.value; return a.id\u0026lt;b.id; } LL bit[MAXN]; inline LL lowbit(LL n){ return n\u0026amp;(-n); } void update(LL p, LL k, LL n){ for(;p\u0026lt;=n;p+=lowbit(p)){ bit[p]+=k; } } long long query(LL p){ LL ans=0; for(;p;p-=lowbit(p)){ ans+=bit[p]; } return ans; } int main(){ LL n; std::cin\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;par[i].value; par[i].id = i; } std::sort(par+1,par+1+n,cmp); for(int i=1;i\u0026lt;=n;i++){ arr[par[i].id] = i; }//这一步其实是离散化，但与stl实现的离散化不同的是， //出现同样的数字时，例如6,-4,3,7,3会离散化为4,1,2,5,3 LL ans = 0; for(int i=1;i\u0026lt;=n;i++){ ans += query(arr[i]); update(arr[i],1,n); } ans = n*(n-1)/2-ans;//本来统计的是等于或顺序对，现在反过来计算逆序对 std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 二维树状数组 //二维树状数组 支持单点修改和区间查询 //loj 133 #include \u0026lt;iostream\u0026gt; int const MAXN = 5005; using LL = long long; class BIT2D{ public: int N,M; LL data[MAXN][MAXN]; void init(int n,int m){ N = n, M = m; } inline int lowbit(int x){ return x\u0026amp;(-x); } void add(int x, int y, LL v){//把(x,y)这个点加上v for(int i=x;i\u0026lt;=N;i+=lowbit(i)){ for(int j=y;j\u0026lt;=M;j+=lowbit(j)){ data[i][j] += v; } } } LL sum(int x, int y){ LL ret = 0; for(int i=x;i\u0026gt;0;i-=lowbit(i)){ for(int j=y;j\u0026gt;0;j-=lowbit(j)){ ret += data[i][j]; } } return ret; } LL query(int x1, int y1, int x2, int y2){//查询(x1,y1)-(x2,y2)这个矩形的区间和 return sum(x2,y2) - sum(x2,y1-1) - sum(x1-1, y2) + sum(x1-1, y1-1); } }; BIT2D bit2d; 并查集 //复杂度 很小 //并查集 Luogu3367 const int MAXN = 10005; class DSU{ public: int fa[MAXN], rk[MAXN]; void init(int n){ for(int i=1;i\u0026lt;=n;i++) fa[i] = i, rk[i] = 1; } int find(int x){ //没有路径压缩的find，在需要删除操作时，不能使用路径压缩，只能按秩合并保证复杂度 return fa[x]==x ? x : find(fa[x]); } int findc(int x){ //带路径压缩的find return fa[x]==x ? x : (fa[x] = findc(fa[x])); } void merge(int x, int y){ //按秩合并，如果不需要则直接 fa[find(x)] = find(y); x = find(x), y = find(y); if(x==y) return; if(rk[x]\u0026gt;rk[y]) std::swap(x,y); fa[x] = y; if(rk[x]==rk[y]) rk[y]++; } void mergec(int x, int y){ //按秩合并+路径压缩，如果不需要则直接 fa[findc(x)] = findc(y); x = findc(x), y = findc(y); if(x==y) return; if(rk[x]\u0026gt;rk[y]) std::swap(x,y); fa[y] = x; if(rk[x]==rk[y]) rk[y]++; } void erase(int x){ --rk[find(x)]; fa[x] = x; } }; 线段树 //复杂度 单次查询 logn 单次修改 logn //luogu p3372 //线段树维护的数据要求满足结合律，比如区间和，区间最大区间最小，区间gcd //区间修改一般支持加、乘、赋值 #include \u0026lt;iostream\u0026gt; int const MAXN = 100005; using LL = long long; struct Node { int s,t;//该端点的起点和终点下标 LL tag, v; }; Node st[MAXN*4+2]; LL arr[MAXN]; void build(int s, int t, int p=1){ st[p].s = s; st[p].t = t; if(s==t) { st[p].v = arr[s]; st[p].tag = 0; return; } int m = s+((t-s)\u0026gt;\u0026gt;1); build(s,m,p*2); build(m+1,t,p*2+1); st[p].v = st[p*2].v + st[p*2+1].v; st[p].tag = 0; } void spreadTag(int p){ if(st[p].tag){ int s = st[p].s, t = st[p].t; int m = s+((t-s)\u0026gt;\u0026gt;1); st[p*2].v += (m-s+1)*st[p].tag; st[p*2+1].v += (t-m)*st[p].tag; st[p*2].tag += st[p].tag; st[p*2+1].tag += st[p].tag; st[p].tag=0; } } void update(int l, int r, LL k, int p=1){ int s = st[p].s, t = st[p].t; if(l\u0026lt;=s \u0026amp;\u0026amp; t\u0026lt;=r){ st[p].v += (t-s+1) * k; st[p].tag += k; return; } spreadTag(p); int m = s+((t-s)\u0026gt;\u0026gt;1); if(l\u0026lt;=m) update(l, r, k, p*2); if(r\u0026gt;m) update(l, r, k, p*2+1); st[p].v = st[p*2].v + st[p*2+1].v; } LL query(int l, int r, int p=1){ int s = st[p].s, t = st[p].t; if(l\u0026lt;=s \u0026amp;\u0026amp; t\u0026lt;=r) return st[p].v; spreadTag(p); int m = s+((t-s)\u0026gt;\u0026gt;1); LL ret = 0; if(l\u0026lt;=m) ret+=query(l,r,p*2); if(r\u0026gt;m) ret+=query(l,r,p*2+1); return ret; } 动态开点线段树 //动态开点线段树 //luogu p3372，由于并没有找到合适的习题，我把题中的查询范围全部加了一个偏移值-5e4 //动态开点线段树并不是动态分配内存，只是在范围很大，但查询不多的时候，可以用 //普通线段树的空间复杂度是O(n)，单次操作的时间复杂度是O(logn) //动态开点，设查询为m次，时间复杂度仍然为O(logn)，但是空间复杂度变成O(mlogn) //动态开点还可以处理查询范围为负数的情况，比如查询[-5,6]这一段上的和 //动态开点假设初始数组全部为0，输入一个数组时直接add修改线段树即可 using LL = long long; int const MAXN = 8e6+5;//能开多大开多大，128M可以开到800万 struct Node{ LL val, tag; int ls, rs; }st[MAXN]; inline int\u0026amp; ls(int x){return st[x].ls;} inline int\u0026amp; rs(int x){return st[x].rs;} inline LL\u0026amp; val(int x){return st[x].val;} inline LL\u0026amp; tag(int x){return st[x].tag;} inline int getMid(int s, int t){ //处理负数边界时，需要强行向下取整，而不是向零取整 if(s+t==0) return 0; if(s+t\u0026gt;0) return (s+t)/2; return -((-s-t+1)/2); } int stcnt = 1; int L = -(1e6+5), R = 1e6+5;//这里根据题目信息选择区间范围 void upd(int \u0026amp;p, LL k, int len){ if(!p) p = ++stcnt; val(p) += k * len; tag(p) += k; } void spreadTag(int p, int len){ if(len\u0026lt;=1) return; upd(ls(p), tag(p), len-len/2); upd(rs(p), tag(p), len/2); tag(p) = 0; } LL query(int l, int r, int p = 1, int s = L, int t = R){ if(s\u0026gt;=l \u0026amp;\u0026amp; t\u0026lt;=r) return val(p); spreadTag(p, t-s+1); int mid = getMid(s,t); LL ret = 0; if(mid \u0026gt;= l) ret += query(l, r, ls(p), s, mid); if(mid \u0026lt; r) ret += query(l, r, rs(p), mid+1, t); return ret; } void add(int l, int r, LL k, int p = 1, int s = L, int t = R){ if(s\u0026gt;=l \u0026amp;\u0026amp; t\u0026lt;=r){ val(p) += k * (t-s+1); tag(p) += k; return; } spreadTag(p, t-s+1); int mid = getMid(s,t); if(mid \u0026gt;= l) add(l, r, k, ls(p), s, mid); if(mid \u0026lt; r) add(l, r, k, rs(p), mid+1, t); val(p) = val(ls(p)) + val(rs(p)); } void solve(){ int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; int const offset = -5e4; for(int i=1;i\u0026lt;=n;i++){ int a; std::cin\u0026gt;\u0026gt;a; add(i+offset,i+offset,a); } while(m--){ int ope, l, r, x; std::cin\u0026gt;\u0026gt;ope\u0026gt;\u0026gt;l\u0026gt;\u0026gt;r; l += offset; r += offset; if(ope==1){ std::cin\u0026gt;\u0026gt;x; add(l,r,x); } else{ std::cout\u0026lt;\u0026lt;query(l,r)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } } } 权值线段树 //权值线段树 //loj 104 //权值线段树大部分时候是用来代替平衡树使用的 //和树状数组求逆序对很像，他把每一个[x,x]范围上的节点视作一个桶，插入数据时，add(x,x,1)，删除一个时add(x,x,-1)。 //查询复杂度为O(logv)，v为值域 /*这里是动态开点线段树的核心代码*/ void insert(int v){//插入一个数 add(v,v,1); } void remove(int v){//删除一个数，相同的只删一个 add(v,v,-1); } int countL(int v){//计算小于v的数的个数 return query(L, v-1); } int countG(int v){//计算大于v的数的个数 return query(v+1, R); } int rank(int v){//求v的排名，即小于v的数的个数+1 return countL(v)+1; } int kth(int k, int p=1, int s=L, int t=R){//查询排名第k的数 if(s==t) return s; int mid = getMid(s,t); if(val(ls(p)) \u0026gt;= k) return kth(k, ls(p), s, mid); else return kth(k-val(ls(p)), rs(p), mid+1, t); } int pre(int v){//查询v的前驱，即第一个比v小的数，可能需要保证一定存在 int r = countL(v); return kth(r); } int suc(int v){//查询v的后继 int r = val(1) - countG(v) + 1; return kth(r); } 可持久化线段树 单点修改 //可持久化线段树，单点修改、区间查询，操作复杂度logn //luogu p3919 //可持久化线段树是完全可持久化的，意味着可以查询历史修改，以及对每一个历史状态都可以再修改 #include \u0026lt;iostream\u0026gt; using LL = long long; int const MAXV = 3e7+5; int const MAXN = 1e6+5; struct Node{ LL val; int ls, rs; }st[MAXV]; inline int\u0026amp; ls(int x){return st[x].ls;} inline int\u0026amp; rs(int x){return st[x].rs;} inline LL\u0026amp; val(int x){return st[x].val;} inline int getMid(int s, int t){ if(s+t==0) return 0; if(s+t\u0026gt;0) return (s+t)/2; return -((-s-t+1)/2); } int stcnt = 1; int L = 1, R = 1e6+5;//这里根据题目信息选择区间范围 LL arr[MAXN], roots[MAXN];//arr存初始数组，roots[i]表示第i次操作的根节点 void build(int s=L, int t=R, int p=1){ //一般不会完全动态开点，会把初始状态建树 if(s==t) val(p) = arr[s]; else{ ls(p) = ++stcnt, rs(p) = ++stcnt; int mid = getMid(s,t); build(s,mid,ls(p)); build(mid+1,t,rs(p)); val(p) = val(ls(p)) + val(rs(p)); } } void assign(int i, LL k, int p, int q, int s=L, int t=R){ //这里是单点修改操作，如果改成区间加，则下一行改成val(q)=val(p)+k //修改第i位为k，对版本x的根节点p进行修改，修改完为版本y的根节点q if(s==t) val(q) = k; else{ ls(q) = ls(p), rs(q) = rs(p); int mid = getMid(s,t); if(i\u0026lt;=mid) ls(q) = ++stcnt, assign(i,k,ls(p),ls(q),s,mid); else rs(q) = ++stcnt, assign(i,k,rs(p),rs(q),mid+1,t); val(q) = val(ls(q)) + val(rs(q)); } } LL query(int l, int r, int p, int s=L, int t=R){ //查询区间和 //对版本p查询 if(s\u0026gt;r || t\u0026lt;l) return 0; else if(s\u0026gt;=l \u0026amp;\u0026amp; t\u0026lt;=r) return val(p); else{ int mid = getMid(s,t); return query(l,r,ls(p),s,mid) + query(l,r,rs(p),mid+1,t); } } void solve(){ int m; std::cin\u0026gt;\u0026gt;R\u0026gt;\u0026gt;m; for(int i=L;i\u0026lt;=R;i++){ std::cin\u0026gt;\u0026gt;arr[i]; } build(); roots[0] = 1;//别忘了初始化初始区间的根 for(int t=1;t\u0026lt;=m;t++){ int v, o; std::cin\u0026gt;\u0026gt;v\u0026gt;\u0026gt;o;//v是对第v个版本操作 if(o==1){ int i;LL k; std::cin\u0026gt;\u0026gt;i\u0026gt;\u0026gt;k; roots[t] = ++stcnt;//本题的修改和查询都算一个版本 assign(i,k,roots[v],roots[t]); //注意你把第1个版本修改为第5个，不会对2、3、4版本产生影响 } else{ int i; std::cin\u0026gt;\u0026gt;i; roots[t] = roots[v];//虽然修改也算一个版本，但是可以和之前的合并 std::cout\u0026lt;\u0026lt;query(i,i,roots[v])\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } } } 区间修改 //可持久化线段树，区间修改、区间查询，操作复杂度logn //hdu 4348 #include \u0026lt;iostream\u0026gt; using LL = long long; int const MAXV = 3e6+5; int const MAXN = 1e5+5; struct Node{ LL val, tag; int ls, rs; }st[MAXV]; inline int\u0026amp; ls(int x){return st[x].ls;} inline int\u0026amp; rs(int x){return st[x].rs;} inline LL\u0026amp; val(int x){return st[x].val;} inline LL\u0026amp; tag(int x){return st[x].tag;} inline int getMid(int s, int t){ if(s+t==0) return 0; if(s+t\u0026gt;0) return (s+t)/2; return -((-s-t+1)/2); } int stcnt = 1; int L = 1, R = 1e6+5;//这里根据题目信息选择区间范围 LL arr[MAXN], roots[MAXN]; void build(int s=L, int t=R, int p=1){ if(s==t) val(p) = arr[s], tag(p) = 0; else{ ls(p) = ++stcnt, rs(p) = ++stcnt; int mid = getMid(s,t); build(s,mid,ls(p)); build(mid+1,t,rs(p)); val(p) = val(ls(p)) + val(rs(p)); } } void add(int l, int r, LL k, int p, int q, int s=L, int t=R){ //l,r是修改范围，其他同单点修改 ls(q) = ls(p), rs(q) = rs(p), tag(q) = tag(p); if(l\u0026lt;=s \u0026amp;\u0026amp; t\u0026lt;=r){ if(t\u0026gt;s) tag(q) += k; } else{ int mid = getMid(s,t); if(s\u0026lt;=r \u0026amp;\u0026amp; mid\u0026gt;=l) ls(q) = ++stcnt, add(l,r,k,ls(p),ls(q),s,mid); if(mid+1\u0026lt;=r \u0026amp;\u0026amp; t\u0026gt;=l) rs(q) = ++stcnt, add(l,r,k,rs(p),rs(q),mid+1,t); } val(q) = val(p) + (std::min(r,t)-std::max(l,s)+1)*k; } LL query(int l, int r, int p, LL tg=0, int s=L, int t=R){ //l,r是修改范围，tg是一种标记永久化的技术，其他同单点修改 if(s\u0026gt;r || t\u0026lt;l) return 0; else if(s\u0026gt;=l \u0026amp;\u0026amp; t\u0026lt;=r) return val(p) + tg*(t-s+1); else{ int mid = getMid(s,t); return query(l,r,ls(p),tg+tag(p),s,mid) + query(l,r,rs(p),tg+tag(p),mid+1,t); } } void solve(){ int m; std::cin\u0026gt;\u0026gt;m; for(int i=L;i\u0026lt;=R;i++){ std::cin\u0026gt;\u0026gt;arr[i]; } stcnt = 1; build(); roots[0] = 1; int time = 0;//本题只有加数才算进行一次版本修改 while(m--){ char o;int l,r;LL d; std::cin\u0026gt;\u0026gt;o; if(o==\u0026#39;C\u0026#39;){ std::cin\u0026gt;\u0026gt;l\u0026gt;\u0026gt;r\u0026gt;\u0026gt;d;//[l,r]上每个数+d time++; roots[time] = ++stcnt; add(l,r,d,roots[time-1],roots[time]); } else if(o==\u0026#39;Q\u0026#39;){ std::cin\u0026gt;\u0026gt;l\u0026gt;\u0026gt;r;//查询当前版本[l,r]和 std::cout\u0026lt;\u0026lt;query(l,r,roots[time])\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } else if(o==\u0026#39;H\u0026#39;){ std::cin\u0026gt;\u0026gt;l\u0026gt;\u0026gt;r\u0026gt;\u0026gt;d;//查询版本d的[l,r]和 std::cout\u0026lt;\u0026lt;query(l,r,roots[d])\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } else if(o==\u0026#39;B\u0026#39;){ std::cin\u0026gt;\u0026gt;d;//把版本倒回d，中间的版本失效 time = d; } } std::cout\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } signed main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); while(std::cin\u0026gt;\u0026gt;R){//本题多组数据 solve(); } return 0; } 主席树（可持久化权值线段树） //主席树，查询静态区间第k小，复杂度logn //luogu p3834 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; using LL = long long; int const MAXV = 8e6+5; int const MAXN = 2e5+5; struct Node{ LL val; int ls, rs; }st[MAXV]; inline int\u0026amp; ls(int x){return st[x].ls;} inline int\u0026amp; rs(int x){return st[x].rs;} inline LL\u0026amp; val(int x){return st[x].val;} inline int getMid(int s, int t){ //处理负数边界时，需要强行向下取整，而不是向零取整 if(s+t==0) return 0; if(s+t\u0026gt;0) return (s+t)/2; return -((-s-t+1)/2); } int stcnt = 1; int L = 1, R = 2e5+5; void build(int s=L, int t=R, int p=1){ //初始化建成全0的，因为主席树是权值线段树的可持久化版 val(p) = 0; if(s!=t){ ls(p) = ++stcnt, rs(p) = ++stcnt; int mid = getMid(s,t); build(s,mid,ls(p)); build(mid+1,t,rs(p)); } } void add(int i, LL k, int p, int q, int s=L, int t=R){ //参数同单点修改 if(s==t) val(q) = val(p) + k; else{ ls(q) = ls(p), rs(q) = rs(p); int mid = getMid(s,t); if(i\u0026lt;=mid) ls(q) = ++stcnt, add(i,k,ls(p),ls(q),s,mid); else rs(q) = ++stcnt, add(i,k,rs(p),rs(q),mid+1,t); val(q) = val(ls(q)) + val(rs(q)); } } int arr[MAXN], disc[MAXN], assi[MAXN],ori[MAXN]; //arr是输入的原数组，disc是离散化后的，assi是临时的辅助数组 //ori[i]代表着在arr里排名为i的数 int roots[MAXN]; int kth(int k, int p, int q, int s=L, int t=R){ if(s==t) return ori[s]; int mid = getMid(s,t); if(val(ls(q)) - val(ls(p))\u0026gt;=k){ return kth(k, ls(p), ls(q), s, mid); } else{ return kth(k-(val(ls(q))-val(ls(p))), rs(p), rs(q), mid+1, t); } } int lrkth(int l, int r, int k){ //查询数组arr的[l,r]区间中第k小的数 return kth(k,roots[l-1],roots[r]); } void solve(){ int m; std::cin\u0026gt;\u0026gt;R\u0026gt;\u0026gt;m; for(int i=L;i\u0026lt;=R;i++){ std::cin\u0026gt;\u0026gt;arr[i]; disc[i] = assi[i] = arr[i]; } std::sort(assi+L,assi+R+1); int last = std::unique(assi+L,assi+R+1) - (assi+L); for(int i=L;i\u0026lt;=R;i++){ disc[i] = std::lower_bound(assi+L,assi+last,disc[i]) - (assi+L)+1; ori[disc[i]] = arr[i]; } //这上面都是离散化和数据输入 build(); roots[0] = 1; for(int i=L;i\u0026lt;=R;i++){ roots[i] = ++stcnt; add(disc[i],1,roots[i-1],roots[i]); //和权值线段树的思路一致 } while(m--){ int l,r,k; std::cin\u0026gt;\u0026gt;l\u0026gt;\u0026gt;r\u0026gt;\u0026gt;k; std::cout\u0026lt;\u0026lt;lrkth(l,r,k)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } } 线段树合并 //线段树合并，合并复杂度大概是O(klogN)，N是值域，k是若干线段树一共进行过k次插入 //luogu p3224 //动态开点线段树，之前的各种操作中都有p=1这一参数默认值，这其实是根节点的意思。也就是如果我们设置不同的p，可以开多颗线段树。 //线段树合并就是把重合位置的节点的值加起来，对于没有重合位置的节点则原地保留，常常用于权值线段树 int merge(int p, int q, int s=L, int t=R){ //不新开空间的合并方式 //把q为根的树合并到p为根的树上，返回p，即新根节点 //由于各题不一样，所以要在合并后手动把roots[j]指定为p if(!p||!q) return p+q; if(s==t) return val(p)+=val(q), p; int mid = getMid(s,t); ls(p) = merge(ls(p), ls(q), s, mid); rs(p) = merge(rs(p), rs(q), mid+1, t); val(p) = val(ls(p)) + val(rs(p)); return p; } int merge(int p, int q, int s=L, int t=R){ //新开空间的合并方式 //把p,q为根的两棵树合并到r为根的树上，返回r，即新根节点 //由于各题不一样，所以要在合并后手动把roots[i]和[j]指定为r if(!p||!q) return p+q; int r = ++stcnt; if(s==t) return val(r) = val(p)+val(q), r; int mid = getMid(s,t); ls(r) = merge(ls(p), ls(q), s, mid); rs(r) = merge(rs(p), rs(q), mid+1, t); val(r) = val(ls(r)) + val(rs(r)); return r; } 珂朵莉树 //珂朵莉树，区间推平问题 //方便给某个区间赋值，区间加数，维护区间第k大值，区间和等等 //数据随机的情况下，复杂度为nloglogn //珂朵莉树的每一个节点都是一个区间，这个区间内的值相同。 //cf896c struct Node{ int l,r; mutable LL v;//这里修改成自己需要的数据类型，在[l,r]内都等于这个值 Node(int l, int r, LL v):l(l),r(r),v(v){} bool operator\u0026lt;(Node const \u0026amp; x) const {return l\u0026lt;x.l;} }; class ODT{ public: std::set\u0026lt;Node\u0026gt; tree; auto split(int pos){ auto it = tree.lower_bound(Node(pos,0,0)); if(it!=tree.end() \u0026amp;\u0026amp; it-\u0026gt;l==pos) return it; it--; int l = it-\u0026gt;l, r = it-\u0026gt;r; LL v = it-\u0026gt;v; tree.erase(it); tree.insert(Node(l,pos-1,v)); return tree.insert(Node(pos,r,v)).first; } void assign(int l, int r, int v){ //给区间赋值 auto end = split(r+1), begin = split(l);//必须要注意顺序 tree.erase(begin,end); tree.insert(Node(l,r,v)); } void perf(int l, int r){//其他操作的模板函数 auto end = split(r+1), begin = split(l); for(auto it=begin;it!=end;it++){ //这里是操作 //这些操作都很暴力，例如k大值，就把区间全部枚举排序一遍去找 //例如区间和，就枚举区间加起来，注意是加it-\u0026gt;v * (it-\u0026gt;r-it-\u0026gt;l+1) //例如区间加数，就枚举区间给所有的it-\u0026gt;v都加一个数 } } }; //珂朵莉树的初始化不能用assign，设范围为[1,w]，初值全部为0，则 ODT odt; odt.tree.insert(Node(1,w,0)); 分块 分块是根号算法，比线段树略差，但是不需要满足结合律，也不需要传递tag。\n//luogu p3372 和线段树区间加，维护区间和一样 //复杂度n sqrt(n) //在块内时对块操作，跨块时中间对块操作，两边多余部分暴力处理 LL arr[MAXN]; class BA{ public: int st[MAXN],ed[MAXN],size[MAXN],bel[MAXN];//每一段的开始下标、结束下标、段大小；每个元素属于哪个段 int sq; LL sum[MAXN];//保存第i个块的和 LL tag[MAXN]; void init(int n){ sq = std::sqrt(n); for(int i=1;i\u0026lt;=sq;i++){ st[i] = n / sq * (i-1) + 1; ed[i] = n / sq * i; size[i] = ed[i] - st[i] + 1; } ed[sq] = n;//最后一段可能长度不够n/sq size[sq] = ed[sq] - st[sq] + 1; for(int i=1;i\u0026lt;=sq;i++) for(int j=st[i];j\u0026lt;=ed[i];j++) bel[j] = i, sum[i] += arr[j]; } void update(int l, int r, LL k){ if(bel[l]==bel[r]){ for(int i=l;i\u0026lt;=r;i++){ arr[i]+=k; sum[bel[i]] += k; } return; } for(int i=l;i\u0026lt;=ed[bel[l]];i++){ arr[i]+=k; sum[bel[i]]+=k; } for(int i=st[bel[r]];i\u0026lt;=r;i++){ arr[i]+=k; sum[bel[i]]+=k; } for(int i=bel[l]+1;i\u0026lt;bel[r];i++){ tag[i] += k; } } LL query(int l, int r){ LL ret = 0; if(bel[l]==bel[r]){ for(int i=l;i\u0026lt;=r;i++) ret += arr[i] + tag[bel[i]]; return ret; } for(int i=l;i\u0026lt;=ed[bel[l]];i++) ret += arr[i] + tag[bel[i]]; for(int i=st[bel[r]];i\u0026lt;=r;i++) ret += arr[i] + tag[bel[i]]; for(int i=bel[l]+1;i\u0026lt;bel[r];i++) ret += sum[i] + tag[i] * size[i]; return ret; } }; BA ba;//注意，开了大数组，要声明在main函数外面，或者可以去用动态分配内存 平衡树（pbds实现） 平衡树在ACM中用的极少，就不手搓了，大部分情况下都可以用set和pbds搞定。\n#include\u0026lt;ext/pb_ds/assoc_container.hpp\u0026gt; #include\u0026lt;ext/pb_ds/tree_policy.hpp\u0026gt; //仅限g++可以使用 namespace pbds = __gnu_pbds; pbds::tree\u0026lt;LL, pbds::null_type, std::less\u0026lt;LL\u0026gt;, pbds::rb_tree_tag, pbds::tree_order_statistics_node_update\u0026gt; tr; 声明如上，还是挺复杂的，但是ACM可以带资料所以不成问题。需要注意只能在g++上用，ACM赛场大多都有g++所以不是问题。\n模板参数解释\nLL是存储数据的类型；\npbds::null_type是映射规则（低版本g++为pbds::null_mapped_type，如果存入类型为std::map\u0026lt;Key,Value\u0026gt;则要填入Value）；\nstd::less\u0026lt;LL\u0026gt;则是我们选择大根还是小根；可选参数，默认为less\npbds::rb_tree_tag 则是我们选择的树的类型。总共有三种平衡树在pbds里，红黑树、splay、ov，但是后两个容易超时，一般不用。可选参数，默认为红黑树\npbds::tree_order_statistics_node_update是节点更新方法，如果使用order_of_key和find_by_key方法，则要用它。可选参数，但默认是null_node_update。\n方法\ntr.insert(x); //插入一个元素x，返回std::pair\u0026lt;point_iterator, bool\u0026gt; //若成功，则是插入之后的迭代器和true，否则是x的迭代器和false tr.erase(x); //成功返回true，也可以把迭代器作为参数 tr.order_of_key(x); //返回x的排名，0为第一名，x不一定要在树里 tr.find_by_order(k); //返回排名为k的元素的迭代器，0为第一名 tr.lower_bound(x); //返回迭代器，这个函数不用多说了吧，和经常见到的一样 tr.upper_bound(x); //返回迭代器 tr.join(b); //将b树并入当前树，两棵树的类型要一样，不能有重复元素，b树将会被删除 tr.split(x,b); //小于等于x的保留在当前树，其他分给b树 tr.empty(); tr.size(); 以上操作均为O(logn)复杂度，除了最后两个是O(1)\n注意事项\ntree里面的元素是唯一的，有点类似与set。但我们并没有multi-tree去使用，做例如洛谷上的平衡树模板题，他要求元素可重复。此时我们有以下奇技淫巧\nLL n; std::cin\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ int ope; LL x; std::cin\u0026gt;\u0026gt;ope\u0026gt;\u0026gt;x; if(ope==1) tr.insert((x\u0026lt;\u0026lt;20)+i); else if(ope==2) tr.erase(tr.lower_bound(x\u0026lt;\u0026lt;20)); else if(ope==3) std::cout\u0026lt;\u0026lt;tr.order_of_key(x\u0026lt;\u0026lt;20)+1\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; else if(ope==4) std::cout\u0026lt;\u0026lt;((*tr.find_by_order(x-1))\u0026gt;\u0026gt;20)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; else if(ope==5){ auto it = tr.lower_bound(x\u0026lt;\u0026lt;20); it--; std::cout\u0026lt;\u0026lt;((*it)\u0026gt;\u0026gt;20)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } else{ auto it = tr.upper_bound((x\u0026lt;\u0026lt;20)+n); std::cout\u0026lt;\u0026lt;((*it)\u0026gt;\u0026gt;20)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } } 假设有\\(n\\)个操作，共\\(6\\)种\n插入\\(x\\) 删除\\(x\\) 查询\\(x\\)的排名（比\\(x\\)小的数的个数\\(+1\\)） 查询排名为\\(x\\)的数 求小于\\(x\\)的最大的数 求大于\\(x\\)的最小的数 看代码，我们将\\(x\\)左移20位，加上了操作序号，这样我们就可以实现可重复插入。只需要我们再最后把数字右移20位回来即可。erase注意是加入迭代器去erase，因为我们并没有等于x\u0026lt;\u0026lt;20的数字。最后一个操作，要\\(+n\\)，来处理所有的相等的\\(x\\)\n01字典树 //01字典树，复杂度线性 //HDU4825 int const MAXN = 3500005; int const MAXBIT = 35;//注意题目给的数据范围，这里2^32以下可以处理 class Trie{ public: int nxt[MAXN][2]; int cnt; LL num[MAXN]; void init(){ for(int i=0;i\u0026lt;=cnt;i++) for(int j=0;j\u0026lt;2;j++) nxt[i][j] = 0; for(int i=0;i\u0026lt;=cnt;i++) num[i] = 0; cnt = 0; } void insert(LL n){ //插入一个自然数 int cur = 0; for(LL i=MAXBIT;i\u0026gt;=0;i--){ LL bit = (n\u0026gt;\u0026gt;i)\u0026amp;1; if(!nxt[cur][bit]){ nxt[cur][bit] = ++cnt; } cur = nxt[cur][bit]; } num[cur] = n; } LL find_max(LL x){ //查询x与数组内的所有数的异或的最大值 int cur=0; for(int i=MAXBIT;i\u0026gt;=0;i--){ LL bit = (x\u0026gt;\u0026gt;i)\u0026amp;1; if(nxt[cur][bit^1])//尽量走与当前位不同的路径，最小值应改为走相同的 cur = nxt[cur][bit^1]; else cur = nxt[cur][bit]; } return x^num[cur]; } }; Trie trie; 可以通过01Trie来计算连续区间的异或最大值。要用到一个性质：\n\\[a\\oplus b\\oplus b = a \\]\n也就是说，我们可以把异或前缀全部插入到Trie里，然后以第i个数为结尾的区间的最大异或值就是find_max(pre[i])。注意特殊处理长度为1的区间。\nLL ans = 0; arr[0] = 0; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;arr[i]; ans = std::max(ans,arr[i]); arr[i] ^= arr[i-1]; } trie.insert(0);//注意要先插入一个0 for(int i=1;i\u0026lt;=n;i++){ ans = std::max(ans,trie.find_max(arr[i])); trie.insert(arr[i]); } std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; 对顶堆 //动态维护一个集合的第k大数，每次操作logn //spoj RMID2 //维护第k小只要维护第n-k大即可 //另外这个k是可以变化的，不需要固定，复杂度确实是logn #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; #include \u0026lt;vector\u0026gt; template\u0026lt;typename T\u0026gt; class KthLargest{ private: std::priority_queue\u0026lt;T,std::vector\u0026lt;T\u0026gt;,std::less\u0026lt;T\u0026gt; \u0026gt; big{}; std::priority_queue\u0026lt;T,std::vector\u0026lt;T\u0026gt;,std::greater\u0026lt;T\u0026gt; \u0026gt; small{}; size_t kth{}; size_t size{}; void update(){ kth = std::min(kth,size); while(kth\u0026lt;small.size()){ big.push(small.top()); small.pop(); } while(kth\u0026gt;small.size()){ small.push(big.top()); big.pop(); } } public: KthLargest():kth(1),size(0){} T findK(size_t k){ //找到第k大的数字 kth = k; update(); return small.top(); } void eraseK(size_t k){ //移除第k大的数字 kth = k; update(); small.pop(); size--; update(); } void insert(T x){ //插入一个数字 size++; if(small.empty() || x\u0026gt;=small.top()){ small.push(x); } else{ big.push(x); } update(); } size_t getSize(){ return size; } }; KthLargest\u0026lt;int\u0026gt; ddd; 单调栈 //单调栈 luogu p5788 //本题定义f[i]为数列中第i个元素之后第一个大于a[i]的元素的下标（不存在则为0） //很显然我们可以维护一个单调不增的栈 //当push的元素x大于栈顶t时，第一个大于t的元素就是x。反复出栈直到栈顶t小于等于x或栈空，入栈。 //复杂度 n int arr[MAXN]; int ans[MAXN]; int stk[MAXN]; int main(){ int n; std::cin\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;arr[i]; } int top = 0; for(int i=1;i\u0026lt;=n;i++){ while(top\u0026amp;\u0026amp;arr[stk[top]]\u0026lt;arr[i]){ ans[stk[top]] = i;//这一行是具体的操作，因题而异；而其他行在这个for循环里都是固定的 top--; } stk[++top] = i; } for(int i=1;i\u0026lt;=n;i++){ std::cout\u0026lt;\u0026lt;ans[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } return 0; } 单调队列 //单调队列，luogu1886 //本题是滑动窗口，即在长度为n的数组中，给出一个长度为k的连续区间，从左向右滑动，求每个区间中的最大值和最小值 //求最小值时，我们可以维护一个单增的双端队列。x加入队尾时，如果队尾元素b\u0026gt;=x，则把队尾弹出，直到b\u0026lt;x或者栈空时把x入队。 //因为我们的区间长度有限，每次我们的区间左端点向右枚举+1时，判断队首元素的下标，如果小于区间左端点，就出队。 //之后留在队首的元素就是区间最小值 //具体可见代码。最大值维护同理。 //复杂度n int arr[MAXN]; int main(){ int n,k; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;k; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;arr[i]; } std::deque\u0026lt;int\u0026gt; dq; for(int i=1;i\u0026lt;k;i++){ while(!dq.empty()\u0026amp;\u0026amp;arr[dq.back()]\u0026gt;=arr[i]) dq.pop_back(); dq.push_back(i); } for(int i=k;i\u0026lt;=n;i++){ while(!dq.empty()\u0026amp;\u0026amp;arr[dq.back()]\u0026gt;=arr[i]) dq.pop_back(); dq.push_back(i); while(dq.front()\u0026lt;=i-k) dq.pop_front(); std::cout\u0026lt;\u0026lt;arr[dq.front()]\u0026lt;\u0026lt;\u0026#34; \u0026#34;;//输出最小值 } std::cout\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; dq.clear(); for(int i=1;i\u0026lt;k;i++){ while(!dq.empty()\u0026amp;\u0026amp;arr[dq.back()]\u0026lt;=arr[i]) dq.pop_back(); dq.push_back(i); } for(int i=k;i\u0026lt;=n;i++){ while(!dq.empty()\u0026amp;\u0026amp;arr[dq.back()]\u0026lt;=arr[i]) dq.pop_back(); dq.push_back(i); while(dq.front()\u0026lt;=i-k) dq.pop_front(); std::cout\u0026lt;\u0026lt;arr[dq.front()]\u0026lt;\u0026lt;\u0026#34; \u0026#34;;//输出最大值 } return 0; } ST表 对于经典的RMQ（即给定一个数组，求区间内的最大值）问题，有如下代码\n//复杂度 单次查询 logn 预处理 nlogn //luogu P3865 //查询区间最大值 //也可以查询其他可重复贡献问题的信息 //可重复贡献指对于运算op，满足x op x = x。这样的运算有最大最小、gcd等。但显然求和不是。 //另外op还必须满足结合律。 #include \u0026lt;cstdio\u0026gt; #include \u0026lt;iostream\u0026gt; const int MAXN = 100005; const int LOGN = 21; int fmax[MAXN][LOGN+1]; //fmax[a][b]表示[a,a+2^b-1]中的最大值 int logn[MAXN]; //预先计算logn int main(){ int n,m; //数组大小以及查询次数 scanf(\u0026#34;%d%d\u0026#34;,\u0026amp;n,\u0026amp;m); for(int i=1;i\u0026lt;=n;i++){ scanf(\u0026#34;%d\u0026#34;,\u0026amp;fmax[i][0]); } logn[1] = 0; logn[2] = 1; for(int i=3;i\u0026lt;MAXN;i++){ logn[i] = logn[i/2]+1; //预先计算logn } for(int j=1;j\u0026lt;=LOGN;j++){ for(int i=1;i+(1\u0026lt;\u0026lt;j)-1\u0026lt;=n;i++){ fmax[i][j] = std::max(fmax[i][j-1],fmax[i+(1\u0026lt;\u0026lt;(j-1))][j-1]); } } for(int i=1;i\u0026lt;=m;i++){ int a,b; scanf(\u0026#34;%d%d\u0026#34;,\u0026amp;a,\u0026amp;b); //查询[a,b]分为两部分，即[a,a+2^s-1]与[b-2^s+1,b] //完全不用担心这两个范围重叠，因为是求max int s = logn[b-a+1]; printf(\u0026#34;%d\\n\u0026#34;,std::max(fmax[a][s],fmax[b-(1\u0026lt;\u0026lt;s)+1][s])); } return 0; } 二分 二分答案 给出一个通用代码\nint l = 0; int r = MAXR; while(l+1\u0026lt;r){ int mid = (l+r)\u0026gt;\u0026gt;1; if(judge(mid)) l=mid; else r = mid; } if(judge(l)) std::cout\u0026lt;\u0026lt;l\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; else std::cout\u0026lt;\u0026lt;r\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; 当验证一个情况是否能满足题目的复杂度小于等于\\(O(n)\\)，而且这些情况具有单调性（即例如若x\u0026gt;y，x不能满足，则y一定不能满足）时，就可以通过二分去得到最符合题意的答案。二分这些情况的复杂度为\\(O(\\log n)\\)，再乘上验证情况的复杂度得到总的复杂度。\njudge函数应该根据题意写出。\n如果是浮点数的二分，则不推荐使用EPS进行精度判断（有可能会丢精度）。而是使用计数器，一般迭代100次就能保证符合题目要求。\n二分查找 通常是在排好序上的数组中，查找第一个大于（或大于等于）x的元素。见STL用法中的lower_bound和upper_bound。每次查找的复杂度是logn\n二分求单调函数零点 设函数\\(f\\)在\\([l,r]\\)上严格单调，\\(mid=(l+r)/2\\)，显然有\\(f(l)f(r)\u003c0\\)。迭代中，若\\(f(l)f(mid)\u003c0\\)，则\\(r=mid\\)，否则\\(l=mid\\)。直到\\(f(mid)=0\\)或者\\(r-l\u003c EPS\\)或者迭代次数达到要求。收敛速度是线性收敛。\n三分法 三分法求单峰函数的极值点 用二分求函数的导数的零点也可以，但是并不是每次都可以方便的求出导数。三分法可以不用求出导数。\n设函数\\(f\\)在\\([l,r]\\)上单峰，意味着有且只有一个极大值\\(x\\)，\\(f\\)在\\([l,x]\\)上严格单增，在\\([x,r]\\)上严格单减。单谷函数则为极小值\\(x\\)。\n//三分法求单峰函数的极值点 luogu p3382 //收敛速度是线性收敛 //用二分求函数的导数的零点也可以，但是并不是每次都可以方便的求出导数。三分法可以不用求出导数。 //设函数f在[l,r]上单峰，意味着有且只有一个极大值x，f在[l,x]上严格单增，在[x,r]上严格单减。单谷函数则为极小值x。 //在[l,r]上取两个不等的点，设靠近l的是l1，靠近r的是r1。如果f(l1)\u0026lt;f(r1)，说明极大值一定在[l1,r]，令l=l1 //如果f(l1)\u0026gt;f(r1)，极大值一定在[l,r1]，令r=r1 //持续下去直到r-l\u0026lt;EPS或者迭代次数足够 //取l1和r1时，可以直接取三等分点，也可以取黄金分割点(l1=l+(r-l)(1-0.618),r1=r-(r-l)*(1-0.618)) //还可以让l1=mid-EPS, r1=mid-EPS，但是要令l=mid而不是l=l1，防止死循环 using DB = double; DB const EPS = 1e-8; DB l,r; std::cin\u0026gt;\u0026gt;l\u0026gt;\u0026gt;r; while(r-l\u0026gt;EPS){ DB mid = (l+r)/2; DB f1 = func(mid-EPS), f2 = func(mid+EPS);//func根据题目要求定义，是一元函数 if(f1\u0026lt;f2) l = mid; else r = mid; } 三分套三分 例如Luogu P2571，这是一个二元函数要求最小值。我们发现这个函数在固定\\(x\\)的时候\\(y\\)是单谷的，固定\\(y\\)的时候\\(x\\)是单谷的。所以我们可以先三分一个变量，再固定这个变量三分另一个变量，最后得出答案。\n注意，三分套三分是指不能先假设一个\\(y\\)的定值，再三分\\(x\\)，然后拿着计算出的\\(x\\)再去三分\\(y\\)。应当在三分\\(x\\)的过程中，把\\(x\\)当作参数，传入三分\\(y\\)的函数中。它们不是先后关系，而是嵌套关系。\nauto func = [\u0026amp;](DB x, DB y){ //这里是函数定义 }; auto sfy = [\u0026amp;](DB x){//固定x，三分y DB ret = 0.0; DB l = 0.0, r = 1.0; while(r-l\u0026gt;EPS){ DB delta = (r-l)/3.0; DB f1 = func(x,l+delta), f2 = func(x,r-delta); if(f1\u0026gt;f2) l = l+delta; else r = r-delta; } return func(x,l); }; DB l=0.0,r=1.0; while(r-l\u0026gt;EPS){//三分x DB delta = (r-l)/3.0; DB f1 = sfy(l+delta), f2 = sfy(r-delta); if(f1\u0026gt;f2) l = l+delta; else r = r-delta; } //最后的答案是sfy(l) 三分答案 TODO 动态规划 01背包 //复杂度 nW //luogu P1048 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cmath\u0026gt; int const MAXN = 1005; using namespace std; int dp[MAXN]; int w[MAXN]; int v[MAXN]; int main(){ int n,W;//物品数，背包大小 cin\u0026gt;\u0026gt;W\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ cin\u0026gt;\u0026gt;w[i]\u0026gt;\u0026gt;v[i];//物品体积，物品价值 } for(int i=1;i\u0026lt;=n;i++){ for(int j=W;j\u0026gt;=w[i];j--){ dp[j] = std::max(dp[j],dp[j-w[i]]+v[i]); } } cout\u0026lt;\u0026lt;dp[W]\u0026lt;\u0026lt;endl; return 0; } 完全背包 //复杂度 nW //luogu P1616 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cmath\u0026gt; int const MAXN = 10007; int const MAXW = 10000007; typedef long long LL; using namespace std; LL dp[MAXW]; int w[MAXN]; int v[MAXN]; int main(){ int n,W;//物品数，背包大小 cin\u0026gt;\u0026gt;W\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ cin\u0026gt;\u0026gt;w[i]\u0026gt;\u0026gt;v[i];//物品体积，物品价值 } for(int i=1;i\u0026lt;=n;i++){ for(int j=w[i];j\u0026lt;=W;j++){ dp[j] = std::max(dp[j],dp[j-w[i]]+v[i]); } } cout\u0026lt;\u0026lt;dp[W]\u0026lt;\u0026lt;endl; return 0; } 多重背包 //复杂度 Wsum(logk_i) //luogu P1776 //即每种物品有ki个 //我们可以简单转化为01背包，但是复杂度太高；采用二进制分组的思想 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cmath\u0026gt; int const MAXN = 100007; int const MAXW = 40007; typedef long long LL; using namespace std; LL dp[MAXW]; int w[MAXN]; int v[MAXN]; int main(){ int m,W;//物品种类数，背包大小 cin\u0026gt;\u0026gt;m\u0026gt;\u0026gt;W; int n = 0; for(int i=1;i\u0026lt;=m;i++){ int c = 1; int p,h,k;//物品价值，物品体积，物品数量 cin\u0026gt;\u0026gt;p\u0026gt;\u0026gt;h\u0026gt;\u0026gt;k; while(k\u0026gt;c){ k -= c; v[++n] = c*p; w[n] = c*h; c *= 2; } v[++n] = p*k; w[n] = h*k; } for(int i=1;i\u0026lt;=n;i++){ for(int j=W;j\u0026gt;=w[i];j--){ dp[j] = std::max(dp[j],dp[j-w[i]]+v[i]); } } cout\u0026lt;\u0026lt;dp[W]\u0026lt;\u0026lt;endl; return 0; } 分组背包 //分组背包 复杂度=组数*背包容量*组内个数最大值 //luogu p1757 //有g个组，每组物品有group[i].size()个，每个物品有价值v和体积w，总共n个物品，背包体积为m。每个组最多只能拿一个物品出来，求最大价值。 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; int const MAXN = 1005; int dp[MAXN]; std::vector\u0026lt;int\u0026gt; group[MAXN];//存储每一组的物品序号 int v[MAXN],w[MAXN];//物品价值和体积 void solve(){ int n,m; std::cin\u0026gt;\u0026gt;m\u0026gt;\u0026gt;n;//背包容量;n件物品 for(int i=1;i\u0026lt;=n;i++){ int a,b,c; std::cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b\u0026gt;\u0026gt;c; w[i] = a, v[i] = b,group[c].push_back(i); } int const g = 100;//本题中只说了有g个组，没有给出具体有多少个以及是否连续，采取遍历的方法 for(int i=1;i\u0026lt;=g;i++){ if(group[i].size()==0) continue; for(int j=m;j\u0026gt;=0;j--){ for(auto k:group[i]){//注意这三个循环的顺序不能改变 if(j\u0026gt;=w[k]) dp[j] = std::max(dp[j], dp[j-w[k]]+v[k]); } } } std::cout\u0026lt;\u0026lt;dp[m]\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int T; T=1; while(T--){ solve(); } return 0; } 最长上升子序列 //最长上升子序列 复杂度nlogn //luogu B3637 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cstring\u0026gt; const int MAXN = 100005; int arr[MAXN]; int dp[MAXN]; //dp[i]表示长度为i的上升子序列的最后一个元素的最小值 //例如1 2 5 3 4 1。 //最开始dp[1]=1，arr[2]=2\u0026gt;dp[1]，所以插入dp[2]=2;arr[3]同理，得到dp={1,2,5};到arr[4]=3时，我们找到第一个大于等于3的元素，即dp[3]，替换他，得到dp={1,2,3};接下来到arr[5]=4，现在4\u0026gt;3，可以插入末尾得到dp={1,2,3,4}，显然我们刚刚的操作把5换成3，让后面的数更有可能直接加入到数组末尾了。最后arr[6]=1，由于我们求的是最长上升子序列，而不是最长不下降，所以替换不影响。 //注意dp里面的数字并不是最长的序列，例如我们加一个0进去，dp={0,2,3,4}，但是0是在最后的，不存在0,2,3,4这个序列。我们只能计算长度。 int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n; std::cin\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;arr[i]; } std::memset(dp,0x3f,sizeof(dp)); int maxv = dp[0]; for(int i=1;i\u0026lt;=n;i++){ *std::lower_bound(dp,dp+n,arr[i]) = arr[i]; //换成最长不下降子序列时，用upper_bound } int ans = 0; while(dp[ans]!=maxv) ans++; std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } Dilworth定理 把一个序列分为若干不上升子序列，其序列总数的最小值等于最长上升子序列的长度\n最长公共子序列 //最长公共子序列，复杂度nm //hdu 1159 //luogu p1439因为是排列，可以转化为LIS问题，复杂度是nlogn。但hdu1159没有这种性质，复杂度到不了nlogn #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;string\u0026gt; #define MAXN 505 int dp[MAXN][MAXN]; int lcs(std::string const \u0026amp; s1, std::string const \u0026amp; s2){ int n1=s1.size(),n2=s2.size(); std::memset(dp,0,sizeof(dp)); for(int i=1;i\u0026lt;=n1;i++){ for(int j=1;j\u0026lt;=n2;j++){ if(s1[i-1]==s2[j-1]) dp[i][j] = dp[i-1][j-1]+1; else dp[i][j] = std::max(dp[i][j-1],dp[i-1][j]); } } return dp[n1][n2]; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); std::string s1,s2; while(std::cin\u0026gt;\u0026gt;s1\u0026gt;\u0026gt;s2){ std::cout\u0026lt;\u0026lt;lcs(s1,s2)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } 最大子段和 //luogu P1115 //复杂度 n //求一个数组里面最大连续子段的和，可以为空，此时和为0 //如果要保证非空，则可以在外部加一条 //ans = std::max(ans, arr[i]); //并且如果每个数都是负数，则直接输出最大的负数。 LL calc(std::vector\u0026lt;LL\u0026gt; const \u0026amp; vec){ LL ret=0; LL cur=0; for(int i=0;i\u0026lt;vec.size();i++){ cur += vec[i]; if(cur\u0026lt;0) cur = 0; ret = std::max(ret, cur); } return ret; } 斜率优化TODO 四边形不等式TODO 悬线法 //luogu p1387 //悬线法求符合条件的最大矩形/正方形，复杂度 nm int grid[MAXN][MAXN]; int l[MAXN][MAXN], r[MAXN][MAXN], u[MAXN][MAXN]; //l,r分别表示从当前格向上的悬线最多能向左向右扩展多少格（含自己） //u表示当前格向上能扩展多少格（含自己），即悬线 void dp(int n, int m){ for(int i=1;i\u0026lt;=n;i++){ for(int j=1;j\u0026lt;=m;j++){ if(grid[i][j]) l[i][j] = l[i][j-1]+1;//若(i,j-1)可选，当然首先要(i,j)可选，(i,j-1)不可选时l[i][j-1]会等于0，l[i][j]就会等于1 //这里的if条件看情况选择，下面同理 } } for(int i=1;i\u0026lt;=n;i++){ for(int j=m;j\u0026gt;=1;j--){ if(grid[i][j]) r[i][j] = r[i][j+1]+1;//若(i,j+1)可选 } } for(int i=1;i\u0026lt;=n;i++){ for(int j=1;j\u0026lt;=m;j++){ if(grid[i][j]){ u[i][j] = u[i-1][j]+1; if(grid[i-1][j]){//若(i-1,j)可选 l[i][j] = std::min(l[i][j], l[i-1][j]); r[i][j] = std::min(r[i][j], r[i-1][j]); } //然后在这里对ans进行该有的操作，因题而异 //对于(i,j)这一格来说，它对应的悬线向左右拓展能得到的最大矩形面积为 //u[i][j]*(l[i][j]+r[i][j]-1) //最大正方形为 //min(u[i][j],l[i][j]+r[i][j]-1)的平方 } } } } 数位DP 数位DP是对有多少数符合特性的计数问题。通常他的题目数据范围会很大，比如\\(10^{18}\\)。题目通常也会要求我们的数字要在某个范围内，还有可能会要求符合题意的一对、一组数。\n我们通常会用记忆化搜索来实现。\n//数位dp模板题，常用记忆化搜索实现 //hdu 2089 //本题要求，[n,m]之间的所有整数，不含4，不含62（连续的）的数字有多少个 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cmath\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; #define pb push_back std::vector\u0026lt;int\u0026gt; digit;//用于存储getSum中x的每一位，最高位从0下标开始 int dp[8][12][2];//dp[pos][last][limit] //pos代表搜索到第几位，如五位数，pos==0说明搜索到高位第一位，pos==4说明搜索到个位 //last代表上一位搜索的数字是多少，如果last==11，10这样的数字则代表目前在搜索pos==0。设置为11还是10还是别的什么要看题目对只有一位数时的要求 //limit代表本位数字的取值有没有限制，例如上限是12345，现在搜到了12???，要搜第三位，显然第三位只能取0,1,2,3，limit==true。又如搜到了11???，第三位就可以取0-9，limit==false。 //limit==true当且仅当上一位limit也为true且取得最大值（第一位特判） int dfs(int pos, int last, bool limit){ int ret = 0; if(pos==digit.size()) return 1;//搜索终点，由于不是非法状态所以返回1 if(dp[pos][last][limit] != -1) return dp[pos][last][limit]; for(int v=0;v\u0026lt;=(limit ? digit[pos] : 9);v++){ if((last==6 \u0026amp;\u0026amp; v==2) || v==4) continue;//非法状态 ret += dfs(pos+1, v, limit \u0026amp;\u0026amp; v==digit[pos]); } dp[pos][last][limit] = ret; return ret; } int getSum(int x){ digit.clear(); std::memset(dp,-1,sizeof(dp)); while(x){//注意如果某些题0也在范围内要特判 digit.pb(x%10); x/=10; } std::reverse(digit.begin(),digit.end());//高位到低位存 return dfs(0,10,true); } void solve(int n, int m){ std::cout\u0026lt;\u0026lt;getSum(m)-getSum(n-1)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m; while(std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m){ if(n==0 \u0026amp;\u0026amp; m==0) break; solve(n,m); } return 0; } 下面再给出一例，求一对数字的、与位运算有关的，拆分成二进制的题。\n//数位dp另一例 //atcoder abc317_f //本题给定n,a1,a2,a3。要求求三元组\u0026lt;x1,x2,x3\u0026gt;的个数，满足 //1. 1\u0026lt;=xi\u0026lt;=n，对所有i //2. xi是ai的任意倍数，对所有i //3. x1^x2^x3=0 //其中n取值[1,1e18] //ai取值[1,10] #define pb push_back using LL = long long; LL const MOD = 998244353; std::vector\u0026lt;int\u0026gt; digit; int dp[80][12][12][12][2][2][2][2][2][2]; int a1,a2,a3; int dfs(int pos, int r1, int r2, int r3, bool l1, bool l2, bool l3, bool z1, bool z2, bool z3){ //分布代表着，pos位数字，上一位搜索到的x1除以a1的余数,...,x1的limit,...,x1是否前面全是前导0 int ret = 0; if(pos==-1){ return !z1 \u0026amp;\u0026amp; !z2 \u0026amp;\u0026amp; !z3 \u0026amp;\u0026amp; !r1 \u0026amp;\u0026amp; !r2 \u0026amp;\u0026amp; !r3; //每个数都没有前导零（即填入了至少一个数字），以及余数都是0（即xi已经是ai的倍数了） } if(dp[pos][r1][r2][r3][l1][l2][l3][z1][z2][z3] != -1) return dp[pos][r1][r2][r3][l1][l2][l3][z1][z2][z3]; int m1 = l1 ? digit[pos] : 1; int m2 = l2 ? digit[pos] : 1; int m3 = l3 ? digit[pos] : 1; for(LL i=0;i\u0026lt;=m1;i++){ for(LL j=0;j\u0026lt;=m2;j++){ for(LL k=0;k\u0026lt;=m3;k++){ if((i^j^k)!=0) continue; int newr1 = ((LL)r1+(i\u0026lt;\u0026lt;pos))%a1;//计算新的余数 int newr2 = ((LL)r2+(j\u0026lt;\u0026lt;pos))%a2; int newr3 = ((LL)r3+(k\u0026lt;\u0026lt;pos))%a3; ret = (ret + dfs(pos-1,newr1,newr2,newr3, l1\u0026amp;\u0026amp;i==digit[pos], l2\u0026amp;\u0026amp;j==digit[pos],l3\u0026amp;\u0026amp;k==digit[pos], z1\u0026amp;\u0026amp;i==0,z2\u0026amp;\u0026amp;j==0,z3\u0026amp;\u0026amp;k==0))%MOD; } } } dp[pos][r1][r2][r3][l1][l2][l3][z1][z2][z3] = ret; return ret; } int getSum(LL x){ digit.clear(); std::memset(dp,-1,sizeof(dp)); while(x){ digit.pb(x%2); x/=2; }//本题低位到高位存更方便，方便移位运算 return dfs(digit.size()-1,0,0,0,1,1,1,1,1,1); } void solve(){ LL n; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;a1\u0026gt;\u0026gt;a2\u0026gt;\u0026gt;a3; std::cout\u0026lt;\u0026lt;getSum(n)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } 选择低位到高位还是高位到低位应该根据题目的不同来选择。\n另外如果满足limit为真的情况出现的概率远低于为假的，那么可以把limit这一维省略掉，dp数组里面只记录limit为假的情况。\n低位到高位存还有一个好处。我们知道高位到低位存时，由于数字长度不一样，比如a有5位，b有10位，把a的dp数组求完后，求b时就必须再次清空成-1。原因是，对于a的pos为1，也就是从高到低第二位，其实对应这b的pos为6，我们就不能用a中求出的dp带进去b里面计算了。\n而低位到高位就没有这个问题，大家的最低位都是平等的从0下标开始的，可以进行复用。清零为-1只需要程序最开始的时候清零一次即可。有时候程序有多个case会避免TLE。\n概率论 处理分数期望、概率 有时候，题目中的期望是一个分数\\(\\frac{P}{Q}\\)，而为了防止精度问题，往往会要求输出一个\\(R\\)，满足\n\\[R\\times Q\\equiv P(mod\\ 998244353) \\]\n此时\n\\[R = (P\\times Q^{-1})\\%998244353 \\]\n\\(Q^{-1}\\)是\\(Q\\)在模\\(998244353\\)意义下的乘法逆元\n杂项 快速幂 //复杂度logn //快速幂 //luogu P1226 using LL = long long; LL qPow(LL x, LL p){ //x^p LL res = 1; while(p){ if(p\u0026amp;1){ res = res * x; } x *= x; p\u0026gt;\u0026gt;=1; } return res; } LL qPowMod(LL x, LL p, LL m){ //x^p % m LL res = 1; while(p){ if(p\u0026amp;1){ res = (res * x)%m; } x = (x*x)%m; p\u0026gt;\u0026gt;=1; } return res; } 离散化 有两种，一种是unique函数版，一种是树状数组求逆序对里使用的，都可以，区别是，那个对于相同的数字根据先后顺序确定大小，这个则是一样大\n//复杂度nlogn //离散化 例如将1,500,40,1000保持相对大小不变，离散化为1,3,2,4 //出现同样的数字时，例如6,-4,3,7,3会离散化为3,1,2,4,2 //luogu B3694 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; std::vector\u0026lt;int\u0026gt; arr,assi; void solve(){ int n; std::cin\u0026gt;\u0026gt;n; arr.clear(); assi.clear(); for(int i=1;i\u0026lt;=n;i++){ int a; std::cin\u0026gt;\u0026gt;a; arr.push_back(a); assi.push_back(a); } std::sort(assi.begin(),assi.end()); assi.erase(std::unique(assi.begin(),assi.end()),assi.end()); for(int i=0;i\u0026lt;n;i++){ arr[i] = std::upper_bound(assi.begin(),assi.end(),arr[i])-assi.begin(); } for(int i=0;i\u0026lt;n;i++){ std::cout\u0026lt;\u0026lt;arr[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } std::cout\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } 莫队算法 //对于序列上的区域离线询问问题，如果[l,r]的答案能够O(1)拓展得到 //[l-1,r],[l+1,r],[l,r-1],[l,r+1]的答案，那么就可以在O(n sqrt(n))中解决所有询问 //SPOJ DQUERY //本题是给定若干个区间[l,r]，查询这个范围内有多少个不同的数 int arr[MAXN]; int sq;//分块数sq = sqrt(n) struct Query{ int l,r,id;//询问区间和询问下标 bool operator\u0026lt;(Query const \u0026amp; x)const{ if(l/sq != x.l/sq)//根据归属于哪个块排序 return l\u0026lt;x.l; if(l/sq \u0026amp; 1) //玄学奇偶排序 return r\u0026lt;x.r; return r\u0026gt;x.r; } }Q[MAXQ]; int ans[MAXQ], cnt[MAXA], cur; int l=1,r=0;//初始化询问区间 inline void add(int p){ if(cnt[arr[p]]==0)//新增一种数 cur++; cnt[arr[p]]++; } inline void del(int p){ cnt[arr[p]]--; if(cnt[arr[p]]==0)//把一种数全部删完 cur--; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n; std::cin\u0026gt;\u0026gt;n; sq = std::sqrt(n); for(int i=1;i\u0026lt;=n;i++) std::cin\u0026gt;\u0026gt;arr[i]; int q; std::cin\u0026gt;\u0026gt;q; for(int i=0;i\u0026lt;q;i++){ std::cin\u0026gt;\u0026gt;Q[i].l\u0026gt;\u0026gt;Q[i].r; Q[i].id = i;//把询问离线 } std::sort(Q,Q+q); for(int i=0;i\u0026lt;q;i++){ while(l\u0026gt;Q[i].l) add(--l);//当前区间l大于查询的l，要把左边的数加进来 while(r\u0026lt;Q[i].r) add(++r);//当前区间r小于查询的r，要把右边的数加进来 while(l\u0026lt;Q[i].l) del(l++);//当前区间l小于查询的l，要把左边的数删掉 while(r\u0026gt;Q[i].r) del(r--);//当前区间r大于查询的r，要把右边的数删掉 //注意上述顺序，扩张区间是先移动再更新，缩减区间是先更新再移动 //四个操作的具体实现可能会有不一样，具体题目具体讨论 ans[Q[i].id] = cur; } for(int i=0;i\u0026lt;q;i++){ std::cout\u0026lt;\u0026lt;ans[i]\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } 0/1分数规划 0/1分数规划的目的是如下列式子取值最大化\n\\[\\dfrac{\\sum^n_{i=1}a_ix_i}{\\sum^n_{i=1}b_ix_i} \\]\n其中\\(\\{a_i\\}\\)和\\(\\{b_i\\}\\)是给定的数列，而\\(\\{x_i\\}\\)是要求的一组解，其取值只能是\\(0\\)或\\(1\\)。或者说，给定\\(n\\)对数\\(a_i,b_i\\)，从中选出若干对（通常题目要求恰好选\\(k\\)对），使选出的数对的\\(a\\)之和和\\(b\\)之和的商最大。\n我们转化成二分答案，验证一个值\\(m\\)，上式的取值能否大于等于\\(m\\)。转化一下就可以得到，是否存在一组解\\(x_1,\\cdots,x_n\\)，满足\n\\[\\sum^n_{i=1}(a_i-m\\times b_i)\\times x_i\\geq 0 \\]\n如果存在则说明\\(m\\)比最大值要小，否则\\(m\\)比最大值要大，满足二分性。\n我们可以计算每一个\\((a_i-m\\times b_i)\\)，如果题目说可以任意选择若干对，则只要有一个非负数，就能满足条件。如果要求恰好选\\(k\\)对，那么我们全部算出来然后排序，选择最大的\\(k\\)个，其和非负就能满足条件。\n//0/1分数规划，复杂度n log^2 n //nowcoder NC14662 //介绍见markdown LL a[MAXN],b[MAXN]; int n,k; bool judge(DB mid){ std::vector\u0026lt;DB\u0026gt; vec; for(int i=1;i\u0026lt;=n;i++){ vec.pb(a[i]-mid*b[i]); } std::sort(vec.begin(),vec.end()); DB sum = 0; for(int i=n-1;i\u0026gt;=0 \u0026amp;\u0026amp; n-1-i+1\u0026lt;=k;i--) sum+=vec[i]; if(sum\u0026gt;=0) return true; return false; } void solve(){ std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;k; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;b[i]\u0026gt;\u0026gt;a[i]; } DB l=0, r=1e13; for(int i=1;i\u0026lt;=100;i++){ DB mid = (l+r)/2; if(judge(mid)) l = mid; else r = mid; } std::cout\u0026lt;\u0026lt;(LL)r\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } 表达式求值 可能需要进一步完善TODO inline bool isOper(char c){ return c==\u0026#39;+\u0026#39;||c==\u0026#39;-\u0026#39;||c==\u0026#39;*\u0026#39;||c==\u0026#39;/\u0026#39;; } inline bool isDigit(char c){ return c\u0026gt;=\u0026#39;0\u0026#39; \u0026amp;\u0026amp; c\u0026lt;=\u0026#39;9\u0026#39;; } inline int priority(char oper){ if(oper==\u0026#39;+\u0026#39; || oper==\u0026#39;-\u0026#39;) return 1; if(oper==\u0026#39;*\u0026#39; || oper==\u0026#39;/\u0026#39;) return 2; return -1; } std::string toRPN(std::string expr){ std::string ret; std::stack\u0026lt;char\u0026gt; oper; int esize = expr.size(); for(int i=0;i\u0026lt;esize;i++){ char\u0026amp; c = expr[i]; if(c==\u0026#39; \u0026#39;) continue; else if(isOper(c)){ if(c==\u0026#39;-\u0026#39; \u0026amp;\u0026amp; (i==0 || expr[i-1]==\u0026#39;(\u0026#39;)){ //判断一元运算符负号，这里采用了加个0-前缀的方法，如果题目要求输出RPN其实是做不到的 //TODO: 把toRPN返回一个vector，实现真正的RPN ret.push_back(\u0026#39;0\u0026#39;); ret.push_back(\u0026#39; \u0026#39;); } while(!oper.empty() \u0026amp;\u0026amp; priority(oper.top())\u0026gt;=priority(c)){ //如果是右结合运算符，则要改成大于，如果只有一部分是右结合运算符，分类讨论 ret.push_back(oper.top()); ret.push_back(\u0026#39; \u0026#39;); oper.pop(); } oper.push(c); } else if(c==\u0026#39;(\u0026#39;){ oper.push(c); } else if(c==\u0026#39;)\u0026#39;){ while(oper.top()!=\u0026#39;(\u0026#39;){ ret.push_back(oper.top()); ret.push_back(\u0026#39; \u0026#39;); oper.pop(); } oper.pop(); } else{ while(i\u0026lt;esize \u0026amp;\u0026amp; isDigit(expr[i])){ ret.push_back(expr[i++]); } ret.push_back(\u0026#39; \u0026#39;); i--; } } while(!oper.empty()){ ret.push_back(oper.top()); ret.push_back(\u0026#39; \u0026#39;); oper.pop(); } return ret; } void processOper(std::stack\u0026lt;int\u0026gt; \u0026amp; st, char oper){ int r = st.top(); st.pop(); int l = st.top(); st.pop(); switch(oper){ case \u0026#39;+\u0026#39;: st.push(l+r); break; case \u0026#39;-\u0026#39;: st.push(l-r); break; case \u0026#39;*\u0026#39;: st.push(l*r); break; case \u0026#39;/\u0026#39;: st.push(l/r); break; } } int RPNCalc(std::string expr){ int ret = 0; std::stack\u0026lt;int\u0026gt; number; int esize = expr.size(); for(int i=0;i\u0026lt;esize;i++){ char\u0026amp; c = expr[i]; if(c==\u0026#39; \u0026#39;) continue; else if(isOper(c)){ processOper(number, c); } else{ int res = 0; while(i\u0026lt;esize \u0026amp;\u0026amp; isDigit(expr[i])){ res = res*10 + expr[i++] - \u0026#39;0\u0026#39;; } i--; number.push(res); } } ret = number.top(); return ret; } int exprCalc(std::string expr){ int ret = RPNCalc(toRPN(expr)); return ret; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); std::string str; std::cin\u0026gt;\u0026gt;str; std::cout\u0026lt;\u0026lt;toRPN(str)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; std::cout\u0026lt;\u0026lt;exprCalc(str)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 艾弗森括号 艾弗森括号常表示为\\([A]\\)，其中\\(A\\)是一个二值表达式。用三元运算符可以等价为\\([A]\\leftrightarrow A?1:0\\)。\n例如\\([\\gcd(a,b)==1]\\)，就意味着，如果\\(a,b\\)互质，式子的值为\\(1\\)，否则为\\(0\\)。\n向上、向下取整 在C++中，如果我们对一个double或者float用强制类型转换\ndouble x = 1.1; std::cout\u0026lt;\u0026lt;(int)x\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; 这其实看起来像是向下取整，实际上却不是。它是省略小数部分，实为向\\(0\\)取整。C++的整数除法也是向零取整的，而Python则是向下取整。具体表现为C++中\\(-7/2\\)为\\(-3\\)，Python中\\(-7//2\\)为\\(-4\\)。\nC++本身也有std::floor()和std::ceil()，但是只能针对浮点数使用。\n我们一般会在结果非负的时候，用以下方式计算向上向下取整\nint x = a/b;//a/b向下取整 int y = (a+b-1)/b;//a/b向上取整 而对于负数结果，我们有一个性质\n\\[-\\lfloor x\\rfloor= \\lceil -x\\rceil \\]\n\\[-\\lceil x\\rceil= \\lfloor -x\\rfloor \\]\n转换即可。\n滚动哈希 （总觉得和之前的字符串哈希其实一模一样）\n滚动哈希用来以线性复杂度求一个序列的哈希，这个序列可以是一个字符串，可以是一个数组。或者也可以退化成单个元素。假设序列是\\(A=(A_1,A_2,\\cdots,A_N)\\)，定义滚动哈希函数为\\(R\\)，为\n\\[R(A) = \\bigg(\\sum^N_{i=1}A_ix^{N-i}\\bigg)\\mod{p} \\]\n其中，\\(P\\)是一个足够大的质数，而\\(x\\)是从\\([0,p)\\)中等可能选出的一个整数。假设\\(A(a,b)\\)为\\(A\\)的下标从\\(a\\)到\\(b\\)的子序列，我们可以立即得到它的递推式：\n\\[R(A(1,1)) = A_1, R(A(1,n))=R(A(1,n-1))\\times x+A_n(n\u003e1) \\]\n并且如果已经与处理过所有的\\(R(A(1, i))\\)，那么我们可以在\\(O(1)\\)内求出\\(R(A(a,b))\\)，即\n\\[R(A(a,b)) = R(A(1,b)) - R(A(1, a-1))\\times x^{b-(a-1)} \\]\n有一个有用的性质，如果记\\(A+B=(A_1+B_1, A_2+B_2, \\cdots, A_N+B_N)\\)，那么有\n\\[R(A+B) = R(A)+R(B) \\]\n对于字符串\\(S\\)和\\(T\\)，它们的拼接，即\\(S+T\\)，可以由之前的递推式得出哈希为\n\\[R(S+T) = R(S)\\times x^{|T|}+R(T) \\]\n这样的序列上的哈希可以方便我们判断任意两个区间的内容是否相等。另外，结合线段树，我们可以实现\\(O(logn)\\)的单点修改和\\(O(logn)\\)的区间哈希查询。只要每个节点存这段区间的哈希即可。两个区间合并的时候相当于拼接。支持区间修改可能有些麻烦，因为lazy tag有些难写。\n另外，对于字符串，滚动哈希还可以用来\\(O(1)\\)地判断一个区间是否是回文串。我们只需要正着求一遍哈希，再倒着求一遍哈希，响应的区间的哈希值相等，那么意味着是回文串。如果要避免下标的转换，则可以换一下哈希函数（注意与之前正着的哈希区分）：\n\\[R'(A) = \\bigg(\\sum^N_{i=1}A_ix^{i-1}\\bigg)\\mod{p} \\]\n此时，\\(R'(S+T)=R'(S)+R'(T)\\times x^{|S|}\\)。\n另外，单哈希可能不能使得碰撞的概率足够低，那么我们就重复使用多个\\(p\\)来算多个哈希即可。\n下面给出一个，支持单点修改，维护字符串子串哈希的线段树代码\n//atcoder abc331_f //滚动哈希+线段树 #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;random\u0026gt; #include \u0026lt;ctime\u0026gt; #include \u0026lt;array\u0026gt; using LL = long long; int const MAXN = 1000005; constexpr int B = 5; LL mod[B] = {998244353, 1000000007, 1000000009, 1000000021, 1000000033}; LL base[B]; struct Hash{ LL h1, h2, pw; Hash():h1(0),h2(0),pw(1){} // 字符串拼接哈希时，拼接操作的幺元 }; using T = std::array\u0026lt;Hash, B\u0026gt;; // 存多个哈希，以减小碰撞概率 T operator+(T lhs, T rhs){ // 区间拼接 T res; for(int i=0;i\u0026lt;B;i++){ res[i].h1 = (lhs[i].h1*rhs[i].pw + rhs[i].h1)%mod[i]; res[i].h2 = (lhs[i].h2 + lhs[i].pw*rhs[i].h2)%mod[i]; res[i].pw = (lhs[i].pw*rhs[i].pw)%mod[i]; // 见字符串拼接的哈希 } return res; } T gen(char c){ // 单个字符的哈希 T res; for(int i=0;i\u0026lt;B;i++){ res[i].h1 = c; res[i].h2 = c; res[i].pw = base[i]; } return res; } struct Node { int s,t;//该端点的起点和终点下标 T v; }; Node st[MAXN*4+2]; std::string arr; void build(int s, int t, int p=1){ st[p].s = s; st[p].t = t; if(s==t) { st[p].v = gen(arr[s]); return; } int m = s+((t-s)\u0026gt;\u0026gt;1); build(s,m,p*2); build(m+1,t,p*2+1); st[p].v = st[p*2].v + st[p*2+1].v; } void update(int i, char ch, int p=1){ int s = st[p].s, t = st[p].t; if(s==t){ st[p].v = gen(ch); return; } int m = s+((t-s)\u0026gt;\u0026gt;1); if(i\u0026lt;=m) update(i, ch, p*2); if(i\u0026gt;m) update(i, ch, p*2+1); st[p].v = st[p*2].v + st[p*2+1].v; } T query(int l, int r, int p=1){ int s = st[p].s, t = st[p].t; if(l\u0026lt;=s \u0026amp;\u0026amp; t\u0026lt;=r) return st[p].v; int m = s+((t-s)\u0026gt;\u0026gt;1); T ret; if(l\u0026lt;=m) ret = ret+query(l,r,p*2); if(r\u0026gt;m) ret = ret+query(l,r,p*2+1); return ret; } void solve(){ std::mt19937_64 rng(time(0)); for(int i=0;i\u0026lt;B;i++){ base[i] = rng() % mod[i]; // 即随机生成的x } int n,q; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;q; std::cin\u0026gt;\u0026gt;arr; arr = \u0026#39;#\u0026#39;+arr; build(1, n); while(q--){ int op; std::cin\u0026gt;\u0026gt;op; if(op==1){ int x; char c; std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;c; update(x,c); } else{ // 判断[l,r]是否为回文串 int l, r; std::cin\u0026gt;\u0026gt;l\u0026gt;\u0026gt;r; auto h = query(l, r); bool ans = 1; for(int i=0;i\u0026lt;B;i++){ ans \u0026amp;= (h[i].h1==h[i].h2); } std::cout\u0026lt;\u0026lt;(ans?\u0026#34;Yes\u0026#34;:\u0026#34;No\u0026#34;)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } } } 线性规划 有\\(n\\)个变量，\\(m\\)条约束，其中第\\(i\\)条约束为\\(\\sum^n_{j=1}a_{ij}x_j\\leq b_i\\)\n另外，所有变量都满足\\(x_j\\geq 0\\)。此时要求求出\\(\\sum^n_{j=1}c_jx_j\\)的最大值，以及对应的变量值。\n// UOJ179 线性规划 #include \u0026lt;cstring\u0026gt; #include \u0026lt;iostream\u0026gt; int const MAXN = 31; using DB = long double; #define double DB class LP { public: int n, m; // 变量个数，约束个数 double cons [MAXN] [MAXN]; // 0维为c_i, // 1~m维为约束条件，共m个，每个长度为n+1，第0维为b，1~n维为a_ij double const EPS = 1e-8; int idx[MAXN * 2]; bool solve() { std::memset(idx, 0, sizeof(idx)); for (int i = 1; i \u0026lt;= n; i++) idx[i] = i; for (;;) { int l = 0, e = 0; // 换入、换出变量 for (int i = 1; i \u0026lt;= m; i++) { if (cons[i][0] \u0026lt; -EPS \u0026amp;\u0026amp; (!l || (rand() \u0026amp; 1))) l = i; // rand可以提升运行效率，避免TLE } if (!l) return Simplex(); for (int j = 1; j \u0026lt;= n; j++) { if (cons[l][j] \u0026lt; -EPS \u0026amp;\u0026amp; (!e || (rand() \u0026amp; 1))) e = j; } if (!e) { std::cout \u0026lt;\u0026lt; \u0026#34;Infeasible\\n\u0026#34;; // 无解 return false; } Pivot(l, e); } } bool Simplex() { for (;;) { int l = 0, e = 0; for (int j = 1; j \u0026lt;= n; j++) { if (cons[0][j] \u0026gt; EPS) { e = j; break; } } if (!e) return true; double minv = 1e18; for (int i = 1; i \u0026lt;= m; i++) { if (cons[i][e] \u0026gt; EPS \u0026amp;\u0026amp; cons[i][0] / cons[i][e] \u0026lt; minv) { minv = cons[i][0] / cons[i][e]; l = i; } } if (!l) { std::cout \u0026lt;\u0026lt; \u0026#34;Unbounded\\n\u0026#34;; return false; } Pivot(l, e); } } void Pivot(int l, int e) { std::swap(idx[n + l], idx[e]); double t = cons[l][e]; cons[l][e] = 1.0; for (int j = 0; j \u0026lt;= n; j++) cons[l][j] /= t; for (int i = 0; i \u0026lt;= m; i++) { if (i != l \u0026amp;\u0026amp; std::abs(cons[i][e]) \u0026gt; EPS) { t = cons[i][e]; cons[i][e] = 0.0; for (int j = 0; j \u0026lt;= n; j++) { cons[i][j] -= t * cons[l][j]; } } } } }; double ans[31]; int main() { std::ios::sync_with_stdio(false); std::cin.tie(0); LP lp; std::cin \u0026gt;\u0026gt; lp.n \u0026gt;\u0026gt; lp.m; int type; std::cin \u0026gt;\u0026gt; type; for (int i = 1; i \u0026lt;= lp.n; i++) { std::cin \u0026gt;\u0026gt; lp.cons[0][i]; } for (int i = 1; i \u0026lt;= lp.m; i++) { for (int j = 1; j \u0026lt;= lp.n; j++) { std::cin \u0026gt;\u0026gt; lp.cons[i][j]; } std::cin \u0026gt;\u0026gt; lp.cons[i][0]; } std::cout \u0026lt;\u0026lt; std::fixed; std::cout.precision(10); if (lp.solve()) { std::cout \u0026lt;\u0026lt; -lp.cons[0][0] \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; if (type) { for (int i = 1; i \u0026lt;= lp.m; i++) ans[lp.idx[i + lp.n]] = lp.cons[i][0]; for (int i = 1; i \u0026lt;= lp.n; i++) std::cout \u0026lt;\u0026lt; ans[i] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } } return 0; } C++ STL用法 std::swap 交换两个元素的内容（也可以交换数组，不重要不介绍）。复杂度：常数。\nint a,b; std::swap(a,b); 注意其中的两个参数，类型要相同。不能一个是LL一个是int。\nstd::sort 对数组、vector等进行排序。复杂度nlogn。\nint a[5]; std::vector\u0026lt;int\u0026gt; vec(5); std::sort(a,a+5); std::sort(vec.begin(),vec.end()); 注意排序范围是左闭右开区间。\n通常会按照类型的\u0026lt;操作符来进行比较。如果对结构体进行排序，可以重载运算符或者设定cmp函数。注意这两种方法一定不能是小于等于或者大于等于的运算，必须只使用小于号或者大于号（严格弱序）。\nbool cmp(const Type1\u0026amp; a, const Type2\u0026amp; b); //然后在sort中加入第三个参数 std::sort(a,a+5,cmp); struct node{ bool operator\u0026lt;(const node\u0026amp; a); }; //不用添加cmp参数 std::merge 对两个有序数组进行合并。\nstd::vector\u0026lt;int\u0026gt; a(5), b(6); std::vector\u0026lt;int\u0026gt; c(5+6); std::merge(a.begin(), a.end(), b.begin(), b.end(), c.begin(), std::less\u0026lt;int\u0026gt;()); 如上，假设a和b都是从小到大排好序的数组，把它们合并成同样从小到大排序的c数组。如果是从大到小合并成从大到小，则改成std::greater\n另外，它的操作逻辑是双指针。比如less情况下，指向a数组元素的指针为p1，指向b数组元素的指针为p2。他会判断p1大还是p2大，如果p1大，则把p1指向的数字放进c，然后p1自增。否则p2放进去后自增。他其实不会管你原来的数组是否真的排好序，有时候这可以用在一些数组的合并上。\nstd::greater, std::less 很简单，greater是大于号\u0026gt;，而less是小于号\u0026lt;。在sort函数里的第三个参数可以用这个，例如std::greater\u0026lt;int\u0026gt;()代表从大到小排序，std::less\u0026lt;int\u0026gt;()则是从小到大排序。\n但是在优先队列里不一样，greater是小根堆，而less才是大根堆。\nstd::lower_bound,std::upper_bound 对某个已经排序好的数组，查找第一个大于等于（lower_bound）或者大于(upper_bound)某个给定值的元素。复杂度：logn（对于随机访问的迭代器），n（对于其他迭代器）。\nint a[5]={0,1,3,4,6}; int first = std::lower_bound(a,a+5,3); 同样是左闭右开区间，第三个参数是指定的值。如果找到就会返回所查找元素的迭代器（或者指针）。找不到就会返回末尾元素的后一个指针（或者end迭代器）。\n如果需要自定义比较方法，同sort函数。\nstd::max,std::min 对于两个元素返回最大值和最小值。复杂度：准确一次比较。\nint a=1,b=2; int maxv = std::max(a,b); int minv = std::min(a,b); 同样，两个参数类型相同。自定义比较方法同sort。如果要比较三四个元素，可以使用initializer_list，例如std::max({1,2,3,4,5});\nstd::max_element,std::min_element 返回一个范围内的最大（最小元素）的迭代器（指针）。复杂度，准确比较max(N-1,0)次\nstd::vector\u0026lt;int\u0026gt; v{3,1,-14,9}; std::cout\u0026lt;\u0026lt;*std::max_element(v.begin(),v.end())\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; std::abs 计算绝对值。复杂度：文档没写但应该是常数。\nint a = -1; int b = std::abs(a); 注意，函数只有float,double,long double的返回值类型。使用时如果给予整数参数会自动转换，这是否会导致精度问题有待观察。\nstd::string ::swap 将两个字符串互换。复杂度：常数。\nstd::string str = \u0026#34;123456\u0026#34;; std::string str2 = \u0026#34;456789\u0026#34;; str.swap(str2); ::begin,std::end 返回字符串的起始得带器和结尾迭代器。\nstr.begin();str.end(); ::size 返回字符串的大小。\nstr.size(); ::push_back 向字符串末尾添加一个字符，同时大小加一。复杂度：常数。\nstr.push_back(\u0026#39;a\u0026#39;); ::pop_back 将字符串末尾的字符弹出，同时大小减一。如果字符串为空则未定义。复杂度：常数。\nstr.pop_back(); ::find 在字符串中寻找某个子串是否存在。复杂度：没有规定，编译器不一定都是使用的kmp算法。\nstd::string::size_type n; std::string s = \u0026#34;this is a string\u0026#34;; n = s.find(\u0026#34;is\u0026#34;); 如果找到则返回首个匹配的首字母位置。否则返回std::string::npos。如果是int n作为s.find的接收端，则会在找不到时接收到-1。\n::replace 将字符串的某个片段替换为另一个字符串\nstd::string s = \u0026#34;abcd efgh\u0026#34;; s.replace(1,3,\u0026#34;aaaa\u0026#34;); 第一个参数是开始位置的下标，第二个参数是指从开始位置有几个字符，第三个参数是将要替换进去的字符串，上式结果是\u0026quot;aaaaa efgh\u0026quot;。\n::substr 获取自字符串\nstd::string s = \u0026#34;abcd efgh\u0026#34;; std::string b = s.substr(1,3); 从下标1开始的3个字符，即b=\u0026ldquo;bcd\u0026rdquo;。\nstd::memset 将值复制到dest所指对象的前count个字节中。复杂度：没有规定。\nint a[20]; std::memset(a,0,sizeof(a)); 注意，赋的值不能随便取，这个函数是一个字节一个字节地去赋值的。如果取1并不会得到全部赋值为1的效果，通常只会取0和-1。\nstd::copy 将一个范围的值复制给另一个范围，复杂度：准确赋值 (last - first) 次\nint a[10],b[10]; std::copy(a,a+10,b);//源起点，源终点，目的地起点 需要注意的点是，不要数组越界，包括源不要越界，目标的大小也要足够复制。类型要一致。以及，目标起点的地址不能在源之内，否则行为是未定义的。\nstd::fill 将给定值填写到整个范围中，复杂度：准确赋值 std::distance(first, last) 次。\nstd::vector\u0026lt;int\u0026gt; v{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}; std::fill(v.begin(), v.end(), -1); 之后v变成全-1的vector。\n可以对C数组使用指针，和memset不一样的是，memset是字节赋值，fill并不会把4字节的int每一个字节都赋值一次。\n注意，如果你对结构体数组使用，你不能直接像memset一样全部memset为0。你要创建一个你认为的初始化应该有的值，再fill进去。\nstruct A{ int a,b; }a[100]; std::memset(a,0,sizeof(a)); //std::fill(a,a+100,0);//出错 A tmp = {0,0}; std::fill(a,a+100,tmp); std::map map是有序键值对容器，通常用红黑树实现。元素的键是唯一的。\ntemplate\u0026lt; class Key, class T, class Compare = std::less\u0026lt;Key\u0026gt;, class Allocator = std::allocator\u0026lt;std::pair\u0026lt;const Key, T\u0026gt; \u0026gt; \u0026gt; class map; 可以通过迭代器来遍历\nfor(std::map\u0026lt;int,int\u0026gt;::iterator it = mp.begin();it!=mp.end();it++); //访问元素用it-\u0026gt;first和it-\u0026gt;second //或者 for(auto it:mp); //访问元素用it.first和it.second 自定义比较函数 map通常会按照key的大小关系进行升序排列。如果要自定义比较函数，则\nstruct cmp{ bool operator()(const int\u0026amp; a, const int\u0026amp; b) const{ return a\u0026gt;b; } }; std::map\u0026lt;int,std::string,cmp\u0026gt; mp; ::empty 检测是否为空。\n::size 返回大小。\n::clear 清除所有内容。复杂度：线性。\n::erase 提供迭代器，删除迭代器所指的键值对。复杂度：常数。\nauto it = mp.begin(); mp.erase(it); 当然也可以提供两个迭代器，删除这之间的所有元素（左闭右开区间）\n::find 寻找key等于给定值的元素，返回迭代器。如果没有找到则返回end迭代器。复杂度：对数。\nauto it = mp.find(1); ::lower_bound,::upper_bound 寻找首个大于等于(或大于，对upper_bound)给定值的key。复杂度：对数。\nauto it = mp.lower_bound(1); std::unordered_map 可以看作是无序的map，通常由哈希表实现。这意味着map中和排序有关的函数都不能使用。\n警告\nunordered_map可能不能用auto x:mp或者迭代器遍历。它的遍历可能是遍历bucket，而不是遍历元素。但是只是查找是可以的。\n这里的bucket是指哈希桶，也就是用拉链法实现的hash表。\nstd::set set是关联容器，含有Key类型对象的已排序集，通常用红黑树实现。\ntemplate\u0026lt; class Key, class Compare = std::less\u0026lt;Key\u0026gt;, class Allocator = std::allocator\u0026lt;Key\u0026gt; \u0026gt; class set; 遍历的方式与map相同。\n使用方法 自定义比较函数,empty,size,clear,erase,find,lower_bound,upper_bound都与map相同。\n::insert map可以用[]进行插入，但是set只能用insert函数。\nstd::set\u0026lt;int\u0026gt; st; st.insert(1); 返回值是一个pair，first是迭代器，指向被插入进去的元素（如果插入不成功则指向没插进去的元素），second是bool，插入成功时为true，否则为false。\n修改内部元素 有时候，我们需要修改内部元素。由于例如begin函数返回的迭代器是const的，我们无法直接修改数据。但我们可以给变量添加mutable修饰。这样我们就可以不用拿出来一个元素再插回去。例子可见珂朵莉树。\n注意，如果你修改的数据和排序依据有关，set不会维护内部有序。要维护还得是拿出来再插入进去。\nstd::unordered_set 用哈希实现，没有内部排序。\n警告\n可能跟unordered_map一样不能遍历。\nstd::multiset 与普通的set不同的是，可以插入多个相同的元素。这在一些情况下是有用的，而且它还是满足内部有序。\n可以用::count(x)来统计Key为x的元素的数量，普通的set也有这个方法，但是要么是0要么是1，与find功能可以说是重复。但是multiset可以统计数量。\n注意，用erase方法时，如果给出的是一个值，那么会把等于这个值的元素都删掉，如果给出迭代器，那么之后删一个。所以，只想删一个等于这个值的元素时，用erase(find(\u0026hellip;))\nstd::stack 栈，有先入后出特性。\n::top 访问栈顶元素，复杂度：常数。\n::empty 检查是否为空，复杂度：常数\n::size 返回元素个数，复杂度：常数\n::push 将元素推入栈，复杂度：通常和deque的push_back相同，即常数\n::pop 将栈顶弹出，复杂度：通常和deque的pop_back相同，即常数\n::emplace 在顶部原位构造元素，通常会用在栈的元素是结构体的时候，复杂度：通常和deque的emplace_back相同，即常数\nstd::queue 队列，拥有先入先出特性。\n::front 访问队首元素，复杂度：常数\n::back 访问队尾元素，复杂度：常数\n其他方法 同stack，不过push是推入队尾，pop是弹出队首。\nstd::priority_queue 优先队列，提供常数时间的最大（或最小）元素查找，以及对数时间的插入与删除。\n自定义比较方法 通常我们会重载元素的运算符来自定义\nstruct node { int dis, u; bool operator\u0026gt;(const node\u0026amp; a) const { return dis \u0026gt; a.dis; } }; priority_queue\u0026lt;node, vector\u0026lt;node\u0026gt;, greater\u0026lt;node\u0026gt; \u0026gt; pq; 方法 其方法与stack相同，只不过没有先入后出特性，插入元素或弹出元素后会根据大小关系进行排序，保证栈顶是最大的（或最小的）元素。\nstd::deque 双端队列，允许在队首和队尾进行插入和删除。另外，在 deque 任一端插入或删除不会非法化指向其余元素的指针或引用。通常也会用来实现单调队列。\n方法 size、empty与stack、queue相同。其pop_back、push_back、pop_front、push_front、emplace_front、emplace_back用法也类似。\nstd::vector 通常可以理解为一个可以变化长度的数组。\n声明方法 std::vector\u0026lt;int\u0026gt; vec;//声明一个初始大小为0的vector std::vector\u0026lt;int\u0026gt; vec2(n);//声明一个初始大小为n的vector，每个元素都会初始化为0 std::vector\u0026lt;int\u0026gt; vec3(n,1);//与上一个不同的是，每一个元素都会初始化为1 元素访问 vec[5];//像数组一样访问 vec.at(5);//与上一个方法的差别在会进行越界检查 vec.front();//访问第一个元素 vec.back();//访问最后一个元素 ::size 获取大小，复杂度：常数\n::empty 查看是否为空，复杂度：常数\n::push_back 向末尾添加元素，复杂度：常数\n::pop_back 把末尾元素弹出，复杂度：常数\n::emplace_back 在末尾原位构造元素，复杂度：常数\n::resize 重新指定vector的大小，会改变size()，resize有两个参数(new_size, value)，第一个为要分配的大小，第二个为指定的初始值（可以忽略，此时调用默认构造函数）。注意只有加大size时，新增的元素会被赋值。\n::reserve 给vector预留空间，但不会改变size()的大小。参数只有一个，为预留的元素个数。\n如果dfs中参数引用的vector会导致RE，可以试试预留足够的大小。\nstd::vector\u0026lt;bool\u0026gt; 这是一个特化的vector，它每一个元素所占的空间是一位，而不是sizeof(bool)（通常是一字节）。\n不建议使用，除非非常了解会发生什么。\noperator[]返回的不是bool类型，返回的是一个proxy reference。\nstd::vector\u0026lt;bool\u0026gt; c{false,true,true}; bool a = c[0];//经过了强制类型转换 auto b = c[0];//没有转换，本身b就是引用了 a = true;//c是0 1 1 b = true;//c是1 1 1 std::bitset 表示一串二进制位。\n声明方法 std::bitset\u0026lt;100\u0026gt; bs;//声明一个位数为100位的bitset std::bitset\u0026lt;4\u0026gt; bs2{0xA};//声明一个四位的bitset，其值等于0xA 元素访问 同数组的访问方式。同样也可以用数组的方式进行修改。\n::all,::any,::none 检查是否全部，存在、没有元素被设置为true。\n::count 返回设置为true的数量。\n运算 bitset和bitset之间能用所有的位运算符。也可以用等号和不等号比较。\n::flip 翻转某一位的值。\n如果没有提供位置，就翻转所有。\n::to_string 转化为二进制数的字符串。\n::to_ulong,::to_ullong 转化为unsigned long和unsigned long long。\n::set 设置某一位为1，如果没有提供位置，则将所有位设为1\n::reset 设置某一位为0，如果没有提供位置，则将所有位设置为0\nstd::pair 定义一个二元组，例如std::pair\u0026lt;int,int\u0026gt;, std::pair\u0026lt;int,std::string\u0026gt;等。其定义是在\u0026lt;utility\u0026gt;中，但是也可以#include \u0026lt;algorithm\u0026gt;来使用\n元素访问 std::pair\u0026lt;int,int\u0026gt; p; p-\u0026gt;first;//访问第一个元素 p-\u0026gt;second;//访问第二个元素 ::swap 交换两个元素的内容。复杂度：没有定义。\nstd::make_pair auto p = std::make_pair(1,1);//自动推断类型为std::pair\u0026lt;int,int\u0026gt; std::tuple 定义一个多元组，可以说pair是tuple的特例。其定义是在\u0026lt;utility\u0026gt;中，但是也可以#include \u0026lt;algorithm\u0026gt;来使用\n元素访问 根据下标可以如下访问\nauto t = std::make_tuple(1, \u0026#34;Foo\u0026#34;, 3.14); std::get\u0026lt;0\u0026gt;(t);//1 std::get\u0026lt;1\u0026gt;(t);//Foo std::get\u0026lt;2\u0026gt;(t);//3.14 std::make_tuple 同pair。\n如果一个函数要返回tuple\nstd::tuple\u0026lt;int, int\u0026gt; foo_tuple() { return {1, -1}; // N4387 前错误 return std::tuple\u0026lt;int, int\u0026gt;{1, -1}; // 始终有效 return std::make_tuple(1, -1); // 始终有效 } 需要注意兼容性，有些编译器不支持第一种返回方式。\nstd::tie 将tuple解包。\nauto t = std::make_tuple(1,2,\u0026#34;Foo\u0026#34;); int a,b; std::string str; std::tie(a,b,str) = t; 当然也可以用auto，都不需要指定变量类型。\nauto[c,d,str2] = t; std::list 声明方法 std::list\u0026lt;int\u0026gt; l;//如果有初值可以l = {1,2,3}; 元素访问 链表的特性让我们无法随机访问，只能用front()和end()访问开始和结束元素。\n::empty() 返回是否为空\n::size() 返回元素个数\n::clear() 清空\n::begin(), ::end(), ::rbegin(), ::rend() 返回开始、结束迭代器。返回反向开始、结束迭代器。所以list是双向链表。\n::insert(pos, value) pos是一个迭代器，会在pos前面插入值为value的元素，不会使任何迭代器失效。\n::erase(pos) pos是一个迭代器，移除pos所指的元素。只有指向该元素的迭代器会失效，其他的不会。\n::push_back(v), ::pop_back(), ::push_front(v), ::pop_front() 和双向队列一样，不再介绍\n::merge(list\u0026amp; other) 将两个有序的链表合并，得到的新链表保持有序。另外新列表是调用这个方法的链表，other则会清空（如果两个链表相等则不会做任何事）。\n迭代器和引用不会失效。指向other元素的迭代器之后会指向新链表里的对应元素。\n::reverse() 翻转链表，迭代器不会失效。\n::sort() 排序，复杂度为nlogn\n::unique() 删除连续的重复的元素，只保留第一个，被删除元素的迭代器失效。\nstd::next_permutation, std::prev_permutation bool next_permutation (Iterator first, Iterator last); bool prev_permutation(Iterator first, Iterator last); 这两个算法都是“原地”算法，也就是说会直接更改原数组，而不会返回一个新数组。这两个函数的作用是，获取按字典序比当前排列小1号的排列，以及大1号的排列。\n例如123是一个排列，比它正好大1号的排列是132，再大1号的是213。比321小1号的是312。\n用法如下\nstring number = \u0026#34;213\u0026#34;; next_permutation(number.begin(), number.end()); cout \u0026lt;\u0026lt; number; 输出231。\n如果当前已经是最小的还要得到更小的，则返回false。已经是最大的还要得到更大的，则返回false。其他情况返回true。\n复杂度：线性。\nstd::unique 对一个已经排好序的数组去除重复元素。或者说是，移除一个一般数组中相邻的、相同的元素。复杂度：线性。\nIterator unique(Iterator first, Iterator last); 给出一个范围来进行这个操作。具体用例可以见离散化一节。\n返回值是新数组的末尾的迭代器。\nstd::mt19937_64 本功能在C++11后可以使用。\n#include\u0026lt;random\u0026gt; #include\u0026lt;ctime\u0026gt; std::mt19937_64 rng(time(0)); for(int i=0;i\u0026lt;B;i++){ base[i] = rng() % mod[i]; // 即随机生成[0,mod[i])之间的整数 } 使用梅森缠绕算法，给出\\([0,2^{64})\\)之间的随机数，如果想要32位的，用mt19937即可。其比cstdlib中的srand和rand生成的随机数性质要好得多，并且rand()的范围不那么好设置。推荐在涉及随机的算法中优先使用这个生成器。\nstd::cin 输入十六进制、八进制、二进制 int a; std::cin\u0026gt;\u0026gt;std::hex\u0026gt;\u0026gt;a;//16进制 std::cin\u0026gt;\u0026gt;std::dec\u0026gt;\u0026gt;a;//10进制 std::cin\u0026gt;\u0026gt;std::oct\u0026gt;\u0026gt;a;//8进制 注意，使用一次std::hex之后所有的输入都会是十六进制，需要用std::dec输入一次十进制才会转换回来。\n输入二进制可以考虑用bitset\nstd::bitset\u0026lt;32\u0026gt; bs; std::cin\u0026gt;\u0026gt;bs; std::cout\u0026lt;\u0026lt;bs.to_ulong(); 输入不忽略空格、回车 虽然可以用cin.get()和cin.getline()来实现，但是我们还是考虑用getchar比较好，当getchar返回EOF时代表输入结束。类似于逗号表达式返回最后一个的值，等号表达式返回等号左边的值，所以我们可以写(c=getchar())!=EOF。\nstd::cout 输出十六进制、八进制、二进制 int a = 16; std::cout\u0026lt;\u0026lt;std::hex\u0026lt;\u0026lt;a;//16进制 std::cout\u0026lt;\u0026lt;std::oct\u0026lt;\u0026lt;a;//8进制 std::cout\u0026lt;\u0026lt;std::dec\u0026lt;\u0026lt;a;//10进制 使用注意事项同前。\n输出二进制也是考虑用bitset\nstd::bitset\u0026lt;32\u0026gt; bs{64}; std::string ans = bs.to_string(); std::cout\u0026lt;\u0026lt;ans.substr(ans.find(\u0026#39;1\u0026#39;),int(ans.end()-ans.begin()))\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; 需要去除前导0，如果直接输出bs或者其to_string的话会带有前导0\n浮点数精度 std::cout\u0026lt;\u0026lt;std::fixed;//如果不用这个，则为有效数字四位。 std::cout.precision(4); std::cout\u0026lt;\u0026lt;a;//这里输出小数点后4位。 scanf TODO 输入十六进制、八进制、二进制 printf TODO 输出十六进制、八进制、二进制 atoi TODO 正则表达式 正则表达式语法 符号 功能 例子 literal 匹配字符串的值 foo \\|转义符，将一些正则表达式需要的符号进行转义 \\. () 括选一些字符，方便星号、加号等当作一个整体处理 a(abc)* re1|re2 匹配re1或匹配re2的值 foo|bar . 匹配换行符以外的单字符 a.b ^ 在字符串开头匹配（在方括号里除外） ^Dear $ 在字符串的结尾匹配 \\.sh$ * 匹配星号前面的零次、一次或多次 a(abc)* + 匹配加号前面的一次或多次 a(abc)+ ? 匹配问号前面的零次或一次 a(abc)? {N} 指定匹配次数 a(abc){5} {M,N} 匹配出现次数在M,N之间的，如果左边留空代表0次，右边留空代表任意次 a(abc){2,8} [\u0026hellip;] 匹配其中的任意字符 [aeiou],[0-9A-Za-z] [^\u0026hellip;] 匹配除了其中字符的任意字符 [^aeiou] \\n 匹配回车符 \\s 匹配任何空白字符 \\S 匹配任何非空字符 贪婪匹配\n*，+都是贪婪匹配的，也就是说，如果用\u0026quot;\u0026lt;.*\u0026gt;\u0026ldquo;匹配\u0026rdquo;\u0026lt;h1\u0026gt;测试\u0026lt;/h1\u0026gt;\u0026ldquo;会匹配到全文，而不是只匹配到\u0026rdquo;\u0026lt;h1\u0026gt;\u0026ldquo;这叫做贪婪匹配。如果遇到第一个满足的就停下，要用\u0026rdquo;\u0026lt;.*?\u0026gt;\u0026quot;\u0026quot;\nC++正则表达式库 std::regex 一个类型，可以设定匹配的模式串。\nstd::regex pattern(\u0026#34;.*\u0026lt;.*?\u0026gt;.*\u0026#34;); 后续如果要更换pattern的内容，可以使用pattern.assign(\u0026ldquo;sth.\u0026quot;)或者直接pattern = \u0026ldquo;sth.\u0026rdquo;\nstd::smatch 一个类型，可以用于接收匹配的结果。\nstd::regex_match 用于测试字符串是否匹配模式串\nbool regex_match(string s,regex pattern); bool regex_match(string s,smatch res,regex pattern); bool regex_match(s.cbegin(),s.cend(),smatch res,regex pattern); 如果匹配到，就会返回1，否则返回0。\ns代表被匹配的字符串，pattern代表模式串。res代表，如果这个字符串被匹配了，就会返回这个字符串。注意这里是完全匹配，后面介绍的search函数是子串匹配。\nres是smatch类型，不能直接cout，要输出res[0]。\n如果要传入一个字符串的范围，需要传入const_iterator，也就是s.cbegin()和s.cend()返回的版本（这其实是因为smatch的模板是const_iterator，如果是c风格字符数组，传入的是头尾指针，则要用cmatch）。此时如果匹配上，返回res是这个范围的字符串，而不是整个。\nconst_iterator不是指迭代器指的位置不能变，而是指你不能通过这个迭代器去修改元素。\nstd::regex_search bool regex_search(string s,regex pattern); bool regex_search(string s,smatch res,regex pattern); bool regex_search(s.cbegin(),s.cend(),smatch res,regex pattern); 参数、返回值同前。\n只不过，这个东西不是完全匹配，只要有任意子串匹配，就会返回1。而且只要匹配到一个就会返回（当然这里要注意贪婪和非贪婪），不会再往后搜索，所以如果你使用res[1]是不会输出第二个结果的。res[0]返回的是匹配到的子串的结果，res[1]以后的东西也有含义，但是我暂时觉得没什么用。\nres[0]的类型是sub_match，可以使用.second方法得到res[0]在s中的匹配结果位置的末尾的迭代器，所以要遍历所有匹配的子序列，可以这么写：\nwhile(std::regex_search(it_begin,it_end,res,pattern)){ std::cout\u0026lt;\u0026lt;res[0]\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;res.position()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; it_begin = res[0].second; } 其中你还可以用.position返回子串开头的位置（相对于it_begin而言）。\nstd::regex_replace string regex_replace(string s,regex p,string rs) s为源字符串，p为模式串，rs为匹配到的子串将会被替换成的字符串。\n返回替换后的字符串。\n这里会替换一切匹配到的子串，不像search一样麻烦。\n如果我们只替换被匹配的子串的一部分，我们可以用如下方法\nstring s = \u0026#34;abcd123abcd\u0026#34;; regex p(\u0026#34;(abcd)([0-9]+)\u0026#34;); string ss = regex_replace(s,p,\u0026#34;a$2\u0026#34;); 则我们的ss会变成a123abcd。$2代表的是第二个捕捉组的意思（这里下标又是从1开始的，而不是0）。捕捉组是括号括起来的算一组。\n转义符 含义 $n 表示第n个捕捉组捕捉到的字符串 $\u0026amp; 表示匹配到的整个子串，相当于$0 $` 在源字符串中，在匹配到的子串左边的部分 $' 在源字符串中，在匹配到的子串右边的部分 $$ 美元符号 ","date":"2021-12-18T15:57:37+08:00","permalink":"https://kegalas.top/p/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%A8%A1%E6%9D%BF%E6%95%B4%E7%90%86/","title":"算法竞赛常用模板整理"},{"content":"网络设备管理 题目描述 ​\t叮叮叮！网络设备管理员欢欢在行动\n​\t欢欢就职于一家庞大的数据管理分析公司\n​\t公司有一个存储数据的庞大网络，把每个数据存储器看做一个节点，这个存储网络可以看做是一个树型结构，每天有庞大的数据流在节点之间穿梭\n​\t随着公司的发展，这个网络越来越庞大，数据的传输速度也越来越慢，通过研究，欢欢发现，每个节点的传输速度，只与与这个节点连接的节点数量有关，比如仅和一个节点连接的节点传输数据会很快，而和 100 个节点连接的节点传输数据会很慢\n​\t欢欢准备提交一份研究报告，报告将会指出，若对于网络中的所有节点，与该节点相连的节点数量不超过 d，那么网络的整体传输速度将会大幅提高。\n​\t欢欢准备通过添加新的网络设备来降低与某节点相连的节点的数量\n​\t简而言之，对于网络设备a，我们可以添加新的设备b，使得原来与a相连的若干节点断开与a的连接并与b连接，并且使a,b连接，显然，添加新的网络设备后，这个网络仍旧是一个树形结构这样通过添加若干新的网络设备，我们可以把所有网络设备的相连网络设备数量降低到不超过d台 (包括与新添加的网络设备相接的网络设备数量不超过 d)\n​\t欢欢发现，有很多种解决方案\n​\t聪明的你知道欢欢最少添加多少台网络设备吗？\n​\t注意: 欢欢添加新的设备后，网络的结构仍保持为树形结构\n输入 ​\t单组输入 ​\t第一行两个正整数 \\(n\\), \\(d$ \\)(1\\le n\\le 10^5,3\\le d\\le n)\\(​\t接下来\\)n-1\\(行，每行两个正整数$a\\)，\\(b$ \\)(1\\le a, b\\le n)\\(，说明设备$a\\)与设备\\(b\\)相连接，数据保证设备网络为树形结构。\n输出 ​\t一个正整数，最小添加的网络设备数量，注意欢欢可以添加0台设备。\n样例 样例输入 样例输出 10 32 13 14 15 26 17 68 59 710 6 1 AC代码 #include \u0026lt;iostream\u0026gt; #define MAXN 100005 using namespace std; int arr[MAXN]; int main(){ int n,d; cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;d; for(int i=1;i\u0026lt;n;i++){ int a,b; scanf(\u0026#34;%d%d\u0026#34;,\u0026amp;a,\u0026amp;b); arr[a]+=1; arr[b]+=1; } int ans=0; for(int i=1;i\u0026lt;=n;i++){ if(arr[i]\u0026gt;d){ int tmp = (d-1)*2; if(arr[i]-tmp\u0026lt;=0){ ans+=1; } else if((arr[i]-tmp)%(d-2)==0) ans += 1 + (arr[i]-tmp)/(d-2); else ans += 1 + (arr[i]-tmp)/(d-2)+1; } } cout\u0026lt;\u0026lt;ans; return 0; } 正确性证明 先给出样例的示意图\n样例图\r其中红色数字表示与这个节点直接相连的节点的个数。显然只有1号节点连了大于3个节点，我们可以新增一个节点A，将2、3号与A相连，4、6号不变，然后将1与A相连，现在1与A连了三个节点，符合要求。不过这不是唯一的连法。\n这种有最大连接节点的结构，很容易让人回想起烷烃。显然的，饱和烷烃的碳链无论怎么排布，所连的氢原子的数目不会改变。每个碳原子也都会连四个原子。\n类比到这道题，我们要做的，就是将形如下图的点（假设上限为连3个）\n2\r变为如下的一些点，当然这里的点怎么排布都不影响，只要他最大的利用了链接上限，就是答案。\n3\r解释一下核心代码\nfor(int i=1;i\u0026lt;=n;i++){ if(arr[i]\u0026gt;d){//枚举超过链接上限的节点 int tmp = (d-1)*2; //点链两端，能“向外”链接d-1个点，必须要向“内部”链接一个点，才能构成点链，这个arr[i]-tmp得到的是还需要“向外”链接的数量。 if(arr[i]-tmp\u0026lt;=0){//特判一下，如果只用新增一个节点，并且有一个节点没有占满上限 ans+=1; } else if((arr[i]-tmp)%(d-2)==0)//内部每个节点都只能“向外”链接d-2个节点，如果能全部占满每个内部节点的上限，ans如下 ans += 1 + (arr[i]-tmp)/(d-2); else//不能占满则ans如下 ans += 1 + (arr[i]-tmp)/(d-2)+1; } ","date":"2021-11-21T14:53:54+08:00","image":"https://kegalas.top/p/%E7%AE%97%E6%B3%95%E9%A2%98-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E7%AE%A1%E7%90%86/1_hue13a31d22502e6414becf06d466eec8f_119570_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E7%AE%97%E6%B3%95%E9%A2%98-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E7%AE%A1%E7%90%86/","title":"算法题-网络设备管理"},{"content":"向量 题目描述 ​ 给你n个向量，请问是否可以通过旋转异或伸缩任意一个向量，使得这n个向量相加等于0向量。 ​\n​ 注意，在本题中，我们认为0向量只能伸缩为0向量，非0向量可以伸缩为0向量、方向相同长度任意的向量、方向相反长度任意的向量。\n输入 ​ 单组输入\n​ 第一行一个正整数 \\(n(1\\le n\\le 10^5)\\)，即向量的个数。\n​ 接下来\\(n\\)行，每行两个整数\\(x_i\\), \\(y_i$ \\)(0\\le |x_i|,|y_i|\\le 10^9)\\(，分别代表第$i\\)个向量\\(x\\)轴与\\(y\\)轴的大小方向。\n数据保证\n\\[\\sum_{i=1}^{n}(|x_i|+|y_i|)\\le 10^9 \\]\n输出 ​ 若存在满足要求的操作输出 “yes”，反之输出 “no”。\n样例 样例输入 样例输出 3\n0 0\n1 2\n4 2 no AC代码 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstdio\u0026gt; typedef long long ll; #define MAXN 100005 using namespace std; struct Vec { ll x; ll y; }; Vec vec[MAXN]; int main(){ int n; cin\u0026gt;\u0026gt;n; Vec allSum; allSum.x=0;allSum.y=0; for(int i=1;i\u0026lt;=n;i++){ cin\u0026gt;\u0026gt;vec[i].x\u0026gt;\u0026gt;vec[i].y; allSum.x+=vec[i].x; allSum.y+=vec[i].y; } ll ans = 0; for(int i=1;i\u0026lt;=n;i++){ if(vec[i].x==0\u0026amp;\u0026amp;vec[i].y==0) continue; Vec tmpSum = allSum; tmpSum.x-=vec[i].x; tmpSum.y-=vec[i].y; ll dis1 = tmpSum.x*tmpSum.x+tmpSum.y*tmpSum.y; ll dis2 = vec[i].x*vec[i].x+vec[i].y*vec[i].y; if(dis1==dis2) { ans=1; break; } if(vec[i].y*tmpSum.x-tmpSum.y*vec[i].x==0) { ans=1; break; } } if(ans) cout\u0026lt;\u0026lt;\u0026#34;yes\u0026#34;; else cout\u0026lt;\u0026lt;\u0026#34;no\u0026#34;; return 0; } 正确性证明 首先分析题目，出题人的表达和数据结果并不一致。“是否可以通过旋转异或伸缩任意一个向量”实际上应该是“是否可以通过旋转异或伸缩某一个向量”，从而“使得这n个向量相加等于0向量”。\n数据也就\\(10^5\\)，直接枚举就行。先将所有向量加到一起记为allSum，然后建立一个tmpSum = allSum-我们当前枚举的向量，记为v。\n然后判断这个tmpSum向量是否和v长度平方相等，是则可以通过旋转v，再相加得到0向量。判断tmpSum向量终点是否和\\((0,0)\\)和v的终点在同一直线上,是则可以通过伸缩v来达到目的。这里判断三点共线的方法是求外积。若都为否，则不可以只对v伸缩或者旋转达到目的，枚举下一个。这里注意，我上述写的代码要将0向量略过，否则0向量总是可以通过三点共线的判断，达不到目的。\n如果枚举出一个向量可以达到目的，就输出yes。如果所有向量都达不到目的，就输出no。\n","date":"2021-11-15T22:30:41+08:00","permalink":"https://kegalas.top/p/%E7%AE%97%E6%B3%95%E9%A2%98-%E5%90%91%E9%87%8F/","title":"算法题-向量"},{"content":"有限小数 题目描述 ​\t现在有一个正整数n,可以证明存在若干个正整数d使得1/n在d进制下为有限小数，输出最小的d。\n输入 ​\t单组输入 ​\t第一行一个正整数\\(n(2\\le n\\le 10^{12})\\)\n输出 ​\t一个正整数d\n样例 输入 输出 9 3 999 111 AC代码 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;cmath\u0026gt; using namespace std; int main(){ long long n; cin\u0026gt;\u0026gt;n; long long ans=1; long long tmp=n; //求n的质因数的乘积 for(long long i=2;i*i\u0026lt;=tmp;i++){ if(tmp%i==0){ ans*=i; while(tmp%i==0){ tmp/=i; } } } if(tmp\u0026gt;1) ans*=tmp; cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;endl; return 0; } 正确性证明 ​若\\(1/n\\)可以在d进制表达为有限小数，那么一定有：\n\\[\\frac{1}{n}=\\frac{a_1}{d}+\\frac{a_2}{d^2}+\\dots+\\frac{a_m}{d^m} \\]\n其中\\(a_i\u003c d(1\\le i\\le m)\\)，且\\(a\\)为正整数，\\(m\\)是一个正整数。将两边同乘\\(nd^m\\)得：\n​$$ d^m=n(a_1d^{m-1}+\\dots+a_md^0)\n\\[ 故只要$d^m$是n的倍数，$1/n$在d进制下就为有限小数。 将n进行质因数分解，由唯一分解定理知只能分解为一种形式，设d为n的质因数的乘积，易知此时总存在m使得n|$d^m$，并且显然，这个d是最小的。 \\]\n","date":"2021-11-15T16:26:01+08:00","permalink":"https://kegalas.top/p/%E7%AE%97%E6%B3%95%E9%A2%98-%E6%9C%89%E9%99%90%E5%B0%8F%E6%95%B0/","title":"算法题-有限小数"},{"content":"各种主义整理 哲学、政治、社会 绝对主义 绝对主义认为在任何一种学说里，某种观点必定是绝对正确或者绝对错误的。\n荒诞主义 “荒诞主义”是对人生的极端反叛，认为人生的意义并不存在，所以可以活得很无厘头都无所谓。\n唯美主义 唯美主义者的人生目的就是去创造和享受一切美的东西。\n利他主义 利他主义者是一种随时都在无私地为他人福利着想的人，在道德判断上，认为别人的幸福快乐比自己的来得重要。利他主义在许多思想和文化中是一种美德。\n无政府主义（安那其主义） “无政府”一词并不代表混乱、虚无或道德沦丧的状态，而是一种由自由的个体自愿结合，以建立互助、自治、反独裁主义的和谐社会。庄子被认为是最早的无政府主义者。\n人类中心主义（以人为本） 人类中心主义认为人类是地球上最核心或者最重要的物种，评价现实的真实与否依靠人类的视角。人类中心主义是环境伦理学和环境哲学的主要概念，被认为是人类为何与自然环境发生冲突的根本原因，但这种理念已经根植在大多数人类的心中。\n无神论 无神论并没有统一的哲学思想，一些无神论者可能完全否定超自然事物，但另一些无神论者可能相信诸如占星术等伪科学。无神论经常同不可知论、反神论或反有神论相混淆。无神论者是认为没有神，不可知论者是认为神的存在是不可知，而反神论者是直接明确反对有神论。\n资本主义 资本主义的特色是私人拥有生产资料，且投资活动是由个人决策左右，而非由国家所控制，经济行为则以追求利润为目标。资本主义的主要经济模式包括了自由的资本和雇佣流动、市场竞争以及价格机制的运行。\n集体主义 集体主义是主张个人从属于社会，个人利益应当服从集体、民族、阶级和国家利益的一种思想理论。\n建构主义 建构主义者认为，任何一个社会人的行为都被约定俗成的社会传统、社会习惯和个人身份来制约或改变，因此现实和我们理解现实的方式都是人造的、主观的。\n犬儒主义 犬儒主义本意是指人不应被一切世俗的事物，包括宗教、礼节、惯常的衣食住行等习俗束缚，提倡对道德的无限追求，同时过着极简朴而非物质的生活。\n现代社会中“犬儒主义”一词常被误用作比喻一些否定利他主义、自私而且毫无道德的人。\n演绎主义 科学知识的产生是通过提出假设，然后通过实验和观察到的现象和数据来证明这样一个过程。\n决定论（determinism） 决定论是哲学的一种命题，认为每个事件的发生，包括人类的认知、举止、决定和行动，都是因为先前的事而有原因地发生。\n教条主义 指那些我们所相信的、不容质疑的观念。宗教上指那些具有权威性的团体所确立的教理，信徒以此作为应该学习的真理课程。\n二元论 二元论认为世界由两种力量统治：善与恶。善是精神，是灵魂，是善的力量创造的一切东西;而恶是物质，是肉体，是恶的力量创造的一切。这两种力量对抗着，共同支配世界。\n折衷主义 折衷主义是指操作运用不同的理论、方法、风格，拣选其中最佳要素，应用在新的创作中。在艺术或建筑批评等特定领域，指挪借多种视觉资源来创作新作品。\n平均主义 平均主义要求平均分享一切社会财富，对人人应该予以同样、平等对待。\n情感主义 情感主义是 20 世纪 30 年代，英美等国最流行的一种元伦理学，它否认伦理学的科学地位，主张道德是个人情感的表达，否认道德的客观性，认为道德判断没有合理的或有效的根据，没有真假之别，不过是表示某种情感、某种愿望。\n经验主义 经验主义指相信现代科学方法，认为理论应建立于对于事物的观察，通过实验研究而后进行理论归纳，优于单纯的逻辑推理、直觉或者先入为主的概念。\n副现象论（epiphenomenalism） 副现象论认为物理世界可以影响内心世界，但是反过来却不行。\n永恒论 永恒论认为时间不过是另外一个维度，明天已经存在了，只是你还没到那里而已。过去、现在、未来都一样真实。\n幸福主义 以幸福作为人生目的和理想的人生哲学。认为幸福包括物质生活和精神生活两个方面，人有追求幸福的权利，这是人的天性，人生的意义即在对于幸福的追求。\n存在主义 存在主义认为人存在的意义无法经由理性思考而得到答案，强调个人的主观经验。\n有序主义（extropy） 有序主义是相信科技进步可以解决人类问题的超人类主义思想之一。它认为随着科技的进步，总有一天人类可以得到永生。有序主义者愿意为了这个目的而努力，比如进行调查研究，志愿测试新技术等。\n女性主义 女性主义是指主要以女性经验为来源与动机的社会理论与政治运动。在对社会关系进行批判之外，许多女性主义的支持者也着重于性别不平等的分析以及推动妇女的权利、利益与议题。\n因果论（finalism） 因果论认为任何事物的发展都由预设好的既定结果来决定。\n自由意志 自由意志是指在社会、道德、政治的限制下，人们依照其拥有的条件去自主决定是否做一件事的能力。\n快乐主义 又称享乐主义。它倾向于用纯粹生物学的或心理学的观点来解释人的行为与需要，认为人们以求得快乐为生活目的，包括肉体与心灵的快乐。\n历史论 历史论认为去理解一个历史事件，我们必须考虑到当时的大环境和历史的上下文，而不是抽象地用概念去解释。\n唯心主义 唯心主义反对现实主义的哲学观，认为在人类的认知中，我们对物体的理解与感知，独立于物体的实际存在。\n个人主义 个人主义是一种道德的、政治的和社会的哲学，认为个人利益应是决定行为的最主要因素，强调个人自由和个人权利的重要性，超越集体如国家、种族、社会组织之上。\n神秘主义 也译作密契主义，包含人类与神明或某种超自然力量结合为一的各种形式、经验、体验，并且强调这是一切宗教共有的现象。神秘主义者的基本信条是世界上存在超自然的力量或隐藏的自然力量，这种力量可以通过特殊教育或者宗教仪式获得。\n自然主义 自然主义者认为自然的和超自然的都是一回事，可以用同一套方法来研究和解释。\n虚无主义 虚无主义作为哲学主义，为怀疑主义的极致形式，认为世界、生命(特别是人类)的存在是没有客观意义、目的以及可以理解的真相的。\n客观主义 在伦理学中，客观主义认为有些事情的对错是客观存在的。\n乐观主义 乐观主义是指一种对一切事物采与正面看法的观念。乐观的人不会想到一件事的缺点与瑕疵，永远以正面的想法对待身边的一切。\n泛神论 泛神论是一种将自然界与神等同起来，以强调自然界的至高无上的哲学观点。泛神论认为神就存在于自然界一切事物之中，并没有另外的超自然的主宰或精神力量。\n观点主义 观点主义认为人思想和价值判断来自不同的内心驱动和个人视角，并没有绝对的真理，只能去融合不同的观点。\n厌世主义 厌世主义，亦即悲观主义和虚无主义，是特定人群中所形成的一种无可奈何的悲观心理的反映。\n理性主义 理性主义是建立在承认人的理性可以作为知识来源的理论基础上的一种哲学方法，认为理性高于并独立于感官感知。\n相对主义 相对主义不是一个单一的学说，而是一系列观点，其共同的主题是，经验、思想、价值总是相对于其他东西而成立的，没有什么绝对的真理或评判标准。\n怀疑论 怀疑论是一种认识论，是认识问题的一种态度，它拒绝对问题作随意的不够严格的定论，对事物的看法采取一种类于“中立”的立场，既怀疑“是”也怀疑“不是”。怀疑论的反面是迷信，或更确切地说是独断论。\n斯多葛主义 斯多葛主义认为，重要的是在任何情况下都必须保持沉着，学会情感和生理的自我控制，以求得内心的平和与力量，获得更好的生活。斯多葛主义认为它的对立面激情是“背离理性和违反自然的精神冲动”。\n结构主义 结构主义认为任何一个现象都必须在知道了语境和上下文和他们之间的相互关系后才能被真正理解。\n融合主义 融合主义倡导不同宗教信仰或哲学主张之间的融合。\n有神论 广义上的有神论认为至少存在一个神明。狭义上特指一神论信仰，认为世界有一位至高的神明，关注于宇宙与这位神明之间的关系。\n功利主义 功利主义提倡追求大多数人的最大幸福，如果需要牺牲少部分人的利益也没办法。\n生命力论（活力论） 生命力论在人类历史上存在长久的历史，现代版本是19世纪初由瑞典化学家贝采利乌斯提出的，认为生命的运作，不只依循物理及化学定律。生命有自我决定的能力。\n新柏拉图主义 新柏拉图主义认为，世界有两极，一端是被称为“上帝”的神圣之光，另一端则是完全的黑暗。但新柏拉图主义也相信，完全的黑暗并不存在，只是缺乏亮光而已。\n柏拉图主义 尤指宣称理念形式是绝对的和永恒的实在，而世界中实在的现象却是不完美的和暂时的反映。\n伊壁鸠鲁学派 伊壁鸠鲁派认为并宣扬人死魂灭，这是人类思想史上的一大进步，同时提倡寻求快乐和幸福。但他们所主张的快乐决非肉欲物质享受之乐，而是排除情感困扰后的心灵宁静之乐。伊壁鸠鲁派生活简朴而又节制，目的就是要抵制奢侈生活对一个人身心的侵袭。\n斯多亚主义 斯多葛派认为世界理性决定事物的发展变化。所谓\u0026quot;世界理性\u0026quot;，就是神性，它是世界的主宰，个人只不过是神的整体中的一分子。在社会生活中斯多葛派强调顺从天命,要安于自己在社会中所处的地位，要恬淡寡欲，只有这样才能得到幸福。\n工具主义 工具主义的实践理性观可以表达为：理性指导人们的实践，是并且只是通过告诉人们采用何种必要的手段以达到既定目的来完成的，但是这些既定目的是否合适则不受理性的批判。\n世界主义 世界主义相信所有的人类都属于一个基于同样道德观念的社群，。世界主义的社群包括一个包容性的道德规范，共享的经济体制，和一个包含所有国家的政治结构。社群之中来自世界各地的人通过彼此的敬意来建立关系。\n加速主义 指一种政治与社会理论，认为资本主义制度或历史上某种技术相关的社会进程应该被加速以产生巨大社会变革。\n国际主义 国际主义是指各国无产阶级在反对剥削制度，争取自身解放斗争中，在政治、经济、道义等方面互相支持，互相援助，坚持国际团结的思想和政治原则。国际主义体现了无产阶级的民族观，是无产阶级处理民族问题的基本原则，也是无产阶级认识和处理各国无产阶级之间、各国无产阶级政党之间以及社会主义国家之间相互关系的行为准则。资本压迫和统治的国际性，决定了无产阶级反对资产阶级的斗争，从形式上看，首先是在一国范围内进行，但从内容上看，从来就是国际性的:无产阶级只有解放全人类，才能最后解放自己。\n沙文主义 沙文主义是资产阶级侵略性的民族主义。18世纪末、19世纪初产生于法国，因法国士兵沙文（Nicolas Chauvin）狂热拥护拿破仑一世的侵略扩张政策，主张用暴力建立法兰西帝国而得名。它鼓吹法兰西民族是世界上最优秀的民族，宣扬本民族利益高于一切，煽动民族之间的仇恨，主张征服和奴役其他民族。在帝国主义时代，沙文主义是帝国主义侵略和压迫其他国家和民族的舆论工具。\n民族主义 民族主义，即指以自我民族的利益为基础而进行的思想或运动。在近代以来，民族主义推动了民族解放与平等，是现代国际社会的源泉。美国学者汉斯·科恩认为：“民族主义首先而且最重要的是应该被看作是一种思想状态。”英国学者爱德华·卡尔认为：“民族主义通常被用来表示个人、群体和一个民族内部成员的一种意识，或者是增进自我民族的力量、自由或财富的一种愿望”。民族主义通常是指以维护本民族利益和尊严为出发点的思想与行为\n民粹主义 民粹主义（populism），又译平民主义，是在19世纪的俄国兴起的一股社会思潮。民粹主义的基本理论包括：强调平民群众的价值和理想，把平民化和大众化作为政治运动和政治制度合法性的最终来源；依靠平民大众对社会进行改革，并把普通群众当作政治改革的决定性力量；通过强调诸如平民的统一、全民公决、人民的创制权等民粹主义价值，对平民大众从整体上实施有效的控制和操纵。\n法西斯主义 法西斯主义（英语：Fascism；俄语：фашизм；意大利语：Fascismo；德语：Faschismus；西班牙语：Fascismo）是一种结合了社团主义、工团主义、独裁主义、极端民族主义、中央集权形式的军国主义、反无政府主义、反自由放任的资本主义、和反共产主义政治哲学；《大英百科全书》对法西斯主义的定义：“个人的地位被压制于集体—例如：某个国家、民族、种族、或社会阶级之下的社会组织。”\n纳粹主义 纳粹主义，是德文“Nationalsozialismus”缩写“Nazismus”的音译，意译为“民族社会主义”。\n纳粹主义意识形态的精神是“属于一个民族”，纳粹主义的基本理论包括：种族优秀论，“优等种族”至上；一切领域的“领袖”原则，“领袖”是国家整体意志的代表；反对英法资本主义体系以及共产主义思想体系，抵制共产主义理论。\n种族主义 种族主义是一种自我为中心的态度，认为种族差异决定人类社会历史和文化发展，认为自己所属的团体，例如人种、民族或国家，优越于其他的团体。\n修正主义 修正主义是在共产主义运动之中歪曲、篡改、否定马克思主义的一类资产阶级思潮和政治势力，是国际工人运动中打着马克思主义旗号反对马克思主义的机会主义思潮。“修正“一词来源于拉丁文reisio，意思是“修改、重新审查”。 修正主义产生于十九世纪九十年代。其社会基础是资本主义“和平”发展时期逐步形成起来的工人贵族阶层以及补充到工人阶级队伍中的小资产阶级。\n改良主义 改良主义是一种试图以非革命手段解决资本主义社会矛盾的资产阶级和小资产阶级思潮。这种思潮宣扬阶级合作，主张在保存资本主义制度的前提下，实行局部的微小的社会改良; 反对暴力革命和无产阶级专政，主张通过法令和立法途径实行社会改革，变资本主义为“普遍福利”社会。\n社会民主主义 社会民主主义是社会思潮和社会运动。它反映和代表了各国社会党 (包括社会民主党、工党) 及其国际联合组织“社会党国际” 解决社会矛盾问题、处理政治问题的共同的基本主张、基本观点、基本理论和方法，是各国社会党思想体系的统称。\n社会民主主义思潮最初于19世纪中叶诞生于欧洲，作为对资本剥削和侮辱劳动阶级的反抗运动，迄今已存在了一个半世纪之久。在一百五十余年的风风雨雨中，社会民主主义已经历了由理论到实践，由欧洲到世界的发展过程，愈益发展壮大。\n孤立主义 孤立主义，是一种外交政策。它通常由防务和经济上的两方面政策组成。在防务上，孤立主义采取不干涉原则，即除自卫战争外不主动卷入任何外部军事冲突；在经济文化上，通过立法最大程度限制与国外的贸易和文化交流。\n单边主义 所谓单边主义是指举足轻重的特定大国，不考虑大多数国家和民众的愿望，单独或带头退出或挑战已制订或商议好了的维护国际性、地区性、集体性和平、发展、进步的规则和制度，并对全局或局部的和平、发展、进步有破坏性的影响和后果的行为与倾向。\n多边主义 多边主义原是指不完全依赖俄罗斯或者独联体内部来解决问题而是谋求多边发展利用外部世界一切可能利用的因素和机会既为自己吸收更多的发展动力又可避免单方面依赖而受制于俄罗斯。现指三个或三个以上国家之间发生联系的方式。\n实用主义 冯友兰总结的实用主义主要观点最为简洁明了。在《三松堂自序》中冯说：“实用主义的特点在于它的真理论。它的真理论实际是一种不可知论。认识来源于经验，人们所能认识的，只限于经验，至于经验的背后还有什么东西，那是不可知的，也不必问这个问题。这个问题是没有意义的，因为无论怎么说，人们总是不能走出经验范围之外而有什么认识。要解决这个问题，还得靠经验。所谓真理，无非就是对于经验的一种解释，对于复杂的经验解释得通。如果解释得通，它就是真理，对于我们有用，即有用就是真理，忽略所谓客观的真理。”如此说得之，实用二字昭然若揭。\n计算机科学 符号主义 符号主义（Symbolism）是一种基于逻辑推理的智能模拟方法，又称为逻辑主义(Logicism)、心理学派(Psychlogism)或计算机学派(Computerism)，其原理主要为物理符号系统（即符号操作系统）假设和有限合理性原理，长期以来，一直在人工智能中处于主导地位，其代表人物是纽威尔、肖、西蒙和尼尔森。\n连接主义 连接主义(connectionism)，又称为仿生学派或生理学派，其主要原理为神经网络及神经网络间的连接机制与学习算法。\n行为主义 行为主义(actionism)，又称为进化主义或控制论学派，其原理为控制论及感知-动作型控制系统。\n文艺 文学 都合主义 剧情、人物、设定等为主角服务而无视因果、设定，这就是都合主义。\n魔幻现实主义 魔幻现实主义作为拉丁美洲所特有的文学样式，它具有与众不同的鲜明而独特的特征。将新闻报道般的写实与神奇的幻想结合起来，采用模糊化技巧和神话模式，表现拉丁美洲的历史文化和现实生活。这是魔幻现实主义突出的艺术特征。\n美术 浪漫主义 这一画派摆脱了当时学院派和古典主义的羁绊，偏重于发挥艺术家自己的想象和创造，创作题材取自现实生活，中世纪传说和文学名著（如莎士比亚、但丁、歌德、拜伦的作品）等，有一定的进步性。\n印象派 不依据可靠的知识，以瞬间的印象作画。画家们是抓住一个具有特点的侧面去作画，所以他们必须疾飞画笔把颜色直接涂在画布上，他们只能多考虑画的总体效果，较少的顾及枝节细部。印象主义的以粗放的笔法作画，作品缺乏修饰，是一种对笔法较草率的画法。\n印象主义采取在户外阳光下直接描绘景物，追求以思维来揣摩光与色的变化，并将瞬间的光感依据自己脑海中的处理附之于画布之上，这种对光线和色彩的揣摩也是达到了色彩和光感美的极致。\n画家：莫奈、马奈、毕沙罗、雷诺阿、 西斯莱、德加、科罗、莫里索、巴齐约\n点彩派（新印象派） 他们不用轮廓线划分形象，而用点状的小笔触，通过合乎科学的光色规律的并置，让无数小色点在观者视觉中混合，从而构成色点组成的形象，被一些艺术评论家称作“点彩派”。\n画家：乔治·修拉、保罗·西涅克、卡米尔·毕沙罗、M. 吕斯、H.-E.克罗斯\n新艺术派 简单讲就是喜欢画些清新脱俗的花草纹样，而且喜欢勾线，还经常画得扁扁平平的。女人头上长花是常有的事，当然，驴头上也可以长。\n画家：慕夏\n野兽派 顾名思义，就是像野兽一样狂放，这一派画家基本是不调色的，颜料挤出来就直接用，而且形状也是粗矿得很。国内的幼儿园墙画深得这种风格的真传。\n画家：马蒂斯\n风格派 风格派完全拒绝使用任何的具象元素，主张用纯粹几何形的抽象来表现纯粹的精神。认为抛开具体描绘,抛开细节，才能避免个别性和特殊性，获得人类共通的纯粹精神表现。\n画家：蒙德里安\n构成主义 简单讲，这个派别特备喜欢画立体块块和几何图形，而且喜欢乱摆。\n画家：里茨斯基\n超现实主义 简单讲就是觉得现实不重要，专门画现实里没有的东西。比如，为什么驴就不能长得像鱼呢？\n画家：达利\n表现主义 表现主义是艺术家通过作品着重表现内心的情感，而忽视对描写对象形式的摹写，因此往往表现为对现实的扭曲和抽象化，这个做法尤其用来表达恐惧的情感，因此，主题欢快的表现主义作品很少见。\n画家：席勒\n抽象表现主义 抽象表现主义是指一种结合了抽象形式和表现主义画家情感价值取向的非写实性绘画风格。\n该运动存在着多样的绘画风格，画风多半大胆粗犷、尖锐且尺幅巨大。画作色彩强烈，并经常出现偶然效果，例如让油彩自然流淌而不加以限制。\n画家：波洛克\n立体派 主要目的是追求一种几何形体的美，在形式的排列组合所产生的美感。 它否定了从一个视点观察事物和表现事物的传统方法，把三度空间的画面归结成平面。因为把不同视点所观察和理解的形诉诸于画面，从而表现出时间的持续性。\n画家：毕加索\n未来派 未来派全盘否定传统文艺的价值，认为人类的文化遗产和现存的文化都是腐朽、僵死，与现时代的精神不相容的。他们的口号是“摒弃一切博物馆、图书馆和学院”，反对一切模仿的形式，反抗和谐和趣味高雅，否定艺术批评的作用。未来派的美学主张与表现主义、立体主义有相同的地方，只是他们特别强调表现运动和力量，口号更激烈，纲领更明确，虚无主义的色彩更浓郁。\n他们觉得不能只表现静态的东西，画什么都要动起来、嗨起来，所以一个驴子可能带着七八个形状各异的残影。\n画家：波丘尼\n达达主义 达达主义是20世纪初期在欧洲兴起的虚无主义运动，是一种无政府主义的艺术运动，其艺术特点如下:\n1.反传统观念，公开蔑视文学艺术的一切现有形式，反秩序，反系统化\n2.运用理性的方法抨击人类，将人性化的内容与机械原理结合起来，并使用现成品作为艺术创作\n3.艺术手法抽象怪异，完全突破了已有的艺术观念和形式的束缚，被认为是后现代主义的创作者\n4.代表画家 杜尚，法国艺术家，被誉为\u0026quot;现代艺术的守护神\u0026quot;，其代表作是《下楼梯的裸女二号》，《泉》\n波普艺术 波普艺术，一种主要源于商业美术形式的艺术风格，其特点是将大众文化的一些细节，如连环画、快餐及印有商标的包装进行放大复制。\n画家：安迪·沃霍尔\n极简主义 顾名思义就是能省就省，企图以最少的东西表达最多的含义，能用一双眼睛搞定何必要画一整头驴呢？\n画家：纽曼\n概念艺术 概念艺术就是在20世纪60年代中后期出现，其基本概念源于马塞尔·杜尚的思想：一件艺术品从根本上说是艺术家的思想，而不是有形的实物，即绘画和雕塑；有形的实物出自那种思想。这种艺术导致以观念取代实物、是艺术摆脱物质的艺术品。\n画家：杜尚\n后现代主义 是一种对现代表达方式甚至思维方式以及价值观的颠覆和反叛。\n音乐 巴洛克时期 音乐领域中的巴洛克时期，如同其他艺术领域一样，也体现了各种不同的风格。 这段时期的音乐中没有太多的思想，讲究韵律的优美。歌剧、清唱剧和大合唱是声乐方面最重要的一些新形式，而奏鸣曲、协奏曲和前奏曲则是为器乐而创作的。\n古典主义时期 其特点是：理智和情感的高度统一，深刻的思想内容与完美的艺术形式的高度统一。创作技法上，继承欧洲传统的复调与主调音乐的成就，并确立了近代奏鸣曲曲式的结构以及交响曲、协奏曲、各类室内乐的体裁和形式，对西洋音乐的发展有深远影响。\n浪漫主义时期 这个时期艺术家的创作上则表现为对主观感情的崇尚，对自然的热爱和对未来的幻想。艺术表现形式也较以前有了新的变化，出现了浪漫主义思潮与风格的形成与发展。\n注：本文有许多内容搜集自互联网，若有侵权请联系删除。\n","date":"2021-01-17T23:25:28Z","permalink":"https://kegalas.top/inferior/%E5%90%84%E7%A7%8D%E4%B8%BB%E4%B9%89%E6%95%B4%E7%90%86/","title":"各种主义整理"},{"content":"系统：Ubuntu 20.10\n今天使用Ubuntu，想安装一下deepin的qq，在网上找到以下方法：\nwget -O- https://deepin-wine.i-m.dev/setup.sh | sh 正常执行\nsudo apt-get install com.qq.im.deepin 报错：\n下列软件包有未满足的依赖关系： libgirepository-1.0-1 : 破坏: python-gi (\u0026lt; 3.34.0-4~) 但是 3.30.4-1 正要被安装 E: 无法修正错误，因为您要求某些软件包保持现状，就是它们破坏了软件包间的依赖关系。 我试着安装python-gi，同样报错，我又试着删了libgirepository-1.0-1，但是他是很多包的依赖，不敢删。\n百度搜索无果，bing搜索外国也没找到解决办法，倒是有人遇到了同样的问题。\n在ubuntu搜集信息后，发现libgirepository-1.0-1依赖于libffi7，但是apt下载不到他，只能去https://packages.ubuntu.com/zh-cn/focal/libffi7手动下载。安装完后又去https://packages.ubuntu.com/zh-cn/focal/python-gi手动下载python-gi，先后安装成功。\n再次安装qq，重启，安装成功。\n但是发现字体显示不全。找了个网站下载了simsun.ttc，放到~/.deepinwine/Deepin-QQ/drive_c/windows/Fonts/\n问题解决。\n图片 1\r后记：现在linux下qq有官方支持的新版本了，应该没人再用这个了吧。\n","date":"2021-01-03T12:16:26Z","image":"https://kegalas.top/p/ubuntu%E5%AE%89%E8%A3%85deepin-qq%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E4%B8%8E%E8%A7%A3%E5%86%B3/cover_huadd5fdafa4a185a8686ebe054dd413b9_24301_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/ubuntu%E5%AE%89%E8%A3%85deepin-qq%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E4%B8%8E%E8%A7%A3%E5%86%B3/","title":"ubuntu安装deepin-qq时遇到的问题与解决"},{"content":"[TOC]\n不等式 均值不等式 \\(H_n\\) 为调和平均数、 ​\\(G_n\\) 为几何平均数、 ​\\(A_n\\) 为算数平均数、 ​\\(Q_n\\) 为平方平均数。 ​任意\\(x_i\u003e 0\\)都成立时，有 ​\n\\[H_n=\\frac{n}{\\sum\\limits_{i=1}^n\\frac{1}{x_i}}=\\frac{n}{\\frac{1}{x_1}+\\frac{1}{x_2}+\\dots+\\frac{1}{x_n}} \\]\n​\n\\[G_n=\\sqrt[n]{\\prod_{i=1}^{n}x_i}=\\sqrt[n]{x_1 x_2 \\dots x_n} \\]\n​\n\\[A_n=\\frac{\\sum\\limits_{i=1}^{n}x_i}{n}=\\frac{x_1+x_2+\\dots+x_n}{n} \\]\n​\n\\[Q_n=\\sqrt{\\frac{\\sum\\limits_{i=1}^{n}x_i^{2}}{n}}=\\sqrt{\\frac{x_1^{2}+x_2^{2}+\\dots+x_n^{2}}{n}} \\]\n​\n\\[H_n\\leq G_n\\leq A_n\\leq Q_n \\]\n当且仅 当\\(x_1=x_2=\\dots =x_n\\)时取等号\n对数平均不等式 \\(a\\neq b\\)时，有 ​\n\\[\\sqrt{ab}\u003c\\frac{a-b}{lna-lnb}\u003c\\frac{a+b}{2} \\]\n柯西不等式 \\[\\sum\\limits_{i=1}^{n}a_i^{2}\\sum\\limits_{i=1}^{n}b_i^{2}\\geq (\\sum\\limits_{i=1}^{n}a_i b_i)^2 \\]\n​当且仅当\\(\\frac{a_1}{b_1}=\\frac{a_2}{b_2}=\\dots =\\frac{a_n}{b_n}\\)时取等号 ​其中二维形式如下 ​\n\\[(a^2+b^2)(c^2+d^2)\\geq (ac+bd)^2 \\]\n​当且仅当\\(ad=bc\\)即\\(\\frac{a}{c}=\\frac{b}{d}\\)时取等\n排序不等式 ​排序不等式表示如下 ​\n设有两组数\\(a_1,a_2,\\dots,a_n\\)和\\(b_1,b_2,\\dots,b_n\\)，满足\\(a_1\\leq a_2\\leq \\dots \\leq a_n\\)且\\(b_1\\leq b_2\\leq \\dots \\leq b_n\\)，\\(c_1,c_2,\\dots,c_n\\)是\\(b_1,b_2,\\dots,b_n\\)的乱序排列，则有： ​ ​\n\\[a_1 b_n+a_2 b_{n-1}+\\dots+a_n b_1\\leq a_1 c_1+a_2 c_2+\\dots+a_n c_n\\leq a_1 b_1+a_2 b_2+\\dots+a_n b_n \\]\n​ ​当且仅当\\(a_1=a_2=\\dots=a_n\\)或\\(b_1=b_2=\\dots=b_n\\)时取等号。便于记忆，常记为：反序和\\(\\leq\\)乱序和\\(\\leq\\)顺序和\n权方和不等式 ​若\\(a_i\u003e0\\)，\\(b_i\u003e0\\)，\\(m\u003e0\\)，则有 ​\n\\[\\sum\\limits_{i=1}^{n}\\frac{a_i^{m+1}}{b_i^{m}}\\geq \\frac{\\left (\\sum\\limits_{i=1}^{n}a_i\\right) ^{m+1}}{\\left (\\sum\\limits_{i=1}^{n}b_i\\right) ^m} \\]\n即为 ​\n\\[\\frac{a_1^{m+1}}{b_1^{m}}+\\frac{a_2^{m+1}}{b_2^{m}}+\\dots+\\frac{a_n^{m+1}}{b_n^{m}}\\geq \\frac{(a_1+a_2+\\dots+a_n)^{m+1}}{(b_1+b_2+\\dots+b_n)^{m}} \\]\n​当且仅当\\(a_i=\\lambda b_i\\)时取等号其中二维形式如下对于正数\\(a\\)，\\(b\\)，\\(x\\)，\\(y\\)，有 ​\n\\[\\frac{a^2}{x}+\\frac{b^2}{y}\\geq \\frac{(a+b)^2}{x+y} \\]\n​当且仅当\\(a:b=x:y\\)时取等号也有 ​\n\\[\\frac{a^2}{ax}+\\frac{b^2}{by}=\\frac{a}{x}+\\frac{b}{y}\\geq \\frac{(a+b)^2}{ax+by} \\]\n​当且仅当\\(x=y\\)时取等号\n舒尔不等式 ​\\(a,b,c\\geq 0\\quad t\\in R\\)时，有 ​\n\\[a^t (a-b)(a-c)+b^t (b-a)(b-c)+c^t (c-a)(c-b)\\geq 0 \\]\n​当且仅当\\(a=b=c\\)，或其中两个数相等且另一个等于零时，取等号。特别的，当\\(t\\)为非负偶数时，此不等式对任意实数\\(a,b,c\\)成立。\n琴生不等式 设\\(f(x)\\)在区间\\(I\\)上是下凸函数，则对任意\\(x_i\\in I\\)及\\(p_i\u003e0\\quad (i=1,2,\\dots,n)\\)，有 ​\n\\[\\frac{\\sum\\limits_{i=1}^{n}p_i\\cdot f(x_i)}{\\sum\\limits_{i=1}^{n}p_i}\\geq f \\left (\\frac{\\sum\\limits_{i=1}^{n}p_i\\cdot x_i}{\\sum\\limits_{i=1}^{n}p_i} \\right ) \\]\n​其中等号当且仅当\\(x_1=x_2=\\dots=x_n\\)时成立，若\\(f(x)\\)在区间\\(I\\)上是上凸函数，则不等号反向。\n绝对值不等式 ​\n\\[||a|-|b|| \\leq |a\\pm b| \\leq |a|+|b| \\]\n糖水不等式 \\[\\frac{b+c}{a+c}\u003e\\frac{b}{a}(a\u003eb\u003e0,c\u003e0) \\]\n\\[\\frac{b+c}{a+c}\u003c\\frac{b}{a}(b\u003ea\u003e0,c\u003e0) \\]\n函数 拉格朗日中值定理 ​设\\(y=f(x)\\)在\\([a,b]\\)上连续，在\\((a,b)\\)上可导，则存在\\(\\xi \\in (a,b)\\)使得 ​\n\\[f^{'}(\\xi)=\\frac{f(b)-f(a)}{b-a} \\]\n拉格朗日乘数法 ​【例题】若正数\\(a,b\\)满足\\(2a+b=1\\)，则\\(\\frac{a}{2-2a}+\\frac{b}{2-b}\\)的最小值为? ​\n解：构造拉格朗日函数 ​\n\\[L(a,b,\\lambda)=\\frac{a}{2-2a}+\\frac{b}{2-b}-\\lambda(2a+b-1) \\]\n令 ​\n\\[\\frac{\\partial L}{\\partial a}=L_a=\\frac{1}{2(1-a)^2}-2\\lambda=0 \\]\n\\[\\frac{\\partial L}{\\partial b}=L_b=\\frac{2}{(2-b)^2}-\\lambda=0 \\]\n​\n\\[\\frac{\\partial L}{\\partial \\lambda}=L_\\lambda=-(2a+b-1)=0 \\]\n联立解得 ​\n\\[a=\\frac{5-3\\sqrt{2}}{2},b=3\\sqrt{2}-4,\\lambda=\\frac{1}{27-18\\sqrt{2}} \\]\n​从而 ​\n\\[\\frac{a}{2-2a}+\\frac{b}{2-b}=\\frac{2\\sqrt{2}}{3}-\\frac{1}{2} \\]\n​此即为所求的最小值。\n高次韦达定理 ​设\\(x_1,x_2,\\dots,x_n\\)为如下方程的根 ​\n\\[a_n x^n+a_{n-1} x^{n-1}+\\dots+a_1 x+a_0=0 \\]\n​则有 ​\n\\[x_1+x_2+\\dots+x_n=-\\frac{a_{n-1}}{a_n} \\]\n\\[x_1 x_2+x_1 x_3+\\dots+x_n x_{n-1}=\\frac{a_{n-2}}{a_n} \\]\n​\n\\[\\dots \\]\n​\n\\[x_1 x_2\\dots x_n=(-1)^n \\frac{a_0}{a_n} \\]\n​其中三次的形式如下若\\(ax^3+bx^2+cx+d=0\\ (a\\neq 0)\\)的3个根分别为\\(x_1,x_2,x_3\\)则有 ​\n\\[x_1+x_2+x_3=-\\frac{b}{a} \\]\n​\n\\[x_1 x_2+x_1 x_3+x_2 x_3=\\frac{c}{a} \\]\n​\n\\[x_1\\cdot x_2\\cdot x_3=-\\frac{d}{a} \\]\n泰勒展开 ​若函数\\(f(x)\\)在\\(x_0\\)存在\\(n\\)阶导数，则有 ​\n\\[f(x)=f(x_0)+\\frac{f'(x_0)}{1!}(x-x_0)+\\frac{f''(x_0)}{2!}(x-x_0)^2+\\dots+\\frac{f^{(n)} (x_0)}{n!}(x-x_0)^n+R_{n+1} \\]\n​上式即为函数\\(f(x)\\)在\\(x_0\\)处的泰勒展开式，其中\\(R_{n+1}=\\frac{f^{(n+1)} (\\xi)}{(n+1)!}(x-x_0)^{n+1}\\)（其中\\(\\xi\\)介于\\(x\\)和\\(x_0\\)间）叫做拉格朗日余项。\n​拉格朗日余项可用于证明不等式。如：\\(-1\u003c x\u003c1\\)时 ​\n\\[\\ln(1+x)=x-\\frac{x^2}{2}+\\frac{x^3}{3}-\\frac{x^4}{4(1+\\xi)^4} (-1\u003c\\xi\u003c1) \\]\n​因为\\(-\\frac{x^4}{4(1+\\xi)^4}\\leq 0\\)，所以\\(\\ln(1+x)\\leq x-\\frac{x^2}{2}+\\frac{x^3}{3}\\)\n极值点偏移 ​【例题】已知函数\\(f(x)=e^x-ax\\)有两个零点\\(x_1\\)和\\(x_2\\)，证明：\\(x_1 +x_2 \u003e2\\) ​\n\\[f(x)=e^x-ax=0\\Leftrightarrow \\frac{e^x}{x}=a \\]\n​令\n\\[\\varphi(x)=\\frac{e^x}{x} \\]\n​则\n\\[f(x_1)=f(x_2)\\Leftrightarrow\\varphi(x_1)=\\varphi(x_2),\\quad \\varphi'(x)=\\frac{(x-1)e^x}{x^2} \\]\n因此\\(\\varphi(x)\\)在\\((0,1)\\)单减，\\((1,+\\infty)\\)单增，不妨设\\(0\u003c x_1\u003c1\u003c x_2\\)，则\\(x_1+x_2\u003e2\\Leftrightarrow x_2\u003e2-x_1\\)，注意到\\(2-x_1\u003e1\\Leftrightarrow\\varphi(x_2)\u003e\\varphi(2-x_1)\\)，注意到\\(\\varphi(x_1)=\\varphi(x_2)\\)，则\\(\\varphi(x_1)\u003e\\varphi(2-x_1)\\)，其中\\(0\u003c x_1\u003c1\\)\n令\n\\[g(x)=\\varphi(x)-\\varphi(2-x), \\quad 0\u003c x\u003c1 \\]\n​ 易知 ​\n\\[g'(x)\u003c0 \\]\n​所以\\(g(x)\\)在\\((0,1)\\)上单减，\\(g(x)\u003eg(1)=\\varphi(1)-\\varphi(1)=0\\)，即\\(\\varphi(x)-\\varphi(2-x)\u003e0\\)，令\\(x=x_1\\)，Q.E.D.\n最值函数基本定理 定理一: ​\n\\[min\\{a,b \\} \\leq \\frac{a+b}{2} \\leq max\\{a,b \\} \\]\n​\n\\[min\\{a,b\\}\\leq\\sqrt{ab}\\leq max\\{a,b\\}.(a\u003e0,b\u003e0) \\]\n定理二： ​\n\\[max\\{\\left|a+b\\right|,\\left|a-b\\right| \\}=|a|+|b| \\]\n​\n\\[min\\{\\left|a+b\\right|,\\left|a-b\\right| \\}=||a|-|b|| \\]\n​定理三： ​\n\\[max\\{|a|,|b|\\}=\\frac{|a+b|}{2}+\\frac{|a-b|}{2} \\]\n​\n\\[min\\{|a|,|b|\\}=\\left|\\frac{|a+b|}{2}-\\frac{|a-b|}{2}\\right| \\]\n数列 不动点原理 ​【例题】求\\(a_1 = 1 , a_{n+1}=2a_n +1\\)的通项公式，其特征函数为\\(f(x)=2x+1\\)，令\\(f(x)=x\\),解得\\(x=-1\\)，带入得\\(a_{n+1}-(-1)=2(a_n-(-1))\\)，即\\(a_{n+1}+1=2(a_n+1)\\)，之后根据等比数列可得\\(a_n=2^n -1\\)\n组合数学 容斥原理 ​建议根据韦恩图解题\n伯努利装错信封问题 ​n封信与n个信封全部错位的组合数为 ​\n\\[f(n)=n!\\left[ \\frac{1}{2!}-\\frac{1}{3!}+\\frac{1}{4!}-\\dots +(-1)^n \\frac{1}{n!} \\right] \\]\n向量 极化恒等式 ​重要恒等式:\\(4ab=(a+b)^2-(a-b)^2\\) ​\n极化恒等式:\\(4\\boldsymbol{a}\\cdot \\boldsymbol{b}=(\\boldsymbol{a}+\\boldsymbol{b})^2-(\\boldsymbol{a}-\\boldsymbol{b})^2\\)\n分点恒等式 ​在\\(\\triangle ABC\\)中，M为BC上一等分点，当\\(\\overrightarrow{BM}=\\lambda \\overrightarrow{MC}时\\)，有 ​\n\\[\\overrightarrow{AM}=\\frac{1}{1+\\lambda}\\overrightarrow{AB}+\\frac{\\lambda}{1+\\lambda}\\overrightarrow{AC} \\]\n三点共线定理 在平面中A、B、P三点共线的充要条件是：对于该平面内任意一点O，存在唯一的实数\\(x,y\\)使得： ​\n\\[\\overrightarrow{OP}=x\\overrightarrow{OA}+y\\overrightarrow{OB} \\]\n且 ​\n\\[x+y=1 \\]\n​特别的有：当P在线段AB上时，\\(x\u003e0,y\u003e0\\)，P在线段AB之外时,\\(xy\u003c0\\)\n向量中值定理 在\\(\\triangle ABC\\)中，M为BC的中点，则 ​\n\\[AB^2+AC^2=2(AM^2+BM^2) \\]\n对应的向量公式有: ​\n\\[\\boldsymbol{a}^2+\\boldsymbol{b}^2=2\\left[\\left(\\frac{\\boldsymbol{a}+\\boldsymbol{b}}{2}\\right)^2 + \\left(\\frac{\\boldsymbol{a}-\\boldsymbol{b}}{2}\\right)^2 \\right] \\]\n向量数乘余弦定理 在\\(\\triangle ABC\\)中,有 ​\n\\[\\overrightarrow{AB}\\cdot \\overrightarrow{AC}=\\frac{AB^2+AC^2-BC^2}{2} \\]\n三角 和差化积 ​\n\\[sin\\alpha+sin\\beta=2sin\\frac{\\alpha+\\beta}{2}\\cdot cos\\frac{\\alpha-\\beta}{2} \\]\n​\n\\[sin\\alpha-sin\\beta=2cos\\frac{\\alpha+\\beta}{2}\\cdot sin\\frac{\\alpha-\\beta}{2} \\]\n​\n\\[cos\\alpha+cos\\beta=2cos\\frac{\\alpha+\\beta}{2}\\cdot cos\\frac{\\alpha-\\beta}{2} \\]\n​\n\\[cos\\alpha-cos\\beta=-2sin\\frac{\\alpha+\\beta}{2}\\cdot sin\\frac{\\alpha-\\beta}{2} \\]\n积化和差 ​\n\\[sin\\alpha cos\\beta=\\frac{1}{2}\\left[sin(\\alpha+\\beta)+sin(\\alpha-\\beta)\\right] \\]\n​\n\\[os\\alpha sin\\beta=\\frac{1}{2}\\left[sin(\\alpha+\\beta)-sin(\\alpha-\\beta)\\right] \\]\n​\n\\[cos\\alpha cos\\beta=\\frac{1}{2}\\left[cos(\\alpha+\\beta)+cos(\\alpha-\\beta)\\right] \\]\n​\n\\[sin\\alpha sin\\beta=-\\frac{1}{2}\\left[cos(\\alpha+\\beta)-cos(\\alpha-\\beta)\\right] \\]\n半角公式 \\[sin\\frac{\\theta}{2}=\\pm \\sqrt{\\frac{1-cos\\alpha}{2}} \\]\n​\n\\[sin\\frac{\\theta}{2}=\\pm \\sqrt{\\frac{1+cos\\alpha}{2}} \\]\n​\n\\[tan\\frac{\\theta}{2}=\\pm \\sqrt{\\frac{1-cos\\alpha}{1+cos\\alpha}}=\\frac{sin\\alpha}{1+cos\\alpha}=\\frac{1-cos\\alpha}{sin\\alpha} \\]\n辅助角公式 ​\n\\[asin\\theta\\pm bcos\\theta=\\sqrt{a^2+b^2}sin(\\theta\\pm\\varphi),\\quad tan\\varphi=\\frac{b}{a} \\]\n统计、概率、分布 期望、方差、标准差 数学期望：我们称\\(E\\xi = x_1 p_1+x_2 p_2+\\dots+x_n p_n\\)为离散型随机变量\\(\\xi\\)的数学期望 ​\n方差和标准差：我们称\\(D\\xi = \\sum_{i=1}^{n}(x_i-E\\xi)^2 p_i\\)为离散型随机变量\\(\\xi\\)的方差，其算数平方根\\(\\sqrt{D\\xi}=\\sigma\\xi\\)叫做离散型随机变量\\(\\xi\\)的标准差 ​\n​定理一： ​\n\\[E(a\\xi+b)=aE\\xi+b \\]\n​\n\\[D(a\\xi+b)=a^2 D\\xi \\]\n​ 定理二： ​\n\\[E(a\\xi _1+b\\xi _2)=aE\\xi _1+bE\\xi _2 \\]\n二项分布 n次试验中事件A恰好发生k次 ​\n\\[P(E) ={n \\choose k}p^k (1-p)^{n-k}\\quad k=1,2,3,\\dots \\]\n​我们称\\(\\xi\\)服从二项分布，记作\\(\\xi \\sim B(n,p)\\) ​\n定理：\\(E\\xi = np\\), \\(D\\xi = np(1-p)\\)\n正态分布 ​\n\\[f_\\xi (x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\sigma ^2}} \\quad x\\in R,\\sigma\u003e0 \\]\n​记作\\(\\xi \\sim N(\\mu,\\sigma ^2)\\) ​\n性质：\n其正态曲线关于\\(x=\\mu\\)对称，最高点为\\(\\frac{1}{\\sigma\\sqrt{2\\pi}}\\) \\(E\\xi=\\mu,D\\xi=\\sigma ^2\\) \\(\\sigma\\)越大，正态曲线越“矮胖”，表示分布越分散，\\(\\sigma\\)越小，正态曲线越“瘦高”，表示分布越集中 几何分布 ​在n次伯努利试验中，试验k次才得到第一次成功的机率。记为\\(P(\\xi=k)=g(k,p)=q^{k-1}p\\),其中\\(q=1-p\\)，也记为\\(\\xi \\sim GE(p)\\)\n定理：\\(E\\xi=\\frac{1}{p},D\\xi=\\frac{q}{p^2}\\)\n超几何分布 它描述了从有限N个物件（其中包含M个指定种类的物件）中抽出n个物件，成功抽出该指定种类的物件的次数（不放回），记为\\(\\eta \\sim H(n,M,N)\\) ​\n\\[P ( \\eta=m ) = \\frac{\\binom{M}{m}\\cdot \\binom{N-M}{n-m}}{\\binom{N}{n}}\\quad m=0,1,2,\\dots,min \\{ n,M \\} \\]\n其中有：\n\\[E(X)=\\frac{nM}{N} \\]\n\\[D(X)=\\frac{nM}{N}\\left(1-\\frac{M}{N}\\right)\\frac{N-n}{N-1} \\]\n方程 立方和分解 ​\n\\[a^3+b^3=(a+b)(a^2-ab+b^2) \\]\n立方差分解 \\[a^3-b^3=(a-b)(a^2+ab+b^2) \\]\n比例性质 ​若\\(\\frac{a}{b}=\\frac{c}{d}\\)则有：\n​合比性质\n\\[\\frac{a+b}{b}=\\frac{c+d}{d} \\]\n​分比性质\n\\[\\frac{a-b}{b}=\\frac{c-d}{d} \\]\n​合分比性质\n\\[\\frac{a+b}{a-b}=\\frac{c+d}{c-d} \\]\n​等比性质\n\\[\\frac{a}{b}=\\frac{c}{d}=\\frac{a+c}{b+d}=\\frac{ma+nc}{mb+nd} \\]\n几何 射影定理 ​射影定理，又称“欧几里德定理”：在直角三角形中，斜边上的高是两条直角边在斜边射影的比例中项，每一条直角边又是这条直角边在斜边上的射影和斜边的比例中项。 ​ ​在\\(Rt\\bigtriangleup ABC\\)中,\\(\\angle ABC=90^\\circ\\)，\\(BD\\)为斜边\\(AC\\)上的高，则有射影定理如下： ​\n\\[BD^2=AD\\cdot CD \\]\n\\[AB^2=AC\\cdot AD \\]\n\\[BC^2=CD\\cdot AC \\]\n阿波罗尼斯圆 ​平面内到两个定点的距离之比为常数\\(k(k\\neq1)\\)的点的轨迹是圆\n角平分线定理 在\\(\\bigtriangleup ABC\\)中，\\(AM\\)为\\(\\angle BAC\\)的角平分线，\\(M\\)在\\(BC\\)上，则有： ​\n\\[\\frac{AB}{AC}=\\frac{MB}{MC} \\]\n三角形五心 重心 ​三角形的三条边的中线交于一点，该点叫三角形的重心 ​\n重心的性质： ​\n重心到顶点的距离与重心到对边中点的距离之比为2:1。 重心和三角形任意两个顶点组成的3个三角形面积相等。即重心到三条边的距离与三条边的长成反比。 重心到三角形3个顶点距离的平方和最小。 在平面直角坐标系中，重心的坐标是顶点坐标的算术平均数，即其重心坐标为 ​ \\[P_1= ​ \\begin{bmatrix} ​ x_1\\\\ ​ y_1 ​ \\end{bmatrix} ​ P_2= ​ \\begin{bmatrix} ​ x_2\\\\ ​ y_2 ​ \\end{bmatrix} ​ p_3= ​ \\begin{bmatrix} ​ x_3\\\\ ​ y_3 ​ \\end{bmatrix} \\]\n\\[​ \\begin{bmatrix} ​ x\\\\ ​ y ​ \\end{bmatrix} ​ =\\frac{1}{3}(P_1+P_2+P_3)=\\frac{1}{3} ​ \\begin{bmatrix} ​ x_1+x_2+x_3\\\\ ​ y_1+y_2+y_3 ​ \\end{bmatrix} \\]\n以重心为起点，以三角形三顶点为终点的三条向量之和等于零向量。 外心 ​三角形外接圆的圆心，叫做三角形的外心。 ​\n外心的性质： ​\n三角形的三条边的垂直平分线交于一点，该点即为该三角形的外心。 若O是\\(\\bigtriangleup\\)ABC的外心，则\\(\\angle\\)BOC=2\\(\\angle\\)A（\\(\\angle\\)A为锐角或直角）或\\(\\angle\\)BOC=360°-2\\(\\angle\\)A（\\(\\angle\\)A为钝角）。 当三角形为锐角三角形时，外心在三角形内部；当三角形为钝角三角形时，外心在三角形外部；当三角形为直角三角形时，外心在斜边上，与斜边的中点重合。 外心到三顶点的距离相等 垂心 ​三角形的三条高（所在直线）交于一点，该点叫做三角形的垂心。 ​\n垂心的性质： ​\n三角形三个顶点，三个垂足，垂心这7个点可以得到6个四点圆。 三角形外心O、重心G和垂心H三点共线，且OG:GH=1:2。（此直线称为三角形的欧拉线（Euler line））（除正三角形） 垂心到三角形一顶点距离为此三角形外心到此顶点对边距离的2倍。 垂心分每条高线的两部分乘积相等 内心 ​三角形内切圆的圆心，叫做三角形的内心。 ​\n内心的性质： ​\n三角形的三条内角平分线交于一点。该点即为三角形的内心。 直角三角形的内心到边的距离等于两直角边的和与斜边的差的二分之一。 P为\\(\\bigtriangleup\\)ABC所在空间中任意一点，点O是ΔABC内心的充要条件是：\\(\\overrightarrow{PO}=(a×\\overrightarrow{PA} +b×\\overrightarrow{PB} +c×\\overrightarrow{PC} )/(a+b+c)\\). O为三角形的内心，A、B、C分别为三角形的三个顶点，延长AO交BC边于N，则有AO:ON=AB:BN=AC:CN=(AB+AC):BC (欧拉定理)⊿ABC中，R和r分别为外接圆为和内切圆的半径，O和I分别为其外心和内心，则\\(OI^2=R^2-2Rr\\)． （内角平分线分三边长度关系）△ABC中，0为内心，∠A 、∠B、 ∠C的内角平分线分别交BC、AC、AB于Q、P、R，则BQ/QC=c/b, CP/PA=a/c, BR/RA=a/b. 内心到三角形三边距离相等。 旁心 三角形的旁切圆（与三角形的一边和其他两边的延长线相切的圆）的圆心，叫做三角形的旁心。 ​\n旁心的性质： ​\n三角形一内角平分线和另外两顶点处的外角平分线交于一点，该点即为三角形的旁心。 每个三角形都有三个旁心。 旁心到三边的距离相等。 法向量叉乘求法 ​已知不共线的两个向量\\(\\boldsymbol{a}=(x_1,y_1,z_1)\\)，\\(\\boldsymbol{b}=(x_2,y_2,z_2)\\)\n​则它们所确定的平面的法向量为：\n​\n\\[\\bm{n}=(y_1 z_2-z_1 y_2,z_1 x_2-x_1 z_2,x_1 y_2-y_1 x_2) \\]\n方法 主元法 ​【例题】对任意\\(m\\in [-1,1]\\),函数\\(f(x)=x^2+(m-4)x+4-2m\\)的值恒大于零，求\\(x\\)的取值范围。 ​\n\\[f(x)=x^2+(m-4)x+4-2m=(x-2)m+x^2-4x+4 \\]\n​ 令 ​\n\\[g(m)=(x-2)m+x^2-4x+4 \\]\n​\n所以有 ​\n\\[\\begin{cases} ​ g(-1)=(x-2)(-1)+x^2-4x+4\u003e0 ​ \\\\ ​ g(1)=(x-2)\\cdot 1+x^2-4x+4\u003e0 ​ \\end{cases} \\]\n​解得\\(x\u003c1 \\)或 \\(x\u003e3\\)\n裂项 \\[\\frac{1}{n(n+1)}=\\frac{1}{n}-\\frac{1}{n+1} \\]\n​\n\\[\\frac{1}{n(n+1)(n+2)}=\\frac{1}{2}\\left[\\frac{1}{n(n+1)}-\\frac{1}{(n+1)(n+2)}\\right] \\]\n​\n\\[\\frac{1}{\\sqrt{n+1}+\\sqrt{n}}=\\sqrt{n+1}-\\sqrt{n} \\]\n​\n\\[a_n=(a_n-a_{n-1})+(a_{n-1}-a_{n-2})+\\dots+(a_2-a_1)+a_1 \\]\n​\n\\[a_n=\\frac{a_n}{a_{n-1}}\\bullet\\frac{a_{n-1}}{a_{n-2}}\\bullet\\dots\\bullet\\frac{a_2}{a_1}\\bullet a_1 \\]\n​\n\\[n\\cdot n!=(n+1)!-n! \\]\n​\n\\[C^{m}_{n}=C^{m}_{n+1}-C^{m-1}_{n} \\]\n​\n\\[n(n+1)=\\frac{1}{3}\\left[n(n+1)(n+2)-(n-1)n(n+1)\\right] \\]\n​\n\\[\\frac{1}{C^{1}_{n+1}C^{2}_{n}}=\\frac{2}{(n+1)n(n-1)}=\\frac{1}{n(n-1)}-\\frac{1}{(n+1)n} \\]\n​\n\\[\\frac{1}{2^n(2^n-1)}=\\frac{1}{2^n-1}-\\frac{1}{2^n} \\]\n​\n\\[\\frac{n}{(n+1)!}=\\frac{1}{n!}-\\frac{1}{(n+1)!} \\]\n放缩 ​\n\\[\\frac{1}{n^2}=\\frac{4}{4n^2}\u003c\\frac{4}{4n^2 -1}=2\\left(\\frac{1}{2n-1}-\\frac{1}{2n+1}\\right) \\]\n​\n\\[\\left(1+\\frac{1}{n}\\right)^n\u003c1+1+\\frac{1}{2\\times 1}+\\frac{1}{3\\times 2}+\\dots+\\frac{1}{n(n-1)}\u003c\\frac{5}{2} \\]\n​\n\\[\\frac{1}{\\sqrt{n+2}}\u003c\\frac{1}{\\sqrt{n+2}}-\\frac{1}{\\sqrt{n}} \\]\n​\n\\[2(\\sqrt{n+1}-\\sqrt{n})\u003c\\frac{1}{\\sqrt{n}}\u003c2(\\sqrt{n}-\\sqrt{n-1}) \\]\n​\n\\[\\frac{2^n}{(2^n-1)^2}\u003c\\frac{2^n}{(2^n-1)(2^n-2)}=\\frac{2^{n-1}}{(2^n-1)(2^{n-1}-1)}=\\frac{1}{2^{n-1}-1}-\\frac{1}{2^n-1} \\]\n​\n\\[\\frac{1}{\\sqrt{n^3}}=\\frac{1}{\\sqrt{n\\cdot n^2}}\u003c\\frac{1}{\\sqrt{n(n-1)(n+1)}}=\\left(\\frac{1}{\\sqrt{n(n-1)}}\\ -\\frac{1}{\\sqrt{n(n+1)}}\\right)\\frac{1}{\\sqrt{n+1}-\\sqrt{n-1}} \\]\n​\n\\[=\\left(\\frac{1}{\\sqrt{n-1}}-\\frac{1}{\\sqrt{n+1}}\\ ​ \\right)\\frac{\\sqrt{n+1}+\\sqrt{n-1}}{2\\sqrt{n}}\u003c\\frac{1}{\\sqrt{n-1}}-\\frac{1}{\\sqrt{n+1}} \\]\n​\n\\[\\frac{1}{\\sqrt{n(n+1)}}\u003c\\sqrt{n}-\\sqrt{n-1} \\]\n\\[e^x\\geq x+1 \\]\n​\n\\[e^x\\leq \\frac{1}{1-x} \\]\n​\n\\[ln(x+1)\\leq x \\]\n​\n\\[ln(x+1)\\geq \\frac{x}{x+1} \\]\n​\n\\[ln(x+1)\\geq x-\\frac{x^2}{2} \\]\n​\n\\[e^x\\geq 1+x+\\frac{x^2}{2} \\]\n​\n\\[tanx\\geq x+\\frac{x^2}{3} \\]\n​\n\\[sinx\\geq x-\\frac{x^3}{6} \\]\n​\n\\[sinx\\leq x \\]\n​\n\\[cosx\\geq 1-\\frac{x^2}{2} \\]\n","date":"2020-12-13T13:10:39Z","permalink":"https://kegalas.top/inferior/%E6%88%91%E7%9A%84%E9%AB%98%E4%B8%AD%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/","title":"我的高中资料整理"},{"content":"这是一个测试文档\n","date":"2020-12-13T12:30:53Z","permalink":"https://kegalas.top/inferior/%E6%B5%8B%E8%AF%95/","title":"测试"}]