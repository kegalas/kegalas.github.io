[{"content":"中英文词汇对照 因为这门课是英语试卷，有些专有名词还是得记录\n英文 中文 neurons 神经元 cortex 皮质（尤指大脑皮层） neocortex 新皮质 synapses 突触 synaptic 突触的 dopamine 多巴胺 amnesia 失忆 prefrontal cortex 额叶前皮质 lobe 脑叶 subcortical 皮质下的 hippocampus 海马区 amygdala 杏仁核 thalamus 丘脑 basal ganglia 基底核 cerebellum 小脑 occipital lobe 枕叶 temporal lobe 颞叶 frontal lobe 额叶 parietal lobe 顶叶 arousal 激励 modulatory functions 调节功能 Reinforcement Learning 强化学习 Motor Control 运动控制 Executive Function 执行功能 motor coordination 运动协调 semantic 语义的 spike dendrites 树突 axon 轴突 excitatory pyramidal neurons 兴奋性椎体神经元 inhibitory interneurons 抑制性中间神经元 white matter 白质 Likelihood function 似然函数 绪论 大脑 在大脑新皮质上，每个神经元都有约10k个来自其他神经元的输入，通过突触连接。而大脑中总体有20billion规模的神经元。\n虽然每两个神经元之间的连接相对而言影响较小，但是通过学习机制（learning mechanisms），这些神经元们可以实现非常复杂的信息处理功能。\n大脑的学习过程并不要求单个神经元非常复杂，它其实是信息整合的一个简单形式\n准确描述神经元的反应特性 在聚合神经网络上实现复杂的信息处理 认知计算的基本问题 视觉 注意力 多巴胺与奖励机制 记忆 含义（Meaning） 任务导向行为 我们应该关注大脑的什么？ David Marr认为，我们只需要独立地关注三个层次：\n计算层次。即大脑中在进行什么计算，什么信息在被处理？ 算法层次。大脑中的计算是如何进行的，信息处理的步骤是什么？ 实现层面。硬件如何实现这些算法？ 注意独立，我们就可以抛弃实现，只研究计算和算法层次。\n这部分的研究的简明历史如下\n1960s~1990s，主要的研究是认为人脑和传统计算机差不多，所以研究主要面向逻辑和符号命题 后来，基于概率的研究变得流行，贝叶斯概率的框架使用广泛，他强调大脑在信息处理过程中的分级性质。但是贝叶斯理论对大脑在神经层面的拟合不是很好，实际上大脑不像一个通用的计算设备 神经网络 脑区域之下皮质 1.jpg\r海马区（Hippocampus） 是旧皮质，在短期记忆中有很重要的作用。\n杏仁核（Amyglada） 对情绪显著刺激（emotionally salient stimuli）很重要，并且可以向大脑的其他部分发送警报（alert）。\n它在基于奖惩机制的强化运动（和认知）动作（reinforcing motor (and cognitive) actions）中也发挥重要的作用。\n丘脑（Thalamus） 为感官信息进入大脑新皮质提供了主要通道。也可能对注意力、激励和其他调节功能很重要。它在感知和注意力以及运动控制和强化学习中发挥作用。\n基底核（Basal Ganglia） 它是下皮质的一系列区域的集合，在运动控制、强化学习和执行功能（Executive Function）中发挥关键作用\n它帮助做出最后的“GO”指令，决定是否执行大脑皮层建议的特定动作，以及决定是否更新前额叶的认知计划。\n小脑（Cerebellum） 其神经元占了脑的一半，在运动协调中有重要作用。在大部分认知任务中也处于活跃状态。\n脑区域之新皮质 2.jpg\rBrodmann根据解剖结果把大脑分为四个区域。\n枕叶（Occipital lobe） 这里包含初级的视觉皮层，在枕叶的非常末端的位置。然后包含向外辐射的高级视觉中枢。\n颞叶（Temporal lobe） 包含初级的听觉皮层，以及联系到高级听觉和语言处理的区域。\n与此同时，视觉看到的物体转换到语言、语言转换到视觉的功能也是在这里进行的。这也是我们为什么能进行阅读的原因。\n颞叶也对语义知识（semantic knowledg）很重要，也就是你对事物的深层理解。\n这里包含了我们对于他人的面容、名字，事实、事件、物体、文字的认知。\n额叶 额叶的前部，或叫前额叶，是大脑执行功能的区域。这里是所有高级shots被called的区域。\n在这里，你的所有计划被整理出来，然后受基本动机和情绪的影响后，才真正决定你会如何行动。\n这里也是处理最抽象、最有挑战性的认知形式的关键所在。\n额叶皮层的内侧和腹侧区域对于情绪和动机非常重要。\n顶叶（Parietal lobe） 这里对encoding空间位置、数字、数学、抽象关系和其他有关“智慧”的东西很重要。\n它给视觉信息指导运动动作提供了主要的通道。\n神经元 大脑神经元如此复杂，其是为了一个非常简单的整体功能“检测（detection）”服务的。\n神经元接受数以千计的输入，但其中重要且有意义的只有一些特定模式（specific pattern）的输入，这些有价值的输入被称为“spike”，这也是神经元之间交流的基础。\n神经元接受信号后，将它们与阈值比较，然后加入到总体的输出中，再用这个总体的输出和其他神经元交流。\n把神经元看作是Detector 发送神经元和接收神经元用突触连接，大部分突触都连接在接收端的树突上。这些信号通过树突进入细胞体，进行信息的处理与综合。\n输出的阈值判断发生在输出端的最开始，也就是轴突。\n突触网络的效能或者说权重，指的是发送神经元发送的信号能以多大程度影响到接收神经元。\n从计算上说，权重决定了一个神经元接受什么。权重越大，神经元对这个输入就更敏感，反之亦然。\n学习的过程就是不断地调整神经元之间连接的权重，来达到想要的输出。\n大脑新皮质的神经网络 有85%的神经元是兴奋性锥体神经元（excitatory pyramidal neurons），它们的连接跨度很广，可以跨越不同的脑区，有时候甚至可以跨越整个大脑。学习行为主要就发生在这些兴奋性神经元中；有15%是抑制性中间神经元（inhibitory interneurons），它们的连接更加局部化。某种意义上，可以理解为兴奋性神经元的散热器。\n新皮质的层级结构 新皮质具有6种不同的层，每种脑区都有这种6层结构。但是拥有不同功能的脑区，其6层结构的厚度也各有不同，暗示了层级结构的功能。\n新皮质中负责数据输入的脑区（Input Area）接收感知的输入（例如视觉；通常会经过丘脑），这些脑区的Layer 4通常会更大。这是因为来自丘脑的轴突都连接到这里。这些输入层（input layer）有一种特别的兴奋性神经元，称为星状细胞（stellate cell）。这些细胞的树突非常浓密，并且似乎尤其善于收集这一层的局部轴突输入。\n新皮质中的隐藏脑区（Hidden Area），并不直接接受感觉输入，也不直接输出运动动作。它们是这个输入和输出的中间部分。我们可以理解为，这些区域从感官输入中创建越来越复杂和抽象的类别（catagories），然后再从这些高级类别中，协助选择出正确的运动动作。这些脑区的superficial layers 2/3会更厚，包含了许多锥体神经元，并且都放在很好的位置来实现这些抽象化功能。\n新皮质中的输出脑区（Output Area），拥有直接作用于肌肉控制区的突触，发出电信号后，可以直接影响物理运动。这些输出层有更厚的deep layer 5/6，会把轴突发送给许多下皮质区域。\n新皮质中的连接模式 信息传输包含正向传播和反向传播两个过程。\n正向传播时，信息从感官信息流向大脑中更高级、更深的部分，从而形成了越来越抽象和复杂的类别（catagories）\n反向传播时，信息从隐藏层和输出层出发，回到这些区域在正向传播时的前级区域，从而支持自上而下的行为认知控制、直接注意力，并且帮助解决感官输入中的歧义。\n所以说，区域之间的连接很大程度上是双向的，发送前向信息的区域通常也会收到下级区域的信息。这种双向连接对于使网络能够跨层聚合到连贯的整体活动状态很重要，对于错误驱动（error-driven）的学习也很重要。\n类别和分布式表示（Categorization and Distributed Representations） 3.jpg\r如上，当我们看到一个人时，在最低的一层中，这里我们获得的表示只有一些最基本的特征。在下一层，我们把这些特征连起来，变成更复杂的视觉特征。在下一层，我们把面部特征全部组合了起来，形成了对于面容的认知。最后，我们把这张脸和语义上的各种东西关联起来，例如名字，性别，性格。\n这个过程可以通过fMRI来显示，不同视觉刺激的脑部活动区域高度重合。\n神经元的数学公式 一个基本的积分和激发神经元（A Basic Integrate-and-Fire Neuron）\n\\[\\tau_m\\dfrac{du(t)}{dt}=u_{res}-u(t)+R_mi(t) \\]\n其中\\(\\tau_m\\)是神经元的膜时间常数，其由通道的平均电导决定。\\(u_{res}\\)是神经元的静息电位。\\(i(t)\\)是输入电流，其由突触前神经元放电产生，并且是众多这种放电的和。\\(R_m\\)是神经元对电流的电阻。\n具体来说，\\(i(t)\\)还受到突触连接强度的影响，\n\\[i(t) = \\sum_j\\sum_{t^f_j} w_jf(t-t^f_j) \\]\n其中\\(f(\\cdot)\\)代表激活函数，\\(t\\)表示突触\\(j\\)的突触前神经元的放电时间，该时间由膜电位\\(u\\)达到阈值\\(\\theta\\)的时间决定。\n\\[u(t^f) = \\theta \\]\n神经网络基础概念 神经元及其数学模型 4.jpg\r神经元大体上由四个部分组成：细胞体、轴突、树突、突触\n在神经元的信息处理过程中，树突相当于信息的接收器，细胞体相当于加和、处理信息的东西，轴突相当于信息的发射器，突触就是信息传递的连接点。\n神经元只有当输入信息达到阈值后才会兴奋。所有这些信息都是电化学信息。学习则是突触间电化学过程效率的变化的过程。\n于是我们就可以把神经元抽象成一个数学模型。这其实是一个有向图，每个节点代表神经元的细胞体。每个节点一般的多个输入对应树突，一个输出（有时有多个）对应轴突。神经元的兴奋阈值在这里是节点的激活函数，而突触间的效率在这里就是边的权重。例如下图\n5.jpg\r其中一个经典的模型是感知器：\n6.jpg\r他这里的中间的两个大节点可以理解为把一个节点拆成两个部分。感知器的作用是把一系列输入分为两个类型中的一类。\n大脑分区和基础的神经网络 大脑分区和功能之前探讨过了，这里不再赘述。\n神经网络面对的问题是，对于一组历史数据\\(\\{(x_1,y_1),(x_2,y_2),\\cdots,(x_l,y_l)\\}\\)，要找出一个函数\\(f(x)=\\hat y\\)，使得对未来的数据\\(x\\)，\\(\\hat y\\)是一个良好的预测。\n单输入的神经元如下：\n7.jpg\r拓展到多输入为\n8.jpg\r\\(f\\)一般称为激活函数，典型的有：\n阶跃函数、符号函数\n\\[f(x) = step(x) \\]\n\\[f(x)=sgn(x) \\]\n线性函数\n\\[f(x)=kx+b \\]\nsigmoid函数\n\\[f(x) = \\sigma(x) = \\dfrac{1}{1+e^{-x}} \\]\n特别的，其导数为\n\\[\\sigma'(x) = \\sigma(x)(1-\\sigma(x)) \\]\n其范围为\\((0,1)\\)，输出中心为\\(0.5\\)。指数运算会比较慢，并且\\(x\\)很大时，出现梯度消失问题。\n双曲正切\n\\[f(x) = \\tanh(x)=\\dfrac{2}{1+e^{-2x}}-1 \\]\n长得和Sigmoid很像，但是其范围为\\((-1,1)\\)，输出中心为\\(0\\)。问题和sigmoid相同。\nReLU\n\\[f(x)=\\max(0,x) \\]\n其没有指数运算，且不会梯度消失。但输入为负数时，完全失效。\nLeaky ReLU\n即在\\(x\\geq 0\\)时，\\(f(x)=x\\)，在\\(x\u003c0\\)时，\\(f(x)=ax\\)，其中\\(a\\)是一个相对于\\(1\\)很小的正常数。其对ReLU进行了微小的修正，使得在负数输入时有效。\n有了这些东西，我们就可以构造神经网络了，其中最简单的单层（Single Layer）（实际上是双层）神经网络如下。\n9.jpg\r这样的神经网络作用极其有限。只能用在线性分类任务上，大部分函数都不是线性的，或者不是线性可分的。\n于是就有了多层的神经网络，在上图的输入层和输出层之间添加一个或非常多个隐藏层。\n10.jpg\r这样，神经网络就能处理更多复杂的分类问题。但是，多层神经网络的问题是难以训练。\n正向传播和反向传播 反向传播算法的出现解决了训练的问题。\n假设神经元\\(j\\)的期望输出是\\(t_j\\)，实际输出是\\(o_j\\)，那么误差就是\n\\[E = \\dfrac{1}{2}\\sum_j(t_j-o_j)^2 \\]\n我们要优化的是每个连接的权重，我们就要找到每个权重对于误差的影响，偏导数\n\\[\\dfrac{\\partial E}{\\partial w_{ij}} \\]\n其中\\(w_{ij}\\)是神经元\\(i\\)到\\(j\\)的权重\n我们经常会用梯度下降法来优化权重，其迭代方向为\n\\[\\Delta w_{ij} = -\\eta\\dfrac{\\partial E}{\\partial w_{ij}} \\]\n假设上一层的输入是\\(b_i\\)，这一层的输入为\\(\\beta_j\\)，那么有\\(\\beta_j = \\sum_i w_{ij}b_i\\)\n注意到\\(w_{ij}\\)首先影响输入值\\(\\beta_j\\)，再影响到输出值\\(o_j\\)，最后才能影响到\\(E\\)。所以\n\\[\\dfrac{\\partial E}{\\partial w_{ij}} = \\dfrac{\\partial E}{\\partial o_j}\\cdot \\dfrac{\\partial o_j}{\\partial \\beta_j}\\cdot\\dfrac{\\partial \\beta_j}{\\partial w_{ij}} \\]\n其中，显然有\\(\\dfrac{\\partial \\beta_j}{\\partial w_{ij}}=b_i\\)\n设\\(g_j = -\\dfrac{\\partial E}{\\partial o_j}\\cdot \\dfrac{\\partial o_j}{\\partial \\beta_j}\\)，如果激活函数为\\(\\sigma(x)\\)，假设神经元阈值为\\(\\theta_j\\)，则\n\\[g_j = -(t_j-o_j)\\sigma'(\\beta_j-\\theta_j) = o_j(1-o_j)(t_j-o_j) \\]\n于是更新公式为\n\\[w_{ij}\\leftarrow w_{ij}+\\Delta w_{ij} = w_{ij} + ng_jb_i \\]\n学习 贝叶斯推理和学习 传统的频率学派认为，可以用大量试验中，事件出现的频率来估计概率。\n但是贝叶斯学派不同，贝叶斯学派同时利用样本信息和先验知识。\n频率学派通过大量独立实验将概率解释为统计均值（大数定律）。贝叶斯学派则将概率解释为信念度（degree of belief）（不需要大量的实验）。\n频率学派把模型参数看做固定量，把样本看做随机变量。而贝叶斯学派则都看作随机变量。\n贝叶斯推理在如下情况时，比频率方法更为有效：\n样本数量十分有限 避免过拟合 我们有理由相信某个模型更为合适，但是这个理由不包含在样本数据里 我们更想知道某个事实有多大的可能性，而不是可能性最大的事实是什么 贝叶斯学派经常用到以下概率公式\n条件概率\n\\[P(A|B) = \\dfrac{P(AB)}{P(B)} \\]\n值得注意的是\\(P(A|B)\\neq P(B|A)\\)通常成立\n事件的积的概率\n\\(P(AB) = P(A|B)P(B)\\)\n有\\(P(AB)=P(BA)\\)\n全概率公式\n\\[P(A) = P(AB_1)+P(AB_2)+\\cdots+P(AB_n) \\]\n其中\\(B_1+B_2+\\cdots+B_n\\)是必然事件，它们两两互斥。\n于是再由条件概率，得到全概率公式为：\n\\[P(A)=\\sum^n_{i=1}P(A|B_i)P(B_i) \\]\n贝叶斯公式\n\\[P(B_i|A) = \\dfrac{P(A|B_i)P(B_i)}{P(A)}=\\dfrac{P(A|B_i)P(B_i)}{\\sum^n_{i=1}P(A|B_i)P(B_i)} \\]\n将贝叶斯公式写在模型中，得到\n\\[P(model|data) = \\dfrac{P(data|model)P(model)}{P(data)} \\]\n也即\n\\[P(\\theta|X)=\\dfrac{P(X|\\theta)P(\\theta)}{P(X)} \\]\n其中\\(P(\\theta|X)\\)是模型的后验概率，\\(P(X|\\theta)\\)是数据的似然函数（Likelihood Function），\\(P(\\theta)\\)是模型的先验概率，\\(P(X)\\)为证据。\n先验概率 先验概率分布即\\(P(\\theta)\\)，他的目的是，在我们得到任何样本之前，先capture我们对于\\(\\theta\\)的先验知识。\n似然函数 记为\\(L(\\theta|X)=P(X|\\theta)\\)，固定\\(X\\)时，关于参数\\(\\theta\\)的似然函数，（在数值上）等于给定参数\\(\\theta\\)后变量\\(X\\)的概率。\n后验概率 贝叶斯推断的目标就是，使用样本数据\\(X\\)，来更新我们的先验概率\\(P(\\theta)\\)，就得到了后验概率\n最大后验估计（MAP） \\[h_{MAP} = \\arg\\max_{h\\in H} P(h|D) = \\arg\\max_{h\\in H}\\dfrac{P(D|h)P(h)}{P(D)} \\]\n由于分母是常数，所以有\n\\[h_{MAP} = \\arg\\max_{h\\in H}P(D|h)P(h) \\]\n最大似然估计（MLP） \\[h_{MLP} = \\arg\\max_{h\\in H}P(D/h) \\]\n在有些时候，所有\\(H\\)的估计的先验概率是一样的（或者可以假设为一样的），就可以用最大似然估计。\n贝叶斯过程 \\[P(X|\\theta)=\\dfrac{P(\\theta|X)P(X)}{P(\\theta)} \\]\n假设你对某些特定的参数\\(\\theta\\)感兴趣，那么通用的步骤如下\n通过先验知识确定\\(P(\\theta)\\) 通过试验等办法收集\\(X\\) 用贝叶斯公式得到后验概率 后验概率作为下一次迭代的先验概率，下次迭代时要获取新的\\(X\\) 贝叶斯分类器 假设总共有\\(N\\)类，其label分别为\\(y=\\{c_1,c_2,\\cdots,c_N\\}\\)。对于一个样本\\(x\\)，设其属于\\(c_j\\)类，其被错误归类为\\(c_i\\)时，损失大小为\\(\\lambda_{ij}\\)\n样本\\(x\\)被归类为\\(c_i\\)的条件风险（或期望损失）就为\n\\[R(c_i|x) = \\sum^N_{j=1}\\lambda_{ij}P(c_j|x) \\]\n我们的任务是最小化损失，即最小化\n\\[R(h) = E_x[R(h(x)|x)] \\]\n为了最小化总体风险，我们只需要在每个样本上都选择那个能使条件风险最小的类别。即\n\\[h^*(x)=\\arg\\min_{c\\in y}R(c|x) \\]\n此时\\(h^*(x)\\)就是贝叶斯最优分类器。与之对应的总体风险\\(R(h^*)\\)称为贝叶斯风险。\n具体来说，若目标是最小化分类错误率，我们是损失可以写作\n\\[\\lambda_{ij}\\left\\{\\begin{matrix} 0, \u0026 i=j\\\\ 1, \u0026 i\\neq j \\end{matrix}\\right. \\]\n此时条件概率可以算出来，\n\\[R(c|x) = 1-P(c|x) \\]\n于是最优分类器就为\n\\[h^*(x) = \\arg\\max_{c\\in y}P(c|x) \\]\n即对每个样本\\(x\\)，都选择能使其后验概率最大的类别\\(c\\)\n对于\\(P(c|x)\\)怎样得出，判别式模型对于给定的\\(x\\)，通过直接建模\\(P(c|x)\\)来预测\\(c\\)。而生成式模型，先对联合概率\\(P(x,c)\\)建模，再通过贝叶斯公式得到\\(P(c|x)\\)\n\\[P(c|x)=\\dfrac{P(x,c)}{P(x)} = \\dfrac{P(c)P(x|c)}{P(x)} \\]\n朴素贝叶斯分类器 之前的贝叶斯公式的问题是\\(P(x|c)\\)是一个联合概率，其并不方便直接从训练样本里面得出。朴素贝叶斯假设属性条件独立，那么有\n\\[P(c|x)=\\dfrac{P(c)P(x|c)}{P(x)}=\\dfrac{P(c)}{P(x)}\\prod^d_{i=1}P(x_i|c) \\]\n其中\\(d\\)为属性数目，\\(x_i\\)为\\(x\\)在第\\(i\\)个属性上的取值。\n于是朴素贝叶斯分类器就为\n\\[h_{nb} = \\arg\\max_{c\\in y} P(c)\\prod^d_{i=1}P(x_i|c) \\]\n若有充足的独立同分布样本，则可容易地估计出类先验概率\n\\[P(c) = \\dfrac{|D_c|}{|D|} \\]\n即类\\(c\\)的个数在所有样本个数中的占比。\n对于离散属性，条件概率可以估计为\n\\[P(x_i|c)=\\dfrac{|D_{c,x_i}|}{|D_c|} \\]\n\\(D_{c,x_i}\\)指的是，\\(D_c\\)中，在第\\(i\\)个属性上取值为\\(x_i\\)的样本组成的集合。\n对于连续属性，可以考虑概率密度函数，例如\\(P(x_i|c)\\sim N(\\mu_{c,i},\\sigma^2_{c,i})\\)，其中\\(\\mu_{c,i},\\sigma^2_{c,i}\\)是第\\(c\\)类样本在第\\(i\\)个属性上取值的均值和方差。\n贝叶斯网络 贝叶斯网络是一个有向无环图。其中节点代表随机变量\\(\\{X_1,X_2,\\cdots,X_n\\}\\)。如果两个节点之间有因果关系，那么用一条有向边连接，起点是原因，终点是结果。\n这个因果关系由参数\\(\\theta\\)描述，所以贝叶斯网络可以表述为一个图\\(G\\)和参数\\(\\theta\\)，即\\(B=\u003c G,\\theta \u003e\\)。假设属性\\(x_i\\)在图中的父节点为\\(\\pi_i\\)（注意可以有多个父节点），则\\(\\theta_{x_i|\\pi_i}=P_B(x_i|\\pi_i)\\)\n贝叶斯网假设每个属性与它的非后裔属性独立，于是有\n\\[P_B(x_1,x_2,\\cdots,x_d) = \\prod^d_{i=1}P_B(x_i|\\pi_i) = \\prod^d_{i=1}\\theta_{x_i|\\pi_i} \\]\n例如\n11.jpg\r有监督学习 即训练集除了属性，还有标签。\n其训练、验证、预测程序框架如下\n12.jpg\r一般来说，其有如下步骤\n决定数据集的类型 获取数据集 决定学习的模型，以及学习的算法 完成程序设计，在训练集上跑 评估正确率等指标，然后选择继续修正参数再次训练或者结束。 有监督学习的任务主要分为两个：回归、分类。回归就是对输入给出预测的输出，例如预测未来某一天的温度；分类则是对样本进行划分，使其属于某一个类别。\n回归任务 其一般如下。设样本为\\(\\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\cdots, (x^{(m)}, y^{(m)})\\}\\)。程序对于\\(x\\)给出的预测是\\(h_\\theta(x)=\\hat y\\)，其中\\(h_\\theta\\)就是我们的预测函数，或者说模型，而\\(\\theta\\)是模型参数。我们的目标是求出\n\\[\\theta^* = \\arg\\min_{\\theta}\\sum^m_{i=1}(\\hat y^{(i)}-y^{(i)})^2=\\arg\\min_\\theta J(\\theta) \\]\n至于如何求出，一般会使用数值最优化方法，例如梯度下降。搜索方向即是\\(-\\eta\\nabla J(\\theta)\\)\n","date":"2023-11-28T10:21:26+08:00","image":"https://kegalas.top/cover.jpg","permalink":"https://kegalas.top/p/%E8%AE%A4%E7%9F%A5%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"认知计算学习笔记"},{"content":"绪论 1.jpg\r2.jpg\r数制与码制 在计组、数电中已经学过这部分内容，这里着重讨论硬件的操作。\n有符号数加减运算的溢出 设次高位向最高位的进位标志为\\(C_p\\)，最高位和次高位进位相加的进位标志为\\(C_s\\)，则当且仅当\\(C_p\\oplus C_s=1\\)时，计算溢出。\n8086CPU中PSW的OF标志位表示有符号数运算是否溢出。\nCPU的结构和功能 外部结构 3.jpg\r微处理器的外部结构表现为数量有限的输入输出引脚（共40个），这些引脚构成了微处理器级总线\n这些引脚用来与存储器、IO设备交换信息，以及输入输出必要的信号。\n通过分时复用技术，实现了引脚的复用。对于存储器，总共地址线为20条，寻址范围1M。对于IO设备则只有16条地址线。采用了独立编址的方式。控制线和数据线分别只有16条。也就是最大表示范围为\\(0\\sim 2^{16}-1\\)\n内部结构 4.jpg\r功能结构 5.jpg\r寄存器组织 通用寄存器 8086一共有8个通用寄存器，虽然通用并不意味着可以随便交换使用，还是有些操作只能用某个寄存器实现。\n数据寄存器\n一共有4个，分别叫AX，BX，CX，DX。每个都是16位大小的，但也可以拆成两个8位的使用。例如AH、AL分别表示AX的高8位、低8位。BH、BL表示BX的。\nA的意思是Accumulator，即累加器。A在以前是8位寄存器，X代表miX，AX就为16位，而之后的EAX的E是Extend，为32位。再之后的RAX是64位。这些寄存器一般用来做运算操作。\nB的意思是Base Register，基址寄存器，用于表示数据段的段内地址。\nC的意思是Count Register，计数器，用于表示循环计数。\nD的意思是Data Register，数据寄存器，用于表示IO端口的地址。\n地址指针与变址寄存器\n总共有4个，SP、BP、SI、DI。都是16位。前两个是地址指针\nSP为Stack Pointer，堆栈指针，用于保存堆栈段的段内偏移地址。\nBP为Base Pointer，基址指针，用于表示段内偏移地址，默认段地址由SS提供。\nSI为Source Index，源变址寄存器。\nDI为Destination Index，目的变址寄存器。\n这两个寄存器用于字符串操作中，源操作数和目的操作数的段内偏移地址。\n段寄存器 总共有4个，CS、DS、ES、SS。都是16位。\nCS为Code Segment，代码段寄存器。用于保存当前执行程序的段地址，不能做被用户操作。\nDS为Data Segment，数据段寄存器。用于保存数据段的段地址。\nES为Extra Segment，附加数据段寄存器。用于保存附加数据段的段地址。\nSS为Stack Segment，堆栈段寄存器。用于保存堆栈段的段地址。\n控制寄存器 总共有2个，IP、PSW。都是16位。\nIP为Instruction Pointer，指令指针寄存器。始终指向下一条要执行的指令的偏移地址（段地址由CS提供）。相当于一般讨论中的程序计数器PC。IP的值不能被用户更改。\nPSW为微处理器状态字。虽然有16位但是有用的只有其中9位。\n6.jpg\r其中CF、PF、AF、ZF、SF、OF这6个是状态标志，反应ALU运算后的结果状态。\nTF、IF、DF这3个是控制标志，用来控制CPU的运行状态。\nCF表示最高位有无进/借位标志，有进位为1。\nPF表示第8位含有1的个数，偶数个为1，奇数个为0。\nAF表示D3位有无进/借位，有则为1。D3为即为8位二进制的第3位（从0位开始算）\nZF表示运算结果是否为0，是则为1。\nSF为符号位，和数字的符号位一致。即等于D7或者等于D15。\nOF之前介绍过，表示是否溢出，是则为1。\nDF为方向标志，在进行字符串操作时，CPU每执行一条串操作指令，对源或(与)目的操作数的地址会自动进行一次调整。当DF为0时，SI/DI自动递增；DF为1时，SI/DI自动递减。在汇编中CLD指令把DF置0，STD指令把DF置1。\nIF为外部中断允许标志，IF为1时，CPU能响应外部可屏蔽中断，即开中断状态。IF为0时为关中断状态。显然可以推知，对内部中断和外部不可屏蔽中断不起作用。STI指令置1，CLI指令置0。\nTF为陷阱标志。当TF=1时，CPU每执行完一条指令便自动产生一个内部中断(类型为1)，转去执行一个中断服务程序，用户可以借助中断服务程序来检查每条指令执行的情况，称为单步工作方式，常用于程序的调试(Debug)。没有专门的设置指令。\n存储器和IO组织 8086有20条地址线。\n对于存储器用了全部的20条，寻址范围为1M，最小单位为字节，所以总共的空间为1MB。地址范围为00000H~FFFFFH。\n对于IO端口则只使用低16条，寻址范围为64K。\n由于寄存器全都是16位的，要表述20位的地址，就要用到两个寄存器。这两个寄存器加起来可以有32位，所以所有地址都可以有多重表示方式。之后会介绍。\n数据在存储器中的存储 字节型数据\n例如指令DB 5, -12, 'a'，存放三个字节型数据，它们顺序存放在内存中。\n7.jpg\r字型数据\n字是16位，即两个字节。其低8位放在低地址，高8位放在高地址。例如1234H放在内存中，指令为DW 1234H，内存中就是34，12。这也叫做小端序。\n整个字型数据的地址是低字节的地址。8086字的地址可以从任何地方开始。当地址为偶地址时，称为对准的；地址为奇地址时，称为未对准的。\n8.jpg\r8086的数据总线为16位，所以存取一个字节只需要1个周期。而对于字，对准的需要1个周期，未对准的需要2个周期。\n存储器的分段 由于寄存器全都是16位的，要表述20位的地址，就要用到两个寄存器。8086采用分段的方式，把地址空间分为若干个逻辑段。即20位地址表示为5位16进制数，例如12345H，1234H表示段地址，5H表示段内偏移。即高16位表示段地址，且每个段的起始地址可以被16整除（即XXXX0H可以被16整除）。\n更具体的说，由于用两个寄存器表示，就可以写作1234H:0005H，前面的为段地址的寄存器，后面位段内偏移的寄存器。\n显然的，这样操作，1MB的空间最多可以分为64K个段。每个段也最多可以有64KB的大小。但是我们最多也就1MB内存的大小，而不是64KB*64K这么大的空间。我们几乎可以立即得到，段是可以重叠的，地址可以有多重表示方式。\n事实上、\\(物理地址=段地址 \\times 10H+偏移地址\\)。这样，00100H就可以表示为0000H:0100H和0010H:0000H，等等。\n在硬件实现上，把段地址的寄存器（如CS、DS、ES、SS）的内容左移4位，加上偏移寄存器（如BX、BP、SP、SI、DI）中的内容，形成20位地址。\n程序的分段存储 每个程序使用的内存可以分为三个段，即代码段、数据段、堆栈段。\n9.jpg\r其中代码段的物理地址由CS:IP表示，数据段由DS/ES:BX/SI/DI表示，堆栈段由SS:SP/BP表示。\n8086汇编 语句类型 指令\n每条指令都对应一条CPU能执行的语句，即对应一条机器语言。\n伪指令\n不对应机器语言的代码，CPU无法进行操作。只是给汇编器看的，告诉汇编器如何汇编。\n宏指令\n用户自定义的一条能完成某一特定功能的新指令，由指令和伪指令组成，在程序汇编时展开，用指令和伪指令替代宏指令\n语句格式 [名称:] 助记符 [操作数] [;注释]\n其中名称有点像C/C++里面的label，给goto用的那个label。为可选项。\n助记符就是指令、伪指令、宏指令的名字。必选项。\n操作数，具体要看助记符要使用什么操作。有时候没有操作数，算是可选项。\n注释用;开头，可选项。\n常数和表达式 常数分为数值常数和字符（串）常数。\n二进制数以B结尾，八进制数以O结尾，十六进制数以0开头，H结尾。\n字符串用单引号括住。\n表达式用的符号有算术、逻辑、关系等\n+,-,*,/,MOD是算术操作\nAND, OR, XOR, NOT是逻辑操作（其实是按位运算，不是逻辑与或）\nEQ, NE, LT, GT, LE, GE是关系操作\n这些运算符只能给常量使用，不能给寄存器使用。变量名使用是把变量名当作其偏移地址常数使用。\n另外，关系判断中，如果为真，则所有位全取1，为假则全取0.\n名称（标号） 前面提到，名称和goto里使用的label差不多。以冒号结尾，其后半部分的语句可以在下一行也可以在同一行。\n标号还有一些属性，例如可以代表标号所在段的段地址，在段内的偏移，以及其类型。其分为两类，如果标号只在本段内使用，则其为NEAR型，如果在段间使用，则为FAR型。\n变量 变量是用伪指令来表达的。分为五种类型\nDB，1字节变量 DW，字，即2字节变量 DD，双字，即4字节变量 DQ，长字，即8字节变量 DT，10字节变量。 变量可以有名称，但是名称不需要冒号。一个伪指令可以包含多个数值，用逗号分隔。例如\nVAR1 DB 12H, 0A5H, 18+20, 50/3, 0, -1 它是单字节的，在内存中存储如下（注意这里内存+1不像C语言的指针+1是偏移一整个类型，这里就是偏移一个字节）\n地址 内容 VAR1 12H VAR1+1 A5H VAR1+2 26H VAR1+3 10H VAR1+4 0 VAR1+5 FFH 由于x86是小端序，在2字节存储时\nVAR2 DW 12H,$+1 其在内存中为\n地址 内容 VAR2 12H VAR2+1 00H VAR2+2 09H VAR2+3 00H 此处$表示当前汇编语句的偏移地址（假设前面已经定义VAR1），可以看到，逗号分隔的前面的数值算做了2个字节的偏移。再加上前面的6个字节，$表示8，那么8+1=9；另外$的长度为字形\n另外，可以用?表示保留空间，但不预先赋值\nVAR3 DB ?, ? 利用DUP，可以表示重复的声明\nVAR4 DB 3 DUP(?) ; 这一句保留了3个未赋值的DB VAR5 DB 4 DUP(0FFH, ?) ; 而且内部参数是可以有多个的，就保存了四个0FFH, ?的数据 VAR6 DB 3 DUP(55H,2 DUP(77H)) ; 而且还可以嵌套 表达字符串时，只能用DB和DW\nVAR7 DB \u0026#39;ABCD\u0026#39; ; 其等价于DB \u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;或者DB \u0026#39;ABC\u0026#39;, \u0026#39;D\u0026#39;等 VAR8 DW \u0026#39;AB\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39; ; DW型保存字符时，要么两个字符，要么一个字符，不能多 ; 其仍然遵循小端序，即B在低位，A在高位。或者C在低位，00H填充高位 变量也有类型：段地址、段内偏移、类型、长度、大小。长度为第一个DUP前的系数（没有DUP则为1），大小不是占用空间大小，是类型乘以长度。类型即为变量字节数（1/2/4/8/10）。可以用伪代码获取这些属性，获取的都是立即数常数。\nMOV AX, SEG VAR1 ; 获取段地址 MOV AX, OFFSET VAR1 ; 获取段内偏移 MOV AL, TYPE VAR1 ; 获取类型 MOV AX, LENGTH VAR1 ; 获取长度 MOV AL, SIZE VAR1 ; 获取大小 PTR操作符 TODO\n数据寻址操作 即MOV命令。其格式如下\nMOV DST, SRC 把SRC里的东西放到DST里。根据DST和SRC的不同可以有很多种MOV操作。\n立即数寻址 MOV AX, 1200H 即源操作数为立即数。\n寄存器寻址 MOV AX, BX 两个寄存器的大小要匹配。另外CS不能作为目的操作数。\n直接寻址 MOV AX, [1200H] 其中[]括起来的东西代表偏移地址，其加上段寄存器（默认为DS）的段地址得到物理地址，再把物理地址里的东西给AX。\n可以指定段寄存器\nMOV AX, ES:[1200H] SRC可以是变量\nMOV AX, VAR1+5 其中是把VAR1+5对应的地址开始的一个字给AX\n还可以把立即数给变量\nMOV VAR1, 2500 寄存器间接寻址 MOV AX,[SI] 把SI中的数据当作段内偏移，加上段地址（默认为DS）得到物理地址，再把物理地址里的东西赋值给AX。\n但是，[]中的寄存器只能是BX、SI、DI这三个\n也可以反过来进行\nMOV ES:[SI], AL 即把寄存器里的东西放到内存里。\n注意：\n不能DST和SRC都表示内存单元 不能直接把立即数当作SRC，内存当作DST，因为没有指定类型，应当： MOV WORD PTR [DI], 12H ; 而不是 MOV [DI], 12H 寄存器相对寻址 和上面的寄存器间接寻址相比，其就是增加了常数偏移。形式为\n\\[[REG\\pm 常数],常数[REG],变量名[REG],变量名[REG\\pm 常数] \\]\n其中REG可以为BX、BP、SI、DI，相比间接寻址多了BP。\n当偏移为常数时，段地址为段寄存器，BX、SI、DI默认为DS段，BP默认为SS段。\n偏移有变量名时，段地址取变量的段地址。\n例如\nMOV BX, [SI+5] MOV BX, 5[SI] ; 和上一行等同 MOV CX, VAR1[BX] ; 变量名意味着段地址以变量为准 MOV AL, VAR2[DI-15] 基址变址寻址 MOV DX, [BX][SI] 如上例，操作数在存储器中，其地址为一个基址寄存器和一个变址寄存器之和，即((BX)+(SI))为其内容。\n其中基址寄存器可以是BX和BP，变址寄存器可以为SI和DI。当BX时，默认为DS段，BP时，默认为SS段。\n基址变址且相对寻址 把上面的基址变址缝上相对寻址，即加上偏移\n\\[[BX/BP\\pm 常数][SI/DI\\pm 常数],常数[BX/BP][SI/DI] \\]\n\\[变量名[BX/BP][SI/DI],变量名[BX/BP\\pm 常数][SI/DI\\pm 常数] \\]\n有变量名时段由变量决定。\n隐含寻址 即操作码本身隐含（提前规定）了操作数地址。例如乘除、字符串操作指令\nMUL BL ; AX \u0026lt;- AL x BL MOVSB ; (ES:DI) \u0026lt;- (DS:SI), SI+-1, DI+-1 一般化的要求 CS不能做DST 立即数不能直接给段寄存器 存储单元不能直接到存储单元 段寄存器不能直接到段寄存器 立即数不能作为DST 源和目的至少有一个类型明确 源和目的都有类型时，类型必须一致 转移地址寻址操作 CPU要执行的指令的地址由CS:IP决定，即IP指向下一条要执行（取）的指令。CPU每执行一 条指令，IP自动增加，使之指向下一条指令。IP增加的值为当前指令的指令长度。\n可以通过改变CS：IP的内容实现程序的跳转 。\n如果程序转移后只有IP发生改变，则称为段内转移（近程、NEAR转移）。如果CS也改变，则称为段间转移（远程、FAR转移）。\n两种转移都有间接和直接寻址。\n段内直接寻址 JMP LABEL 直接用标号给出地址（是16位大小的偏移地址），且标号应与该指令在同一个段。也可以直接给出偏移地址，例如用常数。但是不能用变量，变量算地址保存在存储器中。\n实际汇编后，其会把IP修改为，JMP指令的下一条指令的IP+16位偏移的形式。16位偏移是汇编器直接在编译期转化为常数的。\n但是，段内偏移和JMP指令的偏移是不同的，段内偏移就是内存物理地址中的那个段内偏移，我们明文写给JMP的地址是这个，但是JMP生成的机器码，其偏移是下一行指令的地址加上的一个偏移，可正可负。\n段内间接寻址 JMP BX JMP VAR1 ; VAR1为字型变量 JMP VAR1[SI] 诸如此类，16位偏移地址保存在寄存器或存储单元里。之前介绍的各种存储器寻址方式都可以在这里使用。\n同前，我们写的16位偏移是段内偏移，但是JMP对应的机器码是相对于下一行指令地址的偏移。\n段间直接寻址 JMP LABEL 其中LABEL和当前指令不在一个段。LABEL给出了16位段地址和16位段内偏移。\n段间间接寻址 JMP VAR3 ; VAR3是双字变量，第一个字为段内偏移，第二个字为段地址 JMP VAR3[SI] ; 有效地址为(SI)+VAR3 也可以采用之前的存储器寻址方式。\n转移指令 无条件转移：JMP、CALL、RET、IRET\n条件转移：JZ、JC、JCXZ、LOOP等\n程序结构 段定义伪指令 \u0026lt;段名\u0026gt; SEGMENT (定位类型)(组合类型)(类别) ... 段体 ... \u0026lt;段名\u0026gt; ENDS 段名和普通的名称一致，具有段地址、偏移地址、定位类型、组合类型、类别五个属性\n定位类型\n定位类型 段起始地址（2进制） 段起始地址（16进制） 特性 含义 PAGE(页) xxxx xxxx xxxx 0000 0000 xxx00H 可以被256整除 本段从页的边界开始 PARA(节，默认) xxxx xxxx xxxx xxxx 0000 xxxx0H 可以被16整除 本段从段的边界开始 PAGE(页) xxxx xxxx xxxx xxxx xxx0 / 可以被2整除 本段从偶地址开始 PAGE(页) xxxx xxxx xxxx xxxx xxxx xxxxxH 起始为任意地址 起始为任意地址 组合类型\nNONE：表示本段与其他段不发生任何关系，该段有自己的段基址，是默认的组合关系。\nPUBLIC：在满足定位类型的前提下与其他模块的同名段连接在一起，形成一个新的逻辑段，共用一个段基址。\nCOMMON：表示产生一个覆盖段。连接时，把本段与其他同名段置成相同的起始地址，重叠在一起，共享相同的存储区，其段长度由最长的段确定。\nSTACK：在每个汇编程序中，只能且必须有一个堆栈段，连接时，将本段与其同名段连接成一个连续的STACK段，汇编程序自动初始化SS和SP寄存器，使SS的内容为该连续段的段基址，SP指向堆栈底部加1的存储单元。\nMEMORY： 表示本段在存储器中应定位在所有其他段的最高地址。\nAT\u0026lt;表达式\u0026gt;：表示本段从表达式指定的地址处开始装入，这样，在程序中用户就可以直接定义段地址，这种方式不适用于代码段。\n类别\n如代码段（\u0026lsquo;CODE\u0026rsquo;）、数据段（\u0026lsquo;DATA\u0026rsquo;）、堆栈段（\u0026lsquo;STACK\u0026rsquo;），注意包括单引号，其本质是字符串。也允许自定义类别，方便连接同类别的段。\nASSUME伪指令 ASSUME 段寄存器:段名[, 段寄存器2:段名2, ...] 通知寄存器把哪个段寄存器当作哪个段的寄存器，例如\nCODE SEGMENT ASSUME CS:CODE, DS:DATA, SS:STACK 注意：当程序运行时，DOS的程序加载器(Loader)负责把CS、IP、SS、SP初始化成正确的段地址和段内偏移地址（如果设定了合适的组合类型），因此用户在程序中就不必设置。但是，在用户程序中必须用两条指令对DS和ES进行初始化，以装入用户的数据段段地址。\nCODE SEGMENT ASSUME CS:CODE, DS:DATA, SS:STACK MOV AX, DATA ; DATA为段名，为立即数寻址 MOV DS, AX END伪指令 END 表达式 该伪指令表示整个源程序的结束，其表达式的值为该程序运行时的启动地址，它通常是第一条可执行语句的标号（例如START:）。\nPAGE伪指令 PAGE 参数1, 参数2 该伪指令可以为汇编过程产生的列表文件指定每页的行数“参数 1”和每行的字符数“参数 2”。\nTITLE伪指令 TITLE 正文 该伪指令可以为汇编过程产生的列表文件指定一个标题“正文”，它不能超过 60 个字符。在列表文件的每一页的第一行将打印出这个标题。\nLABEL伪指令 名称 LABEL 类型 该伪指令用来定义变量或标号的类型，它具有段地址与偏移地址的属性，但它并不占用内存单元。\n如果名称为变量名，其类型主要有三种：BYTE、WORD、DWORD\n如果名词为标号，其类型主要有两种：NEAR、FAR\nEQU伪指令和“=”伪指令 名称 EQU 表达式 很类似C语言的#define，即给表达式一个名称，可以在程序里随地替换。\n但是EQU定义的名称不能重复。而\n名称=数值 可以重复定义，值为最近一次定义的值\nORG伪指令 ORG 表达式 该伪指令用于为后续指令指定段内偏移地址，可以方便地将程序存入适当的地址，这一点对中断设计非常有用。\n程序的加载和运行 当用户编写的程序在必须加载到内存中从才能运行，这是由操作系统的程序加载器（Loader）实现的，其具体工作包括：\n决定使用存储器哪一部分的内存 初始化SS:SP和CS:IP(程序的第1条指令的位置) 当加载到内存的程序在计算机中运行时，计算机的控制由操作系统（OS）交给用户程序，当用户程序运行结束后，应再将控制权交回操作系统，可由系统中断程序中INT 21H的4C号程序实现。\n用户程序的代码前一定有100个字节的程序段前缀(Program Segment Prefix, 简称PSP)，PSP给 出了用户的可执行文件(.EXE)的若干控制信息。\n数据传送指令 数据传送指令被用来在寄存器、存储单元之间进行数据的传输。包含有：MOV、LEA、LDS、LES、LAHF、SAHF、XCHG、XLAT、PUSH、POP、PUSHF和POPF\n共同点有\n除了SAHF、 POPF，其他操作不影响PSW 有两个操作数时，第一个为目的，第二个为源 目的操作数的寻址不能是立即数和段寄存器CS MOV MOV DST, SRC 将SRC中的一个字节或一个字传送到DST。可以在立即数、存储单元、寄存器、段寄存器之间传送数据。\n注意事项如下\n操作数至少有一个类型是确定的 两个类型都确定时，类型要一致 不允许MOV [xxx], [xxx]，即内存-\u0026gt;内存 不运行段寄存器-\u0026gt;段寄存器 不允许立即数-\u0026gt;段寄存器 IP不能作SRC或DST CS不能作DST 立即数不能作DST 对于类型\n立即数是无类型的 不含变量名的直接寻址、寄存器间接寻址、寄存器相对寻址、基址变址寻址、基址变址且相对寻址的操作数也是无类型的(存储器寻址) 利用PTR操作符可指定或暂时改变存储单元的类型 立即数分为\n常数和常数表达式 所有由属性操作符得到的标号或变量的属性 前面提到一些不能进行的操作，指的是不能直接进行，但是我们可以间接进行\n内存-\u0026gt;内存不行，但是内存-\u0026gt;通用寄存器-\u0026gt;内存可以 立即数-\u0026gt;段寄存器不行，但是立即数-\u0026gt;通用寄存器-\u0026gt;段寄存器可以 段寄存器-\u0026gt;段寄存器不行，但是段寄存器-\u0026gt;通用寄存器-\u0026gt;段寄存器可以 CS和IP不能用MOV改变，但是可以通过跳转指令改变 LEA LEA REG16, MEM 取有效地址指令，即把MEM的16位段内偏移赋值给REG16。SRC是直接寻址，DST是寄存器寻址，用通用寄存器，一般用BX、BP、DI、SI\n其相当于\nMOV REG16, OFFSET MEM LDS/LES LDS REG16, MEM LES REG16, MEM 取地址指针指令。\nLDS把MEM的物理地址的高16位送入DS，低16位送入指定的REG16.\nLES把MEM的物理地址的高16位送入ES，低16位送入指定的REG16.\nLAHF/SAHF LAHF SAHF 标志传送指令。其没有操作数，也就是隐含寻址。LAHF把PSW的低8位赋值给AH，SAHF把AH赋值给PSW的低8位。\nXCHG XCHG DST, SRC 数据交换指令。该命令完成寄存器之间，或者寄存器与内存之间的内容交换（立即数不行）。即把DST和SRC的内容交换。\n但是寄存器不能是段寄存器，数据可以是字也可以是字节（但是类型要一致）。\nXLAT XLAT 字节交换指令。隐含寻址。将有效地址为(BX)+(AL)的内存的内容送进AL，常用来查表。\nPUSH/PUSHF PUSH SRC PUSHF 压栈指令。PUSH指令把SRC压入堆栈，即SP\u0026lt;-SP-2, (SP)\u0026lt;-(SRC)。PUSHF则把PSW压入栈。这里SRC必须是字型的，可以是通用、段寄存器，也可以是某种寻址的内存，但是不能是立即数。\nPOP/POPF POP DST POPF 弹栈指令。POP指令把栈顶弹出，赋给DST，即(DST)\u0026lt;-(SP), SP\u0026lt;-SP+2。POPF则是栈顶弹出给PSW。\n这里的DST和之前的SRC要求相同。但是DS不能作DST。\n堆栈注意事项 PUSH和POP成对使用 8086不会检测栈溢出，所以交给程序员自己检查 分配堆栈空间时要留有余量（20%以上） 算术运算指令 算术运算指令可以完成两个操作数的各种算术运算，例如加减乘除取余，以及其BCD数运算的调整运算。包括有：ADD、ADC、SUB、SBB、NEG、CMP、INC、DEC、MUL、IMUL、DIV、IDIV、CBW、CWD、AAA、DAA、AAS、DAS、AAM、AAD。\n它们可以分为6类\n加减法指令 比较指令 增量减量指令 乘除法指令 符号扩展指令 BCD数运算调整指令 一般情况下：\n涉及ALU的运算，不能使用段REG 设计ALU的运算，运算结果一般会影响PSW的6个状态位：OF、SF、ZF、AF、PF、CF 一般支持字节或字型数据 ADD/ADC ADD DST, SRC ADC DST, SRC 加法指令。ADD是把DST和SRC的值加起来再给DST；而ADC是把DST和SRC加起来，再加上CF（即PSW进位标志的值），再给DST。\nSRC可以取立即数、通用寄存器、内存（存储单元）。DST可以取通用寄存器和内存。但是SRC和DST不能同时为内存，并且两者类型要一致。\n只能处理字节或字，其他位宽的数据要分开来加。\n比如双字，可以先利用ADD完成低字的加法，再利用ADC完成高字和进位的加法。\nSUB/SBB SUB DST, SRC SBB DST, SRC 减法指令。SUB是(DST)\u0026lt;-(DST)-(SRC)，SBB是(DST)\u0026lt;-(DST)-(SRC)-(CF)\n指令的要求和ADD/ADC一样。\nNEG NEG DST 取负指令。即把DST的相反数传递给DST。\nDST可以取通用寄存器和内存，也会影响6个PSW位。其实质上是一个特殊的减法运算，即0-(DST)\nCMP CMP DST, SRC 比较指令。其完成DST-SRC，然后根据结果设置PSW的标志位，但结果不保存到DST。\n如果DST和SRC都是无符号数，如果DST\u0026gt;=SRC，则CF=0。若DST\u0026lt; SRC，则CF=1。\n如果都是有符号数，则两个数的大小由OF和SF共同决定。\n不溢出时，OF=0，差是正确的，则SF=0代表DST\u0026gt;=SRC，SF=1代表DST\u0026lt; SRC\n溢出时，OF=1，差是错误的，则SF=0代表DST\u0026lt;SRC，SF=1代表DST\u0026gt;= SRC\n简单记为，\\(OF\\oplus SF=0\\Rightarrow DST\\geq SRC\\)，\\(OF\\oplus SF=1\\Rightarrow DST\u003c SRC\\)\nINC/DEC INC DST DEC DST 增量减量指令。INC相当于DST++，DEC相当于DST\u0026ndash;。\nDST可以取通用寄存器和内存。INC和DEC只会影响AF、OF、SF、ZF、PF，但是不会影响CF。\nMUL/IMUL MUL SRC IMUL SRC 乘法指令。其中MUL对应无符号，IMUL对应有符号。目的操作数隐含在AX或AL中，SRC可以是通用寄存器和内存（不能是立即数），但是必须有确定的类型，而且只能是字节或字。\nSRC为字节时，AL和SRC相乘，其结果存在AX中。SRC为字时，AX和SRC相乘，其结果的高16位保存在DX，低16位保存在AX。\n这两个指令只对CF和OF有影响。如果字运算结果的DX为0，那么CF=0，OF=0，表示结果也为一个字。如果字节运算结果的AH为0，那么CF=0，OF=0，表示结果也为一个字节。否则CF=1且OF=1。\nDIV/IDIV DIV SRC IDIV SRC 除法指令。其中DIV对应无符号，IDIV对应有符号。总体上和乘法指令类似。\n当SRC为字节时，将AX中的16位二进制数除以8为二进制数（SRC），其结果的商保存在AL中，预属保存在AH中。\n当SRC为字时，DX与AX联合称为32位被除数，SRC作为16为除数。其结果的商存在AX中，余数存在DX中。\n商的正负性不用多说，讨论余数的正负性：余数的正负永远和被除数的正负相同（和数学上定义不一样）。\n这两个指令不影响PSW的标志位，但是不允许出现除数为0或者除法溢出。如果出现这两种情况，则没有意义，并且会引发中断。\nCBW/CWD CBW CWD 符号扩展指令。CBW将AL的符号扩展到AH中，形成一个字AX。CWD将AX的符号扩展到DX中，形成双字。\n即当D7=0时，扩展为AH=00H，D7=1时，扩展为AH=FFH。扩展双字同理。\nBCD数运算调整指令 在8086这里BCD码可以分为两类。\n分离BCD码，8位的寄存器中只包含以为BCD码，即D0~D3 组合BCD码，8位的寄存器中包含了两位BCD码。 BCD调整指令一共有6条\n助记符 功能 AAA 加法分离BCD调整 DAA 加法组合BCD调整 AAS 减法分离BCD调整 DAS 减法组合BCD调整 AAM 乘法分离BCD调整 AAD 除法分离BCD调整 加法调整指令\n众所周知，BCD码用4位空间表示0~9十个数字，就有6个信息位没用上。所以每一个BCD数字相加时，可能会溢出到这六个没用上的信息位上，此时要整体+6、进位来修正。具体可见计组和数电。\nAAA为分离BCD码加法运算后的调整指令，它会自己判断相加的结果（即AL）需不需要进行加6修正，如果需要则修正，否则不动。根据运算结果及修正结果的AF有无进位，进行下列操作：\nAF有进位，则AH=AH+1，CF=1，AF=1 AF无进位，则CF=0，AF=0 并清除AL中的高4位。\nDAA为组合BCD码的加法调整，表示对相加结果AL的低4位和高4位分别进行加6修正（如有必要）。DAA对AF、CF、SF、ZF、PF都有影响，其效果等同于ADD指令。\n例如\nMOV AH, 0 MOV AL, \u0026#39;4\u0026#39; MOV BL, \u0026#39;8\u0026#39; ; 这两个是因为，ASCII的数字，高4位都是0011，而低4位从0开始。而分离BCD码高4位无效，所以不需要清除高4位。 ADD AL, BL AAA 在AAA之前，(AL)=6CH，AAA调整后，(AX)=0102H，CF=1，AF=1\n这说明4+8=12\n又例如\nMOV AL, 34H MOV BL, 28H ADD AL, BL DAA 执行DAA前，(AL)=5CH，执行之后，(AL)=62H，CF=0，AF=1，SF=0，PF=0，ZF=0。这说明34+28=62。\n而\nMOV AL, 56H MOV BL, 73H ADD AL, BL DAA DAA前，(AL)=C9H，DAA后，(AL)=29H，CF=1，AF=0，SF=0，PF=0，ZF=0。这说明56+73=129。也就是说CF标志位成为了百位数。\n减法调整指令\n与加法正好相反，如果一位溢出时，要进行减6修正。\nAAS根据运算结果及修正结果的AF有无借位，进行下列操作\nAF有借位，则CF=1，AF=1 AF无借位，则CF=0，AF=0 并清除AL的高4位。\n而DAS则会对AF、CF、SF、ZF、PF都有影响，其效果等同于SUB指令。\n逻辑运算指令 总共有五种逻辑运算指令：AND、OR、XOR、TEST、NOT，格式分别为\nAND DST, SRC OR DST, SRC XOR DST, SRC TEST DST, SRC NOT DST 都是按位计算，其中TEST的功能和AND完全相同，但是不改变任何操作数，只改变PSW。\n逻辑运算指令的对象是字节或字。其中NOT指令对PSW无影响，其他指令使得CF=OF=0，ZF、SF、PF根据结果改变。AF无关。\nDST可以为通用寄存器、内存，SRC可以为通用寄存器、内存、立即数。但是二者不能同时为内存。\n移位指令 移位指令的共同特点为：正常影响PSW的SF、PF、ZF、CF和OF标志位，其中CF表示指令所移出的一位，OF=1表示移位前后符号位发生了变化。\n移位指令一般形式如下\nSHR DST, CNT 其中DST为通用存储器或内存，而CNT一般为常数01H或者寄存器CL\n逻辑移位 左移为SHL、右移为SHR。空位用0填补，移出的位放入CF（移出多位时，最后一个移出的放入CF）。\n算术移位 左移位SAL、右移为SAR。SAL与SHL完全相同，SAR则是空位由符号位补充，移出的位也是放入CF。\n循环移位指令 不带CF的循环移位，左移为ROL，右移为ROR。\n10.jpg\r带CF的循环移位，左移为RCL，右移为RCR。\n11.jpg\r标志位操作指令 用这些指令可以手动设置PSW里的位。\n指令 功能 CLC CF置0 STC CF置1 CMC CF取反 CLD DF置0 STD DF置1 CLI IF置0，关闭中断 STI IF置1，打开中断 转移指令 8086汇编中转移指令有两大类：无条件转移指令（如JMP、CALL、RET、IRET），条件转移指令（如JZ，JC，JCXZ，LOOP）\nJMP（无条件） JMP LABEL ; 段内或段间直接寻址，跳转到LABEL标号处 JMP REG16 ; 段内间接寻址，跳转到REG指定的段内偏移 JMP MEM ; 字单元段内转移，双字单元段间转移，跳转到MEM指定的位置 其中JMP LABEL不需要指明是Near还是Far。如果LABEL与该指令在同一个段内，则为段内直接转移，转移后CS不变，(IP)\u0026lt;-(IP)+DISP16。其中DISP16表示转移目的地址与JMP转移指令之间的16位偏移量（可正可负），这时也叫近程转移。如果偏移量可以用8位表示，那么(IP)\u0026lt;-(IP)+DISP8，这时称为短转移。如果LABEL和JMP在不同的段，则表示段间直接转移，转移后(CS)\u0026lt;-SEG LABEL，(IP)\u0026lt;-OFFSET LABEL，这时称为远程转移。\n而段内间接寻址则不是这么玩的，例如JMP BX他直接把BX内容赋值给IP，而没有什么偏移。\n段间间接寻址是用双字内存来实现的，第一个字是OFFSET，第二个字是SEG。\n有条件转移指令 只有当给定的条件满足时，才会转移到指定的地址。条件是看PSW中的标志位，由上一条指令产生。\n有条件转移的寻址方式只有段内直接转移一种，而且是短转移，即偏移只能有8位有符号数。\n指令 测试条件 功能 JC LABEL CF=1 有进/借位 JNC LABEL CF=0 无进/借位 JE/JZ LABEL ZF=1 相等 JNE/JNZ LABEL ZF=0 不相等 JS LABEL SF=1 负数 JNS LABEL SF=0 非负数 JO LABEL OF=1 有溢出 JNO LABEL OF=0 无溢出 JP/JPE LABEL PF=1 有偶数个1 JNP/JPO LABEL PF=0 有奇数个1 JA/JNBE LABEL (CF=0)且(ZF=0) 大于（无符号） JAE/JNB LABEL CF=0 大于等于（无符号） JB/JNAE LABEL CF=1 小于（无符号） JBE/JNA LABEL (CF=1)或(ZF=1) 小于等于（无符号） JG/JNLE LABEL \\((OF\\oplus SF)\\wedge ZF=0\\) 大于（有符号） JGE/JNL LABEL \\(OF\\oplus SF=0\\) 大于等于（有符号） JL/JNGE LABEL \\(OF\\oplus SF=1\\) 小于（有符号） JLE/JNG LABEL \\((OF\\oplus SF)\\vee ZF=1\\) 小于等于（有符号） 由于有条件转移的范围很小，所以可以把他搭配无条件转移来使用。\n循环指令 LOOP LABEL ; (CX)\u0026lt;-(CX)-1, CX!=0时转LABEL LOOPZ/LOOPE LABEL ; CX!=0且ZF=1时转LABEL LOOPNZ/LOOPNE LABEL ; CX!=0且ZF=0时转LABEL JCXZ LABEL ; CX=0时转LABEL 都是段内直接转移，且为短转移。\n字符串操作指令 8086有5类字符串操作，分别为字符串传送（MOVS）、比较（CMPS）、扫描（SCAS）、装入（LODS）、存储（STOS）\n字符串处理既可以按字操作，也可以按字节操作，每次处理一个单元。SRC和DST都是隐含寻址。约定如下：\n如操作数在存储器中，则SRC由DS:SI确定，DST由ES:DI确定；如果操作数在寄存器中，则使用AL（字节型），AX（字型） CPU执行操作后，SI和DI会自动修改，当DF=0时增加，DF=1时减小。字节操作时修改1，字操作时修改2。 字符串传送 MOVSB ; 字节传送 (ES:DI)\u0026lt;-(DS:SI) MOVSW ; 字传送 (ES:DI)\u0026lt;-(DS:SI) MOVS DST, SRC ; 使用变量名，字节或字传送，但是是隐含寻址 字符串传送对PSW无影响。\n注意MOVS的DST和SRC不是寻址，操作数仍然是隐含寻址的ES:DI和DS:SI。当DST和SRC都是字型时等同于MOVSW，都是字节型时等同于MOVSB。\n字符串比较 CMPSB CMPSW CMPS DST, SRC 三个操作都是(DS:SI)-(ES:DI)，然后设置PSW标志位。DST和SRC仍然是只标记大小，并不是寻址。\n字符串扫描 SCASB SCASW SCAS DST 字节扫描时，(AL)-(ES:DI)设置PSW。字扫描时，(AX)-(ES:DI)设置PSW。源操作数固定为AX或AL，目的操作数固定为ES:DI。\n字符串装入 LODSB LODSW LODS SRC 字节操作时，把(DS:SI)放入AL。字操作时，把(DS:SI)放入AX。源操作数固定位DS:SI，目的固定为AL或AX。不影响PSW。\n字符串存储 STOSB STOSW STOS DST 把AL或者AX放入(ES:DI)，操作数固定。不影响PSW。常用作对指定区域清零或者赋初值。\n重复前缀 实际应用中经常需要对整个字符串进行操作，此时需要重复指令。\nREP\nREP STR_OP ; 当CX!=0时，重复执行STR_OP。CX\u0026lt;-CX-1。例如REP STOSB REPZ/REPE\nREPZ STR_OP ; 当CX!=0且ZF=1，重复执行STR_OP。CX\u0026lt;-CX-1。例如REP CMPSB比较直到不相同 REPNZ/REPNE\nREPNZ STR_OP ; 当CX!=0且ZF=1，重复执行STR_OP。CX\u0026lt;-CX-1。例如REP CMPSB比较直到相同 子程序 子程序是一种汇编语言的封装，在和C语言中的函数是类似的。子程序通过修改CS和/或IP来实现调用，一般通过CALL指令。CALL好处在可以保存CS和IP，方便之后用RET指令返回。\nCALL CALL LABEL 如果LABEL可以用短转移。则IP入栈，(IP)\u0026lt;-(IP)+DISP8。如果只能用16位的近程转移，那么IP入栈，(IP)\u0026lt;-(IP)+DISP16。如果只能用远程转移，那么CS先入栈，IP再入栈。再把IP赋值OFFSET，CS赋值SEG。\nCALL OPR 如果OPR为REG16，IP入栈，(IP)\u0026lt;-(REG16)\n如果OPR为16位RAM，IP入栈，(IP)\u0026lt;-(MEM)\n如果OPR为32位RAM，CS入栈，IP入栈，(IP)\u0026lt;-(MEM)，(CS)\u0026lt;-(MEM+2)\nRET RET ; 用于段内返回，使得(IP)\u0026lt;-(SP)，弹栈 RETF ; 用于段间返回，先IP出栈，后CS出栈 RET n ; 完成RET（或RETF）后，(SP)\u0026lt;-(SP)+n 子程序伪指令 过程名 PROC [类型] ... ... RET 过程名 ENDP 其中PROC和ENDP是伪指令。过程名相当于C语言的函数名，给子程序取的名字。它可以看作标号。类型可以是Near也可以是Far，默认为Near。\n但是过程名没有命名空间，也不能嵌套声明（可以嵌套调用）。\n中断 8086有三种中断\n内部中断。包括除法错误（0号中断），单步执行（1号），断点中断（3），INTO指令中断（4），INT n中断（n） 外部非可屏蔽中断NMI（2）。包含存储器错误和关机等。 外部可屏蔽中断INTR。 中断处理程序是放在存储器中的。于是我们获取到中断编号后，就要从内存中获取该编号对应的中断处理程序的地址（包括CS和IP）。\n中断处理程序的地址的地址，为段地址0000H，偏移地址\\(中断类型号\\times 4\\)。于是有四个字节或者两个字，第一个字为IP，第二个字为CS。CS:IP给出了中断处理程序的地址。\n中断类型范围为0~255\nINT INT n 表示调用第n号中断，其值为0~255，其会进行如下操作\n12.jpg\rIRET 中断返回指令。执行时会IP、CS、PSW的顺序出栈。\nDOS提供的系统功能调用 13.jpg\r其中INT21的功能号对应的功能为\n14.jpg\rIO操作 8086是独立编址的，进行IO操作需要特别的指令。\nIN IN DST, SRC 从端口输入数据。其中SRC一般为DX或者立即数，表示设备端口的地址。但是立即数只能是8位，而DX可以用16位也可以用8位。DST例如用AX表示读一个字，用AL则表示读一个字节。\nOUT OUT DST, SRC 和IN的DST和SRC的要求换一下即可。\n处理器控制指令 NOP 空操作指令。表示什么也不做，但要占用机器的三个时钟周期。\nHLT 暂停指令。\n","date":"2023-11-08T08:23:07+08:00","image":"https://kegalas.top/cover.jpg","permalink":"https://kegalas.top/p/%E5%BE%AE%E6%9C%BA%E5%8E%9F%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"微机原理学习笔记"},{"content":"众所周知，学校校园网是一个巨大的局域网。你在教室里面连上校园网的WiFi，就可以访问用有线网（或者WiFi）连接到校园网的宿舍电脑。这给了我们使用SSH在学校的任意地点访问宿舍电脑的可能。\nWindows配置 客户端配置 软件安装 Win11下，我们在设置-应用-可选功能-添加可选功能（查看功能）中搜索ssh，安装OpenSSH客户端。\n密码连接方式 这样就已经可以使用ssh登陆服务器了，当然现在你只能使用用户名和密码登陆。方法如下\nssh username@ip 我们一般局域网都是直接访问ip的，username就是你windows的用户名。密码不是PIN，是你微软账号的密码。如果是本地用户就是用户的密码。\n当然如果你要登陆的用户是管理员，现在可能还登不上，会显示Permission Denied\n密钥连接方式 如果不想输入密码，就要用到ssh的密钥文件。如何生成密钥文件我推荐你参考https://docs.github.com/zh/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent\n生成完之后记得要ssh-add，把密钥添加到ssh-agent里，这也在这篇文章中讲到怎么做了。通常，我也会建议你把ssh-agent服务设置为自动。注意在services.msc中这个服务叫OpenSSH Authentication Agent，在任务管理器中这个服务叫ssh-agent\n服务端配置 软件安装 类似于客户端，这次我们添加的功能叫做OpenSSH服务端。\n安装完成后，启动服务。在services.msc中这个服务叫OpenSSH SSH Server，在任务管理器中叫sshd。建议设置为自动。\n服务器参数配置 一般来说，开启服务之后，会自动在C:\\ProgramData\\ssh\\下生成一大堆文件。其中包括服务器的配置文件，和服务器自己的密钥等等。\n我们修改这个目录下的sshd_config文件，以下内容取消注释\nPermitRootLogin prohibit-password PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys PasswordAuthentication yes 然后，把PermitRootLogin prohibit-password改为PermitRootLogin no；把PasswordAuthentication yes改为PasswordAuthentication no\n最后，再注释掉：\n# Match Group administrators # AuthorizedKeysFile __PROGRAMDATA__/ssh/administrators_authorized_keys 这样，我们就只能用密钥登陆了。可能提升了些微的安全性。注意PermitRootLogin对Windows是无用的，我这样只是方便跟linux统一。\n修改完后重启sshd服务。\n服务器配置密钥连接方式 我们要把客户端的公钥上传服务器，这样我们才能让客户端正常登陆。为此我们要修改服务器用户的~\\.ssh\\authorized_keys文件（没有就创建一个），然后把客户端用户的公钥直接复制粘贴到authorized_keys中。公钥都是一行的，所以如果有多个公钥，每行一个即可。\n更换默认命令行 你可能发现ssh连进去，打开的是cmd命令行，而你更想要PowerShell，参照https://learn.microsoft.com/zh-cn/windows-server/administration/openssh/openssh_server_configuration#configuring-the-default-shell-for-openssh-in-windows\n我的版本如下，修改了我自己的PowerShell7的位置。\nNew-ItemProperty -Path \u0026#34;HKLM:\\SOFTWARE\\OpenSSH\u0026#34; -Name DefaultShell -Value \u0026#34;G:\\Program_Files\\PowerShell\\7\\pwsh.exe\u0026#34; -PropertyType String -Force 后记\npowershell 7在更新的时候可能会把你安装的位置强行迁移到C盘Program Files下，我建议不要换默认安装位置，防止自己搞不清状况又要重新配置。\n注意事项 注意，authorized_keys需要注意权限和所有权的问题。如果假如说，你创建了一个用户2，作为没有管理员权限的用户，用户1是拥有管理员权限的用户。它们两个在服务端。那么你需要确保用户2的~\\.ssh是由用户2自己创建的，并且自己有完全控制的权限。authorized_keys文件同理。这样才能让用户2正常读取文件信息。\n假设你为了方便用用户1为用户2创建文件、写入信息。那么你很有可能会登陆失败，显示Permission Denied。本人曾经踩过这个坑。\nLinux 使用例 Hugo Hugo是可以开启本地服务器的，其使用方法为hugo server，之后我们就可以在localhost:1313访问我们的博客了。\n1.jpg\r但是注意到，他开在127.0.0.1这个回环地址上。也就是说，只有本机才能访问，而内网的其他设备是无法访问的。\n在此我们要区分一下几个ip。localhost、127.0.0.1、192.168.x.x，10.x.x.x。\nlocalhost\n这个其实是个域名，和baidu.com没有本质区别，它一般会被映射到127.0.0.1。我们可以通过修改hosts更改它的映射。\n127.0.0.1\n这个叫回环地址，本机发出的所有信息都会兜一圈再发回给本机，并且这个兜一圈只在本机内部。外部设备是无法连接到这个地址的。\n192.168.x.x\n一般路由器会分配给电脑这个内网地址，同一路由器所连的设备地址都会是这个样子，只是最后几位不同。这些设备可以用它们的这个地址互相访问。\n10.x.x.x\n如果你在用校园网的话，路由器wan口的地址一般会是这个。但是这不是公网地址，这是校内局域网的地址。我们在别处使用校园网的话，就可以用这个地址访问宿舍内的设备。\n综上所述，如果你要让外部的设备访问到Hugo页面，你就不能把他开到127.0.0.1上，你应该开到192.168.x.x上。但是这样的话你本机访问localhost或者127.0.0.1又不能连上了。幸好我们有一种办法可以让两个同时可以访问，就是把服务器开在0.0.0.0上。开在这个ip上的服务器会自动探测本机的所有ip，让他们都能访问（不过0.0.0.0本身是不能访问的）。\nHugo本身的用法是hugo server --bind 0.0.0.0\n到此为止，你已经可以用本机的各种地址访问了，但是还不能用校园网内的其他设备访问10.x.x.x这个地址，因为这个地址是你宿舍路由器的wan口地址（你直接拨号上网除外）。你需要把192.168.x.x:1313映射到10.x.x.x:1313，需要用到的技术叫做端口映射，一般可以在路由器内设置。例如openwrt：\n2.jpg\r之后我们就可以真正在学校任意一个有网的地方访问10.x.x.x:1313来连接博客了。\nAnaconda 假设这样一个场景：你宿舍、实验室的机器显卡很强，可以用来训练AI，但是笔记本不太行。所以你想要在课堂上、图书馆训练AI是不可能的。这时候ssh就派上用场了，直接连到远程机器进行训练即可。\n你可能比较熟悉Anaconda的图形化界面，它启动特定的环境比较方便，只要按几个按钮即可。但是ssh只有命令行，命令行稍微困难点。\n在Anaconda的安装目录下，有一个condabin文件夹，里面的conda.bat可以帮助我们启动环境。\n你可以先使用.\\conda info -e查看你有哪些环境：\n3.jpg\r启动环境的方法是\n.\\conda activate base 你在powershell里输入会发现毫无变化。这其实是因为anaconda只支持cmd，我们要先输入cmd切换到cmd，之后再启动环境，即可。\n4.jpg\r与Hugo类似的，我们也可以通过校园网访问Jupyter Notebook。只要设定其ip即可\njupyter notebook --ip=0.0.0.0 同样，你也需要去开启路由器8888端口的映射。\n","date":"2023-10-20T15:33:36+08:00","permalink":"https://kegalas.top/p/%E5%9C%A8%E6%A0%A1%E5%9B%AD%E7%BD%91%E4%B8%AD%E7%94%A8ssh%E8%BF%9E%E6%8E%A5%E5%AE%BF%E8%88%8D%E7%94%B5%E8%84%91/","title":"在校园网中用ssh连接宿舍电脑"},{"content":"编辑器/IDE Emacs https://mirrors.tuna.tsinghua.edu.cn/gnu/emacs/windows/，在清华源下载安装，可以更改的只有安装目录。\n.emacs.d的部署TODO。\n现在emacs29自带use-package，直接打开就可以，不需要手动安装。\nall-the-icons很奇怪，不会被use-package安装，我们M-x package-install all-the-icons安装重启即可。\n另外，我安装了lsp-pyright来提供python的补全，python里面也要用pip安装pyright才能运行。\n此时，用GUI版本的Emacs已经可以了，但是如果想在命令行里用Emacs，则需要添加环境变量。出于对环境变量冲突的恐惧，我没有直接将Emacs的bin添加进PATH，我选择了照抄Vim的bat文件。如下\n@echo off rem -- Run Emacs -- setlocal set EMACS_EXE_DIR=D:\\Program_Files\\Emacs\\emacs-29.1\\bin if exist \u0026#34;%EMACS%\\emacs-29.1\\bin\\emacs.exe\u0026#34; set EMACS_EXE_DIR=%EMACS%\\emacs-29.1\\bin if exist \u0026#34;%EMACSRUNTIME%\\emacs.exe\u0026#34; set EMACS_EXE_DIR=%EMACSRUNTIME% if not exist \u0026#34;%EMACS_EXE_DIR%\\emacs.exe\u0026#34; ( echo \u0026#34;%EMACS_EXE_DIR%\\emacs.exe\u0026#34; not found goto :eof ) \u0026#34;%EMACS_EXE_DIR%\\emacs.exe\u0026#34; %* 把这个文件保存为emacs.bat，然后找一个文件夹放进去，例如我放在了xxx\\myExec下，然后把这个文件夹添加到PATH的末尾。\nIDEA https://www.jetbrains.com/idea/download/?section=windows，官网下载，我现在主要用Community版本，免费，而且其是可商用的，这点和其他很多软件的社区版不同。\n我这里没有选择添加进PATH，并且把所有文件关联都勾选上了。主要是考虑到防止PATH里面东西太多，干扰运行。\n2.jpg\rPycharm https://www.jetbrains.com/pycharm/download/?section=windows，和IDEA一样。\nQT Creator TODO\n（如果设置Android SDK会导致奇怪的卡顿）\nAndroid Studio https://developer.android.google.cn/studio，官网下载。\n勾上AVD，这个是安卓虚拟机，很显然是必要的。\n10.jpg\rAVD设置TODO（包括用软连接把安装目录转移等）\nObsidian https://obsidian.md/，官网下载，不需要设置环境变量。\n其软件设置，我一般会加上Completr插件来为Latex提供补全，安装Solarized主题。设置严格换行，显示行号，tab功能替换为4个空格而非制表符等。\nCP Editor https://cpeditor.org下载，\n建议选择64位版，不带mingw和llvm的版本，因为我们已经在msys里安装过了。\n这里没有选择all users安装，其他就只有目录可以修改。\nTexStudio 见后\n字体 Jetbrains Mono https://www.jetbrains.com/lp/mono/，下载解压，得到一大堆ttf格式的文件。虽然你可以一个一个双击安装，但是太慢了，我推荐你把它们全部选中，拖入到C:\\Windows\\Fonts文件夹中，可以批量安装。\nNoto TODO\nGit Git for Windows 安装步骤选择todo\n同样，为了防止PATH冲突，采取了和Emacs一样的手法\n@echo off rem -- Run GIT -- setlocal set GIT_EXE_DIR=D:\\Program_Files\\Git\\bin if exist \u0026#34;%GIT%\\bin\\git.exe\u0026#34; set GIT_EXE_DIR=%GIT%\\bin if exist \u0026#34;%GITRUNTIME%\\git.exe\u0026#34; set GIT_EXE_DIR=%GITRUNTIME% if not exist \u0026#34;%GIT_EXE_DIR%\\git.exe\u0026#34; ( echo \u0026#34;%GIT_EXE_DIR%\\git.exe\u0026#34; not found goto :eof ) \u0026#34;%GIT_EXE_DIR%\\git.exe\u0026#34; %* Github Desktop https://desktop.github.com/，可说的不多，甚至不需要安装，双击就打开安装完毕了，也没有环境变量需要配置（自动配置在User的PATH里了）。\n终端模拟器 Terminal 主题 tabby C/C++相关 GCC 这里使用的是MSYS2，https://www.msys2.org/，下载安装包。\n打开安装包，其中只有安装目录是能修改的。\n安装完成后勾选立即打开，打开的是ucrt64，我们首先更换软件源。\n进入xxx\\msys64\\etc\\pacman.d，参照https://developer.aliyun.com/mirror/msys2进行修改，这里我们全都修改一下。\n在文件中搜索ali\n11.jpg\r把阿里云的这一行复制到第一行。对所有文件都进行这个操作。\n之后在ucrt64的命令行中执行pacman -Sy\n之后安装pacman -S mingw-w64-ucrt-x86_64-gcc，当然，也可以使用pacman -S mingw-w64-ucrt-x86_64-toolchain。前者是目前官网的安装示例里的，后者则是以前的示例里的。\n环境变量我们只设置ucrt64、clang64和msys的，全部设置可能会加大冲突风险。\n12.jpg\r注意顺序，不能颠倒。\n之后我们打开MSYS的命令行，安装pacman -S gcc，这一步的目的是，我们使用MSYS提供的虚拟Linux的POSIX，方便我们在windows上进行Linux系统调用，这两个gcc的区别可见../MSYS2,MinGW64,Cygwin的使用区别浅谈\nClang 我们不去安装LLVM官方给Windows的二进制包了，我们直接在clang64里安装。\npacman -S mingw-w64-clang-x86_64-toolchain 安装了clang，clangd等工具。安装完之后不用进行任何环境变量配置。\n注意：不能只安装clang、clang-tools-extra等，否则clangd可能会出现找不到iostream库的问题。\nMSVC TODO\nMake/Cmake/Ninja 在UCRT64的terminal里面，输入\npacman -S mingw-w64-ucrt-x86_64-cmake mingw-w64-ucrt-x86_64-cmake-gui mingw-w64-ucrt-x86_64-ninja mingw-w64-ucrt-x86_64-make 安装cmake官网的windows版本会不会更优有待考察TODO。\n另外，直接安装make后，并不能在powershell里直接使用，见MSYS2中的make工具安装方法\n要让clangd能够检测Cmake项目，还需要进行https://clangd.llvm.org/installation#project-setup里提到的操作，简单来说\n在cmake进行configure的时候添加参数-DCMAKE_EXPORT_COMPILE_COMMANDS=1 把configure后build目录里生成的compile_commands.json软连接到项目根目录 Lua Rust相关 GO相关 Java相关 JRE和JDK Java8运行时 很多软件（例如Minecraft），都还建立在Java8之上，所以安装JRE8是理所当然的。\nhttps://www.java.com/en/download/，java官网目前首选的下载也是Java8。安装过程没什么可说的，只有安装位置可以更改。\n环境变量他也会自动配置好。\nJDK11和JDK17 因为有许多库，其在JDK11上运行最稳定，所以JDK11是要安装的，而想用新特性，最好安装一下JDK17。JDK11和17是LTS版本，更新的有需要再安装。如果你不可避免的要用JDK8 LTS，那么也可以去安装。\n我这里安装的都是Adoptium Eclipse Temurin的JDK，见https://adoptium.net/zh-CN/temurin/releases/?version=17\n以JDK17为例\n5.jpg\r我这里全都勾选了，但是PATH和JAVA_HOME其实可以不用勾选，因为很多IDE（如IDEA，Android Studio）都支持搜索所有JDK，并且手动选择JDK版本，所以这个其实不是很必要。\n另外，如果你加入了PATH，要记得把JAVA8的PATH放到JDK上面，以防运行不了Minecraft。\nScala Kotlin Clojure Python相关 普通版 https://www.python.org/downloads/下载最新版（注意是Windows installer (64-bit)），安装。\n安装它的原因是，因为直接把Anaconda3的Python导入环境变量实在是太容易造成冲突了，我们需要一个默认的Python给Windows用。\n我选择添加python.exe进PATH，并且Customize installation。勾选第二页的全部选项（默认就是全部）、第三页也全部勾选（注意有一个选项需要先安装Visual Studio）。\n6.jpg\r7.jpg\r8.jpg\r如上勾选之后，环境变量也会自动配置。这个普通版Python并不会影响Anaconda的virtual env，放心使用。\n更换pip源见https://mirrors.tuna.tsinghua.edu.cn/help/pypi/\nAnaconda3 https://www.anaconda.com/download下载安装包。\n安装时，我选择的是Just Me而不是All Users\n3.jpg\r勾选如下，勾选了第三个，可以让Pycharm选择里面的环境。第四个看到他推荐也就勾选了。第二个不勾选，防止环境变量冲突。\n4.jpg\rAnaconda的软件源也比较慢，推荐参考https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/换为国内源。\nLatex相关 TexStudio 这其实只是一个编辑器，不包含latex的运行环境。\nhttps://texstudio.sourceforge.net/，下载后只有安装目录可以更改，不需要设置环境变量。\ntexlive 这才是真正的运行环境。\nhttps://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/Images/，推荐在清华源下载，官网实在太慢。下载texlive.iso即可。\n下载后装载这个iso，打开install-tl-windows.bat安装\n9.jpg\r选好位置点击安装。\n安装完成后关闭，弹出iso。环境变量已经自动设定在User的Path里。\nSQL相关 Postgresql JS相关 Node.js SSH配置 参考在校园网中用ssh连接宿舍电脑\n博客（Hugo） Hugo 见我的文章为Hugo安装goldmark-mathjax插件来更好地支持输入公式，不推荐使用官网的安装包，推荐自己加插件自己编译。\n把编译好生成的hugo.exe放到某个你喜欢的地方，比如我的G:\\Program_Files\\Hugo\\，并把这个目录设置为环境变量。\nPandoc https://www.pandoc.org/installing.html，现在有安装包，以前只有压缩文件。我只是选择了为所有用户安装以及选择了安装位置，也没有其他可选项了。\n需要手动配置环境变量，配置在xxx\\Pandoc\\即可。\n但是我现在不怎么用这个了，hugo对goldmark适配的更好\nMatlab 从各种地方下载安装包，例如学校正版软件服务、官网等，直接安装即可。\n软件包选择TODO\n环境变量一般配置在xxx\\MATLAB\\R2021b\\bin，注意版本R2021b换成自己的版本。\n其他 Gpg4win 从https://www.gpg4win.org/下载安装，环境变量其会自动配置。我勾选了除了Okular以外的所有选项。\n一般会配置在xxx\\Gpg4win\\..\\GnuPG\\bin\n1.jpg\rssh客户端、服务端 安装的话很简单，在设置里面找到应用-可选功能。\n13.jpg\r点击圈出来这个查看功能，搜索openssh，把客户端和服务器都安装即可。\n安装好之后在服务设置里，设置为自动即可开机启动。\n14.jpg\r一般配置文件在C:\\ProgramData\\ssh\\sshd_config，具体如何修改TODO，例如配置管理员登陆，以及默认shell\n环境变量顺序 TODO\n","date":"2023-09-23T11:30:14+08:00","permalink":"https://kegalas.top/p/windows%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%90%88%E9%9B%86%E9%95%BF%E6%9C%9F%E6%9B%B4%E6%96%B0/","title":"Windows开发环境配置合集（长期更新）"},{"content":"动机 在很久以前的使用中，我发现默认的Hugo渲染引擎无法正确渲染所有数学公式，但我并没有深究为什么。我进行一番搜索后改用pandoc来作为渲染引擎，它在数学公式方面表现的不错，但是，它无法生成目录，也无法生成代码高亮。\n再一番搜索后，我搜索到这篇文章给 Hugo 增加一些 Pandoc 支持增强，里面详细介绍了怎么才能让pandoc正确生成目录，之后我写了文章重新编译hugo来使得pandoc可以生成目录。\n在这些操作后，目录确实可以生成了，但是代码高亮却没有出现。另外，这个版本比较老，无法使用Hugo的最新特性。\n不过我暂时还是保持使用这个版本，因为比起高亮，正确显示公式才是最重要的。\n现在我开始思考要怎么才能显示高亮。Hugo官方对于其他渲染引擎的支持很少（见https://gohugo.io/content-management/formats/），例如pandoc，go-org，rst，asciidoc等。当然这里面asciidoc是个例外，不过我尝试了一下发现仍然不能生成目录。我最终转向了去研究怎么才能让默认的goldmark正确显示公式。\n问题分析 我仔细观察了一下没渲染出公式的代码变成了什么样。最终，我发现，如果一个公式里面有两个下划线，就有可能渲染不成功，并且不成功的地方会变成斜体。再研究发现，两个下划线中间包含字符，是markdown本来的斜体语法（虽然我更常用两个*号），这与Latex里面的下划线用法冲突了，并最终导致了这个问题。\n解决办法 也有一些教程，例如https://bwaycer.github.io/hugo_tutorial.hugo/tutorials/mathjax/通过往html里面嵌入mathjax的js代码来解决问题，但是我自己试了一下好像并没有成功。\n我搜索到了goldmark有mathjax插件，机缘巧合之下我又看到了这篇文章Hugo\u0026amp;Eureka\u0026amp;Nginx，明白为Hugo加入goldmark-mathjax是可能的，试验之后确实如此，实际操作过程如下。\n环境需求 Go 1.19或更新，GCC 官网没有提到GCC的版本，我这里使用的是msys2 ucrt里安装的gcc 13.1.0，而go用的是1.21.1。\nClone、修改代码 git clone https://github.com/gohugoio/hugo.git （不知道为什么shell代码没有高亮）\n可能会遇到网络问题，需要自行解决。\n之后在hugo/markup/goldmark/convert.go中进行修改。\n在import部分添加\u0026quot;github.com/litao91/goldmark-mathjax\u0026quot; 在extensions = append(extensions, images.New(cfg.Parser.WrapStandAloneImageWithinParagraph))后添加extensions = append(extensions, mathjax.MathJax) 至此修改结束，可以看这个链接查看具体怎么修改的。也可以直接克隆我的fork，https://github.com/kegalas/hugo\n编译 cd hugo go get github.com/litao91/goldmark-mathjax go install --tags extended 后两个命令都需要网络通畅。\n编译成功后，一般会生成在C:\\Users\\XXX\\go\\bin，找不到的建议可以用Everything搜一下hugo.exe。之后就可以愉快的使用了。\n已知问题 输入公式时，\u0026lt;有时要求后有空格，否则会渲染失败。一般来说，应该是\u0026lt;后加上大小写字母会渲染失败，必须加上空格。可以用搜索软件搜索所有笔记手动修改。 两个行内公式，如果中间没有间隔，或者中间间隔为英文逗号、句号，会渲染失败。例如$abc$$abc$，$abc$,$abc$，$abc$.$abc$。后面两种情况搜索即可。第一种情况，由于正常的行间公式双$符在单独一行，所以直接搜索$$，obsidian只会把搜索结果的那一行显示，所以即使有几千条也还是比较方便找到的。 行间公式，双$符要单独在一行，否则会渲染失败。解决方法同上。 ","date":"2023-09-21T21:32:37+08:00","permalink":"https://kegalas.top/p/%E4%B8%BAhugo%E5%AE%89%E8%A3%85goldmark-mathjax%E6%8F%92%E4%BB%B6%E6%9D%A5%E6%9B%B4%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E8%BE%93%E5%85%A5%E5%85%AC%E5%BC%8F/","title":"为Hugo安装goldmark-mathjax插件来更好地支持输入公式"},{"content":"本笔记会记录一些C++中，不是很常用（对于我自己来说）、可能被忽视（对于我自己来说）、我自己不是很熟悉需要记录来复习的、新标准（相较于C++11）引入的、可能有用的功能。不适合详细阅读过某一本C++大部头教材的人，比较适合对于C++的知识只停留在算法竞赛的人。\nstd::endl std::endl会立即刷新字符缓冲区，然后输出。但是'\\n'不会。如果频繁地使用std::endl换行可能会导致性能问题，除非你非常确定这条消息在换行后必须要立即输出。\nstd::clog 其写入字符到stderr中，但不是立即输出。而std::cerr会立即输出和刷新stderr。\n\u0026lt;=\u0026gt;（三路比较 ）运算符 这个运算符是C++20引入的，\n如果a\u0026lt;b，那么(a\u0026lt;=\u0026gt;b) \u0026lt; 0 如果a\u0026gt;b，那么(a\u0026lt;=\u0026gt;b) \u0026gt; 0 如果a和b相等或等价，那么(a\u0026lt;=\u0026gt;b) == 0 其实\u0026lt;=\u0026gt;返回的是std::strong_ordering类型，某些时候给自己的类重载多种比较运算符会简单不少。其中a\u0026lt;b时返回std::strong_ordering::less，a == b时返回std::strong_ordering::equal，a\u0026gt;b时返回std::strong_ordering::greater。\nstd::numeric_limits\u0026lt;T\u0026gt; 这个命名空间包含在\u0026lt;limits\u0026gt;头文件里，其可以给出一个基本数据类型的数据范围，例如\nstd::numeric_limits\u0026lt;T\u0026gt;::lowest();//给出T的最小取值（有符号时为绝对值最大的负数） std::numeric_limits\u0026lt;T\u0026gt;::min();//对于整数，给出最小取值，对于浮点数，给出最小的正数 std::numeric_limits\u0026lt;T\u0026gt;::max();//给出T的最大取值 std::numeric_limits\u0026lt;T\u0026gt;::epsilon();//浮点数给出最小精度，比如第一个大于1的数和1的差 大括号初始化变量 我们可以用如下方法初始化变量\nfloat a = 1.5f; float b {1.5f}; 第一种是传统方法，第二种方法有一点好处是，在隐式的基本类型转换中，如果类型收窄（Type Narrowing）会给出Warning，甚至会直接给出error。\nint i = 2.5f;//编译器无warning float f = 2.5f; int j {f};//编译器产生warning，有时候类型收窄确实可能导致错误。 int k {2.5f};//编译器会直接给出error 如果你确定类型收窄是你需要的，那么用显式的强制类型转换。\n[[nodiscard]]修饰 C++17引入。这个修饰是给函数使用的，如果函数有返回值，并且希望返回值不会被忽略，就可以使用这个修饰。\n比如\nvoid normalize(vec3f \u0026amp; v);//把v变成单位向量 vec3f normalized(vec3f const \u0026amp; v);//返回v的单位向量，但v不变 这组可能分辨不清的函数，我们就可以把第二个函数加上这个修饰，编译器会在返回值没有被接收的时候发出warning。\nvector扩容（初步） 这里是一个简易版本的介绍，后续可能会专门出博客来详细解析STL的各种容器与算法（TODO）。\n我们要首先明白vector的内存布局是怎样的。一般来说，除非你在全局变量里面声明vector，不然vector对象都是在栈中的。但是vector的内容（即buffer）却是分布在堆里。\n首先我们区分一下size和capacity，前者是vector里面拥有的元素的个数，后者是vector可以放多少元素。\n当size=capacity时，此时如果我们进行push_back，容量不够，不能放进去。之后vector就要进行扩容。此时，实际上的内存不是在buffer后面再给你新分配一些，与前面的连起来。而是重新找一块更大的内存，将原来的buffer整体复制到堆中的新位置，再把新的插入元素放到最后。栈中的vector对象则简单的把指向的buffer地址改成新的即可（当然还有修改size和capacity）。\n每次扩容，capacity会变为原来大小的\\(1.1\\)至\\(2\\)倍。\n由于扩容的时候要复制，这是很大的开销。所以如果你提前知道数据个数的具体、或者大概的范围，那么最好使用vector\u0026lt;int\u0026gt; vec(n);或者vec.reserve(n);（区别是前者会有n个初值为0的元素，后者没有元素，只有capacity==n；当然resize(n)时，如果新大小大于原来的大小，会把多出来的空间用0填补）来提前给够空间。如果你不确定那么没有什么办法，大概只能这样。\nauto与“C-Like”字符串字面量 auto a = \u0026quot;test\u0026quot;;这个语句，a不会是std::string类型，而是char const[]类型。这也就意味着你也无法使用auto b = \u0026quot;123\u0026quot;+\u0026quot;456\u0026quot;;。\nstd::string的字符串字面量 这个特性是在C++14引入的。auto s = \u0026quot;test\u0026quot;s;，在原来的基础上，字符串后面加上s，即可推断为std::string类型。\n不过使用之前要先using namespace std::string_literals;\n原始字符串字面量 其用法为R\u0026quot;(此处填入原始字符串)\u0026quot;，这里面的原始字符串，不需要转义符，原本是什么，直接输出出来就是什么，而且转行也会被输出出来。这在我们的字符串是Windows目录时可能会比较方便，例如auto s = R\u0026quot;(C:\\Windows\\SysWOW64\\IME\\SHARED)\u0026quot;，不需要再像以前一样，给每个\\换成\\\\了。\n另外，auto s = R\u0026quot;(C:\\Windows\\SysWOW64\\IME\\SHARED)\u0026quot;还是被推断为char const[]，在C++14之后，声明using namespace std::string_literals;，之后auto s = R\u0026quot;(C:\\Windows\\SysWOW64\\IME\\SHARED)\u0026quot;s;可以推断为std::string\nstd::string_view C++17引入的功能，具体的用法和应该使用的地方都和std::string const \u0026amp;差不多，都是对于一个string的只读，并且不开额外空间。区别是，const \u0026amp;版本是建立了对原string的引用。string和vector很像，都是对象和buffer分开，而std::string_view就是一个对原string的buffer的只读的工具。推荐在新版本C++中使用这个功能。\n函数参数什么时候用const \u0026amp;? 可能会有人在第一次学习到用const \u0026amp;来修饰形参，觉得这东西简直太好了，可以不用花费额外开销去复制。但其实不总是这样。\n如果你传入的数据是double，int等开销本来就很小的变量，根本就不需要用const \u0026amp;，那反而还会增加开销。\n在变量复制开销本来就很小时，不需要修饰符 如果你想要防止自己不小心修改了变量，只加const即可 如果你想要修改实参，则显然必须加且只加\u0026amp;传入引用（例如swap函数） 如果你传入的复制开销很大（例如一个图片类），又不需要修改，加const \u0026amp; 左值、右值（初步） 左值\n左值指的是可以获取地址的表达式，例如变量、函数形参等。\n右值\n右值正好相反，就是不可获取地址的表达式。例如字面常量（除了字符串字面量），操作符的临时结果（例如a=b+c;中的b+c），函数的返回值。\n具体什么是右值什么是左值可以在https://zh.cppreference.com/w/cpp/language/value_category查询。这里面还介绍了纯右值，亡值，将来我会出一篇博客介绍（TODO）。\n\u0026amp;引用\n\u0026amp;只能引用左值。也就是说void fun(int \u0026amp; a);这个函数，你传入fun(1);会编译失败，但是int b=1;fun(b);是可以编译成功的。\nconst \u0026amp;引用\nconst \u0026amp;既可以引用左值，又可以引用右值。\n左右值的名称是来源于它们在与等号的位置关系，一般情况下左值在等号左边，右值在等号右边。不过不能用一个东西能否被赋值去判断左右值。最好的办法是看能否被引用。\n小心返回引用的函数 例如\nint\u0026amp; fun(int x){ int y = x+1; return y; } 显然y的生命周期只能持续到函数结束，返回的引用就指向了一个无效的内存，这个要特别小心。但是如果你通过new分配了一个对象，再返回引用，则是可以的，这个对象的生命周期持续到你手动使用delete或者程序结束。不过并不推荐总是这样做，有时最好直接返回值。\n引用可能会像迭代器一样失效 比如对vector进行的操作会涉及capacity的修改，比如在set中进行插入和删除操作，这些是会使原来的迭代器无效的。这同时会使引用失效。就比如我们介绍过vector在扩容时会复制元素到新的内存，原来的引用指向的内存就会被释放，变成无效内存，此时再进行操作是UB。\n不要用引用来延长函数返回值的生命周期 std::vector\u0026lt;int\u0026gt; fun(){...} auto const \u0026amp; v = fun();//现在fun的返回值的周期延长到和v一样，通常不会造成问题 auto const \u0026amp; v2 = fun()[0];//这是最危险的情况，fun的返回值其实生命周期已结束，v2引用的元素已经变成了无效内存，对v2的操作是UB 鉴于上述情况，最好不要用引用接受函数返回值，直接用传值的方式更好。\nstruct/class的大括号初值 struct St{ int x; double y; }; St st{1, 2.0};//也可以St st = {1, 2.0}; 像这样，用大括号给结构体、类赋初值，其顺序和结构体内部声明的顺序要一致。\n类拷贝（copy） C++与Java、Python等不同，在下面的例子中\nstruct Point{ double x,y; }; Point p1{1.0, 2.0}; Point p2 = p1; 用到了p2 = p1这一语句。在Java和Python中，p1、p2现在都指向同一个对象Point(1.0, 2.0)，而其本身并不是对象。在C++中，p2把p1的所有内容拷贝赋值给自己，它们两个是两个不同的对象（即使内容相等）。\n在C++中，拷贝默认是深拷贝，而Java和Python中是浅拷贝。如果要在C++里面使用浅拷贝，则使用Point \u0026amp; p3 = p1即可（也可以用指针）。\n除了是否新建一个对象以为，这两者的生命周期也不同。C++的对象在p1销毁时就销毁了，而在Java中p1销毁之后，由于还有p2指向这个对象，所以对象本身不会销毁。如果所有指向全都销毁，那么垃圾回收机制才会销毁这个对象。\n另外，通常“相等”的概念也不同。在Java中，对两个对象变量使用==运算符，如果它们指向不同的对象，则不相等，否则相等。在C++中，我们一般会重载==运算符，判断两者的内容是否相等。\n拷贝构造函数 赋值构造函数 argc, argv int main(int argc, char* argv[]){ //... } main函数可以带两个参数，按照传统我们把第一个参数叫argc，第二个参数叫argv。argc是一个整数，代表命令行中参数的个数，argv是每个参数的字符串。\n命令行中参数通常由空格分开，例如\n./g++.exe 1.cpp -o 1.exe -Wall 其中有五个参数，第一个为可运行文件本身的路径，后面的为运行它的参数。意味着argc等于5，argv存有五个字符串。一般我们会用atoi把字符串里的数字转化为int类型。\nfile stream 在NOIP、NOI等竞赛中，一般会用freopen函数。这是一个C的函数，如果要更C++一点，我们会使用file stream。\n#include \u0026lt;fstream\u0026gt; int main(){ std::ofstream os{\u0026#34;1.txt\u0026#34;}; if(os.good()){//在每次使用时都应该确保good os\u0026lt;\u0026lt;\u0026#34;hello world\\n\u0026#34;; } return 0; } 如上为写数据时的使用例子。可以看到和cout的用法很像。\n#include \u0026lt;fstream\u0026gt; int main(){ std::ifstream is{\u0026#34;2.txt\u0026#34;}; if(is.good()){//在每次使用时都应该确保good double x,y; is\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y; std::cout\u0026lt;\u0026lt;x\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;y\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } 如上为读数据的例子。可以看到和cin的用法很像。\n另外，例如写到末尾还是覆盖，是文本还是二进制，这些都是可以设置的。具体参考https://zh.cppreference.com/w/cpp/header/fstream，这里简短的给出几个常用的\nstd::ofstream os{\u0026#34;out.txt\u0026#34;, std::ios::app}; //append而不是覆盖 std::ifstream is2{\u0026#34;in.tga\u0026#34;, std::ios::binary}; //写二进制 std::ofstream os2{\u0026#34;out.tga\u0026#34;, std::ios::binary}; //读二进制 重载\u0026laquo;和\u0026raquo;运算符 struct Vec{ double x,y; }; std::istream\u0026amp; operator\u0026gt;\u0026gt;(std::istream\u0026amp; is, Vec\u0026amp; v){ return is\u0026gt;\u0026gt;v.x\u0026gt;\u0026gt;v.y; } std::ostream\u0026amp; operator\u0026lt;\u0026lt;(std::ostream\u0026amp; os, Vec\u0026amp; v){ return os\u0026lt;\u0026lt;v.x\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;v.y; } std::cout\u0026lt;\u0026lt;Vec(2.0,3.0)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;;//可以像对int一样使用cin cout 主要是方便打印、输入数据，例如你在编写一个数值计算库，需要用到很多向量、矩阵的输出。\nmutable和const的成员函数 class Vec{ public: double x,y; int mutable sth; int sth2; void foo() const { sth++;//不会报错 } void bar() const{ sth2++;//会报错 } }; 把类成员函数用const修饰（放在参数列表之后），意味着，这个函数声称不会改变类内的所有成员变量的值。如果你想让几个特例可以修改，那么就把那个特例变量声明为mutable的即可。\n类成员初始化 在C++ 11以前，我们初始化类成员一般只能在构造函数里进行，如\nclass Vec{ public: double x,y; Vec():y(0),x(0){} }; 其中:后面跟着的这个叫做初始化列表，成员后跟着的括号里面的写入初始值，即可完成初始化。\n注意，初始化列表里面的赋值顺序并不是初始化列表写出来的顺序，而是按照成员变量的声明顺序。例如上例，是先初始化x，再初始化y。这有时会导致UB，建议绝大部分时候，都要保持两者顺序一致。\n当然你也有可能这样写\nVec(int x_, int y_){ //而不是写:x(x_),y(y_) x = x_; y = y_; } 这其实能看出一个C++程序员的水平。对于int、double这种内置类型还好。但如果x、y是class，那么=意味着拷贝赋值，意味着可能会先构造一个新的对象实例，再拷贝给x和y。而是用初始化列表，则会直接调用构造函数，总体上少了拷贝这一个步骤。\n在C++ 11之后，我们也可以这样给初始值\nclass Vec{ public: double x=0.0, y=0.0; Vec(){} }; explicit关键字 class Cl{ public: int n; explicit Cl(int n_):n(n_){} }; void foo (Cl a) {} foo(1); //隐式调用Cl的构造函数，但因为其构造函数是explicit的，会报错 foo(Cl(1));//正常 个人认为这主要是方便强调一下传入的数据的类型，可能在调试环节比较有用。\n构造函数相互调用 Class Vec{ public: double x, y; Vec():Vec(0){} Vec(double a):Vec(a,a){} Vec(double x_, double y_):x(x_),y(y_){} }; 在C++里最好用nullptr而不是null C++和C语言的NULL定义是不同的，在C++中#define NULL 0，而在C中#define NULL ((void*)0)。不得不这样改的原因是：C++不支持void*的隐式转换。可见NULL就是一个数字0，它会有如下问题\nvoid foo(int n){} void foo(void *n){} 此时如果你调用\nfoo(NULL); 则会有二义性问题。编译可能会无法通过。用nullptr则不会有这个问题。\n当然，有时候我们会有以下三种写法\nif(p){} if(p!=NULL){} if(p!=nullptr){} 这更多的是一种风格问题，争论这个似乎是无用的。但是之前的二义性还是要小心的。\n如果你懒得管，那么就永远使用nullptr。\nconst与指针 众所周知，在指针类型的声明里，const放的位置不同会导致语义的不同。主要是指针是否可变，以及指针指向的内容是否可变。 如下表\n声明 所指内容可变？ 指针本身可变？ T * 是 是 T const * 否 是 T * const 是 否 T const * const 否 否 简单来说就是const在星号右边则指针自己不可变，在左边则所指内容不可变。也可以理解为，const修饰的是它左边的东西。要么修饰指针（即星号），要么修饰值（即T）\n所以说，我更推荐T const的写法，而不是const T。但是我们也要知道，const T *是修饰值不可变。\n智能指针 TODO this指针 有点类似于Python里的self参数，都是只能用在类里的。是一个指向对象自己的指针。\n析构函数的析构顺序 在析构函数执行完毕后，类成员变量的析构顺序，是按照其声明顺序的反方向进行的。\n有时候可以尝试集中处理Exception void handle_errors(){ try{ throw; //必要的，进行re-throw } catch(...){} catch(...){} catch(...){} } void foo(...){ try{ ... } catch(...){ handle_errors(); } } void bar(...){ try{ ... } catch(...){ handle_errors(); } } 这可以复用代码，尤其是你的东西可能会抛出一样的exception的时候。\nRAII思想和其对于Exception内存泄漏的保护 RAII是Resource Acquisition Is Initialization的缩写，意为资源获取就是初始化。\n其要求，对象在构造函数中获取资源，在析构函数中释放资源。为什么这是好的呢？他可以减少你管理内存的工作量，你不需要手动去到处写delete来释放内存。它会在对象生命周期结束的时候自动释放，也就避免了内存泄漏。\n而对于Exception，它也可以很好的保护内存。C++的Exception在throw的时候，保证可以释放创建的局部对象。于是就可以自动释放内存，而不用担心是否在throw前正确处理了内存。\n像C语言这样的东西，申请完内存需要free才能释放，如果在函数中提前返回了，无法运行到free这一行，那么内存就泄漏了。如下例\nvoid foo(){ int *a = malloc(...); ... if(...){ ... return; // 这里没有释放内存，产生泄漏 } ... free(a); return; } 所以如果C++调用了某个C库，又没有很好的释放内存，就可能会造成泄漏。如果你想避免这个，可能可以尝试用C++的类包装一下，提供析构函数。\n上例在exception结构中类似下例\nvoid foo(){ int *a = new...; ... if(...){ ... throw ...;// 这里没有释放内存，产生泄漏。但是如果有析构函数则可以避免 } ... delete a; return; } 另外，RAII也就要求你，不能在析构函数本身中出现提前的throw。\nnoexcept修饰 修饰函数时，如果给出noexcept，则意味着你保证：\n函数的操作不会失败 从外部来看，任何Exception是不可见的。或者说所有Exception都在内部处理了。 如果noexcept函数还是抛出了一个Exception，那么程序会终止。\n我们可以给noexcept提供一个条件，满足条件是函数才是noexcept的。\nvoid foo() noexcept(n\u0026lt;9){...} // 当n\u0026lt;9时noexcept void bar() noexcept( noexcept(foo) ){...} // 当foo是noexcept时，bar是noexcept 注意给assert的参数加上括号 因为assert其实是宏，所以\nassert(min(a,b)==a); //不好 assert((min(a,b)==a)); //好 否则，宏替换可能会出问题，而且你无法察觉。\nstatic_assert assert是给运行时用的，而static_assert就是给编译时用的。\nstatic_assert(bool_exp, \u0026#34;msg\u0026#34;); // C++11可用 static_assert(bool_exp); //C++17可用 用-DNDBUG忽略所有assert 这是g++的编译选项，只需使用这个参数即可\ng++ -DNDBUG ... Cmake使用 TODO\ndoctest/catch2使用 TODO\nGDB使用 TODO\n使用g++/clang检测内存错误使用、未定义行为等 TODO\n使用valgrind检测内存泄漏、锁问题等 TODO\n","date":"2023-09-06T21:52:23+08:00","permalink":"https://kegalas.top/p/c-%E7%AC%94%E8%AE%B0%E4%B9%8B%E9%82%A3%E4%BA%9B%E6%9C%89%E7%94%A8%E4%BD%86%E7%BB%8F%E5%B8%B8%E8%A2%AB%E5%BF%BD%E8%A7%86%E7%9A%84%E5%86%85%E5%AE%B9/","title":"C++笔记之那些有用但经常被忽视的内容"},{"content":"背景 可能大家的Firefox里面会有以下几个插件：\n1.jpg\r2.jpg\r此外还有火狐新标签页（个人不喜欢），火狐主页（个人不喜欢），网银支付助手（没用），网页截图（一般都用qq截图了）等插件。\n你可能完全不知道它们是什么时候装在你的Firefox里的，但是它们无形中修改了你的操作使用习惯。\n但是你会发现这几个插件（2021年或2022年以后）是没法在（至少是国际版）Firefox里同步的。也就是说你使用一台新的电脑，新的Firefox，登陆了你的账户，进行同步。却发现以前的一些操作变得非常不习惯，例如：\n新建标签页永远在最右边 无法双击关闭标签页 打开书签会默认替换当前页面而不是新开一个标签页 地址栏没有二维码生成器了 拖拽文字、超链接必须拖拽到标签页那一栏才能搜索、打开连接。以前只要拖拽几毫米就可以。 恢复最近关闭的页面的按钮没了 这些功能其实都是这两个奇怪的插件提供的。这两个插件无法在addons.mozilla.org搜索到，这两个插件实际上藏在mozilla.com.cn/moz-addon.html这个中国特供插件网站。这几个插件也是中国特供版Firefox自带的。\n为什么我的国际版也会有这些插件？曾经我在Firefox将同步由国内服务转变为国际服务，我想我可能就在这个转变的途中，把这几个插件同步到了国际版上。\n至于现在无法同步插件，我猜测以前Firefox可以同步用户自己下载的乱七八糟的插件，比如这几个，比如Listen1。而现在同步的插件必须是官方审核过的，也就是addons.mozilla.org中的。这导致这些东西无法同步，并且如果你在大陆的话甚至也没法同步uBlock Origin（因为在官网上这个插件是锁区的）。\n下面我们通过一些设置来改回我们习惯的操作，这些都是可选的，根据自己的喜好来。\n新建标签页在当前标签页的右边 我们在Firefox的地址栏输入about:config，进入之后接受风险并继续。\n搜索insert，把下面两个选项改为true。\n3.jpg\r双击关闭标签页 搜索browser.tabs.closeTabByDblclick，改为true。\n新建标签页打开书签 browser.tabs.loadBookmarksInTabs改为true。\n新建标签页打开搜索 browser.search.openintab改为true\n地址栏二维码生成器 你也许可以尝试使用https://addons.mozilla.org/zh-CN/firefox/addon/qr-code-address-bar/这个插件。\n拖拽手势 有几个插件可以使用\nhttps://addons.mozilla.org/zh-CN/firefox/addon/quickdrag-we/，它的设置比较简单，也是可以设置拖拽新建标签页在foreground还是background。我本人选用了这个。我把他的选项里的搜索引擎改成百度，位置改成Right，剩下四个选项全部取消勾选。不过这个插件好像在部分页面中不起作用，例如mozilla.org的网站中，以及Firefox自己的设置页面中。\nhttps://addons.mozilla.org/zh-CN/firefox/addon/drag-to-go/，它的设置更为复杂，可以把拖拽的四个方向的动作分开算，但是不知道为什么，拖拽文字搜索居然不可以设置background。而且拖拽的时候虽然确实能拖拽，但是鼠标指针显示的还是“禁止”的那个图样，让我很不爽。\nhttps://addons.mozilla.org/zh-CN/firefox/addon/fire-drag/，它总体而言和第一个差不多。缺点也是有几个页面用不了。\n恢复最近关闭页面的按钮 简单的可以用https://addons.mozilla.org/zh-CN/firefox/addon/%E6%81%A2%E5%A4%8D%E6%A0%87%E7%AD%BE%E9%A1%B5/，这个插件右键没有关闭页面的列表。\n功能更齐全的可以用https://addons.mozilla.org/zh-CN/firefox/addon/undoclosetabbutton/，这个插件右键就有列表了。\n","date":"2023-08-06T09:55:11+08:00","permalink":"https://kegalas.top/p/firefox%E4%B9%A0%E6%83%AF%E8%AE%BE%E7%BD%AE%E8%AE%B0%E5%BD%95%E5%8C%85%E5%90%AB%E5%8F%8C%E5%87%BB%E5%85%B3%E9%97%AD%E6%8B%96%E6%8B%BD%E6%89%8B%E5%8A%BF%E6%96%B0%E5%BB%BA%E6%A0%87%E7%AD%BE%E9%A1%B5%E4%BD%8D%E7%BD%AE%E7%AD%89/","title":"Firefox习惯设置记录（包含双击关闭，拖拽手势，新建标签页位置等）"},{"content":"导航页面\nBlinn-Phong反射模型 Blinn-Phong反射模型将光的反射分为了三个部分。\n漫反射 镜面反射 环境光反射 我们在具体实现光照的时候，会把这三个光照分开计算，然后最后显示出来的时候叠加显示。\n为了方便，我们作出如下约定，对于物体表面上的一点\\(\\bm p\\)，其单位法向量为\\(\\bm n\\)，从\\(\\bm p\\)指向摄像机的单位向量为\\(\\bm v\\)，指向光源的单位向量为\\(\\bm l\\)\n3.jpg\r漫反射 漫反射意味着，从四面八方看过来，这个位置的颜色（亮度）是一致的。\n2.jpg\r如图，光到了反射点后，朝着四面八方反射，并且并没有哪个方向特别突出。\n处理漫反射的规则也叫做Lambert\u0026rsquo;s Cosine Law，这个规则指明，如果光源照射到\\(\\bm p\\)点上的光照强度为\\(I\\)，则其漫反射的光照强度为\\(L_d=I\\cos\\theta\\)，其中\\(\\theta\\)是\\(\\bm l\\)和\\(\\bm n\\)的夹角。同时为了防止从物体表面以下的光线射过来影响亮度，以及考虑各种物体的反射性能不一样，我们写为\n\\[L_d = k_d I \\max(0,\\bm n\\cdot\\bm l) \\]\n其中\\(k_d\\)是该物体的材质的漫反射系数。这里\\(k_d\\)一般是三维向量，而同时\\(I\\)和\\(L_d\\)也是三维向量。这么做的原因是，我们的光是有颜色的，并且反射的时候物体也会对某种颜色反射的多，某种颜色反射的少。这里\\(k_d\\)和\\(I\\)是分量之间各自相乘的乘法，在我们的库里就是operator*，而不是dot函数。\n并且由于我们在这里做乘法，试想一下我们用\\(255\\times255\\)，得到的数超过了\\(255\\)，也就是颜色的上限值，是不对的。我们转化一下，把\\(RGB\\)三个分量的值定为\\([0,1]\\)，用这个数字去进行计算。在最后屏幕上着色的时候，再转换回整数\\([0,255]\\)。\n你可能会问，我知道光有颜色，但是亮度怎么办？简单认为，一个颜色的0.9倍亮度，就是把每个分量都乘以0.9。更详细的我会在以后介绍（TODO）。\n镜面反射 有时候，这个材质比较光滑，在反射角（指\\(\\bm v\\)和\\(\\bm n\\)的夹角）等于入射角（指\\(\\bm l\\)和\\(\\bm n\\)的夹角），或者反射角很接近入射角时，光强会明显强于其他角度。\n4.jpg\r出现这种情况的时候，不仅反射角很接近入射角，而且可以推出，半程向量\\(\\bm h\\)非常接近法向量\\(\\bm n\\)\n所谓的半程向量就是\\(\\bm l,\\bm v\\)的角平分线的单位向量，有\n\\[\\bm h = \\dfrac{\\bm v+\\bm l}{||\\bm v+\\bm l||} \\]\n此时相机接收到的光强就是\n\\[L_s = k_s I \\max(0,\\bm n\\cdot\\bm h)^p \\]\n其中\\(k_s\\)是镜面反射系数，而\\(p\\)决定了\\(\\bm n\\)和\\(\\bm h\\)有多接近才算触发镜面反射。\\(p\\)越大，触发的范围越小，通常\\(p\\geq 100\\)。\n\\(L_s,k_s,I\\)也都是三维向量，并且乘法也是分量各自相乘。\\(k_s\\)会采用比较亮的白色，而不是其他颜色。\n环境光反射 你可以把环境光当成是房间里的其他物体的漫反射经过非常多次再-漫反射，最终照射到该物体上的光。Blinn-Phong模型中，直接采取了取用常数的简单处理办法。\n\\[L_a = k_aI_a \\]\n\\(L_a,k_a,I_a\\)也都是三维向量，并且乘法也是分量各自相乘。\\(k_s\\)会采用比较暗的白色，而不是其他颜色。\\(I_a\\)通常也是比较暗的颜色。\n反射组合 直接加一起即可\n\\[L = L_a+L_d+L_s \\]\n使用例子 我们把上一节所讲的人物模型拿出来使用一下。\n用**这个链接** 中的代码（需要去下载模型文件放到代码中的指定文件夹，见**链接** ），我们可以得到如下的效果图\n1.jpg\r看上去还好，细看的话发现眼睛、嘴巴、耳朵一塌糊涂，这实际上是因为三角形的前后关系导致覆盖而出现的结果，在下一部分我们将介绍Z-buffer算法来解决这个问题。\n","date":"2023-08-04T21:25:38+08:00","image":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E5%85%89%E7%85%A7%E5%88%9D%E6%AD%A5/cover_hu04f6e4c5c5d9e8c832c6dfeafddfe37e_257114_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E5%85%89%E7%85%A7%E5%88%9D%E6%AD%A5/","title":"从零开始的软渲染器 光照初步"},{"content":"导航页面\nOBJ格式简介 .obj格式是描述几何模型的一种简单办法。它可以描述顶点的坐标、法向量、纹理坐标，以及三角面的顶点数据等等。\n注释\n.obj格式里的注释是以#开头的一行\n顶点坐标\n例如\nv 0.511631 -0.845357 0.127832 v 0.608654 -0.568839 -0.416318 v 0.424663 -0.649937 -0.567418 ... 以v开头，后面带三个小数。注意这个坐标是模型相对于自己原点的坐标，而不是我们渲染过程中的世界坐标。它不会提供总数，只会一条一条地提供。\n读取的时候需要注意自己统计总数，另外还要记录序号（写在数组里没有这个问题）。以及序号从\\(1\\)开始计数。\n纹理坐标\n例如\nvt 0.617 0.575 0.000 vt 0.623 0.573 0.000 vt 0.627 0.576 0.000 ... 以vt开头，后面还是带三个数。通常我们的纹理是二维的，所以第三个会是零。这里的纹理坐标指的是在纹理图片文件上的坐标。显然你会怀疑，纹理图片的大小不是800x800这种形式的吗？为什么这里是小数？\n我认为是为了统一，我们只要用坐标乘以宽度、长度，再四舍五入即可得到图片上的像素坐标。\n法向量方向\n例如\nvn -0.250 0.462 -0.851 vn -0.192 0.568 -0.801 vn -0.359 0.279 0.891 ... 描述了法向量指向的方向。\n注意可能并不是单位向量，我没有找到限制必须是单位向量的规定。\n注意\n上面这三种数据总数不一定是一样的，它们之间的关联也不是一定是序号对应的。大部分时候不一样，也不对应。它们只是描述了一组这样的数据而已，具体到三角面上，才会体现如何使用这些数据。\n使用这些数据时，序号就变得重要了起来。再次提醒序号从\\(1\\)开始计数。\n三角面信息\n例如\nf 1206/1252/1206 1207/1254/1207 1205/1255/1205 f 1206/1252/1206 1208/1256/1208 1086/1257/1086 f 1206/1252/1206 1086/1257/1086 1087/1253/1087 ... 以f开头，带了三组数据。每组都有三个数字。带有三个数字是因为要描述三角面的三个顶点。\n第一组，描述了三个顶点的（模型）空间坐标。这三个数字是序号，我们用序号去访问数组即可得到坐标。\n第二组，描述了三个顶点的材质uv坐标，也是序号。\n第三组，描述了三个顶点的法向量坐标，也是序号。\n我们目前了解以上信息即可。\nmodel.h 首先我们需要定义一下model里面要有什么内容。\nstd::vector\u0026lt;geo::vec3f\u0026gt; vertices{}; std::vector\u0026lt;geo::vec2f\u0026gt; tex_coords{}; std::vector\u0026lt;geo::vec3f\u0026gt; norms{}; std::vector\u0026lt;size_t\u0026gt; face_vi{}; std::vector\u0026lt;size_t\u0026gt; face_ti{}; std::vector\u0026lt;size_t\u0026gt; face_ni{}; 我们需要三维的顶点坐标、二维的纹理uv坐标，以及三维的顶点法向量坐标。同时也需要记录每个三角面它的顶点坐标序号，纹理坐标序号以及法向量坐标序号。\n再看看我们可能需要什么方法：\nModel(std::string const \u0026amp; dir); ~Model(); size_t getFaceSize(); geo::vec3f getVert(size_t faceid, size_t nth); bool getTriangle(std::array\u0026lt;geo::vec3f,3\u0026gt; \u0026amp; dist, size_t faceid); bool getTriangle(std::array\u0026lt;geo::vec4f,3\u0026gt; \u0026amp; dist, size_t faceid); bool getNorm(std::array\u0026lt;geo::vec3f,3\u0026gt; \u0026amp; dist, size_t faceid); 一个构造函数和一个析构函数不用多说。\n之后我们可能需要提供获取三角面数量的函数、获取（某个特定）顶点坐标的函数，获取一个三角面上所有顶点坐标的函数（在这里我按需要提供了四维坐标和三维坐标的版本），以及获得三角面上所有顶点法向量的函数。\n之后我们还会在读取材质纹理的地方需要提供纹理坐标的函数。这里先略过。\n全部代码可见**链接**\nmodel.cpp 现在我们来看看具体要怎么实现\n构造函数 Model::Model(std::string const \u0026amp; dir){ std::ifstream in; in.open(dir,std::ifstream::in); if(in.fail()) return; std::string line; while(!in.eof()){ std::getline(in,line); std::istringstream iss(line); char discard; if(line.compare(0,2,\u0026#34;v \u0026#34;)==0){ iss\u0026gt;\u0026gt;discard; geo::vec3f v; for(int i=0;i\u0026lt;3;i++) iss\u0026gt;\u0026gt;v[i]; vertices.push_back(v); } else if(line.compare(0,3,\u0026#34;vt \u0026#34;)==0){ iss\u0026gt;\u0026gt;discard\u0026gt;\u0026gt;discard; geo::vec2f vt; for(int i=0;i\u0026lt;2;i++) iss\u0026gt;\u0026gt;vt[i]; tex_coords.push_back(vt); } else if (line.compare(0,3,\u0026#34;vn \u0026#34;)==0) { iss\u0026gt;\u0026gt;discard\u0026gt;\u0026gt;discard; geo::vec3f vn; for(int i=0;i\u0026lt;3;i++) iss\u0026gt;\u0026gt;vn[i]; norms.push_back(vn); } else if(line.compare(0,2,\u0026#34;f \u0026#34;)==0){ iss\u0026gt;\u0026gt;discard; size_t fv,ft,fn; while(iss\u0026gt;\u0026gt;fv\u0026gt;\u0026gt;discard\u0026gt;\u0026gt;ft\u0026gt;\u0026gt;discard\u0026gt;\u0026gt;fn){ face_vi.push_back(fv-1); face_ti.push_back(ft-1); face_ni.push_back(fn-1); } } } std::cerr\u0026lt;\u0026lt;\u0026#34;v: \u0026#34;\u0026lt;\u0026lt;vertices.size()\u0026lt;\u0026lt;\u0026#34; t: \u0026#34;\u0026lt;\u0026lt;tex_coords.size()\u0026lt;\u0026lt;\u0026#34; n: \u0026#34;\u0026lt;\u0026lt;norms.size()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; std::cerr\u0026lt;\u0026lt;\u0026#34;f: \u0026#34;\u0026lt;\u0026lt;face_ni.size()/3\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } 这其实没什么好多说的，把之前说过的OBJ文件格式理解一下，去实际看看obj文件里面怎么写的。如果掌握了ifstream，字符串的操作，整个操作就会了。\n需要注意的是，obj里面提供的序号是从\\(1\\)开始的，而我这里用的是往vector里push_back元素的办法，方便起见把所有序号都减\\(1\\)。\n获取坐标信息的函数 这一部分其实非常容易理解和实现，就把我们读入的数据，按照下标获取，然后返回即可。全部代码可见**链接**\n使用例子 #include \u0026#34;tga_image.h\u0026#34; #include \u0026#34;raster.h\u0026#34; #include \u0026#34;model.h\u0026#34; #include \u0026lt;ctime\u0026gt; #include \u0026lt;cstdlib\u0026gt; int const width = 1500; int const height = 1500;//设置输出图片的长宽 int main(){ Model model(\u0026#34;../obj/african_head.obj\u0026#34;);//读取我们的模型 TGAImage image(width,height,TGAType::rgb);//新建一个图对象 int nface = model.getFaceSize();//获取三角面的总数 std::array\u0026lt;geo::vec4f,3\u0026gt; vert;//读取顶点坐标 std::array\u0026lt;geo::OARColor,3\u0026gt; color;//设置顶点颜色 std::array\u0026lt;geo::vec2i,3\u0026gt; screen;//把顶点的空间坐标转化到屏幕像素坐标上 for(int i=0;i\u0026lt;nface;i++){ model.getTriangle(vert, i);//把序号为i的三角形的顶点全部读入vert for(int j=0;j\u0026lt;3;j++){ color[j] = geo::OARColor(255,255,255,255);//设置颜色为全白 screen[j] = ras::world2screen(vert[j],width,height);//转换坐标，函数定义见下 } ras::triangle(image,screen,color);//绘制三角形i号 } image.writeToFile(\u0026#34;./af.tga\u0026#34;);//写入图像文件 return 0; } 我们使用以上代码来测试我们的效果，具体步骤解释都写在上面的注释里了（模型见**链接** ）。\ngeo::vec2i ras::world2screen(geo::vec4f v, int width, int height){ return geo::vec2i(int((v.x+1.f)*width*.5f+.5f), int((v.y+1.f)*height*.5f+.5f)); } 我们的坐标转换函数如上（放在这里**链接** ），这里本来应该在坐标转换的地方讲，但是这里不得不用到，我们就提前讲一下。\n我们的物体模型，有他自己的坐标系。这个坐标的范围是\\([-1,1]^3\\)，但我们的显示屏只有两个维度，而且他还只有整数的坐标。为了将模型的坐标映射到显示屏上，我们首先压缩一维，也就是直接不考虑深度（这里是\\(z\\)轴），然后把\\([-1,1]^2\\)映射到\\(\\text{width}\\times\\text{height}\\)这个坐标上。我们分别对\\(x,y\\)进行操作，首先把\\(x\\)整体加\\(1\\)，就得到\\([0,2]\\)，再除以\\(2\\)，就得到\\([0,1]\\)，再乘以\\(\\text{width}\\)，再取四舍五入到整数就得到了显示屏上的横坐标，同理就得到了纵坐标。\n更进一步的知识等到坐标转换的地方再讲吧！\n结果如下：\n1.png\r虽然我们没有看清他的面容（因为我们把每个三角形都设置成全白了），但是至少整个形状正确了。稍后我们将介绍光照，来让他的面容展现出来。\n","date":"2023-06-25T14:37:37+08:00","image":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E6%A8%A1%E5%9E%8B%E5%BA%93/cover_hu1d5ada73bf6b5a759e3568aecd125470_50161_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E6%A8%A1%E5%9E%8B%E5%BA%93/","title":"从零开始的软渲染器 模型库"},{"content":"读前警示 出于Obsidian不支持\\bm的标签的原因，也出于我打字方便、教科书也没用加粗的原因，从某一段开始的瞬间，很多地方都不会使用粗体来表示向量。这其实无所谓，我们可以把标量看做一维向量。我们的大部分讨论都是在向量之上的，除了部分参数是标量。大部分矩阵是大写字母。\n阅读时应结合前后文理解一个符号是什么意思。\n数学基础概念、定义 向量内积 在\\(n\\)维线性空间\\(R^n\\)中，\\(\\bm a = [a_1,a_2,\\cdots,a_n]^T\\in R^n,\\bm b = [b_1,b_2,\\cdots,b_n]^T\\in R^n\\)，则\n\\[\\bm a^T b = a_1b_1+a_2b_2+\\cdots,a_nb_n \\]\n称作向量\\(\\bm a,\\bm b\\)的内积。\n内积满足交换律，线性，以及正定性：\\(\\bm a^T \\bm a\\geq 0\\)，当且仅当\\(\\bm a=\\bm 0\\)时，取等号。\n其他各种性质都在线性代数中学过了，这里只是简单回顾。\n向量范数 称一个从向量空间\\(R^n\\)到实数域\\(R\\)的非负函数\\(||\\cdot||\\)为范数，如果它满足：\n正定性：对于所有的\\(\\bm v\\in R^n\\)，有\\(||\\bm v||\\geq 0\\)，且\\(||\\bm v||=0\\)当且仅当\\(\\bm v=0\\) 齐次性：对于所有的\\(\\bm v\\in R^n\\)和\\(\\alpha\\in R\\)，有\\(||\\alpha\\bm v||=|\\alpha|||\\bm v||\\) 三角不等式：对于所有的\\(\\bm v,\\bm w\\in R^n\\)，有\\(||\\bm v+\\bm w||\\leq ||\\bm v||+||\\bm w||\\) 对于\\(\\bm v = (v_1,v_2,\\cdots,v_n)^T\\)，常见的向量范数为\\(\\mathscr{l}_n\\)范数\\((p\u003e=1)\\)\n\\[||v||_p = (|v_1|^p+|v_2|^p+\\cdots+|v_3|^p)^{1/p} \\]\n当\\(p=\\infty\\)时，\\(\\mathscr{l}_\\infty\\)定义为\n\\[||v||_\\infty = \\max_i|v_i| \\]\n一些地方也可以见到\\(0\\)-范数，其表示分量中不为零的个数。\n最常见的是\\(2\\)-范数，又称欧几里得范数，常常\\(||\\cdot||\\)省略角标不写表示\\(2\\)-范数。\n二次型 \\(n\\)维二次函数可以表示如下\n\\[f(x_1,x_2,\\cdots,x_n)=a_{11}x_1^2+a_{12}x_1x_2+\\cdots+a_{1n}x_1x_n+a_{21}x_2x_1+\\cdots+a_{nn}x^2_n \\]\n其可以表示为向量矩阵形式\n\\[\\sum^n_{i=1}\\sum^n_{j=1}a_{ij}x_ix_j=\\bm x^T A \\bm x \\]\n这个\\(A\\)矩阵是个实对称矩阵，其元素\\(a_{ij}=a_{ji}\\)，是对应的\\(x_ix_j\\)项系数的一半（原式子出于简单起见没有把同类项合并）。\n正定矩阵 如果正定二次型\\(f(\\bm x)=\\bm x^TA\\bm x\\)，对于一组不全为零的数\\(x_1,x_2,\\cdots,x_n\\)，恒有\\(f(x_1,x_2,\\cdots,x_n)\u003e0\\)，则称\\(f\\)正定，\\(A\\)为正定矩阵。若换成\\(\\geq\\)，则称为半正定矩阵，若换成\\(\\leq\\)，则称为半负定矩阵。\n有两个判定定理\n\\(A\\)正定的充要条件为\\(A\\)的特征值都大于\\(0\\) \\(A\\)正定的充要条件为\\(A\\)的所有顺序主子式都大于\\(0\\) 方向导数 设\\(f:R^n\\to R\\)在点\\(\\bm x\\)处可微，\\(\\bm p\\)是固定不变的非零向量，\\(\\bm e\\)是方向\\(\\bm p\\)上的单位向量，则称极限\n\\[\\dfrac{\\partial f(\\bm x)}{\\partial \\bm p} = \\lim_{t\\to 0^+}\\dfrac{f(\\bm x+t\\bm e)-f(\\bm x)}{t} \\]\n为函数\\(f(x)\\)在点\\(\\bm x\\)处沿\\(\\bm p\\)方向的方向导数，记为\\(\\dfrac{\\partial f(\\bm x)}{\\partial\\bm p}\\)。当其大于零时，函数在该点沿此方向上升，小于零时沿此方向下降。\n梯度 给定函数设\\(f:R^n\\to R\\)，且\\(f\\)在点\\(\\bm x\\)的一个领域内有意义，若存在向量\\(\\bm g\\in R^n\\)满足\n\\[\\lim_{\\bm p\\to \\bm 0}\\dfrac{f(\\bm x+\\bm p)-f(\\bm x)-\\bm g^T\\bm p}{||\\bm p||}=0 \\]\n其中这个范数可以是任意向量范数，就称\\(f\\)在点\\(\\bm x\\)可微，此时\\(\\bm g\\)是\\(f\\)在点\\(\\bm x\\)处的梯度，记作\\(\\nabla f(x)\\)。可以计算，若令\\(\\bm p=\\epsilon \\bm e_i\\)，\\(\\bm e_i\\)是第\\(i\\)个分量为\\(1\\)的单位向量，可知\\(\\nabla f(x)\\)的第\\(i\\)个分量即为\\(\\dfrac{\\partial f(x)}{\\partial x_i}\\)。因此\n\\[\\nabla f(x) = \\bigg[\\dfrac{\\partial f(x)}{\\partial x_1},\\dfrac{\\partial f(x)}{\\partial x_2},\\cdots,\\dfrac{\\partial f(x)}{\\partial x_n}\\bigg]^T \\]\n一个非常浅显的事实是，一维向量函数的梯度就是它的一阶导数。\n梯度方向是函数在该点上升的最快方向，反方向是最速下降方向。\n梯度与方向导数的关系为\n\\[\\dfrac{\\partial f(\\bm x)}{\\partial \\bm p}=\\nabla f(\\bm x)^T\\bm e \\]\n其中\\(\\bm e\\)是\\(\\bm p\\)方向上的单位向量。\n\\(\\bigg|\\dfrac{\\partial f(\\bm x)}{\\partial \\bm p}\\bigg|\\leq |\\nabla f(\\bm x)^T|\\)\n梯度有几条显然的性质：\n若\\(\\nabla f(\\bm x)^T\\bm p\u003c0\\)，则\\(\\bm p\\)的方向是函数\\(f\\)在\\(\\bm x\\)处的下降方向 若\\(\\nabla f(\\bm x)^T\\bm p\u003e0\\)，则\\(\\bm p\\)的方向是函数\\(f\\)在\\(\\bm x\\)处的上升方向 梯度正交的方向变化率为零 海瑟矩阵 用一个简单的比方，梯度和海瑟矩阵的关系，就相当于一阶导数和二阶导数的关系。\n给定函数\\(f:R^n\\to R\\)，若其在点\\(\\bm x\\)处的二阶偏导数\\(\\dfrac{\\partial^2 f(\\bm x)}{\\partial \\bm x_i\\partial \\bm x_j},i,j=1,2,\\cdots,n\\)都存在，则\n\\[\\nabla^2f(\\bm x) = \\begin{bmatrix} \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_1^2} \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_1\\partial x_2} \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_1\\partial x_3} \u0026 \\cdots \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_1\\partial x_n}\\\\ \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_2\\partial x_1} \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_2^2} \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_2\\partial x_3} \u0026 \\cdots \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_2\\partial x_n}\\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_n\\partial x_1} \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_n\\partial x_2} \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_n\\partial x_3} \u0026 \u0026 \\dfrac{\\partial^2 f(\\bm x)}{\\partial x_n^2} \\end{bmatrix} \\]\n称为\\(f\\)在点\\(x\\)处的海瑟矩阵。\n泰勒展开 给定函数\\(f:R^n\\to R\\)，具有二阶连续偏导数，则\n\\[f(\\bm x+\\bm p) = f(\\bm x) + \\nabla f(\\bm x)^T\\bm p + \\dfrac{1}{2}\\bm p^T\\nabla^2 f(\\bm x)^T\\bm p + o(||\\bm p||^2) \\]\n其中\\(o(||p||^2)\\)当\\(||p||^2\\to 0\\)时，是关于\\(||p||^2\\)的高阶无穷小量。\n邻域 对于任意给定的实数\\(\\delta\u003e0\\)，满足不等式\\(||\\bm x-\\bm x_0||\u003c\\delta\\)的\\(\\bm x\\)的集合称为点\\(\\bm x_0\\)的邻域，记为\n\\[N(\\bm x_0,\\delta) = \\{\\bm x|\\ ||\\bm x-\\bm x_0||\u003c\\delta,\\delta\u003e0\\} \\]\n极小点 设\\(f:D\\subseteq R^n\\to R\\)，若存在点\\(\\bm x^*\\in D\\)和数\\(\\delta\u003e0\\)，\\(\\forall \\bm x\\in N(\\bm x^*,\\delta)\\cap D\\)，都有\\(f(\\bm x^*)\\leq f(\\bm x)\\)，则称\\(\\bm x^*\\)为\\(f(\\bm x)\\)的（非严格）局部极小点。\n设\\(f:D\\subseteq R^n\\to R\\)，若存在点\\(\\bm x^*\\in D\\)和数\\(\\delta\u003e0\\)，\\(\\forall \\bm x\\in N(\\bm x^*,\\delta)\\cap D\\)，但\\(\\bm x\\neq \\bm x^*\\)，都有\\(f(\\bm x^*)\u003c f(\\bm x)\\)，则称\\(\\bm x^*\\)为\\(f(\\bm x)\\)的严格局部极小点。\n设\\(f:D\\subseteq R^n\\to R\\)，若存在点\\(\\bm x^*\\in D\\)和数\\(\\delta\u003e0\\)，\\(\\forall \\bm x\\in D\\)，都有\\(f(\\bm x^*)\\leq f(\\bm x)\\)，则称\\(\\bm x^*\\)为\\(f(\\bm x)\\)的（非严格）全局极小点。\n设\\(f:D\\subseteq R^n\\to R\\)，若存在点\\(\\bm x^*\\in D\\)和数\\(\\delta\u003e0\\)，\\(\\forall \\bm x\\in D\\)，但\\(\\bm x\\neq \\bm x^*\\)，都有\\(f(\\bm x^*)\\leq f(\\bm x)\\)，则称\\(\\bm x^*\\)为\\(f(\\bm x)\\)的严格全局极小点。\n如果\\(\\bm x^*\\)是极小点并且是\\(D\\)的内点，则\\(\\nabla f(\\bm x^*)=0\\)。这是一个必要非充分条件。\n但如果\\(f\\)有连续二阶偏导数，\\(\\bm x^*\\)是一个驻点，并且\\(\\nabla^2 f(\\bm x^*)\\)是正定的，则\\(\\bm x^*\\)是\\(f(\\bm x)\\)的严格局部极小点。\n驻点 设\\(f:D\\subseteq R^n\\to R\\)，\\(\\bm x^*\\)是\\(D\\)的内点，若\\(\\nabla f(\\bm x^*)=0\\)，则称\\(\\bm x^*\\)为\\(f(\\bm x)\\)的驻点。\n锥 设集合\\(C\\subset R^n\\)，若对\\(\\forall\\bm x\\in C\\)以及\\(\\forall \\lambda\\geq 0\\)均有\\(\\lambda\\bm x\\in C\\)，则称\\(C\\)为锥\n凸组合 设\\(\\bm x_1,\\bm x_2,\\cdots,\\bm x_l\\)是\\(R^n\\)中的\\(l\\)个已知点。若对于某点\\(\\bm x\\in R^n\\)，存在常数\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_l\\geq 0\\)，且\\(\\sum\\lambda_i=1\\)，使得\\(\\bm x=\\sum\\lambda_i\\bm x_i\\)，则称\\(\\bm x\\)是\\(\\bm x_1,\\bm x_2,\\cdots,\\bm x_l\\)的凸组合。如果\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_l\u003e0\\)且\\(\\sum\\lambda_i=1\\)，则称为严格凸组合。\n凸集 对于\\(C\\subset R^n\\)中的任意两个点\\(\\bm x_1, \\bm x_2\\)，如果连接两个点的线段在\\(C\\)内，则称\\(C\\)为凸集。即\n\\[\\bm x_1,\\bm x_2\\in C\\Rightarrow\\theta \\bm x_1+(1-\\theta)\\bm x_2\\in C,\\forall 0\\leq\\theta\\leq 1 \\]\n定理1\n任意一组凸集的交仍然是凸集。\n特别的，规定空集是凸集。容易验证，空间\\(R^n\\)、半空间、超平面、直线、点、球都是凸集。\n凸集分离定理\n设\\(C_1,C_2\\)是\\(R^n\\)中两个非空的集合，\\(H=\\{\\bm x|\\bm p^T\\bm x=\\alpha\\}\\)为超平面，如果对\\(\\forall\\bm x\\in C_1\\)都有\\(\\bm p^T\\bm x\\geq \\alpha\\)，对\\(\\forall x\\in C_2\\)都有\\(\\bm p^T\\bm x\\leq \\alpha\\)（或二者正好相反），则称超平面\\(H\\)分离集合\\(C_1,C_2\\)\n半空间 设\\(\\bm a\\in R^n,\\bm a\\neq\\bm 0,b\\in R\\)，则集合\n\\[\\{\\bm x|\\bm a^T\\bm x\u003eb,\\bm x\\in R^n\\} \\]\n称为\\(R^n\\)的半空间。\n有限个半空间的交\\(\\{\\bm x|\\bm A\\bm x\\leq \\bm b\\}\\)称为多面集，其中\\(\\bm A\\)为\\(m\\times n\\)矩阵，\\(\\bm b\\)为\\(m\\)维向量。\n凸函数 广义实值函数\n令\\(\\bar R\\xlongequal{\\text{def}}R\\cup\\{\\pm\\infty\\}\\)为广义实数空间，则映射\\(f:R^n\\to\\bar R\\)为广义实值函数。\n规定\\(-\\infty\u003c a\u003c+\\infty,\\forall a\\in R\\)，以及\\((+\\infty)+(+\\infty)=+\\infty,(+\\infty)+a=+\\infty,\\forall a\\in R\\)\n适当函数\n给定广义实值函数\\(f\\)和非空集合\\(\\mathcal{X}\\)，如果存在\\(x\\in\\mathcal{X}\\)使得\\(f(x)\u003c+\\infty\\)，并且对任意的\\(x\\in\\mathcal{X}\\)，都有\\(f(x)\u003e-\\infty\\)，那么称函数\\(f\\)关于集合\\(\\mathcal{X}\\)是适当的。\n凸函数\n设函数\\(f\\)为适当函数，如果\\(\\text{dom} f\\)是凸集，且\n\\[f(\\theta x+(1-\\theta)y)\\leq \\theta f(x)+(1-\\theta)f(y) \\]\n对所有\\(x,y\\in\\text{dom}f,0\\leq\\theta\\leq 1\\)都成立，则称\\(f\\)是凸函数。\n如果\\(f(\\theta x+(1-\\theta)y)\u003c \\theta f(x)+(1-\\theta)f(y)\\)，则称为严格凸函数。\n性质1\n设\\(f_1,f_2\\)是凸集\\(C\\)上的凸函数，则函数\\(f_1+f_2\\)在\\(S\\)上也是凸函数。\n性质2\n设\\(f\\)是凸集\\(C\\)上的凸函数，则对任意的\\(a\\geq 0\\)，函数\\(af\\)也是凸函数。\n凸函数判定 \\(f\\)是凸函数，当且仅当对任意的\\(x\\in\\text{dom}f,v\\in R^n,g:R\\to R\\)\n\\[g(t)=f(x+tv),\\text{dom} g = \\{t|x+tv\\in\\text{dom} f\\} \\]\n是凸函数。\n一阶条件\n对于定义在凸集上的可微函数\\(f\\)，\\(f\\)是凸函数当且仅当\n\\[f(y)\\geq f(x)+\\nabla f(x)^T(y-x),\\forall x,y\\in\\text{dom}f \\]\n严格凸函数则要求\\(\u003e\\)号。物理意义是：任意点处的切线增量不超过函数的增量。\n梯度单调性\n设\\(f\\)为可微函数，则\\(f\\)为凸函数当且仅当\\(\\text{dom}f\\)为凸集且\\(\\nabla f\\)为单调映射，即\n\\[(\\nabla f(x)-\\nabla f(y))^T(x-y)\\geq 0,\\forall x,y\\in\\text{dom}f \\]\n二阶条件\n设\\(f\\)为定义在凸集上的二阶连续可微函数，则\\(f\\)是凸函数当且仅当\n\\[\\nabla^2 f(x)\\succeq 0,\\forall x\\in\\text{dom}f \\]\n如果\\(\\succ\\)，则是严格凸函数。\n或者，凸函数的充要条件是\\(\\nabla^2 f(x)\\)在\\(\\text{dom}f\\)上的任意点均半正定。\n线性规划 图解法 确定可行域 确定目标函数的等值线及优化方向 平行移动目标函数等值线，通过观察得到线性规划的最优解 高中已经学过很多次这个东西了，不再详细介绍。\n注意到，图解法只适用于有两个变量的情况，更高维的情况下，要用单纯形法。\n一般形式 一般形式如下\n\\[\\min f(x_1+x_2+\\cdots+x_n) = c_1x_1+c_2x_2+\\cdots+c_nx_n \\]\n\\[s.t. \\left\\{\\begin{matrix} a_{11}x_1+a_{12}x_2+\\cdots+a_{1n}x_n = b_1\\\\ a_{21}x_1+a_{22}x_2+\\cdots+a_{2n}x_n = b_2 \\\\ \\vdots \\\\ a_{m1}x_1+a_{m2}x_2+\\cdots+a_{mn}x_n = b_m\\\\ x_1,x_2,\\cdots,x_n\\geq 0 \\end{matrix}\\right. \\]\n一共包含\\(n\\)个决策变量，\\(m\\)个约束条件。其中对目标函数既可以求最大也可以求最小，约束条件可以是\\(=,\\leq,\\geq\\)。决策变量\\(x_i\\)通常非负，也有其他情况。\\(c_j\\)称为价值系数，\\(b_j\\)称为资源系数，\\(a_{ij}\\)称为约束系数、技术系数。\n利用矩阵，可以写作\n\\[\\min f(x) = c^Tx \\]\n\\[s.t. \\left\\{\\begin{matrix} Ax=b\\\\ x\\geq 0 \\end{matrix}\\right. \\]\n标准形式 标准形式有四个特征\n目标函数求\\(\\min\\) 约束条件两端用\\(=\\)连接 所有\\(b_i\\)非负 所有\\(x_i\\)非负 接下来介绍如何转换其他形式到标准形式（注意按顺序来）\n目标函数求最小值\n例如\\(\\min z=x_1-2x_2+3x_3\\)，等价于\\(\\max z'=-x_1+2x_2-3x_3\\)，其中\\(z'=-z\\)\n约束函数求最小值\n例如\\(-2x_1+6x_2-x_3\\leq3\\)，将其转化为 \\[-2x_1+6x_2-x_3+x_s=3 \\]\n\\(x_s\\)表示决策中尚未使用的那部分资源，所以称之为松弛变量。\\(x_s\\geq 0\\)\n例如\\(-2x_1+6x_2-x_3\\ge3\\)，将其转化为 \\[-2x_1+6x_2-x_3-x_s=3 \\]\n\\(x_s\\)表示决策中超过了实际需要的部分，因此常称它为剩余变量。\\(x_s\\geq 0\\)\n由上可见，既把函数从不等式转变成了等式，并且新添加的变量也是非负的，也不影响原来的目标函数。统一整个计算过程。\n\\(b_i\\)非负\n这个只需要将约束条件两端取反即可。\n\\(x_i\\)非负\n若\\(x_i\\leq 0\\)，则令\\(x'_i=-x_i\\)，此时\\(x'_i\\geq 0\\) 若\\(x_i\\)无约束，则令\\(x_i = x_i'-x_i'',x_i'\\geq0,x_i''\\geq0\\) 注意这里的变换要把变换也代入目标函数中\n线性规划解的基本性质 对于线性规划问题来说，可行解实际上是由约束条件构成的线性方程组的解。并且还满足非负约束条件，即决策变量都取非负值。\n我们假定线性规划问题的系数矩阵\\(A\\)的秩总等于其行数，\\(rank(A)=m\\)。这意味着系数矩阵\\(A\\)的各行是线性无关的，这也表明约束方程中的各个方程是相互独立的。\n由于\\(A\\)的秩为\\(m\\)，所以其必有一个\\(m\\times m\\)的子矩阵为\\(B\\)，其行列式不为零。\n我们将\\(A\\)的任意一个这样的子矩阵\\(B\\)称为线性规划问题的一个基。\n显然\\(B=[p_1,p_2,\\cdots,p_m]\\)，其中的每一个为基向量，与基向量对应的变量\\(x_j\\)称为基变量，\\(x_B = [x_1,x_2,\\cdots,x_m]^T\\)，其余称为非基变量，\\(x_N=[x_{m+1},x_{m+2},\\cdots,x_n]^T\\)。\n可以得到一个解\\(x=[x_B^T,x_N^T]^T=[x_1,x_2,\\cdots,x_m,0,\\cdots,0]^T\\)\n称\\(x\\)为该约束方程的基解，其中\\(x_b=B^{-1}b\\)\n对于满足非负约束条件的\\(x\\geq 0\\)（所有分量都大于等于\\(0\\)）的基解称为可行解，对应的基称为可行基。\n基可行解的非零分量个数小于\\(m\\)时，称为退化解。也就是说，不是所有基解都是可行解。\n定理1\n线性规划问题的基可行解是其可行域的顶点。\n定理2\n若可行域有界，线性规划问题的目标函数则一定在其可行域的极点上达到最优。\n单纯形法 前面提到，可行解一定在凸集的顶点上，但是，这个顶点的数量很可能非常大。单纯形法就是在这些顶点中优化的算法\n基本思路\n首先将线性规划问题化成标准形式 求出初始基本可行解 判断其是否为最优解 如果不是最优，则迭代到其相邻的基本可行解，并再次检验 单纯形法把寻优的目标集中在所有基本可行解（即可行域顶点）中。从一个初始的基本可行解出发，寻找一条达到最优基本可行解的最佳路径。\n确定初始基本可行解 确定初始的基本可行解等价于确定初始的可行基，一旦初始的可行基确定了，那么对应的初始基本可行解也就唯一确定.\n方便起见，不妨设\\(A\\)中的前\\(m\\)个系数列向量恰好构成一个可行基，即\\(A=(B|N)\\)\n其中\\(B=[p_1,p_2,\\cdots,p_m]\\)为基变量\\(x_1,x_2,\\cdots,x_m\\)的系数列向量构成的可行基。\n\\(N = [p_{m+1},p_{m+2},\\cdots,p_n]\\)为非基变量\\(x_{m+1},x_{m+2},\\cdots,x_n\\)的系数列向量构成的矩阵。\n即原始问题为\n\\[\\min z = c^Tx \\]\n\\[s.t.\\left\\{\\begin{matrix} Ax=b \\\\ x\\geq 0 \\end{matrix}\\right. \\]\n化为\n\\[\\min z = [c_B^T,c_N^T][x_B^T,x_N^T]^T \\]\n\\[s.t.\\left\\{\\begin{matrix} [B,N][x_B^T,x_N^T]^T=b \\\\ x_B,x_N\\geq 0 \\end{matrix}\\right. \\]\n乘法后得\n\\[\\min z = c_B^Tx_B+c_N^Tx_N \\]\n\\[s.t.\\left\\{\\begin{matrix} Bx_B+Nx_N=b \\\\ x_B,x_N\\geq 0 \\end{matrix}\\right. \\]\n计算出\\(x_B = B^{-1}b-B^{-1}Nx_N\\)，代入目标函数中，得到\n\\[\\min z = c_B^TB^{-1}b-(c_B^TB^{-1}N-c_N^T)x_N \\]\n\\[s.t.\\left\\{\\begin{matrix} x_B = B^{-1}b-B^{-1}Nx_N \\\\ x_B,x_N\\geq 0 \\end{matrix}\\right. \\]\n令\\(x_N=\\bm 0\\)，则\\(x_B=B^{-1}b\\)\n所以初始的基本可行解为\\(x=[x_B^T,0]^T\\)\n判断现行的基本可行解是否最优 假如求得一个基本可行解为\\(x=[x_B^T,0]^T\\)，那么\n\\[z = cx = [c_B^T,c_N^T][(B^{-1}b)^T,0]^T=c_B^TB^{-1}b \\]\n如果检验向量\\(\\sigma_N\\)满足\n\\[\\sigma_N^T = c_N^T - c_B^TB^{-1}N\\geq 0 \\]\n这个基本可行解就是最优解。检验向量的各个分量称为检验数。上面的\\(\\geq0\\)是指每个分量都\\(\\geq 0\\)\n特殊情况1\n如果\\(\\sigma_N^T\\geq 0\\)，其中存在一个检验数\\(\\sigma_{m+k}=0\\)，则线性规划问题有无穷多最优解\n特殊情况2\n\\(\\sigma_N^T\\)，其中存在一个检验数\\(\\sigma_{m+k}\u003c0\\)，且该检验数所对应的非基变量的系数列向量的全部系数都为负数或零，则线性规划问题无有界最优解。\n基本可行解的改进——基变换 如果现行的基本可行解\\(x\\)不是最优解，即在检验向量\\(σ_N^T=c_N^T－c_B^TB^{-1}N\\)中存在负的检验数，则需在原基本可行解\\(x\\)的基础上寻找一个新的基本可行解，并使目标函数值有所改善。\n具体做法是：\n先从检验数为负的非基变量中确定一个换入变量，使它从非基变量变成基变量， 再从原来的基变量中确定一个换出变量，使它从基变量变成非基变量。由此得到一个新的基本可行解。 换入变量的确定-最大减小原则\n假设检验向量\\(\\sigma_N^T = c_N^T-c_B^TB^{-1}N = [\\sigma_{m+1},\\sigma_{m+2},\\cdots,\\sigma_n]\\)。若其中有两个以上的检验数为负，那么为了使目标函数值下降最快，就要选取最小负检验数所对应的非基变量为换入变量。\n即若\\(\\sigma_{m+k}\\)是最小的，那么就要把\\(x_{m+k}\\)换入。\n换出变量的确定-最小比值原则\n如果确定\\(x_{m+k}\\)为换入变量，方程\\(x_B = B^{-1}b-B^{-1}Nx_N\\Rightarrow x_B = B^{-1}b-B^{-1}p_{m+k}x_{m+k}\\)\n其中\\(p_{m+k}\\)为\\(A\\)中与\\(x_{m+k}\\)对应的系数列向量。我们要在\\(x_B = (x_1,x_2,\\cdots,x_m)^T\\)中确定一个基变量为换出变量，可以按最小比值原则确定换出变量。\n\\[\\theta = \\min\\bigg\\{\\dfrac{(B^{-1}b)_i}{(B^{-1}p_{m+k})_i}\\bigg|(B^{-1}p_{m+k})_i\u003e0,1\\leq i\\leq m\\bigg\\} = \\dfrac{(B^{-1}b)_l}{(B^{-1}p_{m+k})_l} \\]\n则选择对应的\\(x_l\\)作为换出变量。这里的角标是因为\\(B^{-1}b\\)和\\(B^{-1}p_{m+k}\\)都是\\(m\\)维向量。\n用初等变换求改进了的基本可行解——旋转运算 假设\\(B\\)是可行基，则\n\\[Ax = b\\Rightarrow[B,N][x_B^T,x_N^T]^T = b\\Rightarrow [I,B^{-1}N][x_B^T,x_N^T]^T = B^{-1}b \\]\n令非基变量\\(x_N=\\bm 0\\)，则基变量\\(x_B = B^{-1}b\\)，基本可行解为\\(x=[(B^{-1}b)^T,0]^T\\)\n用逆阵\\(B^{-1}\\)左乘约束方程组的两端，等价于对方程组施以一系列的初等“行变换”。变换的结果是将系数矩阵\\(A\\)中的可行基\\(B\\)变换成单位矩阵\\(I\\)，把非基变量系数列向量构成的矩阵\\(N\\)变换成\\(B^{-1}N\\)，把向量\\(b\\)变换成\\(B^{-1}b\\)\n变换前后的方程组同解。\n且改进了的基本可行解\\(X'\\)只是在\\(X\\)的基变量的基础上用一个换入变量替代其中一个换出变量，其它的基变量仍然保持不变。这些基变量的系数列向量是单位矩阵\\(I\\)中的单位向量。为了求得改进的基本可行解\\(X'\\)，只需对增广矩阵\n\\[[I,B^{-1}N,B^{-1}b] \\]\n施行初等行变换，将换入变量的系数列向量变换成换出变量所对应的单位向量即可。\n表格单纯形法 1.jpg\r对偶问题原理 假设全是列向量。\n设原问题\\(P\\)为\n\\[\\min f(x) = c^Tx \\]\n\\[s.t. \\left\\{\\begin{matrix} Ax\\geq b\\\\ x\\geq 0 \\end{matrix}\\right. \\]\n则其对偶问题\\(D\\)为\n\\[\\max g(y) = b^Ty \\]\n\\[s.t. \\left\\{\\begin{matrix} A^Ty\\leq c\\\\ y\\geq 0 \\end{matrix}\\right. \\]\n对偶关系表 2.jpg\r对偶关系定理 弱对偶定理\n对偶问题(max)的任何可行解\\(Y^*\\)，其目标函数值总是不大于原问题(min)任何可行解\\(X^*\\)的目标函数值。\n对偶定理\n假如原问题或对偶问题之一具有有限的最优解，则另一问题也具有有限的最优解，且两者响应的目标函数值相等。假如一个问题的目标函数值是无界的，则另一问题没有可行解。\n互补松弛定理\n假设\\(X^*,Y^*\\)分别是原问题和对偶问题的可行解，\\(U^*\\)是原问题剩余变量的值，\\(V^*\\)是对偶问题松弛变量的值，则\\(X^*,Y^*\\)分别为原问题和对偶问题的最优解的充要条件是\n\\[X^*V^*+Y^*U^* = 0 \\]\n这个定理还表述为如下两个形式\n假如一个问题的某个变量取正数，则相应问题的另外一个约束条件必取等式 一个问题中的约束条件不取等式，则相应于另一个问题中的变量为零 说起来有些抽象，做题理解。\n一维搜索法 概念 对于一维无约束优化问题\n\\[\\min f(\\alpha) \\]\n求解极小点和极小值的数值迭代方法即为一维搜索方法。\n极小点的必要条件和充分条件见前。注意我们可以用充分条件求解最小值，但是并不是所有情况都能使用，比如函数不一定二阶可微。所以我们常使用迭代法。\n基本步骤 确定搜索区间\\([a,b]\\) 在区间内寻找最小点 优化算法的基本迭代公式为：\n\\[x^{k+1} = x^{k} + \\alpha^kd^k \\]\n其中\\(\\alpha^k\\)为搜索步长，\\(d^k\\)为搜索方向。\\(x^0\\)为人工给出的初始估计。\n终止条件 两次迭代的绝对误差\n\\[|f(x^{k+1})-f(x^k)|\u003c\\varepsilon,\\quad ||x^{k+1}-x^k||\u003c\\varepsilon \\]\n两次迭代的相对误差\n\\[\\dfrac{|f(x^{k+1})-f(x^k)|}{|f(x^k)|}\u003c\\varepsilon,\\quad \\dfrac{||x^{k+1}-x^k||}{||x^k||}\u003c\\varepsilon \\]\n目标函数梯度的模足够小\n\\[||\\nabla f(x^k)||\u003c\\varepsilon \\]\n搜索区间的确定 单谷（峰）函数 我们选取的区间使得函数是单股（峰的），这样我们有以下定理（单谷为例）\n设\\(f(x)\\)在\\([a,b]\\)上单谷，\\(x^*\\in[a,b]\\)是其极小点，\\(x_1\u003c x_2\\)是\\([a,b]\\)上任意两点。则：\n若\\(f(x_1)\\geq f(x_2)\\)，则\\(x^*\\in[x_1,b]\\) 否则\\(x^*[a,x_2]*\\) 进退算法（成功-失败法） 求取区间。\n选取初始点\\(a\\)和步长\\(h\\) 计算并比较\\(f(a),f(a+h)\\)。 若\\(f(a)\\geq f(a+h)\\)，则步长加倍，计算\\(f(a+3h)\\)。若\\(f(a+h)\\leq f(a+3h)\\)，则令\\(a_1=a,a_2=a+3h\\)，停止运算；否则步长加倍，并重复以上（计算\\(a+3h\\)和\\(a+7h\\)）。\n若\\(f(a)\u003c f(a+h)\\)，则步长变为\\(-h\\)，计算\\(f(a-h)\\)。若\\(f(a-h)\\geq f(a)\\)，则令\\(a_1=a-h,a_2=a+h\\)，停止运算；否则步长加倍，继续后退（计算\\(a-h\\)和\\(a-3h\\)）。\n二分法 已知区间\\([a,b]\\)，且\\(f(x)\\)在其中可微，求极小点\n计算\\(x_0=\\dfrac{a+b}{2}\\) 若\\(f'(x_0)\u003c0\\)，令\\(a = x_0\\)，转步骤\\(3\\)。若\\(f'(x_0)\u003e0\\)，令\\(b = x_0\\)，转步骤\\(3\\)。若\\(f'(x_0)=0\\)，停止，\\(x^*=x_0\\)。 若\\(|b-a|\u003c\\varepsilon\\)，则\\(x^*=\\dfrac{a+b}{2}\\)，停止，否则转步骤\\(1\\) 优点\n计算量少，而且总能收敛到一个局部极小点\n缺点\n收敛速度慢\n牛顿切线法 给定初始点\\(x_0,\\varepsilon\u003e0,k=0\\) 计算\\(f'(x_k),f''(x_k)\\) 若\\(|f'(x_k)|\u003c\\varepsilon\\)，停止，\\(x^*=x_k\\)，否则转步骤\\(4\\) 计算 \\[x_{k+1} = x_k - \\dfrac{f'(x_k)}{f''(x_k)} \\]\n令\\(k = k+1\\)，转步骤\\(2\\)\n优点\n收敛快，局部二阶收敛\n缺点\n计算二阶导数工作量大。对初始点要求高，需要初始点离极小点不太远，否则有可能使极小化发散或收敛到非极小点；局部收敛。\n黄金分割法 给定区间\\([a,b],\\varepsilon\u003e0\\) 计算\\(x_1 = a+0.382(b-a),x_2 = a+0.618(b-a),f(x_1),f(x_2)\\) 如果\\(f(x_1)\u003c f(x_2)\\)，则\\(b = x_2，x_2 = x_1,f_2=f_1,x_1 = a+0.382(b-a),f_1 = f(x_1)\\)。否则\\(a=x_1,x_1=x_2,f_1=f_2,x_2=a+0.618(b-a),f_2=f(x_2)\\) 判断\\(|a-b|\u003c\\varepsilon\\)，则跳转\\(5\\)，否则跳转\\(4\\) \\(x^*=0.5(a+b),f^*=f(x^*)\\)，终止。 优点\n不要求函数可微，计算量小，程序简单\n缺点\n收敛慢\n抛物线插值法 以二次插值法为例\n设置初始区间\\([x_1,x_3]\\)，和一中间点\\(x_2\\)，一般为区间中点，设置\\(\\varepsilon\u003e0\\) 计算\\(f_1,f_2,f_3\\)，计算 \\[\\overline{x} = \\dfrac{1}{2}(x_1+x_3-\\dfrac{c_1}{c_2}) \\]\n其中\n\\[c_1 = \\dfrac{f_1-f_3}{x_1-x_3}, c_2 = \\dfrac{\\dfrac{f_1-f_2}{x_1-x_2}-c_1}{x_2-x_3} \\]\n计算\\(f(\\overline{x})\\)\n若\\(\\overline{x}\u003c x_2\\)，则新区间为\\([x_1,x_2]\\)，否则新区间为\\([x_2,x_3]\\)。如果\\(|x_2-\\overline{x}|\u003c\\varepsilon\\)，停止迭代，进入\\(4\\)。新中间点为\\(\\overline{x}\\)，返回\\(2\\) \\(x^*=\\overline{x},f^*=f(\\overline{x})\\)，终止。 优点\n不要求函数可微，计算量小，程序简单，比黄金分割法快\n缺点\n不如黄金分割法可靠\n无约束最优化方法 本章和上章一样都是无约束问题，但是本章的函数是\\(f:R^N\\to R\\)\n搜索步长准则 Armijo准则 设\\(d^k\\)是\\(x^k\\)处的下降方向，若\n\\[f(x^k+\\alpha d^k)\\leq f(x^k)+c_1\\alpha \\nabla f(x^k)^Td^k \\]\n则称步长\\(\\alpha\\)满足Armijo准则，其中\\(c_1\\in (0,1)\\)是一个常数（通常很小，1e-3）\n它有一些缺点，例如\\(\\alpha=0\\)显然满足条件\nGoldstein准则 \\[f(x^k+\\alpha d^k)\\leq f(x^k)+c\\alpha \\nabla f(x^k)^Td^k \\]\n\\[f(x^k+\\alpha d^k)\\geq f(x^k)+(1-c)\\alpha \\nabla f(x^k)^Td^k \\]\n则称步长\\(\\alpha\\)满足Goldstein准则，其中\\(c\\in (0,\\dfrac{1}{2})\\)是一个常数。\n它克服了Armijo的困难。第一个公式保证了其有足够的下降，第二个公式保证了步长足够大。\n最速下降法 迭代格式为\n\\[x^{k+1} = x^k - \\alpha_k\\nabla f(x^k) \\]\n显然，这个方法就是选取方向\\(d^k = -\\nabla f(x^k)\\)，也就是最快下降方法。我们通常会记\\(g(x) = \\nabla f(x)\\)。\n终止准则为\\(||g(x^{k+1})||\\leq \\varepsilon\\)\n\\(\\alpha_k\\)可以设定为常数，也可以用线搜索算法确定。设定为常数时不会有锯齿状况，只有线搜索出来的最优步长会锯齿。\n最优步长为\n\\[t_k = \\arg\\min_t f(x^k-t\\nabla f(x^k)) \\]\n线搜索得到\\(\\alpha_k\\)的方法为回退法。其满足Armijo准则。首先给定初值\\(\\hat{\\alpha}\\)，回退发同步不断以指数方式缩小试探步长，找到第一个满足Armijo准则的点。\n选择初始步长\\(\\hat{\\alpha}\\),参数\\(\\gamma,c\\in(0,1)\\)（经验上来说，选择\\(\\gamma\\)接近\\(1\\)比如0.95，\\(c\\)很小，比如1e-3），初始化\\(\\alpha\\leftarrow\\hat{\\alpha}\\) 当\\(f(x^k+\\alpha d^k)\u003ef(x^k)+c\\alpha\\nabla f(x^k)^T d^k\\)时，令\\(\\alpha\\leftarrow \\gamma\\alpha\\) 输出\\(a_k = \\alpha\\) 正定二次函数情况\n如果\\(f(x) = \\dfrac{1}{2}x^TAx+b^Tx+c\\)\n则最优步长为\n\\[\\alpha_k = \\dfrac{||\\nabla(f^k)||^2}{\\nabla f(x^k)^TA\\nabla f(x^k)} \\]\n也可以写作\n\\[\\alpha_k = \\dfrac{g_k^Tg_k}{g_k^TAg_k} \\]\n优点\n算法简单、计算量小、占用内存小\n缺点\n收敛速度慢，前后两次的搜索方向是正交的（仅限于最优步长情况），容易困在局部最优，还可能被困在鞍点\n随机梯度降 我们的优化目标变为了\n\\[\\min f(x) = \\dfrac{1}{N}\\sum^N_{i=1}f_i(x) \\]\n其中\\(f_i(x)\\)对应第\\(i\\)个样本的损失函数。\n按照最速下降法的要求，\n\\[x^{k+1} = x^k - \\alpha_k\\nabla f(x^k) \\]\n我们的梯度为\n\\[\\nabla f(x^k) = \\dfrac{1}{N}\\sum^N_{i=1}\\nabla f_i(x^k) \\]\n通常，这个量会很大，我们不能简单的得到梯度。于是我们用到了随机梯度降\n\\[x^{k+1} = x^k - \\alpha_k\\nabla f_{S_k}(x^k) \\]\n其中\\(s_k\\)是从\\(\\{1,2,\\cdots,N\\}\\)中随机等可能的抽取的一个样本。\\(\\alpha_k\\)是步长，在人工智能算法中也叫做学习率。\n可以推断得到\n\\[E_{S_k}[\\nabla f_{S_k}(x^k)|x^k] = \\nabla f(x^k) \\]\n优缺点\n同下\n小批量随机梯度降 即抽取元素比较少的集合\\(B_k\\in \\{1,2,\\cdots,N\\}\\)\n\\[x^{k+1} = x^k - \\dfrac{\\alpha_k}{|B_k|}\\sum_{s\\in B_k}\\nabla f_{s}(x^k) \\]\n其中\\(|B_k|\\)为元素个数，又叫batch-size。大小为1时就是随机梯度降，大小和训练样本数据一样大时，算法就是梯度下降。\n优点\n同梯度降\n缺点\n学习率选取较为困难，容易收敛到局部最优，还可能被困在鞍点\n动量法 \\[v^{k+1} = \\mu_k v^k - \\alpha_k\\nabla f_{S_k}(x^k) \\]\n\\[x^{k+1} = x^k + v^{k+1} \\]\n其中\\(\\mu_k\\in [0,1)\\)，通常取\\(\\mu_k\\geq 0.5\\)，代表具有较大的惯性。\\(\\mu_k=0\\)时退化成随机梯度降。\n优点\n和上一次梯度方向一致时，能很好的加速。能够跳出局部最优。在梯度改变方向的时候，能减少迭代次数\nNesterov算法 \\[v^{k+1} = \\mu_k v^k - \\alpha_k\\nabla f_{S_k}(x^k+\\mu_k v^k) \\]\n\\[x^{k+1} = x^k + v^{k+1} \\]\n即提前预估了下一次参数所在的位置。\nAdaGrad 该方法可以自发调整参数。\n令\\(g^k = \\nabla f_{S_k}(x^k)\\)\n引入向量\n\\[G^k = \\sum^k_{i=1}g^i\\odot g^i \\]\n其中\\(\\odot\\)代表向量的对应分量相乘，然后再组合成新的向量。\n迭代格式为\n\\[x^{k+1} = x^k-\\dfrac{\\alpha}{\\sqrt{G^k+\\varepsilon}}\\odot g^k \\]\n\\[G^{k+1} = G^k + g^{k+1}\\odot g^{k+1} \\]\n这里\\(\\alpha\\)为初始步长，\\(\\varepsilon\u003e0\\)是防止除零操作。\n缺点\n随着迭代次数的增加，\\(G^k\\)越来越大，使得\\(\\dfrac{\\alpha}{\\sqrt{G^k+\\varepsilon}}\\to 0\\)，梯度消失\nRMSProp 为了解决学习率趋于\\(0\\)的问题，引入一个\\(\\rho\\in[0,1)\\)\n\\[x^{k+1} = x^k-\\dfrac{\\alpha}{\\sqrt{M^k+\\varepsilon}}\\odot g^k \\]\n\\[M^{k+1} = \\rho M^k + (1-\\rho) g^{k+1}\\odot g^{k+1} \\]\nAdaDelta 令\n\\[g'_k = \\sqrt{\\dfrac{\\Delta x^k+\\varepsilon}{M^k+\\varepsilon}}\\odot g^k \\]\n迭代如下\n\\[x^{k+1} = x^k-g'_k \\]\n\\[M^{k+1} = \\rho M^k + (1-\\rho) g^{k+1}\\odot g^{k+1} \\]\n\\[\\Delta x^{k+1} = \\rho \\Delta x^k + (1-\\rho)g'_k\\odot g'_k \\]\nAdam 可以算是RMSProp和动量方法的缝合方法，Adam不直接使用随机梯度作为基础的更新方向，而是选择了一个动量项进行更新：\n\\[S^k = \\rho_1 S^{k-1} + (1-\\rho_1)g^k \\]\n与此同时又和RMSProp相似：\n\\[M^k = \\rho_2 M^{k-1} + (1-\\rho_2) g^k\\odot g^k \\]\n并不使用这两个量进行更新，而是先修正\n\\[\\hat S^k = \\dfrac{S^k}{1-\\rho_1^k}, \\hat M^k = \\dfrac{M^k}{1-\\rho_2^k} \\]\n这里\\(\\rho_1^k,\\rho_2^k\\)是其\\(k\\)次方。然后使用如下公式更新：\n\\[x^{k+1} = x^k - \\dfrac{\\alpha}{\\sqrt{\\hat M^k+\\varepsilon}}\\odot \\hat S^k \\]\n这里的参数\\(\\rho_1\\)通常选为\\(0.9\\)，\\(\\rho_2\\)通常选为\\(0.999\\)，全局步长\\(\\alpha = 0.001\\)\n牛顿法 牛顿法和一维搜索里面的那个基本就是一样的。\n\\[x^{k+1} = x^k - \\dfrac{\\nabla f(x^k)}{\\nabla ^2f(x^k)} \\]\n它的步长恒为\\(1\\)，停止条件为\\(||\\nabla f(x^k)||\u003c\\varepsilon\\)\n修正牛顿法 第一个修正是修正在其步长上，我们不再使用固定步长\\(1\\)，而是像梯度下降法一样，使用线搜索方法确定一个步长。\n第二个修正是在海瑟矩阵上。海瑟矩阵在高维的时候既不容易计算也不容易储存，并且如果海瑟矩阵不正定，下降方向可能会很差。为此，我们求解下降方向\\(d^k\\)时，首先确定矩阵\\(E^k\\)使得矩阵\\(B^k\\xlongequal{\\text{def}}\\nabla^2f(x^k)+E^k\\)正定且条件数较小，之后求解修正的牛顿方程\\(B^k d^k=-\\nabla f(x^k)\\)得到方向\\(d^k\\)。\n迭代方程还是\\(x^{k+1}=x^k+\\alpha_kd^k\\)\n拟牛顿法 拟牛顿算法直接放弃计算海瑟矩阵，而是找到一个具有类似性质的、方便维护的矩阵去替代。\nDFP更新公式 定义矩阵\\(H^0=I\\)，其更新公式为\n\\[H^{k+1} = H^k + \\dfrac{s^k(s^k)^T}{(y^k)^Ts^k} - \\dfrac{H^ky^k(H^ky^k)^T}{(y^k)^TH^ky^k} \\]\n其中\\(s^k = x^{k+1}-x^k, y^ k= g^{k+1}-g^{k}\\)\n优化算法的迭代公式是\n\\[x^{k+1} = x^k - \\alpha_kH^k\\nabla f(x^k) \\]\n其中\\(\\alpha_k\\)用线搜索确定。注意这里的\\(H\\)直接就具有海瑟逆矩阵的性质，不用写到分母上了。\n共轭方向法 思想：为了克服锯齿现象，假设能够选定下一次迭代的搜索方向直指极小点\\(X^*\\) ，那么对于二元二次函数只需依次沿搜索方向\\(d^0,d^1\\)进行两次精确一维搜索就可以求到极小点\\(X^*\\)。此时两个方向需要满足\\((d^0)^T A d^1\\)（假设二元二次函数为\\(f(x)=\\dfrac{1}{2}x^tAx+bx+c\\)）\n定义1\n设\\(A\\in R^{n\\times m}\\)是对称正定矩阵，\\(p_1,p_2\\in R^n\\)，如果\\(p_1^TAp_2=0\\)，则称这两个向量是\\(A\\)共轭（\\(A\\)正交）的。\n如果有限个非零向量\\(p_1,p_2,\\cdots,p_m\\)，它们任意两个不同的向量都是\\(A\\)共轭的，则称这一组向量为\\(A\\)共轭方向组，也称它们是一组\\(A\\)的共轭方向。\n注意特殊情况，当\\(A=I\\)时，这些向量就是普通的正交向量。\n定理1\n如果\\(R^n\\)中的非零向量\\(p_1,p_2,\\cdots,p_m(m\\leq n)\\)是\\(A\\)共轭向量组，则这\\(m\\)个向量是线性无关的。\n定理2\n设\\(n\\)元函数\\(f(x)=\\dfrac{1}{2}x^tAx+bx+c\\)且\\(A=A^T\\)正定，又设\\(n\\)维向量组\\(p_1,p_2,\\cdots,p_n\\)是\\(A\\)共轭向量组，从任意点\\(x^1\\)出发，依次以该向量组为搜索方向进行精确一维搜索，则\n\\(\\nabla f(x^{k+1})\\)与\\(p_1,p_2,\\cdots,p_k\\)正交 最多迭代\\(n\\)次必达到二次函数的极小点。 在下降迭代法中，若取下降方向是共轭方向，所得到的方法我们称为共轭方向法。\n共轭梯度法 共轭方向的选择很多，但是效果不一样。共轭梯度法是一种好的选择共轭方向的办法。\n初始方向为\n\\[d^0 = -\\nabla f(x^0) \\]\n它的方向的更新公式是\n\\[d^{k+1} = -\\nabla f(x^{k+1}) + \\rho_k d^k \\]\n\\[\\rho_k = \\dfrac{\\nabla f(x^{k+1}) Ad^k}{(d^k)^TAd^k} \\]\n总的优化迭代公式仍然是\n\\[x^{k+1} = x^k + \\alpha_k d^k \\]\n步长仍然用线搜索确定。\nFR共轭梯度法 简单地说，就是\n\\[\\rho_k = \\dfrac{||g^{k+1}||^2}{||g^k||^2} \\]\n其他不变。在正定二次函数中，这两个计算\\(\\rho^k\\)的方法是等价的。但是这个函数看着更简单好用一些。\n有约束最优化方法 对于\n\\[\\min f(x) \\]\n\\[s.t. \\left\\{\\begin{matrix} g_i(x)\\geq 0,i=1,2,\\cdots,m\\\\ h_j(x)=0,j=1,2,\\cdots,l \\end{matrix}\\right. \\]\n这样的有不等式和等式约束的优化问题。我们用罚函数法。其本质思想是把处于可行域之外的点，加一个惩罚项，让它搜索路径向着可行域前进。对于可行域内的点则不做惩罚。\n外点罚函数法 等式约束的二次罚函数\n\\[P_E(x,\\sigma) = f(x) + \\dfrac{1}{2}\\sigma\\sum^l_{j=1}h_j^2(x) \\]\n等式右边第二项称为惩罚项，其中\\(\\sigma\u003e0\\)称为罚因子。（这里这个\\(\\dfrac{1}{2}\\)有些教材有有些没有，我不知道为什么，但我觉得没有明显影响）\n不等式约束的二次罚函数\n\\[P_I(x,\\sigma) = f(x) + \\dfrac{1}{2}\\sigma\\sum^m_{i=1}\\min\\{g_i(x),0\\}^2 \\]\n也不难理解，总之我们要使在可行域内的惩罚项设置为\\(0\\)。注意这里是\\(\\min\\)，因为我们的不等式约束是\\(\\geq0\\)型，如果是\\(\\leq0\\)型，要么改变不等式，要么改成\\(\\max\\)\n如果约束既有不等式的又有等式的，那么直接把惩罚项加起来即可。\n计算机迭代办法\n给定\\(\\sigma_0\u003e0,x^0,k=0\\)。罚因子增长函数\\(\\rho\u003e1\\) 当未达到收敛准则时，进行以下计算 求解\\(\\displaystyle {x^{k+1} = \\arg \\min_x P(x,\\sigma_k)}\\) 选取\\(\\sigma_{k+1} = \\rho\\sigma_{k}\\) \\(k = k+1\\) 解析法求解\n我们令\n\\[\\dfrac{\\partial P(x,\\sigma)}{\\partial x_i} = 0 \\]\n对于所有的\\(x\\)的分量\\(x_i\\)成立。然后我们求出所有\\(x_i\\)的表达式\n\\[x_i = F_i(\\sigma) \\]\n则我们的最优解就是\n\\[x^*_i = \\lim_{\\sigma\\to+\\infty}F_i(\\sigma) \\]\n内点罚函数法 只适用于不等式优化的，其罚函数有两种\n\\[P_I(x,\\sigma) = f(x) + \\sigma\\sum^m_{i=1}\\dfrac{1}{g_i(x)} \\]\n和\n\\[P_I(x,\\sigma) = f(x) - \\sigma\\sum^m_{i=1}\\ln(g_i(x)) \\]\n显然，我们需要选择的初始点要在可行域内，而外点罚函数不需要。\n计算机迭代办法\n给定\\(\\sigma_0\u003e0,x^0,k=0\\)。罚因子增长函数\\(\\rho\\in(0,1)\\) 当未达到收敛准则时，进行以下计算 求解\\(\\displaystyle {x^{k+1} = \\arg \\min_x P(x,\\sigma_k)}\\) 选取\\(\\sigma_{k+1} = \\rho\\sigma_{k}\\) \\(k = k+1\\) 解析法求解\n我们令\n\\[\\dfrac{\\partial P(x,\\sigma)}{\\partial x_i} = 0 \\]\n对于所有的\\(x\\)的分量\\(x_i\\)成立。然后我们求出所有\\(x_i\\)的表达式\n\\[x_i = F_i(\\sigma) \\]\n则我们的最优解就是\n\\[x^*_i = \\lim_{\\sigma\\to0}F_i(\\sigma) \\]\n混合罚函数法 我们知道，外点罚函数可以用于等式和不等式优化，而内点罚函数可以用于不等式优化。我们可以进行一个缝合，把等式约束的用外点罚函数，把不等式优化的用内点罚函数。\n罚函数的统一形式为\n\\[P(x,\\sigma) = f(x) + E(x,\\sigma) + I(x,\\sigma) \\]\n其中\\(E(x,\\sigma)\\)只有一种选择\n\\[E(x,\\sigma) = \\dfrac{1}{\\sqrt{\\sigma}}\\sum^l_{j=1}h_j^2(x) \\]\n\\(I(x,\\sigma)\\)则有三种选择\n\\[I(x,\\sigma) = \\dfrac{1}{\\sqrt{\\sigma}}\\sum^m_{i=1}\\min\\{g_i^2(x),0\\} \\]\n\\[I(x,\\sigma) = \\sigma\\sum^m_{i=1}\\dfrac{1}{g_i(x)} \\]\n\\[I(x,\\sigma) = -\\sigma\\sum^m_{i=1}\\ln(g_i(x)) \\]\n进行组合即可。\n注意内点罚函数需要起始点在可行域内。\n","date":"2023-06-16T19:47:47+08:00","image":"https://kegalas.top/p/%E6%9C%80%E4%BC%98%E5%8C%96%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/cover_hu54576080547634ea0a125cfdafb2aa8f_63775_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E6%9C%80%E4%BC%98%E5%8C%96%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"最优化理论学习笔记"},{"content":"数制和编码 十进制、二进制、八进制、十六进制及其转换 过于简单，不多介绍。可以在计组笔记里找到\n反码、补码和补码运算 也可以在计组笔记中找到。\n十进制代码 每四位二进制对应一个十进制数。\n主要有8421(BCD)、2421、5211、余3码、余3循环码。\n8421，2421，5211是三种恒权代码，另外两个不是。\n其中余3码就是在BCD码上加\\(3\\)得到的。余3循环码的特点是相邻的两个代码之间仅有一位状态不同。至于余3循环码怎么得到，看格雷码\n需要注意的是他们的禁止码是哪些，在后面的时序逻辑电路可能会用到。按照从小到大的顺序写出\\(0\\sim 9\\)对应的码，没写出来的就是禁止码。为什么要从小到大？比如2421码，最高位和第二低位都是2，我们要优先选择低位的。\n格雷码 格雷码的形式如下，假设为四位格雷码，最开始是0000. 则最右边的一位变化为0110的顺序，第二位为00111100的顺序，第三位为0000111111110000.以此类推。注意第四位只循环了半个周期，四位格雷码就表示完毕了。\n格雷码的特点是相邻的两个代码之间只有一位发生变化。在代码转换的过程中不会产生过渡噪声。\n四位余3码就是从第四个格雷码开始取10个，即从0010开始到1010。\nASCII码 略。\n逻辑代数基础 三个基本运算 分别是与(AND)\\((\\cdot)\\)、或(OR)\\((+)\\)、非(NOR)\\(('或\\overline{ })\\)，电路符号如下\n1.jpg\r当然，这三个运算可以复合出一些操作。与非(NAND)、或非(NOR)、与或非(AND-NOR)、异或(XOR)，同或(XNOR)。符号如下\n2.jpg\r其中异或有\n\\[A\\oplus B = A\\cdot B'+A'\\cdot B \\]\n同或有\n\\[A\\odot B = A\\cdot B + A'\\cdot B' \\]\n二者互为反运算，\\(A\\oplus B = (A\\odot B)',A\\odot B=(A\\oplus B)'\\)\n注意，与运算可以把\\(A\\cdot B\\)写为\\(AB\\)。关于运算优先级，虽然书上没说，但是应该是非\u0026gt;与\u0026gt;或。\n逻辑代数的基本公式和常用公式 3.jpg\r要证明这些公式，可以列真值表。然后这些公式就可以用来证明别的公式了，比如下面的。\n4.jpg\r逻辑代数的基本定理 代入定理 在任何一个包含变量A的逻辑等式中，若以另外一个逻辑式代入式中所有A的位置，则等式仍然成立。\n反演定理 对于任意一个逻辑式\\(Y\\)，若将所有的\\(\\cdot\\)换成\\(+\\)，所有的\\(+\\)换成\\(\\cdot\\)，\\(0\\)换成\\(1\\)，\\(1\\)换成\\(0\\)，原变量换成反变量，反变量换成原变量，得到的结果就是\\(Y'\\)。\n需要注意：\n要保留原来的运算顺序，例如原来\\(A+BC\\)，变换后要变成\\(A'(B'+C')\\) 不属于单个变量上的反号应保持不变，例如\\((AC)'\\)变换为\\((A'+C')'\\) 对偶定理 若两个逻辑式相等，则它们的对偶式也相等。\n对偶式是：对于任意一个逻辑式\\(Y\\)，若将所有的\\(\\cdot\\)换成\\(+\\)，所有的\\(+\\)换成\\(\\cdot\\)，\\(0\\)换成\\(1\\)，\\(1\\)换成\\(0\\)，得到的结果就是\\(Y^D\\)。\n想要证明两个逻辑式相等，可以转换为证明它们的对偶式相等。有时候这更简单。\n完备集 对于一个代数系统，若仅用它所定义的一组运算符号就能解决所有的运算问题，则称这一组符号是一个完备的集合，简称完备集。\n对于逻辑代数，与、或、非毫无疑问是一个完备集。但它并不是最小的。与非、或非、与或非，它们三个都是能够单独组合实现与、或、非功能的。它们是最小的完备集。\n逻辑函数 如果以逻辑变量作为输入，以运算结果作为输出，那么当输入变量的取值确定之后，输出的取值便确定了，因此输入输出之间是一种函数关系。\n\\[Y = F(A,B,C,\\cdots) \\]\n常用形式 与或式。\\(F=AB+CD\\) 或与式。\\(F=(A+B)(C+D)\\) 与非与非式。\\(F=\\overline{\\overline{AB}\\cdot\\overline{CD}}\\) 或非或非式。\\(F=\\overline{\\overline{A+B}+\\overline{C+D}}\\) 与或非式。\\(F=\\overline{{AB}\\cdot{CD}}\\) 任何逻辑函数都能转换成以上五种形式。它的作用在于，如果电路元件只给你某某元件，你要把原来的表达式转换为上述五种式子，再去套用元件。多用德摩根律。\n描述方法 真值表 逻辑函数式 逻辑图（电路图） 波形图 两种标准式 最小项 \\(n\\)个变量的最小项\\(m\\)是含\\(n\\)个变量的“乘积项”，其中每个变量都以原变量或反变量的形式出现恰好一次。\n\\(n\\)个变量的最小项有\\(2^n\\)个。\n输入变量的每一组取值都使一个对应的最小项等于\\(1\\)。为了方便，例如\\(A=1,B=0,C=1\\)时，该最小项写作\\(AB'C\\)。如果看成二进制数\\(101\\)，则最小项标记为\\(m_{101}=m_5\\)\n最小项的性质有\n在输入变量的任何取值下必有一个最小项，且仅有一个最小项的值为\\(1\\) 全体最小项的和为\\(1\\) 任意两个最小项的乘积为\\(0\\) 具有相邻性的两个最小项之和可以合并成一项并消去一对因子 最大项 \\(n\\)个变量的最大项\\(M\\)是含\\(n\\)个变量的“和”，其中每个变量都以原变量或反变量的形式出现恰好一次。\n\\(n\\)个变量的最小项有\\(2^M\\)个。\n与最小项正好相,反输入变量的每一组取值都使一个对应的最大项等于\\(0\\)。\\(A=1,B=0,C=1\\)时最大项写作\\(A'+B+C'\\)，记作\\(M_{101}=M_5\\)\n最大项的性质有\n在输入变量的任何取值下必有一个最大项，且仅有一个最大项的值为\\(0\\) 全体最大项的积为\\(0\\) 任意两个最大项的和为\\(1\\) 只有一个变量不同的两个最大项的乘积等于各相同变量之和 最后，可以发现\\(M_i=m_i'\\)\n逻辑函数的最小项之和形式 首先将给定的逻辑函数式化为若干乘积项之和的形式，亦称“积之和”形式。然后，再利用基本公式\\(A+A'=1\\)将每个乘积项中缺少的因子补全，这样就可以将与或的形式化为最小项之和的标准形式。\n例如\n\\[Y = ABC'+BC \\]\n\\[Y = ABC'+(A+A')BC = ABC'+ABC+A'BC=m_3+m_6+m_7 \\]\n也可以写作\n\\[Y(A,B,C)=\\sum m(3,6,7) \\]\n### 逻辑函数的最大项之积形式 利用公式\\(AA'=0\\)\n例如\n\\[Y = A'B+AC = (A'B+A)(A'B+C) = (A+B)(A'+C)(B+C) \\]\n\\[Y = (A+B+CC')(A'+BB'+C)(AA'+B+C) = (A+B+C)(A+B+C')(A'+B+C)(A'+B'+C) \\]\n\\[Y(A,B,C,D) = \\prod M(0,1,4,6) \\]\n或者，我们可以先求\\(Y'\\)，并且写出\\(Y'\\)的最小项，再把\\(Y'\\)求反得到最大项。或者得出\\(Y\\)的最小项，利用\\(m_i\\)和\\(M_i\\)的互补关系直接写出结果。\n互补关系指的是，例如\\(3\\)个变量的表达式，\\(Y\\)最小式之和为\\(\\sum m(0,1,4,5)\\)，则\\(Y\\)最大项之积为\\(\\prod M(2,3,6,7)\\)，把剩下没用的都放到最大项里了。这个的证明可以在离散数学笔记中找到。\n逻辑函数的化简 公式化简法 并项法，使用\\(AB+AB'=A\\) 吸收法，使用\\(A+AB=A\\) 消项法，使用\\(AB+A'C+BCDE = AB+A'C\\) 消因子法，使用\\(A+A'B = A+B\\) 配项法，使用\\(A+A=A,A+A'=1\\) 卡诺图法 介绍不方便，看教材。\n注意事项：横轴和纵轴是格雷码排列的。但是填进去的时候，按照坐标的字面量填入最小项。而不是什么转换为格雷码对应的十进制数，再填入对应的十进制表示的最小项。\n如果表达式里有这一项，就填入1，没有就填入0。例如有\\(ABCD\\)就填入坐标为\\(11,11\\)的那一格，也就是第三行第三列，填入\\(m_{15}\\)，填入\\(1\\)，没有这一项就填入\\(0\\)\n如果你得到的是最大项，那么在卡诺图对应的位置填入\\(0\\)，其他位置填入\\(1\\)。\n合并规律\n用尽可能大的圈，去套\\(1\\)，不可套\\(0\\)，但是可以重叠（不要多余，每个圈里面至少有一格只被套过一次）、可以越过边界到达相对的边界一边。\n不方便说，多做题。\n具有无关项的逻辑函数及其化简 对于输入变量的每一组取值组合，逻辑函数都有确定的值，则这类逻辑函数称为完全描述的逻辑函数。\n对于输入变量的某些取值组合，逻辑函数值不确定（可以为1，也可以为0），或者不存在，这类逻辑函数称为非完全描述的逻辑函数。\n无关项在卡诺图里填\\(\\times\\)，在真值表里填\\(\\times\\)，在逻辑函数中用约束项表示\n5.jpg\r在逻辑函数中，一般最小项的约束条件为\\(\\sum d(\\cdots) = 0\\)。最大项的约束条件为\\(\\prod d(\\cdots) = 1\\)\n在卡诺图化简中，带有\\(\\times\\)的可以圈也可以不圈。\n组合逻辑电路 概述 数字电路可以分为两类：组合逻辑电路、时序逻辑电路\n组合逻辑电路的输出仅仅取决于该时刻的输入。\n6.jpg\r输入输出关系可以表示为\n\\[\\left\\{\\begin{matrix} y_1=f_1(a_1,\\cdots,a_n) \\\\ y_2=f_2(a_1,\\cdots,a_n) \\\\ \\vdots \\\\ y_m=f_m(a_1,\\cdots,a_n) \\end{matrix}\\right. \\]\n写成向量形式为\\(Y=F(A)\\)\n分析方法 根据电路图写表达式、列真值表，判断功能\n设计方法 把想做的功能抽象出来，写成表达式，化简表达式，画电路图。\n常用组合逻辑电路模块 8-3普通编码器 7.jpg\r功能就是，把某一位输入变成二进制位输出，比如\\(I_6=1\\)，则输出\\(110\\)。\n它普通就普通在，任意时刻只允许一个输入。\n8-3优先编码器 可以有多个输入，但是按照内部的优先级顺序，会进行选择什么输出。注意这些圆点代表非门，或者说低电平有效。\n8.jpg\r3-8译码器 就是8-3编码器反过来\n9.jpg\r10.jpg\r2-10进制译码器 也就是BCD翻译为10进制数字\n11.jpg\r七段字符管 12.jpg\r数据选择器 从一组输入中选出一个进行输出。\n13.jpg\r14.jpg\r加法器 一位半加器 15.jpg\r\\[\\left\\{\\begin{matrix} S = A'B+AB' = A\\oplus B \\\\ CO = AB \\end{matrix}\\right. \\]\n不考虑低位的进位，称为半加。 \\(S\\)为本位加的结果，\\(CO\\)为进位\n一位全加器、串行加法器、超前进位加法器 见计组笔记。\n\\[\\left\\{\\begin{matrix} S = A\\oplus B\\oplus CI \\\\ CO = AB + (A\\oplus B)CI \\end{matrix}\\right. \\]\n组合逻辑电路中的竞争-冒险 在组合电路中，某一输入变量经不同途径传输后，到达电路中某一会合点的时间有先有后，这种现象称为竞争。由于竞争而使电路输出发生瞬时错误的现象称为冒险。\n将门电路两个输入信号同时向相反的逻辑电平跳变的现象称为竞争。\n应当指出，有竞争不代表一定会产生尖峰脉冲。\n判断有无竞争 只要输出端的逻辑函数在一定条件下能化简成\n\\[Y = A+A'\\quad or\\quad Y = AA' \\]\n则一定有竞争。\n例如\\(Y=AB+A'C\\)，在\\(B=C=1\\)时有\\(Y=A+A'\\)\n或者在卡诺图上看。如果两卡诺圈相切，而相切处未被其他卡诺圈包围，则有竞争。\n两个输入变量以上的竞争就难以判断了，最有效的办法是做实验。利用示波器观察，如果有毛刺，就有冒险。\n消除竞争-冒险的方法 接入滤波电容 引入选通脉冲 修改逻辑设计 修改逻辑设计需要增加冗余项。\n例如，\\(Y = AB+A'C = AB+A'C+BC\\)，此时，当\\(B=C=1\\)时，无论\\(A\\)取什么值，都有\\(Y=1\\)\n半导体存储电路 SR锁存器 16.jpg\r17.jpg\r注意我们约定不同时给SR输入有效。有些地方的SR锁存器是低电平有效，无论什么情况，记住：两个都无效时，保存原有的输出。S（Set）有效时，输出变为\\(1\\)，R（Reset）有效时，输出变为\\(0\\)。\n触发器 电平触发 只有当CLK为有效时，触发器才接受输入信号 在CLK=1的全部时间里，SR状态的变化都有可能引起输出状态的改变。在CLK回到0之后，触发器保存的是CLK回到0之前瞬间的状态。 显然，如果CLK=1时SR多次变化，输出也会多次变化。抗干扰能力弱。\n边沿触发 触发器的次态仅取决于时钟信号的上升沿（或者下降沿）到达时的逻辑状态。抗干扰能力强。\n脉冲触发 当CLK的有效电平消失以后，输出状态才改变。所以也叫延迟触发。\nSR触发器 18.jpg\r\\[\\left\\{\\begin{matrix} Q^* = S+R'Q \\\\ SR = 0(约束) \\end{matrix}\\right. \\]\nJK触发器 \\[Q^* = JQ' + K'Q \\]\n也就是\\(J=K=0\\)时，输出不变，\\(J=1,K=0\\)时输出变\\(1\\)，\\(J=0,K=1\\)时输出变\\(0\\)，\\(J=K=1\\)时，输出翻转。\n只是比SR多了一个翻转的功能而已。\n19.jpg\r由于JK可以实现SR和T，所以现在一般生产JK触发器和D触发器较多。\n注意到上面的时钟信号输入端口有个三角形，和之前的不一样。之前没有三角形的代表电平有效，这里有三角的代表上升沿有效。如果还有个非门在前面，则代表下降沿有效。这张图的JK触发器是下降沿有效。\nT触发器 \\[Q^* = TQ'+T'Q \\]\n也就是说\\(T=0\\)时保持，\\(T=1\\)时翻转。\n20.jpg\rD触发器 \\[Q^*=D \\]\n也就是说输出等于输入。\n21.jpg\r触发器功能的描述方法 状态转移真值表 次态卡诺图与特征方程 状态转移图 激励表 波形图 时序逻辑电路 概述 22.jpg\r23.jpg\r写成向量形式得到\n\\[Y = F(X,Q) \\]\n\\[Z = G(X,Q) \\]\n\\[Q^* = H(Z,Q) \\]\n第一个方程称为输出方程，第二个为驱动方程，第三个为状态方程。\n在时序电路中区分出同步时序电路和异步时序电路。由于课时问题，我们学院只讲同步时序。\n根据输出信号的特点分为米利型和穆尔型。米利型：输出信号取决于存储电路和输入变量。穆尔型：输出电路仅仅取决于存储电路。\n分析方法 从给定的逻辑图中写出每个触发器的驱动方程 驱动方程代入相应触发器的特性方程，得出每个触发器的状态方程，从而得到状态方程组 根据逻辑图写出输出方程 表示方法 状态转换表 状态转换图。输入写斜线上，输出写斜线下，没有输入就空着。 状态机流程图 可自启动电路 时序电路中的所有无效状态经过有限个CP脉冲后都能进入有效状态环，则称它是可自启动的。\n设计方法 逻辑抽象，得出电路的状态转换图或状态转换表 状态化简。如果两个电路状态在相同的输入下有相同的输出，并且转换到同一个次态中，则为等价。可以合并为一个。 状态分配 选定触发器，求出状态方程、驱动方程、输出方程 画出逻辑图 检查能否自启动 常用的时序逻辑电路 移位寄存器 同步计数器 24.jpg\rPT是计数允许端，CP是时钟信号。Cr是异步清零，ABCD是在LD有效时的置数输入。Oc是进位端。\n任意进制计数器的构成方法\n已有N进制计数器，需要M进制计数器\nM\u0026lt; N时\n置零法 置数法 M\u0026gt;N时\n将多片N进制计数器组合起来，构成M进制计数器。可以分为串行进位方式、并行进位方式、整体置零方式。\n集成寄存器 ","date":"2023-06-16T19:42:38+08:00","image":"https://kegalas.top/p/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/cover_hua3505806866a19c5f5a93f876aae8123_184422_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"数字电路学习笔记"},{"content":"认知与计算 认知 内涵：自身以及与外界交互中的能动的过程总称。\n外延：包括感觉、知觉、学习、记忆、注意、思维、想 象、语言、决策和行为等。\n动态：根据任务需求自主完成“感知一分析一决策一执行”的动态过程，并能够应对意外情形。\n认知金字塔 1.jpg\r元认知 对认知的认知，依据认知对象对认知过程进行主动的监则以及连续的协调\n认知信息的来源 嗅觉、味觉、视觉、听觉、触觉、平衡感、第六感等等。\n脑的构成与功能 2.jpg\r间脑位于两侧大脑半球之间，是脑干与大脑半球连接的中继站。\n丘脑是间脑中最大的卵圆形灰质团块，对称分布于第三脑室两侧。除了嗅觉输入以外，其余感觉通道的信息都需要经过丘脑中的相应区域后到达初级感觉皮质\n上丘脑位于背侧丘脑的后上方,包括缰三角、缰连合丘脑髓纹、松果体和后连合。松果体对光线敏感，与光照引起内分泌调节改变有关。\n下丘脑是有调节自主功能、内分泌和内脏功能的皮质下中枢，下丘脑的某些细胞既是神经元又是内分泌细胞。调节体温、摄食、水盐平衡、内分泌。参与情绪过程并控制垂体来调节生理周期的节律。还可以通过向血液释放激素来远距离神经调控。\n基底节是锥体外系统的中继站，各核之间有密切的纤维联系。基底节与大脑皮质及小脑协同调节随意运动、肌张力和姿势反射，也参与复杂行为的调节。\n杏仁体与情绪控制、恐惧感、动机、非语言的情绪解读等有关。\n大脑区块\n额叶：中央前回是人脑控制运动的中枢，前额叶是人类高级认知活动的生理基础，负责计划、调节和控制人 的心理活动，对人的高级的、目标导向的行为有重要作 用；前额叶受损的人会带来诸多缺陷，如无法抑制自己 的行为、无法控制自己的情绪、无法有效的做计划与执 行计划、无法有工作记忆。(反向理解额叶功能)\n顶叶：人类重要的感觉中枢，响应疼痛、触摸、品尝、温度、压力等感觉，顶叶还与注意功能、空间分辨以及数学逻辑相关。\n颞叶：负责处理听觉信息，也与记忆和情感有关。\n枕叶：负责处理视觉信息。\n岛叶：与情绪功能及自主功能有关。\n注意点\n大脑左右半球的分工并不是那么泾渭分明，功能的单侧化只具有相对的意义。 大脑组织的两个基本原则是功能整合和功能分化，需要考虑局部属性和连接属性两个方面。 大脑组织存在个体差异性，获得大脑组织的一般的特征和了解个体差异是相辅相成的，人脑的可塑性。 无论如何分区，大脑作为整体大于各部分之和。 脑的三位一体 3.jpg\r人脑的三位一体学说：古脑，也叫做爬行脑；旧脑，也叫做哺乳脑；最后一个是新脑，也就是大脑的新皮质\n古脑：平衡、自动机能、呼吸心跳\n旧脑：情感、直觉、哺乳、搏斗、逃避\n新脑：高阶认知功能，老鼠失去了脑皮质，仍然可以正常活动\n认知系统的模拟方法 功能模拟（逻辑主义，符号运算系统，例如电梯） 结构模拟（连接主义，人工神经网络，例如人脸识别） 行为模拟（涌现主义，集智、群智、社会化，例如无人机蜂群） 方法与技术 心理学方法 这里验证大脑功能的方法有\n反应时法 比较法 眼动分析法 口语报告法 内隐联想测验 计算机模拟法 损伤研究法 心理学方法设置的要点\n输入输出设置要精简全面 测试流程简洁 测试结果、测试流程、输入和输出之间的关系平衡 定性分析和定量分析 人工成像系统的基本性能指标 基本指标（最小角分辨率，空间分辨率）如下\n\\[1.22\\lambda /nD \\]\n其中\\(D\\)是口径，\\(n\\)是折射率，\\(\\lambda\\)是入射波长。\n空间分辨率的影响因素 见上\n时间分辨率的影响因素 时间分辨率指的是帧率\n脑成像包括的技术方法 CT（计算机断层扫描） PET（正电子发射计算机断层扫描技术） SPECT（单光子发射计算机断层显像技术） 干涉成像 MRI（磁共振成像技术） 光声成像技术 FMRI（功能磁共振成像技术） EEG (脑电波) MEG（脑磁图） 脑电图和脑磁图的基本概念 神经与信息 新函数的出现对科技的推动作用 函数的发展：\n参数多 形式复杂 数函数并不能理解为传统的“显示表达” 重大函数的发现，都能推进科学技术的显著进步 神经网络 理论上两层神经网络已经可以拟合任意函数\n单个人工神经元可以用一个简单函数表示，人工神经元的串联相当于函数的嵌套，并联相当于函数间的线性组合。\n激活函数的性质 输连续并可导的非线性函数，可导的激活函数可以直接利用数值优化的方法来学习网络参数； 测激活函数及其导函数要尽可能的简单，有利于提高网络的计算效率。 激活函数的导函数的值域要在一个合适的区间内，不能太大也不能太小，否则回影响训练的效率和稳定性。 神经网络的传播都是形如Y=WX+b的矩阵运算；为了给矩阵运算加入非线性，需要在隐藏层中加入激活层；输出层结果需要经过Softmax层处理为概率值，并通过交叉熵损失来量化当前网络的优劣\n4.jpg\r神经系统的组成 神经系统主要由神经元、神经胶质细胞两种细胞组成。\n数量众多的神经胶质细胞，几十倍于神经元，占脑容量的一半，有神经胶水之称，通常其胞体较小。\n神经胶质细胞在形态上与神经元最大的区别是虽然有突起但没有形成明显的轴突，自身不传递信息。\n神经元的组成及其功能 神经元是神经系统的基本结构和功能单位之一，可以分为细胞体、树突、轴突以及轴突终末。\n细胞体又被称为核周体，其由细胞膜、细胞核、细胞质、细胞器组成，进行着维持生命的各种代谢活动。细胞质内有尼氏体(Nissl Body)，强嗜碱性，均匀分布，合成蛋白质、酶类、肤类。\n树突表面有大量细小的突起，即树突棘。树突棘实际上是树突上的小突起。在树突棘的顶部有突触的连接点，负责接受刺激，并把刺激传向胞体(神经元之间通过神经递质传递神经信号的连接称为突触)。\n神经元只有一个长细而均匀的轴突，轴突以及套在外面的髓鞘，被称为神经纤维，比树突长得多。轴突在细胞起始部被称为轴丘，轴丘内没有尼氏体，其兴奋性最高，往往是动作电位发起的地方。轴突进行动作电位的快速传导和物质的转运。\n在脑和脊髓里，细胞体密集的部位色泽灰暗，叫灰质。在灰质里，功能相同的神经元细胞体汇集在一起，调节人体的某一项相应的生理功能，这部分结构就叫作神经中枢。\n神经纤维主要集中在周围神经系统里，许多神经纤维集结成束，外面包着由结缔组织形成的膜，就成为一条神经。神经纤维末端的细小分支叫神经末梢，神经末梢分布在全身各处。\n在脑和脊髓里，也有神经纤维分布，它们汇集的部位色泽亮白，叫白质。白质内的神经纤维，有的能向上传导兴奋，有的能向下传导兴奋。\n神经胶质细胞的作用有：\n支持作用 绝缘作用 屏障作用 营养性作用 修复和再生作用 维持神经元周围的K+平衡 摄取神经递质 神经信息传播一般分两个阶段，即神经元内的传导过程和神经元间的传递过程。\n在神经信号传播过程中，神经元的四个部分要产生四种类型的信号活动：输入信号、整合信号、传导信号和输出信号。\n树突是神经元的输入和接受成分，细胞体是神经元的整合或总合成分，轴突为神经元的信号传送或传导成分，轴突终末为神经元的输出或分泌成分。\n神经元机能最大的特点是特异的信息传递和处理，且具有传递信息的绝缘性和极性。\n神经元类型 按形状分\n5.jpg\r只有一个远离胞体的突起，此突起能分支形成树突和轴突，常见于无脊椎动物； 两个突起，一个树突，一个轴突，一端接收一端传递，听觉、嗅觉、视觉等信息传递系统； 一个轴突和多个树突，多见于运动和感觉系统中； 一个树突，一个轴突，多见于脊髓背根神经节，躯体感觉神经细胞。 按功能分\n感觉神经元，或称传入神经元，多为假单极或双极神经元 运动神经元，或称传出神经元，多为多极神经元 中间神经元，介于前两种神经元之间，多为多极神经元。 根据释放的神经递质分\n胆碱能神经元 胺能神经元 肤能神经元 氨基酸能神经元 神经信息的产生过程 在脑和神经元的细胞膜上一些称为离子通道的蛋白质分子允许离子流动，导致神经元细胞膜内、外的电位差，称之为膜电位。\n在没有任何外来刺激情况下的膜电位称为静息电位，这时膜内相对膜外约为-70毫伏。\n当神经元受到刺激发生兴奋时，在静息电位的基础上会发生瞬时的电位变化，这时膜内外的极性改变(即所谓的去极化作用)，此时的膜电位称之为动作电位(此时膜内可比膜外高出30–50毫伏)，它是神经元传导兴奋的电信号。\n6.jpg\rNa进K出。\n神经信息编码 7.jpg\r发放率编码：单个神经元强烈并且独立地放电，激活了下游的读出神经元\n相关性编码：较弱但同步性的发放同样可以激活下游的读出神经元\n发放率编码的效率比较低，但是抗噪音干扰的能力很强。\n相关性编码可能会与外界刺激绑定，感觉神经元通过时间特征不同的激发模式，来代表不同的外界感觉刺激，例如 光、声音、味觉、嗅觉与触觉信号。\n在一定条件下，神经系统可以在两种编码策略间进行动 态地“切换”，以达到更好的信息编码效果，这就是“动态 编码”。一个特殊的例子就是适应性期间，神经系统在接受 到恒定不变的刺激时，其反应强度会随着时间逐渐衰减。这 也就是所谓的“久居兰室，不闻其香”现象。\n视觉与计算 眼睛的组成结构及其功能，其与人工成像系统相比所具有的优势 视觉信息感知和传递的过程中，眼睛执行两个功能：\n眼睛光学系统在眼底视网膜上形成外界物体的影像； 视网膜将物像的电磁波能转换为视觉的神经冲动。 波长低于可见光的光分辨率高，但是衰减快，传播距离短。波长高于可见光的光虽然分辨率低，但是衰减慢，传播距离远。\n眼睛分为：\n瞳孔 相当于相机的光圈。外面光线强的时候，瞳孔缩小；光线弱的时候，瞳孔变大，从而使眼睛里接受的光线总是恰到好处。一旦失调，则曝光不当。\n虹膜 相当于光圈的叶片。如果光线过强，虹膜内瞳孔括约肌收缩，则瞳孔缩小；光线变弱，虹膜开大肌收缩，瞳孔变大。根据虹膜内含色素的不同，虹膜呈现不同的颜色。白种人虹膜色素较少，呈灰蓝色；黄种人色素较多，呈棕黄色；黑人色素最多，呈黑色。\n巩膜 相当于相机壳。对眼球的内部结构起保护作用，占据整个眼球后面约5/6的范围，俗称眼白。\n晶状体 相当于全自动变焦镜头。位于瞳孔虹膜后面，呈双凸透镜。正常人既能看近又能看远，全依赖于晶状体的调节。看远时，睫状肌放松，悬韧带绷紧，晶状体变扁平，折光力减少；看近时，睫状肌收缩，悬韧带放松，晶状体依靠其本身弹性变凸，折光力增加。\n通过如此调节，使光线能聚焦在视网膜黄斑上。如果通过调节，光线不能聚焦在视网膜上，就存在屈光不正。\n光线聚焦在视网膜之前称为近视眼；聚焦在视网膜之后称为远视眼； 不能聚焦在一个点，称为散光眼； 如果晶状体的调节功能失调，如年老时，晶状体不能变凸，称为老视，即老花眼； 如果晶状体变混浊，就称为白内障。 视网膜 视网膜相当于胶卷。起感光功能。感光最敏锐的那部分，称为黄斑。虽然视网膜很薄，结构却很复杂，分为10层，感光的细胞主要是视锥细胞和视杆细胞。视锥细胞主要负责明视觉和色觉，视杆细胞主要负责暗视觉。自然视网膜让人工技术难以望其项背。\n视网膜又称为外周脑，与脑组织同源，起源于外胚层。\n脉络膜 相当于照相机的暗箱。主要由血管组成，因此还兼有营养眼球的责任。\n立体视觉的分类 单眼立体视觉\n双眼立体视觉\n单眼立体视觉的因素因素 可以通过通过透视原理（绘画上的那个）来感知立体，也可以通过空气透视（想象大雾天远近的清晰度不一样），也可以通过光和阴影关系，也可以通过重叠效应、视野、单眼运动视差、调节效应、像的大小。\n重叠效应：当两个图像重叠、轮廓线相交时，交点轮廓线平滑连续的图像比轮廓线不连续的看起来更近。见下\n8.jpg\r视野：人眼的视野颇宽，水平方向约220◦，垂直方向约130◦，呈一椭圆状。所以宽荧幕的立体感比窄银幕强。\n单眼运动视差：由于视线方向的连续变化，单眼的视网膜成像也不断发生变化，这样，借助时间顺序的比较便形成立体视觉。这种利用观看者与物体间的相对运动使空间物体的相互位置产生变化，从而判断出物体间的前后关系，相当于连续地从几个方向观看景物，类似于有几只眼睛观看景物的状况。\n当用单眼观看物体时，若眼睛位置不动，调节效应便是对深度感的唯一心理暗示，若允许观看位置移动的话，便可利用双眼视差这种效应从各个方向来观看物体，从而产生出深度感，这个效应便称为单眼运动视差。显然，单眼运动视差对静态物体不起作用。单眼运动视差这一视觉因素形成立体视觉的有效距离为300m以内。\n调节效应：当人眼观看距离不同的物体时，为使物体能在视网膜上成像，人眼通过改变睫状肌的张弛程度来改变眼球晶状体的曲率，从而使晶状体凸透镜的焦距产生变化，达到视网膜上清晰成像。大脑就可以通过这个东西来判断远近。这一视觉因素单独起作用时，距离超过5m便失效了。\n像的大小：视网膜成像的相对大小同样大小的物体，当观看距离不同时，在视网膜上成像的大小也不一样。\n双眼立体视觉 双眼立体视觉：主要用于短距事物的感知。双眼立体视觉主要因素是双眼视差。\n视觉的恒常性包括那些内容 当客观条件在一定范围内改变时，大脑知觉映象在相当程度上却保持着它的稳定性，即知觉恒常性。知觉恒常性是在日常生活中造成的，是先天和经历独特影响的。\n外部世界投影在视网膜上产生了图象，大脑经过因素分解把这些影响传感器信息的条件，如照明条件、观察者的距和方位等因素分出去，得到纯粹的关于对象的信息，这些信息是不随这些条件而变的，因此被称为恒常性。\n双稳态视觉\n9.jpg\r要么看见花瓶，要么看见人脸。即使可以切换，也只能同时看到一个。\n大脑预设的前提\n10.jpg\r大脑预设了光从上面照下来，会看到左边凸，右边凹。如果预设光从下面来则相反。\n情景\n11.jpg\r亮度\n12.jpg\r分类\n大小恒常性，形状恒常性，方向恒常性，颜色恒常性，明度恒常性\n其他恒常性：距离恒常性，速度恒常性，年龄恒常性，声音恒常性，语音恒常性\n大脑解决问题的思路 大脑解决似是而非问题的思路是一个“猜测与印证＂动态交互过程。\n在日常生活中，很多时候只需要一两个回合就能成功识别。但的确有的时候一个图像看得不太清楚，我们会盯着 它左看右看，大脑内部可能就进行了信息的上传、下传的交替，不断地进行“猜测-印证-猜测-印证”，只要印证结果 是否定的，这个过程就会一直进行下去，直到得到肯定的结果。\n图像模糊的原因 透镜缺陷 相机抖动 场景运动 深度散焦 感知与运动 感觉与知觉的基本概念 人类对自身和外部世界的认知，都是从经验中获得的，而经验来源于感觉和知觉。\n感觉：是人脑对客观事物个别属性和特征的直接反映。\n知觉：人脑对客观事物各种属性、多种特征及其相互联系的综合性和整体性反映\n感觉与知觉的区别和联系 14.jpg\r感觉是人脑对客观事物个别属性和特征的直接反映，知觉则是人脑对客观事物各种属性、多种特征及其相互联系的综合性和整体性反映。\n感觉系统处理的是某种感受器感受到的未经整合的具体刺激信息，知觉系统处理的则是多种感受器整合组织后的信息。\n人类五种基本的感觉系统 13.jpg\r其中肤觉又叫躯体感觉。肤觉下面还可以加一个痒觉。内部感觉还可以把动觉分为震动觉和运动觉，还可以再加上饥感、渴感。\n其中物种基本感觉是：听觉、视觉、嗅觉、味觉、躯体感觉。\n典型感觉的感受器及其适宜刺激 感受刺激的步骤为：\n感受器感受物理刺激 神经元将刺激转化为神经信息 大脑加工信息后产生知觉或有意识的感觉体验 20.jpg\r15.jpg\r16.jpg\r感觉剥离实验告诉我们：生命活动的维持需要一定水平的外界刺激。\n感觉信息编码时，刺激信息的基本属性 刺激信息只有四个基本属性：模态-位置-强度-时间\n模态：标记线性编码（感受器特异性） 位置：空间分布编码 强度：动作电位频率编码 时间：时间适应率编码 知觉的特性及影响因素 17.jpg\r知觉的特性为：\n选择性 我们并非对一切刺激都全部接收，我们有选择地接受少数事物作为知觉的对象。例如双稳态视觉。\n影响因素有：客观上：对象与背景的差别；对象的活动性；对象各部分的组合；主观上：兴趣；需要；情绪\n对象和背景是相互依存、相互转化的。\n整体性 对象可能由不同的部分组成，但我们的知觉并不看做孤立的部分，而是当作一个整体。\n组织定律：接近律（距离上近的容易被知觉组织在一起）、相似律（物理属性相似的容易被组织在一起）、连续律（具有连续性或者共同运动方向的刺激）、封闭律（倾向于将缺损的轮廓加以补充使知觉成为一个完整的封闭图形）。\n影响因素：对象各组成部分的强度；对象各组成部分的相互关系；个体生活经验和知识储备。\n理解性 人在知觉客观事物时，总是根据已有的认知经验来解释它，赋予它一定的意义，并用词把它标志出来。\n影响因素：个人的知觉经验；言语的指导作用；实践活动的任务。\n恒常性 当知觉的客观条件在定范围内改变时，知觉的印象仍然相对地保持不变，知觉的这种特性称为知觉的恒常性。\n大小恒常性\n指在一定范围内，个体对物体大小的知觉不完全随距离变化而变化，也不随视网膜上视像大小的变化其知觉映象仍按实际大小知觉的特征。\n形状恒常性\n物体形状的知觉不因它在网膜上投影的变化而变化。\n明度恒常性\n当照明条件改变时，人知觉到的物体相对明度保持不变的知觉特征。\n颜色恒常性\n指有颜色的物体（熟悉的），当其表面颜色受到照明等条件的影响而改变时，个体对颜色的知觉不因色光改变而改变，趋于保持相对不变的知觉特征。\n错觉的分类 错觉是对客观事物的一种不正确的、歪曲的知觉。\n错觉是知觉的一种特殊状态。\n18.jpg\r物体知觉的错觉的原因假说有：\n眼动说 常性误用说 神经位移说 混淆或错误比较说 对比和同化说 社会知觉误区有：\n第一印象 近因效应 光环效应 期望效应 心理定势 生活中的刻板印象 听觉信号的转换过程 耳道引起鼓膜震动 鼓膜的震动引起三块小骨-锥骨、镫骨和钻骨上相震动,能将声音传递至充满淋巴液的内耳 内耳可产生神经冲动,冲动沿听神经转为神经能,从那儿声音的信息就传到大脑 19.jpg\r等响曲线的理解 由于耳朵的结构，我们感受到的响度和声音的频率有关，不仅局限于声压级的影响。\n听声辩位的原理 耳间时差：声音到达两耳的时间不同，分辨率为10\\(\\mu s\\) 耳间强差：声音在两耳的强度不同，分辨率为1dB 学习与记忆 脑神经科学，学习、记忆的定义 学习：人或动物通过神经系统获取新信息和新知识的神经过程\n记忆：对所获取信息的保存和读取的过程\n多媒体解释学习认知模型 21.jpg\r多媒体学习把认知分为三个基本过程\n选择 对所呈现的语词和图像相关部分予以注意，把感觉记忆中的信息转化到工作记忆中。\n组织 对已经选择的语词进行组织，以形成连贯的言语模型；对已经选择的图像进行组织，以形成连贯的图像模型；在工作记忆中深层加工信息。\n整合 将声音表征和图像表征相互联系起来，并与原有知识相结合；把长时记忆中的知识转换到工作记忆中同时也调整长时记忆内容。\n学习过程中最重要的是认知表征。\n认知表征是指个体经知觉而将其外在环境中的物体或事件转换为内在心理事件的过程，人类获得知识的过程就是对事件进行认知表征的过程。认知表征的实质其实就是观念、事件和事物在心中是如何被储存和被概念化的。\n赫布理论 突触可塑性 突触可塑性（Synaptic plasticity）是指神经细胞间的连接，即突触，其连接强度可调节的特性。突触的形态和功能可发生较为持久的改变的特性或现象。\n赫布理论(Hebbian theory)描述了学习过程中突触可塑性的基本原理，即突触前神经元向突触后神经元的持续重复的刺激可以导致突触传递效能的增加。\n赫布理论也是非监督学习的生物学基础。\nSTDP 学习规则 Henry Markram提出STDP(Spike Timing Dependent Plasticity) ：根据神经元学习的先后顺序，调整神经元之间连接的强弱——即大脑中神经元之间权重连接的更新规则。\nSTDP可以说是赫布理论的一种延伸。赫布理论强调两个神经元经常一起活动，则二者的连接会增强。\nSTDP则进一步说明，两个神经元之间的活动，如果其他神经元的信息在本身活动产生之前，则两神经元之间的连接会增强。如果神经元本身产生活动之后才接受其他神经元传来的信息，则两神经元之间的额连接会减弱。如果两个神经元的发放在时间上离的越近，他们之间的绑定关系就越紧密。（这段话摘自老师PPT，我的评价是狗屁不通，见下面的例子）\n对于神经元\\(i\\)而言，如果神经元\\(i\\)传递信息之后，神经元\\(j\\)才产生反应，那么类似于因果关系，它和传递信息的神经元之间连接\\(G(j-\u003ei)\\)会加强。\n如果\\(i\\)产生反应之后，\\(j\\)才传递信息来，那么这个信息就有可能被忽略，\\(i\\)和\\(j\\)的连接\\(G(j-\u003ei)\\)就会减弱。\n当突触前神经元的峰电位先于突触后神经元峰电位产生，即\\(t^{pre}_j\u003c t^{post}_i\\)，则连接两个神经元间的突触权值变大；反之，权值变小。\n突触前脉冲先于突触后脉冲到达时，能够引起长时程增强\\(LTP\\)；反之引起长时程抑制\\(LTD\\)\n脉冲神经网络 脉冲形式处理 传统神经网络算法仍然依据于使用高精度的浮点数进行运算， 然而人脑并不会使用浮点数进行运算。 在人的传感系统和大脑中， 信息会以动作电压或称之为电脉冲（electric spike）的形式传递，接受，和处理。因此，产生了脉冲神经网络——第三代人工神经网络。\n迁移学习：脑认知和人工智能领域定义、包含的类型 脑认知领域中\n迁移学习：一种学习对另一种学习的影响。\n知识可以迁移，动作技能、情感、态度、习惯等都可以迁移。\n迁移学习分为：\n顺向迁移：先前的学习对后来学习的影响 逆向迁移：后来的学习对先前学习的迁移 也可以分为\n正迁移（positive transfer）：指一种学习中学得的经验对另一种学习起促进作用 负迁移（negative transfer）：指一种学习中学得的经验对另一种学习起阻碍作用 也可以分为\n水平迁移(侧向迁移）：已习得的概念、规则或解决问题的方法在新的情境中的运用 垂直迁移(纵向迁移）：:低级概念和规则向高级概念和规则的迁移 也可以分为\n特殊迁移（special transfer）：具体知识和动作技能的迁移 一般迁移（nonspecial transfer）：原理和态度的迁移。这一类迁移是教育的核心。 人工智能领域中\n迁移学习涉及到两个概念，分别是域和任务。域，与特定数据集的特征空间和特征的边际概率分布有关；任务，与数据集的标签空间和目标预测函数有关。迁移学习的目的是将从某一个域（通常称为源域）任务中学习到的知识迁移至另一个域（通常称为目标域）的任务上。\n迁移学习的方法包括\n基于数据 主要通过改变源域数据来达到知识迁移的目的。例如数据增强，提升源域数据的丰富程度，减小源域数据与目标域数据的差异。\n基于特征对齐/转换 主要通过将源域和目标域的特征进行对齐或转换来进行知识的迁移。例如DANN模型。\n基于模型 通过调整模型的参数、集成模型等方式来进行知识迁移。例如将在源域内训练好的模型在目标域数据上加以微调。\n元学习定义 学会学习 选择题 脑认知领域中\n元学习是学习者意识到并逐渐控制自己已经习惯化了的感知、查询、学习和成长的过程，这一过程体现了“学会学习”的内涵。\n人工智能领域中\n利用元数据来理解如何提升学习在解决问题时的灵活性，从而提升现有学习算法性能或诱导学习算法对自身进行调整和学习的手段。元学习最大的颠覆性在于其将学习的对象由数据提升至了学习任务。\n学习形成记忆的分子机制 海兔，神经系统只有2w个神经细胞。具有一种可以保护鳃的简单保护性反射，可以用来研究基本的学习机制。\n“短期记忆”的机制是由于离子通道受影响，使更多的钙离子进入神经末梢。由此，导致神经突触释放更多的神经递质，从而使反射加强。这些转变是由几个离子通道蛋白的磷酸化所致。\n长期记忆需要生成新的蛋白质。\n长期记忆与短期记忆均发生在突触部分。\n短期记忆到长期记忆 持续重复的刺激。\n记忆的基本过程 编码或登录。感知外界事物或接受外界信息(外界刺激)的阶段，也即通过感觉系统向脑内输入讯号一学习过程。 存储：获取的信息在脑内贮存和保持的阶段。 提取或再现：将贮存于脑内的信息提取出来使之再现于意识中的过程一一回忆过程。 遗忘：是对识记过的材料不能再认与回忆，或者错误的再认与回忆。 记忆的类型 22.jpg\r短期记忆 如前图所述。\n短期记忆中，乱序的、无意义的东西，比有序的、有意义的东西记忆容量要小。\n长期记忆分类 23.jpg\r老实说我觉得记住深度为2的节点就行，更下面的了解一下。\n多重存储记忆模型 电话号码、圆周率形成长期记忆 该模型认为，信息首先被存储在感觉记忆中，被注意选择的事件将进入短时记忆。一旦进入短时记忆，如果事件被复述则可以进入长时记忆，并且信息在每一个阶段都可能遗失，其原因可能是衰退、干扰，或者两者的结合。\n多重存储记忆模型有两个重要过程：\n注意。感觉记忆通过“注意”进入短时记忆，没注意的就很快消失。 复述。短时记忆的保留时间也很短。但是，通过复述(重复背诵)可以使得信息在短时记忆中保持更长的时间并且可以存储到更加持久的长时记忆中。 工作记忆模型定义 绘制 Baddeley-Hitch 工作记忆模型 工作记忆是指在执行认知任务过程中，用于已知的或新的信息提供暂时储存与加工的容量有限的系统。这种记忆一般持续数秒，易被抹去，并随时更换。\n工作记忆=短时记忆+控制加工系统\n24.jpg\rBaddeley-Hitch工作记忆模型认为工作记忆由语音回路视觉空间模板和中央执行系统组成。\n语音回路负责以声音为基础的信息储存与控制，\n视觉空间模板主要负责储存和加工视觉信息，\n中央执行系统是工作记忆的核心，负责各子系统之间以及它们与长时记忆的联系、注意资源的协调和策略的选择与计划等。\n由于有些东西不能被原版模型解释，Baddeley又加入了情景缓冲区的概念。\n不同脑区的功能 不同脑区负责不同形式的记忆产生与存储 非陈述性记忆\n小脑：运动性技巧记忆 杏仁核：情绪性记忆 纹状体：习惯化行为记忆 陈述性记忆\n间脑（丘脑）：连接大脑皮层，是短期记忆向长期记忆过度的关键脑区。 前额皮层：工作记忆，长时情节记忆和抽象的语义记忆。 海马(内侧颞叶)： 短期(几分钟到数周) 空间方位和情节性事件记忆。海马相当于大脑中的图书管理员，将信息长期储存于大脑皮层。 HM 病人 HM，被切除了双侧颞叶内侧。记忆维持不到30秒，虽然无法记得刚讲过的话、刚阅读过的文字、刚看过的照片，但其它的心智功能并不受到影响。\n这称为顺行性失忆。\n海马体 长期记忆存储转换、空间位置定向\n记忆遗忘曲线 密集学习 间隔学习 艾宾浩斯遗忘曲线，过于著名，无需介绍。\n25.jpg\r这个告诉我们，应该采用间隔学习而不是密集学习。比如我们应该一个星期背十遍单词，而不是一天背十遍。\n人工智能专业 记忆存在在哪里 并举出一个例子 PPT没给，我猜测是存在神经网络之中。\n例子：利用预训练好的GAN（生成对抗网络）作为记忆存储器；提取GAN中的知识记忆，并作为先验指导人脸图像的修复。\n贝叶斯大脑定义 贝叶斯定理 大脑可能遵循贝叶斯定理。大脑不是外部世界刺激信号的“记录机”，而是在先验知识引导下，主动进行加工、推理与生成预测。\n贝叶斯网络 贝叶斯准则和图论相结合形成贝叶斯网络。\n沟通与语言 语言的广义和严格定义 语言就广义而言，是一套共同采用的沟通符号、表达方式与处理规则。\n严格来讲，语言是由语音、词汇和语法构成并能表达人类思想的符号系统。\n不同生物的沟通方式 果蝇：嗅觉、拍打、唱歌 蜜蜂：跳舞 长尾猴：吼叫 红毛猩猩：手势 研究动物沟通有助于了解人类语言演化 无\n人类语言关键不在于喉咙结构，而在于脑区！ 无\n人类语言演化历程 30w年前有口语（喉头位置推断），17w年前有语法（FOXP2基因），5w年前有壁画，6000年前有文字。\n语言不是人类独有的 无\n布罗卡失语症 表达性失语症 Broca区（按高中来说是S区）负责说话、发音。Broca去病变引起运动性失语症或表达性失语症。阅读、理解、书写不受影响，知道想说什么，但是发音困难。\n韦尼克失语症 感知性失语症 Wernicke区（H区）负责听懂说话。病变时可以正常流利讲话，但是话可能没有意义，并且不能听懂他人讲话。并且自己意识不到自己的问题。也叫听觉性失语症。\n其他失语症：失读症 失写症 命名型失语症 视觉性语言中枢也称阅读中枢（V区）。病变时，不能读懂字，称为失读症。\n书写性语言中枢也称书写中枢（W区）。病变时，写字、绘画等精细运动出现障碍，称为失写症。\n命名型失语症即患者不能说出一个东西的名字，得靠手势描述等方法才能指明手边的物件。\n心理词典 大脑中词汇组织方式 心理词典根据单词间的意义关系组织起来。比如car和truck、bus、taxi关联起来。cat和dog、rabbit、mouse关联起来。\n26.jpg\r不同性质的词汇会被储存在不同的脑区。\n语言对认知的影响 不同语言的母语者对于一些事物的认知有区别。\n自然语言处理的发展历程 NLP-规则时代 机器只能理解规则和逻辑，把语言抽象成规则和逻辑\nNLP-统计模型时代 一个句子是否合理，取决于其出现在自然语言中的可能性\nNLP-DL1代 本质上还是概率模型，用NN计算概率语言模型的参数。这是一个过渡期，使用向量法。\nNLP-DL2代 RNN及类RNN时期。\nNLP-DL3代 使用预训练语言模型（Transformer-GPT/BERT）\n每个人的语言区定位都不同。虽然每个人都有类似的语言区， 但是语言区在大脑的定位都不同。 无\n情感与计算-报偿与成瘾 动机的定义 与 分类 动机是引起个体活动，维持并促使活动朝向某一目标进行的内部动力。\n动机可以分为两类：\n生理动机：为了降低基本生理需求（很奇怪的一句话，难道不是维持吗）。这个动机的行为称为摄取行为，为了维持生理恒定。 奖赏动机：并无非要不可的理由，不符合降低基本需求的条件。这个动机的行为称为欲望行为，为满足奖赏（报偿）动机。 动机激发过程 27.jpg\r动物动机强弱 定义\n动机的强弱可由“获得奖励”的努力去评估。\n在缺乏立即目标的情况下，动物产生奖赏动机，并必须利用过去学习的经验来预测获得奖赏的可能性。可能包含：\n经典条件反射：又称为经典制约。例如巴甫洛夫狗与食物关联。不受意识控制的非自愿行为。 ，目标导向的操作条件反射：又称为操作性制约。这是受意识控制的自愿行为。（强化学习的原理） 测量方法实验\n静脉自身给药模型，脑电击奖赏模型，条件性位置偏爱。\n可卡因剂量实验测量动机大小\n28.jpg\r多巴胺与动机关系\n多巴胺可以引起兴奋、欣快的感觉。\n多巴胺的水平对于“报偿效应”十分关键。\n当人作出某一决策后，如果被证实正确并产生了好的结果，大脑会向负责决策的区域发送“报偿”信号，这会促进人的认知能力进一步提升，形成良性循环，这被称作报偿效应。\n而报偿效应和奖赏动机的关系见前。\n脑电击奖赏模型测量多巴胺与动机关系\n29.jpg\r环境连结实验喜爱程度去评估动机大小\n30.jpg\r更喜爱哪个环境来比较动机大小\n见上\n药品上市之前的实验\n无\n引起兴奋、欣快感觉的脑内物质 有三种: 多巴胺、血清素和内啡肽\n多巴胺报偿途径 有两条，起点都位于中脑，一条成瘾通路，一条与惯性学习、程序性记忆有关\n多巴胺何时释放、设计实验验证 多巴胺在期待奖赏的时候会大量释放。\n多巴胺神经元对奖赏出现反应。\n多巴胺神经元对预测奖赏反应，但对奖赏出现没有反应。\n多巴胺神经元对预测奖赏反应，但对奖赏未出现产生抑制反应。\n多巴胺突出效能调整过程 关于大脑奖赏系统，多巴胺的作用不是实现奖赏，而是奖赏的预期，也就是说某种行为能够导致获得奖赏的期望有多大。\n强化学习的过程就是使得每个行为决策的改进都朝向提高奖赏期望的方向。\n多巴胺强化学习的作用要依赖试错学习过程的记忆，因此海马和杏仁核作用很关键，有短期和长期作用，短期作用依赖于突触间隙中多巴胺浓度的调整，能够短期强化某种行为或者大脑网络，长期作用则依赖突触后神经元受体数量的调整，能够长时间强化某种行为或者大脑网络。两者可以统称为多巴胺突触效能调整。\n成瘾带来痛苦 不是快乐 毒品“绑架”脑中的报赏中枢。\n成瘾性最高的毒品如海洛因，甚至可能打一、两次就会成瘾。成瘾后会产生耐受性，造成需要更大量的药物，才能得到同样的效果，否则就会产生身心双重痛苦。因此大部分人一旦上瘾，不是为了追求快乐，而是为了避免戒掉的痛苦才会继续。\n毒品戒断症状定义 与多巴胺水平的关系 戒断时期，多巴胺急速下降，比药物使用前还低。\n成瘾的正负强化机制 所有的毒品都有两种作用，毒品通过两种作用协同作用引起精神依赖和生理依赖，即正性强化与负性强化。\n正性强化:初期吸毒后可产生强烈的欣快感和松弛宁静感，这种感觉能满足吸毒者的心理需要，产生精神依赖，吸毒者会再次吸毒;\n负性强化:成瘾后，停止吸毒后会产生难以忍受的痛苦，也就是通常所说的“戒断症状”产生身体依赖，吸毒者只得继续追求药物。这两种强化使人成瘾并难以自拔。\n成瘾对脑造成长期性伤害 古柯碱、酒精、鸦片类与安非他命等滥用药物，都会霸占脑部原有的报偿线路。\n重复使用这些药物，会造成脑部化学与构造上的长期变化，因而改变报偿系统神经元处理信息与互动的方式。\n成瘾难以戒除的原因：树突棘、神经结构、多巴胺系统 树突棘增加可放大神经元间的信号，也可能让脑部对引发联想的东西过度反应，或许这便是成瘾难以戒除的关键。\n其他几个见上节。\n烟瘾成瘾过程 尼古丁会刺激抑欲系统，直到其活性会超过欲求系统。大脑迅速产生适应，大幅增强欲求系统的活性，试图恢复平衡。\n尼古丁效应逐渐消退后，抑欲系统不再受到刺激而回到较低的活性状态。但因为受到戒断相关适应的促进作用，欲求系统超越了抑欲系统的活性，因而渴望可以抑欲的事\u0026ndash;再抽一根烟。\n赌瘾和毒瘾没什么区别 都会类似方式重组神经回路 无\n咖啡不会上瘾 只会产生依赖性 致瘾药物必须摄取量逐渐增加才能发挥作用 无\n情感与计算-理性与感性 前额叶 主要功能\n执行具有意义的目标导向行为\n组成部分\n背外侧、腹内侧、眶额回\n每部分的主要功能\n前两部分负责认知处理。眶额回主要和情绪处理相关。\n灵长类生物的前额叶面积更大 无\n前额受损病人心智产生的影响 设计实验 无法抑制自己的行为 无法控制自己的情绪 无法有效的做计划与执行计划 无法有工作记忆 前额叶是有限理性。\n情绪不是什么 关于情绪的说法 情绪与认知关系 不是情景的思考整合。不是推理。当人们情绪激动时，它不能透过称述心中的想法来了解这个情绪。\n刺激→ 激发→ 认知→ 感觉。 情绪刺激的评估理论：情绪是对任何被评为好的有正感觉倾向，对任何被评为不好的有远离感觉倾向，这个评估的历程是潜意识的。刺激→ 评估→ 动作倾向→ 感觉。 感情优先理论。刺激→ 潜意识的感情→ 感觉 情绪和认知是分开的，但相互作用的心智功能，是靠着不同但有互动的大脑系统来媒介运作的\n恐惧情绪 高低通路 解释盲视病人 低通道：丘脑到杏仁核：恐惧感受可以在快速且无意识状态下刺激杏仁核。\n高通道：丘脑到视觉皮层看清晰图像之后，再传回杏仁核。\n模糊图像比清晰图像更让人产生恐惧情绪\n盲视（blindsight）的人看不见物体却能躲避障碍，是因为走了低通道。\n情绪的长短通路 各有什么特点 画图表示 31.jpg\r长通路称为“理性脑”，短通路称为“情绪脑”。\n除了路径长短外：长通路携带信息多，对信息的加工更为精细，需要更长时间。短通路只能携带少量信息，速度很快。\n人脑三位一体 爬行脑 哺乳脑 新脑 见前。\n补充：古脑（爬行脑）是本能脑或者生存脑；旧脑（哺乳脑），主要是边缘系统，是情绪脑；新脑（新皮质，新哺乳动物脑），是视觉脑或智慧脑或理性脑。\n6 种基本情绪、对应脑区 生气（眶额皮质，扣带前回）、快乐（没写）、厌恶（前脑岛，扣带前回）、惊讶（没写）、伤心（杏仁核，右侧颞极）、恐惧（杏仁核）\n杏仁核受伤病人 不知恐惧：分辨表情、画恐惧表情、恐惧制约\n恐惧制约实验 无\n意识记忆与海马 情绪记忆与杏仁核 海马区：情景记忆（意识记忆、情节记忆）\n杏仁核：情绪记忆\n意识记忆和情绪记忆脑机制不同。\n镁光灯记忆 无\n3 岁以内的孩子没有记忆，但有创伤性记忆 无\n情绪与决策 32.jpg\r情绪与心理障碍、焦虑、社会感情 焦虑是来自内心，恐惧是来自外界。\n焦虑是一个不可化解的恐惧。\n罪恶感、羞耻心、嫉妒、困窘、骄傲等，这些与社会行为有关的感情，发展的时间都晚于另一些比较基本的感情像是快乐、恐怖等\n社会感情引领我们的复杂的社会行为，包括渴望帮助他人以及想要惩罚欺骗着，即使需要付出代价也在所不惜\nPTSD 相关脑结构和功能的变化 前扣带回：体积变小，活性降低；认知功能有关；与前额叶构成注意监控系统；检测冲突和可能出现的错误\n内侧前额叶：体积变小，活性降低；认知功能有关；情绪控制密切相关\n杏仁核：过度活跃，经常产生异常情绪反映；恐惧\n海马：体积变小，影响记忆形成\n感情调节方式：分心，重新评估 分心：把注意力转到别的事情上，往往通常是暂时的\n重新评估：借由重新思考某个事件的意义，来改变你对它的感受。擅长重新评估的人，多半情绪比较稳定(EQ较高)。看心理医生能获得的好处，也是因为改善了重新评估的能力，用比较建设性的方式去看事情。\n情感与计算-选择与决策 画图表示选择引起的情绪变化、并解释 33.jpg\r极大化者和满足化者定义 极大化者：做任何决定都寻求最好的结果，不停的在各种选择之间比较，期待找到一个最好的选择 满足化者：只要找到了符合自己标准的东西，就立即停止，不会继续找下去。 选择多失落感越深的原因分析 机会成本\n为了得到某种利益而所要放弃另一些利益的最大价值，被放弃的就是机会成本\n沉没成本\n人们在做出决策时，往往会受到过去的决策和损失的影响，从而导致对当前决策的不满和后悔。\n当人们已经投入了一定的时间、金钱或其他资源，但是最终决策并不理想，这些投入就会成为沉没成本。\n后悔心理\n后悔心理是指当人们面临难以避免的选择时，经常会因为过去的决策而后悔，\n损失规避心理\n失去的痛苦要远大于得到的快感。\n适应心理\n适应现象简单的说是指我们会对事物产生习惯，所以生命中很少会有事物像我们所预期的一样好。\n高期待高失望\n选择障碍的建议 选择何时做选择（限制选择范围） 学习接受“够好了” 错过的就别烦恼 控制你的期待 该用脑袋的哪个部分做决策 34.jpg\r定势效应 及 建议 定势效应：人们在认知活动中习惯用已有的知识经验，来看待当前的问题。也会因为在固定的环境中工作和生活，久而久之形成一种固定的思维模式。也习惯于从固定的角度来观察、思考和接受事物。\n这种认知捷径，有时会忽略更有效或者更适合的方法\n人工与系统 类脑研究的目标 目标是人造超级大脑。\n数值计算为基础的虚拟超级脑和以虚拟脑与生物脑为基础的脑机一体化超级大脑\n为了实现类脑计算系统，从哪些方面理解脑计算？ 明确不同尺度脑信息处理的基本单元 明确脑信息处理的重要原理和过程 揭示脑功能进化的过程和原理 类脑研究存在的挑战 35.jpg\r脑机接口的定义和应用 脑机接口(BCI)，也称作脑机融合技术，就是通过芯片和传感器，用大脑控制各种设备，也可以向大脑反馈触觉信息，再来指导输出，形成一个闭环。对患者或者常人难以企及的应用场景有着重要意义。\n正常人和心理变态罪犯的在处理负性情绪时的活性脑区不一样 无\n人工智能发展所面临的风险并解释 36.jpg\r2019 年两项人工智能伦理原则 八项原则 37.jpg\r","date":"2023-06-11T15:11:44+08:00","permalink":"https://kegalas.top/p/%E8%84%91%E7%A7%91%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"脑科学基础学习笔记"},{"content":"集成运算放大器 基本分析方法 一个集成运算放大器的典型形式如下\n1.jpg\r分析它的基本方式是：\n虚短：\\(u_+=u_-\\) 虚断：\\(i_+=i_-=0\\) 以下是集成运算放大器的一些参数：\n\\(u_{id}=u_{i+}-u_{i-}\\)：差模输入电压 \\(A_{uo}\\)：集成运放的开环电压放大倍数 \\(R_i\\)：集成运放的输入电阻 \\(R_o\\)：集成运放的输出电阻 其中理想条件是\\(R_i\\to\\infty,R_o\\to 0,A_{uo}\\to\\infty,i_+=i_-=0\\)。\n电压传输特性 2.jpg\r后记：假设把一个正的电压接到同相输入端，则输出端为正；把一个正的电压接到反相输入端，则输出为负。这个在后面的反馈分析中有用。\n基本运算电路 反向比例运算电路 3.jpg\r（根据虚短虚断）可以计算得到\n\\[u_O = -\\dfrac{R_f}{R}u_I \\]\n其中输出电阻\\(R_o=0\\)，输入电阻\\(R_i=R\\)\n同相比例运算电路 4.jpg\r\\[u_O = (1+\\dfrac{R_f}{R})u_I \\]\n引入了电压串联负反馈，可以认为输入电阻无穷大，输出电阻为\\(0\\)\n电压跟随器 5.jpg\r\\[u_O = u_I \\]\n反向求和运算电路 6.jpg\r\\[u_O = -R_f\\bigg(\\dfrac{u_{I1}}{R_1}+\\dfrac{u_{I2}}{R_2}+\\dfrac{u_{I3}}{R_3}\\bigg) \\]\n可以看作是反相比例放大器的叠加电路，输入电阻取决于不同的端口。\n同相求和运算电路 7.jpg\r\\[u_O = R_f\\cdot\\dfrac{R_P}{R_N}\\cdot \\bigg(\\dfrac{u_{I1}}{R_1}+\\dfrac{u_{I2}}{R_2}+\\dfrac{u_{I3}}{R_3}\\bigg) \\]\n其中，\\(R_P = R_1\\parallel R_2\\parallel R_3\\parallel R_4, R_N = R\\parallel R_f\\)，若\\(R_P=R_N\\)，则\n\\[u_O = R_f\\cdot \\bigg(\\dfrac{u_{I1}}{R_1}+\\dfrac{u_{I2}}{R_2}+\\dfrac{u_{I3}}{R_3}\\bigg) \\]\n加减运算电路 其实就是把上面两个电路结合一下。\n8.jpg\r\\[u_O = R_f\\bigg(\\dfrac{u_{I3}}{R_3}+\\dfrac{u_{I4}}{R_4}-\\dfrac{u_{I1}}{R_1}-\\dfrac{u_{I2}}{R_2}\\bigg) \\]\n要求\\(R_1\\parallel R_2\\parallel R_f=R_3\\parallel R_4\\parallel R_5\\)\n差分比例运算电路 是加减运算电路的一种特例，其只有两个输入，且参数对称\n9.jpg\r\\[u_O = \\dfrac{R_f}{R}(u_{I2}-u_{I1}) \\]\n积分器 10.jpg\r\\[u_O = -\\dfrac{1}{RC}\\int u_Idt \\]\n微分器 11.jpg\r\\[u_O = -RC\\dfrac{du_I}{dt} \\]\n滤波器 滤波器可以分为无源和有源滤波器。如果滤波电路仅由无源元件（电阻、电容、电感）组成，则称为无源滤波电路。如果滤波电路由无源元件和有源元件（双极型管，单极型管、集成运放）共同组成，则称为有源滤波电路。\n我们主要讨论有源滤波器。在分析有源滤波电路时，常常通过拉普拉斯变换将电压、电流、以及无源元件变换为等效电路（具体见信号与系统学习笔记）。输出量与输入量之比称为传递函数，即\n\\[A_u(s) = \\dfrac{U_o(s)}{U_i(s)} \\]\n下面介绍的都是有源滤波电路。\n一阶同相输入低通滤波器 12.jpg\r其传递函数为\n\\[A_u(s)=\\dfrac{U_o(s)}{U_i(s)}=\\bigg(1+\\dfrac{R_2}{R_1}\\bigg)\\dfrac{U_p(s)}{U_i(s)}=\\bigg(1+\\dfrac{R_2}{R_1}\\bigg)\\dfrac{1}{1+sRC} \\]\n用\\(jw\\)取代\\(s\\)，令\\(f_0=\\dfrac{1}{2\\pi RC}\\)，得到\n\\[\\dot{A}_u = \\bigg(1+\\dfrac{R_2}{R_1}\\bigg)\\cdot\\dfrac{1}{1+j\\dfrac{f}{f_0}} \\]\n式中\\(f_0\\)称为特征频率。令\\(f=0\\)，得到通带放大倍数。\n\\[\\dot A_{up}=1+\\dfrac{R_2}{R_1} \\]\n当\\(f=f_0\\)时，\\(\\dot A_u=\\dfrac{\\dot A_{up}}{\\sqrt 2}\\)，故通带截止频率\\(f_p=f_0\\)。\n二阶同相输入低通滤波器 13.jpg\r假设\\(C_1=C_2=C\\)\n\\[A_u(s) = \\bigg(1+\\dfrac{R_2}{R_1}\\bigg)\\dfrac{1}{1+3sRC+(sRC)^2} \\]\n用\\(jw\\)取代\\(s\\)，令\\(f_0=\\dfrac{1}{2\\pi RC}\\)，得到\n\\[\\dot A_u = \\dfrac{1+\\dfrac{R_2}{R_1}}{1-\\bigg(\\dfrac{f}{f_0}\\bigg)^2+j3\\dfrac{f}{f_0}} \\]\n称\\(f_0\\)为特征频率。令上式分母的模等于\\(\\sqrt 2\\)，可以解出通带截止频率为\\(f_p\\approx 0.37f_0\\)。\n一阶反向输入低通滤波器 14.jpg\r通带放大倍数为\n\\[\\dot A_{up} = -\\dfrac{R_2}{R_1} \\]\n电路的传输函数为\n\\[A_u(s) = -\\dfrac{R_2\\parallel\\dfrac{1}{sC}}{R_1}=\\dfrac{R_2}{R_1}\\dfrac{1}{1+sR_2C} \\]\n用\\(jw\\)取代\\(s\\)，令\\(f_0=\\dfrac{1}{2\\pi R_2C}\\)\n\\[\\dot A_u = \\dfrac{\\dot A_{up}}{1+j\\dfrac{f}{f_0}} \\]\n截止频率\\(f_p=f_0\\)\n二阶反向输入低通滤波器 15.jpg\r\\[\\dot A_{up} = -\\dfrac{R_f}{R_1} \\]\n教材上并没有给出\\(\\dot A_u\\)的表达式和截止频率。\n\\[f_0=\\dfrac{1}{2\\pi\\sqrt{C_1C_2R_2R_f}} \\]\n二阶高通滤波器 16.jpg\r\\[\\dot A_{up} = 1+\\dfrac{R_f}{R_1} \\]\n\\[f_p = \\dfrac{1}{2\\pi RC} \\]\n带通滤波器 将低通和高通串联，就得到带通。\n设前者的截止频率为\\(f_{p1}\\)，后者的截止频率为\\(f_{p2}\\)，则\\(f_{p2}\\)应该小于\\(f_{p1}\\)，则通带为\\((f_{p1}-f_{p2})\\)\n17.jpg\r\\[\\dot A_{uf} = 1+\\dfrac{R_f}{R_1} \\]\n当\\(C_1=C_2=C,R_1=R,R_2=2R\\)，令\\(f_0=\\dfrac{1}{2\\pi RC}\\)（中心频率）\n\\[\\dot A_u = \\dfrac{1}{1+j\\dfrac{1}{3-\\dot A_{uf}}\\bigg(\\dfrac{f}{f_0}-\\dfrac{f_0}{f}\\bigg)}\\dfrac{\\dot A_{uf}}{3-\\dot A_{uf}} \\]\n当\\(f=f_0\\)\n\\[\\dot A_{up}=\\dfrac{\\dot A_{uf}}{|3-\\dot A_{uf}|} \\]\n\\[f_{p1} = \\dfrac{f_0}{2}\\bigg(\\sqrt{(3-\\dot A_{uf})^2+4}-(3-\\dot A_{uf})\\bigg) \\]\n\\[f_{p2} = \\dfrac{f_0}{2}\\bigg(\\sqrt{(3-\\dot A_{uf})^2+4}+(3-\\dot A_{uf})\\bigg) \\]\n带阻滤波器 将输入电压同时作用于低通和高通，再将两个电路的输出电压求和，就可以得到带阻滤波器。\\(f_{p1}\u003c f_{p2}\\)，阻带为\\((f_{p2}-f_{p1})\\)\n18.jpg\r\\[\\dot A_{up} = 1+\\dfrac{R_f}{R_1} \\]\n全通滤波器（移相器） 19.jpg\r\\[\\dot A_u = \\dfrac{1-jwRC}{1+jwRC} \\]\n也即\n\\[|\\dot A_u| = 1 \\]\n\\[\\varphi = 180\\degree-2arctan\\dfrac{f}{f_0},f_0=\\dfrac{1}{2\\pi RC} \\]\n滤波器判断 为了避免积分、微分运算，把电路转变为拉普拉斯变换下的等效电路是必要的。\n通过拉普拉斯变换，我们可以更容易地得到输入-输出关系，或者就是求出系统函数（传递函数）。通过系统函数我们可以方便地判断滤波器的类型。\n一阶还是二阶\n传递函数中，分子分母的多项式，如果其中一个最高含有\\(s^2\\)项，则是二阶。如果两个都最高只含\\(s\\)项，就是一阶。\n二阶低通\n传递函数常见为\n\\[H(s) = \\dfrac{H(0)w_0^2}{s^2+\\dfrac{w_0}{Q}s+w_02} \\]\n其零极点图，包含了两个共轭的极点。\n二阶高通\n传递函数常见为\n\\[H(s) = \\dfrac{H(\\infty)s^2}{s^2+\\dfrac{w_0}{Q}s+w_02} \\]\n其零极点图，包含了两个共轭的极点，一个取值为零的二阶零点。\n二阶带通\n传递函数常见为\n\\[H(s) = \\dfrac{H(w_0)\\dfrac{w_0}{Q}s}{s^2+\\dfrac{w_0}{Q}s+w_02} \\]\n其零极点图，包含了一个取值为\\(0\\)的零点，两个共轭极点。\\(Q\\)为品质因数，越大，带宽越窄，选频性能越好。\n二阶带阻\n传递函数常见为\n\\[H(s) = \\dfrac{H(0)(s^2+w_0^2)}{s^2+\\dfrac{w_0}{Q}s+w_02} \\]\n其零极点图，两个零点，两个共轭极点。\\(Q\\)越大，陷波特性越尖锐。这两个零点是共轭的，在\\(jw\\)轴上。\n二阶全通\n传递函数常见为\n\\[H(s) = \\dfrac{H(0)(s^2-\\dfrac{w_0}{Q}s+w_0^2)}{s^2+\\dfrac{w_0}{Q}s+w_02} \\]\n其零极点图，两个共轭零点，两个共轭极点。构成一个矩形。\n一阶\n不知道为什么书上没讲一阶电路判断。但是根据传递函数多少也能看明白。\n半导体器件 半导体基础知识 本征半导体\n纯净的具有晶体结构的半导体称为本征半导体。例如硅和锗的纯净半导体。\n本征半导体中，共价键的价电子可以获得足够大的能量，挣脱共价键的束缚，游离出去，成为自由电子，并在共价键处留下带有一个单位的正电荷的空穴。这个过程称为本征激发。\n本征激发产生成对的自由电子和空穴，所以本征半导体中自由电子和空穴的数量相等。\n价电子的反向递补运动等价为空穴在半导体中自由移动。因此，在本征激发的作用下，本征半导体中出现了带负电的自由电子和带正电的空穴，二者都可以参与导电，统称为载流子。\n杂质半导体\n往本征半导体里掺入少量合适的杂质元素，便可得到杂质半导体。按掺入的杂质元素不同，可以分成N型半导体和P型半导体。\nN型半导体\n在本征半导体中掺入五价原子，即构成N型半导体。N型半导体中每掺杂一个杂质元素的原子，就提供一个自由电子，从而大量增加了自由电子的浓度。\nN型半导体中，自由电子的浓度大于空穴的浓度，故称自由电子为多数载流子，空穴为少数载流子，前者也称为多子，后者也称为少子，由于杂质原子可以提供电子，故称为施主原子。\nP型半导体\n在本征半导体中掺入三价原子，即构成P型半导体。P型半导体中每掺杂一个杂质元素的原子，就提供一个空穴，从而大量增加了空穴的浓度。\nP型半导体中，空穴为多子，自由电子为少子，主要靠空穴导电。因杂质原子中的空位吸收电子，故称之为受主原子。\n漂移电流和扩散电流\n漂移电流：在电场的作用下，自由电子会逆着电场方向漂移，而空穴则顺着电场方向漂移，这样产生的电流称为漂移电流，该电流的大小主要取决于载流子的浓度，迁移率和电场强度。\n扩散电流：半导体中载流子浓度不均匀分布时，载流子会从高浓度区向低浓度区扩散，从而形成扩散电流，该电流的大小正比于载流子的浓度差即浓度梯度的大小。\nPN结\n通过掺杂工艺，把本征半导体的一边做成 P 型半导体，另一边做成 N 型半导体，则 P 型半导体和 N 型半导体的交接面处会形成一个有特殊物理性质的薄层，称为 PN 结。\n在无外电场和其他激发作用下，参与扩散运动的多子数目等于参与漂移运动的少子数目，从而达到动态平衡，形成PN结。\n由于扩散到P区的自由电子与空穴复合，而扩散到N区的空穴与自由电子复合，所以在交界面附近多子的浓度下降，P区出现负离子区，N区出现正离子区，它们是不能移动的，称为空间电荷区（耗尽层），从而形成内电场。\n当外加电压极性不同时，PN结表现出截然不同的导电性能。\n当电源的正极接到PN结的P端，且电源的负极接到PN结的N端时，称PN结外加正向电压，也称正向接法或正向偏置。此时空间电荷区变窄，削弱内电场，使扩散运动加剧，漂移运动减弱。由于电源的作用，扩散运动将源源不断地进行，从而形成正向电流，PN结导通。\n当电源的正极接到PN结的N端，且电源的负极接到PN结的P端时，称PN结外加反向电压，也称反向接法或反向偏置。加强了内电场，阻止扩散运动，加剧漂移运动。但是少子数目极少，反向电流非常小，所以常常忽略不计，认为PN结外加反向电压时处于截止状态。\nPN结的电流方程\nPN结所加端电压\\(u\\)与流过它的电流\\(i\\)的关系为\n\\[i = I_S(e^{\\frac{qu}{kT}}-1) \\]\n其中\\(I_S\\)为反向饱和电流，\\(q\\)为电子的电量，\\(k\\)为玻尔兹曼常数，\\(T\\)为热力学温度，将\\(kT/q\\)用\\(U_T\\)取得，得到\n\\[i = I_S(e^{u/U_T}-1) \\]\n常温下，即\\(T=300K\\)时，\\(U_T\\approx26\\text{mV}\\)，称\\(U_T\\)为温度的电压当量。\nPN结的伏安特性、击穿特性\n当施加正向电压，且\\(u\u003e\u003eU_T\\)时，\\(i\\approx I_Se^{u/U_T}\\)，即指数变化。反向电压时，当\\(|u|\u003e\u003eU_T\\)，\\(i\\approx -I_S\\)。画出图如下\n20.jpg\r\\(u\u003e0\\)时为正向特性，\\(u\u003c0\\)时为反向特性。\n当反向电压超过一定数值\\(U_{(BR)}\\)后，反向电流急剧增加，称之为反向击穿。击穿可以分为齐纳击穿和雪崩击穿。\n在高掺杂的情况下，因为耗尽层的宽度很窄，不大的反向电压就可以在耗尽层形成很强的电场，从而直接破坏共价键，使价电子脱离共价键束缚，产生电子-空穴对，致使电流急剧加大，这种击穿称为齐纳击穿。齐纳击穿电压较低。\n如果掺杂浓度低，耗尽层宽度较宽，那么低反向电压下不会产生齐纳击穿。当反向电压较大，耗尽层的电场使少子加快漂移速度，从而与共价键中的价电子相碰撞，把价电子撞出共价键，产生电子-空穴对。新产生的电子与空穴被电场加速后又撞出其他价电子，载流子雪崩式地倍增，致使电流急剧增加，称为雪崩击穿。\nPN结的电容特性\n一定条件下，PN结具有电容效应，根据产生的原因不同分为势垒电容\\(C_b\\)和扩散电容\\(C_d\\)\nPN结的结电容\\(C_j=C_b+C_d\\)\n一般两个电容都很小，对于低频信号呈现出很大的容抗，可以忽略不计。只有在信号频率较高时才考虑结电容的作用。\n二极管 将PN结用外壳封装起来加上电极引线就构成了半导体二极管，简称二极管。P区的电极称为阳极，N区的称为阴极。\n二极管的伏安特性 和PN结差不多，但是由于二极管存在半导体体电阻和引线电阻，所以当外加正向电压时，在电流相同的情况下，二极管的端电压大于PN结上的压降。并且二极管表面有漏电流，在外加反向电压时反向电流增大。\n21.jpg\r实测发现，只有当正向电压足够大的时候，正向电流才指数增长。使得二极管开始导通的临界电压称为开启电压\\(U_{on}\\)。施加反向电压足够大的反向电流为\\(I_S\\)，太大则会击穿。\n硅管的典型导通电压为\\(0.7V\\)，锗管的典型导通电压为\\(0.2V\\)。\n二极管的特性对温度很敏感。\n二极管的等效电路 22.jpg\r等效电路是理想二极管串联电压源\\(U_{on}\\)和电阻\\(r_D\\)，且\\(r_D=\\Delta U/\\Delta I\\)\n在做题算直流电阻的时候，直接把某个点的电压除以电流即可。算交流电阻时，用\\(U_T\\)除以该点的电流即可。\n稳压二极管 稳压管在反向击穿时，在一定的电流范围内，端电压几乎不变，表现出稳压特性。\n23.jpg\r稳定电压\\(U_Z\\)是在规定电流下稳压管的反向击穿电压。 稳定电流\\(I_Z(I_{Zmin})\\)是稳压管工作在稳压状态时的参考电流。 最大稳定电流\\(I_{ZM}(I_{Zmax})\\)，电流超过这个值时，功耗会过大，超过额定功耗\\(P_{ZM}\\)，可能烧坏PN结。 二极管应用电路 整流电路\n24.jpg\r限幅电路\n25.jpg\r电平选择电路\n26.jpg\r晶体三极管 基本类型 27.jpg\rNPN型三极管如上。\n28.jpg\rPNP型三极管如上。\n使晶体管工作在放大状态的外部条件是，发射结正偏且集电结反偏。NPN型，就是\\(U_{be}\u003eU_{on}\\)，并且\\(U_{bc}\u003c0\\)。\\(PNP\\)型就是\\(U_{be}\u003c-U_{on}\\)且\\(U_{bc}\u003e0\\)。\n晶体管的放大作用体现在小的基极电流可以控制大的集电极电流。\n内部载流子运动与外部电流 以NPN型为例\n29.jpg\r内部看\n\\[I_E = I_{EN}+I_{EP}=I_{CN}+I_{BN}+I_{EP} \\]\n\\[I_C=I_{CN}+I_{CBO} \\]\n\\[I_B = I_{BN}+I_{EP}-I_{CBO} = I'_B-I_{CBO} \\]\n从外部看\n\\[I_E = I_C+I_B \\]\n注意从外部看PNP型的方程一样，但是三个电流方向都相反。\n共发射极放大倍数\n\\[\\bar\\beta = \\dfrac{I_{CN}}{I'_B}=\\dfrac{I_C-I_{CBO}}{I_B+I_{CBO}} \\]\n一般情况下\\(I_B\u003e\u003eI_{CBO},\\bar\\beta\u003e\u003e1\\)，所以\n\\[I_C\\approx\\bar\\beta I_B,\\quad I_E\\approx(1+\\bar\\beta)I_B \\]\n如果输入电压是动态电压，则\n\\[\\beta = \\dfrac{\\Delta i_C}{\\Delta i_B} \\]\n在\\(|\\Delta i_B|\\)不太大时，可以认为\\(\\beta\\approx\\bar\\beta\\)\n共基极直流放大倍数\n\\[\\bar\\alpha = \\dfrac{I_{CN}}{I_E} \\]\n同样一般有\n\\[I_C\\approx \\bar\\alpha I_E \\]\n我们可以得到关系式\n\\[\\bar\\beta = \\dfrac{\\bar\\alpha}{1-\\bar\\alpha},\\quad\\bar\\alpha=\\dfrac{\\bar\\beta}{1+\\bar\\beta} \\]\n同样\n\\[\\alpha = \\dfrac{\\Delta i_C}{\\Delta i_E} = \\dfrac{\\beta}{1+\\beta} \\]\n通常\\(\\beta\u003e\u003e1\\)，故\\(\\alpha\\approx1\\)；而且与\\(\\beta\\approx\\bar\\beta\\)相同，\\(\\alpha\\approx\\bar\\alpha\\)\n这两个放大倍数在NPN和PNP型处于放大区都可以用，注意电流方向即可。\n共射特性曲线 输入特性曲线\n输入特性曲线描述在管降压\\(U_{CE}\\)一定的情况下，基极电流\\(i_B\\)与发射结降压\\(U_{BE}\\)之间的函数关系，即\n\\[i_B = f(U_{BE})\\bigg|_{U_{CE}=常数} \\]\n30.jpg\r输出特性曲线\n输出特性曲线描述基极电流\\(I_B\\)为一常量时，集电极电流\\(i_C\\)与管降压\\(U_{CE}\\)之间的函数关系，即\n\\[i_C = f(U_{CE})\\bigg|_{I_B=常数} \\]\n31.jpg\r截止区\n其特征是发射结电压小于开启电压且集电结反向偏置。对于共射电路，\\(u_{BE}\\leq U_{on}\\)且\\(u_{CE}\u003eu_{BE}\\)。此时\\(I_B=0\\)，近似认为\\(i_c\\approx0\\)\n放大区\n其特征是发射结电压正向偏置且集电结反向偏置。对于共射电路，\\(u_{BE}\u003eU_{on}\\)且\\(u_{CE}\\geq u_{BE}\\)。此时\\(i_C\\)几乎仅仅决定于\\(i_B\\)，而与\\(u_{CE}\\)无关。\\(I_C=\\bar\\beta I_B, \\Delta i_C=\\beta\\Delta i_B\\)\n饱和区\n其特征是发射极与集电极均正向偏置。对于共射电路，\\(u_{BE}\u003eU_{on}\\)且\\(u_{CE} \u003c u_{BE}\\)。此时\\(i_C\\)不仅与\\(i_B\\)有关，而且明显随\\(u_{CE}\\)增大而增大，\\(i_C\\)小于\\(\\bar\\beta I_B\\)。此时\\(u_{CE}=U_{CE(sat)}\\)，通常为\\(0.2\\sim 0.3\\text{V}\\)\n放大电路的分析方法 放大的主要性能指标 放大倍数\n电压放大倍数\\(\\dot A_{uu}=\\dot A_{u}=\\dfrac{\\dot U_o}{\\dot U_i}\\)\n电流放大倍数\\(\\dot A_{ii}=\\dot A_{i}=\\dfrac{\\dot I_o}{\\dot I_i}\\)\n互阻放大倍数\\(\\dot A_{ui}=\\dfrac{\\dot U_o}{\\dot I_i}\\)\n互导放大倍数\\(\\dot A_{ui}=\\dfrac{\\dot I_o}{\\dot U_i}\\)\n输入电阻\n\\[R_i = \\dfrac{U_i}{I_i} \\]\n输入电阻与信号源内阻无关。\n输出电阻\n\\[R_o = \\bigg(\\dfrac{U_o'}{U_o}-1\\bigg)R_L \\]\n其中\\(U_o'\\)为空载时输出电压的有效值，\\(U_o\\)为带负载后输出电压的有效值，\\(R_L\\)为负载电阻。但是，这个只是计算方法，输出电阻与负载无关。\n静态工作点 以共射放大电路为例。\n33.jpg\r当\\(u_i=0\\)时，称放大电路处于静态。\\(V_{BB}\\)使得\\(U_{BE}\u003eU_{on}\\)并且与\\(R_b\\)共同决定\\(I_B\\)，\\(V_{CC}\\)应该足够高，使得集电极反向偏置，从而保持在放大状态，此时\\(I_C=\\beta I_B\\)，并确定了\\(U_{CE}=V_{CC}-I_CR_c\\)\n图中的输入回路和输出回路以发射极为公共端，故称为共射放大电路。\n输入信号为零，直流电源单独作用时晶体管的\\(I_{B},I_{C},U_{BE},U_{CE}\\)称为放大电路的静态工作点\\(Q\\)，常记作\\(I_{BQ},I_{CQ},U_{BEQ},U_{CEQ}\\)，通常认为\\(U_{BEQ}\\)为已知量，硅管为\\(0.7V\\)，锗管为\\(0.2V\\)，并且认为\\(\\bar\\beta=\\beta\\)\n令\\(\\dot U_i=0\\)，从上面的电路可以解出\n\\[\\left\\{\\begin{matrix} I_{BQ}=\\dfrac{V_{BB}-U_{BEQ}}{R_b} \\\\ I_{CQ}=\\bar\\beta I_{BQ}=\\beta I_{BQ} \\\\ U_{CEQ} = V_{CC}-I_{CQ}R_c \\end{matrix}\\right. \\]\n直流通路与交流通路 32.jpg\r直流通路是在直流电源作用下直流电流流经的通路, 也就是静态电流流经的通路,用于研究静态工作点。对于直流通路,\n电容视为开路; 电感线圈视为短路(即忽略线圈电阻); 信号源视为短路,但应保留其内阻。 交流通路是输入信号作用下交流信号流经的通路, 用于研究动态参数。对于交流通路,\n容量大的电容(如耦合电容)视为短路, 无内阻的直流电源(如\\(V_{CC}\\))视为短路。 三极管等效电路 晶体管等效（在做题中几乎无用）\n34.jpg\r直流模型是在静态工作时的模型。必须在放大区才可以使用，并且要求\\(\\beta=\\bar\\beta\\)\n交流小信号模型（在做题中，注意\\(r_{be}\\)是怎么求的）\n35.jpg\r忽略\\(r_{bc}\\)的影响后，\n36.jpg\r\\[r_{be} = r_{bb'}+(1+\\beta)\\dfrac{U_T}{I_{CQ}} \\]\n\\[g_mU_{b'e}=\\beta I_b \\]\n这里的\\(r_{bb'}\\)是基区体电阻，\\(r_{b'e}\\)是发射结电阻。部分题目会用到来求\\(r_{be}\\)。\\(r_{bb'}\\)一般在几十到几百欧，题目没说就取\\(200\\)欧。\nh参数等效模型（最主要用这个分析题目）\n37.jpg\r这是静态工作点一节中的电路的等效。\\(r_{ce}\\)和\\(R_c\\)并联，它很大，可以忽略。\n可以计算\n\\[\\dot A_u = \\dfrac{\\dot U_o}{\\dot U_i} = -\\dfrac{\\beta R_c}{R_b+r_{be}} \\]\n\\[R_i = R_b+r_{be} \\]\n\\[R_o = R_c \\]\n特别指出，放大电路的输入电阻与信号源内阻无关，输出电阻与负载无关。\n这个等效电路可以用来分析交流情况。\n图解法 静态工作点的分析 38.jpg\r如图，当\\(\\Delta u_I=0\\)时，静态工作点既应在晶体管的输入特性曲线上，又应满足\n\\[u_{BE}=V_{BB}-i_BR_b \\]\n在输出回路中，静态工作点既应在\\(I_B=I_{BQ}\\)的那条输出特性曲线上，又应满足外电路的回路方程\n\\[u_{CE} = V_{CC}-i_CR_c \\]\n39.jpg\r于是我们就可以从图中读出静态工作点的数据。如果\\(I_B=I_{BQ}\\)的那条曲线没有，则应当补测。\n电压放大倍数的分析 40.jpg\r\\[u_{BE}=V_{BB}+\\Delta u_I-i_BR_b \\]\n\\[A_u = \\dfrac{\\Delta u_{CE}}{\\Delta u_I} = \\dfrac{\\Delta u_O}{\\Delta u_I} \\]\n波形非线性失真的分析 假设静态工作点设置合适并且信号输入幅值较小，则可以正常工作，如下\n41.jpg\r如果\\(Q\\)点过低，输入信号负半周期峰值的某段时间内，晶体管b-e间电压总量小于开启电压，晶体管截止。因此基极电流\\(i_b\\)将产生底部失真，最后导致\\(u_O\\)顶部失真。这种情况叫做截止失真。解决办法是加大\\(V_{BB}\\)\n42.jpg\r如果\\(Q\\)点过高，虽然\\(i_B\\)本身不失真，但是在输出回路中，\\(i_B\\)的正半周期可能会进入饱和区，导致了\\(i_c\\)产生顶部失真，最后导致\\(u_O\\)底部失真。这种情况叫做饱和失真。解决办法是增大\\(R_b\\)而减小\\(I_{BQ}\\)，从而减小\\(I_{CQ}\\)；也可以减小\\(R_c\\)，从而增大\\(U_{CEQ}\\)；或者更换一只\\(\\beta\\)较小的管子，以便在\\(I_{BQ}\\)相同的情况下减小\\(I_{CQ}\\)\n43.jpg\r计算最大不失真参数\n如果将晶体管理想化，即认为在管压降总量\\(u_{CE}\\)最小值大于饱和管压降\\(U_{CES}\\)（即管子不饱和），且基极电流总量\\(i_{B}\\)大于\\(0\\)（即管子不截止）的情况下，非线性失真可以忽略不计，那么就可以得出放大电路的最大不失真电压\\(U_{om}\\)\n从图2.3.7(b)可以计算，其方法是以\\(U_{CEQ}\\)为中心，取\\(V_{CC}-U_{CEQ}\\)和\\(V_{CEQ}-U_{CES}\\)这两段距离中较小的数值，并除以\\(\\sqrt{2}\\)，则得到其有效值\\(U_{om}\\)\n为了使\\(U_{om}\\)尽可能大，应该将\\(Q\\)点放置在放大区内负载线的终点，即横坐标\\(\\dfrac{V_{CC}+U_{CES}}{2}\\)的位置，此时的\\(U_{om}=\\dfrac{V_{CC}-U_{CEQ}}{\\sqrt{2}}\\)\n或者你需要计算其他电路中的参数，按照此时的设置，\\(U_{CEQ}=\\dfrac{V_{CC}+U_{CES}}{2}\\)，用这个东西去计算\\(I_{CQ},I_{BQ},I_{EQ}\\)等等都是可以的。\n直流、交流负载线 直流通路所确定的负载线\\(u_{CE}=V_{CC}-i_CR_c\\)称为直流负载线，而动态信号遵循的负载线称为交流负载线。\n70.jpg\r交流负载线有两个特点\n输入电压为零时，其实就是静态工作点，所以负载线必过\\(Q\\)点 由于集电极电流\\(i_c\\)仅取决于基极动态电流\\(i_b\\)，而动态管压降\\(u_{ce}\\)等于\\(i_c\\)与\\(R_{c}\\parallel R_L\\)之积，所以它的斜率为\\(-1/(R_c\\parallel R_L)\\) 但其实也不一定要找出斜率。我们可以再找一个不同于\\(Q\\)的点即可。\n三极管的三种接法 共射 之前的例子都是共射电路，其特征是发射极为输出回路与输入回路的公共端（这个画出交流通路比较好判断，不要在原来的电路上判断）。\n静态工作点、放大倍数、输入输出阻抗见前。\n共集 即输出输入回路（交流通路上）以集电极为公共端。\n44.jpg\r\\[\\left\\{\\begin{matrix} I_{BQ}=\\dfrac{V_{BB}-U_{BEQ}}{R_b+(1+\\beta)R_e} \\\\ I_{EQ}=(1+\\beta)I_{BQ} \\\\ U_{CEQ} = V_{CC}-I_{EQ}R_e \\end{matrix}\\right. \\]\n\\[\\dot A_u = \\dfrac{(1+\\beta)R_e}{R_b+r_{be}+(1+\\beta)R_e} \\]\n显然\\(\\dot A_u\\)在\\(0\\)到\\(1\\)之间，输入输出同向，输出小于输入。当\\((1+\\beta)R_e\u003e\u003eR_b+r_{be}\\)时，\\(\\dot A_u\\approx 1\\)，即\\(\\dot U_o\\approx\\dot U_i\\)，故常称共集放大电路为射极跟随器。虽然电路没有电压放大能力但是输出电流\\(I_e\\)远大于输入电流\\(I_b\\)，仍有功率放大作用。\n45.jpg\r\\[R_i = R_b+r_{be}+(1+\\beta)R_e \\]\n\\[R_o = R_e\\parallel\\dfrac{R_b+r_{be}}{1+\\beta} \\]\n共基 即输出输入回路（交流通路上）以基极为公共端。\n46.jpg\r\\[\\left\\{\\begin{matrix} I_{EQ}=\\dfrac{V_{BB}-U_{BEQ}}{R_e} \\\\ I_{BQ}=\\dfrac{I_{EQ}}{1+\\beta} \\\\ U_{CEQ} = U_{CQ}-U_{EQ}=V_{CC}-I_{CQ}R_c+U_{BEQ} \\end{matrix}\\right. \\]\n\\[\\dot A_u = \\dfrac{\\beta R_c}{r_{be}+(1+\\beta)R_e} \\]\n\\[R_i=R_e+\\dfrac{r_{be}}{1+\\beta} \\]\n\\[R_o=R_c \\]\n由于共基电路的输入回路电流为\\(i_E\\)，而输出回路电流为\\(i_C\\)，所以无电流放大能力。但有足够的电压放大能力，从而实现功率放大。此外输入电压和输出电压同相。\n三种接法的比较 共射电路既能放大电流又能放大电压，输入电阻居三种电路之中，输出电阻较大,频带较窄。常作为低频电压放大电路的单元电路。 共集电路只能放大电流不能放大电压，是三种接法中输入电阻最大、输出电阻最小的电路，并具有电压跟随的特点。常用于电压放大电路的输入级和输出级，在功率放大电路中也常采用射极输出的形式。 共基电路只能放大电压不能放大电流，具有电流跟随的特点；输人电阻小，电压放大倍数、输出电阻与共射电路相当，是三种接法中高频特性最好的电路。常作为宽频带放大电路。 集成运放的内部电路 多级放大电路的一般问题 耦合方式 直接耦合\n将前一级的输出端直接连接到后一级的输入端。\n采用直接耦合方式使各级之间的直流通路相连，因静态工作点相互影响，这样就给电路的分析、设计和调试带来困难。计算静态工作点和放大倍数都要考虑前后级的影响。最大的问题是存在零点漂移现象。\n优点是具有良好的低频特性，可以放大变化缓慢的信号。由于没有大电容，易于集成在一片硅片上，构成集成放大电路。\n阻容耦合\n前级输出端通过电容接到后级输入端。\n阻容耦合的电路各级之间的直流通路各不相通，静态工作点相互独立，在求解和调试\\(Q\\)点时可以按单级处理。而且，只要输入信号频率较高，耦合电容容量较大，前级的输出就可以几乎无损地传递到后级。\n缺点是低频特性差，不能放大缓慢变化的信号。以及不便于集成化。所以一般只有频率高、输出功率大等情况下才会采用阻容耦合。\n变压器耦合\n前级输出端通过变压器接到后级输入端或负载电阻上。\n静态工作点相互独立，在求解和调试\\(Q\\)点时可以按单级处理。\n低频特性差，不能放大缓慢的信号。比阻容耦合还不能集成化。\n但其最大的特点是可以实现阻抗变换。\n光电耦合\n以光信号为媒介来实现电信号的耦合和传递，通过将发光二极管与光电三极管相互绝缘地组合在一起来实现。\n书上没有提到优缺点\n多级放大电路的动态分析 无论什么耦合，放大电路中前级的输出电压就是后级的输入电压，即\\(\\dot U_{o1}=\\dot U_{i2},\\dot U_{o2}=\\dot U_{i3},\\cdots,\\dot U_{o(N-1)}=\\dot U_{iN}\\)\n所以总体的放大倍数为\n\\[\\dot A_u = \\dfrac{\\dot U_{o1}}{\\dot U_i}\\cdot\\dfrac{\\dot U_{o2}}{\\dot U_i2}\\cdot\\cdots\\cdot\\dfrac{\\dot U_{o}}{\\dot U_{iN}}=\\dot A_{u1}\\cdot\\dot A_{u2}\\cdot\\dots\\cdot\\dot A_{uN} = \\prod^{N}_{j=1}\\dot A_{uj} \\]\n输入电阻就是第一级的输入电阻，输出电阻就是最后一级的输出电阻。\n\\[R_i = R_{i1}, R_o = R_{oN} \\]\n注意，当共集放大电路作为输入级时，它的输入电阻与其负载，即与第二级的输入电阻有关；共集放大电路作为输出级时，它的输出电阻与其信号源内阻，即倒数第二级的输出电阻有关。\n差分放大电路 共模信号：大小相等、极性相同的输入信号。\n差模信号：大小相等、极性相反的输入信号。\n差分放大电路对于共模信号有很强的抑制作用（不仅因为其电路参数对称，还因为其反馈作用），所以能克服零点漂移的问题。\n47.jpg\r由于输入的是差模信号，电路参数对称，集电极电位的变化也是大小相等且方向相反的，即\\(\\Delta u_{c1}=-\\Delta u_{c2}\\)，所以输出电压为\\(\\Delta u_o=\\Delta u_{c1}-\\Delta u_{c2}=2\\Delta u_{c1}\\)，从而实现了电压放大。\n显然的，在差模信号作用下，\\(R_e\\)中的电流变化为零，即\\(R_e\\)对差模信号没有反馈作用，相当于短路。而\\(R_e\\)对共模信号有负反馈作用，可以抑制零点漂移。\n长尾式差分放大电路 48.jpg\r如图，\\(R_e\\)接到一个\\(-V_{EE}\\)上，故称长尾式电路。参数理想对称，即\\(R_{b1}=R_{b2}=R_b,R_{e1}=R_{e2}=R_e\\)；\\(T_1\\)与\\(T_2\\)的特性相同，\\(\\beta_1=\\beta_2=\\beta,r_{be1}=r_{be2}=r_{be}\\)\n静态分析\n当\\(u_{I1}=u_{I2}=0\\)时，\n\\[I_{R_e} = I_{EQ1} + I_{EQ2} = 2I_{EQ} \\]\n根据基极回路方程\n\\[I_{BQ}R_b + U_{BEQ} + 2I_{EQ}R_e = V_{EE} \\]\n可以求出\\(I_{BQ}\\)或\\(I_{EQ}\\)从而解出静态工作点。通常，由于\\(R_b\\)很小，很多情况下\\(R_b\\)就是信号源内阻，而且\\(I_{BQ}\\)也很小，所以\\(R_b\\)上的电压可忽略不计，从而\\(U_{EQ}\\approx-U_{BEQ}\\)，因而\n\\[I_{EQ}\\approx\\dfrac{V_{EE}-U_{BEQ}}{2R_e} \\]\n\\[I_{BQ} = \\dfrac{I_{EQ}}{1+\\beta} \\]\n\\[U_{CEQ} = U_{CQ}-U_{EQ}\\approx V_{CC}-I_{CQ}R_c+U_{BEQ} \\]\n由于\\(U_{CQ1}=U_{CQ2}\\)，所以\\(u_O=U_{CQ1}-U_{CQ2}=0\\)\n对共模信号的抑制作用\n之前提到过由于参数对称，输入共模信号时集电极的电压也是共模的，从而输出电压为零。\n除此之外还有负反馈作用，见下图\n49.jpg\r\\(R_e\\)越大，负反馈作用越强。但也不宜过大，应该受到\\(V_{EE}\\)的限制，以防止\\(I_{EQ}\\)过小。为了描述对共模信号的抑制能力，引入共模放大倍数\\(A_c\\)\n\\[A_c = \\dfrac{\\Delta u_{Oc}}{\\Delta u_{Ic}} \\]\n理想情况下\\(A_c = 0\\)\n对差模信号的放大作用\n当给差分放大电路输入一个差模信号\\(\\Delta u_{Id}\\)时，由于电路参数的对称性，\\(\\Delta u_{Id}\\)经分压后，加在\\(T_1\\)管一边的为\\(+\\Delta u_{Id}/2\\)，加在\\(T_2\\)管一边的为\\(-\\Delta u_{Id}/2\\)\n50.jpg\r\\(E\\)点在差模信号下电位不变，相当于接地。负载电阻的中点电位在差模信号的作用下电位也不变，相当于接地。交流等效通路如图。\n差模放大倍数为\n\\[A_d = \\dfrac{\\Delta u_{Od}}{\\Delta u_{Id}} \\]\n由交流等效电路可得\\(\\Delta u_{Id}=2\\Delta i_{B1}(R_b+r_{be}),\\Delta u_{Od}=-2\\Delta i_{C1}\\bigg(R_c\\parallel\\dfrac{R_L}{2}\\bigg)\\)，所以\n\\[A_d = -\\dfrac{\\beta\\bigg(R_c\\parallel\\dfrac{R_L}{2}\\bigg)}{R_b+r_{be}} \\]\n可见，用了两只晶体管，放大能力只相当于一只晶体管，牺牲了一只管子为代价换来了低温漂的效果。\n从等效电路也可以看出\n\\[R_i = 2(R_b+r_{be}) \\]\n\\[R_o = 2R_c \\]\n为了综合考察对差模信号的放大能力和对共模信号的抑制能力，引入共模抑制比\n\\[K_{CMR} = \\bigg|\\dfrac{A_d}{A_c}\\bigg| \\]\n理想情况下\\(K_{CMR}=\\infty\\)\n当然这些输入输出电阻、差模放大倍数等东西，都是从这个图中推出来的，如果某个题中的电路没有某个电阻什么的，要自己学会用这个方法推断。\n四种接法 双入双出\n之前介绍的叫做双入双出接法。\n双入单出\n51.jpg\r其中右边的直流通路是用戴维南定理来算的，有\n\\[V'_{CC} = \\dfrac{R_L}{R_c+R_L}\\cdot V_{CC} \\]\n\\[R'_c = R_c\\parallel R_L \\]\n现在输出回路不对称了，\\(T_1\\)管和\\(T_2\\)管的集电极电位\\(U_{CQ1}\\neq U_{CQ2}\\)，从而\\(U_{CEQ1}\\neq U_{CEQ2}\\)。由图可得\n\\[U_{CQ1} = V'_{CC}-I_{CQ}R'_c \\]\n\\[U_{CQ2} = V_{CC}-I_{CQ}R_c \\]\n静态工作点和之前的计算方法一致。\n在差模信号作用时，负载电阻只取得\\(T_1\\)管集电极电位的变化量，所以与双出电路相比，差模放大倍数的数值减小。画出等效电路如下，\n52.jpg\r易计算输出电压为\\(\\Delta u_{Od}=-\\Delta i_C(R_c\\parallel R_L)\\)，输入电压为\\(\\Delta u_{Id}=2\\Delta i_b(R_b+r_{be})\\)\n差模放大倍数变为\n\\[A_d = \\dfrac{\\Delta u_{Od}}{\\Delta u_{Id}} = -\\dfrac{1}{2}\\cdot\\dfrac{\\beta(R_c\\parallel R_L)}{R_b+r_{be}} \\]\n输入电阻仍然为\\(R_i=2(R_b+r_{be})\\)，输出电阻为\\(R_o=R_c\\)，是双端输出电路的一半。\n分析\\(A_c\\)时，输入共模电压，我们注意到\\(\\Delta i_{Re} = 2\\Delta i_E,\\Delta u_e = 2\\Delta i_ER_e\\)，对于每只管子，可以认为是\\(\\Delta i_E\\)流过阻值为\\(2R_e\\)的电阻造成的，如下\n55.jpg\r可以计算得到\n\\[A_c = \\dfrac{\\Delta u_{Oc}}{\\Delta u_{Ic}} = -\\dfrac{\\beta(R_c\\parallel R_L)}{R_b+r_{be}+2(1+\\beta)R_e} \\]\n\\[K_{CMR} = \\bigg|\\dfrac{A_d}{A_c}\\bigg| = \\dfrac{R_b+r_{be}+2(1+\\beta)R_e}{2(R_b+r_{be})} \\]\n增大\\(R_e\\)，\\(K_{CMR}\\)越大，电路性能越好。\n单入双出\n53.jpg\r这个也叫做射极耦合电路，因为\\(T_2\\)管的信号是从\\(T_1\\)管传来的。\n将电路等效为右边，如果\\(A_c\\)不等于零，则输出电压不仅有差模信号产生的，还有共模信号产生的。\n\\[\\Delta u_{O} = A_d\\Delta u_I + A_c\\cdot\\dfrac{\\Delta u_I}{2} \\]\n当然理想状况下\\(A_c=0\\)。单入双出和双入双出分析完全一样，不再介绍。\n单入单出\n54.jpg\r对于单出电路，常把不输出信号一边的\\(R_c\\)省掉。对\\(Q\\)点、\\(A_d\\)、\\(A_c\\)、\\(R_i\\)、\\(R_o\\)的分析和双入单出一样，对于输入信号作用的分析和单入双出一样。\n总结\n四种解法的特点：\n输入电阻均为\\(2(R_b+r_{be})\\) \\(A_d,A_c,R_o\\)与输出方式有关，双端输出时，\\(A_d\\)见前，\\(A_c=0,R_o=2R_c\\)；单端输出时\\(A_d,A_c\\)见前，\\(R_o=R_c\\) 单端输入时，差模信号输入的同时总伴随着共模输入。若输入信号为\\(\\Delta u_I\\)，则\\(\\Delta u_{Id}=\\Delta u_{I},\\Delta u_{Ic}=+\\Delta u_{I}/2\\)，输出电压表达式见前。 改进型差分放大电路 在差分放大电路中，提高\\(R_e\\)能抑制温漂，提高共模抑制比。\n我们可以利用工作点稳定电路来取代\\(R_e\\)，得到下图的恒流源差分放大电路\n56.jpg\r电源\\(V_{EE}\\)可取几伏，电路参数应满足\\(I_2\u003e\u003eI_{B3}\\)。这样\\(I_1\\approx I_2\\)，所以\\(R_2\\)上的电压为\n\\[U_{R2}\\approx\\dfrac{R_2}{R_1+R_2}\\cdot V_{EE} \\]\n\\[I_{C3}\\approx I_{E3} = \\dfrac{U_{R2}-U_{BE3}}{R_3} \\]\n若\\(U_{BE3}\\)的变换可忽略不计，则\\(I_{C3}\\)基本不受温度影响。由于没有动态信号可以作用到\\(T_3\\)的基极和发射极，因此\\(I_{C3}\\)为恒流，发射极所接电路可以等效成一个恒流源。有\n\\[I_{EQ1}=I_{EQ2}=\\dfrac{I_{C3}}{2} \\]\n当\\(T_3\\)管输出特性为理想特性时，\\(T_3\\)在放大区的输出特性曲线是横轴的平行线时，恒流源的内阻为无穷大，即相当于\\(T_1,T_2\\)接了一个无穷大的电阻，此时\\(A_c=0,K_{CMR}=\\infty\\)\n电流源电路 单管电流源电路 57.jpg\r（题外话，这和改进型差分放大器中的下面接的那个电流源一模一样）\n\\[I_O = I_C\\approx I_E = \\bigg(\\dfrac{R_2}{R_1+R_2}|U_{EE}|-U_{BE}\\bigg)\\bigg/R_3 \\]\n\\[R_O = r_{ce}\\bigg(1+\\dfrac{\\beta R_3}{r_{be}+R_3+R_1\\parallel R_2}\\bigg)\u003e\u003er_{ce} \\]\n镜像电流源 58.jpg\r它由两只特性完全相同的管子构成，由于\\(T_0\\)的管压降\\(U_{CE0}\\)与其\\(b-e\\)间电压\\(U_{BE0}\\)相等，从而保证\\(T_0\\)工作在放大状态。所以\\(I_{C0}=\\beta_0I_{B0}\\)，由于图中\\(T_0,T_1\\)的\\(b-e\\)间电压相等，所以有\\(I_{B0}=I_{B1}=I_B\\)；由于放大系数相等，所以\\(I_{C0}=I_{C1}=I_C=\\beta I_B\\)。由于电流相等的关系，所以叫做镜像电流源，\\(I_{C1}\\)为输出电流。\n电阻\\(R\\)中的电流称为基准电流，其表达式为\n\\[I_R = \\dfrac{V_{CC}-U_{BE}}{R} = I_C+2I_B = I_C + 2\\cdot\\dfrac{I_C}{\\beta} \\]\n所以集电极电流\n\\[I_C = \\dfrac{\\beta}{\\beta+2}I_R \\]\n\\(\\beta\u003e\u003e2\\)时，输出电流\n\\[I_C \\approx I_R = \\dfrac{V_{CC}-U_{BE}}{R} \\]\n镜像电流源具有一定的温度补偿作用，如下\n59.jpg\r这个电路不好用的地方在于，如果要求\\(I_{C1}\\)较大，\\(I_R\\)就要大，\\(R\\)的功耗也要很大。如果要求\\(I_{C1}\\)很小，那么\\(R\\)的数值就要很大。这两点在集成电路中都难以做到。\n比例电流源 60.jpg\r\\[U_{BE0} + I_{E0}R_{e0} = U_{BE1} + I_{E1}R_{e1} \\]\n根据晶体管发射结电压与发射极电流的近似关系可得\n\\[U_{BE}\\approx U_T\\ln \\dfrac{I_E}{I_S} \\]\n（上述公式是忽略基区电阻\\(r_{bb'}\\)上的电压时，晶体管发射极电流与\\(b-e\\)间电压的关系，\\(I_E\\approx I_S\\exp({U_{BE}/U_T})\\)，推导得到的）\n由于两只管的特性完全相同，所以\n\\[U_{BE0}-U_{BE1}\\approx U_T\\ln\\dfrac{I_{E0}}{I_{E1}} \\]\n代入前式整理得\n\\[I_{E1}R_{e1}\\approx I_{E0}R_{e0}+U_{T}\\ln\\dfrac{I_{E0}}{I_{E1}} \\]\n当\\(\\beta\u003e\u003e2\\)时，\\(I_{C0}\\approx I_{E0}\\approx I_{R},I_{C1}\\approx I_{E1}\\)，所以\n\\[I_{C1}\\approx\\dfrac{R_{e0}}{R_{e1}}\\cdot I_R+\\dfrac{U_T}{R_{e1}}\\ln\\dfrac{I_R}{I_{C1}} \\]\n在一定的取值范围内，如果对数项可以忽略，那么\n\\[I_{C1}\\approx\\dfrac{R_{e0}}{R_{e1}}\\cdot I_R \\]\n当然我们可以很容易地算出\n\\[I_{R}\\approx\\dfrac{V_{CC}-U_{BE0}}{R+R_{e0}} \\]\n微电流源 如果不想用很大的电阻，又要使得输出电流较小，可以把\\(R_{e0}\\)直接舍弃掉，如下图\n61.jpg\r当\\(\\beta\u003e\u003e1\\)时，有\n\\[I_{C1}\\approx I_{E1}=\\dfrac{U_{BE0}-U_{BE1}}{R_e} \\]\n其中这个电压差只有几十毫伏，甚至更小。只需要几千欧的\\(R_e\\)就可以得到几十微安的输出电流。\n两管完全相同，则\n\\[I_{C1}\\approx \\dfrac{U_T}{R_e}\\ln\\dfrac{I_R}{I_{C1}} \\]\n在\\(R_e\\)已知的情况下，上式对\\(I_{C1}\\)是超越方程，可以通过图解法或累试法解出\\(I_{C1}\\)（做题意义上，题目会直接给出一些数据方便你求解）。\n易算\n\\[I_{R}\\approx \\dfrac{V_{CC}-U_{BE0}}{R} \\]\n改进型电流源 上面三个电路很多分析结果都要\\(\\beta\\)很大时才成立，也就是没考虑基极电流的影响。\n加射极输出器的电流源\n62.jpg\r加了\\(T_2\\)后，利用放大作用，减小了\\(I_{B0},I_{B1}\\)对于\\(I_R\\)的分流。三个管特性要完全相同，即\\(\\beta_0=\\beta_1=\\beta_2=\\beta\\)，而由于\\(U_{BE1}=U_{BE0},I_{B1}=I_{B0}=I_B\\)，因此输出电流\n\\[I_{C1}=I_{C0} = I_R-I_{B2} = I_R-\\dfrac{I_{E2}}{1+\\beta}=I_R-\\dfrac{2I_B}{1+\\beta} = I_R-\\dfrac{2I_{C1}}{(1+\\beta)\\beta} \\]\n最后整理得\n\\[I_{C1} = \\dfrac{I_R}{1+\\dfrac{2}{(1+\\beta)\\beta}}\\approx I_R \\]\n有时会加上图中的\\(R_{e2}\\)，用于提高\\(T_2\\)管的\\(\\beta\\)\n威尔逊电流源\n63.jpg\r如上图，三个管子也是特性一致。由于\\(c-e\\)间等效电阻非常大，所以可以使\\(I_{C2}\\)高度稳定。\\(\\beta_0=\\beta_1=\\beta_2=\\beta,I_{C1}=I_{C0}=I_C\\)\n\\[I_{E2} = I_C + 2I_B = I_C + \\dfrac{2I_C}{\\beta} \\]\n所以\n\\[I_C = \\dfrac{\\beta}{\\beta+2}\\cdot I_{E2}=\\dfrac{\\beta}{\\beta+2}\\cdot\\dfrac{1+\\beta}{\\beta}I_{C2} = \\dfrac{\\beta+1}{\\beta+2}\\cdot I_{C2} \\]\n在上图的\\(B\\)点有\n\\[I_R = I_{B2}+I_C = \\dfrac{I_{C2}}{\\beta}+\\dfrac{\\beta+1}{\\beta+2}\\cdot I_{C2}=\\dfrac{\\beta^2+2\\beta+2}{\\beta^2+2\\beta}\\cdot I_{C2} \\]\n整理得\n\\[I_{C2} = (1-\\dfrac{2}{\\beta^2+2\\beta+2})I_R\\approx I_R \\]\n多路电流源 64.jpg\r\\(I_R\\)为基准电流，\\(I_{C1},I_{C2},I_{C3}\\)为三路输出电流。\n\\[U_{BE0}+I_{E0}R_{e0}=U_{BE1}+I_{E1}R_{e1}=U_{BE2}+I_{E2}R_{e2}=U_{BE3}+I_{E3}R_{e3} \\]\n由于各管的\\(U_{BE}\\)大致相等，则\n\\[I_{E0}R_{e0}\\approx I_{E1}R_{e1}\\approx I_{E2}R_{e2}\\approx I_{E3}R_{e3} \\]\n当\\(I_{E0}\\)确定之后，只要选择合适的电阻，就可以得到所需的电流。注意这里有\\(I_R\\approx I_{C0}\\approx I_{E0}\\)，其他路有\\(I_{Ci}\\approx I_{Ei}\\)\n当然可能会遇到\\(R_e\\)全都等于零的情况，那么输出电流全部都等于\\(I_R\\)。\n65.jpg\r上图的叫做多集电极管，集电极电流之比等于它们的集电区面积之比\n\\[\\dfrac{I_{C1}}{I_{C0}}=\\dfrac{S_1}{S_0},\\dfrac{I_{C2}}{I_{C0}}=\\dfrac{S_2}{S_0} \\]\n有源负载共射放大电路 66.jpg\r如上图，\\(T_1\\)为放大管，\\(T_2,T_3\\)构成镜像电流源。\\(T_2\\)是\\(T_1\\)的有源负载。设\\(T_2,T_3\\)管特性相同，从而\\(\\beta_2=\\beta_3=\\beta,I_{C2}=I_{C3}\\)。基准电流有\n\\[I_R = \\dfrac{V_{CC}-U_{EB3}}{R} \\]\n根据前面镜像电流源的讨论，空载时\\(T_1\\)管有\n\\[I_{CQ1} = I_{C2} = \\dfrac{\\beta}{\\beta+2}\\cdot I_R \\]\n可见设置\\(I_{CQ1}\\)只需要\\(V_{CC}\\)和\\(R\\)相配合。\n应当指出，输入端\\(u_I\\)中应含有直流分量，为\\(T_1\\)提供静态基极电流\\(I_{BQ1}=I_{CQ1}/\\beta_1\\)，而不与镜像电流源提供的\\(I_{C2}\\)产生冲突。带上负载电阻\\(R_L\\)后，由于分流作用，\\(I_{CQ1}\\)会有所变化。\n\\[\\dot A_u=-\\dfrac{\\beta_1(r_{ce1}\\parallel r_{ce2}\\parallel R_L)}{R_b+r_{be1}} \\]\n若\\(R_L \u003c\u003c (r_{ce1}\\parallel r_{ce2})\\)，则\n\\[\\dot A_u\\approx -\\dfrac{\\beta_1 R_L}{R_b+r_{be1}} \\]\n频率响应 我们学院的模电学时很少，没有涉及这方面，主要介绍一下波特图的横纵坐标。可能会在放大倍数中用到\n波特图 波特图由对数幅频特性和对数相频特性两部分组成，它们的横轴采用对数刻度\\(\\lg f\\)，幅频特性的纵轴采用\\(20\\lg |\\dot A_u|\\)表示，单位是分贝\\((dB)\\)，相频特性的纵轴仍采用\\(\\varphi\\)表示。这样不但开阔了视野，还能将放大倍数的乘除运算转换成加减运算。\n反馈 反馈的基本概念 在电子电路中，将输出量的一部分或全部通过一定的电路形式作用到输入回路，来影响其输入量的措施称为反馈。\n67.jpg\r使得净输入量增大的反馈称为正反馈，减小的称为负反馈。由于净输入影响输出，所以也有使得输出变化增大的称为正反馈，减小的称为负反馈。\n如果反馈量只含有直流量，则成为直流反馈。如果反馈量只含有交流量，则成为交流反馈。或者说，仅在直流通路中存在的反馈是直流反馈，仅在交流通路中存在的反馈是交流反馈。很多电路中二者都有。\n反馈的判断 有无反馈 如果放大电路中存在将输出回路与输入回路相连的通路，并且影响了净输入，则引入了反馈，否则没有引入。\n反馈极性的判断 我们用到了瞬时极性法。\n规定电路输入信号在某一时刻对地的极性，并以此为依据，逐级判断电路中各相关点电流的流向和电位的极性，从而得到输出信号的极性。根据输出信号的极性判断反馈信号的极性；若反馈信号使基本放大电路的净输入增大，则为正反馈，反之为负反馈。\n书上描述的并没有很详细。其实是将信号源断开，然后在输入端加上一个“上升”信号，记为\u0026quot;+\u0026quot;，然后推其他相关点的极性。\n对于集成放大器，从同相输入端输入，则输出端与输入相同。从反相输入端输入，则输出端与输入相反。\n对于三极管，无论是PNP还是NPN，基极和发射极相同，基极和集电极相反。\n经过电阻不变。由于交流、直流分开讨论，所以不需要讨论电容。\n对于集成放大器，如果反馈电路接到与输入不同的那一端，一般我们会考察那一端输入电压的变化。如果是反馈到相同的一端，一般我们会考察这一端输入电流的变化。对于三极管，我们可以考察净输入电压（\\(U_{be},U_{eb}\\)）或者净输入电流\\(I_B,I_E\\)。\n有一个好用的规律：从集成运放的输出端通过电阻、电容等反馈通路引回到其反相输入端的电路必然构成负反馈电路。从集成运放的输出端通过电阻、电容等反馈通路引回到其同相输入端的电路必然构成正反馈电路\n不方便做笔记，这个靠做题和解析来弄明白。\n特别指出，反馈量仅仅取决于输出量，与输入量无关。\n直流反馈与交流反馈的判断 画出直流通路和交流通路，存在于哪个电路中，就是哪种反馈。\n电压负反馈与电流负反馈的判断 令负反馈放大电路的输出电压\\(u_O=0\\)，然后判断反馈量。如果反馈量也立即归零，则为电压负反馈。否则为电流负反馈。\n注意这里是反馈量\\(u_F,i_F\\)，不是某个器件上的电压电流，有可能那个器件上的电压电流并没有归零，但是，由于输出电压作用引起的电流电压值归零了，则是电压负反馈。它们还可能有其他东西作用，所以并不一定全部归零。\n这个东西不能用于实验，强制接地将会导致集成运放烧坏。只能用于理论判断。\n串联反馈与并联反馈的判断 若反馈信号为电压量，与输入电压求差而获得净输入电压，则为串联反馈。若反馈信号为电流量，与输入电流求差获得净输入电流，则为并联反馈。\n负反馈放大电路的四种基本组态 分为电压串联负反馈、电流串联负反馈、电压并联负反馈、电流并联负反馈。\n负反馈放大电路的方块图及一般表达式 68.jpg\r任何负反馈都可以用这个图来表示。图中\\(\\dot X_i\\)为输入量，\\(\\dot X_f\\)为反馈量，\\(\\dot X_i'\\)为净输入量，\\(\\dot X_o\\)为输出量。另外箭头表示信号是单向流通的。\n显然，由图\n\\[\\dot X_i' = \\dot X_i-\\dot X_f \\]\n在信号的中频段，\\(\\dot X_i,\\dot X_i',\\dot X_f\\)都为实数，所以可以写为\n\\[|\\dot X_i'| = |\\dot X_i| - |\\dot X_f|\\quad \\text{or}\\quad X_i' = X_i-X_f \\]\n基本放大器传输增益（放大倍数）、开环增益、开环放大倍数\n\\[\\dot A = \\dfrac{\\dot X_o}{\\dot X_i'} \\]\n反馈网络的传输系数、反馈系数\n\\[\\dot F = \\dfrac{\\dot X_f}{\\dot X_o} \\]\n反馈放大器的传输增益、闭环增益、闭环放大倍数\n\\[\\dot A_f=\\dfrac{\\dot X_o}{\\dot X_i} \\]\n环路增益、环路放大倍数\n\\[\\dot T = \\dot A\\dot F = \\dfrac{\\dot X_f}{\\dot X_i'} \\]\n由此可以推出闭环增益的另一个表达式\n\\[\\dot A_f=\\dfrac{\\dot A}{1+\\dot A\\dot F} \\]\n以上这些在中频段都可以把头上的点去掉。\n注意到若\\(\\dot A\\dot F\u003c0\\)，则\\(|\\dot A_f|\u003e|\\dot A|\\)，则说明引入了正反馈。若\\(\\dot A\\dot F=-1\\)，则说明电路在没有输入的时候就有输出，称电路产生了自激震荡。正反馈时\\(X_i'=X_i+X_f,A_f=\\dfrac{A}{1-AF}\\)（此时\\(AF\u003e0\\)）\n四种组态的方块图 69.jpg\r显然不同电路的输入输出反馈量不同，得到的各种放大倍数量纲都不同，功能也就不同。除了环路放大倍数的量纲，它们都为一。\n深度负反馈 方便我打字起见，后面不打字母上面的点了。\n定义反馈深度为\n\\[D = 1+AF = \\dfrac{X_i}{X_i'} \\]\n若\\(D\u003e\u003e1\\)即\\(AF\u003e\u003e1\\)时，有\n\\[A_f \\approx \\dfrac{1}{F} \\]\n此时引入了深度负反馈。又因为\n\\[A_f = \\dfrac{X_o}{X_i},\\quad F=\\dfrac{X_f}{X_o},\\quad A_f\\approx\\dfrac{1}{F}=\\dfrac{X_o}{X_f} \\]\n所以有\\(X_i\\approx X_f\\)。可见深度负反馈的实质是在近似分析中忽略净输入量。\n求解深度负反馈放大电路放大倍数的一般步骤是\n正确判断反馈组态 求解反馈系数 利用\\(F\\)求解\\(A_f\\) 负反馈对放大电路性能的影响 稳定放大系数 \\[\\dfrac{dA_f}{A_f} = \\dfrac{1}{1+AF}\\dfrac{dA}{A} \\]\n也就是说，负反馈放大电路放大倍数的相对变化量\\(dA_f/A_f\\)仅为其开环增益相对变化量的\\((1+AF)\\)分之一。也就是说\\(A_f\\)的稳定性是\\(A\\)的\\((1+AF)\\)倍。\n但是，这是以损失了放大倍数为代价的，\\(A_f\\)是\\(A\\)的\\((1+AF)\\)分之一。\n对输入电阻的影响 串联负反馈时\n\\[R_{if} = (1+AF)R_i \\]\n注意，有些输入电阻是有多个的，有些并联有些串联，这里引入串联负反馈，只影响在反馈环上的输入电阻，其他并联的输入电阻不变，将这些电阻最后全部并联起来再计算。之后也有类似的情况，不再讨论。\n并联负反馈时\n\\[R_{if} = \\dfrac{R_{i}}{1+AF} \\]\n对输出电阻的影响 电压负反馈时\n\\[R_{of} = \\dfrac{R_o}{1+AF} \\]\n电流负反馈时\n\\[R_{of} = (1+AF)R_o \\]\n展宽频带 原来的频带，假设中频段放大倍数为\\(A_m\\)，则低频使得放大倍数为\\(0.707A_m\\)或\\(A_m-3dB\\)的频率叫做下限频率\\(f_L\\)。高频使得放大倍数为\\(0.707A_m\\)或\\(A_m-3dB\\)的频率叫做上限频率\\(f_H\\)。\n\\[f_{Lf} = \\dfrac{f_L}{1+A_mF} \\]\n一般情况下，由于\\(f_H\u003e\u003ef_L,f_{Hf}\u003e\u003ef_{Lf}\\)，因此，近似有\n\\[f_{bw} = f_H-f_L \\approx f_H \\]\n\\[f_{bwf} = f_{Hf}-f_{Lf}\\approx f_{Hf} \\]\n即引入负反馈使频带展宽到基本放大电路的\\((1+AF)\\)倍。\n减小非线性失真 \\[THD_f=\\dfrac{THD}{1+AF} \\]\n提高信噪比 提高\\((1+AF)\\)倍。\n","date":"2023-05-25T16:29:15+08:00","image":"https://kegalas.top/p/%E6%A8%A1%E6%8B%9F%E7%94%B5%E8%B7%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/cover_hu519ff8a40d33619eeac863a3de25a967_23559_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E6%A8%A1%E6%8B%9F%E7%94%B5%E8%B7%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"模拟电路学习笔记"},{"content":"导航页面\n线段光栅化算法 从《Fundamentals of Computer Graphics》（第五版）中的第179页，我们得到了一种直线的表达方式，\n\\[f(x,y)\\equiv (y_0-y_1)x+(x_1-x_0)y + x_0y_1-x_1y_0 = 0 \\]\n其中\\((x_0,y_0),(x_1,y_1)\\)代表直线上的任意不同的两点。并且\\(x_0\\leq x_1\\)，如果这个不满足，就交换两点的序号。然后直线的斜率显然就是\n\\[m = \\dfrac{y_1-y_0}{x_1-x_0} \\]\n方便起见，我们先假设\\(m\\in(0,1]\\)。\n显然，我们要画一条直线的话，无非就两种情况：\n1.jpg\r要么向右移动一格，要么向右后再向上移动一格。总之，我们总是向右移动一格，然后根据某种条件向上移动一格。我们可以把这个条件设置为\n\\[\\mathbf{if}\\ f(x+1,y+0.5)\u003c0\\ \\mathbf{then}\\ y=y+1 \\]\n注意这里的\\((x,y)\\)取整数，起始像素在直线上。\n进一步的，如果我们不想每次都调用函数\\(f\\)，我们有如下优化\ny = y0 d = f(x0+1,y0+0.5) for x = x0 to x1 do draw(x,y) if d\u0026lt;0 then y = y+1 d = d+(x1-x0)+(y0-y1) else d = d+(y0-y1) 不优化的方法写成cpp的样子大概如下\nif(p0-\u0026gt;x\u0026gt;p1-\u0026gt;x) std::swap(p0,p1); auto fxy = [\u0026amp;](float x, float y)-\u0026gt;float{ return (p0-\u0026gt;y-p1-\u0026gt;y)*x+(p1-\u0026gt;x-p0-\u0026gt;x)*y+p0-\u0026gt;x*p1-\u0026gt;y-p1-\u0026gt;x*p0-\u0026gt;y; }; int y = p0-\u0026gt;y; for(int x = p0-\u0026gt;x ; x\u0026lt;=p1-\u0026gt;x ; x++){ image.setFragment(x,y,color); float er = fxy(static_cast\u0026lt;float\u0026gt;(x)+1.f, static_cast\u0026lt;float\u0026gt;(y)+.5f); if(p0-\u0026gt;y\u0026lt;p1-\u0026gt;y \u0026amp;\u0026amp; er\u0026lt;0.f \u0026amp;\u0026amp; y\u0026lt;image.getHeight()-1){ y++; } else if(p0-\u0026gt;y\u0026gt;p1-\u0026gt;y \u0026amp;\u0026amp; er\u0026gt;0.f \u0026amp;\u0026amp; y\u0026gt;0){ y--; } } 这里写的包括了\\(m\\in[-1,1]\\)的情况，负数情况很简单，就把y++变成y\u0026ndash;，以及判断小于零转变为判断大于零。\n当\\(m\\in(1,+\\infty]\\)时，情况转变为，我们要么向上走一格，要么向上后向右走一格，与之前的情况非常相似，我们只要把遍历x改成遍历y，判断x++的条件即可。\n三角形光栅化算法 我会直接使用三角形的重心坐标来实现三角形的光栅化，因为比起其他一些扫描方法，重心坐标能比较方便的实现插值。\n三角形的重心坐标可见《Fundamentals of Computer Graphics》（第五版）中的第52页。\n根据线性代数的知识，假设我们三角形有三个不重合的点\\(A,B,C\\)，则我们可以用\\(\\vec{AB},\\vec{AC}\\)表示平面中任意的点\\(p\\)，我们有如下公式\n\\[\\vec{p} = \\alpha\\vec{a} + \\beta\\vec{b}+\\gamma\\vec{c} \\]\n其中\\(\\alpha+\\beta+\\gamma=1\\)\n可以计算得到，对于平面上的任意一个点\\((x,y)\\)\n\\[\\gamma = \\dfrac{(y_a-y_b)x+(x_b-x_a)y+x_ay_b-x_by_a}{(y_a-y_b)x_c+(x_b-x_a)y_c+x_ay_b-x_by_a} \\]\n\\[\\beta = \\dfrac{(y_a-y_c)x+(x_c-x_a)y+x_ay_c-x_cy_a}{(y_a-y_c)x_b+(x_c-x_a)y_b+x_ay_c-x_cy_a} \\]\n\\[\\alpha = 1-\\beta-\\gamma \\]\n当这个点在三角形内时，满足以下条件\n\\[0\u003c\\alpha\u003c1 \\]\n\\[0\u003c\\beta\u003c1 \\]\n\\[0\u003c\\gamma\u003c1 \\]\n特别的，如果在三角形上，则可以取等号。总体还是要满足\\(\\alpha+\\beta+\\gamma=1\\)。\n这个东西好就好在，如果需要对颜色进行插值，对于三角形内部任意一点\\(p\\)，有\\(color_p=\\alpha color_a+\\beta color_b+\\gamma color_c\\)。\n我们绘制的时候设置三个点为红、绿、蓝，中间颜色进行插值，就会得到这个结果\n2.jpg\r接下来我们谈谈具体怎么画三角形。\n首先非常暴力的想法是，把整个屏幕上的点扫描一遍，如果这个点在三角形内部，就给他上色。\n稍微优化一下，我们只需要扫描三角形的外接矩形（四边平行于坐标轴）即可。\ncpp代码如下\nint maxx = 0, minx = image.getWidth()-1, maxy = 0, miny = image.getHeight()-1; for(int i=0;i\u0026lt;3;i++){ maxx = std::max(maxx, points[i].x); minx = std::min(minx, points[i].x); maxy = std::max(maxy, points[i].y); miny = std::min(miny, points[i].y); } for(int x=minx;x\u0026lt;=maxx;x++){ for(int y=miny;y\u0026lt;=maxy;y++){ std::tuple\u0026lt;float,float,float\u0026gt; ret = geo::getBarycentric(points, x, y); float alpha = std::get\u0026lt;0\u0026gt; (ret); float beta = std::get\u0026lt;1\u0026gt; (ret); float gamma = std::get\u0026lt;2\u0026gt; (ret); if(0.f\u0026lt;=alpha \u0026amp;\u0026amp; alpha\u0026lt;=1.f \u0026amp;\u0026amp; 0.f\u0026lt;=beta \u0026amp;\u0026amp; beta \u0026lt;=1.f \u0026amp;\u0026amp; 0.f\u0026lt;=gamma \u0026amp;\u0026amp; gamma\u0026lt;=1.f) { geo::OARColor color = static_cast\u0026lt;geo::vec4i\u0026gt;( alpha*static_cast\u0026lt;geo::vec4f\u0026gt;(colors[0]) + beta*static_cast\u0026lt;geo::vec4f\u0026gt;(colors[1]) + gamma*static_cast\u0026lt;geo::vec4f\u0026gt;(colors[2])); image.setFragment(x,y,color); } } } 全部光栅化的代码可见**这里**\n另外，求重心坐标的代码我写到了geometry.cpp里，方便别处调用。链接在**这里**（在文件末尾）\n另外，求重心坐标还有一种不那么复杂的公式，见**计算机图形学基础学习笔记-数学基础**\n注意，\nif(0.f\u0026lt;=alpha \u0026amp;\u0026amp; alpha\u0026lt;=1.f \u0026amp;\u0026amp; 0.f\u0026lt;=beta \u0026amp;\u0026amp; beta \u0026lt;=1.f \u0026amp;\u0026amp; 0.f\u0026lt;=gamma \u0026amp;\u0026amp; gamma\u0026lt;=1.f) 这一段代码也可以写作\nif(alpha \u0026lt; 0.f || beta \u0026lt; 0.f || gamma \u0026lt; 0.f) continue; 这也是对的。唯一需要小心的是精度问题，float的精度可能不足以把边界上的每一个点都画出来。如果你不在乎这一两个像素点就可以不用管，如果你在乎，那么我们可以修改为alpha\u0026lt;-(1e-5)这样的条件。\n使用例子 绘制线段 #include \u0026#34;tga_image.h\u0026#34; #include \u0026#34;raster.h\u0026#34; int main(){ TGAImage image(100,100,TGAType::rgb); geo::vec2i pts0[2] = {geo::vec2i(99,0),geo::vec2i(0,99)}; ras::line(image, pts0, geo::OARColor(255,0,0,255)); for(int i=0;i\u0026lt;=99;i+=10){ pts0[0] = geo::vec2i(i,0); ras::line(image, pts0, geo::OARColor(255,0,0,255)); } image.writeToFile(\u0026#34;./line.tga\u0026#34;); } 如上，我们首先绘制了一条\\((99,0),(0,99)\\)的直线，也就是从右下角到左上角，然后我们用循环绘制了一组，一个点固定在右上角的直线。\n效果如下\n3.jpg\r绘制三角形 #include \u0026#34;tga_image.h\u0026#34; #include \u0026#34;raster.h\u0026#34; int main(){ TGAImage image2(100,100,TGAType::rgb); geo::vec2i pts1[3] = {geo::vec2i(60,5),geo::vec2i(5,60),geo::vec2i(70,90)}; geo::OARColor colors[3] = {geo::OARColor(255,0,0,255),geo::OARColor(0,255,0,255),geo::OARColor(0,0,255,255)}; ras::triangle(image2,pts1,colors); image2.writeToFile(\u0026#34;./triangle.tga\u0026#34;); return 0; } 代码非常直观，就是把三个点和三个点的颜色设置一下扔到光栅化函数里去。效果如下\n2.jpg\r","date":"2023-05-17T21:31:12+08:00","image":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E7%BA%BF%E6%AE%B5%E5%92%8C%E4%B8%89%E8%A7%92%E5%BD%A2%E7%9A%84%E5%85%89%E6%A0%85%E5%8C%96/cover_hu72dadf0d98aceb343e3fe7cb76faf398_301126_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E7%BA%BF%E6%AE%B5%E5%92%8C%E4%B8%89%E8%A7%92%E5%BD%A2%E7%9A%84%E5%85%89%E6%A0%85%E5%8C%96/","title":"从零开始的软渲染器 线段和三角形的光栅化"},{"content":"你可能会遇到如下情况：无论你使用MSYS2还是MinGW64还是Ucrt64还是Clang64，去输入pacman -S make，你的make都只会安装在/usr/bin里，也就是MSYS2里。如果你安装它们的toolchain，例如pacman -S mingw-w64-ucrt-x86_64-toolchain，里面包含了mingw-w64-ucrt-x86_64-make这个工具，但是在/ucrt64/bin里面并没有make.exe。\n其实并不是没有安装，只不过，他叫mingw32-make.exe。你如果要像使用make一样使用这个工具，你可以在打开cmd，在/ucrt64/bin中，输入mklink make mingw32-make.exe来创建软连接。这样，如果这个目录在环境变量之下，你就可以使用ucrt64中的make工具了。\n值得注意的是，虽然他叫mingw32-make，不过编译32位和64位的源码都可以用。\n","date":"2023-05-13T15:15:55+08:00","permalink":"https://kegalas.top/p/msys2%E4%B8%AD%E7%9A%84make%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/","title":"MSYS2中的make工具安装方法"},{"content":"这篇文章不探讨这几个东西的历史、关系，只来说一下什么时候该用什么，以及区别。\n首先，在MSYS2官网上下载安装后，它会提供许许多多的exe文件，包括msys2.exe, clang64.exe, mingw64.exe, ucrt64.exe等。这些东西里面都提供gcc或者clang/llvm等编译器，当然也提供其他一些工具链，但是编译出来的目标文件却不相同。我们把这些东西分为两类。\n第一类是msys2.exe，它的目标文件依赖于msys2提供的一个叫做msys-2.0.dll的动态链接库，这是一个虚拟POSIX环境。通过这个东西，一个程序可以调用Linux的API，但是经过这个dll后，转换到调用Windows对应的API来实现。程序本身不是原生的目标文件，而是中间加了一个仿真。\n第二类是其他三个，它们的目标文件是原生Windows的，也就是说，不需要这个msys-2.0.dll，直接就可以打开用。缺点是如果你要开发的东西非常依赖于POSIX，则这个东西没法编译，只能去用MSYS2。\n而Cygwin，和MSYS2差不多（非常简略地来说的话），只不过POSIX环境变成了cygwin.dll。\n总结，如果你需要给别人发Release，那么用MinGW、UCRT、CLANG的编译器（当然你也可以使用MSYS2然后附上msys-2.0.dll）。如果你开发的东西非常依赖POSIX，那么用MSYS2。\n至于Cygwin，由于它的安装和卸载我不是很喜欢，我一般不用。不过Cygwin有它很优秀的X server适配，在Windows下表现很好，这点比MSYS2好（实际上它根本没有X server和一些图形库）。不过随着WSL2的发布，也不是必需品了。\n现在MSYS2官网更推荐使用UCRT而不是MINGW。如果你要使用clang/llvm，那么用clang64是肯定的（我试了，在clang64里面装用pacman -S clang装进的是MSYS2里面。而且版本比较旧，也没有clangd等工具。我们要用的是 pacman -S mingw-w64-clang-x86_64-toolchain，当然也可以用llvm-mingw，不过好像有一些其他问题。而且这个clang64的前端好像是gcc，而不是在Windows下安装的llvm的默认前端msvc）。它们的具体区别可见https://www.msys2.org/docs/environments/。\n另外，笔者曾经有使用MinGW的困难（链接），不过现在我觉得可能不是MinGW的问题，具体什么问题由于我现在没有再遇到，可能不能解决了。\n注意，你安装ucrt64中的gcc后，可能会遇到编译过后，exe文件运行不正常的情况，例如打开直接错误退出，例如emacs的native compile错误的问题。这很可能是因为，你的电脑里面有太多g++的库了，比如GPG4Win，git，cmake，emacs，qt都会自带libstdc++-6.dll，这是gnu实现的c++的STL，这可能没什么，但是如果它们都在环境变量里，即使不会干扰到各自的运行（因为在同一个目录下的dll优先级高于在环境变量里的），也会对你自己编译的程序造成影响。解决办法是，把ucrt64的环境变量优先级拉高；或者复制一份ucrt64的libstdc++-6.dll到你的build目录下；或者干脆静态链接libstdc++。\n如果你要打包发送给别人用，别人一般不会拥有libstdc++这个库，你要么选择静态链接，要么把dll一起打包发布。可能这里静态链接会有被GPL感染的风险（我查到的说法基本上各执一词），建议还是动态链接吧。\n","date":"2023-05-06T23:44:47+08:00","permalink":"https://kegalas.top/p/msys2mingw64cygwin%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8C%BA%E5%88%AB%E6%B5%85%E8%B0%88/","title":"MSYS2,MinGW64,Cygwin的使用区别浅谈"},{"content":"信号与系统概论 信号的能量与功率 对于连续时间信号\\(x(t)\\)，在\\(t_1\\leq t\\leq t_2\\)内的总能量为\n\\[\\int^{t_2}_{t_1}|x(t)|^2 dt \\]\n\\(|\\cdot|\\)指的是模，因为可能是复数。\n在\\(n_1\\leq n\\leq n_2\\)内的离散时间信号\\(x[n]\\)的总能量为\n\\[\\sum^{n_2}_{n=n_1}|x[n]|^2 \\]\n功率将能量除以时间间隔即可。\n能量有限信号指\\(E\u003c\\infty\\)的信号，此时\\(P=0\\)（无限长时间意义上）\n功率有限信号指\\(0\u003c P\u003c\\infty\\)的信号，此时\\(E=\\infty\\)（无限长时间意义上）\n时限信号为能量信号，周期信号是功率信号，非周期信号可能是其中之一，有些信号两种都不是。\n自变量的变换 时移 时间翻转 时间尺度变换 周期信号 基波周期就是最小正周期。其对应的频率称为基波频率。\n两个周期信号的周期分别为\\(T_1\\)和\\(T_2\\)，若\\(T_1/T_2\\)为有理数，则周期信号之和仍然是周期信号，其周期为\\(T_1\\)和\\(T_2\\)的最小公倍数。\n离散的情况下，\\(sin(\\beta k)\\)是否为周期信号？\n如果\\(2\\pi/\\beta\\)是整数，则周期为\\(N=2\\pi/\\beta\\) 如果\\(2\\pi/\\beta\\)是有理数，则周期为\\(N=M(2\\pi/\\beta)\\)，\\(M\\)为使\\(N\\)称为正整数的最小正整数 如果\\(2\\pi/\\beta\\)是无理数，则不是周期信号。 偶信号与奇信号 任何信号都能分解成一个偶信号和一个奇信号的和。\n单位冲激函数与单位阶跃函数 单位冲激的符号是\\(\\delta\\)，单位阶跃的符号是\\(\\varepsilon\\)或\\(u\\)\n在离散情况下\n\\[\\delta[n] = u[n]-u[n-1] \\]\n是一次差分关系\n而\n\\[u[n] = \\sum^n_{m=-\\infty}\\delta [m] \\]\n连续情况下\n\\[\\delta(t) = \\dfrac{du(t)}{dt} \\]\n\\[u(t) = \\int^t_{-\\infty}\\delta(\\tau)d\\tau \\]\n单位冲激的导数，即单位冲激偶有\n\\[\\delta'(t) = \\begin{cases} \\pm\\infty \u0026 \\text{ if } t=0 \\\\ 0 \u0026 \\text{ if } t\\neq 0 \\end{cases} \\]\n连续时间系统和离散时间系统 定义 系统的互联 需要记住的是，并联在一起的是用加法，级联在一起的是用卷积。\n系统的基本性质 有记忆与无记忆 一个系统的输出仅仅取决于该时刻的输入，则为无记忆系统。\n可逆系统 一个系统在不同的输入下，导致不同的输出，那么就是可逆的。\n因果性 一个系统在任何时刻的输出只取决于现在的输入和过去的输入，则称为因果系统。\n因果系统的零状态响应不会出现在激励之前。\n稳定性 一个稳定系统，若其输入是有界的，那么输出也必须是有界的。\n时不变性 若系统的特性和行为不随时间改变，那么该系统就是时不变的。\n如果在输入信号上有一个时移，而在输出信号中产生同样的时移，那么就是时不变的。\n\\[T[f(t-t_0)] = y(t-t_0) \\]\n有一个直观的办法可以判定一个系统是时变的。如果\\(f(\\cdot)\\)前出现变系数，或者有反转、伸缩变换，则一定是时变系统。\n线性 一个线性系统应该满足\n\\(y_1(t)+y_2(t)\\)是对\\(x_1(t)+x_2(t)\\)的响应。 \\(ay_1(t)\\)是对\\(ax_1(t)\\)的响应，此处\\(a\\)为任意复常数。 可以记作\n\\[T[af_1(\\cdot)+bf_2(\\cdot)] = aT[f_1(\\cdot)]+bT[f_2(\\cdot)] \\]\n动态系统 动态系统不仅和激励\\(\\{f(\\cdot)\\}\\)有关，还与它过去的历史状况\\(\\{x(0)\\}\\)有关。\n完全响应\n\\[y(\\cdot) = T[\\{f(\\cdot)\\},\\{x(0)\\}] \\]\n零状态响应\n\\[y_{zs}(\\cdot) = T[\\{f(\\cdot)\\},\\{0\\}] \\]\n零输入响应\n\\[y_{zi}(\\cdot) = T[\\{0\\},\\{x(0)\\}] \\]\n当动态系统满足下列三个条件时，可以成为线性系统\n可分解性 \\[y = y_{zs} + y_{zi} \\]\n零状态线性 \\[T[\\{af_1(\\cdot)+bf_2(\\cdot)\\},\\{0\\}] = aT[\\{f_1(\\cdot)\\},\\{0\\}]+bT[\\{f_2(\\cdot)\\},\\{0\\}] \\]\n零输入线性 \\[T[\\{0\\},\\{ax_1(0)+bx_2(0)\\}] = aT[\\{0\\},\\{x_1(0)\\}]+bT[\\{0\\},\\{x_2(0)\\}] \\]\n线性时不变系统 卷积 离散情况\n\\[a[n]*b[n] = \\sum^{+\\infty}_{k=-\\infty} a[k]b[n-k] \\]\n连续情况\n\\[a(t)*b(t) = \\int^{+\\infty}_{-\\infty}a(\\tau)b(t-\\tau)d\\tau \\]\n用脉冲表示信号，及其响应 以下系统指线性时不变系统（LTI）。\n脉冲信号的筛选性质：\n\\[x[n] = \\sum^{+\\infty}_{k=-\\infty} x[k]\\delta[n-k] = x[n]*\\delta[n] \\]\n\\[x(t) = \\int^{+\\infty}_{-\\infty}x(\\tau)\\delta(t-\\tau)d\\tau = x(t)*\\delta(t) \\]\n一个系统对脉冲信号的（零状态）响应记作\\(h\\)。一个系统的特征可以完全由脉冲响应刻画，一个系统对其他信号的响应可以用该信号和脉冲响应的卷积表示。\n\\[y[n] = x[n]*h[n] \\]\n\\[y(t) = x(t)*h(t) \\]\n通常，题目中不会给以下两个条件。因为是零状态的响应，所以\\(h(0_-)=h'(0_-)=0\\)\n线性时不变系统的性质 线性时不变下卷积的性质 交换律 分配律 结合律 当然他都叫线性时不变系统了，肯定有线性和时不变性。\n微分特性（仅限于连续情况）\n\\[\\dfrac{d^n}{dt^n}[f_1*f_2] = \\dfrac{d^n f_1}{dt^n}*f_2 = f_1*\\dfrac{d^n f_2}{dt^n} \\]\n积分特性（仅限于连续情况）\n\\[\\int^t_{-\\infty}[f_1*f_2]d\\tau = [\\int^t_{-\\infty}f_1d\\tau]*f_2 = f_1 * [\\int^t_{-\\infty}f_2d\\tau] \\]\n\\(f_1(-\\infty)=0\\)或\\(f_2'(\\infty) = 0\\)（仅限连续情况）\n\\[f_1*f_2=f_1'*f_2' \\]\n（后向）差分特性（仅限于离散情况）\n\\[\\nabla[f_1*f_2] = \\nabla f_1*f_2 = f_1*\\nabla f_2 \\]\n时移特性\n若\\(f(t)=f_1(t)*f_2(t)\\)\n则\n\\[f_1(t-t_1)*f_2(t-t_2) = f_1(t-t_1-t_2)*f_2(t) = f_1(t)*f_2(t-t_1-t_2) = f(t-t_1-t_2) \\]\n无记忆的LTI 因为输出只和当前的输入有关，所以其冲激响应为\\(h(t)=K\\delta(t)\\)。\n系统对于其他信号的响应就为\\(y(t)=Kx(t)\\)。离散的情况类似。\n微分特性 \\[if\\quad x(t)\\to y(t)\\quad then\\quad x'(t)\\to y'(t) \\]\n积分特性 \\[if\\quad x(t)\\to y(t)\\quad then\\quad \\int^t_{-\\infty}x(t)dt\\to \\int^t_{-\\infty}y(t)dt \\]\n可逆性 仅当存在一个逆系统，其与原系统级联后所产生的输出等于第一个系统的输入时，这个系统才是可逆的。\n设一个系统的冲激响应是\\(h(t)\\)，逆系统的冲激响应是\\(h_1(t)\\)，则\n\\[h(t)*h_1(t) = \\delta(t) \\]\n离散的情况类似。\n因果性 如果\\(h(t)=0,t\u003c0\\)，那么一个LTI就是因果的，这时\n\\[y(t) = \\int^t_{-\\infty} x(\\tau)h(t-\\tau)d\\tau = \\int^\\infty_0 h(\\tau)x(t-\\tau)d\\tau \\]\n稳定性 一个稳定的离散LTI，要求\n\\[\\sum^{+\\infty}_{k=-\\infty}|h[k]| \u003c \\infty \\]\n一个稳定的连续LTI，要求\n\\[\\int^{+\\infty}_{-\\infty} |h(\\tau)|d\\tau \u003c \\infty \\]\nLTI的单位阶跃响应 单位阶跃响应记作\\(s\\)或\\(g\\)\n\\[s[n] = u[n]*h[n] = \\sum^n_{k=-\\infty}h[k] \\]\n\\[h[n] = s[n]-s[n-1] \\]\n\\[s(t) = \\int^t_{-\\infty} h(\\tau)d\\tau \\]\n\\[h(t) = \\dfrac{ds(t)}{dt} \\]\n用微分方程描述的连续因果线性时不变系统 微分方程 微分方程的形式如下\n\\[y^{(n)}(t) + a_{n-1}y^{(n-1)}(t)+\\cdots+a_{1}y^{(1)}(t)+a_0y(t) = b_{m}f^{(m)}(t)+b_{m-1}f^{(m-1)}(t)+\\cdots+b_{1}f^{(1)}(t)+b_{0}f(t) \\]\n解的形式如下\n\\[y(t) = y_h(t) + y_p(t) \\]\n其中\\(y_h\\)是齐次解，\\(y_p\\)是特解。\n齐次解是对应的齐次方程\n\\[y^{(n)}(t) + a_{n-1}y^{(n-1)}(t)+\\cdots+a_{1}y^{(1)}(t)+a_0y(t) = 0 \\]\n的解。\n解这个方程，我们首先要求得特征根\\(\\lambda\\)，由以下方程解出\n\\[\\lambda^n + a_{n-1}\\lambda^{n-1}+\\cdots+a_0=0 \\]\n对于每一个\\(\\lambda_i\\)，\n如果它是单实根，则 \\[y_h = Ce^{\\lambda t} \\]\n如果它是二重实根，则 \\[y_h = (C_1t+C_0)e^{\\lambda t} \\]\n如果是一对共轭复根\\(\\lambda_{1,2} = \\alpha\\pm j\\beta\\)，则 \\[e^{\\alpha t}[C\\cos(\\beta t)+D\\sin(\\beta t)] \\]\n整个齐次解就是把这些对于每一个\\(\\lambda_i\\)的齐次解加起来，再根据条件求出待定系数。\n特解的常见形式为\n激励为\\(f(t)=t\\)时，如果所有的特征根均不等于\\(0\\)， \\[P_1 t+P_0 \\]\n如果有\\(1\\)个等于\\(0\\)的特征根，\n\\[t(P_1t+P_0) \\]\n激励为\\(f(t)=e^{\\alpha t}\\)，如果\\(\\alpha\\)不等于特征根 \\[Pe^{\\alpha t} \\]\n如果\\(\\alpha\\)等于特征根\n\\[(P_1t+P_0)e^{\\alpha t} \\]\n激励为\\(cos(\\beta t)\\)或\\(\\sin(\\beta t)\\)，如果所有的特征根都不等于\\(\\pm j\\beta\\) \\[P\\cos(\\beta t) + Q\\sin(\\beta t) \\]\n这个通常可以把\\(y_p\\)直接代入原方程求解系数。\n激励为\\(\\delta,\\varepsilon\\)等时，由于我们的特解是零状态响应中的部分，所以都是在\\(0_+\\)时的取值，我们直接把激励在\\(0_+\\)的值写在等号右边，然后设定\\(y_p=p\\)（常数），解出\\(p\\)即可。显然，\\(p\\)的值会是\\(\\varepsilon\\text{的系数}/y\\text{的系数}\\)（因为\\(y\\)现在是常数，任意阶导数为\\(0\\)）。如果是\\(e^t\\varepsilon(t)\\)这种形式又怎么办呢，还是老话，我们求特解是\\(0_+\\)时的值，此时看做激励为\\(e^t\\)，然后用上面的特解。 注意，如果题目给的条件是\\(y(0),y'(0)\\)等条件，我们需要在全解中去求齐次解中设的参数。如果题目给的条件是\\(y_{zi},y'_{zi}\\)等条件，我们在齐次解中求参数即可。\n题目中也可能只给出\\(y(0^-),y'(0^-)\\)的条件，这显然就是给零输入条件。如果你还要求出零状态响应和全解，你必须在这之前求出\\(y(0^+),y'(0^+)\\)，才能带进去求零状态响应的参数，求解方法见后。\n如果给的激励包含多种情况？我自己的思考是，求出冲激响应即可，然后根据线性性质，将激励分别与冲激响应卷积，再相加。\n还有一种办法是求频率响应\\(H(jw)\\)来求零状态响应，见后。\n系统的初始值 初始值是\\(n\\)阶系统在\\(t=0\\)时接入激励，其响应在\\(t=0_+\\)时刻的值，即\\(y^{(j)}(0_+) (j=0,1,2,\\cdots,n-1)\\)。\n初始状态是指系统在激励尚未接入的\\(t=0_-\\)时刻的响应值\\(y^{(j)}(0_-)\\)，该值反映了系统的历史情况，而与激励无关。\n例如\\(y''(t)+3y'(t)+2y(t)=2\\delta(t)+6\\varepsilon(t)\\)，（老师在PPT中给出但我没有看懂的办法是）两端积分\n\\[\\int^{0_+}_{0_-}y''(t)dt+3\\int^{0_+}_{0_-}y'(t)dt+2\\int^{0_+}_{0_-}y(t)dt = 2\\int^{0_+}_{0_-}\\delta(t)dt + 6\\int^{0_+}_{0_-}\\varepsilon(t)dt \\]\n其中从左到右每一项分别对应，\\(y'(0_+)-y'(0_-),y(0_+)-y(0_-),0,2,0\\)\n所以\\(y'(0_+)-y'(0_-) = 2, y(0_+)-y(0_-) = 0\\)\n结论是，微分方程等号右边含有\\(\\delta(t)\\)及其各阶导数时，响应\\(y(t)\\)及其各阶导数由\\(0_-\\)到\\(0_+\\)的瞬间将发生跃变（如果不含，则\\(y(t)\\)在t=0处是连续的，\\(y(0_+)=0\\)）。这时可按如下步骤由\\(0_-\\)求取\\(0_+\\)（以二阶系统为例）\n将\\(f(t)\\)代入微分方程。如果等号右边含有\\(\\delta(t)\\)及其各阶导数，根据微分方程等号两端各奇异函数的系数相等原理，判断方程左端\\(y(t)\\)的最高阶导数所含\\(\\delta(t)\\)导数的最高阶次。 令\\(y''(t) = a\\delta''(t)+b\\delta'(t)+c\\delta(t)+r_0(t)\\)（其中\\(r_0(t)\\)是指不含\\(\\delta(t)\\)及其各阶导数的项，在第四步中的积分，由于不含这些项，所以是\\(0\\)），对\\(y''(t)\\)进行积分（从\\(-\\infty\\)到\\(t\\)），求得\\(y'(t),y(t)\\)。 将\\(y'',y',y\\)代入微分方程，根据等号两端各奇异函数的系数相等，从而求得各个待定系数。 分别对\\(y',y''\\)等号两端从\\(0_-\\)到\\(0_+\\)积分，求得\\(0_+\\)值 用这种方法能对上式较好的求解。\n必须要提到的一点是，设\\(g(f) = \\int^{0_+}_{0_-}f(x)dx\\)，应该只有\\(f(x)=\\delta(x)\\)（不考虑常数系数），才有\\(g(f)=1\\)，其他全部都有\\(g(f)=0\\)。或许有其他函数也满足\\(g(f)\\neq 0\\)，但是在信号这里，所有连续的函数、阶跃函数、冲激函数的导数、二阶导数、\\(n\\)阶导数\\(g(f)\\)都等于\\(0\\)，只有冲激函数自己等于\\(1\\)。\n零输入响应 记作\\(y_{zi}\\)，对应齐次微分方程的解。故不存在跃变。\n零状态响应 记作\\(y_{zs}\\)，对应非齐次方程的解，需要求出来齐次解和特解，再加起来。最后的全响应需要将零输入和零状态加起来。注意零输入和零状态都要求一个齐次解，虽然它们形式相同，但是系数可能不同。\n有一种投机取巧的办法求全响应就是用电路课中介绍的三要素法。\n响应分类 响应可以分为固有响应和强迫响应\n固有响应仅与系统本身的特性有关，而与激励的函数形式无关。是微分方程的齐次解。\n强迫响应与激励的函数形式有关。是微分方程的特解。\n响应可以分为暂态响应和稳态响应\n暂态响应是指响应中暂时出现的分量，随着时间的增长，它将消失。\n稳态响应是稳定的分量，若存在，通常表现为阶跃函数和周期函数。比如，电路系统中的直流稳态响应和正弦稳态响应。\n微分方程求冲激响应 例如我们有\\(y''+a_1y'+a_0y' = b_2f''+b_1f'+b_0f\\)，我们可以分两步进行\n选择一个响应\\(h_1(t)\\)，使得 \\[h_1''+a_1h_1'+a_0h_1 = \\delta \\]\n\\[h_1(0_-)=h_1'(0_-) = 0 \\]\n计算出\\(h_1(0_+),h_1'(0_+)\\)，然后我们使用之前提到的解法求出\\(h_1\\)，不过显然这里特解为\\(0\\)，和齐次解具有同样的形式。冲激响应求的是一种零状态响应，虽然它和齐次解有同样的形式。\n根据线性性质和微分特性，可知\\(h = b_2h_1''+b_1h_1'+b_0h_1\\)。不过注意这个\\(b_i\\)是常数，如果我们等式右边是\\(b_2f''+b_0f+q\\)，这个\\(q\\)不是\\(f\\)的导数（其他情况类似），则我们的\\(h=b_2h_1''+b_0h_1+q*h_1\\)。当然你也可以全部都做卷积，只是不是把\\(b_2,b_1,b_0\\)拿来做卷积，而是把整体的\\(b_2f'',b_1f',b_0f\\)拿来做卷积。如果\\(f=h\\)，卷积的结果就是\\(b_2h_1''+b_1h_1'+b_0h_1\\) 当然我强烈推荐你用拉普拉斯变换来算。\n微分方程求阶跃响应 类似的，还是上面那个例子\n选择一个响应\\(g_1(t)\\)，使得 \\[g_1''+a_1g_1'+a_0g_1 = \\varepsilon \\]\n\\[g_1(0_-)=g_1'(0_-) = 0 \\]\n计算出\\(g_1(0_+),g_1'(0_+)\\)，然后我们使用之前提到的解法求出\\(g_1\\)。阶跃响应求的是一种零状态响应，它有特解和齐次解。\n根据线性性质和微分特性，可知\\(g = b_2g_1''+b_1g_1'+b_0g_1\\) 或者，如果我们已知冲激响应，我们有更简单的办法，由于微积分特性，我们可以求出\n\\[g(t) = \\int^t_{-\\infty} h(\\tau)d\\tau \\]\n同理\n\\[h(t) = g'(t) \\]\n用差分方程描述的离散因果线性时不变系统 差分方程 一般形式为\n\\[y[k]+a_{n-1}y[k-1]+\\cdots+a_0y[k-n] = b_mf[k]+\\cdots+b_0f[k-m] \\]\n和微分方程相似，差分方程的解也可以分为\\(y = y_h+y_p\\)\n齐次解也是由齐次方程求特征根得到。\n对于每一个\\(\\lambda_i\\)，\n如果它是单实根，则 \\[y_h = C\\lambda^k \\]\n如果它是二重实根，则 \\[y_h = (C_1k+C_0)\\lambda^k \\]\n如果是一对共轭复根\\(\\lambda_{1,2} = \\alpha\\pm j\\beta\\)，则 \\[\\rho^k[C\\cos(\\beta k)+D\\sin(\\beta k)] \\]\n整个齐次解就是把这些对于每一个\\(\\lambda_i\\)的齐次解加起来，再根据条件求出待定系数。\n特解的常见形式为\n激励为\\(f[k]=k\\)时，如果所有的特征根均不等于\\(1\\)， \\[P_1 k+P_0 \\]\n如果有\\(1\\)个等于\\(1\\)的特征根，\n\\[k(P_1k+P_0) \\]\n激励为\\(f[k]=a^k\\)，如果\\(a\\)不等于特征根 \\[Pa^k \\]\n如果\\(a\\)等于特征根\n\\[(P_1k+P_0)a^k \\]\n激励为\\(cos(\\beta k)\\)或\\(\\sin(\\beta k)\\)，如果所有的特征根都不等于\\(e^{\\pm j\\beta}\\) \\[P\\cos(\\beta k) + Q\\sin(\\beta k) \\]\n这个通常可以把\\(y_p\\)直接代入原方程求解系数。\n激励为\\(\\delta,\\varepsilon\\)时。如果只有\\(\\varepsilon\\)，则我们直接设置\\(y[k]\\)为常数，与连续的情况不同，差分不会使得\\(y[k-1]\\)等于零。解出的特解就是\\(y\\)的各项系数之和分之\\(\\varepsilon\\)的系数之和（我确定这个在激励只有\\(\\varepsilon[k]\\)的时候是成立的，如果有\\(\\varepsilon[k-1]\\)等东西成不成立我不确定，没找到网上和教材中讨论这个）。如果只有\\(\\delta\\)，则实际上是在求冲激响应，由后面可得，就是在求齐次解形式的解，不存在特解。如果两个都有，只管\\(\\varepsilon\\)（这是我的猜测，没找到教材讨论这个，我们或许还可以考虑\\(\\delta[k]=\\varepsilon[k]-\\varepsilon[k-1]\\)）。 注意，如果题目给的条件是\\(y[k],y[k-1]\\)等条件，我们需要在全解中去求齐次解中设的参数。如果题目给的条件是\\(y_{zi}[k],y_{zi}[k-1]\\)等条件，我们在齐次解中求参数即可。\n零输入响应 同前\n零状态响应 同前\n差分方程求单位脉冲响应 例如\\(y[k]-4y[k-1]+3y[k-2]=3f[k]-f[k-1]\\)，我么可以首先\n\\[h[k]-4h[k-1]+3h[k-2]=3\\delta[k]-\\delta[k-1] \\]\n由隐含条件（二阶下），\\(h[-1]=h[-2]=0\\)，又由上式，我们可以求出\\(h[0],h[1]\\)。再对上式用传统方法求出齐次解。\n由于代入求解参数时代入的是\\(h[0],h[1]\\)，对于\\(k=1,k=0\\)时方程也成立（实际上单位脉冲响应和零输入响应、齐次解具有同样的形式，不需要特解），所以单位脉冲响应就是\\(h[k] = [-1+4(3)^k]\\varepsilon[k]\\)\n当然，如果等式右边出现的是\\(f[k-2]+f[k-1]\\)这样的，我们就要求出\\(h[2],h[1]\\)，然后用这个代入求解齐次解的参数。\n或者我们还是用老办法，求出\\(h_1[k]-4h_1[k-1]+3h_1[k-2]=\\delta[k]\\)，中\\(h_1[k]\\)的表达式（需要用\\(h[0],h[-1]\\)求出参数），然后在根据线性性质求出\\(h[k]\\)\n差分方程求单位阶跃响应 阶跃响应和差分方程的全解是一个形式。我们求出全解即可。注意隐含条件（二阶下）是\\(g[-1]=g[-2]=0\\)，我们可以求出\\(g[0],g[1]\\)，代入求出参数。\n或者由差分特性\n\\[g[k] = \\sum^k_{i=-\\infty}h[i] \\]\n同理有\n\\[h[k] = g[k] - g[k-1] \\]\n用方框图描述LTI 不做细致介绍（主要是我懒，但这玩意其实很浅显，做一两题就会列表达式了，会不会解题另说），注意级联的时候\\(h(t)\\)之间用卷积，\\(H(jw)\\)用乘号即可。有时会用上设中间变量的方法。\n奇异函数 对于连续情况\n\\[x(t) = x(t) * \\delta(t) \\]\n\\[x'(t) = x(t)*\\delta '(t) \\]\n\\[x''(t) = x(t) * \\delta ''(t) = x(t) * \\delta '(t) * \\delta '(t) \\]\n以此类推。而\n\\[x(t) * u(t) = \\int^t_{-\\infty}x(\\tau)d\\tau \\]\n也可以以此类推。\n其中\\(u(t)*u(t) = tu(t)\\)称为单位斜坡函数。\n此外还有\n\\[f(t)\\delta(t)=f(0)\\delta(t) \\]\n\\[\\int^{+\\infty}_{-\\infty}f(t)\\delta(t)dt=f(0) \\]\n\\[f(t)\\delta(t-a) = f(a)\\delta(t-a) \\]\n\\[\\int^{+\\infty}_{-\\infty}f(t)\\delta(t-a)dt = f(a) \\]\n\\[f(t)\\delta'(t) = f(0)\\delta'(t)-f'(0)\\delta(t) \\]\n\\[\\int^{+\\infty}_{-\\infty}f(t)\\delta'(t)dt = -f'(0) \\]\n\\[\\int^{+\\infty}_{-\\infty}f(t)\\delta'(t-a)dt = -f'(a) \\]\n\\[\\int^{+\\infty}_{-\\infty}f(t)\\delta^{(n)}(t)dt = (-1)^nf^{(n)}(0) \\]\n\\[\\delta(at) = \\dfrac{1}{|a|}\\delta(t) \\]\n\\[\\delta^{(n)}(at) = \\dfrac{1}{|a|}\\dfrac{1}{a^n}\\delta^{(n)}(t) \\]\n\\[\\delta^{(n)}(-t)=(-1)^n\\delta^{(n)}(t) \\]\n对于离散情况\n\\[f[k]*\\delta[k] = f[k] \\]\n\\[f[k]*\\delta[k-k_0] = f[k-k_0] \\]\n\\[f[k]*\\varepsilon[k] = \\sum^k_{i=-\\infty}f[i] \\]\n此外还有\n\\[f[k]\\delta[k] = f[0]\\delta[k] \\]\n\\[f[k]\\delta[k-k_0] = f[k_0]\\delta[k-k_0] \\]\n\\[\\sum^{+\\infty}_{k=-\\infty}\\delta[k] = 1 \\]\n\\[\\sum^{+\\infty}_{k=-\\infty}f[k]\\delta[k] = f[0] \\]\n\\[\\sum^{+\\infty}_{k=-\\infty}f[k]\\delta[k-k_0] = f[k_0] \\]\n\\[\\sum^{k}_{i=-\\infty}\\delta[i] = \\varepsilon[k] \\]\n\\[\\delta[k] = \\varepsilon[k]-\\varepsilon[k-1] \\]\n\\[\\delta[k] = \\delta[-k] \\]\n相关函数 实函数\\(f_1(t)\\)和\\(f_2(t)\\)，如为能量有限信号，它们之间的互相关函数定义为：\n\\[R_{12}(\\tau) = \\int^{+\\infty}_{-\\infty}f_1(t)f_2(t-\\tau)dt = \\int^{+\\infty}_{-\\infty}f_1(t+\\tau)f_2(t)dt \\]\n\\[R_{21}(\\tau) = \\int^{+\\infty}_{-\\infty}f_1(t-\\tau)f_2(t)dt = \\int^{+\\infty}_{-\\infty}f_1(t)f_2(t+\\tau)dt \\]\n一般两者不相等，但是有\\(R_{12}(\\tau) = R_{21}(-\\tau)\\)\n如果\\(f_1,f_2\\)是同一个函数，那么无须区分二者，直接用\\(R\\)表示自相关系数，\n\\[R(\\tau) = \\int^{+\\infty}_{-\\infty}f(t+\\tau)f(t)dt = \\int^{+\\infty}_{-\\infty}f(t)f(t-\\tau)dt \\]\n此时\\(R(\\tau)=R(-\\tau)\\)\n这东西和卷积的形式很像，显然我们可以推出来\n\\[R_{12} = f_1(t)*f_2(-t) \\]\n周期信号的傅里叶级数表示 信号的正交分解 LTI对复指数信号的响应 LTI对复指数信号的响应也是一个复指数信号，不同的只是在幅度上的变化\n\\[e^{st}\\rightarrow H(s)e^{st} \\]\n\\[z^n = H(z)z^n \\]\n上面\\(s,z\\)是复数，我们更多讨论\\(s=jw,z=e^{jw}\\)的情况。\n其中\\(H\\)是一个复振幅因子。\n一个信号，如果系统对该信号的输出响应仅是一个常数（可能是复数）乘以输入，那么这个信号就是这个系统的特征函数，幅度因子称为特征值。\n如果将输入信号表示为傅立叶级数\n\\[x(t) = \\sum_ka_ke^{s_kt} \\]\n则响应一定是\n\\[y(t) = \\sum_k a_kH(s_k)e^{s_kt} \\]\n离散情况下\n\\[x[n] = \\sum_ka_kz^n_k \\]\n\\[y[n] = \\sum_k a_kH(z_k)z^n_k \\]\n连续时间周期信号的傅里叶级数表示 \\[x(t) = \\sum^{+\\infty}_{k=-\\infty}a_ke^{jkw_0t} = \\sum^{+\\infty}_{k=-\\infty}a_ke^{jk(2\\pi/T)t} \\]\n\\(k=0\\)的一项是一个常数，\\(k=\\pm 1\\)的两项合称为基波分量，也称为一次谐波分量，之后类推。\n也可以写作\n\\[x(t) = a_0 + 2\\sum^\\infty_{k=1}[B_k\\cos kw_0 t - C_k\\sin kw_0t] \\]\n或者\n\\[x(t) = \\dfrac{a_0}{2}+\\sum^\\infty_{n=1}a_n\\cos(n\\Omega t)+\\sum^\\infty_{n=1}b_n\\sin(n\\Omega t) = \\dfrac{A_0}{2} + \\sum^\\infty_{n=1}A_n\\cos(n\\Omega t+\\varphi_n) \\]\n其中（指数表示的那个）\\(a_n\\)由以下公式确定\n\\[a_n = \\dfrac{1}{T}\\int^T_0x(t)e^{-jnw_0t}dt \\]\n或者也可以是在任意一个最小正周期内的积分，记作\\(\\int_T\\)\n\\(a_n\\)称为傅里叶级数系数或频谱系数，\\(a_0\\)为直流或常数分量。\n傅立叶级数的收敛 条件1\n在任何周期内，\\(x(t)\\)必须绝对可积，即\n\\[\\int_T|x(t)|dt\u003c\\infty \\]\n这也保证了平方可积，也就保证了能量有限，每一个系数有限。\n条件2\n在任意有限区间内，\\(x(t)\\)具有有限个起伏变化。也就是说，在任何单个周期内，\\(x(t)\\)的最大值和最小值的数目有限。\n条件3\n在\\(x(t)\\)的任何有限区间内，只有有限个不连续点，而且在这些不连续点上，函数是有限值。\n在这些不连续点上，傅里叶级数收敛到不连续点处的平均值。\n连续时间傅里叶级数的性质 首先设\\(x(t),y(t)\\)的周期都为\\(T\\)，傅立叶系数为\\(a_k,b_k\\)\n线性\n\\[Ax(t)+By(t)\\leftrightarrow Aa_k+Bb_k \\]\n时移\n\\[x(t-t_0) \\leftrightarrow a_ke^{-jkw_0t_0} = a_ke^{-jk(2\\pi/T)t_0} \\]\n频移\n\\[e^{jMw_0t}x(t) = e^{jM(2\\pi/T)t}x(t) \\leftrightarrow a_{k-M} \\]\n共轭\n\\[x^*(t) = a^*_{-k} \\]\n时间反转\n\\[x(-t) = a_{-k} \\]\n时域尺度变换\n\\[x(\\alpha t),\\alpha \u003e0(周期为T/\\alpha) \\leftrightarrow a_k \\]\n周期卷积\n\\[\\int_Tx(\\tau)y(t-\\tau)d\\tau\\leftrightarrow Ta_kb_k \\]\n相乘\n\\[x(t)y(t) \\leftrightarrow a_k*b_k \\]\n微分\n\\[\\dfrac{dx(t)}{dt} \\leftrightarrow jkw_0a_k=jk\\dfrac{2\\pi}{T}a_k \\]\n积分\n\\[\\int^t_{-\\infty} x(t)dt \\leftrightarrow \\dfrac{1}{jkw_0}a_k = \\dfrac{1}{jk(2\\pi/T)}a_k \\]\n周期信号的帕塞瓦尔定理\n\\[\\dfrac{1}{T}\\int_T|x(t)|^2 dt = \\sum^{+\\infty}_{k=-\\infty}|a_k|^2 \\]\n谐波特性 偶函数\n如果\\(x(t)\\)是偶函数，则其没有正弦分量，只有余弦分量和直流分量。\n奇函数\n如果\\(x(t)\\)是奇函数，则其没有余弦分量和直流分量，只有正弦分量。\n奇谐函数\n傅里叶级数中只含有奇次谐波分量，不含有偶次谐波分量，即\n\\[a_0=a_2=a_4=\\cdots=b_2=b_4=\\cdots=0 \\]\n表现为\\(x(t) = -x(t\\pm T/2)\\)\n偶谐函数\n傅里叶级数中只含有偶次谐波分量，不含有奇次谐波分量，即\n\\[a_1=a_3=\\cdots=b_1=b_3=\\cdots=0 \\]\n表现为\\(x(t) = x(t\\pm T/2)\\)\n离散时间周期信号的傅里叶级数表示 离散时间周期信号的傅里叶级数是有限项级数，而连续情况下是无穷级数。所以离散情况下不存在收敛的问题。\n离散情况下，周期N满足\n\\[x[n] = x[n+N] \\]\n其中最小的正整数\\(N\\)对应的角频率称为基波频率。\n\\(x[n]\\)的傅里叶级数表示为\n\\[x[n] = \\sum_k a_ke^{jkw_0n} = \\sum_ka_ke^{jk(2\\pi/N)n} \\]\n其中这个求和是，k在任意连续\\(N\\)个数中都成立的。所以也可以记作\n\\[x[n] = \\sum_{k= \u003c N \u003e }a_ke^{jkw_0n} \\]\n\\(a_k\\)由以下公式确定\n\\[a_k = \\dfrac{1}{N}\\sum_{n= \u003c N \u003e }x[n]e^{-jkw_0n} = \\dfrac{1}{N}\\sum_{n= \u003c N \u003e }x[n]e^{-jk(2\\pi/N)n} \\]\n离散时间傅里叶级数的性质 整体和连续的情况差别不大。\n首先设\\(x[n],y[n]\\)的周期都为\\(N\\)，傅立叶系数为\\(a_k,b_k\\)，系数是周期的，周期也为\\(N\\)\n线性\n\\[Ax[n]+By[n]\\leftrightarrow Aa_k+Bb_k \\]\n时移\n\\[x[n-n_0] \\leftrightarrow a_ke^{-jk(2\\pi/N)n_0} \\]\n频移\n\\[e^{jM(2\\pi/N)n}x[n]\\leftrightarrow a_{k-M} \\]\n共轭\n\\[x^*[n] = a^*_{-k} \\]\n时间反转\n\\[x[-n] = a_{-k} \\]\n时域尺度变换\n\\[x_{(m)}[n] = \\begin{cases} x[n/m] \u0026 n是m的倍数\\\\ 0 \u0026 n不是m的倍数 \\end{cases} \\leftrightarrow \\dfrac{1}{m}a_k,周期为mN \\]\n周期卷积\n\\[\\sum_{r= \u003c N \u003e }x[r]y[n-r]\\leftrightarrow Na_kb_k \\]\n相乘\n\\[x[n]y[n] \\leftrightarrow \\sum_{l= \u003c N \u003e }a_l b_{k-l} \\]\n差分\n\\[x[n]-x[n-1] \\leftrightarrow (1-e^{-jk(2\\pi/N)})a_k \\]\n求和\n\\[\\sum^n_{k=-\\infty}x[n](仅当a_0=0才为有限的且为周期的)\\leftrightarrow \\bigg(\\dfrac{1}{1-e^{-jk(2\\pi/N)}}\\bigg)a_k \\]\n周期信号的帕塞瓦尔定理\n\\[\\dfrac{1}{N}\\sum_{n= \u003c N \u003e }|x[n]|^2 = \\sum_{k= \u003c N \u003e }|a_k|^2 \\]\n傅里叶级数与LTI 若\\(x(t)=e^{st}\\)是一个连续时间线性时不变系统的输入，其输出就为\\(y(t)=H(s)e^{st}\\)，而\n\\[H(s) = \\int^{+\\infty}_{-\\infty} h(\\tau)e^{-s\\tau}d\\tau \\]\n其中\\(h(\\tau)\\)是该线性时不变系统的单位冲激响应（这其实是\\(h(t)\\)的傅立叶变换）。\n同理离散情况下\\(x[n]=z^n\\)，\\(y[n]=H(z)z^n\\)\n\\[H(z) = \\sum^{+\\infty}_{k=-\\infty}h[k]z^{-k} \\]\n当\\(s,z\\)是一般复数时，\\(H(s),H(z)\\)就称为该系统的系统函数。一般我们考虑\\(s=jw,z=e^{jw}\\)，此时\\(H(s),H(z)\\)称为频率响应。\n此时我们可以说\n若用傅里叶级数表示输入\n\\[x(t) = \\sum^{+\\infty}_{k=-\\infty}a_ke^{jkw_0t} \\]\n则输出为\n\\[y(t) = \\sum^{+\\infty}_{k=-\\infty}a_kH(jkw_0)e^{jkw_0t} \\]\n此时\\(y(t)\\)也是周期的，并且与\\(x(t)\\)有相同的基波频率。若\\(a_k\\)是\\(x(t)\\)的傅立叶系数，那么\\(a_kH(jkw_0)\\)就是\\(y(t)\\)的傅里叶系数。\n离散情况下，若用傅里叶级数表示输入\n\\[x[n] = \\sum_{k= \u003c N \u003e } a_ke^{jk(2\\pi/N)n} \\]\n那么输出为\n\\[y[n] = \\sum_{k= \u003c N \u003e } a_kH(e^{j2\\pi k/N})e^{jk(2\\pi/N)n} \\]\n\\(y[n]\\)也是周期的，且和\\(x[n]\\)具有相同的周期，\\(y[n]\\)的第\\(k\\)个傅里叶系数就是\\(a_kH(e^{j2\\pi k/N})\\)\n周期信号的频谱 分为单边谱和双边谱。\n单边谱是对于三角函数形式展开的，\n\\[x(t) = \\dfrac{A_0}{2} + \\sum^\\infty_{n=1}A_n\\cos(n\\Omega t+\\varphi_n) \\]\n频谱分为两个函数图像，即\\(A_n\\sim\\omega\\)的幅度谱和\\(\\varphi_n\\sim\\omega\\)的相位谱（\\(\\omega=n\\Omega,n=0,1,2,\\cdots\\)）\n双边谱是对于指数形式展开的，\n\\[x(t) = \\sum^{+\\infty}_{k=-\\infty}a_ke^{jkw_0t} \\]\n频谱分为两个函数图像，即\\(|a_k|\\sim\\omega\\)的幅度谱和\\(\\varphi_k\\sim\\omega\\)的相位谱（\\(\\omega=k\\omega_0,\\varphi_k=k\\omega_0 t,k=0,\\pm1,\\pm2,\\cdots\\)）\n滤波 按我的理解，简单来说，就是弄一个系统，使得它的频率响应\\(H(jw)\\)弄成你想要滤波的效果。\n比如，你想要弄一个理想低通滤波器，那么你就设计一个系统，使得其\n\\[H(jw) = \\begin{cases} 1 \u0026 \\text{ if } |w|\\leq w_c \\\\ 0 \u0026 \\text{ if } |w| \u003ew_c \\end{cases} \\]\n这样输出\\(y(t)=H(jw)x(t)\\)，就只会保留\\(x(t)\\)中频率在\\([-w_c,w_c]\\)之间的部分。\n连续时间傅里叶变换 非周期信号的表示 可以把非周期信号当成一个周期信号在周期任意大时的极限。\n设\\(\\tilde x(t)\\)是一个周期信号，而\\(x(t)\\)是这个周期信号的其中一个周期，其他部分全为\\(0\\)，那么（方便起见取周期\\([-T/2,T/2]\\)）\n\\[a_k = \\dfrac{1}{T}\\int^{T/2}_{-T/2}x(t)e^{-jkw_0t}dt = \\dfrac{1}{T}\\int^{+\\infty}_{-\\infty}x(t)e^{-jkw_0t}dt \\]\n定义\\(Ta_k\\)的包络\\(X(jw)\\)为\n\\[X(jw) = \\int^{+\\infty}_{-\\infty}x(t)e^{-jwt}dt \\]\n则\n\\[a_k= \\dfrac{1}{T}X(jkw_0) \\]\n然后我们就可以用上式去表示\\(\\tilde{x}(t)\\)，当周期无限大时，表示\\(x(t)\\)如下\n\\[x(t) = \\dfrac{1}{2\\pi}\\int^{+\\infty}_{-\\infty}X(jw)e^{jwt}dw \\]\n\\[X(jw) = \\int^{+\\infty}_{-\\infty}x(t)e^{-jwt}dt \\]\n这两个式子称为傅立叶变换对。\\(X(jw)\\)称为\\(x(t)\\)的傅里叶变换，也称为\\(x(t)\\)的频谱。\n傅立叶变换的收敛 和之前一样\n\\(\\int^{+\\infty}_{-\\infty}|x(t)|dt\u003c\\infty\\) 任何有限区间内，\\(x(t)\\)只有有限个最大值和最小值 任何有限区间内，\\(x(t)\\)有有限个不连续点，并且在每个不连续点处都必须是有限值。 但有些函数其实不满足，也可以收敛，有傅里叶变换，比如阶跃函数。\n周期信号的傅立叶变换 \\[x(t) = \\sum^{+\\infty}_{k=-\\infty}a_ke^{jkw_0t} \\]\n\\[X(jw) = \\sum^{+\\infty}_{k=-\\infty}2\\pi a_k\\delta(w-kw_0) \\]\n连续时间傅里叶变换的性质 设非周期信号\\(x(t),y(t)\\)，傅立叶变换分别为\\(X(jw),Y(jw)\\)\n线性\n\\[ax(t)+by(t)\\leftrightarrow aX(jw)+bY(jw) \\]\n时移\n\\[x(t-t_0)\\leftrightarrow e^{-jwt_0}X(jw) \\]\n频移\n\\[e^{jw_0t}x(t)\\leftrightarrow X(j(w-w_0)) \\]\n共轭\n\\[x^*(t)\\leftrightarrow X^*(-jw) \\]\n时间反转\n\\[x(-t)\\leftrightarrow X(-jw) \\]\n如果\\(x(t)\\)为实函数，\\(x(-t)\\leftrightarrow X(-jw) = X^*(jw)\\)\n如果\\(x(t)\\)为虚函数\\(jg(t)\\)，\\(x(-t)\\leftrightarrow X(-jw) = -X^*(jw)\\)\n尺度变换\n\\[x(at)\\leftrightarrow\\dfrac{1}{|a|}X(\\dfrac{jw}{a}) \\]\n卷积\n\\[x(t)*y(t)\\leftrightarrow X(jw)Y(jw) \\]\n相乘\n\\[x(t)y(t)\\leftrightarrow \\dfrac{1}{2\\pi} X(jw)*Y(jw) \\]\n时域微分\n\\[\\dfrac{d^n}{dt^n}x(t)\\leftrightarrow (jw)^nX(jw) \\]\n积分\n\\[\\int^t_{-\\infty}x(t)dt\\leftrightarrow \\dfrac{1}{jw}X(jw)+\\pi X(0)\\delta(w) \\]\n频域微分\n\\[tx(t)\\leftrightarrow j\\dfrac{d}{dw}X(jw) \\]\n\\[(-jt)^nx(t)\\leftrightarrow X^{(n)}(jw) \\]\n频域积分\n\\[\\dfrac{1}{-jt}x(t)+\\pi x(0)\\delta(t)\\leftrightarrow \\int^w_{-\\infty}X(jx)dx \\]\n非周期信号的帕塞瓦尔定理\n\\[\\int^{+\\infty}_{-\\infty}|x(t)|^2dt=\\dfrac{1}{2\\pi}\\int^{+\\infty}_{-\\infty}|X(jw)|^2dw \\]\n对称\n\\[X(jt)\\leftrightarrow 2\\pi x(-w) \\]\n相关定理\n前面我们介绍过相关函数，有\n\\[R_{12}(t) = x_1(t)*x_2(-t) \\]\n\\[R_{21}(t) = x_2(t)*x_1(-t) \\]\n\\[R(t) = x(t)*x(-t) \\]\n我们有\n\\[R_{12}(t)\\leftrightarrow X_1(jw)X_2^*(jw) \\]\n\\[R_{21}(t)\\leftrightarrow X_2(jw)X_1^*(jw) \\]\n\\[R(\\tau)\\leftrightarrow |X(jw)|^2 \\]\n基本傅立叶变换对 \\[\\sum^{+\\infty}_{k=-\\infty}a_k e^{jkw_0t}\\leftrightarrow 2\\pi\\sum^{+\\infty}_{k=-\\infty}a_k\\delta(w-kw_0) \\]\n\\[e^{jkw_0t}\\leftrightarrow 2\\pi\\delta(w-kw_0) \\]\n\\[cos(w_0t)\\leftrightarrow\\pi[\\delta(w-w_0)+\\delta(w+w_0)] \\]\n\\[sin(w_0t)\\leftrightarrow \\dfrac{\\pi}{j}[\\delta(w-w_0)-\\delta(w+w_0)] \\]\n\\[x(t)=1\\leftrightarrow 2\\pi\\delta(w) \\]\n\\[g_\\tau(t)\\leftrightarrow \\tau Sa(\\dfrac{w\\tau}{2}) \\]\n\\[sgn(t)\\leftrightarrow \\dfrac{2}{jw} \\]\n\\[\\delta(t)\\leftrightarrow 1 \\]\n\\[\\delta^{(n)}\\leftrightarrow(jw)^n \\]\n\\[u(t)\\leftrightarrow\\dfrac{1}{jw}+\\pi\\delta(w) \\]\n\\[e^{-\\alpha t}\\varepsilon(t)\\leftrightarrow\\dfrac{1}{\\alpha+jw},\\alpha\u003e0 \\]\n\\[e^{-\\alpha |t|}\\leftrightarrow\\dfrac{2\\alpha}{\\alpha^2+w^2},\\alpha\u003e0 \\]\n其中\n\\(sgn(t)\\)是符号函数，\\(Sa(\\theta)=sin\\theta/\\theta\\)，\\(g_\\tau(t)\\)代表门函数，即在\\([-\\tau/2,\\tau/2]\\)的范围内取\\(1\\)，其他范围内取\\(0\\)。\n阶跃函数此时可以表示为\\(\\varepsilon(t) = \\dfrac{1}{2}[1+sgn(t)]\\)\n线性常系数微分方程表征的系统 线性常系数微分方程有如下形式\n\\[\\sum^N_{k=0}a_k\\dfrac{d^k y(t)}{dt^k} = \\sum^m_{k=0}b_k\\dfrac{d^k x(t)}{dt^k} \\]\n我们可以像之前一样用经典方法去解输入对应的输出（零状态响应）。但是我们也可以使用频率响应来求出。\n如果我们有\\(x(t)=e^{jwt}\\)，则系统的输入就是\\(y(t)=H(jw)e^{jwt}\\)。\n一个事实是，\\(H(jw)\\leftrightarrow h(t)\\)。我们之前还说过，\\(y(t)=h(t)*x(t)\\)，我们就可以得到\\(Y(jw)=H(jw)X(jw)\\)。\n或者我们有\n\\[H(jw) = \\dfrac{Y(jw)}{X(jw)} = \\dfrac{\\sum^M_{k=0}b_k(jw)^k}{\\sum^{N}_{k=0}a_k(jw)^k} \\]\n其中第二个等号后面的式子可以把微分方程的两边全部取傅立叶变换，再提项得到。\n有了\\(H(jw)\\)，我们就容易求出对于任意一个输入信号\\(f(t)\\)，这个系统的零状态响应。\n要么我们可以\\(Y(jw)=H(jw)F(jw)\\)再傅立叶逆变换得到\\(y(t)\\)，要么\\(y(t)=H(jw)f(t)\\)。\n\\(H(jw)\\)一般是复函数，记为\n\\[H(jw)=|H(jw)|e^{j\\theta(w)} \\]\n其中\\(|H(jw)|\\)称为幅频特性或者幅频响应，是\\(w\\)的偶函数。\n\\(\\theta(w)\\)称为相频特性或相频响应，是\\(w\\)的奇函数。\n当然，我们可以直接在微分方程转变为\\(Y(jw)=aX(jw)\\)（\\(a\\)是某个系数）后，直接将两边傅立叶逆变换得到\\(y(t)\\)而不用先得到\\(H(jw)\\) 。\n再次提醒，傅里叶变换只能求零状态响应。想要求出零输入响应和全响应，用后面介绍的拉普拉斯变换。\n傅立叶变换与电路 虽然书上没说，但我觉得电阻、电容、电感也可以有傅立叶变换的模型。但是这样就无法求初始值了，还是用拉普拉斯变换吧，见后。\n帕塞瓦尔能量方程 \\[E = \\lim_{T\\to\\infty}\\int^T_{-T}|f(t)|^2dt = \\int^\\infty_{-\\infty}|f(t)|^2dt = \\dfrac{1}{2\\pi}\\int^\\infty_{-\\infty}|F(jw)|^2dw \\]\n能量频谱 \\[\\mathcal{E}(w) = |F(jw)|^2 \\]\n根据前面的相关定理，我们可以得到\n\\[R(\\tau)\\leftrightarrow \\mathcal{E}(w) \\]\n即能量信号的自相关函数与其能量谱是一对傅里叶变换。\n频带宽度 在满足一定失真条件下，信号可以用某段频率范围的信号来表示，此频率范围称为频带宽度。\n信号频谱的距离原点最近的两个零点之间集中了信号的绝大部分能量。信号的功率集中在低频段。\n一般把第一个零点作为信号的频带宽度 对于一般周期信号，将幅度下降为\\(\\dfrac{1}{10}|F_n|_{\\text{max}}\\)的频率定义为频带宽度 系统的通频带\\(\u003e\\)信号的带宽，才能不失真。 无失真传输 信号无失真传输是指系统的输出信号与输入信号相比，只有幅度的大小和出现时间的先后不同，而没有波形上的变化。\n其条件为\n对于系统的\\(h(t)\\)，\\(h(t)=K\\delta(t-t_d)\\)\n或者对于系统的\\(H(jw)=Ke^{-jwt_d}\\)\n功率频谱 \\[P = \\lim_{T\\to\\infty}\\dfrac{1}{T}\\int_T f^2(t)dt = \\dfrac{1}{2\\pi}\\int^\\infty_{-\\infty}\\lim_{T\\to\\infty}\\dfrac{|F_T(jw)|^2}{T}dw \\]\n记\n\\[\\mathcal{P}(w) = \\lim_{T\\to\\infty}\\dfrac{|F_T(jw)|^2}{T} \\]\n也可以证明\n\\[R(\\tau)\\leftrightarrow\\mathcal{P}(w) \\]\n即功率信号的自相关函数与其功率谱是一对傅里叶变换。\n物理可实现条件 一个系统要在物理上可以实现，要求\n时域特性\n\\(h(t)=0,t\u003c0\\)，也就是要求是因果系统。响应不应出现在激励之前。\n频域特性\n\\[\\int ^{+\\infty}_{-\\infty} |H(jw)^2|dw\u003c\\infty\\quad \\text{and}\\quad \\int ^{+\\infty}_{-\\infty} \\dfrac{|\\ln |H(jw)||}{1+w^2}dw\u003c\\infty \\]\n这称为佩利-维纳准则，这是一个必要条件。\n对于物理可实现系统,可以允许\\(H(jw)\\)特性在某些不连续的频率点上为\\(0\\)，但不允许在一个有限频带内为\\(0\\)。\n佩利-维纳准则要求可实现的幅度特性其总的衰减不能过于迅速；\n离散时间傅里叶变换 信号与系统的时域和频域特性 采样 冲激串采样 周期冲激串\\(p(t)\\)称为采样函数，周期\\(T\\)称为采样周期，而\\(p(t)\\)的基波频率\\(w_s=2\\pi/T\\)称为，采样频率。\n在时域中有\n\\[x_p(t) = x(t)p(t) \\]\n其中\n\\[p(t) = \\sum^{+\\infty}_{n=-\\infty}\\delta(t-nT) \\]\n经过计算可以得到，频域中有\n\\[X_p(jw) = \\dfrac{1}{T}\\sum^{+\\infty}_{k=-\\infty}X(j(w-kw_s)) \\]\n采样定理 设\\(x(t)\\)是某一个带限信号，在\\(|w|\u003ew_M\\)时，\\(X(jw)=0\\)。如果采样频率\\(w_s\u003e2w_M\\)，其中\\(w_s=2\\pi /T\\)，那么\\(x(t)\\)就唯一地由其样本\\(x(nT),n=0,\\pm1,\\pm2,\\cdots\\)所确定\n在采样定理中，采样频率必须大于\\(2w_M\\)，该频率\\(2w_M\\)一般称为奈奎斯特速率。\n已知样本值，重建\\(x(t)\\)的方法：产生一个周期冲激串，其冲激幅度就是这些依次而来的样本值；然后将该冲激串通过一个增益为\\(T\\)，截止频率\\(w_c\\)大于\\(w_M\\)而小于\\(w_s-w_M\\)的理想低通滤波器，该滤波器的输出就是\\(x(t)\\)。\n这个滤波器的\\(h(t)\\)为\n\\[h(t) = T_s\\dfrac{w_c}{\\pi}Sa(w_ct) \\]\n其中\\(w_M\u003c w_c\u003c w_s-w_M\\)，方便起见常取\\(w_c=0.5w_s\\)\n此时\n\\[x(t) = \\sum^{+\\infty}_{n=-\\infty}x(nT_s)Sa[\\dfrac{w_s}{2}(t-nT_s)] \\]\n注意，你可能会奇怪式子里面的\\(T_s\\dfrac{w_c}{\\pi}\\)到哪里去了，实际上当\\(w_c=0.5w_s\\)时，因为\\(w_s=\\dfrac{2\\pi}{T_s}\\)，这个式子约分为\\(0\\)\n奈奎斯特速率的运算性质 假设\\(f(t)\\)的最高频率为\\(w_M\\)\n\\(f(at)\\)，则对应\\(w_M'=|a|w_M,w_s=2w'_M\\)\n\\(f_1(t)+f_2(t)\\)，则对应\\(w'_M=\\max{\\{w_{m1},w_{m2}\\}}\\)\n\\(f_1(t)\\ast f_2(t)\\)，则对应\\(w'_M=\\min{\\{w_{m1},w_{m2}\\}}\\)\n\\(f_1(t)f_2(t)\\)，则对应\\(w'_M=w_{m1}+w_{m2}\\)\n频率采样定理 一个在时域区间\\((-t_m,t_m)\\)以外为\\(0\\)的时限信号\\(f(t)\\)的频谱函数，可唯一地由其在均匀频率间隔\\(f_s\\)上的样值点\\(F(jnw_s)\\)确定。要求\\(f_s\u003c1/(2t_m)\\)，或者说\\(w_s\u003c2\\pi/(2t_m)\\)\n\\[F(jw) = \\sum^{+\\infty}_{n=-\\infty} F(j\\dfrac{n\\pi}{t_m})Sa(wt_m-n\\pi) \\]\n拉普拉斯变换 一个信号\\(x(t)\\)的拉普拉斯变换定义如下\n\\[X(s) = \\int^{+\\infty}_{-\\infty}x(t)e^{-st}dt \\]\n当然，傅立叶变换就是\\(s=jw\\)时的一个特例。\n复变量\\(s\\)可以写为\\(s=\\sigma+jw\\)，其中\\(\\sigma,w\\)分别是它的实部和虚部。方便起见\\(X(s)=\\mathcal{L}\\{x(t)\\}\\)，或者记作\n\\[x(t)\\overset{\\mathcal{L}}{\\longleftrightarrow} X(t) \\]\n因为\n\\[X(\\sigma+jw) = \\int^{+\\infty}_{-\\infty}x(t)e^{-(\\sigma+jw)t}dt = \\int^{+\\infty}_{-\\infty}[x(t)e^{-\\sigma t}]e^{-jwt}dt \\]\n所以\\(x(t)\\)的拉普拉斯变换可以看成\\(x(t)\\)乘以一个实指数信号以后的傅立叶变换。\n当然，正如傅立叶变换不是对所有信号都收敛，拉普拉斯变换对有些\\(Re\\{s\\}\\)收敛，而有些不收敛。\n拉普拉斯变换的有理分式情况 如果拉普拉斯变换具有以下形式\n\\[X(s) = \\dfrac{N(s)}{D(s)} \\]\n使得\\(N(s)=0\\)的\\(s\\)称为零点，使得\\(D(s)=0\\)的\\(s\\)称为极点。把这些点标记在复平面上。我们可以判断收敛域。极点用叉号表示，零点用圈圈表示。\n也可以通过零-极点图来反过来求拉普拉斯变换，这时你需要设\\(X(s)=\\dfrac{KN(s)}{D(s)}\\)，保留一个常系数\\(K\\)。然后根据题目的已知条件解出\\(K\\)。\n拉普拉斯变换的收敛域 收敛域记作\\(ROC\\)\n\\(X(s)\\)的收敛域在\\(s\\)平面内是由平行于\\(jw\\)轴的带状区域组成的。 对有理拉普拉斯变换来说，收敛域内不包括任何极点。 如果\\(x(t)\\)是有限持续期的，并且是绝对可积的，那么收敛域就是整个\\(s\\)平面。 如果\\(x(t)\\)是右边信号，并且\\(Re\\{s\\}=\\sigma_0\\)这条线位于收敛域内，那么\\(Re\\{s\\}\u003e\\sigma_0\\)的全部\\(s\\)值一定在收敛域内 如果\\(x(t)\\)是左边信号，并且\\(Re\\{s\\}=\\sigma_0\\)这条线位于收敛域内，那么\\(Re\\{s\\}\u003c\\sigma_0\\)的全部\\(s\\)值一定在收敛域内 如果\\(x(t)\\)是双边信号，并且\\(Re\\{s\\}=\\sigma_0\\)这条线位于收敛域内，那么收敛域就一定由\\(s\\)平面的一条带状区域组成，直线\\(Re\\{s\\}=\\sigma_0\\)位于该区域中。 如果\\(x(t)\\)的拉普拉斯变换\\(X(s)\\)是有理的，那么它的收敛域是被极点所界定的或延伸到无限远。另外，在收敛域内不包含任何极点。 如果\\(x(t)\\)的拉普拉斯变换\\(X(s)\\)是有理的，若\\(x(t)\\)是右边信号，那么收敛域在\\(s\\)平面上位于最右边极点的右边；若\\(x(t)\\)是左边信号，那么收敛域在\\(s\\)平面上位于最左边极点的左边 拉普拉斯逆变换 \\[x(t) = \\dfrac{1}{2\\pi j}\\int^{\\sigma+j\\infty}_{\\sigma-j\\infty}X(s)e^{st}dt \\]\n显然不太可能用这玩意去算，大部分时候我们都用后面的常用变换对来算。\n如果\\(X(s)\\)是一个有理分式，则我们要做的就是将他拆开，为此我们可以使用待定系数法。\n例如\n\\[X(s) = \\dfrac{1}{x^2(x-1)} \\]\n我们就要拆成\n\\[X(s)=\\dfrac{a}{x}+\\dfrac{b}{x^2}+\\dfrac{c}{x-1} \\]\n然后根据系数关系求得待定系数的值。注意，这里\\(x^{-2}\\)要拆成两项，一项是\\(x^{-1}\\)，一项是\\(x^{-2}\\)，其他情况以此类推。\n（双边）拉普拉斯变换的性质 假设\\(x_1(t)\\leftrightarrow X_1(s),ROC=R_1\\)和\\(x_2(t)\\leftrightarrow X_2(s),ROC=R_2\\)\n线性\n\\[ax_1(t)+bx_2(t)\\leftrightarrow aX_1(s)+bX_2(s), ROC至少是R_1\\cap R_2 \\]\n时移\n\\[x(t-t_0)\\leftrightarrow e^{-st_0}X(s), ROC=R \\]\n\\(s\\)域平移\n\\[e^{s_0t}x(t)\\leftrightarrow X(s-s_0),ROC=R的平移 \\]\n时域尺度变换\n\\[x(at)\\leftrightarrow \\dfrac{1}{|a|}X(\\dfrac{s}{a}),ROC=R/a \\]\n共轭\n\\[x^*(t) \\leftrightarrow X^*(s^*), ROC=R \\]\n卷积\n\\[x_1(t)*x_2(t)\\leftrightarrow X_1(s)X_2(s), ROC至少是R_1\\cap R_2 \\]\n乘积\n\\[x_1(t)x_2(t)\\leftrightarrow \\dfrac{1}{2\\pi j}\\int^{c+j\\infty}_{c-j\\infty}X_1(\\eta)X_2(s-\\eta)d\\eta \\]\n设\\(R_1\\)为\\(Re\\{s\\}\u003e\\sigma_1\\)，\\(R_2\\)为\\(Re\\{s\\}\u003e\\sigma_2\\)，则\\(R\\)为\\(Re\\{s\\} \u003e \\sigma_1+\\sigma_2,\\sigma_1 \u003c c \u003c Re\\{s\\}-\\sigma_2\\)\n这里\\(c\\)是\\(X_1(\\eta)\\)与\\(X_2(\\eta)\\)收敛域重叠部分内与虚轴平行的直线。这里对积分路线的限制较严，积分计算也比较复杂，所以很少用该定理。\n时域微分\n\\[\\dfrac{d}{dt}x(t)\\leftrightarrow sX(s), ROC至少是R \\]\n\\(s\\)域微分\n\\[-tx(t)\\leftrightarrow \\dfrac{d}{ds}X(s), R \\]\n\\[(-t)^nx(t)\\leftrightarrow \\dfrac{d^n}{ds^n}X(s), R \\]\n\\(s\\)域积分\n\\[\\dfrac{x(t)}{t}\\leftrightarrow \\int^{+\\infty}_{s}X(\\eta)d\\eta \\]\n时域积分\n\\[\\int^t_{-\\infty}x(\\tau)d\\tau\\leftrightarrow\\dfrac{1}{s}X(s), ROC至少是R\\cap\\{Re{s}\u003e0\\} \\]\n初值定理和终值定理\n若\\(t\u003c0\\)时\\(x(t)=0\\)且在\\(t=0\\)不包括任何冲激或高阶奇异函数，则\n\\[x(0^+)=\\lim_{s\\to\\infty} sX(s) \\]\n\\[\\lim_{t\\to\\infty}x(t) = \\lim_{s\\to 0}sX(s) \\]\n常用拉普拉斯变换对 \\[\\delta(t)\\leftrightarrow 1, s\\in C \\]\n\\[\\varepsilon(t)\\leftrightarrow\\dfrac{1}{s},Re\\{s\\}\u003e0 \\]\n\\[-\\varepsilon(-t)\\leftrightarrow \\dfrac{1}{s},Re\\{s\\}\u003c0 \\]\n\\[\\dfrac{t^{n-1}}{(n-1)!}\\varepsilon(t)\\leftrightarrow\\dfrac{1}{s^n},Re\\{s\\}\u003e0 \\]\n\\[-\\dfrac{t^{n-1}}{(n-1)!}\\varepsilon(-t)\\leftrightarrow\\dfrac{1}{s^n},Re\\{s\\}\u003c0 \\]\n\\[e^{-at}\\varepsilon(t)\\leftrightarrow\\dfrac{1}{s+a},Re\\{s\\}\u003e-a \\]\n\\[-e^{-at}\\varepsilon(-t)\\leftrightarrow\\dfrac{1}{s+a},Re\\{s\\}\u003c-a \\]\n\\[\\dfrac{t^{n-1}}{(n-1)!}e^{-at}\\varepsilon(t)\\leftrightarrow\\dfrac{1}{(s+a)^n},Re\\{s\\}\u003e-a \\]\n\\[-\\dfrac{t^{n-1}}{(n-1)!}e^{-at}\\varepsilon(-t)\\leftrightarrow\\dfrac{1}{(s+a)^n},Re\\{s\\}\u003c-a \\]\n\\[\\delta(t-T)\\leftrightarrow e^{-sT}, s\\in C \\]\n\\[\\cos(w_0t)\\varepsilon(t)\\leftrightarrow \\dfrac{s}{s^2+w_0^2}, Re\\{s\\}\u003e0 \\]\n\\[\\sin(w_0t)\\varepsilon(t)\\leftrightarrow \\dfrac{w_0}{s^2+w_0^2}, Re\\{s\\}\u003e0 \\]\n\\[e^{-at}\\cos(w_0t)\\varepsilon(t)\\leftrightarrow \\dfrac{s+a}{(s+a)^2+w_0^2}, Re\\{s\\}\u003e-a \\]\n\\[e^{-at}\\sin(w_0t)\\varepsilon(t)\\leftrightarrow \\dfrac{w_0}{(s+a)^2+w_0^2}, Re\\{s\\}\u003e-a \\]\n\\[\\dfrac{d^n}{dt^n}\\delta(t)\\leftrightarrow s^n, s\\in C \\]\n\\[t\\varepsilon(t)\\leftrightarrow \\dfrac{1}{s^2}, Re\\{s\\}\u003e0 \\]\n\\[t^n\\varepsilon(t)\\leftrightarrow \\dfrac{n!}{s^{n+1}}, Re\\{s\\}\u003e0 \\]\n\\[\\varepsilon(t)*\\cdots*\\varepsilon(t)\\leftrightarrow\\dfrac{1}{s^n}, Re\\{s\\}\u003e0 \\]\n周期函数\n设\\(f(t)\\)是周期为\\(T\\)的周期函数，则其一个周期的拉普拉斯变换为\n\\[f_T(t)\\leftrightarrow \\dfrac{F(s)}{1-e^{-sT}} \\]\n用拉普拉斯变换分析与表征线性时不变系统 一个线性时不变系统的输入和输出的拉普拉斯变换由该系统的单位冲激响应的拉普拉斯变换联系起来，和傅里叶变换一样\n\\[Y(s) = H(s)X(s) \\]\n若一个线性是不变系统的输入是\\(x(t)=e^{st}\\)，则输出一定是。\\(H(s)e^{st}\\)，即\\(e^{st}\\)是系统的一个特征函数，其特征值就等于单位冲激响应的拉普拉斯变换。\n在拉普拉斯变换的范畴内，称\\(H(s)\\)为系统函数或传递函数。\\(s=jw\\)时\\(H(s)\\)称为系统的频率响应。\n因果性 一个因果系统的系统函数的收敛域是某个右半平面。\n对于一个具有有理系统函数的系统来说，系统的因果性就等效于收敛域位于最右边极点的右边的右半平面。\n反因果信号则为左半平面。\n稳定性 当且仅当系统函数\\(H(s)\\)的收敛域包括\\(jw\\)轴时，一个线性时不变系统是稳定的。\n当且仅当\\(H(s)\\)的全部极点都位于\\(s\\)平面的左半平面时，一个具有有理\\(H(s)\\)的因果系统才是稳定的。\n反因果系统需要极点都在右半平面。\n由线性常系数微分方程表征的线性时不变系统 和用傅立叶变换求解微分方程一样，我们这里换成了两边求拉普拉斯变换。\n注意，如果有初始值，那么需要用后面的单边拉普拉斯变换中的微分和积分性质。不能用之前的双边性质。\n微分方程为\n\\[\\sum^N_{k=0}a_k\\dfrac{d^k y(t)}{dt^k}= \\sum^M_{k=0}b_k\\dfrac{d^k x(t)}{dt^k} \\]\n两边同时应用拉普拉斯变换（初始值为零，即零输入响应为零，假设在\\(t=0\\)时接入\\(x(t)\\)），得\n\\[\\bigg(\\sum^N_{k=0}a_ks^k\\bigg)Y(s)= \\bigg(\\sum^M_{k=0}b_ks^k\\bigg)X(s) \\]\n如果初始值不为零，则全响应为\n\\[\\bigg(\\sum^N_{k=0}a_ks^k\\bigg)Y(s)-\\sum^N_{k=0}a_k\\bigg[\\sum^{k-1}_{p=0}s^{k-1-p}y^{(p)}(0^-)\\bigg]= \\bigg(\\sum^M_{k=0}b_ks^k\\bigg)X(s) \\]\n之后我们可以算出\n\\[H(s) = \\dfrac{Y(s)}{X(s)} \\]\n注意冲激响应是冲激函数的零状态响应。\n然后我们就可以用\\(H(s)\\)去求任意输入的零状态响应，\\(Y(s)=H(s)X(s)\\)，再拉普拉斯逆变换换到\\(s\\)域上。\n或者，我们不求\\(H(s)\\)。\n\\[Y_{zs}(s) = \\bigg(\\sum^M_{k=0}b_ks^k\\bigg)X(s)\\bigg/\\bigg(\\sum^N_{k=0}a_ks^k\\bigg) \\]\n如果有零输入响应，那么\n\\[Y_{zi} = \\sum^N_{k=0}a_k\\bigg[\\sum^{k-1}_{p=0}s^{k-1-p}y^{(p)}(0^-)\\bigg]\\bigg/\\bigg(\\sum^N_{k=0}a_ks^k\\bigg) \\]\n全响应就是两个相加，之后要求\\(s\\)域上的则逆变换即可。\n相比之下，傅立叶变换只能求零状态而不能求零输入。\n系统的\\(s\\)域框图 不做细致介绍。\n电路的\\(s\\)域模型 电阻\n\\[u(t) = Ri(t)\\leftrightarrow U(s) = RI(s) \\]\n变换后仍然是电阻。\n电感\n\\[u(t) = L\\dfrac{di(t)}{dt}\\leftrightarrow U(s) = sLI(s)-Li(0^-) \\]\n变换后变成了一个大小为\\(sL\\)的电阻，和一个电压大小为\\(Li(0^-)\\)的电压源，方向：\\(i\\)从电压源的负极流进，正极流出。也可以等效为电流源。\n电容\n\\[i(t) = C\\dfrac{du(t)}{dt}\\leftrightarrow U(s)=\\dfrac{1}{sC}I(s)+\\dfrac{u(0^-)}{s} \\]\n变换后变成了一个大小为\\(1/(sC)\\)的电阻，和一个电压大小为\\(u(0^-)/s\\)的电压源，方向：\\(i\\)从电压源的正极流进，负极流出。也可以等效为电流源。\n电源\n\\[u_s(t),i_s(t)\\leftrightarrow U_s(s),I_s(s) \\]\nKCL和KVL\n节点\n\\[\\sum_k i_k(t) = 0\\leftrightarrow\\sum_k I_k(s)=0 \\]\n回路\n\\[\\sum_k u_k(t) = 0\\leftrightarrow\\sum_k U_k(s)=0 \\]\n用了这些变换后，得到的新电路，就可以只用算电阻，不用算难算的电容和电感关系，解出来所需要的量之后，再逆变换得到\\(t\\)上的式子即可。\n单边拉普拉斯变换及其性质 一个连续时间信号\\(x(t)\\)的单边拉普拉斯变换\\(X(s)\\)定义为\n\\[X(s)=\\int^\\infty_{0^-}x(t) e^{-st}dt \\]\n积分下限取\\(0^-\\)，来表示积分区间内包括了集中于\\(t=0\\)的任何冲激或高阶奇异函数。\n\\[x(t)\\overset{\\mathcal{UL}}{\\longleftrightarrow}X(s) = \\mathcal{UL}\\{x(t)\\} \\]\n如果两个信号在\\(t\u003c0\\)时不同，而在\\(t\\geq0\\)时相同，则具有不同的双边变换，相同的单边变换。任何在\\(t\u003c0\\)时都为零的信号，双边和单边变换相同。\n单边变换就是将信号在\\(t\u003c0\\)时将它置零而求得的双边变换。\n性质\n不列出收敛域，任何单边拉普拉斯变换的收敛域总是某右半平面。\n线性，\\(s\\)域平移，时域尺度变换，\\(s\\)域微分，初值终值定理\n和双边的一样。\n时移\n和双边的不同，这里没有这个性质。\n共轭\n\\[x^*(t)\\leftrightarrow X^*(s) \\]\n与双边不同的是\\(s\\)没有取共轭（其实我有点怀疑是否是书的错误，因为后面的\\(z\\)变换又是单边双边相同的，有点出乎我的意料。但是我不知道是这个错了还是那个错了）\n卷积\n特别要求\\(t\u003c0\\)时，\\(x_1(t),x_2(t)\\)都为零。\n时域微分\n\\[x'(t)\\leftrightarrow sX(s)-x(0^-) \\]\n\\[x''(t)\\leftrightarrow s^2X(s)-sx(0^-)-x'(0^-) \\]\n\\[x^{(n)}(t)\\leftrightarrow s^nX(s)-\\sum^{n-1}_{m=0}s^{n-1-m}x^{(m)}(0^-) \\]\n并且特别给出，当\\(x(t)\\)是因果信号时，\\(x^{(n)}(t)\\leftrightarrow s^nX(s)\\)。\n时域积分\n初始条件为零（松弛）时\n\\[\\bigg(\\int^t_{0^-}\\bigg)^nx(\\tau)d\\tau\\leftrightarrow \\dfrac{1}{s^n}X(s) \\]\n在初始条件不是松弛的情况下，以下公式对于求微分方程的解非常好用。\n\\[x^{(-1)}(t)=\\int^t_{-\\infty}x(\\tau)d\\tau \\leftrightarrow s^{-1}X(s) +s^{-1}x^{(-1)}(0^-) \\]\n\\(z\\)变换 一个离散时间信号\\(x[n]\\)的\\(z\\)变换定义为\n\\[X(z) = \\sum^{+\\infty}_{n=-\\infty} x[n]z^{-n} \\]\n其中\\(z\\)是一个复变量。我们也记作\n\\[x[n]\\overset{z}{\\longleftrightarrow}X(z)=\\mathcal{Z}\\{x[n]\\} \\]\n当然，离散傅里叶变换就是\\(z=e^{jw}\\)时的一个特例。我们现在将\\(z\\)表示为\\(z=re^{jw}\\)，用\\(r\\)表示\\(z\\)的模，用\\(w\\)表示它的相角。于是就可以把\\(X(re^{jw})\\)看成序列\\(x[n]\\)乘以实指数\\(r^{-n}\\)后的傅里叶变换，即\n\\[X(re^{jw}) = \\mathcal{F}\\{x[n]r^{-n}\\} \\]\n类似于在虚轴\\(jw\\)上的拉普拉斯变换就是傅里叶变换，在复平面的单位圆上进行的\\(z\\)变换，就是傅里叶变换。\n\\(z\\)变换的有理分式情况 和拉普拉斯变换一样。同时也有极点和零点的概念。记住，求零点极点时，分子分母的\\(z\\)不要出现负幂项，全部转成正幂项再来求。\n\\(z\\)变换的收敛域 收敛域记作\\(ROC\\)\n\\(X(z)\\)的收敛域是在\\(z\\)平面内以原点为中心的圆环 收敛域内不包括任何极点 如果\\(x[n]\\)是有限长序列，那么收敛域就是整个\\(z\\)平面，可能除去\\(z=0\\)和/或\\(z=\\infty\\) 如果\\(x[n]\\)是一个右边序列，并且\\(|z|=r_0\\)的圆位于收敛域内，那么\\(|z|\u003er_0\\)的全部有限\\(z\\)值都一定在这个收敛域内 如果\\(x[n]\\)是一个左边序列，而且\\(|z|=r_0\\)的圆位于收敛域内，那么满足\\(0\u003c|z|\u003c r_0\\)的全部\\(z\\)值都一定在这个收敛域内 如果\\(x[n]\\)是一个双边序列，而且\\(|z|=r_0\\)的圆位于收敛域内，那么该收敛域在\\(z\\)域中一定是包含\\(|z|=r_0\\)这一圆环的环状区域 如果\\(x[n]\\)的\\(z\\)变换\\(X(z)\\)是有理的，它的收敛域就被极点所界定，或延伸至无限远 如果\\(x[n]\\)的\\(z\\)变换\\(X(z)\\)是有理的，并且\\(x[n]\\)是右边序列，那么收敛域就位于\\(z\\)平面内最外层的极点的外边，也就是半径等于\\(X(z)\\)极点中最大模值的圆的外边。而且，若\\(x[n]\\)是因果序列，即\\(x[n]\\)为\\(n\u003c0\\)时等于零的右边序列，那么收敛域也包括\\(z=\\infty\\) 如果\\(x[n]\\)的\\(z\\)变换\\(X(z)\\)是有理的，并且\\(x[n]\\)是左边序列，那么收敛域就位于\\(z\\)平面内最外层的极点的里边，也就是半径等于\\(X(z)\\)中除去\\(z=0\\)的极点中最小模值的圆的里边，并且向内延伸到可能包括\\(z=0\\)。特别是，若\\(x[n]\\)是反因果序列，即\\(x[n]\\)为\\(n\u003e0\\)时等于零的左边序列，那么收敛域也包括\\(z=0\\) \\(z\\)逆变换 \\[x[n] = \\dfrac{1}{2\\pi j}\\oint X(z)z^{n-1}dz \\]\n和拉普拉斯逆变换一样，很难直接用这个东西去算。遇上有理分式就待定系数法拆开，遇上其他函数就分开来看，然后套用常用\\(z\\)变换表和其性质来算。\n当然，你可能会发现拆出来的项是\\(\\dfrac{1}{z-1}\\)这种形式的，然后就会发现变换表里的不是\\(z\\)而是\\(z^{-1}\\)。这种情况应该对\\(\\dfrac{X(z)}{z}\\)进行因式分解，得到结果后两边同乘\\(z\\)，然后再转换一下就可以使用变换表了。\n（双边）\\(z\\)变换的性质 假设\\(x_1[n]\\leftrightarrow X_1(z),ROC=R_1\\)和\\(x_2[n]\\leftrightarrow X_2(z),ROC=R_2\\)\n线性\n\\[ax_1[n]+bx_2[n]\\leftrightarrow aX_1(z)+bX_2(z) \\]\n时移\n\\[x[n-n_0]\\leftrightarrow z^{-n_0}X(z), ROC=R \\]\n\\(z\\)域尺度变换\n\\[e^{jw_0n}x[n]\\leftrightarrow X(e^{-jw_0}z),ROC=R \\]\n\\[z_0^nx[n]\\leftrightarrow X(\\dfrac{z}{z_0}),ROC=z_0R \\]\n\\[a^nx[n]\\leftrightarrow X(a^{-1}z),ROC=R的尺度变换 \\]\n时间翻转\n\\[x[-n]\\leftrightarrow X(z^{-1}),ROC=R^{-1} \\]\n时间扩展\n\\[x_{(k)}[n] = \\left\\{\\begin{matrix} x[r], \u0026 n=rk\\\\ 0, \u0026 n\\neq rk \\end{matrix}\\right.\\leftrightarrow X(z^k),ROC = R^{1/k} \\]\n共轭\n\\[x^*[n] \\leftrightarrow X^*[z^*], ROC=R \\]\n卷积\n\\[x_1[n]*x_2[n]\\leftrightarrow X_1(z)X_2(z), ROC至少是R_1\\cap R_2 \\]\n一次差分\n\\[x[n]-x[n-1]\\leftrightarrow (1-z^{-1})X(z),ROC至少是R\\cap|z|\u003e0 \\]\n累加\n\\[\\sum^n_{k=-\\infty}x[k]\\leftrightarrow \\dfrac{1}{1-z^{-1}}X(z),ROC至少是R\\cap|z|\u003e1 \\]\n\\(z\\)域微分\n\\[nx[n]\\leftrightarrow -z\\dfrac{d}{dz}X(z), ROC=R \\]\n\\(z\\)域积分\n\\[\\dfrac{x[n]}{n+m}\\leftrightarrow z^m\\int^{\\infty}_{z}\\dfrac{X(\\eta)}{\\eta^{m+1}}d\\eta,ROC=R \\]\n初值定理和终值定理\n若\\(n\u003c0\\)时,\\(x[n]=0\\)则\n\\[x[0]=\\lim_{z\\to\\infty} X(z) \\]\n若\\(n","date":"2023-04-05T20:24:29+08:00","image":"https://kegalas.top/p/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/cover_hu1925d5b7c7f8a1062326c6e2b8e7c8b0_29169_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"信号与系统学习笔记"},{"content":"简称表 简称 含义 CPU 中央处理器 PC 程序计数器 IR 指令寄存器 CU 控制单元 ALU 算术逻辑单元 ACC 累加器 MQ 乘商寄存器 X 操作数寄存器 MAR 存储器地址寄存器 MDR 存储器数据寄存器 MM 主寄存器 I/O 输入输出设备 简称 含义 SATA 串行ATA总线 PCI 外围设备互联 DMA 直接存储器访问 DMI 直接媒体接口 QPI 快速通道互联 FSB 前端总线 PCH 平台控制中心 IOH 输入/输出中心 ICH 控制器集线器 MCH 内存控制器集线器 NVRAM 非易失型随机存储器 SCSI 小型计算机系统接口 简称 含义 RAM 随机存储器 ROM 只读存储器 SRAM 静态随机读写存储器 DRAM 动态随机读写存储器 DDR SDRAM 双倍数据率同步DRAM MROM 掩模ROM PROM 可一次编程ROM EPROM 可擦除的PROM EEPROM 电可擦除的EPROM EAROM 电改写ROM SIMM 单列直插式存储器模块 DIMM 双列直插式存储器模块 FIFO 先进先出算法 LRU 近期最少使用算法 TLB 转换后援缓冲器，快表 计算机的性能描述 机器字长 指CPU一次能处理的数据位数\n存储容量 存储容量=存储单元个数×存储字长。其中MAR反应存储单元个数，MDR反应存储字长。\n运行速度 主频/时钟周期 主频与时钟周期二者互为倒数\nCPI 执行一条指令（平均）需要的时钟周期数\n\\[CPI = \\dfrac{\\text{所有指令的时钟周期之和}}{\\text{指令总数}}\\\\ = \\sum(\\text{各类指令的CPI}\\times \\text{该类指令的比例}) \\]\nMIPS 每秒钟CPU能执行的指令总条数（百万条/秒）\n\\[MIPS = \\dfrac{\\text{指令条数}}{\\text{执行时间}\\times 10^6} \\]\n\\[= \\dfrac{\\text{指令条数}}{\\left(\\dfrac{\\text{所有指令CPU时钟周期数之和}}{f}\\right)\\times 10^6}\\\\ \\]\n\\[= \\dfrac{f}{\\text{CPI}\\times 10^6} \\]\n其中最后一个公式又称为全性能公式\nAmdahl定律 加速比\n\\[\\text{加速比} = \\dfrac{\\text{改进后的系统性能}}{\\text{改进前的系统性能}}\\\\ \\]\n\\[= \\dfrac{\\text{改进前的系统执行时间}}{\\text{改进后的系统执行时间}} \\]\n可改进比例\\(f_e\\)\n可改进部分在原系统执行时间中所占的比例\n部件加速比\\(r_e\\)\n可改进部分改进后性能提高的程度\nAmdahl定律\n假设改进前的系统执行时间为\\(T_0\\)，改进后的系统执行时间为\\(T_n\\)，则\n\\[T_n = T_0\\bigg(1-f_e+\\dfrac{f_e}{r_e}\\bigg) \\]\n若加速比用\\(S_p\\)表示，则有\n\\[S_p = \\dfrac{1}{1-f_e+\\dfrac{f_e}{r_e}} \\]\n有多个部件同时可以改进时\n\\[S_p = \\dfrac{1}{(1-\\sum f_e)+\\sum(\\dfrac{f_e}{r_e})} \\]\n总线和IO 分类 按照总线的传输方式不同（定时），可以分为同步总线和异步总线； 按照总线中数据线的多少不同（传送信息），可以分为并行总线和串行总线。 按照总线的使用方式不同，可以分为专用总线和公用总线。 按照连接部件不同，可分为片内总线、系统总线、通信总线 按照系统总线传输信息的不同，又可分为数据总线、地址总线、控制总线 总线带宽 \\[\\text{总线带宽} = \\text{数据线宽度}\\times \\text{总线频率} \\]\n总线结构 可以分为单总线和多总线结构。\n总线控制 中断 存储系统 主存 技术指标 存储容量\n\\[\\text{存储容量}=\\text{存储单元个数}\\times\\text{存储字长} \\]\n上式的单位是位，如果用字节需要除以8。\n存储器带宽\n\\[B_m = \\dfrac{n}{t_m} \\]\n其中\\(n\\)为每次读出/写入的字节数，\\(t_m\\)为存储周期\n半导体存储芯片的译码驱动方式 DRAM的刷新 存储器芯片的扩展 Cache Cache的命中率 在一个程序执行期间，设\\(N_c\\)为访问Cache的总命中次数，\\(N_m\\)为访问主存的总次数，则命中率\\(h\\)（hit rate）为\n\\[h = \\dfrac{N_c}{N_c+N_m} \\]\n设\\(t_c\\)为命中时的Cache访问时间，\\(t_m\\)为未命中时的主存访问时间，通常\\(t_m \u003e\u003e tc\\) ，\\(1-h\\)表示未命中率（缺失率，miss rate）\n当Cache和主存同时访问时，Cache-主存系统的平均访问时间\\(ta\\)为：\n\\[t_a = ht_c + (1-h)t_m \\]\n当Cache和主存不同时访问时，Cache-主存系统的平均访问时间\\(ta\\)为（我们一般考虑同时访问的情况）：\n\\[t_a = ht_c+(1-h)(t_m+t_c) = t_c+(1-h)t_m \\]\nCache-主存系统的效率 \\[e = \\dfrac{t_c}{t_a} = \\dfrac{\\text{访问Cache的时间}}{\\text{平均访问时间}}\\times 100\\% \\]\n\\[= \\dfrac{t_c}{t_c+(1-h)\\times t_m}\\times 100\\% \\]\nCache-主存系统的加速比 \\[S_p = \\dfrac{t_m}{t_a} = \\dfrac{t_m}{t_c+(1-h)\\times t_m} = \\dfrac{1}{1-h+\\dfrac{1}{r}} \\]\n其中，\\(r=t_m/t_c\\)为从主存到Cache速度提升的倍数。\nCache-主存系统的成本 假设计算机中的主存与Cache的容量分别为\\(S_1\\)和\\(S_2\\),显然\\(S_1 \u003e\u003e S_2\\)；\n主存与Cache的单位价格分别为\\(C_1\\)和\\(C_2\\)，且\\(C_1\\)是价格较低的。\n那么Cache—主存系统的平均价格\\(C\\)为\n\\[C = \\dfrac{C_1\\times S_1+C_2\\times S_2}{S_1+S_2} \\]\nCache的映射 替换算法 多级Cache 虚拟存储器 外部存储器 磁盘 非格式化容量\n\\[\\text{非格式化容量} = \\text{位密度}\\times\\dfrac{\\text{内圈磁道周长}+\\text{外圈磁道周长}}{2}\\times\\text{每盘面磁道数}\\times\\text{盘面数} \\]\n格式化容量\n\\[\\text{格式化容量} = \\text{每扇区字节数}\\times\\text{每道扇区数}\\times\\text{每盘面磁道数}\\times\\text{盘面数} \\]\n平均存取时间\n\\[\\text{平均存取时间} = \\text{平均寻道时间}+\\text{平均等待时间}+\\text{传输时间} \\]\n数据传输率\n\\[\\text{数据传输率} = \\text{每个扇区的字节数}\\times\\text{每道扇区数}\\times\\text{磁盘的转速} \\]\n数据表示 带符号的定点小数 其一般形式为\n\\[X_s.X_{-1}X_{-2}\\cdots X_{-(n-1)} \\]\n其中第一位是符号位，后面的每一位都在小数点后，也就是说定点小数一定是纯小数，不含整数部分。\n原码、反码、补码、移码 原码转换为另外三个码的规则\n原码符号 反码 补码 移码 正 相同 相同 符号位改为1 负 除符号位外取反 反码+1 符号位与补码相反 假设不含符号位有\\(n\\)位，则原码和反码的范围为\\(-2^{n}+1\\sim 2^{n}-1\\)，补码和移码的范围为\\(-2^{n}\\sim 2^{n}-1\\)\n以上是定点整数的转换方法，定点小数的转换方法相同，数据范围不同\n假设不含符号位有\\(n\\)位，则原码和反码的范围为\\(-(1-2^n)\\sim 1-2^n\\)，补码和移码的范围为\\(-1\\sim 1-2^n\\)\n浮点数 浮点数\\(N\\)由三部分来决定，阶码\\(E\\)，尾数\\(M\\)和阶码的底\\(B\\)\n\\[N = B^E\\cdot M \\]\n阶码的底\\(B\\)一般隐含表示，取决于机器本身。阶码是定点整数，尾数是定点小数。\n非规格化浮点数 非规格化浮点数不要求定点小数的第一位是1.其数据范围如下，假设尾数部分\\(n+1\\)位，阶码部分\\(k+1\\)位，均用补码表示\n阶码最小值 \\(-2^k\\) 阶码最大值 \\(2^k-1\\) 尾数最小负值 \\(-1\\) 尾数最大负值 \\(-2^{-n}\\) 尾数最小正值 \\(2^{-n}\\) 尾数最大正值 \\(1-2^{-n}\\) 可表示的最小负数 \\(-1\\times 2^{2^k-1}\\) 可表示的最大负数 \\(-2^{-n}\\times 2^{-2^k}\\) 可表示的最小正数 \\(2^{-n}\\times 2^{-2^k}\\) 可表示的最大正数 \\((1-2^{-n})\\times 2^{2^k-1}\\) 规格化浮点数 要求定点小数的第一位是1.在用补码表示时，符号位和第一位如果不同，则为规格化浮点数。\n阶码最小值 \\(-2^k\\) 阶码最大值 \\(2^k-1\\) 尾数最小负值 \\(-1\\) 尾数最大负值 \\(-(1/2+2^{-n})\\) 尾数最小正值 \\(+1/2\\) 尾数最大正值 \\(1-2^{-n}\\) 可表示的最小负数 \\(-1\\times 2^{2^k-1}\\) 可表示的最大负数 \\(-(1/2+2^{-n})\\times 2^{-2^k}\\) 可表示的最小正数 \\(1/2\\times 2^{-2^k}\\) 可表示的最大正数 \\((1-2^{-n})\\times 2^{2^k-1}\\) IEEE754标准浮点数 以单精度为例，单精度有32位长，最高位(\\(S\\))是浮点数的符号位，接下来8位是指数(\\(E\\))，最后23位是尾数(\\(F\\))。\n其表示为\n\\[(-1)^S\\times (1+F)\\times 2^{(E-Bias)} \\]\n其中，尾数本来应该为1.xxxxx，但是我们将第一位暗含了，所以式子中为\\(1+F\\)，那23位尾数只包含小数点后面的数。这个尾数永远为正，不需要考虑补码等问题，符号由符号位提供。\n而\\(Bias\\)提供了一种类似于移码的方式来表示正负，在单精度中，Bias为\\(127\\)，也就是说，如果我们要表示\\(2^6\\)，则\\(E = 6+127 = 133\\)，而133才是会被记录在那8位尾数中的数字。\n单精度表示对象表如下\n指数 尾数 表示对象 0 0 0 0 非0 \\(\\pm\\)非规格化数 1-254 任意 \\(\\pm\\)浮点数 255 0 \\(\\pm\\)无穷 255 非0 NaN 其中浮点数的表示范围为\\(\\pm[1,2)\\times 2^{[-126,127]}\\)\n双精度浮点数的Bias为1023。\nASCII码 汉字编码 \\[\\text{国标码} = (\\text{区位码})_{16} + 2020H \\]\n\\[\\text{机内码} = (\\text{国标码})_{16} + 8080H \\]\n\\[\\text{机内码} = (\\text{区位码})_{16} + A0A0H \\]\nUnicode与UTF-8 检错与纠错码 校验码的码距 \\[d_{min} \\geq t+e+1, 且e\\geq t \\]\n其中\\(d_{min}\\)为编码码距，\\(t\\)为可纠错的位数，\\(e\\)为可检错的位数\n\\(d_{min}\\geq 2\\)的数据校验码具有检错的能力\n奇偶校验 海明码 设信息码为\\(n\\)位，欲检测\\(1\\)位错误，增添\\(k\\)位校验位，组成\\(m=n+k\\)位的校验码，应满足\n\\[2^k\\geq n+k+1 \\]\nCRC码 运算方法与运算器 机器数的逻辑运算 按位与、或、非、异或等等。\n机器数的移位运算 算术移位 正数的原码、补码、反码，左移右移都补0.\n负数的原码左右都补0；补码右补1，左移补0；反码左右都补1.\n运算的结果\\(p+q\\)位，保留前\\(p\\)位，常见的舍入方法有：\n恒舍（切断）。实现简单，误差大。 冯诺依曼舍入法，又称恒置1法，把保留部分\\(p\\)位的最低位置1.实现简单，平均误差接近0，应用较多。 下舍上入法，即0舍1入。用\\(q\\)位的最高位作为标志。如果为0，则全部舍去；如果为1，则在保留的\\(p\\)位的最低位上加1. 查表舍入法，或ROM舍入法。每次经查表来读得相应的处理结果。表的设计通常是当尾数最低\\(k-1\\)位全1时用截断法，其余用舍入法。实现速度快，虽然增加了硬件，但是整体性能最佳。 逻辑移位 把所有码都看成无符号码，左移右移都添加0，多出来的位直接舍弃。\n循环移位 1.jpg\r一位全加器 输入\\(X_i,Y_i,C_i\\)，表示两个加数和一个进位。\n输出\\(Z_i,C_{i+1}\\)，表示结果和进位。\n\\[Z_i = X_i\\oplus Y_i\\oplus C_i \\]\n\\[C_{i+1} = (X_i\\cdot Y_i)+(X_i+ Y_i)\\cdot C_i \\]\n若果令\\(G_i = X_i\\cdot Y_i, P_i = X_i+ Y_i\\)，则\\(C_{i+1}=G_i+P_i\\cdot C_i\\)\n当然\\(P_i=X_i\\oplus Y_i\\)其实是等效的，有些地方会这么写。\n\\(G_i\\)为进位产生函数：若本位两个输入均为\\(1\\)，必向高位产生进位，与低位进位无关。\n\\(P_i\\)为进位传递函数：当\\(P_i =1\\)时，若低位有进位，本位将产生进位。\nn位加减法器 串行（行波）进位的并行加减法器 \\(n\\)个全加器串接起来，就可以进行两个\\(n\\)位数的相加减。进位信号是逐级形成的。\n并行加法器的快速进位 并行进位（先行进位、同时进位、CLA）方式 即把\\(C_{i+2}\\)用\\(C_{i+1}\\)表示，把\\(C_{i+3}\\)用\\(C_{i+2}\\)表示，以此类推，然后从一开始就得到进位信息。\n分组并行进位 单级先行进位，即，组内并行，组间串行。因为全部都并行电路很复杂，所以采用这个方法。\n多级先行进位，即组内并行，组间并行。\nALU电路 既能完成算术运算又能完成逻辑运算的部件。\n定点数加减运算 补码 两个数连同符号位一起相加，符号位产生的进位丢掉。减法则是把右边的加数变成相反数的补码再来相加。得到的结果也是补码。\n符号扩展 将采用给定位数表示的数转换成具有更多位数的某种表示形式。\n对于补码，正数用0填充，负数用1填充。\n溢出判断 有两种情况，一种是正溢，即两个正数相加。一种是负溢，即两个负数相加。\n采用符号位判断。如果正数相加符号位变成1了，那么正溢。如果负数相加符号位变成0了，那么负溢。 采用进位法。如果正数相加，最高有效位产生进位而符号位不产生进位，那么正溢。如果负数相加最高有效位不产生进位，而符号位产生进位，那么负溢。 采用变形补码（双符号位补码，模4补码）。计算方法相同，都是相加然后进位。如果符号位为00，则为正数；11则为负数，01则为正溢，10则为负溢。 标志信息 零标志ZF=1表示结果为0，不论有符号还是无符号都有意义。\n符号SF表示结果的符号，即最高位。对于无符号数没有意义。\nCF表示无符号加减运算时的借进位。加法时CF=1表示溢出，减法时CF=1表示借位。对于有符号数没有意义。\n溢出表示OF=1表示有符号数的运算结果发生了溢出。对于无符号数没有意义。\nBCD加法器 对于一位数，加出来的结果如果大于9，则加6进位。\n移码加减运算 两个移码直接相加 将结果的符号取反 定点数乘法运算 乘法用加法和移位实现，参照手算竖式乘法。\n原码乘法，略。\n部分积这个概念可能会考。\n补码乘法——校正法 计算x*y\n当y\u0026gt;0时，不管被乘数x的正负都直接按原码乘法计算，只是移位时按补码规则进行。\ny\u0026lt;0时，可以先把[y]补的符号位丢掉不管，仍按原码乘法运算，最后再加上[-x]补进行校正。\n综上，表达式为\n\\[=[X]_补\\cdot 0.y_1y_2\\cdots y_n + [-X]_补\\cdot y_0 \\]\n补码乘法——比较法（Booth法） 我们可以证明，\\([-X]_补=-[X]_补\\)，布斯法从这里入手。\n\\[[X\\cdot Y]_补 = [X]_补\\cdot(-y_0\\cdot 2^0+y_1\\cdot 2^{-1}+y_2\\cdot 2^{-2}+\\cdots+y_n\\cdot 2^{-n}) \\]\n\\[= [X]_补\\cdot[-y_0\\cdot 2^0+(y_1\\cdot 2^{0}-y_1\\cdot 2^{-1})+(y_2\\cdot 2^{-1}-y_2\\cdot 2^{-2})+\\cdots+(y_n\\cdot 2^{-(n-1)}-y_n\\cdot 2^{-n})] \\]\n\\[= [X]_补\\cdot[(y_1-y_0)\\cdot 2^0+(y_2-y_1)\\cdot 2^{-1}+\\cdots+(y_n-y_{n-1})\\cdot 2^{-(n-1)}+(y_{n+1}-y_n)\\cdot 2^{-n}] \\]\n其中\\(y_{n+1}=0\\)，写出来只是方便起见。\n于是我们可以方便的递推\n\\[[z_0]_补 = 0 \\]\n\\[[z_1]_补 = 2^{-1}\\{(y_{n+1}-y_n)[x]_补+[z_0]_补\\} \\]\n\\[\\vdots \\]\n\\[[z_n]_补=2^{-1}\\{(y_2-y_1)[x]_补+[z_{n-1}]_补\\} \\]\n\\[[x\\cdot y]_补 = [z_n]_补+(y_1-y_0)[x]_补 \\]\n阵列乘法器 原码和补码的乘法算法，利用加法和移位进行，属于串行乘法，它是一行行地来实现竖式乘法的。而阵列乘法器，通过电路实现了整个竖式乘法，速度快。\n定点数除法运算 类似的，除法是用减法和移位实现。\n原码除法分为恢复余数法和加减交替法\n恢复余数法是直接作减法试探方法，不管被除数（或余数）减除数是否够减，都一律先做减法。 若余数为正，表示够减，该位商上“1”；若余数为负，表示不够减，该位商上“0”，并要恢复原来的被除数（或余数）。\n加减交替法 符号位不参与运算；上商 n+1 次；第一次上商判溢出；左移 n 次，加 n+1 或n+2次；用移位的次数判断除法是否结束；若最终余数为负，需恢复余数。\n补码除法：补码除法共上商 n +1 次（末位恒置 1）第一次为商符；第一次商可判溢出；加 n+1 次 左移 n 次；用移位的次数判断除法是否结束；精度误差最大为\\(2^{-n}\\)\n浮点数加减运算 步骤如下\n使两个数的小数点位置对齐 将尾数按定点加减运算计算 将尾数计算结果重新规格化 尾数在规格化后进行舍入 判断是否溢出 浮点数乘除运算 步骤如下\n阶码采用补码（对于IEEE754则不是补码，总之是定点加减）定点加减运算 尾数乘除同定点运算 规格化 舍入 溢出判断 运算器的组成和结构 指令系统 存储模式 大端存储（大部分RISC），小端存储（Intel/AMD）\n堆栈（Stack）：具有先进后出(FILO)操作规则的被特殊定义的主存区域。\n使用堆栈时用三个专用地址寄存器来管理\n堆栈指针（Stack Pointer，SP）：指示当前可操作的堆栈单元。 堆栈基址（Stack Base，SB）：指示堆栈的底部。 堆栈界限（Stack Limit，SL）：指示堆栈的最顶端 堆栈界限\\(=\\)堆栈基址\\(\\pm\\)堆栈大小。\n寄存器组织 寄存器按功能可以分为通用寄存器和专用寄存器。按可操作性分为可见与不可见寄存器。\n典型寄存器有地址寄存器(AR)、数据寄存器(DR)、指令寄存器(IR)、程序计数器(PC)、堆栈指针寄存器(SP)、标志寄存器(FR)等。\n指令格式 为了使指令能够有效地指挥计算机完成各种操作，一条指令应包含两个基本要素：操作码和地址码，其基本格式为：操作码字段+地址码字段。\n指令功能不同，需要的操作数数量也不同。地址码字段为指令指定源操作数、目的操作数和下条指令地址等信息，格式为：源操作数+目的操作数+下条指令地址。\n按照地址码字段的数量，指令可以分为四地址、三地址、两地址、单地址和零地址指令。\n四地址指令：op,rd, rs1, rs2,ni; rs1 op rs2-\u0026gt;rd, ni提供顺序或转移地址\n三地址指令：op,rd,rs1,rs2 rs1 op rs2-\u0026gt;rd, PC提供顺序地址\n二地址指令：op,rd,rs1 rd op rs1-\u0026gt;rd或rs1 op ACC-\u0026gt;rd, PC提供顺序地址\n单地址指令：op rd rd op ACC -\u0026gt; ACC或rd自身操作-\u0026gt;rd, PC提供顺序地址；或rd提供转移地址。ACC为累加器或操作码隐含指定的操作数。\n零地址指令：op 由操作码指定操作数（隐含寻址）或无需操作数。\n定长操作码 对所有指令的操作码用相同位数的二进制数进行编码，即为定长操作码编码方式。\n某计算机的指令系统需要设置\\(N\\)条指令，若所有指令的操作码均用\\(n\\)位二进制数表示，则应满足关系式：\n\\[N\\leq 2^n \\]\n从\\(2^n\\)个编码中选出\\(N\\)个编码分配给\\(N\\)条指令，即可完成操作码设计。\n变长操作码 对不同类型的指令操作码用不固定长度的二进制数进行编码即为变长操作码或扩展操作码编码方式。\n扩展操作码技术是指令优化技术，其技术核心是：\n使程序中指令的平均操作码长度尽可能短，以减少操作码在程序中的总位数； 尽可能充分地利用指令的二进制数位，以增加指令字表示的操作信息。 扩展操作码的设计原则：\n如果指令字长固定，则长地址码对应短操作码，操作码长度随地址码长度缩短而增加。 如果指令字长可变，则以指令的使用频率作为设计依据，频率高的用短操作码，长的用长操作码。用到了霍夫曼编码。 设计总是从短操作码开始，并且保证短码不能是长码的前缀。 寻址 隐含寻址：操作数的存放地由操作码指定。 立即寻址：操作数在指令中。 寄存器寻址：操作数在指令指定的寄存器中。 直接寻址：操作数地址在指令中，操作数在主存单元中，访问一次主存便可获得操作数。 （存储器）间接寻址：操作数地址的地址在指令中，操作数在主存单元中。 寄存器间接寻址：操作数地址在指令指定的寄存器中，操作数在主存单元中，访问一次主存即可获得操作数。 相对寻址：操作数地址由程序计数器和指令提供的地址偏移量决定，操作数在主存单元中，访问一次主存即可获得操作数。 基址寻址：操作数地址由基址寄存器和指令提供的地址偏移量决定，操作数在主存单元中,访问一次主存即可获得操作数。 变址寻址：操作数地址由变址寄存器和指令提供的地址偏移量决定，操作数在主存单元中。 堆栈寻址：该寻址方式通常由指令操作码指定，用在涉及堆栈操作的指令中，所寻址的操作数在堆栈中。 中央处理器 CPU的功能和结构 CPU的功能 CPU主要由控制器+运算器+寄存器组构成。\nCPU具有以下四方面功能\n指令控制 操作控制 时间控制 数据加工 CPU的主要功能是执行存储在主存中的指令序列,也即执行程序，具体操作如下:\n取得指令：cpu从主存中取指令，存在指令寄存器中 执行指令 确定下条指令的地址：可能是顺序地址，或者分支跳转地址 重复1~3，直到执行完毕 其中，控制器CU的功能为：从存储器中取指令、对指令译码、产生控制信号并控制计算机系统各部件有序地执行，从而实现这条指令的功能。\n控制器组成为：PC，IR，AR，DR，指令译码器，操作控制信号形成部件，时序信号产生器。\n指令周期 CPU执行一条指令所用的时间即为指令周期，在指令周期内CPU完成一组操作。\n一个周期分为三个子周期：取指令子周期、执行指令子周期（分为取数子周期、执行子周期、存数字周期）、中断子周期。\n2.jpg\r微操作 概念\n在CISC系统中，指令周期内的CPU行为常常被分解为一系列微操作\\((\\mu op)\\)\n微操作是CPU可以进行的基本或原子操作。它是CPU可实现的、不可分解的操作。以含有一个寄存器传递（移进、移出）操作为标志。\n每一个微操作是通过控制器将控制信号发送到相关部件上引起部件动作而完成的。\n这些控制微操作完成的控制信号称为微命令。 微命令是由控制器产生的。 流程\n时序信号\nCPU执行微操作有严格的时间顺序性，这种时间关系是由计算机的时序系统来控制的。CPU执行微操作序列中的时序信号：\n指令周期：执行一条指令所用的时间 CPU周期：完成一个子周期所用的时间 节拍周期：完成一个微操作所用的时间 通常利用时序电路为控制器提供所需的时序信号。\n节拍周期 最基本的时序信号为节拍，它可由顺序脉冲发生器（也称脉冲分配器或节拍脉冲发生器）产生。\n节拍周期\\(T\\)：完成各种CPU微操作所需时间的最大者，常作为定义CPU时钟周期\\(T_{clk}\\)或时钟频率\\(f_{clk}\\)的依据。\n\\[T = (1\\sim n)\\times T_{clk} = (1\\sim n)/f_{clk} \\]\n节拍脉冲发生器分为两类：计数型=计数器+译码器；移位型=移位寄存器+译码器。\nCPU周期（机器周期） 完成一个子周期所用的时间。一般指CPU与内存交换一次信息所需要的时间。若干个节拍组成一个CPU周期。\nCPU周期可以设计为定长 CPU周期与不定长CPU周期两种。\n指令周期 执行一条指令所用的时间。若干个CPU周期组成一个指令周期，指令周期也可以设计为定长指令周期与不定长指令周期两种。\n取指令与中断子周期微操作流程\n当一条指令在该系统上执行时，可以被看作是一组微操作的执行。\n每条指令对应的一组微操作，称为该指令的微操作流程或微操作序列。\n取指令周期 一个简单的取指令周期可由3个节拍、4个微操作组成\nT1: AR\u0026lt;-PC //PC的内容传送到AR T2: DR\u0026lt;-Memory[AR], Mread //读取主存到DR PC\u0026lt;-PC+I //PC自增到下一条指令，其中I为指令长度 T3: IR\u0026lt;-DR //DR的内容传送到IR 组合微操作：\nT1: AR\u0026lt;-PC T2: DR\u0026lt;-Memory[AR], Mread T3: PC\u0026lt;-PC+I IR\u0026lt;-DR 组合微操作的规则：遵守操作发生的顺序、必须避免冲突\n所有指令的取指令操作相同，故取指令周期称为公操作。\n中断周期 在执行周期结束时有一个检测，用来确定被允许的中断是否已出现，若是，中断周期产生。\n中断周期也是公操作。\n中断周期微操作序列举例：\nT1: DR\u0026lt;-PC //将PC的内容传到DR保护 T2: AR\u0026lt;-Save_Address //中断断点信息保护区的存储单元地址传送到AR PC\u0026lt;-Routine_Address //中断服务程序首地址送入PC T3: Memory[AR]\u0026lt;-DR, Mwrite //将老PC的内容保存于主存（如堆栈）中 执行周期 MOV R1, R0 实现将寄存器R0的内容传送至寄存器R1中。\nT1: R1\u0026lt;-R0 MOV R0, X 实现将存储单元X中的内容传送至寄存器R0中。\nT1: AR\u0026lt;-IR //IR = X T2: DR\u0026lt;-Memory[AR], Mread T3: R0\u0026lt;-DR MOV (R1), R0 将寄存器R0的内容传送至由寄存器R1间接寻址的存储单元中。\nT1: AR\u0026lt;-R1 T2: DR\u0026lt;-R0 T3: Memory[AR]\u0026lt;-DR, Mwrite ADD R1, R0 将寄存器R0的内容与寄存器R1的内容相加并将结果存入R1。\nT1: Y\u0026lt;-R0 T2: Z\u0026lt;-R1+Y T3: R1\u0026lt;-Z SUB R0, (X) 实现寄存器R0中的被减数减去存储器地址X间接寻址的存储单元中的减数、将差值传送至寄存器R0中。\nT1: AR\u0026lt;-IR //IR = X T2: DR\u0026lt;-Memory[AR], Mread T3: AR\u0026lt;-DR T4: DR\u0026lt;-Memory[AR], Mread T5: Y\u0026lt;-R0 T6: Z\u0026lt;-Y﹣DR T7: R0\u0026lt;-Z IN R0, P 从I/O地址为P的I/O设备(接口)中输入数据并存入寄存器R0中。\nT1: AR\u0026lt;-IR //IR = P T2: DR\u0026lt;-IO[AR], IOread T3: R0\u0026lt;-DR OUT P, R0 将寄存器R0中的数据输出到I/O地址为P的I/O设备(接口)中。\nT1: AR\u0026lt;-IR //IR = P T2: DR\u0026lt;-R0 T3: IO[AR]\u0026lt;-DR, IOwrite JUMP X 无条件跳转指令，实现将程序执行地址从当前跳转指令所在位置转移到存储器地址为X处。\nT1: PC\u0026lt;-IR JZ offs 采用相对寻址的条件跳转指令。当条件为真（即零标志ZF=1）时，程序发生跳转；条件为假（即零标志ZF=0）时，程序顺序执行下条指令。跳转地址=PC+offs，offs为带符号地址偏移量。\nIf(ZF==1) then { T1: Y\u0026lt;-IR T2: Z\u0026lt;-PC+Y T3: PC\u0026lt;-Z } PUSH R0 实现将寄存器R0中的数据压入到堆栈中。\nT1: SP\u0026lt;-SP-n // SP指向新栈顶，n为一次压栈的字节数 DR\u0026lt;-R0 T2: AR\u0026lt;-SP T3: Memory[AR]\u0026lt;-DR, Mwrite POP R0 实现将堆栈栈顶的数据弹出至寄存器R0中。\nT1: AR\u0026lt;-SP T2: DR\u0026lt;-Memory[AR], Mread T3: R0\u0026lt;-DR SP\u0026lt;-SP+n //将SP指向新栈顶，n为一次弹出的字节数 CALL(X) 子程序调用指令。将程序执行地址从当前调用指令所在位置转移到以存储器地址X间接寻址的存储单元处，并保存返回地址。\nT1：SP\u0026lt;-SP-n DR\u0026lt;-PC T2：AR\u0026lt;-SP T3：Memory[AR]\u0026lt;-DR, Mwrite T4：AR\u0026lt;-IR T5：DR\u0026lt;-Memory[AR], Mread T6：PC\u0026lt;-DR RET 子程序返回指令，实现从堆栈栈顶处获得子程序调用时保存的返回主程序的地址。\nT1: AR\u0026lt;-SP T2: DR\u0026lt;-Memory[AR], Mread T3: PC\u0026lt;-DR SP\u0026lt;-SP+n 控制器的组成 控制器应完成的任务：\n产生微命令（即控制信号） 按节拍产生微命令 在设计控制器前需要：\n定义计算机基本硬件组成和基本指令系统 基于定义的硬件结构，针对每条指令，描述CPU完成的微操作 确定控制单元应该完成的功能，即何时产生何种微命令 有两种方法：\n硬布线控制设计法 微程序控制或微码控制设计法 硬布线控制器设计 硬布线控制器设计法将控制单元看作一个顺序逻辑电路或有限状态机，它可以产生规定顺序的控制信号，这些信号与提供给控制单元的指令相对应。\n它的设计目标是：使用最少的元器件，达到最快的操作速度。\nRISC-V\n对于RISC-V，其为单周期实现。\n类x86\n对于类x86系统，其为多周期实现。有两种设计方法：\n采用一级时序，即只利用节拍信号。一条指令执行的全过程是用一个从取指令到执行指令的完整微操作序列来描述的，而且对这个微操作序列也是从头至尾分配节拍的。 采用两级时序，即利用节拍和CPU周期两种时间信号。按照CPU周期来描述一条指令的微操作序列。 我们要从微操作序列得出微命令序列。例如把AR\u0026lt;-PC转换为\\(PC_{out},AR_{in}\\)\n由控制单元产生并加载到CPU内外的全部控制信号均可用下述形式表述：\n两级时序：\n\\[C_i = \\sum(M_m\\cdot T_n\\cdot I_j\\cdot F_k) \\]\n在执行指令\\(I_j\\)时，若状态\\(F_k\\)满足要求，则在第\\(m\\)个CPU周期\\(M_m\\)的第\\(n\\)个节拍\\(T_n\\)，控制单元发出\\(C_i\\)控制命令。\n一级时序：\n\\[C_i = \\sum(T_n\\cdot I_j\\cdot F_k) \\]\n总结：\n每个控制信号的逻辑表达式就是一个与或逻辑方程式。 用一个与或逻辑电路就可以实现该控制信号的生成。 将所有控制信号的与或逻辑电路组合在一起就构成了硬布线控制单元。 时间信息（单周期实现不需要）、指令信息、状态信息是硬布线控制单元的输入，控制信号是硬布线控制单元的输出。 特点： 一旦完成设计，改变控制器的行为的唯一方法就是重新设计电路（修改不灵活） 在现代复杂处理器中，需要定义庞大的方程组（与或组合电路实现困难） 微程序控制器设计 用软件方法组织和控制数据处理系统的信息传送，并最终用硬件实现。依据微程序顺序产生一条指令执行时所需的全部控制信号。相当于把控制信号存储起来，因此又称存储控制逻辑方法。\n对在一个时间单位（节拍）内出现的一组微操作进行描述的语句称作微指令。\n一个微指令序列称作微程序或固件。\n通过一组微指令产生的控制信号，使一条指令中的所有微操作得以实现，从而实现一条指令的功能。\n一条（机器）指令对应一个微程序，该微程序包含从取指令到执行指令一个完整微操作序列对应的全部微指令，它被存入一个称为控制存储器的ROM中。\n微指令周期：一条微指令执行的时间（包括从控制存储器中取得微指令和执行微指令所用时间）。\n微指令格式 水平型微指令\n多个控制信号同时有效-\u0026gt;多个微操作同时发生\n3.jpg\r垂直型微指令\n类似于机器指令，利用微操作码的不同编码来表示不同的微操作功能。\n4.jpg\r微程序控制器的一般结构和工作原理 5.jpg\r微指令地址的生成 两地址格式 单地址格式 可变格式 微指令控制域编码 水平型微指令控制域的编码： 直接表示法 译码法 字段译码法 垂直型微指令控制域的编码 微程序设计及示例 微程序结构\n在设计微程序时，通常采用如下两种典型结构\n一条指令对应一段完整的微程序 将微程序中的公共部分设计成微子程序进行公共调用 编写微程序\nCPU性能测量与提高 CPU性能测量 CPU主频\\(f_{CLK}\\)：CPU使用的时钟的频率，单位为赫兹。\nCPU时钟周期\\(T_{CLK}\\)：时钟频率的倒数。\n一般而言，主频高代表速度快。\nCPU时间\n运行一个程序所花费的时间\n响应时间：CPU时间与等待时间（包括用于磁盘访问、存储器访问、I/O操作、操作系统开销等时间）的总和。\n假设时钟周期为\\(T_{CLK}\\)，执行某程序时，CPU需要使用\\(N\\)个时钟周期，那么，CPU执行该程序所用时间为\n\\[T_{CPU}=N\\times T_{CLK} = N/f_{CLK} \\]\nCPI与IPC\nCPI是每条指令执行所用的时钟数的平均值。\nIPC是每时钟周期执行的指令数。\n设某个程序要用\\(N\\)个时钟周期，该程序汇总的指令数为\\(I\\)，其CPI记为\\(CPI\\)，则\n\\[N = I\\times CPI \\]\n\\[T_{CPU} = I\\times CPI\\times T_{CLK} = \\dfrac{I\\times CPI}{f_{CLK}} \\]\n有三方面的因素使得程序的CPI可能不同于CPU执行的CPI：\nCache行为发生变化 指令混合发生变化 分支预测发生变化 影响CPU性能的三个关键因素：\nCPI 时钟频率 指令数 MIPS\nCPU每秒钟执行的百万指令数。\n\\[MIPS = \\dfrac{I}{T\\times 10^6} = \\dfrac{f_{CLK}}{CPI\\times 10^6} \\]\n其中\\(T\\)为程序的执行时间。\nMIPS的局限：\n不能对指令集不同的计算机使用MIPS进行比较：MIPS只说明了指令执行速率，而没有考虑指令的能力 计算机对所有程序没有单一的MIPS值：对于同一个计算机上的不同程序，MIPS是变化的 MIPS会与性能反向变化 Flops\nCPU每秒完成的浮点运算次数\n\\[FLOPS = \\dfrac{M}{T} \\]\n其中\\(M\\)为浮点运算次数，\\(T\\)为执行时间。\nFLOPS可以用于不同计算机之间的比较。\n就像MB，GB，TB。FLOPS也有MFLOPS，GFLOPS，PFLOPS等等\nCPU性能提高 采用更先进的硅加工制造技术 缩短指令执行路径长度。减少执行指令的时钟周期数：优化微操作、微程序；双总线、三总线；增加特定硬件，实现并行 简化组织结构来缩短时钟周期。例如RISC 采用并行处理技术。指令级和处理器级并行 多核与多线程技术 流水线技术 流水线处理的概念 流水线的处理方式 若将一重复的处理过程分解为若干子过程，每个子过程都可在专用设备构成的流水线功能段上实现，并可与其它子过程同时执行，这种技术称为流水技术。\n流水线的类型 按流水线位于计算机系统的层次划分\n系统级流水线/宏流水线：在多个系统中有多个处理机串行构成的流水线 处理器级流水线：在处理器内部由多个部件构成的流水线。——指令流水线 部件级流水线：在处理器中某部件内部由多个子部件构成的流水线。 按功能强弱划分\n单功能流水线 多功能流水线 按是否有反馈回路划分\n线性流水线 非线性流水线-流水线调度 按流水线输出端任务流出顺序与输入端任务流入顺序是否相同划分\n顺序流动流水线（入出顺序相同） 异步流动流水线（入出顺序不同） 按流水线一次处理对象的数量划分\n标量流水线 超标量流水线 向量流水线 超长指令字流水线 设计运算流水线的一般方法 寻找一个适当的、可分解为多步骤的、连续运行的算法，该算法的每一步骤应是时间均衡的、可以由硬件电路实现的。 将实现算法每一步骤的硬件电路作为流水线的一段，并按照步骤顺序将各段连接起来。 在流水线各段之间放置快速缓冲寄存器来分离各段，并利用缓冲寄存器逐段传送处理数据（部分或全部结果）。所有缓冲寄存器受同一时钟控制。 指令流水线 基本的指令流水线 指令流水线是利用执行指令时存在的直接并行性实现多条指令重叠执行的一种技术。\n指令流水线对于程序员是不可见的，它由程序编译器和CPU内部程序控制单元自动管理。\n如果流水线各段采用同步方式控制各段间信息的同步推进，则流水线同步控制时钟的周期应选定为\n\\[T_{CLK} = \\max_i\\{\\tau_i\\} \\]\n其中\\(\\tau_i\\)是该指令的运行时间。由于时钟周期取决于最长指令的运行时间，所以其他指令运行完后就要等待，造成浪费，速度减慢。所以要将指令的执行步骤再分解，使每一步骤所用时间尽可能均衡，并依此设计一个多级的指令流水线。\n例如，将指令处理分为以下四步\n指令获取（IF）：从主存或cache中获取指令并对指令进行译码 操作数加载（OL）：从主存或cache中获取操作数放入寄存器中 执行指令（EX）：利用ALU等执行部件，对寄存器中的操作数进行处理，结果存于寄存器中 写操作数（WO、OS）：将寄存器中的结果存入主存或cache中 指令流水线策略 采用深度指令流水线结构 将指令的执行过程进一步细化，使流水线的级（段）数变多，而每一级的工作更少（有可能一个时钟周期完成）、时间更均衡。\n多条流水线结构 流水线性能测量 时空图 装入时间=(流水线级数-1)\\(\\times\\)时钟周期\\(\\tau\\)；\\(\\tau=(1\\sim n)\\times T_{CLK}\\)\n吞吐率 吞吐率：指单位时间内流水线所完成的任务数或输出结果的数量，它是衡量流水线速度的重要指标。\n最大吞吐率\\(TP_{max}\\)：流水线在达到稳定状态后所得到的吞吐率。\n假设流水线各段运行时间相等，为\\(1\\)个时钟周期\\(T_{CLK}\\)，则：\n\\[TP_{max} = 1/T_{CLK} \\]\n假设流水线各段运行时间不等，第\\(i\\)段时间为\\(\\tau_i\\)，则：\n\\[TP_{max} = 1/\\max_i\\{\\tau_i\\} \\]\n所以瓶颈在于最慢的一段。消除瓶颈的办法有：\n细分瓶颈段（首选）（例如把他拆分成两个阶段） 重复设置瓶颈段（即物理上再增加一个一样的，和原来的并联） 实际吞吐率\n之前说的吞吐率是当待执行任务无限多时，取得的极限。若流水线由m段组成，完成n个任务的吞吐率称为实际吞吐率，记作\\(TP\\)。\n假设流水线各段运行时间相等，为\\(1\\)个时钟周期\\(T_{CLK}\\)，在不出现流水线断流的情况下，完成\\(n\\)个任务所用时间为\n\\[T_n(m) = (m+(n-1))\\tau = (m+(n-1))T_{CLK} \\]\n实际吞吐率为\n\\[TP = \\dfrac{n}{T_n(m)} = \\dfrac{n}{(m+(n-1))\\times T_{CLK}} = \\dfrac{TP_{max}}{1+\\dfrac{m-1}{n}} \\]\n假设流水线各段运行时间不等，第\\(i\\)段时间为\\(\\tau_i\\) ，则完成\\(n\\)个任务所用时间为\n\\[T_n(m) = \\sum^m_{i=1}\\tau_i + (n-1)\\times \\max_i\\{\\tau_i\\} \\]\n实际吞吐率为\n\\[TP = \\dfrac{n}{\\sum^m_{i=1}\\tau_i + (n-1)\\times \\max_i\\{\\tau_i\\}} \\]\n对于指令流水线而言，吞吐率TP就是每秒执行的指令数，所以也可以用MIPS指标表示吞吐率，即\n\\[TP = MIPS = f_{CLK}/CPI \\]\n对于单流水线系统，它的\\(CPI\\)是\\(1\\)，所以\\(TP_{max} = f_{CLK}\\)\n加速比 若流水线为\\(m\\)段，加速比\\(S\\)定义为等功能的非流水线执行时间\\(T(1)\\)与流水线执行时间\\(T(m)\\)之比，即\n\\[S = S_n(m) = T_n(1)/T_n(m) \\]\n若每段运行时间均为\\(\\tau\\)，在不流水情况下，总时间为\\(T_n(1)=nm\\tau\\)\n在流水但不出现断流的情况下，完成n个任务所需时间为\\(T_n(m)=m\\tau+(n-1)\\tau\\)，因此\n\\[S_n(m) = \\dfrac{mn}{m+n-1} = \\dfrac{m}{1+\\dfrac{m-1}{n}} \\]\n从上式可以看出，增大流水线的级数和送入流水线的指令数均可以加速流水线的运行速度。\n效率 效率：流水线中各功能段（或设备）的利用率。\n由于流水线有通过（填充）时间和排空时间，还有各种引起断流的状况，所以流水线的各段并非一直满负荷工作，效率\\(E\u003c1\\)。\n通常用流水线各段处于工作时间的时空区（面积）与流水线中各段总的时空区（面积）之比来衡量流水线的效率。\n\\[E = \\dfrac{n个任务占用的时空区}{m个段总的时空区} \\]\n假设流水线各段运行时间相等为\\(\\tau\\)，则整个流水线效率\\(e\\)为：\n\\[E = \\dfrac{mn\\tau}{m(m+n-1)\\tau} = \\dfrac{n}{m+n-1} = \\dfrac{1}{1+\\dfrac{m-1}{n}} \\]\n指令流水线的性能提高 流水线的基本性能问题 限制指令流水线性能提高的因素：\n流水线的深度受限于流水线的延迟、流水线段的时间不均衡和流水线的额外开销。 指令执行时可能存在的“相关”或“冒险”问题。 冒险：指相邻或相近的两条指令因存在某种关联，后一条指令不能在原指定的时钟周期开始执行。\n冒险分为三类：\n结构冒险：资源冲突 数据冒险：一条指令需要用到前面某条指令的结果 控制冒险：分支等转移类指令/其他能够改变PC值的指令 前两个是局部性相关，后一个是全局性相关\n结构冒险 有两种情况会导致结构冒险：\n部分功能单元没有充分流水\n解决办法：将流水线设计的更合理。\n资源冲突\n当两个以上流水线段需要同时使用同一个硬件资源时，发生冲突。\n解决办法：\n增加资源副本。如哈佛结构、两个ALU 改变资源以便它们能并发的使用。不相关的数据尽量使用不同的寄存器；寄存器重命名 通过延迟（或暂停）流水线的冲突段或在冲突段插入流水线气泡（气泡在流水线中只占资源不做实际操作），使各段“轮流”使用资源。 数据冒险 指令在流水线中重叠执行有可能改变指令读/写操作数的顺序\n当一条指令的结果还未有效生成，该结果就被作为后续指令的操作数时，数据冒险出现。\n解决办法：\n增加专用硬件（推后法）。增加流水线互锁（pipeline interlock）硬件。当互锁硬件发现数据相关时，使流水线工作停顿下来，直到冒险消失为止。 采用直通/转发技术 乱序，流水线（指令）调度：利用编译器（RISC），硬件（CISC）。编译器可以对指令重新排序或插入空操作指令 对寄存器读写做特别设计 控制冒险 使程序执行顺序发生改变的转移指令有两类：\n无条件转移指令（如无条件跳转、调用、返回指令等） 条件分支转移指令（为零跳转、循环控制指令等） 处理办法：\n冻结流水线 静态分支预测 动态分支预测 延迟分支 冒险影响性能 冒险可能引起流水线停顿, 停顿也称为流水线气泡。\n有停顿的流水线的CPI为：CPI = 理想流水线CPI+(结构冒险停顿 + 数据冒险停顿 + 控制冒险停顿) / 指令数\n有停顿的流水线的加速比为：\n\\[加速比=\\dfrac{流水线深度}{1+平均每条指令的流水线停顿周期} \\]\n多发射处理器 多发射(Multiple Issue)是在一个时钟周期内启动多个指令并行执行的处理器实现方案。\n实现多发射处理器主要有两种方法:\n静态多发射——编译时由编译器决定 动态多发射——执行过程中由处理器决定 指令级并行 ","date":"2023-03-29T16:00:26+08:00","image":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/cover_huaa3a4f4fef897a96376c721aafe499bc_261058_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"计算机组成原理学习笔记"},{"content":"原版快捷键 光标、页面移动相关 按键 功能 C-v 下一屏 M-v 上一屏 C-l 重绘屏幕，将光标至于中央、顶端、底端 C-p 方向键上 C-n 方向键下 C-b 方向键左 C-f 方向键右 M-f 这个词的末尾 M-b 这个词的开头 C-a 行首 C-e 行尾 M-a 这一句的开头 M-e 这一句的末尾 M-\u0026lt; 文件开头 M-\u0026gt; 文件末尾 C-M-v 在另一个window里下一屏 C-M-S-v 在另一个window里上一屏 M-g M-g 行号 跳转到某一行 文本操作 按键 功能 \u0026lt;DEL\u0026gt; 删除(delete)光标前的一个字符，windows上为Backspace C-d 删除光标后的一个字符 M-\u0026lt;DEL\u0026gt; 移除(kill)光标前的一个词 M-d 移除光标后的一个词 C-k 移除光标到行尾间的字符 M-k 移除光标到句尾间的字符 C-\u0026lt;SPC\u0026gt; 开始标记范围，从光标处开始，移动光标扩大选中范围 C-w 移除选中范围的字符，其实就是剪切 M-w 复制选中范围的字符 C-y 召回(yanking)被最近一次移除(kill)的字符 M-y 在C-y之后，紧接着使用，可以替换为召回再上一次被移除的字符，连续使用多次则替换为召回在上多次被移除的字符 C-/ 撤回，多次使用则撤回更以前的操作。如果使用C-g打断undo，则之后的C-/是重做 C-s 向下文搜索。再次按C-s则搜索下一个出现的位置。\u0026lt;Return\u0026gt;即回车将光标停在这个位置，结束搜索。C-g结束搜索并将光标还原到原来的位置 C-r 向上文搜索,其他类似 M-x replace-string 替换字符串 C-o 与回车不同的是，光标不会进入到下一行 C-x C-o 将光标前后的所有空白行变成一个空白行 C-x h 全选 文件相关 按键 功能 C-x C-f 寻找并打开一个文件，如果不存在，则新建这个文件 C-x C-s 保存文件 C-x C-r 以只读方式打开文件 C-x C-q 切换为只读模式 Buffer相关 按键 功能 C-x C-b 列出Buffer C-x b 缓冲区名 切换到这个缓冲区 C-x s 保存多个缓冲区 Window相关 按键 功能 C-x 0 关闭当前光标所在的window C-x 1 保留当前光标所在的window，关闭其他所有 C-x 2 将屏幕分为上下两个window C-x 3 将屏幕分为左右两个window C-x o 光标切换到另一个window C-x 4 以该命令为前缀时，表示在另外一个窗口做……例如C-x 4 f表示在另一个窗口打开新文件 其他 按键 功能 C-u 数字 其他命令 给其他命令传递一个数字，大部分都是重复次数 C-g 取消没输完的命令或者正在执行的命令 C-x 字符扩展，之后输入另一个字符或组合键 M-x 命令名扩展，之后输入一个命令名 C-x C-c 退出Emacs C-x C-= 放大字号 C-x C-- 减小字号 C-x C-0 默认字号 evil-mode快捷键 大部分都是从vim教程中整理来的，标注一些与emacs冲突的快捷键。\n光标、页面移动相关 按键 功能 j 向下 k 向上 h 向左 l 向右 w 移动到下一个单词开始。W,b,B,$等可通过motion表推出来 2w 往后移动两个单词，类似的33w是33个单词，33b等可以类推 C-o 在搜索后移动到之前的位置 C-i 相当于C-o的反向操作 % 当前光标是括号的话，光标移动到与该括号匹配的括号 C-f 下一屏 C-b 上一屏 行号-G 输入行号后按G，跳转到行号，也可以用:行号 行号-\u0026lt;RET\u0026gt; 输入行号后回车，跳转到n行后 切换模式 按键 功能 \u0026lt;ESC\u0026gt; 切换到命令模式（指从其他模式退出） i 输入模式（方框光标的字符前，竖线光标则为原地） a 输入模式（方框光标的字符后，竖线光标则为下一个字符） A 输入模式（光标在行尾） v 可视模式，跟emacs原版的C-\u0026lt;SPC\u0026gt;可以说是一样 o 在光标下新建一行并换到插入模式 O 在光标上新建一行并换到插入模式 motion motion有些类似原版emacs指令中，C-x后面加的那个东西。\nmotion 含义 w 从光标开始，到（本行）下一个单词的第一个字符前。标点符号会被识别为单独的单词 W 遇上一个不同的是，单词只会被空字符隔开，如果标点符号和字母连在一起会是一个单词 b 光标开始往左数，第一个单词的首字母，如果在单词中间使用会移动到该单词首字母 B 类似于W与w的区别 e 光标开始，到本单词的最后一个字符，竖线光标为字符前，方框光标则为该字符 E 类似于W与w的区别 $ 光标开始到行尾 g_ 光标开始到本行最后一个非空字符 0 光标之前到行首 ^ 光标之前到本行第一个非空字符 G 光标开始到文本最后一行第一个非空字符 gg 光标前到文本第一行第一个非空字符 文本相关 按键 功能 x 删除（也可理解为剪切）光标所在的字符（光标是方框时，如果光标是竖线则删除之后的一个字符） dw 删除光标开始，到下一个单词的第一个字符前。dW,db,dB,d$之类可以类推 d2w 删除两个单词，d33w则是删除33个，d33b可以类推 dd 删除一整行，2dd删除光标所在的和下一行，以此类推 u 撤销操作 U 撤销对改行的操作 C-r 重做操作（emacs不兼容，推荐用C-g打断后再用u撤销撤销） p 在方框光标后粘贴文本，可以是从外部剪贴板来的，也可以是之前操作删除的（可以理解为只有剪切操作而没有删除） y 复制v模式选中的文本 yw 复制一个词，其他类推 r 输入之后输入任意字符，把方框光标的字符替换为该字符 R 替换更多字符，有些类似其他文本编辑器按到了Insert cw 其实就只是dw操作完后直接进入插入模式，ce,cb等类推，c2w等也类推 /name 搜索name，完成后按回车。按n搜索下一个，N搜索上一个 ?name 反向搜索name，和/的操作逻辑正好相反 :s/old/new 将本行的第一个old替换为new :s/old/new/g 将本行的所有old替换为new :#,#s/old/new/g 将#,#这两个行号之间的所有行的old替换为new :%s/old/new/g 将全文的old替换为new :%s/old/new/gc 替换全文，但是会要求逐个确认 /name\\c 搜索时忽略大小写（暂时） :set ic 设置永久忽略大小写 :set noic 设置成永久不忽略大小写 文件相关 按键 功能 :w 保存文件（可以和q结合使用，见后） :w filename 另存为filename :\u0026rsquo;\u0026lt;,\u0026rsquo;\u0026gt;w filename 用v选中一些字符后，按:会自动出现\u0026rsquo;\u0026lt;,\u0026rsquo;\u0026gt;，输入w filename将选中的东西另存为 :r filename 将filename里的东西复制到光标后 :r !dir 将dir命令的输出复制到光标后 其他 按键 功能 :q 退出程序 :wq 保存并退出 :q! 未保存强制退出 :!command 执行外部命令，例如:!ls evil代替不了或者最好不要代替的原版按键 M-x\n由于安装了counsel，提供的命令列表不宜直接替换为:，因为这两个是不同的东西。虽然都是输入命令，但是:经常只会使用一些短小的命令，例如:dw，:wq。虽然:也能使用emacs里面的其他指令，例如package-install，但是却又没有补全。而M-x补全强大，但是根本无法使用:dw, :wq。综上不建议替代。不应当把counsel绑定到:上\nC-s\n由于安装了swiper，emacs的搜索快捷键被替换成了更强的插件，与/或者?相比也算是操作逻辑有不同，不应当把swiper绑定到/或者?上。\nC-x\n很多关于buffer，file，window的操作是emacs特有的，不应该换掉。好在原版vim也没有C-x这个快捷键。不过是否可以把切换window的操作绑定成vim的，TODO。\n另外注意，不应当把undo-tree绑定到u和C-r上，具体怎么做，TODO。\n\u0026lt;f1\u0026gt;~\u0026lt;f12\u0026gt;\n大部分也都是绑定的插件，没有必要替换。\nM-., M-?\n感觉可以替换成vim按键，TODO。\n自己设置的快捷键\n尝试找到vim的替代，TODO。\n自用插件 use-package 在init.el里自动安装其他插件的必备。通常可以用M-x package-install来手动安装use-package。\ngood-scroll 平滑滚动的插件。\nmwim 优化了原版的C-a和C-e快捷键，具体如下。\n按键 功能 C-a 跳到文字的开头或这一行的开头 C-e 跳到文字的结尾或一行的结尾 但是安装了evil后，我怀疑这个插件是否有必要，TODO。\nall-the-icons 提供emacs内许多图标的显示功能，需要在下载插件后M-x all-the-icons-install-font。或是去其github下载fonts安装后才能使用。\ncounsel、ivy、swiper 三个著名的插件，优化了诸多功能，如搜索、切换buffer、文件操作、命令列表等等。\n下面的命令可能会根据我使用的熟练程度来更新。\n按键 功能 C-s 使用swiper代替原版的搜索 C-x b 替代原版的buffer列表 C-x C-f 替代原版的文件操作 M-x 替代原版的命令列表 amx 将我们在M-x中输入命令的历史记录下来，每次显示最常用的。\nace-window 按键 功能 C-x o 优化切换window的操作逻辑，可以根据编号进行切换 undo-tree 提供比原版更好的撤销、重做操作。\n按键 功能 C-x u 打开undo tree which-key 在输入快捷键时提醒我们可以接下来输入什么，以及有什么功能。\nflycheck 语法检查程序，对于c/c++需要装好clang才能使用。另外在windows上并不是完美支持的，虽然github的issue里最近没有什么东西。\nsolarized-theme Emacs下的Solarized主题。\nayu-theme 一个主题。我目前喜欢Ayu的light主题胜过了Solarized的light主题。\ndashboard 一个欢迎界面。\nyasnippet 在补全的时候提供代码片段。\nhighlight-symbol 高亮Buffer中所有的、与光标处符号相同的符号。按\u0026lt;f3\u0026gt;开启。\n按键 功能 \u0026lt;f3\u0026gt; 开启高亮 rainbow-delimiters 彩虹括号，方便在lisp系语言中看清。\navy 一套跳转光标的操作。暂时还不太会使用。\n见https://github.com/abo-abo/avy\ncompany 自动补全插件。\n按键 功能 \u0026lt;f1\u0026gt; 显示候选项的文档（如果有、如果支持） company-box 在图形界面下为company提供图标。以及可以开一个小的悬浮窗口展示候选项的文档（如果有）。但是其有一些问题，我觉得还是不开好。\nlsp-mode 代码分析。如定义跳转等等功能由lsp提供。\nlsp-ui 为lsp提供图形化的显示，同时\n按键 功能 M-. 寻找符号定义 M-? 寻找符号引用 lsp-ivy 使lsp和ivy协作，可以通过命令 lsp-ivy-workspace-symbol 来搜索当前工作区的符号。\nprojectile 项目管理插件。通常我们查找一个函数的定义或者别的什么的定义的时候，这些定义并不会在同一个文件里，而是在同一个项目里，此时我们lsp需要projectile才能正确查找。\ncounsel-projectile 允许我们在项目中进行搜索。\nmagit 内置git。\nneotree 打开文件夹树形结构图\n按键 功能 \u0026lt;f8\u0026gt; 打开neotree c++-mode 提供c++、c的支持。\npowerline 更好的mode-line显示。\nyasnippet-snippets 相当于yasnippet那个插入代码片段的插件的一个范例。\nmarkdown-mode 与markdown相关，还在探索中。\ntexfrag 与latex相关，还在探索中。\ngoto-chg evil部分功能的前置插件。\nevil 使我们可以在emacs中使用vim的快捷键\n自用设置 init.el https://github.com/kegalas/.emacs.d/blob/main/init.el\n额外快捷键 按键 功能 M-n 下十行 M-p 上十行 C-\u0026lt;TAB\u0026gt; 打4个空格，而不是像TAB在emacs中的智能缩进 C-c c 适用于打codeforces等竞赛，编译当前window里的单c++文件 ","date":"2023-01-20T16:09:29+08:00","permalink":"https://kegalas.top/p/emacs%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","title":"Emacs使用笔记"},{"content":"导航页面\nTGA格式介绍 具体可以参考http://paulbourke.net/dataformats/tga/\n这里将部分重要的介绍一下。\n首先为了简单起见，我们使用没有颜色表，也没有压缩的TGA格式。\n文件头 首先是文件头。\n字节数 内容 1 图像信息长度 1 颜色表类型 1 图像类型 5 颜色表规范 10 图像规范 图像信息长度\n我们并不会使用这个部分，所以我们定为0.\n颜色表类型\n0代表不使用颜色表，1代表使用，我们定为0.\n图像类型\n0代表没有图像数据，2代表未压缩的真彩色图像，3代表未压缩的彩色图像，其他类型可以参照原文。\n颜色表规范\n前两个字节为颜色表首地址，然后的两个字节为颜色表长度，最后一个字节是颜色表位数。我们不会使用颜色表，所以全部设置为0.\n图形规范\n十个字节分为\n字节数 内容 2 图像x坐标起始位置 2 图像y坐标起始位置 2 图像宽度 2 图像高度 1 每个像素占用的位数 1 图像描述字节 和一些图像格式不同，TGA的坐标原点是左下角。不过这不影响我们选择xy坐标起始位置为(0,0)。\n图像宽度和高度也不难理解，唯一需要注意的是，数据是以小端序来存储的，也就是说800在用两个字节表示，16进制的形式是，0x0320。但是实际上写入文件时，由低到高，第一个字节是20，第二个字节是03，连起来是2003。\n每个像素占用的位数，如果是黑白图像，只有一个颜色，也就是0~255，只需要一个字节，也就是8位，所以会显示为8. 如果是RGB图像，就会是24，RGBA图像，就会是32. 值得注意的一点是，写入到文件的顺序是BGR和BGRA。\n图像描述字节，占一个字节，从低到高，\n0-3位 TGA 16位图像设为0或1，TGA 24位设为0，TGA 32位设为8. 原文并没有说8位图像设置为多少，我设置为0没有问题。\n4位 必须为0\n5位 设置原点在左下角还是左上角，0为左下角，1为左上角，实际上就是垂直翻转图像，不过TGA默认为0.\n6-7位 我们不考虑这个，直接设置为0，原文有详细解释\n图像信息 如果没有颜色表，那么在文件头的十八个字节之后就进入图像信息。\n很简单，如果是黑白图像，每个字节表示一个像素。如果是RGB图像，每三个字节表示一个像素，并且在文件中是以BGR的顺序放置的。如果是RGBA图像，每四个字节表示一个像素，并且在文件中是以BGRA的顺序放置的。\n总共有“宽\\(\\times\\)高\\(\\times\\)每个像素占用的字节数”个字节\n文件尾 在写完图像信息之后是文件尾，内容包含\n字节数 内容 2 扩展区域 2 开发者自定义区域 8 签名 2 结束 扩展区域和开发者自定义区域我们不用，直接设置为0.\n签名是TRUEVISION-XFILE的ASCII码表示，注意小端序。如果我们用两个uint64表示，就是0x4953495645555254和0x454C4946582D4E4F\n最后的结束是ASCII中的.符号和eof符号，分别是0x2E和0x00，写成一个uint16就是0x002E（考虑小端序）。\n整个TGA文件到此结束。\ntga_image.h 首先我们根据文件头的描述设定一个结构体\nstruct TGAHeader{ std::uint8_t length = 0; //TGA图像Identification Field的长度 std::uint8_t colorMapType = 0; //0：不使用颜色表，1：使用颜色表 std::uint8_t imageType = 0; //图像类型，2代表未压缩的真彩色图像，3代表未压缩的黑白图像 std::uint16_t cMapStart = 0; //颜色表首地址 std::uint16_t cMapLength = 0; //颜色表长度 std::uint8_t cMapDepth = 0; //颜色表位数 std::uint16_t xOffset = 0; //x坐标的起始位置 std::uint16_t yOffset = 0; //y坐标的起始位置 std::uint16_t width = 0; //图形宽度 std::uint16_t height = 0; //图像高度 std::uint8_t pixelDepth = 0; //图像每一个像素占用的位数，例如RGB为24位，RGBA为32位 std::uint8_t descriptor = 0; //图像描述信息，可见http://paulbourke.net/dataformats/tga/ TGAHeader(){} }; 然后是文件尾的结构体\nstruct TGAFooter{ std::uint32_t extend = 0; //扩展区域 std::uint32_t custom = 0; //开发者自定义区域 std::uint64_t sig1 = 0; //签名1 std::uint64_t sig2 = 0; //签名2 std::uint16_t end = 0; //结束 TGAFooter(){ sig1 = 0x4953495645555254; //TRUEVISI sig2 = 0x454C4946582D4E4F; //ON-XFILE end = 0x002E; } }; 注意，内存默认是以4字节对齐的，我们需要使用如下语句来保证对齐到1个字节，防止写入错误。\n#pragma pack(push) #pragma pack(1) //...这里放入刚刚的两个结构体。 #pragma pack(pop) 方便起见，我们定义\nnamespace TGAType{ const unsigned int rgb = 0; const unsigned int rgba = 1; const unsigned int grey = 2; const unsigned int pixelSize[] = {3,4,1}; } 来帮助我们定义颜色的编号和颜色格式占用的字节数，这可能并不是最好的写法，并且可能会暴露我的C++水平。\n然后我们给文件头一个新的构造函数\nTGAHeader(unsigned int type, std::uint16_t width_, std::uint16_t height_){ if(type == TGAType::rgb){ imageType = 2; pixelDepth = 24; } else if(type == TGAType::rgba){ imageType = 2; pixelDepth = 32; } else if(type == TGAType::grey){ imageType = 3; pixelDepth = 8; } else{ std::cerr\u0026lt;\u0026lt;\u0026#34;Error! Wrong TGA Type!\\n\u0026#34;; } width = width_; height = height_; if(type == TGAType::grey || type == TGAType::rgb){ descriptor |= 0x00; } else if(type == TGAType::rgba){ descriptor |= 0x08; } } 这不难理解，如果我们要写入到一个新的文件中，我们定义它的颜色类型和宽度高度，然后修改内容。\n之后我们定义一个图片类\nclass TGAImage{ private: std::uint16_t width; std::uint16_t height; std::uint8_t *data; unsigned int type; bool isFlipVertically; public: TGAImage(std::uint16_t const width_, std::uint16_t const height_, unsigned int const type_); TGAImage(std::string const \u0026amp; dir); ~TGAImage(); bool readFromFile(std::string const \u0026amp; dir); bool writeToFile(std::string const \u0026amp; dir); bool setFragment(std::uint16_t const x, std::uint16_t const y, geo::OARColor const \u0026amp; color); bool flipVertically(); inline std::uint16_t getWidth(){return width;} inline std::uint16_t getHeight(){return height;} }; 赋予了它少量功能，包括读写图片文件，图像翻转，以及设置某个像素的颜色值。\n完整的代码在这里\ntga_image.cpp TGAImage::TGAImage(std::uint16_t const width_, std::uint16_t const height_, unsigned int const type_){ width = width_; height = height_; type = type_; data = new std::uint8_t[width*height*TGAType::pixelSize[type]]; isFlipVertically = 0; std::fill(data,data+width*height*TGAType::pixelSize[type],0); } 首先是一个构造函数，也不难理解，只是设定了图像自身的属性以及分配了图像数据的内存。\n注意我们分配图像数据内存的时候，要乘以每个像素占用的字节数。同时注意要把图像数据清零，也可以用memset来。\nTGAImage::TGAImage(std::string const \u0026amp; dir){ readFromFile(dir); } 如果要从文件中定义个新图像，则我们直接调用读取文件的功能。\nTGAImage::~TGAImage(){ delete[] data; } 析构函数，释放内存。\n读取文件\nbool TGAImage::readFromFile(std::string const \u0026amp; dir){ //... } std::ifstream ifs; ifs.open(dir, std::ios::binary); if(!ifs.is_open()){ std::cerr \u0026lt;\u0026lt; \u0026#34;Error! Can\u0026#39;t open file: \u0026#34; \u0026lt;\u0026lt; dir \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; ifs.close(); return false; } 首先我们以二进制形式打开文件，并且检查错误\nTGAHeader header; ifs.read(reinterpret_cast\u0026lt;char *\u0026gt;(\u0026amp;header), sizeof(header)); if(!ifs.good()){ std::cerr \u0026lt;\u0026lt; \u0026#34;An error occured while reading the header. File: \u0026#34; \u0026lt;\u0026lt; dir \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; ifs.close(); return false; } if(header.descriptor\u0026amp;0x20){ isFlipVertically = 1; } width = header.width; height = header.height; if(width\u0026lt;=0||height\u0026lt;=0){ std::cerr \u0026lt;\u0026lt; \u0026#34;Error! Bad image width/height. File: \u0026#34; \u0026lt;\u0026lt; dir \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; ifs.close(); return false; } 然后我们读取文件头，并且检查是否成功读取以及数据是否有误。\nif(header.imageType == 2){ if(header.pixelDepth == 24){ type = TGAType::rgb; } else if(header.pixelDepth == 32){ type = TGAType::rgba; } else{ std::cerr \u0026lt;\u0026lt; \u0026#34;Error! Unknown pixel depth. File: \u0026#34; \u0026lt;\u0026lt; dir \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; ifs.close(); return false; } } else if(header.imageType == 3){ type = TGAType::grey; if(header.pixelDepth != 8){ std::cerr \u0026lt;\u0026lt; \u0026#34;Error! Unknown pixel depth. File: \u0026#34; \u0026lt;\u0026lt; dir \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; ifs.close(); return false; } } else{ std::cerr \u0026lt;\u0026lt; \u0026#34;Error! Unknown image type. File: \u0026#34; \u0026lt;\u0026lt; dir \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; ifs.close(); return false; } 根据图像信息来设置图像信息。\nint pixelSize = TGAType::pixelSize[type]; data = new std::uint8_t[width * height * pixelSize]; ifs.read(reinterpret_cast\u0026lt;char *\u0026gt;(data), pixelSize*width*height); if(!ifs.good()){ std::cerr \u0026lt;\u0026lt; \u0026#34;An error occured while reading the data. File: \u0026#34; \u0026lt;\u0026lt; dir \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; ifs.close(); return false; } 分配内存并读入图像数据，之后检查错误。\nif(isFlipVertically){ flipVertically(); } 如果图像有翻转那么进行翻转。\n文件写入\n和文件读取大同小异，不再详细说明。\n翻转图像\nbool TGAImage::flipVertically(){ int pixelSize = TGAType::pixelSize[type]; int half = height/2; isFlipVertically = isFlipVertically^1; for(int i=0;i\u0026lt;width;i++){ for(int j=0;j\u0026lt;half;j++){ for(int k=0;k\u0026lt;pixelSize;k++){ std::swap(data[(i+j*width)*pixelSize+k], data[(i+(height-1-j)*width)*pixelSize+k]); } } } return true; } 如上，我们将isFlipVertically取反，并且将图像数据按height/2位轴做翻转。不过我们这里虽然叫图像翻转，但是最后输出的图像和原图不会有区别，因为我们翻转图像的时候同时改变了坐标原点的位置。这样做只是方便将两个坐标系下的图像数据统一到一起去计算。\n设置像素颜色\nbool TGAImage::setFragment(std::uint16_t const x, std::uint16_t const y, geo::OARColor const \u0026amp; color){ assert(x\u0026gt;=0 \u0026amp;\u0026amp; x\u0026lt;width \u0026amp;\u0026amp; y\u0026gt;=0 \u0026amp;\u0026amp; y\u0026lt;height); assert(color.r\u0026gt;=0 \u0026amp;\u0026amp; color.r\u0026lt;=255); assert(color.g\u0026gt;=0 \u0026amp;\u0026amp; color.g\u0026lt;=255); assert(color.b\u0026gt;=0 \u0026amp;\u0026amp; color.b\u0026lt;=255); assert(color.a\u0026gt;=0 \u0026amp;\u0026amp; color.a\u0026lt;=255); int pixelSize = TGAType::pixelSize[type]; size_t index = (y*width + x)*pixelSize; if(type==TGAType::grey){ data[index] = static_cast\u0026lt;std::uint8_t\u0026gt; (color.r/3.0+color.g/3.0+color.b/3.0+0.5); } else if(type==TGAType::rgb || type==TGAType::rgba){ data[index] = color.b; data[index+1] = color.g; data[index+2] = color.r; if(type==TGAType::rgba){ data[index+3] = color.a; } } else{ std::cerr\u0026lt;\u0026lt;\u0026#34;An error occured while set fragment\\n\u0026#34;; return false; } return true; } 主要注意下标要乘以像素占用的字节大小，以及颜色顺序为BGRA。\n完整的代码在这里\n使用例子 我们用红色画一条从左下到右上的斜线，我们可以用以下代码\n#include \u0026#34;tga_image.h\u0026#34; int main(){ TGAImage image(100,100,TGAType::rgb); for(int i=0;i\u0026lt;100;i++){ image.setFragment(i,i,{255,0,0,255}); } image.writeToFile(\u0026#34;./test.tga\u0026#34;); return 0; } 输出结果如下：\n1.jpg\r","date":"2022-11-01T14:24:29+08:00","image":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E5%9B%BE%E7%89%87%E5%A4%84%E7%90%86%E5%BA%93/cover_hu2fa2362891bfb402ec26ffe12b2b88a0_64078_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E5%9B%BE%E7%89%87%E5%A4%84%E7%90%86%E5%BA%93/","title":"从零开始的软渲染器 图片处理库"},{"content":"一些概念解释 弱人工智能与强人工智能 弱人工智能是指不能真正实现推理和解决问题的智能机器，这些机器表面看像是智能的，但是并不真正拥有智能，也不会有自主意识。\n强人工智能是指真正能思维的智能机器，并且认为这样的机器是有知觉的和自我意识的，这类机器可分为类人（机器的思考和推理类似人的思维）与非类人（机器产生了和人完全不一样的知觉和意识，使用和人完全不一样的推理方式）两大类。\n符号处理系统 六种功能 输入符号 输出符号 存储符号 复制符号 建立符号结构：在符号系统中形成符号结构 条件性迁移：根据已有符号，继续完成活动的过程 可以把人看作是一个物理符号系统。如果一个物理符号系统具有上述全部6种功能，能够完成这个全过程，那么它就是一个完整的物理符号系统。人具有上述6种功能；现代计算机也具备物理符号系统的这6种功能。\n有一个假设：任何一个系统，如果它能表现出智能，那么它就必定能够执行上述6种功能。反之，任何系统如果具有这6种功能，那么它就能够表现出智能；这种智能指的是人类所具有的那种智能。把这个假设称为物理符号系统的假设。\n这个假设有很多局限性，许多乐观预言都成了泡影。90年代之后人工智能领域形成了很多新的研究模式\n人工智能的学派 符号主义 又称：逻辑主义、心理学派或计算机学派\n原理：物理符号系统（即符号操作系统）假设和有限合理性原理\n符号主义认为人的认知基元是符号，认知过程即符号操作过程。认为人是一个物理符号系统，计算机也是一个物理符号系统，因此能够用计算机来模拟人的智能行为。人工智能的核心问题是知识表示、知识推理和知识运用。\n连接主义 又称：仿生学派或生理学派\n原理：神经网络及神经网络间的连接机制与学习算法。\n连接主义认为思维基元是神经元，而不是符号处理过程。认为人脑不同于电脑，并提出连接主义的大脑工作模式，用于取代符号操作的电脑工作模式。\n行为主义 又称：进化主义或控制论学派\n原理：控制论及感知—动作型控制系统\n行为主义认为智能取决于感知和行动（所以被称为行为主义），提出智能行为的“感知—动作”模式。认为智能不需要知识、不需要表示、不需要推理；人工智能可以象人类智能一样逐步进化(所以称为进化主义)；智能行为只能在现实世界中与周围环境交互作用而表现出来。\n研究领域 自然语言理解 是计算机对人类的书面和口头形式的自然语言信息进行处理加工的技术,涉及语言学,数学和计算机科学等多学科知识领域.其主要任务是建立各种自然语言处理系统,如:文字(语音)自动识别系统,电子词典,机器翻译,自动索引系统等.\n模式识别 模式识别是指用计算机代替人类或帮助人类感知模式，是对人类感知外界功能的模拟，研究的是计算机模式识别系统，也就是使一个计算机系统具有模拟人类通过感官接受外界信息、识别和理解周围环境的感知能力。\n其已在医学图象,指纹识别,天气预报,汽车牌照识别中广泛应用。\n计算机视觉 机器视觉或计算机视觉是一种用计算机实现(或模拟)人的视觉功能，对客观外界进行感知和理解的技术。它是在图像处理和模式识别技术基础上发展起来的一门新兴的学科分支，其主要目的就是用机器识别客观外界景物，即从外界获得二维图像，抽取其特征(如形状、位置、大小、灰度、颜色、纹理等)构成本征描述，然后与已知物体的描述相匹配，从而辨认出所描述的物体。\n专家系统 专家系统是一个具有大量专门知识和经验的程序系统，它应用于人工智能技术，根据某个领域中一个或多个人类专家提供的知识和经验进行推理和判断，模拟人类专家的决策过程，以解决那些需要专家决定的复杂问题。\n机器学习 所谓机器学习，就是要使计算机能模拟人的学习行为，自动地通过学习获取知识和技能，不断改善性能，实现自我完善。机器学习就是计算机自动获取知识，它是知识工程的三个分支（使用知识、知识表示、获取知识）之一 。\n神经网络 也称神经计算,是指一类计算模型,其工作原理模仿了人类大脑的某些工作机制,其利用大量人工神经元组成一个大网络,来实现大规模并行运算。\n状态空间知识表示及其搜索技术 知识 知识是人们在改造客观世界的实践中积累起来的认识和经验。\n一般来说，我们把有关信息关联在一起所形成的信息结构称为知识。\n知识表示就是对知识的一种描述，一种计算机可以 接受的用于描述知识的数据结构。\n知识的要素，一般而言，人工智能系统的知识包含事实、规则、控制和元知识。\n事实：事物的分类、属性、事物间关系、科学事实、客观事实等。\n规则：事物的行动、动作和联系的因果关系知识。\n控制：是有关问题的求解步骤、规划、求解策略等技巧性知识，告诉怎么做一件事。\n元知识：怎样使用规则、解释规则、校验规则、解释程序结构等知识。是有关知识的知识，是知识库中的高层知识。\n知识表示的一般方法 一般有：状态空间法、问题归约法、谓词逻辑法、语义网络、框架表示、剧本表示、过程表示等。\n状态空间法 问题求解(problem solving)是个大课题，它涉及归约、推断、决策、规划、常识推理、定理证明和相关过程的核心概念。在分析了人工智能研究中运用的问题求解方法之后，就会发现许多问题求解方法是采用试探搜索方法的。也就是说，这些方法是通过在某个可能的解空间内寻找一个解来求解问题的。这种基于解答空间的问题表示和求解方法就是状态空间法，它是以状态和算符(operator)为基础来表示和求解问题的。\n状态\n为描述某类不同事物间的差别而引入的一组最少变量\\(q_0,q_1,\\cdots,q_n\\)的有序集合\n可用矢量来表示：\\(Q=[q_0,q_1,\\cdots,q_n]^T\\)\n其中的每一个元素为集合的分量，称为状态变量。\n给定每个分量的一组值就得到一个具体的状态。\n算符\n把问题从一种状态变换为另一种状态的手段。\n问题的状态空间\n是一个表示该问题全部可能状态及其关系的图。\n它包含三种说明的集合,即三元状态（S，F，G），S-初始状态集合，F-操作符集合，G-目标状态集合。\n状态图示法\n用有向带权图来表示，图上的节点代表状态，边代表状态转移的路径以及转移的代价。这个路径通常也和算符有关。\n搜索推理技术 知识表示是问题求解所必须的，从问题表示到问题的解决，有一个求解过程，也就是搜索推理过程。\n搜索 根据问题的实际情况不断寻找可利用的知识,构造出一条代价较少的推理路线,使问题得到圆满解决的过程称为搜索\n要求，找到一条从初始事实到问题的最终答案的一条推理路径、找到的这条路在时间和空间复杂度上最优。\n在状态空间中搜索时，我们通常会用：图搜索策略、盲目搜索、启发式搜索等方法。\n图搜索策略 这是一种在图中寻找路径的方法。\n图中每个节点对应一个状态，每条连线对应一个操作符。\n搜索方法有很多，例如深度优先搜索等，可以看算法竞赛整理。\n在这里我们通常需要\n必须记住下一步可以走哪些点。OPEN表，记录还没有扩展的节点，用于存放刚生成的节点。 必须记住哪些点走过了。CLOSED表，记录已经扩展过的节点，用于存放已经扩展或将要扩展的节点 必须记住从目标返回的路径 其基本思想是，先把问题的初始状态作为当前扩展节点对其进行扩展，生成一组子节点，然后检查问题的目标状态是否出现在这些子节点中。\n若出现，则找到问题的解。\n若没有出现，则按照某种策略继续扩展。\n重复上述过程，直到找到解或者没有可以操作的节点为止。\n总结如下\n1.jpg\r其中第七步的排序可以是任意的即盲目的（属于盲目搜索），也可以用之后讨论的各种启发性思想或其他准则为依据（属于启发式搜索）。\n盲目搜索 这是没有启发信息的一种搜索形式，搜索过程中获得的信息不会用来改进策略。\n一般只适用于求解比较简单的问题。\n不需要重排OPEN表。\n种类主要分为：宽度优先、深度优先、等代价搜索。\nDFS和BFS不再介绍，介绍一个有界深度优先搜索。\n有界深度优先搜索\n对深度优先搜索引入搜索深度的界限（设为\\(d_m\\)），当搜索深度达到了深度界限，而仍未出现目标节点时，就换一个分支进行搜索。\n等代价搜索\n它宽度优先搜索的一种推广。不是沿着等长度路径断层进行扩展，而是沿着等代价路径断层进行扩展。\n代价树的广度优先搜索\n每次从OPEN表中选择节点往CLOSED表传送时，总是选择其中代价最小的节点。\n换句话说就是用二叉堆去维护OPEN表的节点。\n代价树的深度优先搜索\n如果说深度优先搜索是将后继节点按枚举顺序放入OPEN表里，那么代价树的深度优先搜索就是将后继节点按代价从小到大的顺序放入OPEN表。\n启发式搜索 特点是重排OPEN表,选择最有希望的节点加以扩展。种类有：有序搜索、\\(A^*\\)算法等等。\n启发式搜索的估价函数\n估价函数(evaluation function)，是估算节点希望程度的量度，用\\(f(n)\\)表示节点\\(n\\)的估价函数值。\n建立估价函数的一般方法是：提出任意节点与目标集之间的距离量度或差别量度\n有序搜索\n有序搜索，也称最好优先搜索，选择OPEN表上具有最小\\(f\\)值的节点作为下一个要扩展的节点。\n\\(A^*\\)算法\n它是有序搜索的一种，其特点在于对估价函数的定义上。\n用\\(k(n_i,n_j)\\)表示任意两个节点\\(n_i\\)和\\(n_j\\)之间最小代价路径的实际代价。\n如果两个节点没有通路，则\\(k\\)没有定义。\n对于一个具体的目标节点\\(t_i\\)，用\\(h^*(n)\\)表示整个目标节点集合\\(\\{t_i\\}\\)上所有\\(k(n,t_i)\\)中最小的一个，此时\\(h^*(n)\\)就是从\\(n\\)到目标节点最小代价路径的代价，从\\(n\\)到目标节点的代价为\\(h^*(n)\\)的任一路径就是一条最佳路径。\n估价函数设计如下(S是初始状态)\n\\[g^*(n) = k(S,n) \\]\n\\[f^*(n) = g^*(n)+h^*(n) \\]\n\\(f^*(n)\\)就是从\\(S\\)开始约束通过节点\\(n\\)的一条最佳路径的代价。\n希望估价函数\\(f\\)是\\(f^*\\)的一个估计，\\(g\\)是\\(g^*\\)的一个估计，\\(h\\)是\\(h^*\\)的一个估计，\\(h\\)叫做启发函数\n\\[f(n) = g(n)+h(n) \\]\n在图搜索中，如果OPEN表的重排是根据\\(f(n) = g(n)+h(n)\\)来进行的，那么称为\\(A\\)算法。\n在\\(A\\)算法中,如果对所有的\\(n\\)存在\\(h(n)\\leq h^*(n)\\) ,则称\\(h(n)\\)为\\(h^*(n)\\)的下界,它表示某种偏于保守的估计;\n采用\\(h^*(n)\\)的下界\\(h(n)\\)为启发函数的\\(A\\)算法，称为\\(A^*\\)算法。\n问题归约知识表示及其搜索技术 已知问题的描述，通过一系列变换把此问题最终变为一个子问题集合；这些子问题的解可以直接得到，从而解决了初始问题。\n该方法也就是从目标(要解决的问题)出发逆向推理，建立子问题以及子问题的子问题，直至最后把初始问题归约为一个平凡的本原问题集合。这就是问题归约的实质。\n问题归约法的组成部分：\n一个初始问题描述 一套把问题变为子问题的操作符 一套本原问题描述 举个例子\n2.jpg\r与或图表示 3.jpg\r或节点：只要解决某个问题就可以解决其父节点的问题\n与节点：只有解决所有子问题才可以解决其父节点的问题\n终叶节点：对应本原问题的节点\n可解节点：如下定义\n终叶节点是可解节点 如果某个非终叶节点含有或后继节点，那么只有当其后继节点至少有一个是可解的时，此非终叶节点才是可解的。 如果某个非终叶节点含有与后继节点，那么只要当其后继节点全部为可解时，此非终叶节点才是可解的 不可解节点：如下定义\n没有后裔的非终叶节点为不可解节点 如果某个非终叶节点含有或后继节点，那么只有当其全部后裔为不可解时，此非终叶节点才是不可解的。 如果某个非终叶节点含有与后继节点，那么只要当其后裔至少有一个为不可解时，此非终叶节点才是不可解的。 与或图搜索 整体与之前提到的图搜索基础没有差别，只是要去记录节点的可解性。如果最终初始节点可解，原问题就有解，否则就无解。\nMax-Min搜索 目的是为博弈的双方中的一方寻找一个最优行动方案 要寻找这个最优方案，就要通过计算当前所有可能的方案来进行比较； 方案的比较是根据问题的特征来定义一个估价函数，用来估算当前博弈树端节点的得分； 当计算出端节点的估值后，再推算出父节点的得分（即计算倒推值）； 对或节点，选其子节点中一个最大得分作为父节点的得分 对与节点，选其子节点中一个最小得分作为父节点的得分 如果一个行动方案能获得较大的倒推值，则它就是当前最好的行动方案。 假设Max是机器人下棋，Min是人类对手下棋，搜索的步骤是\n以\\(c(o)\\)为根，生成\\(k\\)-步博弈树； 评估博弈树叶节点对应的博弈状态(棋局)； 进行极大极小运算 (Max-Min 运算)； 等待 Min 行棋，产生新的 c(o)，返回 step1. 其实和人类思考差不多，往下多想\\(k\\)步可能的局面，选择自己最优，对方最差的局面。但是机器暴力地枚举了所有可能。\n\\(\\alpha-\\beta\\)剪枝 之前说的暴力算法，先生成一棵博弈树，然后再计算其倒推值，效率非常低。\n而\\(\\alpha-\\beta\\)剪枝技术的基本思想是，边生成博弈树边计算评估各节点的倒推值并且根据评估出的倒推值范围，及时停止扩展那些已无必要再扩展的子节点，即相当于剪去了博弈树上的一些分枝，从而节约了机器开销，提高了搜索效率。\n谓词逻辑表示与推理技术 谓词逻辑的概念和离散数学中讲授的一样，不再重复。具体可见离散数学整理\n谓词逻辑法 谓词逻辑法采用谓词合式公式和一阶谓词演算把要解决的问题变为一个有待证明的问题,然后采用消解原理和消解反演来证明一个新语句是从已知的正确语句导出的,从而证明新语句也是正确的.\n利用谓词公式进行知识表示的步骤 定义谓词及个体，确定其含义 根据要表达的事物或概念,为每个谓词中的变元赋值 根据表达的知识的含义,用适当的连接符号将各个谓词连接起来,形成谓词公式。 置换与合一 置换 介绍一下在离散数学中不是很详细的部分。\n一个表达式的置换就是在该表达式中用置换项置换变量。\n置换是形如\n\\[\\{t_1/x_1,t_2/x_2,\\cdots,t_n/x_n\\} \\]\n的有限集合。其中，\\(t_i\\)是不同于\\(x_i\\)的项（常量、变量、函数）；\\(x_1,x_2,\\cdots,x_n\\)是互不相同的变量；\\(t_i/x_i\\)表示用\\(t_i\\)代换\\(x_i\\)\n令置换\\(s=\\{t_1/x_1,t_2/x_2,\\cdots,t_n/x_n\\}\\)，而\\(E\\)是一个谓词公式，那么\\(s\\)作用于\\(E\\)，就是将\\(E\\)中出现的\\(x_i\\)都以\\(t_i\\)代入。结果以\\(Es\\)表示，并称为\\(E\\)的一个例\n而合成，也称为置换乘法，是置换之间的一种运算，若\n\\[\\theta = \\{t_1/x_1,\\cdots,t_n/x_n\\} \\]\n\\[\\lambda = \\{u_1/y_1,\\cdots,u_m/y_m\\} \\]\n置换的乘积\\(\\theta\\cdot\\lambda\\)是个新的置换，作用于\\(E\\)相当于先\\(\\theta\\)后\\(\\lambda\\)对\\(E\\)的作用。\n先作置换\n\\[\\{t_1\\cdot\\lambda/x_1,\\cdots,t_n\\cdot\\lambda/x_n,u_1/y_1,\\cdots,u_m/y_m\\} \\]\n若\\(y_i\\in\\{x_1,\\cdots,x_n\\}\\)时，先从中删除\\(u_i/y_i\\)；\\(t_i\\cdot\\lambda=x_i\\)时，再从中删除\\(t_i\\cdot\\lambda/x_i\\)\n所得的置换称为\\(\\theta\\)与\\(\\lambda\\)的乘积，记作\\(\\theta\\cdot\\lambda\\)\n置换的乘法是有结合律的，但没有交换率。\n合一 合一是寻找项对变量的置换，以使两表达式一致。\n如果一个置换\\(s\\)作用于表达式集\\(\\{E_i\\}\\)的每个元素，则我们用\\(\\{E_i\\}s\\)来表示置换例的集。\n称表达式集\\(\\{E_i\\}\\)是可合一的。如果存在一个置换\\(s\\)，使得：\n\\[E_1s=E_2s=E_3s=\\cdots \\]\n那么我们称此\\(s\\)为\\(\\{E_i\\}\\)的合一者，因为\\(s\\)的作用是使 集合\\(\\{E_i\\}\\)成为单一形式。\n通过置换最少的变量以使表达式一致，这个置换就叫最一般合一者,记为mgu。\n消解原理 消解原理又称为归结原理。该原理是Robinson提出的一种基于逻辑的、采用反证法的推理方法。\n消解法的基本原理是采用反证法或者称为反演推理方法，将待证明的表达式（定理）转换成为逻辑公式（谓词公式），然后再进行归结，归结能够顺利完成，则证明原公式(定理）是正确性的。\n子句集的求解 先给出一些定义\n文字\n一个原子公式和原子公式的否定都叫做文字\n子句\n由文字的析取组成的公式\n空子句\n不包含任何文字的子句\n子句集\n由子句构成的集合\n任一谓词演算公式可以化成一个子句集。由九个步骤组成\n消去蕴涵符号（使用蕴含律）\n减少否定符号的辖域，应用德摩根定律等使得每个否定符号都只结合一个谓词符号\n对变量标准化。在任一量词辖域内，受该量词约束的变量为一哑元(虚构变量)，它可以在该辖域内处处统一地被另一个没有出现过的任意变量所代替，而不改变公式的真值。\n消去存在量词\n如果要消去的存在量词在某些全称量词的辖域内，例如\\((\\forall y)[(\\exists x)P(x,y)]\\)中，中，存在量词是在全称量词的辖域内，我们允许所存在的\\(x\\)可能依赖于\\(y\\)值。令这种依赖关系明显地由函数\\(g(y)\\)所定义，它把每个\\(y\\)值映射到存在的那个\\(x\\)。这种函数叫做Skolem函数。如果用Skolem函数代替存在的\\(x\\),我们就可以消去全部存在量词，并写成：\\((\\forall y)P(g(y),y)\\) 如果不在全称量词的辖域内，直接用一个新的常量符号来替代即可。 化为前束形。把所有全称量词移到公式的左边，并使每个量词的辖域包括这个量词后面公式的整个部分。所得公式称为前束形。前束形公式由前缀和母式组成，前缀由全称量词串组成，母式由没有量词的公式组成。\n把母式化为合取范式\n消去全称量词\n消去连词符号\\(\\wedge\\)。用\\(\\{(A\\vee B),(A\\vee C)\\}\\)替代\\((A\\vee B)\\wedge(A\\vee C)\\)\n更换变量名称，把每个子句中重复变量的名称换成不同的。\n消解反演 一般过程\n建立子句集\\(S\\) 从子句集\\(S\\)出发,仅对\\(S\\)的子句间使用归结推理规则（也即反证法） 如果得出空子句, 则结束;否则转下一步 将所得归结式仍放入\\(S\\)中 对新的子句集使用归结推理规则 转3. 空子句不含有文字,它不能被任何解释满足,所以空子句是永假的,不可满足的。\n归结过程出现空子句,说明出现互补文字,说明S中有矛盾,因此S是不可满足的。\n语义网络法 语义网络是知识的一种结构化图解表示，它由节点和弧线组成。节点用于表示实体、概念和情况等，节点之间的弧线用于表示节点间的关系。\n框架表示 框架是一种结构化表示法，通常采用语义网络中的节点-槽-值表示结构。\n规则演绎系统 基于规则的演绎推理是一种直接的推理方法，它不像消解反演把知识转化为子句集，而是把有关问题的知识和信息划分为规则和事实两种类型。\n规则由包含蕴含形式的表达式表示，事实由无蕴含形式的表达式表示，并画出相应的与或图，然后通过规则进行演绎推理。\n规则演绎系统可以分为规则正向演绎推理、规则逆向演绎系统和规则双向演绎系统。\n基于规则的问题求解系统运用下述规则来建立：\n\\[If\\to Then \\]\n其中，If部分可能由几个if组成，而Then部分可能由一个或一个以上的then组成。\n在这种系统中，通常称每个if部分为前项，称每个then部分为后项。\n规则正向演绎系统 规则正向演绎系统是从事实到目标进行操作的，即从状况条件到动作进行推理的，也就是从if到then的方向进行推理的。\n过程\n事实表达式的与或形变换。把事实表示为非蕴涵形式的与或形，作为系统的总数据库。具体变换步骤与前述化为子句形类似。 事实表达式的与或图表示，即用与或图来表达事实表达式。 与或图的F规则变换 这些规则是建立在某个问题辖域中普通陈述性知识的蕴涵公式基础上的。我们把允许用作规则的公式类型限制为下列形式：\n\\[L\\Rightarrow W \\]\n式中：\\(L\\)是单文字；\\(W\\)为与或形的公式。\n作为终止条件的目标公式 基于规则的正向演绎推理的基本原理是：应用F规则作 用于表示事实的与或图，改变与或图的结构，从而产生 新的事实，直到推出目标公式，则推理成功结束。\n其推理过程为\n首先用与或图把已知事实表示出来。 用F规则的左部和与或图的叶节点进行匹配，并将匹配成功的F规则加入到与或图中，即利用F规则转换与或图。 重复第（2）步，直到产生一个含有以目标节点作为终止节点的解图为止。 规则逆向演绎系统 规则逆向演绎系统是从then向if进行推理的，即从目标或动作向事实或状况条件进行推理的。\n逆向演绎系统能够处理任意形式的目标表达式。采用和变换事实表达式类似的过程，把目标公式化成与或形。\n与或图的B规则变换\n这个B规则是建立在确定的蕴涵式基础上的，正如正向系统的F规则一样。不过，我们现在把这些B规则限制为: \\(W\\Rightarrow L\\)形式的表达式。\n其中，W为任一与或形公式，L为文字，而且蕴涵式中任何变量的量词辖域为整个蕴涵式。其次，把B规则限制为这种形式的蕴涵式还可以简化匹配，使之不会引起重大的实际困难。\n此外，可以把像\\(W\\Rightarrow(L1\\wedge L2)\\)这样的蕴涵式化为两个规则\\(W\\Rightarrow L1\\)和\\(W\\Rightarrow L2\\)。\n作为终止条件的事实节点的一致解图\n逆向系统中的事实表达式均限制为文字合取形，它可以表示为一个文字集。当一个事实文字和标在该图文字节点上的文字相匹配时，就可把相应的后裔事实节点添加到该与或图中去。这个事实节点通过标有mgu的匹配弧与匹配的子目标文字节点连接起来。同一个事实文字可以多次重复使用(每次用不同变量)，以便建立多重事实节点。逆向系统成功的终止条件是与或图包含有某个终止在事实节点上的一致解图。\n规则双向演绎系统 正向和逆向组合系统是建立在两个系统相结合的基础上的。此组合系统的总数据库由表示目标和表示事实的两个与或图结构组成，并分别用F规则和B规则来修正。\n双向演绎系统的主要复杂之处在于其终止条件，终止涉及两个图结构之间的适当交接处。这些结构可由标有合一文字的节点上的匹配棱线来连接。\n产生式系统 用来描述若干个不同的以一个基本概念为基础的系统。这个基本概念就是产生式规则或产生式条件和操作对的概念。\n在产生式系统中，论域的知识分为两部分：用事实表示静态知识，如事物、事件和它们之间的关系；用产生式规则表示推理过程和行为。由于这类系统的知识库主要用于存储规则，因此又把此类系统称为基于规则的系统。\n不确定性推理 模糊计算和模糊推理 与二值逻辑这样的非真即假的概念不同，模糊概念中，从属于该概念到不属于该概念之间无明显分界线。\n比如快慢、大小、软硬、强弱等。\n其基本思想是，用属于程度替代属于或不属于。\n经典集合 设\\(A\\)是论域\\(U\\)上的一个集合，对任意\\(u\\in U\\)，令\n\\[C_A(u) = \\left\\{\\begin{matrix} 1,u\\in A\\\\ 0,u\\notin A \\end{matrix}\\right. \\]\n则称\\(C_A(u)\\)为集合\\(A\\)的特征函数。\n模糊理论基本概念 模糊集合\n论域\\(U\\)中的模糊集\\(F\\)用一个在区间\\([0,1]\\)的取值的隶属函数\\(\\mu_F\\)来表示，即：\n\\[\\mu_F:U\\to[0,1] \\]\n\\(\\mu_F\\)称为\\(F\\)的隶属函数，\\(\\mu_F(u)\\)称为\\(u\\)对\\(A\\)的隶属度。\n直观上来说，就是将一些元素属于某个集合的程度映射到连续的\\([0,1]\\)上。\n模糊集的表示方法 若\\(U\\)为离散域且为有限集合时，模糊集合可以表示为：\n扎德表示法\n\\[F = \\sum^n_{i=1}\\mu_F(u_i)/u_i \\]\n其中“\\(/\\)”符号表示的意思是，分母是论域中的元素，分子是该元素对模糊子集\\(F\\)的隶属度。\\(\\sum\\)也不是表示相加，只是一个记号。\n比如我们写出来的可能是\\(A = 1/u_1+0.7/u_2+0/u_3+0.5/u_4\\)这样的形式。如果隶属度为\\(0\\)可以省略不写。\n序偶表示法\n\\[F=\\{(u_1,\\mu(u_1)),(u_2,\\mu(u_2)),\\cdots,(u_n,\\mu(u_n))\\} \\]\n向量表示法\n\\[F = \\{\\mu(u_1),\\mu(u_2),\\cdots,\\mu(u_n)\\} \\]\n无论论域是有限的还是无限的，连续的还是离散的，扎德都用如下记号作为模糊子集的一般表示形式：\n\\[F = \\int_U\\frac{\\mu_F}{u} \\]\n这里的积分号不是数学中的积分，也不是求和，只是表示论域中各元素与其隶属度对应关系的总括，是一个记号。\n集合运算 定义1\n设\\(A,B\\)是论域\\(U\\)的模糊集，即\\(A,B\\in F(U)\\)，若对于任一\\(u\\in U\\)都有\\(\\mu_B(u)\\leq\\mu_A(A)\\)，则称\\(B\\)包含于\\(A\\)，或者说\\(B\\)是\\(A\\)的一个子集，记作\\(B\\subseteq A\\)。若对于任一\\(u\\in U\\)都有\\(\\mu_B(u)=\\mu_A(A)\\)，则称\\(B\\)等于\\(A\\)，记作\\(B=A\\)\n定义2\n并运算（\\(A\\bigcup B\\)）的隶属度函数\\(\\mu_{A\\bigcup B}\\)对所有的\\(u\\in U\\)被逐点定义为取大运算，即\n\\[\\mu_{A\\bigcup B} = \\mu_A(u)\\vee\\mu_B(u) \\]\n式中，\\(\\vee\\)符号取极大值运算。\n定义3\n交运算（\\(A\\bigcap B\\)）的隶属度函数\\(\\mu_{A\\bigcap B}\\)对所有的\\(u\\in U\\)被逐点定义为取小运算，即\n\\[\\mu_{A\\bigcap B} = \\mu_A(u)\\wedge\\mu_B(u) \\]\n式中，\\(\\wedge\\)符号取极小值运算。\n定义4\n补，隶属度函数\\(\\mu_{\\bar A}\\)，对所有的\\(u\\in U\\)，被逐点定义为\\(\\mu_{\\bar A}(u) = 1-\\mu_{A}(u)\\)\n模糊集合中有时会用\\(\\neg A\\)表示\\(A\\)的补集。\n定理\n集合运算的定理和经典的集合没有区别，例如结合、分配律，德摩根律等等。\n模糊集的截集 定义1\n设\\(A\\in F(u),\\lambda\\in[0,1]\\)，则\n\\(A_\\lambda=\\{u|u\\in U,\\mu_A(u)\\geq\\lambda\\}\\)，称\\(A_\\lambda\\)为\\(A\\)的一个\\(\\lambda\\)截集，称\\(\\lambda\\)为阈值（置信水平） \\(A_\\lambda=\\{u|u\\in U,\\mu_A(u)\u003e\\lambda\\}\\)，称\\(A_\\lambda\\)为\\(A\\)的一个\\(\\lambda\\)强截集 \\(SuppA=\\{u|u\\in U,\\mu_A(u)\u003e0\\}\\)为\\(A\\)的支集 \\(KerA=\\{u|u\\in U,\\mu_A(u)=1\\}\\)为\\(A\\)的核 当\\(A\\)的核不为空，则称\\(A\\)为正规\\(F\\)集。\n模糊集合的模糊度 模糊度是模糊集模糊程度的一种度量\n定义\n设\\(A\\in F(U)\\)，\\(d\\)是定义在\\(F(U)\\)上的一个实函数，如果它满足以下条件：\n对任意\\(A\\in F(U)\\)，有\\(d(A)\\in[0,1]\\) 当且仅当\\(A\\)是一个普通集合时，\\(d(A) = 0\\) 若\\(A\\)的隶属函数\\(\\mu_A(U)\\equiv0.5\\)，则\\(d(A)=1\\) 若\\(A,B\\in F(U)\\)，且对任意\\(u\\in U\\)，满足 \\[\\mu_B(u)\\leq\\mu_A(u)\\leq0.5或者\\mu_B(u)\\geq\\mu_A(u)\\geq0.5 \\]\n则有\\(d(B)\\leq d(A)\\)\n对任意\\(A\\in F(U)\\)，有\\(d(A)=d(\\neg A)\\) 则称\\(d\\)为定义在\\(F(U)\\)上的一个模糊度，\\(d(A)\\)称为\\(A\\)的模糊度。\n直观地理解\n模糊度是\\([0,1]\\)上的一个数 普通集合的模糊度是\\(0\\)，也就代表其不模糊 越靠近\\(0.5\\)就越模糊，\\(\\mu_A(u)=0.5\\)时最模糊 模糊集\\(A\\)与其补集\\(\\neg A\\)具有相同的模糊度 模糊度的计算方法\nHaming（海明）模糊度\n\\[d_1(A) = \\frac{2}{n}\\sum^n_{i=1}|\\mu_A(u_i)-\\mu_{A_{0.5}}(u_i)| \\]\n其中，\\(\\mu_{A_{0.5}}(u_i)\\)是\\(A\\)的\\(\\lambda=0.5\\)截集的隶属函数。由于\\(A_{0.5}\\)是一个普通集合，所以\\(\\mu_{A_{0.5}}(u_i)\\)实际上是特征函数\nEuclid（欧几里得）模糊度\n\\[d_2(A) = \\frac{2}{\\sqrt n }(\\sum^n_{i=1}|\\mu_A(u_i)-\\mu_{A_{0.5}}(u_i)|^2)^{1/2} \\]\nMinkowski（明可夫斯基）模糊度\n\\[d_p(A) = \\frac{2}{n^{1/p}}(\\sum^n_{i=1}|\\mu_A(u_i)-\\mu_{A_{0.5}}(u_i)|^p)^{1/p} \\]\nShannon（香农）模糊度\n\\[d(A) = \\frac{1}{n\\ln 2}\\sum^n_{i=1}S(\\mu_A(u_i)) \\]\n其中\\(S(x)\\)是定义在\\([0,1]\\)上的香农函数，即\n\\[S(x) = \\left\\{\\begin{matrix} -x\\ln x-(1-x)ln(1-x),\\quad \u0026x\\in(0,1) \\\\ 0,\\quad \u0026x=1\\ or\\ x = 0 \\end{matrix}\\right. \\]\n模糊数 模糊的数量，例如：500人左右，大约0.6等\n定义\n如果实数域\\(R\\)上的模糊集\\(A\\)的隶属函数\\(\\mu_A(u)\\)在\\(R\\)上连续且具有如下性质\n\\(A\\)是凸模糊集，即对任意\\(\\lambda\\in[0,1]\\)，\\(A_\\lambda\\)是闭区间 \\(A\\)是正规模糊集，即存在\\(u\\in R\\)，使得\\(\\mu_A(u)=1\\) 则称\\(A\\)为一个模糊数\n直观上模糊数的隶属函数图形是单峰的，且在峰顶使隶属度达到\\(1\\)\n模糊关系 在普通集合上定义的关系已经在离散数学中介绍过了。这种关系是一种确定性的关系，要么有，要么没有。\n而模糊关系就不是非常明确的。\n定义\n设论域\\(U,V\\)，则\\(U\\times V\\)（笛卡尔积）的一个子集\\(R\\)就是从\\(U\\)到\\(V\\)的模糊关系，记作\n\\[U\\overset{R}{\\rightarrow} V \\]\n这里的模糊关系\\(R\\)是属于模糊二元关系。\n其隶属函数为映射\\(\\mu_R:U\\times V\\to[0,1]\\)\n隶属度\\(\\mu_R(u_0,v_0)\\)，表示\\(u_0\\)与\\(v_0\\)具有关系\\(R\\)的程度。\n对于有限论域\\(U = \\{u_1,u_2,\\cdots,u_m\\},V = \\{v_1,v_2,\\cdots,v_n\\}\\)，则\\(U\\)对\\(V\\)的模糊关系的隶属函数可以用\\(m\\times n\\)阶模糊矩阵\\(R\\)来表示，即\n\\[R = (r_{ij})_{m\\times n} \\]\n模糊集的笛卡尔乘积\n模糊集\\(A,B\\)的笛卡尔乘积为\n\\[A\\times B = \\int_{U\\times V}\\min(\\mu_A(u),\\mu_B(v))/(u,v) \\]\n模糊关系的合成\n设\\(R_1\\)与\\(R_2\\)分别是\\(u\\times v\\)及\\(v\\times w\\)上的两个模糊关系，则\\(R_1\\)与\\(R_2\\)的合成是指从\\(u\\)到\\(w\\)的一个模糊关系，记为\\(R_1\\circ R_2\\)，其隶属度为\n\\[\\mu_{R_1\\circ R_2}(u,w) = \\{\\bigvee^{v}\\mu_{R_1}(u,v)\\wedge\\mu_{R_2}(v,w) \\} \\]\n模糊推理 模糊命题\n含有模糊概念、模糊数据的语句称为模糊命题。\n它的一般表示形式为\n\\[x\\quad is \\quad A \\]\n或者\n\\[x\\quad is \\quad A(CF) \\]\n其中\\(A\\)是模糊概念或模糊数，用相应的模糊集及隶属函数刻画；\\(x\\)是论域上的变量，用以代表所论述对象的属性； \\(CF\\)是该模糊命题的可信度，它既可以是一个确定的数，也可以是一个模糊数或者模糊语言值。\n模糊语言值是指表示大小、长短、多少等程度的一些词汇。如：极大、很大、相当大、比较大。模糊语言值同样可用模糊集描述。\n模糊的知识表示 模糊产生式规则的一般形式是 \\[IF\\quad E\\quad THEN\\quad H\\quad (CF,\\lambda) \\]\n其中\\(E\\)是用模糊命题表示的模糊条件；\\(H\\)是用模糊命题表示的模糊结论；\\(CF\\)是知识的可信度因子，它既可以是一个确定的数，也可以是一个模糊数或模糊语言值。\\(\\lambda\\)是匹配度的阈值，用以指出知识被运用的条件。\n推理中所用的证据也用模糊命题表示，一般形式为 \\[x\\quad is \\quad A' \\]\n或者\n\\[x\\quad is \\quad A'(CF) \\]\n模糊推理要解决的问题：证据与知识的条件是否匹配；如果匹配，如何利用知识及证据推出结论。 模糊匹配与冲突消解 贴近度 设\\(A,B\\)分别是论域\\(U=\\{u_1,u_2,\\cdots,u_n\\}\\)上的两个模糊集，则它们的贴近度定义为：\n\\[(A,B) = [A\\cdot B+(1-A\\odot B)]/2 \\]\n其中\n\\[A\\cdot B = \\bigvee_U(\\mu_A(u_i)\\wedge\\mu_B(u_i)) \\]\n是内积\n\\[A\\odot B = \\bigwedge_U(\\mu_A(u_i)\\vee\\mu_B(u_i)) \\]\n是外积。\n语义距离 海明距离\n\\[d(A,B) = \\frac{1}{n}\\sum^n_{i=1}|\\mu_A(u_i)-\\mu_B(u_i)| \\]\n\\[d(A,B) = \\frac{1}{b-a}\\int^b_a|\\mu_A(u)-\\mu_B(u)|du \\]\n欧几里得距离\n\\[d(A,B) = \\frac{1}{\\sqrt n}\\sqrt{\\sum^n_{i=1}(\\mu_A(u_i)-\\mu_B(u_i))^2} \\]\n明可夫斯基距离\n\\[d(A,B) = [\\frac{1}{n}\\sum^n_{i=1}|\\mu_A(u_i)-\\mu_{A_{0.5}}(u_i)|^p]^{1/p},\\quad p\\geq1 \\]\n切比雪夫距离\n\\[d(A,B) = \\underset{1\\leq i\\leq n}{\\max}|\\mu_A(u_i)-\\mu_B(u_i)| \\]\n匹配度为\\(1-d(A,B)\\)\n相似度 最大最小法 \\[r(A,B) = \\frac{\\sum\\min\\{\\mu_A(u_i),\\mu_B(u_i)\\}}{\\sum\\max\\{\\mu_A(u_i),\\mu_B(u_i)\\}} \\]\n算术平均法 \\[r(A,B) = \\frac{\\sum\\min\\{\\mu_A(u_i),\\mu_B(u_i)\\}}{\\frac{1}{2}\\sum(\\mu_A(u_i)+\\mu_B(u_i))} \\]\n几何平均最小法 \\[r(A,B) = \\frac{\\sum\\min\\{\\mu_A(u_i),\\mu_B(u_i)\\}}{\\sum\\sqrt {(\\mu_A(u_i)\\times\\mu_B(u_i))}} \\]\n相关系数法 \\[r(A,B) = \\frac{\\sum(\\mu_A(u_i)-\\bar\\mu_A)\\times(\\mu_B(u_i)-\\bar\\mu_B)}{\\sqrt{[\\sum(\\mu_A(u_i)-\\bar\\mu_A)^2]\\times[\\sum(\\mu_B(u_i)-\\bar\\mu_B)^2]}} \\]\n\\[\\bar\\mu_A = \\frac{1}{n}\\sum\\mu_A(u_i),\\quad\\bar\\mu_B = \\frac{1}{n}\\sum\\mu_B(u_i) \\]\n指数法 \\[r(A,B) = \\exp\\bigg(-\\sum|\\mu_A(u_i)-\\mu_B(u_i)|\\bigg) \\]\n复合条件的模糊匹配 分别计算出每一个子条件与其证据的匹配度 求出整个前提条件与证据的总匹配度。目前常用的方法有“取极小”和“相乘”等。 检查总匹配度是否满足阈值条件，如果满足就可以匹配，否则为不可匹配。 冲突消解 按匹配度大小排序 按加权平均值排序 按广义顺序关系排序 模糊推理的基本形式 模糊假言推理 知识：\\(IF\\quad x\\ is\\ A\\quad THEN\\quad y\\ is\\ B\\)\n证据：\\(x\\ is\\ A'\\)\n结论：\\(y\\ is\\ B'\\)\n模糊拒取式推理 知识：\\(IF\\quad x\\ is\\ A\\quad THEN\\quad y\\ is\\ B\\)\n证据：\\(y\\ is\\ B'\\)\n结论：\\(x\\ is\\ A'\\)\n知识中只含有简单条件，且不带可信度因子的模糊推理称为简单模糊推理。\n合成推理知识\n对于知识\\(IF\\quad x\\ is\\ A\\quad THEN\\quad y\\ is\\ B\\)\n首先构造出\\(A,B\\)之间的模糊关系\\(R\\)，\n如果已知证据是\\(x\\ is\\ A'\\)，且\\(A,A'\\)之间可以进行模糊匹配，则\\(B' = A'\\circ R\\)\n如果已知证据是\\(y\\ is\\ B'\\)，且\\(B,B'\\)之间可以进行模糊匹配，则\\(A' = R\\circ B'\\)\n构造模糊关系R的方法 扎德方法 扎德提出了两种方法：一种称为条件命题的极大极小规则。另一种称为条件命题的算术规则，由它们获得的模糊关系分别记为\\(R_m\\)和\\(R_a\\)\n设\\(A\\in F(U), B\\in F(V)\\)，其分别表示为\n\\[A = \\int_U \\mu_A(u)/u, B = \\int_V \\mu_B(u)/u \\]\n则\n\\[R_m = (A\\times B)\\cup(\\neg A\\times V) = \\int_{U\\times V}(\\mu_A(u)\\wedge\\mu_B(v))\\vee(1-\\mu_A(u))/(u,v) \\]\n\\[R_a = (\\neg A\\times V)\\oplus(U\\times B) = \\int_{U\\times V}1\\wedge(1-\\mu_A(u)+\\mu_B(v))/(u,v) \\]\n其中\\(\\times\\)是笛卡尔积；有界和\\(x\\oplus y=\\min\\{1,x+y\\}\\)\nMamdani方法 对于知识\\(IF\\quad x\\ is\\ A\\quad THEN\\quad y\\ is\\ B\\)\n\\[R_C = A\\times B = \\int_{U\\times V}\\mu_A(u)\\wedge\\mu_B(v)/(u,v) \\]\nMizumoto方法 米祖莫托等人根据多值逻辑中计算\\(T(AB)\\)的定义，提出了一组构造模糊关系的方法，分别记为\\(R_s,R_g,R_{sg},R_{gs},R_{gg},R_{ss}\\)等等。\n\\[R_s = A\\times V \\underset{s}{\\Rightarrow} U\\times B = \\int_{U\\times V}[\\mu_A(u)\\underset{s}{\\to}\\mu_B(v)]/(u,v) \\]\n其中\n\\[\\mu_A(u)\\underset{s}{\\to}\\mu_B(v) = \\left\\{\\begin{matrix} 1,\\mu_A(u)\\leq\\mu_B(v) \\\\ 0,\\mu_A(u)\u003e\\mu_B(v) \\end{matrix}\\right. \\]\n\\[R_s = A\\times V \\underset{g}{\\Rightarrow} U\\times B = \\int_{U\\times V}[\\mu_A(u)\\underset{g}{\\to}\\mu_B(v)]/(u,v) \\]\n其中\n\\[\\mu_A(u)\\underset{g}{\\to}\\mu_B(v) = \\left\\{\\begin{matrix} 1,\u0026\\mu_A(u)\\leq\\mu_B(v) \\\\ \\mu_B(v),\u0026\\mu_A(u)\u003e\\mu_B(v) \\end{matrix}\\right. \\]\n模糊判决方法 在推理得到的模糊集合中取一个相对最能代表这个模糊集合的单值的过程就称作解模糊（去模糊）或模糊判决(Defuzzification)。\n方法有：重心法、最大隶属度方法、加权平均法、隶属度限幅元素平均法等等。\n重心法 所谓重心法就是取模糊隶属函数曲线与横坐标轴围成面积的重心作为代表点。理论上应该计算输出范围内一系列连续点的重心，即\n\\[u = \\frac{\\int_x x\\mu_N(x)dx}{\\int_x \\mu_N(x)dx} \\]\n最大隶属度法 这种方法最简单，只要在推理结论的模糊集合中取隶属度最大的那个元素作为输出量即可。不过，要求这种情况下的隶属函数曲线一定是单峰曲线。如果该曲线是梯形平顶，那么具有最大隶属度的元素就可能不只一个，这时就要对所有取最大隶属度的元素求其平均值。\n系数加权平均法 \\[u = \\sum k_i\\cdot x_i/\\sum k_i \\]\n其中系数\\(k_i\\)的选择要根据实际情况而定。\n隶属度限幅元素平均法 用所确定的隶属度值 a对隶属度函数曲线进行切割，再对切割后大于等于该隶属度的所有元素进行平均，用这个平均值作为输出执行量，这种方法就称为隶属度限幅元素平均法。\n不确定性推理的基本概念 不确定性推理是建立在非经典逻辑基础上的一种推理，它是对不确定性知识的运用与处理。\n具体地说，所谓不确定性推理就是从不确定性的初始证据（即事实）出发，通过运用不确定性的知识，最终推出具有一定程度不确定性的结论。\n不确定性推理中的基本问题 不确定性的表示与度量 不确定性一般分为两类，一类是知识的不确定性，一类是证据的不确定性。\n知识不确定性的表示：目前在专家系统中知识的不确定性一般是由领域专家给出的，通常用一个数值表示，它表示相应知识的不确定性程度，称为知识的静态强度。\n证据不确定性的表示：证据不确定性的表示方法与知识不确定性的表示方法一致，通常也用一个数值表示，代表相应证据的不确定性程度，称之为动态强度。\n不确定性匹配算法及阈值的选择 推理是不断运用知识的过程,为了找到所需的知 识,需要在这一过程中用知识的前提与已知证据进 行匹配.只有匹配成功的知识才有可能被应用.\n组合证据不确定性的计算方法 即已知证据\\(E_1\\)和\\(E_2\\)的不确定性度量，求证据\\(E_1\\)和\\(E_2\\)的析取和合取的不确定性，常用的方法有：\n最大最小法 \\[T(E_1\\ AND\\ E_2) = \\min\\{T(E_1),T(E_2)\\} \\]\n\\[T(E_1\\ OR\\ E_2) = \\max\\{T(E_1),T(E_2)\\} \\]\n概率法 \\[T(E_1\\ AND\\ E_2) = T(E_1)\\times T(E_2) \\]\n\\[T(E_1\\ OR\\ E_2) = T(E_1)+T(E_2) - T(E_1)\\times T(E_2) \\]\n有界法 \\[T(E_1\\ AND\\ E_2) = \\max\\{0,T(E_1)+T(E_2)-1\\} \\]\n\\[T(E_1\\ OR\\ E_2) = \\min\\{1,T(E_1)+T(E_2)\\} \\]\n其中，\\(T(E)\\)表示证据\\(E\\)为真的程度（动态强度），如可信度、概率等。\n不确定性的传递算法 在每一步推理中，如何把证据及知识的不确定性传递给结论 在多步推理中，如何把初始证据的不确定性传递给最终结论 结论不确定性的合成 用不同知识进行推理得到了相同结论，但所得结论的 不确定性却不同。此时，需要用合适的算法对结论的 不确定性进行合成。\n不确定性推理方法的分类 不确定性推理方法主要可分为模型法与控制法。\n模型法：在推理一级对确定性推理进行扩展，引入证据的不确定性及知识的不确定性。\n模型方法又分为数值方法和非数值方法两类。数值方法对不确定性进行定量的描述，按其所依据的理论又可分为基于概率的方法和基于模糊理论的方法。\n本节主要针对模型方法中相关的典型算法展开.\n逆概率法 经典概率方法\n设有如下产生式规则： \\[\\text{IF\\quad E\\quad\\quad THEN\\quad H} \\]\n其中，\\(E\\)为前提条件，\\(H\\)为结论。条件概率\\(P(H|E)\\)可以作为在证据\\(E\\)出现时结论\\(H\\)的确定性程度，即规则的静态强度。\n对于复合条件 \\[E=E_1\\ \\text{AND}\\ E_2\\ \\text{AND}\\cdots\\text{AND}\\ E_n \\]\n当已知条件概率\\(P(H|E_1,E_2,\\cdots,E_n)\\)时，就可把它作为在证 据\\(E_1,E_2,\\cdots,E_n\\)出现时结论H的确定性程度。\n先验概率：\\(P(H)\\)，后验概率\\(P(H|E)\\) 经典概率方法要求给出条件概率\\(P(H|E)\\)，在实际中通常比较困难。例如\\(E\\)代表咳嗽，\\(H\\)代表支气管炎，则\\(P(H|E)\\)表示在咳嗽的人群中患支气管炎的概率，这个比较困难，因为样本空间太大。而\\(P(E|H)\\)表示在得支气管炎的人群中咳嗽的概率，这个就比较容易获得。我们可以根据Bayes定理从\\(P(E|H)\\)推出\\(P(H|E)\\)\n优点\n逆概率法有较强的理论背景和良好的数学特性，当证据彼此独立时计算的复杂度比较低。\n缺点\n逆概率法要求给出结论\\(H_i\\)的先验概率\\(P(H_i)\\)及条件概率\\(P(E_j|H_i)\\)。\n可信度方法 可信度方法是在确定性理论的基础上，结合概率论等提出的一种不确定性推理方法，简称C-F模型。该方法首先在医疗系统MYCIN中得到成功的应用。\n可信度的概念\n根据经验对一个事物和现象为真的相信程度称为可信度。\n在可信度方法中，由专家给出规则或知识的可信度，从而可避免对先验概率、或条件概率的要求。\n1.知识不确定性的表示 在C-F模型中，知识是用产生式规则表示的，其一般形式为：\n\\[\\text{IF}\\quad E\\quad \\text{THEN}\\quad H\\quad (CF(H,E)) \\]\n其中\n前提\\(E\\)可以是命题的合取和析取组合 结论\\(H\\)可为单一命题，也可以是复合命题 \\(CF(H,E)\\)为确定性因子(Certainty factor)，简称可信度，用以量度规则的确定性（可信）程度。取值于\\([-1，1]\\)，表示\\(E\\)为真时，对\\(H\\)的支持程度。\\(CF(H,E)\\)值越大，\\(E\\)就越支持\\(H\\)为真。 可信度因子的定义\n\\(CF(H,E)\\)定义为\n\\[CF(H,E) = MB(H,E) - MD(H,E) \\]\nMB反映了证据对结论有利的一面，MD反映了证据对结论不利的一面。MB(Measure Belief) 表示因与\\(E\\)匹配的证据出现，使\\(H\\)为真的信任增长度。MD(Measure Disbelief)指不信任增长度，表示因与\\(E\\)匹配的证据出现，使\\(H\\)为真的不信任增长度。 MB和MD的定义为：\n\\[MB(H,E) = \\left\\{\\begin{matrix} 1 \u0026 ,P(H)=1\\\\ \\dfrac{max\\{P(H|E),P(H)\\}-P(H)}{1-P(H)} \u0026 ,\\text{other} \\end{matrix}\\right. \\]\n\\[MD(H,E) = \\left\\{\\begin{matrix} 1 \u0026 ,P(H)=0\\\\ \\dfrac{min\\{P(H|E),P(H)\\}-P(H)}{-P(H)} \u0026 ,\\text{other} \\end{matrix}\\right. \\]\n当\\(P(H|E)\u003eP(H)\\)时：表示证据E支持结论\\(H\\)，\\(MB(H,E)\u003e0，MD(H,E)=0\\)。 当\\(P(H|E)\u003c P(H)\\)时，表示\\(E\\)不支持\\(H\\)，\\(MD(H,E)\u003e0， MB(H,E)=0\\)。当\\(p(H|E)=p(H)\\)时，表示\\(E\\)对\\(H\\)无影响，则有\\(MB=MD=0\\) \\(MB(H,E)\\)与\\(MD(H,E)\\)是互斥的：当\\(MB(H,E)\u003e0\\)时，\\(MD(H,E)=0\\);当\\(MD(H,E)\u003e0\\)时，\\(MB(H,E)=0\\) \\(CF(H,E)\\)的计算公式\n根据上述定义，可知\n\\[CF(H,E) = \\left\\{\\begin{matrix} MB(H,E)-0=\\dfrac{P(H|E)-P(H)}{1-P(H)} \u0026 ,P(H|E) \u003e P(H)\\\\ 0 \u0026 ,P(H|E)=P(H)\\\\ 0-MD(H,E)=-\\dfrac{P(H)-P(H|E)}{P(H)}\u0026 ,P(H|E) \u003c P(H) \\end{matrix}\\right. \\]\n从上式可以看出\n\\(CF(H,E)\u003e0\\)对应于\\(P(H|E)\u003eP(H)\\)\n\\(CF(H,E)=0\\)对应于\\(P(H|E)=P(H)\\)\n\\(CF(H,E) \u003c 0\\)对应于\\(P(H|E) \u003c P(H)\\)\n当且仅当\\(P(H|E)=1\\)时,\\(CF(H,E)=1\\)\n当且仅当\\(P(H|E)=0\\)时,\\(CF(H,E)=-1\\)\n\\(CF(H,E)\\)定性地反映了\\(P(H|E)\\)的大小,因此可以用\\(CF(H,E)\\)近似表示\\(P(H|E)\\)的大小,从而描述了规则的可信度。\n2.证据不确定性的表示 证据的不确定性也用可信度因子表示。如：\\(CF(E)=0.6\\)\n\\(CF(E)\\)的取值范围：\\([-1，+1]\\)。\n\\(CF(E)\u003e0\\):表示证据以某种程度为真。\n\\(CF(E)\u003c0\\):表示证据以某种程度为假。\n\\(CF(E)\\)表示证据的强度，即动态强度。\n设证据E所在的环境为\\(S\\)，则可用可信度\\(CF(E,S)\\)来表示\\(E在$S\\)下的确定性程度，并有：\n\\[CF(E,S) = MB(E,S)-MD(E,S) \\]\n若\\(S\\)下\\(E\\)为真，则\\(CF(E,S) = 1\\)；\n若\\(E\\)为假，则\\(CF(E,S) =-1\\)；\n若\\(S\\)对\\(E\\)的真值无影响，则\\(CF(E,S)= 0\\)。\n类似于规则的不确定性，证据的可信度往往可由领域专家凭经验主观确定。\n证据的可信度值来源于两种情况：\n初始证据由领域专家或用户给出； 中间结论由不确定性传递算法计算得到。 3.组合证据不确定性的算法 当组合证据是多个单一证据的合取时，即: \\[E=E_1\\ \\text{AND}\\ E_2\\ \\text{AND}\\cdots\\text{AND}\\ E_n \\]\n则\\(CF(E)=min\\{CF(E_1),CF(E_2),\\cdots,CF(E_n)\\}\\)\n当组合证据是多个单一证据的析取时，即: \\[E=E_1\\ \\text{OR}\\ E_2\\ \\text{OR}\\cdots\\text{OR}\\ E_n \\]\n则\\(CF(E)=max\\{CF(E_1),CF(E_2),\\cdots,CF(E_n)\\}\\)\n4. 不确定性的传递 不确定性的传递算法定义如下：\n\\[CF(H) = CF(H,E)\\times max\\{0,CF(E)\\} \\]\n由上式可以看出:\n\\(CF(E)\u003c0\\)时,\\(CF(H)=0\\),说明该模型没有考虑证据为假时对结论\\(H\\)所产生的影响。 \\(CF(E)=1\\)时,\\(CF(H)=CF(H,E)\\),说明规则可信度\\(CF(H,E)\\)就是证据为真时的结论\\(H\\)的可信度。 5. 结论不确定性的合成算法 若由多条不同知识推出了相同的结论，但可信度不同，则可用合成算法求出综合的可信度。由于对多条知识的综合可通过两两的合成实现，所以下面只考虑两条知识的情况。\n设有如下知识：\n\\[\\text{IF}\\quad E_1\\quad \\text{THEN}\\quad H\\quad\\quad (CF(H,E_1)) \\]\n\\[\\text{IF}\\quad E_2\\quad \\text{THEN}\\quad H\\quad\\quad (CF(H,E_2)) \\]\n则结论H的综合可信度可分为如下两步算出：\n首先分别对每一条知识求出\\(CF(H)\\) \\[CF_1(H) = CF(H,E_1)\\times max\\{0,CF(E_1)\\} \\]\n\\[CF_2(H) = CF(H,E_2)\\times max\\{0,CF(E_2)\\} \\]\n然后用下述公式求出\\(E_1\\)与\\(E_2\\)对\\(H\\)的综合可信度\\(CF_{12}(H)\\): \\[CF_{12}(H) = \\left\\{\\begin{matrix} CF_1(H)+CF_2(H)-CF_1(H)\\times CF_2(H) \u0026,CF_1(H)\\geq 0,CF_2(H)\\geq 0\\\\ CF_1(H)+CF_2(H)+CF_1(H)\\times CF_2(H) \u0026,CF_1(H)\u003c0,CF_2(H)\u003c0\\\\ \\dfrac{CF_1(H)+CF_2(H)}{1-min\\{|CF_1(H)|,|CF_2(H)|\\}} \u0026,CF_1(H)\\times CF_2(H)\u003c0\\\\ \\end{matrix}\\right. \\]\n冲突消解\n\\[r_1: \\text{IF}\\quad \\{E_1(\\omega_1)\\}\\quad \\text{THEN}\\quad H_1\\quad\\quad (CF(H_1,E_1),\\lambda_1) \\]\n\\[r_2: \\text{IF}\\quad \\{E_2(\\omega_2)\\}\\quad \\text{THEN}\\quad H_2\\quad\\quad (CF(H_2,E_2),\\lambda_2) \\]\n且\\(CF(\\{E_1(\\omega_1)\\})\\geq\\lambda_1,CF(\\{E_2(\\omega_2)\\})\\geq\\lambda_2\\)\n若\\(CF(\\{E_1(\\omega_1)\\})\\geq CF(\\{E_2(\\omega_2)\\})\\)，则优先使用\\(r_1\\)进行推理。\n加权的不确定性推理 1. 知识的不确定性的表示 \\[\\text{IF}\\quad \\{E_1(\\omega_1)\\}\\quad \\text{AND}\\quad \\{E_2(\\omega_2)\\}\\quad \\text{AND}\\cdots\\text{AND}\\quad \\{E_n(\\omega_n)\\} \\]\n\\[\\text{THEN}\\quad H\\quad (CF(H,E),\\lambda) \\]\n其中\\(\\omega_i(i=1,2,\\cdots,n)\\)是加权因子，\\(λ\\)是阈值，其值均由专家给出。\n其中\n\\[0\\leq \\omega_i\\leq 1,\\sum\\omega_i=1 \\]\n2. 组合证据不确定性的算法 若有\\(CF(E_1),CF(E_2),\\cdots,CF(E_n)\\)，则组合证据的可信度为：\n\\[CF(E)=\\sum(\\omega_i\\times CF(E_i)) \\]\n3. 不确定性的传递算法 当一条知识的\\(CF(E)\\)满足如下条件时，\n\\[CF(E)\\geq\\lambda \\]\n该知识就可被应用。结论\\(H\\)的可信度为：\n\\[CF(H) = CF(H,E)\\times CF(E) \\]\n加权因子的引入不仅可以区分不同证据的重要性同时还可以解决证据不全时的推理问题。\n基于可信度的不确定性推理方法的特点\n优点\n简单、直观。\n缺点\n可信度因子依赖于专家主观指定，没有统一、客观的尺度，容易产生片面性。\n随着推理延伸，可信度越来越不可靠，误差越来越大。当推理深度达到一定深度时，有可能出现推出的结论不再可信的情况。\n遗传算法 计算智能 计算智能就是受自然界（生物界）规律的启迪，根据其原理，模仿设计求解问题的算法。\n计算智能:生物智能的计算模拟, 是一种智力方式的低层认知，它与人工智能的区别只是认知层次从中层下降至低层而已。中层系统含有知识，低层系统则没有。\n当一个系统只涉及数值（低层）数据，含有模式识别部分，不应用人工智能意义上的知识，而且能够呈现出：\n计算适应性 计算容错性 接近人的速度 误差率与人相近 则该系统就是计算智能系统。\n当一个智能计算系统以非数值方式加上知识，即成为人工智能系统。\n进化计算 进化计算是一类模拟生物进化过程与机制求解问题的自组织、自适应技术。\n生物种群的生存过程普遍遵循达尔文的物竞天择、适者生存的进化准则；生物通过个体间的选择、交叉、变异来适应大自然环境。\n依照达尔文的自然选择和孟德尔的遗传变异理论，生物的进化是通过繁殖、变异、竞争、选择来实现的，进化算法就是建立在上述生物模型基础上的一种随机搜索技术。\n几十年来的研究与应用已经清楚地表明：虽然模拟自然进化搜索过程的一些模型还只是自然界生物体的粗糙简化，但是已经可以产生非常鲁棒的计算方法。\n进化算法（Evolutionary Algorithm—EA）就是基于这种思想发展起来的，目前研究的进化算法主要有三种典型的算法：遗传算法、进化规划和进化策略。这三种算法是彼此独立发展起来的。\n种群搜索策略和种群中个体之间的信息交换是进化算法的两大特点。它们的优越性主要表现在：\n进化算法在搜索过程中不容易陷入局部最优 由于它们固有的并行性，进化算法非常适合于并行机 由于它们容易介入到已有的模型中并且具有可扩展性，以及易于同别的技术混合等因素，因而进化算法目前已经在最优化、机器学习和并行处理等领域得到越来越广泛的应用。 基本思想 遗传算法把问题的解表示成“染色体”，在算法中即是以一定方式编码的串。并且，在执行遗传算法之前，给出一群“染色体”，也即假设解（候选解）。然后，把这些假设解置于问题的“环境”中，并按适者生存的原则，从中选择出较适应环境的“染色体”进行复制，再通过交叉，变异过程产生更适应环境的新一代“染色体”群。这样，一代一代地进化，最后就会收敛到最适应环境的一个“染色体”上，它就是问题的最优解。\n其算法框图为\n4.jpg\r一些基本概念 串(String) 它是个体(Individual)的形式，在算法中为二进制串或者其它编码方式的串，并且对应于遗传学中的染色体(Chromosome)。 种群(Population) 个体的集合称为种群，串是种群的元素 种群规模(Population Size) 在种群中个体的数量称为种群的规模。 基因(Gene) 基因是串中的元素，基因用于表示个体的特征 适应度(Fitness) 表示某一个体对于环境的适应程度 基本机理 一般的遗传算法由四个部分组成: 编码机制、适应度函数、控制参数、遗传算子 编码机制(encoding mechanism) 用遗传算法解决问题时，首先要对待解决问题的模型结构和参数进行编码，一般用字符串表示。 编码机制是GA的基础 GA不是对研究对象直接进行讨论,而是通过某种编码机制把对象统一赋于由特定符号(字母)按一定顺序排成的串(string)。正如研究生物遗传,是从染色体着手,染色体则是由基因排成的串。 适应度函数 优胜劣败是自然进化的原则。优、劣要有标准。在GA中，用适应度函数描述每一个体的适应程度。 对优化问题,适应度函数与目标函数直接相关。引进适应度函数的目的在于可根据其适应度对个体进行评估比较,定出优劣程度。 在遗传算法的执行过程中,每一代有许多不同的个体(染色体)同时存在。这些染色体中哪个保留(生存)、哪个淘汰(死亡),是根据它们对环境的适应能力来决定的,适应性强的有更多的机会保留下来。 适应性强弱是通过计算适应度函数f(x)的值来判别的,这个值称为适应值。适应度函数f(x)的构成与目标函数有密切关系。 算法参数；在GA的实际操作时,需适当确定某些参数的值以提高选优的效果。这些参数包含： 字符串所含字符的个数,即串长。这一长度为常数,即为定长,记为\\(L\\) 每一代种群的大小,即所包含字符串的个数,也称种群规模,记为\\(n\\) 交叉概率(crossover rate),即施行交叉算子的概率,记为\\(P_c\\) 变异概率(mutation rate),即施行变异算子的概率,记为\\(P_m\\) 在GA中,种群规模\\(n\\)太小时难以求出最优解，太大则增长收敛时间。一般\\(n=30\\sim 160\\)。 交叉概率\\(P_c\\)太小时难以向前搜索，太大则容易破坏高适应值的结构。一般取\\(P_c=0.25\\sim 0.75\\)。 变异概率\\(P_m\\)太小时难以产生新的基因结构，太大使遗传算法成了单纯的随机搜索。一般取\\(P_m=0.01\\sim 0.2\\)。系统参数对算法的收敛速度及结果有很大的影响，应视具体问题选取不同的值。 遗传算子 选择算子(Selection/Reproduction): 选择算子从 种群中按某一概率成对选择个体，某个体\\(x_i\\)被选择的概率\\(P_i\\)与其适应度值成正比。最通常的实现方法是轮盘赌(roulette wheel)模型。 交叉算子(Crossover): 交叉算子将被选中的两个个体的基因链按概率\\(P_c\\)进行交叉，生成两个新的个体，交叉位置是随机的。其中\\(P_c\\)是一个系统参数。 变异算子(Mutation): 变异算子将新个体的基因链的各位按概率\\(P_m\\)进行变异，对二值基因链(0,1编码)来说即是取反。上述各种算子的实现是多种多样的，而且许多新的算子正在不断地提出，以改进GA的某些性能。 编码与解码 GA中的编码方法可分为三大类：二进制编码方法、浮点数编码方法和符号编码方法。\n二进制编码方案\n是GA中最常用的一种编码方法。它所构成的个体基因型是一个二进制编码符号串。\n二进制编码符号串的长度与问题所要求的求解精度有关。设某一参数的取值范围是\\([A, B]，A\u003c B\\)。则二进制编码的编码精度为：\n\\[\\delta = \\dfrac{B-A}{2^l-1} \\]\n假设某一个体的编码是：\\(X:b_lb_{l-1}b_{l-2}\\cdots b_2b_1\\)，则对应的解码公式为：\n\\[x = A+\\dfrac{B-A}{2^l-1}\\bigg(\\sum^l_{i=1}b_i2^{i-1}\\bigg) \\]\n格雷码\n格雷码是这样的一种编码方法，其连续的两个整数所对应的编码值之间仅仅有一个码位是不相同的，其余码位都完全相同。\n浮点编码\n所谓浮点数编码方法是指个体染色体编码串中的基因值用某一范围内的一个浮点数来表示，个体的编码长度等于其决策变量的个数。因为这种编码方法使用的是决策变量的真实值，所以浮点数编码方法也叫做真值编码方法。\n符号编码\n符号编码方法是指个体染色体编码串中的基因值取自一个无数值含义、而只有代码含义的符号集。\n这个符号集可以是一个字母表，如\\(\\{A,B,C,D,\\cdots\\}\\)；也可以是一个数字序号表，如\\(\\{1,2,3,\\cdots\\}\\)；还可以是一个代码表，如\\(\\{A_1,A_2,A_3,\\cdots\\}\\)等等。\n适应度函数 为了体现染色体的适应能力，引入了对问题中的每一个染色体都能进行度量的函数，叫适应度函数。通过适应度函数来衡量染色体的优、劣程度，它体现了自然进化中的优胜劣汰原则。一般，对于最大化的优化问题，适应度函数就是目标函数。\n交叉算子 对于选中用于繁殖下一代的个体，随机地选择两个个体的相同位置，按交叉概率\\(P_c\\)在选中的位置实行交叉。这个过程反映了随机信息交换；\n目的在于产生新的基因组合，也即产生新的个体。交叉时，可实行单点交叉或多点交叉。\n例如有个体\n\\[P1 = 10010110\\\\ P2 = 01011110 \\]\n选择它们的左边\\(3\\)位进行交叉操作，则有\n\\[P1 = 01010110\\\\ P2 = 10011110 \\]\n变异算子 根据生物遗传中基因变异的原理，以变异概率\\(P_m\\)对某些个体的某些位执行变异。\n在变异时，对执行变异的串的对应位求反，即把\\(1\\)变为\\(0\\)，把\\(0\\)变为\\(1\\)。\n变异概率\\(P_m\\)与生物变异极小的情况一致，所以，\\(P_m\\)的取值较小。\n变异能保证算法过程不会产生无法进化的单一种群。因为在所有的个体一样时，交叉是无法产生新的个体的，这时只能靠变异产生新的个体。\n选择算子 选择操作：根据适应度函数值所度量的个体的优、劣程度决定它在下一代是被淘汰还是被保留。\n简单遗传算法采用轮盘赌选择机制\n轮盘赌选择机制\n令\\(\\sum f_i\\)表示种群的适应度值之总和，\\(f_i\\)表示种群中第\\(i\\)个染色体的适应度值，则它产生后代的能力正好为其适应度值所占份额\\(f_i/\\sum f_i\\)。\n显然，从上式可知：\n适应度较高的个体，繁殖下一代的能力就较强。 适应度较小的个体，繁殖下一代的能力就较弱，甚至被淘汰。 这样，就产生了对环境适应能力较强的后代。对于问题求解角度来讲，就是选择出和最优解较接近的中间解。\n停止条件 完成了预先给定的进化代数则停止； 种群中的最优个体在连续若干代没有改进 平均适应度在连续若干代基本没有改进时停止 特点 遗传算法是从问题解的编码组开始而非从单个解开始搜索； 遗传算法利用目标函数的适应度这一信息而非利用导数或其它辅助信息来指导搜索； 遗传算法利用选择、交叉、变异等算子而不是利用确定性规则进行随机操作。 不足 在变量多，取值范围大或无给定范围时，收敛速度下降； 可找到最优解附近，但无法精确确定最优解位置； 遗传算法的参数选择尚未有定量方法。 进化策略概述 进化策略 (Evolution Strategies，ES)是一类模仿自然进化原理以求解参数优化问题的算法。\n进化策略与遗传算法的结构类似，只是在算法的具体策略上存在差异。\n染色体编码：浮点数编码 交叉：离散重组、中值重组、混杂重组 变异：在每个分量上面加上零均值、某一方差的高斯分布的变化产生新的个体 选择：\\((\\mu+\\lambda)-ES\\)、\\((\\mu, \\lambda)-ES\\) 进化规划概述 进化规划（Evolutionary Programming）又称为进化编程，是由福格尔（Fogel）在1962年提出的一种模仿人类智能的方法。进化规划根据正确预测的符号数来度量适应值。通过变异，为父代群体中的每个机器状态产生一个子代。父代和子代中最好的部分被选择生存下来。\n5.jpg\r遗传算法、进化策略、进化规划的对比 进化计算的三种算法——遗传算法、进化策略和进化规划都是模拟生物界自然进化过程而建立的鲁棒性计算机算法。在统一框架下对三种算法进行比较，可以发现它们有许多 相似之处，同时也存在较大的差别。\n进化策略和进化规划都把变异作为主要搜索算子，而在标准的遗传算法中，变异只处于次要位置。交叉在遗传算法中起着重要作用，而在进化规划中却被完全省去，在进化策略中与自适应结合使用，起了很重要的作用。标准遗传算法和进化规划都强调随机选择机制的重要性，而从进化策略的角度看，选择是完全确定的。\n6.jpg\r进化计算的应用 复杂的非线性最优化问题 复杂的组合规划或整数规划问题 生物学：小生境理论、生物物种的形成 计算机科学：图像处理、自动识别、文档自动处理 工程应用：通讯网络的优化、超大规模集成电路布线、飞机外形设计 社会科学：人类行为规范进化过程的模拟、人口迁移模型 人工生命 人工生命(试图通过人工方法建造具有自然生命特征的人造系统。人工生命(Artificial Life ，AL))\n1987年兰德提出的人工生命定义为：“人工生命是研究能够演示出自然生命系统特征行为的人造系统”。\n人工生命的研究内容 人工生命的研究对象包括人工动物、人工植物和人工人等，而人工人的研究又涉及人工脑和其它人工器官。\n研究内容包括\n构成生物体的内部系统，包括脑、神经系统、内分泌系统、免疫系统、遗传系统、酶系统、代谢系统等。 生物体及其种群的外部系统，包括环境适应系统和遗传进化系统等。 人工生命的科学框架 生命现象仿生系统 生命现象的建模与仿真 进化动力学 人工生命的计算理论和工具 进化机器人 进化和学习等方面的结合 人工生命的应用 人工生命的研究方法 从生物体内部和外部系统的各种信息出发，可得到人工生命的不同研究方法，主要可分为两类：\n信息模型法。 工作原理法。 人工生命的研究技术途径也可分为两种：\n工程技术途径。 生物科学途径。 人工生命的实例 人工脑、计算机病毒、计算机进程、细胞自动机、人工核苷酸\n群智能算法 群智能概述 群智能（Swarm Intelligence, SI）\n群（swarm）：某种交互作用的组织或agent的结构集合。\n对于群居昆虫，如蚂蚁、蜜蜂、鱼群、鸟群等，个体在结构上是很简单的，而它们的集体行为却可能变得相当复杂。\n人们把群居昆虫的集体行为称作“群智能”，即低智能的主体通过合作表现出高智能行为的特性。\n群智能算法是一种基于生物群体行为规律的计算技术。\n特点\n个体的行为很简单，但当它们一起协同工作时却能够突现出非常复杂（智能）的行为特征。\n群智能优化在没有集中控制且不提供全局模型的前提下，为寻找复杂的分布式问题求解方案提供了基础。\n优点\n灵活性：群体可以适应随时变化的环境； 稳健性：个体失败，群体仍能完成任务； 自组织：活动既不受中央控制，也不受局部监管。 典型算法\n粒子群优化算法（鸟群捕食），蚁群算法（蚂蚁觅食）\n粒子群优化算法 简述\n粒子群优化算法（Particle Swarm Optimization，PSO），也称为粒子群算法，是近几年来发展起来的一种新的群体搜索算法。\n和遗传算法相似，它也是从随机的解出发，通过迭代寻找最优解，通过适应度来评价解的品质。\n比遗传算法规则更为简单，它没有遗传算法的“交叉”(Crossover) 和“变异”(Mutation) 操作，而是追随当前搜索到的最优值来寻找全局最优。\n原理描述\n假设存在一个区域，所有的鸟都不知道食物的位置，但是它们知道当前的位置离食物还有多远。找到食物的最优策略是什么呢？搜寻目前离食物最近的鸟的周围区域。\n在该算法中，每个解看作一只鸟，称为粒子(particle)，所有的粒子都有一个适应值，每个粒子都有一个速度决定它们的飞翔方向和距离，粒子们追随当前最优粒子在解空间中搜索。\n当其它鸟发现了更佳的觅食地点，鸟群间会有某种类似广播的沟通行为，渐渐的将其它鸟群引领至较佳的地点。这样的觅食行为是利用社会中所存在的互相影响的概念，来引领所有个体朝向最佳解位置。\n假设在D维搜索空间中，有m个粒子；\n其中第i个粒子的位置矢量表示为： \\[\\overrightarrow{x_i} = (x_{i1},x_{i2},\\cdots,x_{iD}) \\]\n飞翔速度矢量表示为： \\[\\overrightarrow{v_i} = (v_{i1},v_{i2},\\cdots,v_{iD}) \\]\n第 i个粒子搜索到的最优位置为： \\[\\overrightarrow{p_i} = (p_{i1},p_{i2},\\cdots,p_{iD}) \\]\n整个粒子群搜索到的最优位置为： \\[\\overrightarrow{p}_{gbest} = (p_{gbest1},p_{gbest2},\\cdots,p_{gbestD}) \\]\n粒子速度和位置的更新\n\\[v_{id}^{k+1} = wv_{id}^k+c_1\\text{rand}()(p_{id}-x_{id}^k)+c_2\\text{rand}()(p_{gbest}-x_{id}^k) \\]\n\\[x_{id}^{k+1} = x_{id}^k + v_{id}^{k+1} \\]\n其中\\(w\\)为惯性权重，\\(d=1,2,\\cdots,D,\\quad i=1,2,\\cdots,M\\)。\\(c_1,c_2\\)为两个正常数称为加速因子，\\(\\text{rand}()\\)为分布于\\([0,1]\\)的随机数\n\\(v_{id}^{k+1}\\)分为三项，第一项是惯性部分，第二项是认知部分，第三项是社会部分\n7.jpg\r参数分析\n惯性权重\\(w\\) 使粒子保持运动惯性，使其有搜索扩展空间的趋势，有能力探索新的区域。\n也表示微粒对当前自身运动状态的信任，依据自身的速度进行惯性运动。\n较大的\\(w\\)有利于跳出局部极值，而较小的\\(w\\)有利于算法收敛。\n改进的惯性权重\\(w\\) 在优化实际优化问题时，往往希望先采用全局搜索，使搜索空间快速收敛于某一区域，然后采用局部精细搜索以获得高精度的解。\n因此提出了自适应调整的策略，即随着迭代的进行，线性地减小\\(w\\)的值。\n\\[w = w_{\\text{max}} - \\dfrac{w_{\\text{max}}-w_{\\text{min}}}{iter_{\\text{max}}}\\times iter \\]\n其中\\(iter,iter_{\\text{max}}\\)分别是当前迭代次数和最大迭代次数\n加速因子\\(c_1,c_2\\) 使代表将微粒推向\\(pbest\\)和\\(gbest\\)位置的统计加速项的权重。\n表示粒子的动作来源于自己经验的部分和其它粒子经验的部分。\n低的值粒子在目标区域外徘徊，而高的值导致粒子越过目标域。\n改进的加速因子\\(c_1\\)和\\(c_2\\) 通常将\\(c_1\\)和\\(c_2\\)统一为一个控制参数，\\(\\varphi=c_1+c_2\\)\n如果\\(\\varphi\\)很小，微粒群运动轨迹将非常缓慢；\n如果\\(\\varphi\\)很大，则微粒位置变化非常快；\n通过仿真可以获得\\(\\varphi\\)的经验值，当\\(\\varphi=4.0(c_1=2.0,c_2=2.0)\\)时，具有很好的收敛效果。\n粒子数 通常一般取20～40，对较难或特定类别的问 题可以取100～200。\n最大速度\\(v_{max}\\) 决定粒子在一个循环中最大的移动距离，通常设定为粒子的范围宽度。\n粒子群算法与遗传算法的比较\n共性：\n都属于仿生算法； 都属于全局优化方法； 都属于随机搜索算法； 都隐含并行性； 根据个体的适配信息进行搜索，因此不受函数约束条件的限制，如连续性、可导性。 对高维复杂问题，无法保证收敛到最优点。 差异：\nPSO有记忆，所有粒子都保存较优解的知识，而GA，以前的知识随着种群的改变被改变； PSO中的粒子是一种单向共享信息机制。而GA中的染色体之间相互共享信息； GA需要编码和遗传操作，粒子只是通过内部速度进行更新，实现更容易。 蚁群算法 蚂蚁可以找出最短路径，为什么？\n信息素（pheromone）：蚂蚁在寻找食物时，其经过的路 上释放的一种易挥发的物质。该信息素 可以被其它的蚂蚁感知，并且信息素的浓度越高，对应的路径越短。\n正反馈：蚂蚁会以较大的概率选择信息素浓度较高的路径，并释放一定量的信息素以增强该路径上的信息素浓素，从而距离较短的路径被加强，形成一个正反馈。\n蚁群算法的模型与实现\u0026mdash;-TSP\n不失一般性设蚂蚁的数量为\\(m\\)，城市的数量为\\(n\\)，城市\\(i\\)和城市\\(j\\)的距离为\\(d(i,j)\\)，距离选用欧式距离，\\(t\\)时刻城市\\(i\\)和城市\\(j\\)连接路径的信息素浓度为\\(\\tau(i,j)\\)。\n在算法初始时刻，设各城市连接路径的信息素浓度具有相同的值，\\(m\\)只蚂蚁放到\\(n\\)座城市。\n蚂蚁的初始分布\n所有蚂蚁初始时刻放在同一城市。 所有蚂蚁初始时刻分布在不同城市中。 显而易见，第二种方法将蚂蚁放在不同的城市中算法具有较高的性能。在不同城市分布时，随机分布与统一均匀分布的效果差别不大。\n每只蚂蚁根据路径上的信息素和启发式信息，独立地访问下一座城市，概率公式如下 \\[p^k(i,j)=\\left\\{\\begin{align*} \u0026 \\dfrac{[\\tau(i,j)]^\\alpha\\cdot[\\eta(i,j)]^\\beta}{\\displaystyle{\\sum_{s\\notin tabu_k}}[\\tau(i,s)]^\\alpha\\cdot[\\eta(i,s)]^\\beta},\\ \u0026if\\ j\\notin tabu_k\\\\ \u0026 0,\\ \u0026otherwise \\end{align*}\\right. \\]\n其中\\(\\eta(i,j) = 1/d(i,j)\\)是启发函数，表示蚂蚁从城\\(i\\)到城\\(j\\)的期望程度，距离越短函数值越大。\n\\(\\alpha\\)是信息素重要程度因子。\\(\\beta\\)是启发函数重要程度因子。\n\\(tabu_k\\)为禁忌表，表示已经访问的城市集合\n蚂蚁从当前城市访问下一城市的概率确定后，通常采用轮盘赌法选择下一城市，概率大被选中机会就大。\n当所有蚂蚁完成一次访问后，各路径上的信息素将进行更新，信息素公式更新如下\n\\[\\tau_{i,j}(t+1) = (1-\\rho)\\cdot\\tau_{i,j}(t)+\\Delta\\tau_{ij} \\]\n\\[\\Delta\\tau_{ij} = \\sum^m_{k=1}\\Delta\\tau_{ij}^k \\]\n其中\\(ρ\\)的取值为\\(0\u003cρ\u003c1\\)，表示路径上信 素的挥发系数。\n针对蚂蚁释放信息素问题，比较常用的有如下三种模型： Ant cycle system\n\\[\\Delta\\tau^k_{ij}=\\left\\{\\begin{align*} \u0026 \\dfrac{Q}{L_k},\\ \u0026ij\\in l_k\\\\ \u0026 0,\\ \u0026otherwise \\end{align*}\\right. \\]\n\\(Q\\)为正常数，\\(L_k\\)表示第\\(k\\)只蚂蚁在本次访问城市中所走过路径的长度\nAnt quantity system\n\\[\\Delta\\tau^k_{ij}=\\left\\{\\begin{align*} \u0026 \\dfrac{Q}{D_{ij}},\\ \u0026ij\\in l_k\\\\ \u0026 0,\\ \u0026otherwise \\end{align*}\\right. \\]\n\\(Q\\)为正常数，\\(D_{ij}\\)表示第\\(k\\)只蚂蚁在本次访问中城市\\(i\\)和城市\\(j\\)的距离\nAnt density system\n\\[\\Delta\\tau^k_{ij}=\\left\\{\\begin{align*} \u0026 Q,\\ \u0026ij\\in l_k\\\\ \u0026 0,\\ \u0026otherwise \\end{align*}\\right. \\]\n\\(Q\\)为正常数，在整个访问过程中密度始终保持不变。\n这三种模型分别对应路径的整体信息（蚂蚁所访问路径的总长）、局部信息（蚂蚁所访问城市间的距离）和不考虑路径信息。\n以下优化TSP问题，选用ant cycle system模型，即路径的整体信息路径越短，释放的信息素度越高\n蚁群算法解决TSP问题基本流程 8.jpg\r优点\n蚁群算法与其他启发式算法相比，在求解性能上，具有很强的鲁棒性（对基本蚁群算法模型稍加修改，便可以应用于其他问题）和搜索较好解的能力。 蚁群算法是一种基于种群的进化算法，具有本质并行性，易于并行实现。 蚁群算法很容易与多种启发式算法结合如遗传算法、粒子群算法，以改善算法性能。 不足\n如果初始化参数设置不当，导致求解速度很慢且所得解的质量特别差。 基本蚁群算法即无改进的蚁群算法计算量大，求解所需时间较长。 基本蚁群算法理论上要求所有的蚂蚁选择同一路线，该线路即为所求的最优线路；但在实际计算中，在给定一定循环数的条件下很难达到这种情况。 改进\n最优解保留策略（Ant System with Elitist）该策略能够以更快的速度获得最好解，但是如果选择的精英过多则算法会由于较早收敛于局部次优解而导致搜索的过早停滞。 局部信息素更新使已选的路径对后来的蚂蚁具有较小的影响力，从而使蚂蚁对没有选中的路径有更强的探索能力。 最大\u0026ndash;最小蚂蚁系统（max-min ant system） 每次迭代后，只有最优解（最优蚂蚁）所属路径上的信息被更新； 为了避免过早收敛，将各条路径可能的信息素限制于\\([\\tau_{min},\\tau_{max}]\\)； 在算法初始时刻，\\(\\rho\\)取较小值，算法有更好的发现较好解的能力。随着迭代次数的增加，\\(\\rho\\)变大加快算法的收敛。 群智能优化的特点与不足 共同特点：\n基于概率计算的随机搜索进化算法，在结 构、研究内容、方法以及步骤上有较大的相似性；结果偏随机性。\n存在的问题：\n数学理论基础相对薄弱； 参数设置没有确切的理论依据，对具体问题和应用环境的依赖性大； 进一步的改进：\n进一步研究真实群居动物的行为特征，建立合适的数学模型； 进一步研究算法的收敛性； 进一步提高收敛速度，从而解决大规模优化问题； 进一步研究各种参数设置问题； 研究群智能的并行算法； 进一步研究各算法的适用范围； 研究与其它算法的混合技术。 人工神经网络 神经计算 智慧（思维）是人的大脑的功能的表现。\n大脑是由无数的脑细胞组成。既然“思维”是大脑的功能的表现，即智慧是脑神经网络的功能。那么人们希望利用人工神经网络来模拟人脑的神经网络，研究其性能，希望从中悟出人的思维的一些“奥秘”。这就是所谓的人工神经网络技术，这种技术为人工智能提供新的解决问题的方法,并广泛应用于各个领域。\n生物神经系统 生物神经系统是一个有高度组织和相互作用的数量巨大的细胞组织群体。\n神经细胞也称神经元，是神经系统的基本单元，它们按不同的结合方式构成了复杂的神经网络。通过神经元及其联接的可塑性，使得大脑具有学习、记忆和认知等各种智能。\n生物神经元主要由以下3个部分组成：\n细胞体，是神经细胞的本体; 树突，用于接受来自其它细胞元的信号; 轴突，用于输出信号，与多个神经元连接; 突触，是神经元之间相互连接的的接口部分，即一个神经元的神经末梢与另一个神经元的树突相接触的交界面，位于神经元的神经末梢尾端。\n生物神经元的基本工作机制\n一个神经元有两种状态-兴奋和抑制。\n平时处于抑制状态的神经元，其树突和细胞体接受其它神经元经由突触传来的兴奋电位，多个输入在神经元中以代数和的方式叠加。\n如输入兴奋总量超过阈值，神经元被激发进入兴奋状态，发出输出脉冲，由轴突的突触传递给其它神经元。\n生物神经特性\n并行分布处理的工作模式。 神经系统的可塑性和自组织性。 信息处理与信息存贮合二为一。 信息处理的系统性。 能接受和处理模糊的、模拟的、随机的信息。 求满意解而不是精确解。 系统的恰当退化和冗余备份(鲁棒性和容错性) 人工神经网络 人工神经网络（Artificial Neural Network，ANN）是由大量处理单元经广泛互连而组成的人工网络，用来模拟脑神经系统的结构和功能。而这些处理单元称作人工神经元。\n人工神经网络的结构\n人工神经网络（ANN）可以看成是以人工神经元为结点，用有向加权弧连接起来的有向图。\n在此有向图中，人工神经元就是对生物神经元的模拟，而有向弧则是树突—突触—轴突对的模拟。有向弧的权值表示相互连接的两个人工神经元间相互作用的强弱。\n人工神经网络的进展\n初创阶段（二十世纪四十年代至六十年代） 过渡阶段（二十世纪六十年代初至七十年代） 高潮阶段（二十世纪八十年代） 平稳发展阶段（二十世纪九十年代以后） 人工神经网络的特性\n可以充分逼近任意复杂的非线性关系 所有定量或定性的信息都等势分布贮存于网络内的各神经元，故有很强的鲁棒性和容错性 采用并行分布处理方法，使得快速进行大量运算成为可能 可学习和自适应不知道或不确定的系统 能够同时处理定量、定性知识。 可以通过软件和硬件实现。 人工神经元模型\n神经元单元由多个输入\\(x_i,i=1,2,\\cdots,n\\)和一个输出\\(y\\)组成。中间状态由输入信号的权和表示，而输出为\n\\[y_j = a\\bigg(\\sum^n_{i=1}\\omega_{ji}x_i-\\theta_j \\bigg) \\]\n式中，\\(\\theta_j\\)为神经元单元的偏置或阈值，\\(w_{ji}\\)为连接权系数。\\(n\\)为输入信号数目，\\(y_j\\)为神经元输出， \\(a(\\cdots)\\)为输出变换函数,也叫激励函数，特性函数。\n神经网络的基本特性和结构\n人工神经网络是具有下列特性的有向图\n对于每个节点\\(i\\)，存在一个状态变量\\(x_i\\)； 从节点\\(i\\)至节点\\(j\\),存在一个连接权系数\\(w_{ij}\\)； 对于每个节点\\(i\\)，存在一个阈值\\(\\theta_i\\)； 对于每个节点\\(i\\)，定义一个激活函数。 神经网络中的常见模型\n主要有前馈神经网络（也叫前向神经网络）；反馈神经网络（也叫递归神经网络）。\n前馈神经网络：具有递阶分层结构,神经元从一层连接至下一层，不存在同层神经元间的连接。\n反馈神经网络：有些神经元的输出被反馈至同层或前层神经元。其输入数据决定反馈系统的初始状态，然后系统经过一系列的状态转移后逐渐收敛于平衡状态，即为反馈神经网络经过计算后的输出结果。\n前馈神经网络 前馈网络具有递阶分层结构，由同层神经元间不存在互连的层级组成。\n从输入层至输出层的信号通过单向连接流通；神经元从一层连接至下一层，不存在同层神经元间的连接，前馈网络的例子有：\n反向传播神经网络（BP） 径向基神经网络（RBF） 多层感知器（MLP） 学习矢量量化（LVQ）网络 小脑模型联接控制（CMAC）网络 反馈神经网络 反馈网络又叫做递归网络。在反馈（递归）神经网络中，多个神经元互连以组织一个互连神经网络。如图所示。有些经元的输出被反馈至同层或前层神经元。因此，信号能够从正向和反向流通。\nHopfield网络，Elmman网络和Jordan网络是递归网络有代表性的例子。\n神经网络的主要学习算法 学习是神经网络研究的一个重要内容，它的适应性是通过学习实现的。根据环境的变化，对权值进行调整，改善系统的行为。\n神经网络主要通过指导式（有师）学习算法和非指导式（无师）学习算法。此外，还存在第三种学习算法，即强化学习算法；可把它看做有师学习的一种特例。\n有师学习\n有师学习算法能够根据期望的和实际的网络输出（对应于给定输入）间的差来调整神经元间连接的强度或权。因此，有师学习需要有个老师或导师来提供期望或目标输出信号。\n有师学习算法的例子包括\\(\\delta\\)规则、广义\\(\\delta\\)规则或反向传播算法以及LVQ算法等。\n无师学习\n无师学习算法不需要知道期望输出。在训练过程中，只要向神经网络提供输入模式，神经网络就能够自动地适应连接权，以便按相似特征把输入模式分组聚集。\n无师学习算法的例子包括Kohonen算法和 Carpenter-Grossberg自适应谐振理论(ART) 等.\n强化学习\n强化（增强）学习是有师学习的特例。它不需要老师给出目标输出。强化学习算法采用一个“评论员”来评价与给定输入相对应的神经网络输出的优度（质量因数）。\n基于神经网络的知识表示 在基于神经网络的系统中，知识的表示方法与传统人工智能系统中所用的方法（如产生式系统、框架、语义网络等）完全不同。人工智能系统中所用的方法是知识的显式表示，而神经网络中的知识是一种隐式的表示方法。在这里，知识并不像在产生式系统中那样独立地表示为每一条规则, 而是将某一问题的若干知识在同一网络中表示。\n基于神经网络的知识推理 基于神经网络的知识推理实质上是在一个已经训练成熟的网络基础上对未知样本进行反应或者判断。\n神经网络的训练是一个网络对训练样本内在规律的学习过程，而对网络进行训练的目的主要是为了让网络模型对训练样本以外的数据具有正确的映射能力。\n通常将神经网络在训练完成后输入其训练样本以外的新数据时获得正确输出的能力定义为神经网络的泛化能力（推广能力）。\n它是人工神经网络的一个属性，称为泛化性能。\n泛化性能的好坏取决于人工神经网络是否 从训练样本中找到内在的真正规律。\n影响泛化能力的因素主要有：\n训练样本的质量和数量 网络结构 问题本身的复杂程度 神经网络的训练次数也称为神经网络的学 习时间。在一定范围内，训练次数的增加 可以提高神经网络的泛化能力。\n然而，在神经网络的训练过程中经常出现一种过拟合现象，即在训练样本的误差逐渐减小并达到某个定值以后，往往会出现网络对训练样本以外的测试样本的误差反而开始增加的情况。因而，对网络的训练，并不是使训练误差越小越好，而是要从实际出发，提高泛化能力。\n最佳的泛化能力往往出现在训练误差的全局最小点出现之前，最佳泛化点出现存在一定的时间范围。只要训练时间合适，较大的神经网络也会有好的泛化能力。\n训练完成后，基于神经网络的推理是通过网络计算实现的。把用户提供的初始证据用作网络的输入，通过网络计算最终得到输出结果。\n网络推理的大致过程。一般来说，正向网络推理的步聚如下：\n把已知数据输入网络输入层的各个节点。 利用特性函数分别计算网络中各层的输出。计算中，前一层的输出作为后一层有关节点的输入，逐层进行计算 ，直至计算出输出层的输出值为止。 用阈值函数对输出层的输出进行判定，从而得到输出结果。 机器学习 ","date":"2022-10-31T09:56:28+08:00","image":"https://kegalas.top/p/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E7%AC%94%E8%AE%B0/cover_hu729735102c3c060f4a29b2f0df39e169_86954_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E7%AC%94%E8%AE%B0/","title":"人工智能概论笔记"},{"content":"导航页面\n图形学中最基础的数学涉及到线性代数，我们需要自己先写一个能处理简单的向量、矩阵运算的库。前置知识：大学本科水平的线性代数。\ngeometry.h 向量的定义 首先构造一个一般化的向量类\ntemplate\u0026lt;class T, size_t dim\u0026gt; class Vec{ public: Vec(){ for(size_t i=0;i\u0026lt;dim;i++){ data_[i] = T(); } } Vec(Vec\u0026lt;T,dim\u0026gt; const \u0026amp; v){ for(size_t i=0;i\u0026lt;dim;i++){ data_[i] = v[i]; } } T\u0026amp; operator[](const size_t i){ assert(i\u0026lt;dim \u0026amp;\u0026amp; i\u0026gt;=0); return data_[i]; } const T\u0026amp; operator[](const size_t i) const { assert(i\u0026lt;dim \u0026amp;\u0026amp; i\u0026gt;=0); return data_[i]; } Vec\u0026lt;T, dim\u0026gt;\u0026amp; operator=(const Vec\u0026lt;T,dim\u0026gt; vec){ if(this==\u0026amp;vec){ return *this; } for(size_t i=0;i\u0026lt;dim;i++){ this-\u0026gt;data_[i] = vec[i]; } return *this; } private: T data_[dim]; }; 首先template\u0026lt;class T, size_t dim\u0026gt;指的是让它的向量元素的数据类型为T，然后有dim维\nVec()这个默认构造函数不难理解，Vec(Vec\u0026lt;T,dim\u0026gt; const \u0026amp; v)是一个复制构造函数，而相应的Vec\u0026lt;T, dim\u0026gt;\u0026amp; operator=(const Vec\u0026lt;T,dim\u0026gt; vec)是一个复制赋值运算符。\nT\u0026amp; operator[]是为了方便取向量的某一个元素，并且同时提供了const的版本，这是一个经常可以见到的设计。并且我们检查数组越界。\n下面对其进行模板特殊化\ntemplate\u0026lt;class T\u0026gt; class Vec\u0026lt;T,2\u0026gt;{ public: union{ struct {T x,y;}; struct {T s,t;}; struct {T u,v;}; T raw[2]; }; Vec\u0026lt;T,2\u0026gt;():x(),y(){} Vec\u0026lt;T,2\u0026gt;(T x_, T y_):x(x_),y(y_){} Vec\u0026lt;T,2\u0026gt;(Vec\u0026lt;T,2\u0026gt; const \u0026amp; v):x(v.x),y(v.y){} template\u0026lt;class U\u0026gt; Vec\u0026lt;T,2\u0026gt;(Vec\u0026lt;U,2\u0026gt; const \u0026amp;); template\u0026lt;class U\u0026gt; Vec\u0026lt;T,2\u0026gt;(Vec\u0026lt;U,3\u0026gt; const \u0026amp;); template\u0026lt;class U\u0026gt; Vec\u0026lt;T,2\u0026gt;(Vec\u0026lt;U,4\u0026gt; const \u0026amp;); T\u0026amp; operator[](const size_t i){ assert(i\u0026lt;2 \u0026amp;\u0026amp; i\u0026gt;=0); return raw[i]; } const T\u0026amp; operator[](const size_t i) const{ assert(i\u0026lt;2 \u0026amp;\u0026amp; i\u0026gt;=0); return raw[i]; } Vec\u0026lt;T, 2\u0026gt;\u0026amp; operator=(const Vec\u0026lt;T,2\u0026gt;\u0026amp; vec){ if(this==\u0026amp;vec){ return *this; } for(size_t i=0;i\u0026lt;2;i++){ this-\u0026gt;raw[i] = vec[i]; } return *this; } }; 如上，我们定义了一个二维的向量，这个叫做模板特殊化，当我们声明Vec\u0026lt;float,2\u0026gt;时，会首先调用最特殊的那个，在此处会调用Vec\u0026lt;T,2\u0026gt;，而不是更一般的Vec\u0026lt;T,dim\u0026gt;\n另外需要注意的是，模板特殊化并不是继承，特殊的模板不会继承一般的模板的成员。所以我们需要重新地定义整个Vec\u0026lt;T,2\u0026gt;\nunion{ struct {T x,y;}; struct {T s,t;}; struct {T u,v;}; T raw[2]; }; 这是一个联合，但实际上只用了两个sizeof(T)的内存，其中x、s、u和raw[0]表示的都是第一维，而y、t、v、raw[1]表示的是第二维\nVec\u0026lt;T,2\u0026gt;():x(),y(){} Vec\u0026lt;T,2\u0026gt;(T x_, T y_):x(x_),y(y_){} Vec\u0026lt;T,2\u0026gt;(Vec\u0026lt;T,2\u0026gt; const \u0026amp; v):x(v.x),y(v.y){} 这是三个构造函数，有时我们可能会写成\nVec\u0026lt;T,2\u0026gt;(T x_, T y_){ x = x_; y = y_; } 这效果是相同的，但是如果T是一个类，而不是一个int、float这样的类型，那会导致性能问题。\n此时会先调用x的默认构造函数，然后再将x_赋值给x，调用复制赋值运算符，这是两步。而我们用成员初始化列表就直接调用了赋值构造函数，只有一步。\n虽然你可能会想为什么会有人给向量除了int和float之外的类型，我觉得你最好不要推断用户的想法。\ntemplate\u0026lt;class U\u0026gt; Vec\u0026lt;T,2\u0026gt;(Vec\u0026lt;U,2\u0026gt; const \u0026amp;); template\u0026lt;class U\u0026gt; Vec\u0026lt;T,2\u0026gt;(Vec\u0026lt;U,3\u0026gt; const \u0026amp;); template\u0026lt;class U\u0026gt; Vec\u0026lt;T,2\u0026gt;(Vec\u0026lt;U,4\u0026gt; const \u0026amp;); 这是我们之后要让float类型和int类型互相转化而提前声明的模板。\n对三维和四维的向量基本相同，目前我们要学的图形学不会用到更高维的向量了。\n下面开始定义向量的各种运算\ntemplate\u0026lt;class T, size_t dim\u0026gt; Vec\u0026lt;T, dim\u0026gt; operator+(Vec\u0026lt;T, dim\u0026gt; const \u0026amp; lhs, Vec\u0026lt;T, dim\u0026gt; const \u0026amp; rhs){ Vec\u0026lt;T,dim\u0026gt; ret; for(size_t i=0;i\u0026lt;dim;i++){ ret[i] = lhs[i] + rhs[i]; } return ret; } 代码不难理解，我们选择在全局定义这个运算符，而不是在类内部定义成员函数。这是为了更好的泛用性。以及缩短码量。\n其他的加减乘除类似，不过我们这里的乘法和除法指的是各个元素对应的乘除，并且我们还要定义向量和的数乘，数除。数除还应该注意左右操作数。\n然后再定义点乘和叉乘\ntemplate\u0026lt;class T, size_t dim\u0026gt; T dot(Vec\u0026lt;T, dim\u0026gt; const \u0026amp; lhs, Vec\u0026lt;T, dim\u0026gt; const \u0026amp; rhs){ T ret = T(); for(int i=0;i\u0026lt;dim;i++){ ret += lhs[i] * rhs[i]; } return ret; } template\u0026lt;class T\u0026gt; Vec\u0026lt;T, 3\u0026gt; cross(Vec\u0026lt;T, 3\u0026gt; const \u0026amp; lhs, Vec\u0026lt;T, 3\u0026gt; const \u0026amp; rhs){ Vec\u0026lt;T, 3\u0026gt; ret; ret.x = lhs.y*rhs.z - lhs.z*rhs.y; ret.y = lhs.z*rhs.x - lhs.x*rhs.z; ret.z = lhs.x*rhs.y - lhs.y*rhs.x; return ret; } 不把*设计为点乘，主要是考虑到OpenGL也是用dot表示点乘，而*表示元素对应相乘。\n代码并不困难，数学也是高中知识，值得注意的是，叉乘只有三维向量才有定义。\ntemplate\u0026lt;class T, size_t dim\u0026gt; T norm(Vec\u0026lt;T, dim\u0026gt; const \u0026amp; vec){ T ret = dot(vec,vec); ret = std::sqrt(ret); return ret; } 定义向量的2-范数，也就是\\(\\sqrt{x_1^2+x_2^2+\\cdots}\\)，这可以方便我们计算长度。1-范数和无穷范数暂时用不上。\ntemplate\u0026lt;class T, size_t dim\u0026gt; void normalize(Vec\u0026lt;T, dim\u0026gt; \u0026amp; vec){ T vnorm = (static_cast\u0026lt;T\u0026gt; (1))/norm(vec); for(size_t i=0;i\u0026lt;dim;i++){ vec[i] *= vnorm; } } template\u0026lt;class T, size_t dim\u0026gt; Vec\u0026lt;T, dim\u0026gt; normalized(Vec\u0026lt;T, dim\u0026gt; const \u0026amp; vec){ Vec\u0026lt;T, dim\u0026gt; ret; T vnorm = (static_cast\u0026lt;T\u0026gt; (1))/norm(vec); for(size_t i=0;i\u0026lt;dim;i++){ ret[i] = vec[i] * vnorm; } return ret; } 分别定义了，将一个向量标准化，和返回一个向量的标准化。后者是可以对const变量使用的。\n值得注意的一点是，我们使用vnorm这个变量，是因为除法比乘法慢，我们通过预先计算倒数，来加速这个过程。\ntemplate\u0026lt;class T, size_t dim\u0026gt; std::ostream\u0026amp; operator\u0026lt;\u0026lt;(std::ostream\u0026amp; out, const Vec\u0026lt;T, dim\u0026gt;\u0026amp; vec){ for(size_t i=0;i\u0026lt;dim;i++){ out\u0026lt;\u0026lt;vec[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } return out; } 我们重载了输出流，方便直接打印出来调试。\nVec\u0026lt;int,4\u0026gt; toOARColor(int const \u0026amp; v); Vec\u0026lt;int,4\u0026gt; toOARColor(float const \u0026amp; v); Vec\u0026lt;int,4\u0026gt; toOARColor(Vec\u0026lt;int,3\u0026gt; const \u0026amp; v); Vec\u0026lt;int,4\u0026gt; toOARColor(Vec\u0026lt;float,3\u0026gt; const \u0026amp; v); Vec\u0026lt;int,4\u0026gt; toOARColor(Vec\u0026lt;int,4\u0026gt; const \u0026amp; v); Vec\u0026lt;int,4\u0026gt; toOARColor(Vec\u0026lt;float,4\u0026gt; const \u0026amp; v); 在计算机图形学中，颜色也可以表示为一个向量，为此我们声明几个函数将其他的向量转变为RGB或RGBA颜色值。\n这里其中前两个是转换灰度值，中间两个是转换RGB，最后两个是转换RGBA。具体的实现后面会介绍到。\n矩阵的定义 template\u0026lt;class T, size_t nRow, size_t nCol\u0026gt; class Mat{ private: Vec\u0026lt;T, nCol\u0026gt; rowVec[nRow]; public: Mat\u0026lt;T, nRow, nCol\u0026gt;(){ size_t minDim = std::min(nRow, nCol); for(size_t i=0 ; i\u0026lt;minDim ; i++){ rowVec[i][i] = static_cast\u0026lt;T\u0026gt; (1); } } Mat\u0026lt;T, nRow, nCol\u0026gt;(T const value){ size_t minDim = std::min(nRow, nCol); for(size_t i=0 ; i\u0026lt;minDim ; i++){ rowVec[i][i] = value; } } Mat\u0026lt;T, nRow, nCol\u0026gt;(Mat\u0026lt;T, nRow, nCol\u0026gt; const \u0026amp; m){ for(size_t i=0 ; i\u0026lt;nRow ; i++){ rowVec[i] = m[i]; } } Vec\u0026lt;T, nCol\u0026gt;\u0026amp; operator[](size_t const i){ assert(i\u0026gt;=0 \u0026amp;\u0026amp; i\u0026lt;nRow); return rowVec[i]; } const Vec\u0026lt;T, nCol\u0026gt;\u0026amp; operator[](size_t const i) const { assert(i\u0026gt;=0 \u0026amp;\u0026amp; i\u0026lt;nRow); return rowVec[i]; } Mat\u0026lt;T, nRow, nCol\u0026gt;\u0026amp; operator=(Mat\u0026lt;T, nRow, nCol\u0026gt; const \u0026amp; mat){ if(this==\u0026amp;mat){ return *this; } for(size_t i=0 ; i\u0026lt;nRow ; i++){ this-\u0026gt;rowVec[i] = mat[i]; } return *this; } Vec\u0026lt;T, nRow\u0026gt; getColVec(size_t const index) const { assert(index\u0026gt;=0 \u0026amp;\u0026amp; index\u0026lt;nCol); Vec\u0026lt;T, nRow\u0026gt; ret; for(size_t i=0 ; i\u0026lt;nRow ; i++){ ret[i] = rowVec[i][index]; } return ret; } void setColVec(size_t const index, Vec\u0026lt;T, nRow\u0026gt; const \u0026amp; vec){ assert(index\u0026gt;=0 \u0026amp;\u0026amp; index\u0026lt;nCol); for(size_t i=0 ; i\u0026lt;nRow ; i++){ rowVec[i][index] = vec[i]; } } }; Vec\u0026lt;T, nCol\u0026gt; rowVec[nRow] 这一句，意味着我们采取了行先序，我们将一个矩阵看成了n个行向量。意味着mat[1][2]代表着第1行的第2个元素。行先序和matlab一致，也和glm库一致。\n我们的默认构造函数默认地构造了一个单位矩阵，即主对角线上的元素都是1，而Mat\u0026lt;T, nRow, nCol\u0026gt;(T const value)这个构造函数将主对角线上的元素设置为value。\nMat\u0026lt;T, nRow, nCol\u0026gt;\u0026amp; operator=(Mat\u0026lt;T, nRow, nCol\u0026gt; const \u0026amp; mat){ if(this==\u0026amp;mat){ return *this; } for(size_t i=0 ; i\u0026lt;nRow ; i++){ this-\u0026gt;rowVec[i] = mat[i]; } return *this; } 另外我们提供了复制构造函数以及复制赋值运算符，后者是很有必要的，否则默认的赋值运算，将会把rowVec这个指针指向右值中对应的地址，此时两个矩阵实际上用的是同一份数据，为了避免这个，我们有必要重新设计复制赋值运算符。\nVec\u0026lt;T, nRow\u0026gt; getColVec(size_t const index) const { assert(index\u0026gt;=0 \u0026amp;\u0026amp; index\u0026lt;nCol); Vec\u0026lt;T, nRow\u0026gt; ret; for(size_t i=0 ; i\u0026lt;nRow ; i++){ ret[i] = rowVec[i][index]; } return ret; } void setColVec(size_t const index, Vec\u0026lt;T, nRow\u0026gt; const \u0026amp; vec){ assert(index\u0026gt;=0 \u0026amp;\u0026amp; index\u0026lt;nCol); for(size_t i=0 ; i\u0026lt;nRow ; i++){ rowVec[i][index] = vec[i]; } } 我们也提供了获取和修改列向量的函数。\n接下来同样是提供全局的运算符重载。\n矩阵的相加、相减、数乘、数除和向量的代码基本一致。但同样为了和OpenGL着色器语言保持一致，我们矩阵乘以向量和向量相乘用的是*符号。\ntemplate\u0026lt;class T, size_t nRow, size_t nCol\u0026gt; Vec\u0026lt;T, nRow\u0026gt; operator*(Mat\u0026lt;T, nRow, nCol\u0026gt; const \u0026amp; lhs, Vec\u0026lt;T, nCol\u0026gt; const \u0026amp; rhs){ Vec\u0026lt;T, nRow\u0026gt; ret; for(size_t i=0 ; i\u0026lt;nRow ; i++){ ret[i] = dot(lhs[i] , rhs); } return ret; } template\u0026lt;class T, size_t nRow, size_t nCol, size_t sameDim\u0026gt; Mat\u0026lt;T, nRow, nCol\u0026gt; operator*(Mat\u0026lt;T, nRow, sameDim\u0026gt; const \u0026amp; lhs, Mat\u0026lt;T, sameDim, nCol\u0026gt; const \u0026amp; rhs){ Mat\u0026lt;T, nRow, nCol\u0026gt; ret; for(size_t i=0 ; i\u0026lt;nRow ; i++){ for(size_t j=0 ; j\u0026lt;nCol ; j++){ ret[i][j] = dot(lhs[i] , rhs.getColVec(j)); } } return ret; } 这里我们默认向量都是列向量，所以矩阵向量要求向量的维数和矩阵的列数相同。 在图形学中，我们大部分时候其实只会把矩阵当成左操作数，向量当成右操作数，所以我们就暂时不考虑相反情况的代码了。\n而矩阵乘以矩阵要求前者的列数等于后者的行数。\n用模板可以很好地实现上述内容。\ntemplate\u0026lt;class T, size_t nRow, size_t nCol\u0026gt; Mat\u0026lt;T, nCol, nRow\u0026gt; transpose(Mat\u0026lt;T, nRow, nCol\u0026gt; const \u0026amp; mat){ Mat\u0026lt;T, nCol, nRow\u0026gt; ret; for(size_t i=0 ; i\u0026lt;nRow ; i++){ ret.setColVec(i, mat[i]); } return ret; } 矩阵转置很简单，将原来的行向量设置给新的列向量即可。\ntemplate\u0026lt;class T, size_t dim\u0026gt; Mat\u0026lt;T, dim-1, dim-1\u0026gt; getMinor(Mat\u0026lt;T, dim, dim\u0026gt; const \u0026amp; mat, size_t x, size_t y){ assert(dim\u0026gt;0); Mat\u0026lt;T, dim-1, dim-1\u0026gt; ret; for(size_t i=0;i\u0026lt;dim-1;i++){ for(size_t j=0;j\u0026lt;dim-1;j++){ ret[i][j] = mat[i\u0026lt;x?i:i+1][j\u0026lt;y?j:j+1]; } } return ret; } 这是在计算一个矩阵，去除某个元素的所在行和所在列得到的子矩阵。\ntemplate\u0026lt;class T, size_t dim\u0026gt; T det(Mat\u0026lt;T, dim, dim\u0026gt; const \u0026amp; mat){ assert(dim\u0026gt;0); T ret = T(); for(size_t i=0;i\u0026lt;dim;i++){ ret += cofactor(mat, 0, i) * mat[0][i]; } return ret; } template\u0026lt;class T\u0026gt; T det(Mat\u0026lt;T,2,2\u0026gt; const \u0026amp; mat){ return mat[0][0]*mat[1][1] - mat[0][1]*mat[1][0]; } template\u0026lt;class T\u0026gt; T det(Mat\u0026lt;T,1,1\u0026gt; const \u0026amp; mat){ return mat[0][0]; } template\u0026lt;class T\u0026gt; T det(Mat\u0026lt;T,0,0\u0026gt; const \u0026amp; mat){ return static_cast\u0026lt;T\u0026gt;(0); } template\u0026lt;class T, size_t dim\u0026gt; T cofactor(Mat\u0026lt;T, dim, dim\u0026gt; const \u0026amp; mat, size_t x, size_t y){ return det(getMinor(mat,x,y)) * static_cast\u0026lt;T\u0026gt;((x+y)%2?-1:1); } 这是计算行列式与代数余子式的代码。\n计算大于2阶的行列式，需要用到代数余子式的方法，可以参考线性代数笔记。\n值得注意的是，det中我们每次计算都会减少dim一阶，但是你并不能使用if(dim==2);if(dim==1);if(dim\u0026lt;=0)这样的语句来在模板内部定义特例，这是无法编译通过的。你需要做的是将模板特殊化，这样才能通过编译。\ntemplate\u0026lt;class T, size_t dim\u0026gt; Mat\u0026lt;T,dim,dim\u0026gt; adjugate(Mat\u0026lt;T, dim, dim\u0026gt; const \u0026amp; mat){ Mat\u0026lt;T, dim, dim\u0026gt; ret; for(size_t i=0;i\u0026lt;dim;i++){ for(size_t j=0;j\u0026lt;dim;j++){ ret[j][i] = cofactor(mat,i,j); } } return ret; } template\u0026lt;class T, size_t dim\u0026gt; Mat\u0026lt;T,dim,dim\u0026gt; inverse(Mat\u0026lt;T, dim, dim\u0026gt; const \u0026amp; mat){ Mat\u0026lt;T, dim, dim\u0026gt; ret; ret = adjugate(mat)/det(mat); return ret; } 这是计算伴随矩阵和逆矩阵的代码，有一点值得注意，就是伴随矩阵的下标相当于进行了转置。\ntypedef Vec\u0026lt;float,2\u0026gt; vec2f; typedef Vec\u0026lt;float,3\u0026gt; vec3f; typedef Vec\u0026lt;float,4\u0026gt; vec4f; typedef Vec\u0026lt;int,2\u0026gt; vec2i; typedef Vec\u0026lt;int,3\u0026gt; vec3i; typedef Vec\u0026lt;int,4\u0026gt; vec4i; typedef Vec\u0026lt;int,4\u0026gt; OARColor; typedef Mat\u0026lt;float, 4, 4\u0026gt; mat4f; typedef Mat\u0026lt;int, 4, 4\u0026gt; mat3f; 最后声明一下变量的别名方便使用。\n另外这些全部都是在geo命名空间中，方便辨别。\n着重讲一下为什么我们的颜色信息（OARColor）被设置成4维的int向量。\n相信大家都听过RGB颜色，在这上面多加一维透明度，就是RGBA，基本上可以达到我们所有想要的效果了。而RGBA四个属性的取值范围分别都是\\([0,255]\\)的整数，所以用四维int向量就理所当然了。\n你可能会问为什么不拆成黑白、RGB、RGBA三种颜色。确实，这可能会更省内存，但是现在电脑内存一点也不稀缺，并且我们的微型渲染器很难有多大开销，统一处理可能更简单一些。\n完整的代码在这里\ngeometry.cpp 这个文件里大部分都是涉及向量类型转换的。唯一需要注意的是四舍五入。以三维为例\ntemplate\u0026lt;\u0026gt; template\u0026lt;\u0026gt; geo::Vec\u0026lt;int,3\u0026gt;::Vec(geo::Vec\u0026lt;float, 2\u0026gt; const \u0026amp; v, float const z_){ x = static_cast\u0026lt;int\u0026gt;(v.x + 0.5f); y = static_cast\u0026lt;int\u0026gt;(v.y + 0.5f); z = static_cast\u0026lt;int\u0026gt;(z_ + 0.5f); } 这段代码将二维的float向量转为三维的int向量，+0.5f即是四舍五入。\n然后就是转化为RGBA颜色格式，为了简单起见，我们假设所有的颜色都用RGBA表示，所以我们需要将RGB和灰度图像转化为RGBA，然后在写入图像时再具体分析写入什么颜色数据。举例将float的RGB和int的灰度转换为RGBA：\n（注：RGBA其实每一个颜色的权重也可以表示为\\([0,1]\\)之间的实数（这样在处理光照的时候容易些），但我们的图像写出去的是离散的值，所以要将\\([0,1]\\)映射到\\([0,255]\\)上的实数。注意四舍五入）\ngeo::Vec\u0026lt;int,4\u0026gt; geo::toOARColor(geo::Vec\u0026lt;float,3\u0026gt; const \u0026amp; v){ OARColor ret; for(int i=0;i\u0026lt;3;i++){ ret[i] = static_cast\u0026lt;int\u0026gt;(v[i]*255.f+0.5f); if (ret[i]\u0026lt;0) ret[i] = 0; else if(ret[i]\u0026gt;255) ret[i] = 255; } ret[3] = 255; return ret; } geo::Vec\u0026lt;int,4\u0026gt; geo::toOARColor(int const \u0026amp; v){ OARColor ret; for(int i=0;i\u0026lt;3;i++){ if(v\u0026lt;0) ret[i] = 0; else if(v\u0026gt;255) ret[i] = 255; else ret[i] = v; } ret[3] = 255; return ret; } 其将连续的[0,1]映射到离散的[0,255]（或者本来就是离散的），并且超出的部分映射到边界上，同时也计算了四舍五入。\n完整的代码在这里\n","date":"2022-10-28T15:34:04+08:00","image":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E6%95%B0%E5%AD%A6%E5%B7%A5%E5%85%B7%E5%BA%93/cover_huc0107afa81d973e7d87fe5de99d27181_24753_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E6%95%B0%E5%AD%A6%E5%B7%A5%E5%85%B7%E5%BA%93/","title":"从零开始的软渲染器 数学工具库"},{"content":"目录 1. 从零开始的软渲染器-数学工具库\n2. 从零开始的软渲染器-图片处理库\n3. 从零开始的软渲染器-线段和三角形的光栅化\n4. 从零开始的软渲染器-模型库\n5. 从零开始的软渲染器-光照初步\nTODO:\n6. 从零开始的软渲染器-坐标变换与视角\n番外1. 从零开始的软渲染器-YAML记录参数\n7. 从零开始的软渲染器-Z-Buffer\n8. 从零开始的软渲染器-图形渲染管线\n9. 从零开始的软渲染器-纹理贴图\n10. 从零开始的软渲染器-阴影贴图\n11. 从零开始的软渲染器-更真实的光照\n12. 从零开始的软渲染器-光线追踪初步\nTODO: 改成导航与前言，前言部分介绍这个项目的目的，以及主要参考了什么资料（例如Fundamentals of Computer Graphics、tiny renderer，learnopengl）\n","date":"2022-10-28T15:33:42+08:00","image":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E5%AF%BC%E8%88%AA/cover_huef498dd5cf38693b5a441291f5d52b83_173498_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%BD%AF%E6%B8%B2%E6%9F%93%E5%99%A8-%E5%AF%BC%E8%88%AA/","title":"从零开始的软渲染器 导航"},{"content":"基础知识 多项式求值 对于形如下式的多项式\n\\[P(x)=2x^4+3x^3-3x^2+5x-1 \\]\n如果我们普通地代入计算，则会需要计算10次乘法，以及4次加法。这显然不是最优的，更优的方法例如秦九韶算法，将多项式重写为\n\\[P(x)=-1+x*(5+x*(-3+x*(3+x*2))) \\]\n此时再代入值计算，则只用4次乘法和4次加法。一般来说\\(d\\)阶多项式可以通过\\(d\\)次乘法和\\(d\\)次加法求值。\n标准形式的多项式\n\\[P(x) = c_1+c_2x+c_3x^2+c_4x^3+c_5x^4 \\]\n可以写成\n\\[P(x)=c_1+x(c_2+x(c_3+x(c_4+x(c_5)))) \\]\n或者也有更一般的形式，可以用于之后的插值计算\n\\[P(x)=c_1+(x-r_1)(c_2+(x-r_2)(c_3+(x-r_3)(c_4+(x-r_4)(c_5)))) \\]\n其中称\\(r1,r2,r3,r4\\)为基点。\n二进制数字 二进制数字可以表示为：\n\\[\\cdots b_2b_1b_0b_{-1}b_{-2}\\cdots \\]\n其等价于十进制下的\n\\[\\cdots b_22^2+b_12^1+b_02^0+b_{-1}2^{-1}+b_{-2}2^{-2}\\cdots \\]\n十进制转化为二进制 例如\\(53.7\\)转化为二进制，可以拆分为整数部分和小数部分，分别转化，然后在拼接起来。\n整数部分\n将整数连续除以\\(2\\)，记录余数，直到整数最后变为\\(0\\)，余数反过来排列在一起就是二进制表示。例如\n\\[53\\div 2 = 26\\cdots1 \\]\n\\[26\\div 2 = 13\\cdots0 \\]\n\\[13\\div 2 = 6\\cdots1 \\]\n\\[6\\div 2 = 3\\cdots0 \\]\n\\[3\\div 2 = 1\\cdots1 \\]\n\\[1\\div 2 = 0\\cdots1 \\]\n那么二进制表示就是\\(110101\\)\n小数部分\n将小数部分不断乘以\\(2\\)，得到的结果保留整数部分，直到小数部分为\\(0\\)，整数部分顺序排列即为小数部分的二进制表示\n例如\n\\[0.7*2 = 0.4+1 \\]\n\\[0.4*2 = 0.8+0 \\]\n\\[0.8*2 = 0.6+1 \\]\n\\[0.6*2 = 0.2+1 \\]\n\\[0.2*2 = 0.4+0 \\]\n\\[0.4*2 = 0.8+0 \\]\n\\[\\vdots \\]\n后面重复，代表在二进制中是无限循环小数。有\\((0.7)_{10}=(0.1\\overline{0110})_2\\)\n最后有\\((53.7)_{10} = (110101.1\\overline{0110})_2\\)。\n二进制转化为十进制 开头已经介绍过一般情况，对于有限小数是容易计算的。\n无限小数时，例如\\(x=(0.\\overline{1011})_2\\)，先左移\\(4\\)位，再减去原始的\\(x\\)，有\n\\[2^4x = 1011.\\overline{1011}\\\\ x=0000.\\overline{1011} \\]\n相减得\n\\[(2^4-1)x = (1101)_2 = (11)_{10} \\]\n求解\\(x\\)可得，\\(x=(0.\\overline{1011})_2=11/15\\)。\n实数的浮点表示 本节按照IEEE754标准。\n浮点格式 一个浮点数字包含三个部分：符号（正负）、尾数（包含一串有效数位）和一个指数，这些部分都在一个计算机字(WORD)里。\n浮点数常用三种精度级别：单精度、双精度、扩展精度。它们分配的数位分别是32、64、80。具体如下\n精度 符号 指数 尾数 单精度 1 8 23 双精度 1 11 52 扩展精度 1 15 64 三种精度以相同的方式运行。标准化的IEEE浮点数表示为\n\\[\\pm 1.bbb\\cdots b\\times 2^p \\]\n其中\\(N\\)个\\(b\\)或0或1，\\(p\\)是一个\\(M\\)位的二进制数表示指数。最左边的一位（主导数位）必须是\\(1\\)。\n当一个二进制数用一个标准浮点数字表示的时候，它被称为“左对齐”，意味着其中最左边的一个数位\\(1\\)被平移到小数点的左边，平移通过指数的变化来补偿，例如，十进制数\\(9\\)，对应的二进制数\\(1001\\)保存为\n\\[+1.001\\times 2^3 \\]\n以双精度（\\(M=11,N=52\\)）为例，1的双精度表示为\n\\[+1.0000000000000000000000000000000000000000000000000000\\times 2^0 \\]\n其中有52位尾数，下一个比\\(1\\)大的浮点数是\n\\[+1.0000000000000000000000000000000000000000000000000001\\times 2^0 \\]\n或者说是\\(1+2^{-52}\\)\n定义1\n机器精度对应的数字，记作\\(\\varepsilon_{math}\\)，是\\(1\\)和比\\(1\\)大的最小浮点数之间的距离。对于双精度来说就是\\(2^{-52}\\)\n如果一个小数是无限小数，或者是超过了52位的小数，IEEE规定，如果在第53位为0，则52位以后的全部社区，如果53位为1，则在52位上加1。特别的，如果第53位为1，其后所有已知位为0，那么当且仅当52位是1时在52位上加1。\n上述方法称为IEEE舍入最近法则。\n定义2\n将IEEE双精度浮点数字记做\\(x\\)，利用舍入最近法则记做\\(fl(x)\\)\n在计算机算术中，实数\\(x\\)用一串数位\\(fl(x)\\)替换。根据这个定义，\\(9.4\\)在二进制中表示如下\n\\[+1.0010110011001100110011001100110011001100110011001100|110\\cdots\\times 2^3 \\]\n则\\(fl(9.4)\\)表示为\n\\[+1.0010110011001100110011001100110011001100110011001101\\cdots\\times 2^3 \\]\n我们通过去掉最右边无穷长的数字尾巴\\(0.\\overline{1100}\\times 2^{-52}\\times 2^3=\\overline{0.0110}\\times 2^{-51}\\times 2^3=0.4\\times 2^{-48}\\)得到浮点表达。并在舍入过程中加上\\(2^{-52}\\times 2^3=2^{-49}\\)。因而\n\\[fl(9.4) = 9.4+2^{-49}-0.4\\times 2^{-48}\\\\ =9.4+(1-0.8)2^{-49}\\\\ =9.4+0.2\\times 2^{-49} \\]\n换句话说，将\\(9.4\\)保存为双精度浮点数时可能产生了\\(0.2\\times 2^{-49}\\)的误差，我们把它称作舍入误差。\n定义3\n令\\(x_c\\)是计算版本\\(x\\)的精确度量，则\n\\[绝对误差=|x_c-x| \\]\n\\[相对误差=\\frac{|x_c-x|}{|x|}(x\\neq 0) \\]\n相对舍入误差\n在IEEE机器算术模型中，\\(fl(x)\\)的相对舍入误差不会比机器精度的一半大：\n\\[\\frac{|fl(x)-x|}{|x|}\\leq \\frac{1}{2}\\varepsilon_{math} \\]\n浮点数的机器表示 每个双精度浮点数字被分配了8字节，或者说64位，来存储对应的三个部分。每个字都有如下形式\n\\[se_1e_2\\cdots e_{11}b_1b_2\\cdots b_{52} \\]\n其中第1位保存了符号位，后面11位用于保存指数，再后面小数点后的52位保存尾数。符号位0是正数，1是负数。11位指数表示的正二进制整数，这些正数通过往指数上叠加\\(2^10-1=1023\\)得到，指数范围在\\(-1022\\)和\\(1023\\)之间，\\(e_1\\cdots e_{11}\\)覆盖了从\\(1\\)到\\(2046\\)之间对应的指数，由于特殊目的，没有使用\\(0\\)和\\(2047\\)。\n数字\\(1023\\)称为双精度格式的指数偏差。它被用于把正和负指数转化为正的二进制数保存在指数位中，对于单精度和扩展精度，指数偏差位分别是127和16383.\n也就是说，指数位上的数字，减去1023才是浮点数中所应该是的指数。\n再来看特殊值\\(2047\\)。如果尾数位串都是0，则用于表示\\(\\infty\\)（其符号取决于第一位），否则表示\\(NaN\\)，意为不是一个数字。\n例如\\(1/0\\)是\\(+\\inf\\)，前\\(12\\)位用十六进制表示为7FF，后面全是0.\n\\(-1/0\\)是\\(-\\inf\\)，前\\(12\\)位用十六进制表示为FFF，后面全是0.\n\\(0/0\\)是\\(NaN\\)，前\\(12\\)位用十六进制表示为FFF，后面不全是0.\n再来看特殊值\\(0\\)，意味着\\(e_1e_2\\cdots e_{11}=(000 0000 0000)_2\\)。其表示一个非标准浮点数\n\\[\\pm 0.b_1b_2\\cdots b_{52}\\times 2^{-1022} \\]\n由上可见，第一位不再假设为1.这样的非标准化数字称作异常浮点数字。这样就扩展了数字的表示范围，因而，最小的可表达的双精度数字是\\(2^{-52}\\times 2^{-1022}\\)。\n另外\\(+0,-0\\)也是一个异常数字。计算中它们被看作是相同的两个实数。\n浮点数加法 首先对齐进行加法的两个数字的小数点位，接着相加，然后把结果保存为浮点数字。\n在加法寄存器中，可以进行超过52位的加法，但是在相加之后必须舍入变回52位。\n有效数字缺失 有一个主要问题以多种形式出现，该问题是由于对近似相等的两个数字相减造成有效数字的位数减少。\n例如\\(123.4567-123.4566=0.0001\\)，有效数字从原来的七位减少到一位。\n很多情况下我们可以通过重新构造计算来解决这个问题。\n例1\n在三位小数的计算机上计算\\(\\sqrt{9.01}-3\\)\n正确的结果接近\\(1.6662\\times 10^{-3}\\)，但当我们使用三位有效数字时，由于\\(\\sqrt{9.01}\\approx 3.0016662\\)，保存三位有效数字时得到\\(3.00\\)。再减去\\(3.00\\)，得到\\(0.00\\)，没有一个有效数位是正确的。\n但是我们可以用以下方法挽救\n\\[\\sqrt{9.01}-3 = \\frac{(\\sqrt{9.01}-3)(\\sqrt{9.01}+3)}{\\sqrt{9.01}+3}=\\frac{9.01-9}{\\sqrt{9.01}+3} \\]\n\\[=\\frac{0.01}{3.00+3.00}=\\frac{0.01}{6}=0.00167\\approx 1.67\\times 10^{-3} \\]\n这种方法本质上是一个窍门。称作“共轭等式”。通常会使用一些特定的恒等式，例如三角恒等式。\n例如\n\\[E_1=\\frac{1-cosx}{sin^2x},E_2=\\frac{1}{1+cosx} \\]\n两个式子虽然等价，但是在数值计算上，输入一个较为靠近0的数，则第二个比第一个精度高。\n例2\n解方程\\(ax^2+bx+c=0\\)\n对于最基础的求根公式\n\\[x=\\frac{-b\\pm \\sqrt{b^2-4ac}}{2a} \\]\n其中间取负号问题可能不大，但是取正号时，如果\\(ac\\)相对于\\(b^2\\)非常小，则分式上面会直接舍入等于0，造成整个结果等于0.\n为了解决这个问题，可以在\\(b\\)是正数时\n\\[x_1=-\\frac{b+\\sqrt{b^2-4ac}}{2a},x_1=-\\frac{2c}{b+\\sqrt{b^2-4ac}} \\]\n\\(b\\)是负数时\n\\[x_1=\\frac{-b+\\sqrt{b^2-4ac}}{2a},x_1=\\frac{2c}{-b+\\sqrt{b^2-4ac}} \\]\n微积分回顾 书中回顾了函数的连续性、罗尔定理、拉格朗日中值定理、泰勒展开、积分中值定理等。\n求解方程 二分法 方法 定义1\n如果\\(f(r)=0\\)，函数\\(f(x)\\)在\\(x=r\\)时有一个根。\n定理1\n根据函数的连续性，我们知道，如果一个函数是连续的（在[a,b]上），并且在\\(a\u003c b\\)时有\\(f(a)f(b)\u003c0\\)，那么函数在\\((a,b)\\)之间至少有一个根\\(r\\)使得\\(f(r)=0\\)\n显然，我们可以判断\\(c=(b+a)/2\\)时\\(f(a)f(c)\\)的符号来判断根具体在\\([a,c]\\)还是\\([c,b]\\)之中\n由此我们就可以得到一个求出根的伪代码\n二分法 给定初始区间[a,b]使得f(a)f(b)\u0026lt;0 while (b-a)/2\u0026gt;TOL c = (a+b)/2 if f(c)=0,stop,end if f(a)f(c)\u0026lt;0 b = c else a = c end end 最终的区间[a,b]中包含一个根 近似根为(a+b)/2 显然我们求出的是一个区间\\([a,b]\\)，有一个根在其中，我们只能估计一个值。另外代码中的TOL指的是精度，即这个根在\\((a+b)/2\\pm TOL\\)这个范围内。\n分析 现在来分析二分法的精确度和收敛速度。\n假设\\([a,b]\\)是初始区间，在\\(n\\)次二分之后，得到的最终区间\\([a_n,b_n]\\)的长度为\\((b-a)/2^n\\)。选择中点\\(x_c=(a_n+b_n)/2\\)为解的最优估计值，与真实值的误差不会超过区间长度的一般。总之，n步二分法之后，我们得到\n\\[求解误差=|x_c-r|\u003c\\frac{b-a}{2^{n+1}} \\]\n\\[函数计算次数=n+2 \\]\n对于其精度，每一次函数计算后，解的不确定性都会减少一半。\n定义2\n如果误差小于\\(0.5\\times 10^{-p}\\)，解精确到小数点后\\(p\\)位。\n不动点迭代 举一个例子，以弧度制计算\\(\\cos\\)。以任意值代入，比如我们代入\\(1\\).有\\(cos1=0.5403\\cdots\\)，再将结果代入，有\\(cos(cos1)=0.85755\\cdots\\)，以此类推，多次代入后，我们发现无论初始值是多少，最后都会收敛到\\(0.7390851332\\cdots\\)\n函数的不动点 定义1\n当\\(g(r)=r\\)，实数\\(r\\)是函数\\(g\\)的不动点。\n例如，我们求解\\(\\cos x-x=0\\)的方程，用不动点的视角来看，就是求解\\(\\cos x=x\\)，或者说求解\\(\\cos x\\)的不动点。\n一旦方程写做\\(g(x)=x\\)，从一个初始估计\\(x_0\\)开始进行不动点迭代过程，对函数\\(g\\)进行迭代，\n\\[x_1=g(x_0)\\\\ x_2=g(x_1)\\\\ x_3=g(x_2)\\\\ \\vdots \\]\n依此下去。当进行无穷多步迭代后序列\\(x_i\\)可能收敛，也可能不收敛。但是，如果函数\\(g\\)是一个连续函数并且\\(x_i\\)收敛，收敛到一个数字\\(r\\)，那么\\(r\\)就是对应的不动点。意味着\n\\[g(r) = g(\\lim_{i\\to\\infty}x_i)=\\lim_{i\\to\\infty}g(x_i) = \\lim_{i\\to\\infty}x_{i+1}=r \\]\n所有方程\\(f(x)=0\\)都能转化为\\(g(x)=x\\)来不动点迭代吗？答案是肯定的。\n虽然都能迭代，但不总是能收敛的。\n例如\\(x^3+x-1=0\\)换成\\(x=1-x^3\\)来迭代，最后结果就会在\\(1,0\\)之间摆动，这是因为\\(g(0)=1,g(1)=0\\)。\n但是，如果使用\\(x=\\sqrt[3]{1-x}\\)来迭代，就可以求出正确的不动点\\(x=0.6823\\cdots\\)。迭代了大概25次。\n如果使用\\(x=(1+2x^3)/(1+3x^2)\\)，也可以收敛，并且只需要迭代4次就可以得到\\(x=0.6823\\cdots\\)。\n不动点迭代几何 我们要解释出现上述差异的原因。\n如下图，将\\(g(x),x\\)画在同一坐标系下，其中交点就是不动点，图中的箭头代表迭代过程。这种表示又被称作cobweb图。\n1.jpg\r图\\(a\\)中迭代逐渐远离了不动点，而\\(b,c\\)两图，迭代都在不断靠近不动点。\n由图我们猜测迭代收敛与否和\\(g(x)\\)在不动点附近的斜率有关。\n不动点迭代的线性收敛 以\\(g_1(x)=-\\frac{3}{2}x+\\frac{5}{2},g_2(x)=-\\frac{1}{2}x+\\frac{3}{2}\\)为例。它们的不动点都是\\(x=1\\)。\n我们把\\(g(x)\\)写作\\(x-r\\)的形式，其中\\(r=1\\)：\n\\[g_1(x)=-\\frac{3}{2}(x-1)+1\\\\ g_1(x)-1=-\\frac{3}{2}(x-1)\\\\ x_{i+1}-1=-\\frac{3}{2}(x_i-1) \\]\n如果我们把\\(e_i=|r-x_i|\\)作为第\\(i\\)步时的误差，可以看到上式的误差是\\(e_{i+1}=3e_i/2\\)，意味着误差越来越大，也就是发散。\n对于\\(g_2(x)\\)有\n\\[x_{i+1}-1=-\\frac{1}{2}(x_i-1) \\]\n\\(e_{i+1}=e_i/2\\)，误差越来越小，就是收敛。\n定义2\n令\\(e_i\\)表示迭代过程中第\\(i\\)步时的误差，如果\n\\[\\lim_{i\\to\\infty}\\frac{e_{i+1}}{e_i}=S\u003c1 \\]\n该方法被称为满足线性收敛，收敛速度为\\(S\\)。\n这样的推理过程也可以适用于更加一般的连续可微函数\n定理1\n假设函数\\(g\\)是连续可微函数，\\(g(r)=r,S=|g'(r)|\u003c1\\)，则不动点迭代对于一个足够接近\\(r\\)的初始估计，以速度\\(S\\)线性收敛到不动点\\(r\\)。\n定义3\n如果迭代方法对于一个足够接近\\(r\\)的初值能收敛到\\(r\\)，该迭代方法称为局部收敛到\\(r\\)。\n终止条件 同二分法不同，FPI没有误差与迭代次数的关系公式，必须决定何时终止算法，这称为终止条件。\n对于一组容差\\(TOL\\)，我们可能使用绝对终止条件\n\\[|x_{i+1}-x_i| \u003c \\text{TOL} \\]\n当解不在\\(0\\)附件时可以使用相对误差条件\n\\[\\frac{|x_{i+1}-x_i|}{|x_{i+1}|} \u003c \\text{TOL} \\]\n还有混合绝对/相对误差终止条件\n\\[\\frac{|x_{i+1}-x_i|}{max(|x_{i+1}|,\\theta)} \u003c \\text{TOL} \\]\n其中\\(\\theta\u003e0\\)，常常用于\\(0\\)附近的解。此外，如果收敛失败，一个好的FPI也应该设置迭代次数上限。\n二分法可以保证线性收敛，不动点迭代仅仅是局部收敛。不动点迭代收敛时，是线性收敛。二分法每次可以去掉\\(1/2\\)的不确定性，而FPI的不确定性每次会乘上\\(S=|g'(r)|\\)，因此可能比二分法更快或更慢，依赖于\\(S\\)比\\(1/2\\)更大还是更小。\n精度的极限 前向与后向误差 定义1\n假设\\(f\\)是一个函数，\\(r\\)是一个根，意味着满足\\(f(r)=0\\)。假设\\(x_a\\)是\\(r\\)的近似值。对于根求解问题，近似\\(x_a\\)的后向误差是\\(|f(x_a)|\\)，前向误差是\\(|r-x_a|\\)。\n举个例子，求解以下函数的根\n\\[f(x) = x^3-2x^2+\\frac{4}{3}x-\\frac{8}{27} \\]\n我们可以通过手算验证\\(2/3\\)是它的根。\n当我们使用双精度浮点数去二分法求解时，最后可能解出\\(r=0.6666641\\)，并且到此结束，因为此时\\(f(r)=0\\)，意味着其等于机器\\(0\\)。在这\\(2/3\\pm 10^{-5}\\)的范围上，其函数值都等于机器\\(0\\)。\n事实上，\\(r\\)的后向误差接近\\(\\varepsilon_{math}=2.2\\times 10^{-16}\\)，而前向误差在大约\\(10^{-5}\\)。双精度不能在机器精度的相对误差下可靠计算，从而导致了一个范围内的数最终都等于机器\\(0\\)。\n事实上\\(2/3\\)是这个函数的三重根\n定义2\n假设\\(r\\)是可微函数\\(f\\)的根，如果\\(0=f(r)=f'(r)=f''(r)=\\cdots=f^{(m-1)}(r)\\)，但是\\(f^{(m)}(r)\\neq 0\\)，就说\\(f\\)在\\(r\\)点具有\\(m\\)重根。多于一个根的叫重根，只有一个根的叫单根。\n由于函数在多根附近十分平缓，前向和后向误差之间在近似解的附近存在很大的不一致。后向误差在垂直方向进行度量，通常比在水平方向度量的前向误差小得多。\n前向和后向误差的讨论和方程求解器的终止条件有关。我们有两种方法更加接近方程的根\n使得\\(|x_a-r|\\)足够小 使得\\(|f(x_a)|\\)足够小 具体选择使用哪一种，取决于问题所处的环境。对于二分法，两种误差都可以观察到。而FPI只能知道后向误差，而不可能知道前向误差。\n威尔金森多项式 一个难以进行数值求解的单根例子在威尔金森的论著中进行了讨论，威尔金森多项式是\n\\[W(x) = (x-1)(x-2)\\cdots(x-20) \\]\n但当我们把它展开，并用二分法等方法却很难求出正确的解，精确度甚至不到第二个小数。\n这主要是因为其展开式的每一项的常数太大，例如常数项是\\(2432902008176640000\\)，这导致在求值计算中会由于近似相等、大数字的消去而有损失。\n但是若不展开，代入求根器中却能算出精确根。当然如果已经分解好了，也就没有求解的必要了。\n根搜索的敏感性 威尔金森多项式和多重根的问题，其本质都是方程中小的求解误差造成求解根中的大误差。\n如果在输入中是一个小误差，在这种情况下对问题进行求解，造成输出中的大问题，这样的问题被称作敏感性问题。\n假设问题是找到\\(f(x)=0\\)的根\\(r\\)，但是对输入做了一个小变化\\(\\varepsilon g(x)\\)，其中\\(\\varepsilon\\)很小。令\\(\\Delta r\\)是对应根中的变化，因而\n\\[f(r+\\Delta r)+\\varepsilon g(r+\\Delta r)=0 \\]\n将\\(f\\)和\\(g\\)一阶泰勒展开，有\n\\[f(r)+(\\Delta r)f'(r)+\\varepsilon g(r)+\\varepsilon(\\Delta r)g'(r)+O((\\Delta r)^2) \\]\n对于小的\\(\\Delta r\\)，直接忽略掉\\(O((\\Delta r)^2)\\)，有\n\\[(\\Delta r)(f'(r)+\\varepsilon g'(r))\\approx-f(r)-\\varepsilon g(r)=-\\varepsilon g(r) \\]\n假设和\\(f'(r)\\)相比，\\(\\varepsilon\\)很小，则又有\n\\[\\Delta r\\approx\\frac{-\\varepsilon g(r)}{f'(r)+\\varepsilon g'(r)}\\approx -\\varepsilon\\frac{g(r)}{f'(r)} \\]\n上式就叫做根的敏感公式。（假设\\(r\\)是\\(f(x)\\)的根，并且\\(r+\\Delta r\\)是\\(f(x)+\\varepsilon g(x)\\)的根，则当\\(\\varepsilon \u003c\u003c f'(r)\\)时有上式）\n对于一个一般算法生成的近似\\(x_c\\)，我们定义\n\\[误差放大因子=\\frac{相对前向误差}{相对后向误差} \\]\n条件\n条件数也是误差放大度量的一种方式。数值分析是对算法的研究，算法把定义问题的数据作为输入，对应的结果作为输出。条件数指的是理论问题本身所带来的的误差放大部分，和用于求解问题的特定算法无关。\n问题的条件数定义为所有输入变化，或者至少规定类型的变化所造成的最大误差放大。\n条件数高的问题称为病态问题，条件数在\\(1\\)附件的问题称为良态问题。\n牛顿方法 为了找到\\(f(x)=0\\)的根，给定一个初始估计\\(x_0\\)，画出函数\\(f\\)在\\(x_0\\)的切线。用切线来近似函数\\(f\\)，求出其与\\(x\\)轴的交点作为\\(f\\)的根。由于函数\\(f\\)的弯曲，该交点可能不是精确解，因而该步骤要迭代进行。\n\\[x_0=初始估计 \\]\n\\[x_{i+1}=x_i-\\frac{f(x_i)}{f'(x_i)},\\quad i=0,1,2,\\cdots \\]\n牛顿方法的二次收敛 定义1\n令\\(e_i\\)表示一个迭代方法第\\(i\\)步后得到的误差。该迭代是二次收敛，如果满足下式\n\\[M=\\lim_{i\\to\\infty}\\frac{e_{i+1}}{e^2_i}\u003c\\infty \\]\n定理1\n令\\(f\\)是二阶连续可微函数，\\(f(r)=0\\)。如果\\(f'(r)\\neq 0\\)，则牛顿方法局部二次收敛到\\(r\\)。第\\(i\\)步的误差\\(e_i\\)满足\n\\[\\lim_{i\\to\\infty}\\frac{e_i}{e_i^2}=M \\]\n其中\n\\[M=\\frac{f''(r)}{2f'(r)} \\]\n也可被看作\n\\[e_{i+1}\\approx M e_i^2 \\]\n对于线性收敛方法，这个误差公式应该和\\(e_{i+1}\\approx Se_i\\)进行比较，FPI方法中\\(S=|g'(r)|\\)，二分法中\\(S=1/2\\)\n尽管\\(S\\)对线性收敛很关键，但是\\(M\\)的值并不是很重要，这是由于其包含了平方，只要\\(M\\)不太大，误差就会进一步下降。\n牛顿方法的线性收敛 上面的定理并不意味着牛顿方法总能二次收敛。\n例如求\\(f(x)=x^2\\)的实根，牛顿法如下\n\\[x_{i+1}=x_i-\\frac{f(x_i)}{f'(x_i)}=\\frac{x_i}{2} \\]\n仅仅每步除以\\(2\\).对于其他幂函数也有类似的结果。\n定理1\n假设在区间\\([a,b]\\)上，\\((m+1)\\)阶连续可微函数\\(f\\)在\\(r\\)点有一个\\(m\\)阶多重根，则牛顿方法局部收敛到\\(r\\)，第\\(i\\)步误差\\(e_i\\)满足\n\\[\\lim_{i\\to \\infty}\\frac{e_{i+1}}{e_i}=S \\]\n其中\\(S=(m-1)/m\\)\n事实上，牛顿法在单根位置上，\\(f'(r)\\neq 0\\)，具有二次收敛速度，在多根位置上\\(f'(r)=0\\)，收敛式线性的。\n定理2\n如果在\\([a,b]\\)区间上\\(f\\)是\\((m+1)\\)阶连续函数，包含\\(m\u003e1\\)的多重根，则改进的牛顿方法\n\\[x_{i+1}=x_i-\\frac{mf(x_i)}{f'(x_i)} \\]\n收敛到\\(r\\)，并具有二次收敛速度。\n牛顿法如同FPI，也可能不会收敛到根。例如两个数循环出现、某一步\\(f'(x_i)=0\\)等。\n不需要导数的根求解 虽然牛顿法在非重根时表现的比二分法和FPI更好，因为它获取了“导数”这个额外信息。但有时候我们可能难以计算导数。\n这种情况下，割线方法就是一个好的替代。它使用近似值割线替代了切线，并且收敛速度差不多快。\n割线方法及其变体 不难想到，直接用差商\n\\[\\frac{f(x_i)-f(x_{i-1})}{x_i-x_{i-1}} \\]\n去近似替换牛顿法中的\\(f'(x_i)\\)，就得到了割线方法\n\\[x_0,x_1=初始估计 \\]\n\\[x_{i+1}=x_i-\\frac{f(x_i)(x_i-x_{i-1})}{f(x_i)-f(x_{i-1})},i=1,2,3,\\cdots \\]\n假设割线方法收敛到函数\\(f\\)的根\\(r\\)，且\\(f'(r)\\neq 0\\)，近似误差关系\n\\[e_{i+1}\\approx \\bigg|\\frac{f''(r)}{2f'(r)}\\bigg|e_ie_{i-1} \\]\n成立并且\n\\[e_{i+1}\\approx \\bigg|\\frac{f''(r)}{2f'(r)}\\bigg|^{\\alpha-1}e_i^\\alpha \\]\n其中\\(\\alpha = (1+\\sqrt 5)/2\\approx 1.62\\)。割线方法以超线性的速度收敛到一个单根，意味着它在线性和二次收敛方法之间。\n割线方法有三种推广形式，它们也很重要。\n试位方法（Regula Falsi）\n和二分法相似，但是其中的中点被类似割线方法的近似所替换，给定区间\\([a,b]\\)，该区间包含根（假设\\(f(a)f(b)\u003c0\\)），使用割线方法定义下一个点为\n\\[c = a-\\frac{f(a)(a-b)}{f(a)-f(b)}=\\frac{bf(a)-af(b)}{f(a)-f(b)} \\]\n根据\\(f(a)f(c)\u003c0\\)或者\\(f(c)f(b)\u003c0\\)，分别选择新的区间\\([a,c]\\)或\\([c,b]\\)，新的区间仍然可以括住根。\n通常试位方法会表现地比二分法和割线方法都好，但是试位方法不能包子每一步都消除一半的不确定性，有时收敛会很慢。\nMuller方法\n该方法不是计算经过先前两个点的直线和\\(x\\)轴的交点，而是使用桑耳前面生成的点\\(x_0,x_1,x_2\\)，画出通过它们的抛物线\\(y=p(x)\\)，并计算抛物线和\\(x\\)轴的交点。\n书上并没有详细介绍这个方法。\n逆二次插值（IQI）\n是割线方法到抛物线的一种相近的泛化方法。但是使用形如\\(x=p(y)\\)的抛物线，而不是Muller方法中的\\(y=p(x)\\)。\n我们的问题可以立刻求解：这个抛物线和\\(x\\)轴只有一个交点，所以从上一步中的三个估计\\(x_i,x_{i+1},x_{i+2}\\)寻找\\(x_{i+3}\\)，这个过程中没有混淆。\n经过三点\\((a,A),(b,B),(c,C)\\)的二阶多项式\\(x=P(y)\\)为\n\\[P(y) = a\\frac{(y-B)(y-C)}{(A-B)(A-C)}+b\\frac{(y-A)(y-C)}{(B-A)(B-C)}+c\\frac{(y-A)(y-B)}{(C-A)(C-B)} \\]\n这是一个拉格朗日插值的例子，用\\(y=0\\)代入，得到和\\(x\\)轴的交点，经过重新组合与替代，我们得到\n\\[P(0)=c-\\frac{r(r-q)(c-b)+(1-r)s(c-a)}{(q-1)(r-1)(s-1)} \\]\n其中\\(q=f(a)/f(b),r=f(c)/f(b),s=f(c)/f(a)\\)\n对于IQI，设置\n\\[a=x_i,b=x_{i+1},c=x_{i+2},A=f(x_i),B=f(x_{i+1}),C=f(x_{i+2}) \\]\n下一步的估计\\(x_{i+3}=P(0)\\)为\n\\[x_{i+3}=x_{i+2}-\\frac{r(r-q)(x_{i+2}-x_{i+1})+(1-r)s(x_{i+2}-x_{i})}{(q-1)(r-1)(s-1)} \\]\n其中\\(q=f(x_{i})/f(x_{i+1}),r=f(x_{i+2})/f(x_{i+1}),s=f(x_{i+2})/f(x_{i})\\)\nBrent方法 这是一种混合方法，该方法使用前面介绍的迭代技术，推出一个新的方法。\n该方法用于连续函数\\(f\\)，区间的边界是\\(a\\)和\\(b\\)，同时\\(f(a)f(b)\u003c0\\)。Brent方法记录当前点\\(x_i\\)，该点具有最优的后向误差，同时有包含根的区间\\([a_i,b_i]\\)。简单来讲，尝试使用逆二次方法，并在下述情况下，使用结果来替代\\(x_i,a_i,b_i\\)中的一个\n后向误差得到改进 包含根的区间至少减小一半 否则，尝试使用割线方法以实现相同的目的，如果割线方法也失败了，则使用二分法，保证至少减少一半的不确定性。\n方程组 高斯消元法 朴素的高斯消元法 和线性代数中介绍的一致\n对于一个线性方程组可以进行三种操作\n两个方程彼此交换位置 在一个方程上加上或减去另外一个方程的倍数 对于一个方程乘以非零的常数 通常我们也会使用增广矩阵来替代方程组。\n操作次数 引理1\n对于任何正整数\\(n\\)\n\\(1+2+3+\\cdots+n = n*(n+1)/2\\) \\(1^2+2^2+\\cdots+n^2 = n(n+1)(2n+1)/6\\) 消去某一列在主对角线下的元素，以第一列为例，将第二行变为如下形式\n\\[\\begin{matrix} a_{11} \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n} \u0026 | \u0026 b_1\\\\ 0 \u0026 a_{22}-\\frac{a_{21}}{a_{11}}a_{12} \u0026 \\cdots \u0026 a_{2n}-\\frac{a_{21}}{a_{11}}a_{1n} \u0026 | \u0026b_2-\\frac{a_{21}}{a_{11}}b_1 \\end{matrix} \\]\n其他行同理，其中\\(a_{11}\\)在操作中作为除数，这样的数字称为主元。不难得知，如果主元为\\(0\\)，算法会终止，这是朴素办法的一个问题。\n高斯消元法中消去步骤的操作次数\n\\(n\\)个方程\\(n\\)个未知数的消去计算（下三角除了对角线的部分转换为\\(0\\)），可以在\\(2n^3/3+n^2/2-7n/6\\)次操作后完成\n消去之后，矩阵变成上三角形式，之后从最后一个未知数往回带进行求解。\n高斯消元法中回代过程的操作次数\n\\(n\\)个方程\\(n\\)个未知数的三角形系统的回代过程，可以在\\(n^2\\)次操作后完成\n综上，消去的事件复杂度为\\(O(n^3)\\)，回代是\\(O(n^2)\\)，总的是\\(O(n^3)\\)\nLU分解 高斯消元法的矩阵形式 继续同线性代数，我们可以把方程组写成一个矩阵和一个向量相乘的形式，即\\(\\bm A\\bm x=\\bm b\\)\n吧方程组写成矩阵的形式的优势在于可以使用矩阵运算。LU分解是高斯消元法的矩阵形式。它包含把系数矩阵\\(A\\)写做下三角矩阵\\(L\\)和上三角矩阵\\(U\\)的乘积\n我们有关于LU分解的三个事实\n令\\(L_{ij}(-c)\\)表示下三角矩阵，其主对角线上的元素为\\(1\\)，在\\((i,j)\\)位置上的元素为\\(-c\\)。则\\(A\\to L_{ij}(-c)A\\)表示行运算“从第\\(i\\)行中减去第\\(j\\)行的\\(c\\)倍”。 例如\\(L_{21}(-c)\\)\n\\[A= \\begin{bmatrix} a_{11} \u0026 a_{12} \u0026 a_{13}\\\\ a_{21} \u0026 a_{22} \u0026 a_{23}\\\\ a_{31} \u0026 a_{32} \u0026 a_{33} \\end{bmatrix}\\to \\begin{bmatrix} 1 \u0026 0 \u0026 0\\\\ -c \u0026 1 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} a_{11} \u0026 a_{12} \u0026 a_{13}\\\\ a_{21} \u0026 a_{22} \u0026 a_{23}\\\\ a_{31} \u0026 a_{32} \u0026 a_{33} \\end{bmatrix} \\]\n\\[=\\begin{bmatrix} a_{11} \u0026 a_{12} \u0026 a_{13}\\\\ a_{21}-ca_{11} \u0026 a_{22}-ca_{12} \u0026 a_{23}-ca_{13}\\\\ a_{31} \u0026 a_{32} \u0026 a_{33} \\end{bmatrix} \\]\n\\(L_{ij}(-c)^{-1}=L_{ij}(c)\\) 下面的矩阵乘积成立 \\[\\begin{bmatrix} 1 \u0026 \u0026 0\\\\ c_1 \u0026 1 \u0026 \\\\ \u0026 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 \u0026 \\\\ \u0026 1 \u0026 \\\\ c_2 \u0026 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 \u0026 \\\\ \u0026 1 \u0026 \\\\ \u0026 c_3 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 \u0026 \\\\ c_1 \u0026 1 \u0026 \\\\ c_2 \u0026 c_3 \u0026 1 \\end{bmatrix} \\]\n根据以上事实，我们可以把系数矩阵\\(A\\)表示为\\(A=LU\\)，其中\\(U\\)和高斯消元得到的上三角矩阵相同，而\\(L\\)矩阵就是所进行的操作乘起来的矩阵。\n使用LU分解回代 一旦知道\\(L,U\\)，问题\\(Ax=b\\)就可以转化为\\(LUx=b\\)。定义\\(c=Ux\\)，则回代有两个步骤\n对于方程\\(Lc=b\\)，求解\\(c\\) 对于方程\\(Ux=c\\)，求解\\(x\\) 其中\\(Lc=b\\)因为\\(L\\)是下三角矩阵，从上往下回代，\\(Ux=c\\)因为\\(U\\)是上三角矩阵，从下往上回代。\nLU分解的复杂度 如果只有一个方程组，那么和高斯消元法没有区别\n但是，如果我们遇到的问题是\n\\[Ax=b_1\\\\ Ax=b_2\\\\ \\cdots\\\\ Ax=b_k \\]\n这样的。那LU分解会比高斯消元一个一个去计算要来得快。\n但是，并不是所有的矩阵都可以进行\\(LU\\)分解\n例如分解\n\\[\\begin{bmatrix} 0 \u0026 1\\\\ 1 \u0026 1 \\end{bmatrix} = \\begin{bmatrix} 1 \u0026 0\\\\ a \u0026 1 \\end{bmatrix} \\begin{bmatrix} b \u0026 c\\\\ 0 \u0026 d \\end{bmatrix}= \\begin{bmatrix} b \u0026 c\\\\ ab \u0026 ac+d \\end{bmatrix} \\]\n由于\\(ab=1,b=0\\)不可能同时成立，所以反证法得知不能分解。\n误差来源 误差放大和条件数 定义1\n向量\\(x=(x_1,\\cdots,x_n)\\)的无穷范数或者最大范数为\\(||x||_\\infty=max|x_i|\\)，即\\(x\\)所有元素中的最大绝对值。\n定义2\n令\\(x_a\\)是线性方程组\\(Ax=b\\)的近似解。余项是向量\\(r=b-Ax_a\\)，后向误差是余项的范数\\(||b-Ax_a||_\\infty\\)，前向误差是\\(||x-x_a||_\\infty\\)\n同时也定义相对后向误差为\n\\[\\frac{||r||_\\infty}{||b||_\\infty} \\]\n相对前向误差定义为\n\\[\\frac{||x-x_a||_\\infty}{||x||_\\infty} \\]\n这个方程的误差放大因子是二者的比率，即\n\\[误差放大因子=\\frac{相对前向误差}{相对后向误差} \\]\n定义3\n方阵\\(A\\)的条件数\\(cond(A)\\)为求解\\(Ax=b\\)时，对于所有右侧向量\\(b\\)，可能出现的最大误差放大因子。\n和向量范数类似，定义\\(n\\times n\\)矩阵\\(A\\)的矩阵（无穷）范数为\n\\[||A||_\\infty = 每行元素绝对值之和的最大值 \\]\n定理1\n\\(n\\times n\\)矩阵\\(A\\)的条件数是\n\\[cond(A) = ||A||\\cdot||A^{-1}|| \\]\n依据误差放大因子，在求解\\(Ax=b\\)可能出现的相关前向误差是\\(\\varepsilon_{math}\\cdot cond(A)\\)。换句话说，如果\\(cond(A)\\approx 10^k\\)，我们在计算\\(x\\)时，将丢掉\\(k\\)位数字精度。\n向量范数和矩阵范数的性质\n对于向量无穷范数\n\\(||x||\\geq 0\\)，当且仅当\\(x=[0,\\cdots,0]\\)时等号成立 对于每个标量\\(\\alpha\\)和向量\\(x\\)，\\(||\\alpha x||=|\\alpha|\\cdot ||x||\\) 对于向量\\(x,y\\)有\\(||x+y||\\leq||x||+||y||\\) 对于矩阵无穷范数\n\\(||A||\\geq 0\\)，当且仅当\\(A=0\\)时等号成立 对于每个标量\\(\\alpha\\)和向量\\(x\\)，\\(||\\alpha A||=|\\alpha|\\cdot ||A||\\) 对于矩阵\\(A,B\\)有\\(||A+B||\\leq||A||+||B||\\) 被称为算子范数的矩阵范数，也可以使用特定的向量范数进行定义\n\\[||A||=\\max \\frac{||Ax||}{||x||} \\]\n对于任意矩阵\\(A\\)和向量\\(x\\)满足\n\\[||Ax||\\leq ||A||\\cdot||x|| \\]\n淹没 考虑如下方程组\n\\[10^{-20}x_1+x_2=1\\\\ x_1+2x_2=4 \\]\n高斯消元如下\n\\[\\begin{bmatrix} 10^{-20} \u0026 1 \u0026 | \u0026 1\\\\ 1 \u0026 2 \u0026 | \u0026 4 \\end{bmatrix}\\to \\begin{bmatrix} 10^{-20} \u0026 1 \u0026 | \u0026 1\\\\ 0 \u0026 2-10^{20} \u0026 | \u0026 4-10^{20} \\end{bmatrix} \\]\n然后解出\n\\[[x_1,x_2]=\\bigg [\\frac{2\\times 10^{20}}{10^{20}-2},\\frac{4-10^{20}}{2-10^{20}}\\bigg]\\approx[2,1] \\]\n我们手算是可以这样的，但是当我们使用IEEE双精度的时候，\n\\[\\begin{bmatrix} 10^{-20} \u0026 1 \u0026 | \u0026 1\\\\ 0 \u0026 2-10^{20} \u0026 | \u0026 4-10^{20} \\end{bmatrix} \\]\n舍入得\n\\[\\begin{bmatrix} 10^{-20} \u0026 1 \u0026 | \u0026 1\\\\ 0 \u0026 -10^{20} \u0026 | \u0026 -10^{20} \\end{bmatrix} \\]\n然后首先解出\\(x_2=1\\)，然后\\(x_1=0\\)，与精确解相比相差巨大。\n我们的解决办法是，更换行顺序，\n\\[\\begin{bmatrix} 1 \u0026 2 \u0026 | \u0026 4\\\\ 10^{-20} \u0026 1 \u0026 | \u0026 1 \\end{bmatrix}\\to \\begin{bmatrix} 1 \u0026 2 \u0026 | \u0026 4\\\\ 0 \u0026 1-2\\times 10^{-20} \u0026 | \u0026 1-4\\times 10^{-20} \\end{bmatrix} \\]\n舍入后也可以得到\\(x_2=1\\)，然后\\(x_1=2\\)。\n上述例子告诉我们，高斯消去的过程中要尽可能保证乘子比较小。\nPA=LU分解 部分主元 部分主元要求，在每一次选择主元时，找到这一列中绝对值最大的一个元素，其对应行与主元行进行交换。交换之后作为新的主元。这样我们就能完全避免淹没问题。\n同样，这样可以避免\\(0\\)主元问题。如果这一列没有非零元素，则矩阵是奇异矩阵，此时高斯消元怎样都不能得到正确解。\n置换矩阵 定义1\n置换矩阵是一个\\(n\\times n\\)矩阵，其在每一行、每一列仅有一个\\(1\\)，其他全部为\\(0\\)\n置换矩阵基础定理\n令\\(P\\)是通过对单位矩阵实施一组特定的行交换后得到的一个\\(n\\times n\\)的置换矩阵，则对于任意的\\(n\\times n\\)矩阵\\(A\\)，\\(PA\\)对应于对矩阵\\(A\\)实施同样的行变换得到的结果。\n例如\n\\[\\begin{bmatrix} 1 \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \\\\ 0 \u0026 1 \u0026 0 \\end{bmatrix} \\]\n是由单位矩阵交换二三行得到的，则\n\\[\\begin{bmatrix} 1 \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \\\\ 0 \u0026 1 \u0026 0 \\end{bmatrix} \\begin{bmatrix} a \u0026 b \u0026 c\\\\ d \u0026 e \u0026 f \\\\ g \u0026 h \u0026 i \\end{bmatrix}= \\begin{bmatrix} a \u0026 b \u0026 c \\\\ g \u0026 h \u0026 i \\\\ d \u0026 e \u0026 f \\end{bmatrix} \\]\n即把后面那个矩阵也交换了二三行。\n","date":"2022-10-02T16:42:53+08:00","image":"https://kegalas.top/p/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/cover_hu6778f7153b0100018882cd949f083bca_49831_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"数值分析学习笔记"},{"content":"电路的基本规律 集中（或集总）参数电路 实际电路的几何尺寸远小于工作波长时，我们用能足够精确反映其电磁性质的一些理想电路元件或他们的组合来模拟实际元件，这种理想化的电路元件称为集中参数元件。由其连接组成的电路称为集中参数电路。\n而一些远距离输电线就不能看做集中参数电路，称作分布参数电路，要用其他理论来研究。\n电流 单位时间内通过导体横截面的电荷量\\(q\\)定义为电流强度，简称电流，用\\(i,i(t)\\)表示，即\n\\[i(t)=\\frac{dq(t)}{dt} \\]\n电荷量的单位是库伦，时间的单位是秒，电流的单位是安培。\n方向，一般把正电荷运动的方向定义为电流的实际方向。但在具体电路中，电流的实际方向常常随时间变化。通常在分析电路时会指定某一方向为电流方向，称为电流的参考方向。如果参考方向和实际方向一致，则电流\\(i\u003e0\\)，否则\\(i\u003c0\\)。\n电流的参考方向是任意指定的，一般用箭头和双下标表示，如\\(i_{ab}\\)指\\(a\\)到\\(b\\)的电流。\n电压 电路中，电场力将单位正电荷从某点移到另一点所作的功定义为该两点之间的电压，也称电位差，用\\(u,u(t)\\)表示，即\n\\[u(t)=\\frac{dw(t)}{dq(t)} \\]\n功的单位是焦耳，电压的单位是伏特。\n通常，高电位为正极，低电位为负极。\n和电路的参考方向一样，我们也可以为电压指定参考极性。在分析电路问题时，先指定电压的参考极性，\\(+\\)表示高电位，\\(-\\)表示低电位。如果电压的参考极性和实际极性一致，则\\(u\u003e0\\)，否则\\(u\u003c0\\)。\n电流参考方向给定，若电流流入的方向是电压的高电位，流出的方向是电压的低电位，则称此时电流、电压是关联参考方向。反之为非关联参考方向。\n能量 正电荷从电路元件上电压的正极经元件移动到负极是电场力对电荷做功的结果，此时元件吸收能量。反之发出能量。\n若某元件两端的电压为\\(u\\)，在\\(dt\\)时间内流过该元件的电荷量为\\(dq\\)，那么，根据电压的定义式，电场力做的功\\(dw(t)=u(t)dq(t)\\)。\n在关联参考方向时，\\(dw(t)=u(t)i(t)dt\\)\n功率 能量对时间的变化率称为电功率。\n\\[p(t)=u(t)i(t) \\]\n基尔霍夫定律 电路图\n如果仅研究各元件的连接关系，暂不关心元件本身的特性，则可用一条线段来代表元件。\n支路\n电路图中的每一个元件，即图中的每一条线段，称为支路。\n节点\n支路的连接点称为节点。\n路径\n在图中，从某一节点出发。连续地经过一些支路和节点（只能各经过一次），到达另一节点，就构成路径。\n回路\n如果路径的最后到达点就是出发点，则这样的闭合路径称为回路。\n基尔霍夫 电流定律 对于集中参数电路中的任一节点，在任意时刻，流出该节点电流的和等于流入该节点电流的和。\n\\[\\sum_{流出} i(t) = \\sum_{流入} i(t)\\quad \\forall t \\]\n基尔霍夫电压定律 在集中参数电路中，任意时刻沿任一回路绕行，回路中所有支路电压的代数和恒为零\n\\[\\sum u(t) = 0\\quad\\forall t \\]\n注意，上式在计算时，需要任意指定一个回路的绕行方向，凡是之路电压的参考方向与回路的绕行方向一致者，该电压前面去+号；否则取-号。\n电阻元件 二端电阻 二端电阻元件可以定义为：一个二端元件，如果在任意时刻\\(t\\)，其两端电压\\(u\\)与流经它的电流\\(i\\)之间的关系(VCR)能用\\(u-i\\)平面上通过原点的曲线所确定，就称其为二端电阻元件，简称电阻元件。\n由于电压和电流的单位是V和A，因而电阻元件的特性称为伏安特性或伏安关系。\n如果电阻元件的伏安特性不随时间变化，则称其为非时变的。否则就是时变的。\n如果伏安特性是通过原点的直线，则称为线性的，否则是非线性的。\n欧姆定律\n在电压、电流参考方向相关联时，其电压与电流的关系就是熟知的欧姆定律\n\\[u(t)=Ri(t)\\quad\\forall t \\]\n或者\n\\[i(t) = Gu(t)\\quad\\forall t \\]\n其中电阻\\(R\\)的单位是欧姆\\(\\Omega\\)，电导\\(G\\)的单位是西\\(S\\)。对于线性非时变电阻元件，\\(R\\)和\\(G\\)都是常实数，他们的关系是\n\\[G=\\frac{1}{R} \\]\n分立电阻与集成电阻 任何材料都有电阻。导体、半导体和绝缘体三者的区别是材料的电阻率\\(\\rho\\)。通常\\(\\rho\u003c10^{-4}\\Omega\\cdot m\\)的材料称为导体，\\(\\rho\u003e10^4\\Omega\\cdot m\\)的材料称为绝缘体，介于其中的称为半导体。\n一段长度为\\(L\\)、截面积为\\(S\\)、电阻率为\\(\\rho\\)的材料，其电阻值为\n\\[R = \\rho\\frac{L}{S} \\]\n分立电阻器的主要参数\n电子电路中单个使用的具有电阻特性的元件，称为分立电阻器。电阻元件是由实际电阻器抽象出来的理想化模型。\n电阻元件和电阻器不是一个概念。电阻元件的参数只有一个电阻值，而电阻器的元件参数包括标称值、容差、额定功率、温度系数等。\n集成电阻\n集成电阻又称扩散电阻、薄层电阻。\n通过复杂的扩散工艺在硅片上生成一定尺寸的薄层而制成的电阻，称为扩散电阻。\n无论是分离电阻器还是集成电阻，分析时都应该抽象为电阻元件。\n电源 电压源 一个二端元件，如果其端口电压总能保持为给定的电压\\(u_s(t)\\)，而与通过它的电流无关，则称其为电压源。\n如果\\(u_s(t)\\)为恒定值，则称其为直流电压源或恒定电压源。\n电压源具有如下特点：\n无论通过它的电流为何值，电压源的端口电压\\(u\\)总保持\\(u(t)=u_s(t)\\) 电压源的电流由电压源和与它相连的外电路共同决定。 电流源 一个二端元件，如其端口电流值总能保持为给定的电流\\(i_s(t)\\)，而与其端口电压无关，则称其为电流源。\n如果\\(i_s(t)\\)为恒定值，则称其为直流电流源或恒定电流源。\n电流源具有如下特点：\n无论其端口电压\\(u\\)为何值，电流源的电流\\(i\\)总保持\\(i(t)=i_s(t)\\) 电流源的端口电压源由电流源和与它相连的外电路共同决定。 电路中的参考点 在电路分析中，常常指定电路中的某点为参考点，计算或测量其它各节点对参考点的电位差，称其为各节点的电位，或各节点的电压。\n受控源 非独立电源是指电压源的电压或电流源的电流不是给定的时间函数，而是受电路中某支路电压或电流控制的，因此常称为受控源。\n受控源的符号通常用菱形，而不是圆形。\n电路等效 概念 对于两部分结构、元件参数完全不同的电路，若它们具有完全相同的端口电压电流关系，就称它们是等效的。\n电阻的串联和并联 串联\n\\[R_{eq}=R_1+R_2+\\cdots \\]\n串联时，电流相等；各电阻的电压如下\n\\[u_k=R_k i =\\frac{R_k}{R_{eq}}u \\]\n并联\n电导有\n\\[G_{eq}=G_1+G_2+\\cdots \\]\n电阻有\n\\[\\frac{1}{R_{eq}}=\\frac{1}{R_{1}}+\\frac{1}{R_{2}}+\\cdots \\]\n并联时，电压相同，各电阻的电流如下\n\\[i_k=G_iu=\\frac{G_k}{G_{eq}}i \\]\n电阻Y型和三角形电路的等效变换 1.jpg\r含独立源电路的等效 独立源的串联和并联 电压源串联\n电压源串联时，得到的净电压等于电压极性相同的各个电源电压总和，减去极性相反的各电源电压总和。净电压方向与大的那个相同。\n电压源并联\n只有两端电压是相同的电压源才可以并联。可以增加输出电流的能力。\n电流源串联\n只有电流大小相同的电流源能串联。\n电流源并联\n电流源并联时，得到的等效电流源电流大小等于极性相同的各个电源流总和，减去极性相反的各电源电流总和。净电流方向与大的那个相同。\n实际电源的等效变换\n实际电源，比如电池，我们在高中通常会说它含有一个内阻。也就是等价为一个理想电压源+一个电阻的串联。我们也可以将其等价为一个理想电流源+一个电阻的并联。如下图\n2.jpg\r电压源的等效转移\n电流源可以转移到各并联支路上，如下图\n3.jpg\r可以证明，此时电路中的KVL仍然保持不变。\n电流源的等效转移\n电流源可以转移成如下形式\n4.jpg\r电阻电路分析 图与电路方程 图的基本概念\n图的定义和离散数学、算法竞赛图论部分没有什么差别。\n主要介绍基本回路：仅包含一条连支（其余为树枝，即树加了任意一条连支）的回路称为单连支回路或基本回路\n基本割集：仅包含一条树枝（其余为连支）的割集称为单树支割集或基本割集。\nKCL与KVL的独立方程\n根据我们的朴素想法，我们会把每一个节点的KCL方程和每一个回路的KVL方程列出来，试图求解电路中的所有未知量。这的确是可行的，但是，我们会发现我们有一些方程是可以由其他方程推出的，这就导致了不是所有方程都是独立的。\n可以证明，对于有\\(n\\)个节点的连通图，任选\\(n-1\\)个节点所列的\\(KCL\\)方程是独立的。这些对应的节点叫独立节点，另外一个节点叫参考节点。\n对于\\(n\\)个节点、\\(b\\)条支路的连通图，有\\(L=b-n+1\\)个基本回路，可以列出\\(L\\)个独立的KVL方程。\n或者说，对于平面图，有\\(L\\)个网孔，可以根据这\\(L\\)个网孔列出独立的KVL方程。\n在平面图中，网孔就是内部不包含边的回路。\n2b法和支路法 2b法 对一个具有\\(b\\)条支路和\\(n\\)个节点的电路，当以支路电压和支路电流为变量列写方程时，共有\\(2b\\)个未知变量，根据KCL可列出\\(n-1\\)个独立方程，根据KVL可列出\\(b-n+1\\)个独立方程；根据元件的伏安关系，每条支路可以列出\\(b\\)个支路电压和电流关系的方程。于是总共列出了\\(2b\\)个方程。\n这个方法称为\\(2b\\)法，可行，但是对于手算不方便\n支路法 如果以支路电流（或支路电压）为电路变量列出方程，求解支路电流（或支路电压），则称为支路电流（支路电压）法。\n步骤如下\n选定各支路电流的参考方向 对\\(n-1\\)个独立节点，列出KCL方程 对所有的网孔，按指定回路绕行方向，根据KVL，列出电压方程 总共列出了\\(b\\)个方程。\n例如：\n5.jpg\r任一回路内，电阻上电压的代数和等于电压源电压的代数和，其中支路电流参考方向与回路方向一致者，\\(R_ki_k\\)前取\\(+\\)号，否则取\\(-\\)号，电压源\\(u_{sk}\\)的参考方向与回路方向相反者取\\(+\\)号，否则取\\(-\\)号。（当然在本例中电压源写在了方程等号左边，上面说的符号是写在右边时的符号）\n回路法和网孔法 以独立回路电流为未知变量列出并求解方程的方法称为回路法。若选平面电路的网孔作独立回路，则这样的回路法又常称为网孔法。\n回路电流实际上并不存在，只是为了方便分析而引入的概念。\n回路法的步骤归纳如下\n选定一组独立回路，并指定各回路电流的参考方向 列出回路方程（注意电阻和电压源的符号） 解方程 例如：\n6.jpg\r节点法 以节点电压为未知变量列出并求解方程的方法称为节点法\n在电路中任选一个节点为参考节点，其余节点与参考节点之间的电压称为节点电压或节点电位。\n7.jpg\r8.jpg\r但以上方程不需要推导，可以直观的列出\n规律如下：\n\\(G_{ii}\\)称为节点\\(i\\)的自电导，等于与节点\\(i\\)相连的所有支路的电导之和，恒取\\(+\\) \\(G_{ij}(i\\neq j)\\)称为节点\\(i,j\\)之间的互电导，等于两节点之间的电导之和，恒取\\(-\\) \\((\\sum I_s)_i\\)称为节点\\(i\\)的等效电流源，等于流入节点\\(i\\)的所有电流源电流的代数和。流入为\\(+\\)，流出为\\(-\\) 齐次定理和叠加定理 首先介绍齐次性和叠加性，对于线性映射\\(f\\)，它满足\n齐次性（比例性），即 \\[f(ax)=af(x) \\]\n可加性（叠加性） \\[f(x_1+x_2) = f(x_1)+f(x_2) \\]\n两者也可以结合使用。\n例如\\(f(x)=ax\\)是线性的，但\\(f(x)=ax+b\\)就不是线性的。\n齐次定理 对于有唯一解的线性电路，当只有一个激励源（独立电压源或独立电流源，必须是独立的）x(t)作用时，其响应y(t)（电路任意处的电压或电流）与激励成齐次关系。例如\n9.jpg\r注意：\n只能用于有唯一解的线性电路，不能用于非线性电路 响应也称为输出，指电路中任意处的电流或电压；功率与激励源之间不存在线性关系 激励也称为输入，指电路中的独立源，受控源不是激励源 叠加定理 对于有唯一解的线性电路，多个激励源共同作用时引起的响应（电路中各处的电流、电压）等于各个激励源单独作用时（其他激励源置零，具体表现为电压源变成导线，电流源变成开路）所引起的响应之和\n替代定理 对于有唯一解的线性或非线性电路，若某支路的电压\\(u\\)或电流\\(i\\)已知，则该支路可用方向和大小与\\(u\\)相同的电压源替代，或用方向和大小与\\(i\\)相同的电流源替代，而不会影响其他点的电流和电压。\n注意，替换成电流源后电压不变，替换成电压源后电流也不变。\n等效电源定理 戴维南定理 任意一个线性二端含源电路\\(N\\)，对其外部而言，可以用一个电压源和电阻的串联组合来等效。该电压源的电压值\\(U_{OC}\\)等于电路\\(N\\)二端子间的开路电压，其串联电阻值\\(R_0\\)等于电路N内部所有独立源置零时二端子的等效电阻。\n例如\n10.jpg\r求其等效电源，先将\\(ab\\)断开，计算等效电压\n\\[U_{OC}=\\frac{6}{6+3}\\times 24-\\frac{4}{4+4}\\times 24 = 4V \\]\n将电压源置零，得到一根导线，计算等效电阻为\n\\[R_0=\\frac{18}{9}+\\frac{16}{8}=4\\Omega \\]\n得到的等效电源为\n11.jpg\r诺顿定理 诺顿定理与戴维南不同的地方是，诺顿定理等效为一个电流源和一个电阻并联。本质上是等效的。\n我们可以选择先计算戴维南等效，再电源等效为电流源。\n也可以选择将两个端子短路来计算等效电流源，将独立源置零来计算等效并联电阻。\n计算技巧 等效的电流源和电压源是容易计算的，电流源将两个端子短路，电压源将两个端子开路。\n没有受控源时，将独立源置零，根据串并联关系，等效电阻也是容易计算的。\n当有受控源时\n外加电源法\n12.jpg\r13.jpg\r开路短路法\n即计算开路电压\\(u_{oc}\\)和短路电流\\(i_{sc}\\)，得到\\(R_0=u_{oc}/i_{sc}\\)\n伏安关系法\n直接对二端线性电路\\(N\\)，推导出两端子上的电压\\(u\\)和电流\\(i\\)之间的一次关系式，通常是以下形式\n\\[u=u_{oc}-R_0i \\]\n就可以得到开路电压和等效内阻。\n最大传输功率电源定理 在电子技术中，常要求负载从给定电源（或给定电路）获得最大功率，即最大功率传输问题。\n实际应用常遇到这样的问题：一个有源二端电路，向负载电阻\\(R_L\\)供电。问\\(R_L\\)为何值时其上获得最大功率？\n由于电路\\(N\\)给定，可以将其等效为戴维南等效电路来分析。\n设等效电压为\\(u_{oc}\\)，电源内阻为\\(R_0\\)，则\n\\[P_L = \\bigg(\\frac{u_{oc}}{R_0+R_L}\\bigg)^2R_L \\]\n可以用求导等方式证明，\\(R_L=R_0\\)时，其\\(P_L\\)最大。这称为最大功率匹配条件。\n特勒根定理和互易定理 特勒根定理 定理1\n对于任意一个具有\\(b\\)条支路\\(n\\)个节点的集总参数电路，设支路电压、支路电流分别为\\(u_k,i_k\\)，且各支路电压和电流取关联参考方向，对任何时间\\(t\\)，有\n\\[\\sum^b_{k=1}u_ki_k=0 \\]\n定理2\n对于任意两个拓扑结构完全相同（即图完全相同，各支路组成元件性质任意）的集中参数电路\\(N\\)和\\(N'\\)。设它们具有\\(b\\)条支路\\(n\\)个节点，其相对应的各支路和各节点的编号相同。设它们的支路电压分别为\\(u_k\\)和\\(u'_k\\)，支路电流分别为\\(i_k\\)和\\(i'_k(k=1,2,\\cdots,b)\\)，且各支路电压和电流取关联参考方向，则对任意时刻\\(t\\)，有\n\\[\\sum^b_{k=1}u_ki'_k=0 \\]\n\\[\\sum^b_{k=1}u'_ki_k=0 \\]\n互易定理 互易定理表明: 对于一个仅含线性电阻的二端口电路\\(N_R\\)，在只有一个激励源的情况下，当激励与响应互换位置时，同一激励所产生的响应相同。\n有三个形式\n15.png\r16.png\r动态电路 动态元件 电容 一个二端元件，若在任一时刻\\(t\\)，其电荷\\(q(t)\\)与电压\\(u(t)\\)之间的关系能用\\(q\\sim u\\)平面上的曲线表征，即具有代数关系\\(f(u,q)=0\\)，则称该元件为电容元件，简称电容。\n电容分为时变的和非时变的、线性的和非线性的，我们主要讨论线性非时变电容。\n此时电容的库伏特性是\n\\[q(t) = Cu(t) \\]\n其中\\(C\\)与时间无关，是电容的大小，单位为法拉（电量单位为库伦时）。\n电容的VAR\n当电容两端的电压变化时，聚集在电容上的电荷也相应发生变化，表明连接电容的导线上电荷移动，即电流流过；若电容上电压不变化，电荷也不变化，即电流为零。\n微分关系\n若电容上电压与电流参考方向关联，则有\n\\[i(t) = C\\frac{du(t)}{dt} \\]\n积分关系\n\\[u(t) = \\frac{1}{C}\\int^t_{-\\infty}i(\\xi)d\\xi \\]\n设\\(t=t_0\\)为初始观察时刻，上式可改写为\n\\[u(t) = \\frac{1}{C}\\int^{t_0}_{-\\infty}i(\\xi)d\\xi+\\frac{1}{C}\\int^{t}_{t_0}i(\\xi)d\\xi=u(t_0)+\\frac{1}{C}\\int^{t}_{t_0}i(\\xi)d\\xi,t\\geq t_0 \\]\n其中\n\\[u(t_0)=\\frac{1}{C}\\int^{t_0}_{-\\infty}i(\\xi)d\\xi \\]\n称电容电压在\\(t_0\\)时刻的初始值，或初始状态，它包含了在\\(t_0\\)以前电流的“全部历史”信息。一般取\\(t_0=0\\)。\n注意\n电容的伏安关系是微积分关系，因此电容元件是动态元件。而电阻元件的伏安关系是代数关系，电阻是一个即时(瞬时)元件。 任意时刻，通过电容的电流与该时刻电压的变化率成正比。当电容电流\\(i\\)为有限值时，其\\(du/dt\\)也为有限值，则电压\\(u\\)必定是连续函数，此时电容电压不会跃变。 当电容电压为直流电压时，则电流\\(i = 0\\)，此时电容相当于开路，故电容有隔直流的作用。 由电容VAR的积分形式可知:在任意时刻t，电容电压u是此时刻以前的电流作用的结果，它“记载”了以前电流的“全部历史”。即电容电压具有“记忆”电流的作用，故电容是一个记忆元件，而电阻是无记忆元件。 电容的功率和储能\n功率\n当电压和电流为关联方向时，电容吸收的瞬时功率为\n\\[p(t) = u(t)i(t) = Cu(t)\\frac{du(t)}{dt} \\]\n电容是储能元件，它不消耗能量。释放的能量不会超过吸收的能量。电容不能产生能量，因此为无源元件。\n储能\n对功率从\\(-\\infty\\)到\\(t\\)进行积分，即得\\(t\\)时刻电容上的储能：\n\\[w_c(t)=\\int^t_{-\\infty}p(\\xi)d\\xi=\\int^{u(t)}_{u(-\\infty)}Cu(\\xi)du(\\xi)=\\frac{1}{2}Cu^2(t)-\\frac{1}{2}Cu^2(-\\infty) \\]\n而未充电时应有\\(u(-\\infty)=0\\)，所以\n\\[w_c(t) = \\frac{1}{2}Cu^2(t) \\]\n电容在某一时刻\\(t\\)的储能仅取决于此时刻的电压，而与电流无关，并且大于等于零。\n电感 一个二端元件，若在任一时刻\\(t\\)，其磁链\\(\\varPsi(t)\\)与电流\\(i(t)\\)之间的关系能用\\(\\varPsi\\sim i\\)平面上的曲线表征，即具有代数关系\\(f (\\varPsi, i ) = 0\\)，则称该元件为电感元件，简称电感。\n电感也分为时变的和非时变的、线性的和非线性的。\n主要讨论的是线性非时变电感。\n线性时不变电感的外特性（韦安特性）是\\(\\varPsi\\sim i\\)平面上一条过原点的直线，且其斜率\\(L\\)不随时间变化，\n\\[\\varPsi(t) = Li(t) \\]\n磁链单位是韦伯，电感单位是亨利。\n电感的VAR\n电感中，当电流变化时，磁链也发生变化，从而产生感应电压。在电流与电压参考方向关联时，若电压参考方向与磁通的方向符合右手法则，根据法拉第电磁感应定律，感应电压\\(u_L(t)\\)与磁链的变化率成正比，即：\n微分关系\n\\[u_L(t)=\\frac{d\\varPsi(t)}{dt}=L\\frac{di(t)}{dt} \\]\n积分关系\n\\[i(t) = \\frac{1}{L}\\int^t_{-\\infty}u(\\xi)d\\xi \\]\n设\\(t=t_0\\)为初始观察时刻，上式可改写为\n\\[i(t) = \\frac{1}{L}\\int^{t_0}_{-\\infty}u(\\xi)d\\xi+\\frac{1}{L}\\int^{t}_{t_0}u(\\xi)d\\xi=i(t_0)+\\frac{1}{L}\\int^{t}_{t_0}u(\\xi)d\\xi,t\\geq t_0 \\]\n其中\n\\[i(t_0)=\\frac{1}{L}\\int^{t_0}_{-\\infty}u(\\xi)d\\xi \\]\n称电感电流在\\(t_0\\)时刻的初始值，或初始状态，它包含了在\\(t_0\\)以前电压的“全部历史”信息。一般取\\(t_0=0\\)。\n注意\n电感元件是动态元件。 电感的电压与该时刻电流的变化率成正比 电流\\(i\\)是连续函数，电感电流不会跃变 电感对直流相当于短路。 电感电流\\(i\\)是此时刻以前的电压作用的结果，它“记载” 了以前电压的“全部历史”。即电感也是一个记忆元件。 电感是一个储能元件，它从外部电路吸收的能量，以磁场能量的形式储存于自身的磁场中。电感\\(L\\)在某一时刻的储能只与该时刻\\(t\\)电感电流有关。 电感的功率与储能\n功率\n当电压和电流为关联方向时，电感吸收的瞬时功率为\n\\[p(t) = u(t)i(t) = Li(t)\\frac{di(t)}{dt} \\]\n电感是储能元件，它不消耗能量。释放的能量不会超过吸收的能量。电感不能产生能量，因此为无源元件。\n储能\n对功率从\\(-\\infty\\)到\\(t\\)进行积分，即得\\(t\\)时刻电感上的储能：\n\\[w_c(t)=\\int^t_{-\\infty}p(\\xi)d\\xi=\\int^{i(t)}_{i(-\\infty)}Li(\\xi)di(\\xi)=\\frac{1}{2}Li^2(t)-\\frac{1}{2}Li^2(-\\infty) \\]\n而未充电时应有\\(i(-\\infty)=0\\)，所以\n\\[w_c(t) = \\frac{1}{2}Li^2(t) \\]\n电感在某一时刻\\(t\\)的储能仅取决于此时刻的电流，而与电压无关，并且大于等于零。\n电容的串并联 串联\n\\[\\frac{1}{C_{eq}}=\\frac{1}{C_1}+\\frac{1}{C_2}+\\cdots+\\frac{1}{C_n} \\]\n并联\n\\[C_{eq}=C_1+C_2+\\cdots+C_n \\]\n电感的串并联 串联\n\\[L_{eq}=L_1+L_2+\\cdots+L_n \\]\n并联\n\\[\\frac{1}{L_{eq}}=\\frac{1}{L_1}+\\frac{1}{L_2}+\\cdots+\\frac{1}{L_n} \\]\n动态电路方程及其解 动态电路方程 一阶电路\n17.jpg\r由KCL等可得\n\\[\\frac{du_C}{dt}+\\frac{1}{\\tau}u_C = \\frac{1}{RC}u_S \\]\n其中\\(\\tau=RC\\)，量纲为秒，称为时常数。\n18.jpg\r由\\(KVL\\)等可得\n\\[\\frac{i_L}{dt} + \\frac{1}{\\tau}i_L = \\frac{R}{L}i_s \\]\n其中\\(\\tau=L/R\\)，其量纲也为秒。\n观察两个方程，除了变量不同，均为典型的一阶微分方程，因此均为一阶电路。一般形式为\n\\[y'(t)+ay(t) = bf(t) \\]\n其中\\(y(t)\\)为响应，\\(f(t)\\)为激励。\n二阶电路\n19.jpg\r\\[\\frac{d^2 u_C}{dt^2} + \\frac{R}{L}\\frac{du_C}{dt}+\\frac{1}{LC}u_c = \\frac{1}{LC}u_S \\]\n建立动态方程的一般步骤\n根据电路建立KCL或KVL方程，写出各个元件的伏安关系 在以上方程中消去中间变量，得到所需变量的微分方程 对于较复杂的动态电路，常用拉普拉斯变换进行分析 动态电路方程的求解 同高数内容，不再赘述。对于电路的一些形式可以在三要素部分介绍。\n电路的初始值 换路定律 若电容电流\\(i_C\\)和电感电压\\(u_L\\)在\\(t=0\\)时为有限制，则换路前后瞬间电容电压\\(u_C\\)和电感电流\\(i_L\\)是连续的，即\n\\[\\left\\{\\begin{matrix} u_C(0_+) =u_C(0_-)\\\\ i_L(0_+) = i_L(0_-) \\end{matrix}\\right. \\]\n而除了这两个值（独立初始值），其余各处的电压电流（非独立初始值）不受换路定律的约束，可以出现跃变。\n独立初始值的求解 在换路之前，也就是\\(t\u003c0\\)时，直流电源作用下电路处于稳态。此时电容可以视为开路，电感视为短路，由此我们可以直接计算\\(u_C(0_-)\\)和\\(i_L(0_-)\\)，就像没有动态元件时所做的那样。\n然后根据换路定律就可以求出\\(t=0_+\\)时的独立初始值。\n非独立初始值的求解 在\\(t=0_+\\)时刻，将电容用电压等于\\(u_C(0_+)\\)的电压源替代，电感用电流等于\\(i_L(0_+)\\)的电流源替代，再去计算各处的电流电压。\n动态电路的响应 零输入响应 外加激励均为零时，仅由初始状态所引起的响应，称为零输入响应，记为\\(y_x(t)\\)或\\(y_{zi}(t)\\)。\n例如\n20.jpg\r通过某种手段先给\\(C\\)充电到电压为\\(u_C\\)，然后接入电阻\n此时方程为\n\\[RC\\frac{du_C}{dt}+u_C=0 \\]\n解得\n\\[u_C(t) = Ke^{-t/\\tau} \\]\n其中\\(\\tau = RC\\)，\\(K=u_C(0_+)\\)\n零状态响应 当电路的初始储能为零(即初始状态为零)时，仅由外加激励所引起的响应，称为零状态响应，记为\\(y_f(t)\\)或\\(y_{zs}(t)\\)。\n例如\n21.jpg\r\\(t=0\\)突然将开关打开，给右侧电路一个激励。\n方程解得\n\\[i_c = I_Se^{-t/\\tau} \\]\n其中\\(\\tau=RC\\)\n若有多个激励，零状态响应与各激励之间也满足可加性。这种性质称之为零状态线性。\n全响应 电路在外加激励和初始状态共同作用下所产生的响应，称为全响应。\n全响应=零输入响应+零状态响应，即\n\\[y(t) = y_{zi}(t) + y_{zs}(t) \\]\n计算只要\n将独立源置零计算零输入响应 将电容、电感的状态置零计算零状态响应 一阶电路的三要素 对于直流激励下的一阶电路中任意一处的电流和电压，只要计算出其在\\(t=0_+\\)和\\(t=\\infty\\)时的值以及整个电路的时常数，就可以直接列出它随时间的函数\n\\[y(t) = y(\\infty) + [y(0_+)-y(\\infty)]e^{-t/\\tau} \\]\n如果起始时间是\\(t=t_0\\)，则\n\\[y(t) = y(\\infty) + [y(t_{0_+})-y(\\infty)]exp(-(t-t_0)/\\tau) \\]\n计算\\(y(0_+)\\)\n独立初始值和非独立初始值的计算已经介绍过，不再重复。\n计算\\(y(\\infty)\\)\n\\(t\\to\\infty\\)时，电路进入直流稳态，此时电容看做开路，电感看做短路。然后再用这个电路去计算我们所要的电流、电压值。\n计算\\(\\tau\\)\n对于一阶\\(RC\\)电路，\\(\\tau = R_0C\\)\n对于一阶\\(RL\\)电路，\\(\\tau = L/R_0\\)\n\\(R_0\\)是换路后从动态元件\\(C\\)或\\(L\\)看进去的戴维南等效内阻。\n阶跃函数与阶跃响应 阶跃函数 单位阶跃函数用\\(\\varepsilon(t)\\)表示，其定义为\n\\[\\varepsilon(t) = \\left\\{\\begin{matrix} 1,t\u003e0\\\\ 0,t\u003c0 \\end{matrix}\\right. \\]\n其中\\(t=0\\)处的值可以不定义。\n如果单位直流电源接入的时刻为\\(t_0\\)，则可用延迟单位阶跃函数表示\n\\[\\varepsilon(t-t_0) = \\left\\{\\begin{matrix} 1,t \u003e t_0\\\\ 0,t \u003c t_0 \\end{matrix}\\right. \\]\n阶跃响应 当激励为单位阶跃函数\\(\\varepsilon(t)\\)时，电路的零状态响应称为单位阶跃响应，简称阶跃响应，用g(t)表示。\n单位阶跃函数\\(\\varepsilon(t)\\)作用于电路相当于单位直流源(\\(1V\\)或\\(1A\\))在\\(t = 0\\)时接入电路，因此，一阶电路的阶跃响应仍可用三要素法求得。\n正弦稳态分析 正弦量 正弦量的三要素 按正弦(余弦)规律变化的电压、电流称为正弦电压、电流，统称为正弦量\n正弦量的三要素是：振幅、初相、角频率。\n瞬时值表达式为\n\\[i(t) = I_m\\cos(\\omega t+\\varphi_i)\\\\ u(t) = U_m\\cos(\\omega t+\\varphi_u) \\]\n\\(U_m(I_m)\\)是最大值，称为振幅\n\\(\\omega t+\\varphi\\)是相位（角），单位\\(rad\\)或度\n\\(t=0\\)时的相位\\(\\varphi\\)称为初相位，\\(-\\pi\\leq \\varphi\\leq\\pi\\)\n\\(\\omega\\)是正弦量相位变化的速率\n正弦量的有效值 \\[I = \\frac{1}{\\sqrt 2}I_m \\]\n\\[U = \\frac{1}{\\sqrt 2}U_m \\]\n相位差 两个同频率的正弦波之间的相位之差称为相位差\n频率相同，则相位差即为初相之差。\n相量法 正弦量与相量 根据欧拉公式\n\\[u(t) = U_mcos(\\omega t+\\varphi_u) = Re[U_me^{j(\\omega t+\\varphi_u)}] = Re[U_me^{j\\varphi_u}e^{j\\omega t}] = Re[\\dot{U_m}e^{j\\omega t}] \\]\n这样，一个余弦时间函数就能用一个复指数函数来表示，其中\n\\[\\dot{U_m} = U_me^{j\\varphi_u} = U_m\\angle\\varphi_u \\]\n\\(\\dot{U_m}\\)的模式正弦电压的振幅\\(U_m\\)，辐角是正线电压的初相角\\(\\varphi_u\\)，我们称其为电压\\(u\\)的振幅相量。为了将相量与一般复数做区别，\\(U_m\\)上加\\(\\cdot\\)。\n式中\\(e^{j\\omega t}\\)称为旋转因子，它是模等于\\(1\\)，初相为零，并以角速度\\(\\omega\\)逆时针旋转的复值函数。向量\\(\\dot{U_m}\\)乘以旋转因子\\(e^{j\\omega t}\\)得到的\\(\\dot{U_m}e^{j\\omega t}\\)称为旋转相量，\\(\\dot{U_m}\\)称为其振幅。\n有效值与最大值的关系为\n\\[\\dot{I_m} = \\sqrt 2 \\dot I,\\dot{U_m} = \\sqrt 2 \\dot U \\]\n\\(u(t) = Re[\\dot{U_m}e^{j\\omega t}]\\)的几何意义是，一个正弦量在任意时刻的瞬时值，等于对应的旋转向量同一时刻在实轴上的投影。\n注意相量法只适用于同频率正弦激励的线性时不变电路。\n正弦量的相量运算 同频率正弦量加减\n设\n\\[u_1(t) = \\sqrt 2U_1\\cos(\\omega t+\\varphi_1) = Re[\\sqrt 2\\dot{U_1}e^{j\\omega t}] \\]\n\\[u_2(t) = \\sqrt 2U_2\\cos(\\omega t+\\varphi_1) = Re[\\sqrt 2\\dot{U_2}e^{j\\omega t}] \\]\n\\[u(t) = u_1(t) + u_2(t) = Re[\\sqrt 2\\dot{U_1}e^{j\\omega t}] + Re[\\sqrt 2\\dot{U_2}e^{j\\omega t}] \\]\n\\[Re[\\sqrt 2\\dot{U}e^{j\\omega t}] = Re[\\sqrt 2\\dot{U_1}e^{j\\omega t} + \\sqrt 2\\dot{U_2}e^{j\\omega t}] = Re[\\sqrt{2}(\\dot{U_1}+\\dot{U_2})e^{j\\omega t}] \\]\n所以有\\(\\dot U = \\dot{U_1}+\\dot{U_2}\\)\n对于\\(\\dot I\\)同理。\n正弦量的微分、积分\n设\\(i = \\sqrt 2I\\cos(\\omega t+\\varphi_i)=\\sqrt 2Re[\\dot Ie^{j\\omega t}]\\)\n微分\n\\[\\dfrac{di(t)}{dt} = \\sqrt 2Re[j\\omega\\dot Ie^{j\\omega t}] \\]\n其中\n\\[\\dot I' = j\\omega\\dot I = \\omega I e^{j(\\varphi_i+\\pi/2)} \\]\n积分\n\\[\\int i(t)dt = \\sqrt 2Re[\\dfrac{\\dot I}{j\\omega}e^{j\\omega t}] \\]\n\\[\\dot I' = \\dfrac{\\dot I}{j\\omega} = \\dfrac I\\omega e^{j(\\varphi_i-\\pi/2)} \\]\n电路定律的相量形式 KCL和KVL \\[\\sum\\dot I = 0 \\]\n\\[\\sum\\dot U = 0 \\]\n如果改用最大值，也有\n\\[\\sum\\dot I_m = 0 \\]\n\\[\\sum\\dot U_m = 0 \\]\nVAR的相量形式 22.jpg\r阻抗与导纳 阻抗 阻抗以如下形式定义\n\\[Z = \\dfrac{\\dot U}{\\dot I} = \\dfrac{U\\angle\\varphi_u}{I\\angle\\varphi_i} = |Z|\\angle\\theta_Z = R+jX \\]\n其中\\(|Z|=\\dfrac{U}{I}=\\sqrt{R^2+X^2}\\)称为阻抗模，\\(\\theta_Z = \\varphi_u-\\varphi_i = \\arctan\\dfrac{X}{R}\\)称为阻抗角。\n\\(R = |Z|\\cos\\theta_Z\\)称为电阻，即阻抗的实部。\\(X = |Z|\\sin\\theta_Z\\)称为电抗，即阻抗的虚部。\n单个元件\\(R,L,C\\)的阻抗\\(Z_R,Z_L,Z_C\\)分别为\n\\[\\left\\{\\begin{align*} \u0026Z_R = R\\\\ \u0026Z_L = j\\omega L = jX_L = X_L\\angle\\dfrac{\\pi}{2} \\\\ \u0026Z_C = \\dfrac{1}{j\\omega C} = -j\\dfrac{1}{\\omega C} = -jX_C = X_C\\angle-\\dfrac{\\pi}{2} \\end{align*}\\right. \\]\n阻抗串联时\n\\[Z_{eq} = \\sum Z_k \\]\n分压为\n\\[\\dot U_k = \\dfrac{Z_k}{Z_{eq}}\\dot U \\]\n导纳 导纳以如下形式定义\n\\[Y = \\dfrac{\\dot I}{\\dot U} = \\dfrac{I\\angle\\varphi_i}{U\\angle\\varphi_u} = |Y|\\angle\\theta_Y = G+jB \\]\n其中\\(|Y|=\\dfrac{I}{U}=\\sqrt{G^2+B^2}\\)称为导纳模，\\(\\theta_Y = \\varphi_i-\\varphi_u = \\arctan\\dfrac{B}{G}\\)称为导纳角。\n\\(G = |Y|\\cos\\theta_Y\\)称为电导，即导纳的实部。\\(B = |B|\\sin\\theta_Y\\)称为电纳，即导纳的虚部。\n单个元件\\(R,L,C\\)的导纳\\(Y_R,Y_L,Y_C\\)分别为\n\\[\\left\\{\\begin{align*} \u0026Y_R = \\dfrac{1}{R} = G\\\\ \u0026Y_L = \\dfrac{1}{j\\omega L} = -j\\dfrac{1}{\\omega L} = -jB_L\\\\ \u0026Y_C = j\\omega C = jB_C \\end{align*}\\right. \\]\n导纳并联时\n\\[Y_{eq} = \\sum Y_k \\]\n分流为\n\\[\\dot I_k = \\dfrac{Y_k}{Y_{eq}}\\dot I \\]\n阻抗和导纳的关系 对统一电路，阻抗和导纳互为倒数。\n\\[Z = \\dfrac{1}{Y},Y=\\dfrac{1}{Z} \\]\n或者\n\\[|Y| = \\dfrac{1}{|Z|},\\theta_y = -\\theta_z \\]\n阻抗与导纳的性质 对于阻抗\\(Z = R+jX\\)\n若\\(X\u003e0\\)，电路呈感性，\\(0\\degree\u003c\\theta_z\u003c90\\degree\\)。\\(X=0\\)，电路呈阻性，\\(\\theta_z=0\\)。\\(X\u003c0\\)，电路呈容性，\\(-90\\degree\u003c\\theta_z\u003c0\\degree\\)。\n对于导纳\\(Y = G+jB\\)\n若\\(B\u003e0\\)，电路呈容性，\\(0\\degree\u003c\\theta_y\u003c90\\degree\\)。\\(B=0\\)，电路呈阻性，\\(\\theta_y=0\\)。\\(B\u003c0\\)，电路呈感性，\\(-90\\degree\u003c\\theta_y\u003c0\\degree\\)。\n电路为感性时，电压超前于电流，\\(\\theta_z\u003e0\\)，电路为阻性时，电压和电流同向，电路为容性时，电压落后与电流，\\(\\theta_z\u003c0\\)\nRLC串联电路中会出现分压和大于总电压的情况。\nRLC并联电路中会出现分流和大于总电流的情况。\n正弦稳态电路的计算 和直流电阻电路的电路定律是相似的，也就是说网孔法、节点法、阻抗的串并联、电源的等效互换、等效电源等方法可以使用。\n正弦稳态电路的功率 一端口电路的功率 设无源一端口正弦稳态电路端口\\(u,i\\)关联\n\\[u(t) = \\sqrt 2U\\cos(\\omega t+\\varphi_u) \\]\n\\[i(t) = \\sqrt 2I\\cos(\\omega t+\\varphi_u-\\theta) \\]\n\\(\\theta = \\varphi_u-\\varphi_i\\)，即\\(u,i\\)的相位差\n瞬时功率\n\\[p(t) = ui = UI[\\cos\\theta + \\cos(2\\omega t+2\\varphi_u-\\theta)] \\]\n\\(p\u003e0\\)是电路吸收功率，\\(p\u003c0\\)是电路发出功率。\n或者也可以\n\\[p(t) = UI\\cos\\theta[1+\\cos 2(\\omega t+\\varphi_u)] + UI\\sin\\theta\\sin 2(\\omega t+\\varphi_u) \\]\n其中\\(UI\\cos\\theta[1+\\cos 2(\\omega t+\\varphi_u)]\\)为消耗功率，\\(UI\\sin\\theta\\sin 2(\\omega t+\\varphi_u)\\)为交换功率。\n平均功率\n\\[P = \\dfrac{1}{T}\\int^T_0 p(t)dt = \\dfrac{1}{T}\\int^T_0[UI\\cos\\theta + UI\\cos(2\\omega t+2\\varphi_u-\\theta)]dt \\]\n上式积分得\n\\[P = UI\\cos\\theta = \\dfrac{1}{2}U_mI_m\\cos\\theta \\]\n其中\\(\\cos\\theta\\)为功率因数，\\(\\theta=\\varphi_u-\\varphi_i\\)为功率因数角。无源网络中为等效阻抗的阻抗角。\n如果\\(\\cos\\theta = 0\\)，其为纯电抗电路，\\(\\cos\\theta = 1\\)，其为纯电阻电路。\n平均功率实际上是电阻消耗的功率，也称为有功功率。\n无功功率\n\\[Q = UI\\sin\\theta \\]\n表示交换功率的最大值，单位\\(var\\)（乏）。\\(Q\\)的大小反映电路\\(N\\)与外电路交换功率的大小，由储能元件\\(L,C\\)决定。\n视在功率\n\\[S = UI \\]\n反映电气设备的容量。\nRLC的有功和无功功率\n\\(P_R=UI,Q_R=0\\)，电阻只吸收功率，不发出功率\n\\(P_L=0,Q_L=UI\\)，电感不消耗功率，\\(u\\)超前\\(i90\\degree\\)\n\\(P_C=0,Q_C=-UI\\)，电容不消耗功率，\\(i\\)超前\\(u90\\degree\\)\n可见二端电路中只有电阻在消耗功率，电感和电容不消耗功率，只储存能量、交换能量。\n复功率 \\[\\~S = P+jQ \\]\n可以计算得到\n\\[\\~S = Ue^{j\\varphi_u}Ie^{-j\\varphi_i} = \\dot U\\dot I^* = Se^{j\\theta} \\]\n\\[S = \\sqrt{P^2+Q^2} \\]\n其中\\(\\dot I^* = Ie^{-j\\varphi_i}\\)是\\(\\dot I\\)的共轭值。\n功率与阻抗、导纳的关系为\n\\[\\~S = ZI^2 = RI^2+jXI^2 \\]\n\\[P = RI^2,Q=XI^2,S=|Z|I^2 \\]\n\\[\\~S = Y^*U^2 = GU^2-jBU^2 \\]\n\\[P = GU^2,Q=-BU^2,S=|Y|U^2 \\]\n对于正弦稳态电路，利用特勒根定理可以证明\n\\[\\sum\\~S = 0 \\]\n拆开为\n\\[\\sum P = \\sum UI\\cos\\theta = 0\\\\ \\sum Q = \\sum UI\\sin\\theta = 0 \\]\n即对于正弦稳态电路，电路的总有功功率之代数和等于零，或者说，电路中发出的各有功功率之和等于吸收的各有功功率之和；电路的总无功功率之代数和恒等于零。\n注意复功率守恒不等于视在功率守恒。并且一般\\(S\\neq\\sum S_k\\)\n多频电路的响应和平均功率 多频电路响应\n我们可以把多个频率不相同的激励源先计算单独作用时的响应，再利用叠加定理计算多频电路响应。\n多频电路瞬时功率\n同样先计算单独作用时的电流，这里假设有两个，为\\(i_1(t),i_2(t)\\)\n\\[p_R(t) = R[i_1(t)+i_2(t)]^2 = p_1(t)+p_2(t) + 2Ri_1(t)i_2(t) \\]\n多频电路平均功率\n当\\(i_1(t),i_2(t)\\)的频率之比为有理数，且不相等时\n\\[P_R = P_1 + P_2 \\]\n如果相等时\n\\[P_R = P_1 + P_2 + RI_{m1}I_{m2}\\cos(\\varphi_1-\\varphi_2) \\]\n非正弦周期信号平均功率\n可以把电压和电流展开为傅里叶级数，即分解为直流和各次谐波分量之和\n\\[u(t) = U_0 + \\sum^N_{k=1}\\sqrt 2U_k\\cos(k\\omega t+\\mu_{u_k}) \\]\n\\[i(t) = I_0 + \\sum^N_{k=1}\\sqrt 2I_k\\cos(k\\omega t+\\mu_{i_k}) \\]\n则该一端口电路吸收的平均功率为\n\\[P = U_0I_0+\\sum^N_{k=1}U_kI_k\\cos\\theta_k = P_0 + \\sum^N_{k=1}P_k\\quad(\\theta_k = \\varphi_{u_k}-\\varphi_{i_k}) \\]\n电压和电流的有效值为\n\\[U = \\sqrt{\\sum^N_{k=0}U_k^2} \\]\n\\[I = \\sqrt{\\sum^N_{k=0}I_k^2} \\]\n最大功率传输条件 讨论正弦稳态电路中负载\\(Z_L\\)获得最大功率\\(P_{\\max}\\)的条件。\n23.jpg\r共轭匹配\n\\[Z_L = R_L + jX_L \\]\n其中\\(R_L,X_L\\)可以独立调节时\n\\[P_{\\max} = \\dfrac{U_s^2}{4R_s} \\]\n条件是\\(Z_L = Z_S^*\\)，即\\(R_L=R_S,X_L=-X_S\\)\n模匹配\n若\\(Z_L = R_L+jX_L=|Z_L|\\angle\\theta\\)，\\(|Z_L|\\)可变，\\(\\theta\\)不变，此时\n\\[P_{\\max} = \\dfrac{\\cos\\theta U_s^2}{2|Z_S|+2(R_S\\cos\\theta+X_S\\sin\\theta)} \\]\n条件是\\(|Z_L|=|Z_S|\\)\n","date":"2022-09-02T11:22:59+08:00","image":"https://kegalas.top/p/%E7%94%B5%E8%B7%AF%E5%9F%BA%E7%A1%80%E6%95%B4%E7%90%86/cover_hu0536c6b8cad2f38cd8d175ab5c2d8577_29925_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E7%94%B5%E8%B7%AF%E5%9F%BA%E7%A1%80%E6%95%B4%E7%90%86/","title":"电路基础整理"},{"content":"复数与复变函数 复数的定义及其运算 把负数定义为一堆有序的实数\\((a,b)\\)，如果用\\(\\bm R\\)作为实数集，\\(\\bm C\\)为复数集，则\n\\[\\bm C = \\{(a,b):a\\in\\bm R,b\\in\\bm R\\} \\]\n定义加法和乘法如下\n\\[(a,b)+(c,d)=(a+c,b+d) \\]\n\\[(a,b)(c,d)=(ac-bd,ad+bc) \\]\n易知，加法和乘法满足交换率和结合律。\n\\((0,0)\\)是零元素，\\((-a,-b)\\)是\\((a,b)\\)的负元素，\\((1,0)\\)是乘法的单位元素。每个非零元素\\((a,b)\\)的逆元素是\\((\\frac{a}{a^2+b^2},-\\frac{b}{a^2+b^2})\\)\n此外还满足分配律\n\\[[(a,b)+(c,d)](e,f) = (a,b)(e,f)+(c,d)(e,f) \\]\n可以直接记\\((a,0)=a\\)。\n对于\\((0,1)\\)有\n\\[(0,1)^2=(-1,0)=-1 \\]\n记为\\((0,1)=i\\)\n同样有\\((0,b)=(b,0)(0,1)=bi\\)\n于是每一个复数都可以写成\n\\[(a,b)=(a,0)+(0,b)=a+bi \\]\n定理1\n复数域不是有序域，换句话说，不可以比较大小。\n出于方便和其他一些原因，用\\(z=a+bi\\)来描述复数，\\(a\\)称为\\(z\\)的实部，\\(b\\)称为\\(z\\)的虚部。可以记为\\(a=Rez,b=Imz\\)。\n四则运算\n加法\n\\[(a+bi)+(c+di)=(a+c)+(b+d)i \\]\n乘法\n\\[(a+bi)(c+di)=(ac-bd)+(ad+bc)i \\]\n减法\n\\[(a+bi)-(c+di)=(a-c)+(b-d)i \\]\n除法\n\\[\\frac{a+bi}{c+di}=(a+bi)\\left(\\frac{c-di}{c^2+d^2}\\right)=\\frac{ac+bd}{c^2+d^2}+\\frac{bc-ad}{c^2+d^2}i \\]\n模\n\\[|z|=\\sqrt{a^2+b^2} \\]\n共轭\n\\[\\overline{z}=a-bi \\]\n定理2\n\\(Rez=(z+\\overline{z})/2,Imz=(z-\\overline z)/2i\\) \\(z\\overline z=|z|^2\\) \\(\\overline{z+w}=\\overline z+\\overline w,\\overline{zw}=\\overline z\\cdot\\overline w,\\overline{z/w}=\\overline{z}/\\overline{w}\\) \\(|zw|=|z||w|,|z/w|=|z|/|w|\\) \\(|z|=|\\overline z|\\) \\(|Rez|\\leq |z|,|Imz|\\leq|z|\\) \\(|z+w|\\leq|z|+|w|\\)当且仅当存在一个\\(t\\geq 0,z=tw\\)时取等。 \\(|z-w|\\geq||z|-|w||\\) 复数的几何表示 三角表示法\n复数能用上一节提到的实数对\\((a,b)\\)表示，同时就可以看成平面上的一个点。同样的，也可以用极坐标\\((r,\\theta)\\)表示，那么有，\n\\[a=rcos\\theta,b=rsin\\theta \\]\n所以复数也可以表示为\n\\[z=r(cos\\theta+isin\\theta) \\]\n其中\\(r=|z|\\)，\\(\\theta\\)称为辐角，记为\\(\\theta=Argz\\)。显然若\\(\\theta\\)是辐角，那么\\(\\theta+2k\\pi\\)也是辐角。但在\\(Argz\\)中，只有一个辐角满足\\(-\\pi\u003c\\theta\\leq\\pi\\)，称为辐角的主值，记为\\(argz\\)，所以有\n\\[Argz=argz+2k\\pi,\\quad k\\in Z \\]\n特别注意，模为0的复数的辐角没有意义。\n指数表示法\n由欧拉公式\n\\[e^{i\\theta}=cos\\theta+isin\\theta \\]\n得到\n\\[z=re^{i\\theta} \\]\nde Moivre公式\n设\\(z_1=r_1(cos\\theta_1+isin\\theta_1),\\cdots,z_n=r_n(cos\\theta_n+isin\\theta_n)\\)是给定的n个复数，数学归纳法可知\n\\[z_1\\cdots z_n=r_1\\cdots r_n[cos(\\theta_1+\\cdots+\\theta_n)+isin(\\theta_1+\\cdots+\\theta_n)] \\]\n作为特殊情况，有\n\\[z^n=r^n(\\cos n\\theta+i\\sin n\\theta) \\]\n同样对于负整数也是成立的\n\\[z^{-n}=r^{-n}(\\cos(-n\\theta)+i\\sin(-n\\theta)) \\]\n现在设\\(\\omega=r(\\cos\\theta+i\\sin\\theta)\\)是给定的，要求的\\(z=\\rho(\\cos\\varphi+i\\sin\\varphi)\\).由de Moivre公式，\\(z^n=\\omega\\)等价为\n\\[\\rho^n(\\cos n\\varphi+i\\sin n\\varphi)=r(\\cos\\theta+i\\sin\\theta) \\]\n所以\\(\\rho=\\sqrt[n]{r},n\\varphi=\\theta+2k\\pi,k=0,1,\\cdots,n-1\\).共有\\(n\\)个复数满足\\(z^n=w\\)，即\n\\[z=\\sqrt[n]{|\\omega |}\\left(\\cos\\frac{\\theta+2k\\pi}{n}+i\\sin\\frac{\\theta+2k\\pi}{n}\\right),k=0,1,\\cdots,n-1 \\]\n这\\(n\\)个复数恰好是以原点为中心，\\(\\sqrt[n]{|\\omega |}\\)为半径的圆的内接正\\(n\\)边形的顶点。\n\\(\\omega=1\\)时，若记\\(w=\\cos\\frac{2\\pi}{n}+i\\sin\\frac{2\\pi}{n}\\)，则\\(\\sqrt[n]{1}\\)的\\(n\\)个值为\n\\[1,w,w^2,\\cdots,w^{n-1} \\]\n称为\\(n\\)个单位根，如果用\\(\\sqrt[n]{\\omega}\\)的任一\\(n\\)次根，那么\\(\\omega\\)的\\(n\\)个\\(n\\)次根又可以表示为\n\\[\\sqrt[n]{\\omega}, \\sqrt[n]{\\omega}w,\\cdots,\\sqrt[n]{\\omega}w^{n-1} \\]\n扩充平面和复数的球面表示 因为需要，在\\(\\bm C\\)中引入一个新的数\\(\\infty\\)，其模是\\(\\infty\\)，辐角没有意义，运算规则如下\n\\[z\\pm\\infty = \\infty, z\\cdot \\infty = \\infty(z\\neq 0) \\]\n\\[\\frac{z}{\\infty} = 0, \\frac{z}{0} = \\infty(z\\neq 0) \\]\n而\\(0\\cdot \\infty\\)和\\(\\infty\\pm\\infty\\)不规定意义。引入之后的复数系记为\\(\\bm C_\\infty\\)。在复平面上，没有一个点和\\(\\infty\\)对应，但是我们想象有一个无穷远点和\\(\\infty\\)对应，加上无穷远点的复平面称为扩充平面或闭平面。否则是开平面。\n在复平面上，无穷远点和普通点是不一样的。但在黎曼引入的球面表示中没有什么区别。\n设\\(S\\)是\\(\\bm R^3\\)中的单位球面，即\n\\[S = \\{(x_1,x_2,x_3)\\in \\bm R^3:x_1^2+x_2^2+x_3^2=1\\} \\]\n把\\(\\bm C\\)等同于平面\n\\[\\bm C = \\{(x_1,x_2,0):x_1,x_2\\in \\bm R\\} \\]\n称\\(N=(0,0,1)\\)为北极点。在\\(\\bm C\\)上的任一一点\\(z\\)，连接\\(N,z\\)的直线必然和\\(S\\)交于一点\\(P\\)。若\\(|z|\u003e1\\)，则\\(P\\)在北半球；若\\(|z|\u003c1\\)，则\\(P\\)在南半球；若\\(|z|=1\\)，则\\(z\\)就是\\(P\\)。\n当\\(z\\)趋向\\(\\infty\\)时，球面上的点就会趋向于\\(N\\)，所以就可以把\\(\\infty\\)对应于\\(N\\)。这样一来\\(\\bm C_\\infty\\)中的所有点都可以被移植到球面上去了，并且所有的点一视同仁。\n设\\(z=x+iy\\)，则\\(P\\)的坐标为\n\\[x_1=\\frac{2x}{x^2+y^2+1},x_2=\\frac{2y}{x^2+y^2+1},x_3=\\frac{x^2+y^2-1}{x^2+y^2+1} \\]\n或者用复数表示为\n\\[x_1=\\frac{z+\\bar z}{1+|z|^2},x_2=\\frac{z-\\bar z}{i(1+|z|^2)},x_3=\\frac{|z|^2-1}{|z|^2+1} \\]\n同样也就可以用球面上的点来表示复数\n\\[z=\\frac{x_1+ix_2}{1-x_3} \\]\n复数列的极限 极限\n复数列\\(\\{z_n\\}\\)收敛到点\\(z_0\\)，指的是对于任给的\\(\\varepsilon\u003e0\\)，存在正整数\\(N\\)，当\\(n\u003eN\\)时，\\(|z_n-z_0|\u003c\\varepsilon\\)，记作\\(\\lim_{n\\to \\infty}z_n=z_0\\)\n复数列\\(\\{z_n\\}\\)收敛到\\(\\infty\\)，指的是对于任意正数\\(M\u003e0\\)，存在正整数\\(N\\)，当\\(n\u003eN\\)时，\\(|z_n|\u003eM\\)，记为\\(\\lim_{n\\to\\infty}z_n=\\infty\\)\n邻域\n对于\\(a\\in\\bm C,r\u003e0\\)，称\n\\[B(a,r)=\\{z\\in C:|z-a|\u003c r\\} \\]\n为以\\(a\\)为中心、以\\(r\\)为半径的圆盘，特别当\\(a=0,r=1\\)时称为单位圆盘。\\(B(a,r)\\)也称为\\(a\\)点的一个\\(r\\)邻域，或简称邻域。无穷远点的邻域是指集合\\(\\{z\\in \\bm C:|z|\u003eR\\}\\)，记为\\(B(\\infty, R)\\)\n此时极限有可以表示为：\n\\(\\lim_{n\\to \\infty}z_n=z_0\\)可以说成对任意\\(\\varepsilon\u003e0\\)，当\\(n\\)充分大时，\\(z_n\\in B(z_0,\\varepsilon)\\)\n\\(\\lim_{n\\to\\infty}z_n=\\infty\\)可以说成对任意\\(M\u003e0\\)，当\\(n\\)充分大时，\\(z_n\\in B(\\infty, M)\\)\n同时马上就可以得到，\\(\\lim_{n\\to \\infty}z_n=z_0\\)的充要条件是，其实部和虚部分别有\\(\\lim_{n\\to \\infty}x_n=x_0\\)和\\(\\lim_{n\\to \\infty}y_n=y_0\\)。\n开集、闭集和紧集 内点\n如果存在\\(r\u003e0\\)，使得\\(B(a,r)\\subset E\\)，就称\\(a\\)为\\(E\\)的内点\n外点\n如果存在\\(r\u003e0\\)使得\\(B(a,r)\\subset E^c\\)，就称\\(a\\)为\\(E\\)的外点。其中\\(E^c\\)是补集。\n边界点\n如果对于任意\\(r\u003e0\\)，\\(B(a,r)\\)中既有\\(E\\)的点，也有\\(E^c\\)的点，就称\\(a\\)为\\(E\\)的边界点。\n内部\n\\(E\\)的内点的全体称为\\(E\\)的内部，记为\\(E\\degree\\)\n外部\n\\(E\\)的外点的全体称为\\(E\\)的外部，记为\\((E^c)\\degree\\)\n边界\n\\(E\\)的边界点的全体称为\\(E\\)的边界，记为\\(\\partial E\\)\n开集\n如果\\(E\\)的所有点都是他的内点，即\\(E=E\\degree\\)，就称\\(E\\)是开集。\n另外，空集是开集。\n闭集\n如果\\(E^c\\)是开集，就称\\(E\\)为闭集。\n另外，无限集是闭集。\n极限点、聚点\n如果对任意\\(r\u003e0\\)，\\(B(a,r)\\)中除\\(a\\)外总有\\(E\\)中的点，则称\\(a\\)为极限点或聚点。\n导集\n集\\(E\\)的所有极限点构成的集称为\\(E\\)的导集，记为\\(E'\\)。\n孤立点\n\\(E\\)中不属于\\(E'\\)的点称为孤立点。\n闭包\n\\(E\\)和它的导集的并称为\\(E\\)的闭包，记为\\(\\bar E=E\\cup E'\\)\n直径\n点集\\(E\\)的直径定义为\\(E\\)中任意两点间距离的上确界，记为\\(diamE\\)，即\n\\[diamE=sup\\{|z_1-z_2|:z_1,z_2\\in E\\} \\]\nCantor定理\n若非空闭集序列\\(\\{F_n\\}\\)满足\n\\(F_1\\supset F_2\\supset\\cdots\\supset F_n\\supset\\cdots\\) \\(diamF_n\\to 0\\)（当\\(n\\to \\infty\\)时） 那么\\(\\bigcap^\\infty_{n=1}F_n\\)是一个独点集（只有一个点的集）。\n开集族、开覆盖\n设\\(E\\)是一个集，\\(\\mathscr{F}=\\{G\\}\\)是一个开集族，即\\(\\mathscr{F}\\)中的每一个元素都是开集。如果\\(E\\)中每一点至少属于\\(\\mathscr{F}\\)中的一个开集，就说\\(\\mathscr{F}\\)是\\(E\\)的一个开覆盖。\n有限覆盖性质\n点集\\(E\\)具有有限覆盖性质，是指从\\(E\\)的任一个开覆盖中必能选出有限个开集\\(G_1,\\cdots,G_n\\)，使得这有限个开集的并就能覆盖\\(E\\)，即\n\\[E\\subset\\bigcup^n_{j=1}G_j \\]\n紧集\n具有有限覆盖性质的集称为紧集。\n有界\n集\\(E\\)称为是有界的，如果存在\\(R\u003e0\\)，使得\\(E\\subset B(0,R)\\)\nHeine-Borel定理\n在\\(C\\)中，\\(E\\)是紧集的充要条件为\\(E\\)是有界闭集；在\\(C_\\infty\\)中，\\(E\\)是紧集的充要条件为\\(E\\)是闭集。\n定理\n设\\(E\\)是紧集，\\(F\\)是闭集，且\\(E\\cap F=\\empty\\)，则\n\\[d(E,F) \u003e 0 \\]\n其中\n\\[d(E,F) = \\inf\\{|z_1-z_2|:z_1\\in E, z_2\\in F\\} \\]\nBolzano-Weierstrass定理\n任一无穷点集至少有一个极限点。\n曲线和域 连续曲线\n定义在闭区间\\([a,b]\\)上的一个复值连续函数\\(\\gamma:[a,b]\\to \\bm C\\)，写为\n\\[z = \\gamma(t)=x(t)+iy(t),\\quad a\\leq t\\leq b \\]\n这里\\(x(t),y(t)\\)都是\\([a,b]\\)上的连续函数。\n如果用\\(\\gamma^*\\)记\\(\\gamma\\)的像点所成的集合\n\\[\\gamma^* = \\{\\gamma(t):a\\leq t\\leq b\\} \\]\n那么\\(\\gamma^*\\)是\\(\\bm C\\)上的紧集。\n曲线\\(\\gamma\\)的方向就是\\(t\\)增加的方向。此时\\(\\gamma(a)\\)为起点，\\(\\gamma(b)\\)为终点。\n闭曲线\n如果\\(\\gamma(a)=\\gamma(b)\\)，则称为闭曲线。\n简单曲线\n如果当且仅当\\(t_1=t_2\\)时才有\\(\\gamma(t_1)=\\gamma(t_2)\\)，则称为简单曲线或Jordan曲线。\n简单闭曲线\n如果当且仅当如果当且仅当\\(t_1=a,t_2=b\\)时才有\\(\\gamma(t_1)=\\gamma(t_2)\\)，则称为简单闭曲线或Jordan闭曲线，或简称围道。\n可求长的\n设\\(z=\\gamma(t)\\)是一条曲线，对区间\\([a,b]\\)做分割\\(a=t_0\u003c t_1\u003c\\cdots\u003c t_n=b\\)，得到以\\(z_k=\\gamma(t_k)\\)为顶点的折线\\(P\\)，那么\\(P\\)的长度为\n\\[|P|=\\sum_{k=1}^n|\\gamma(t_k)-\\gamma(t_{k-1})| \\]\n如果不论如何分割区间\\([a,b]\\)，所得折线的长度都是有界的，就称曲线\\(\\gamma\\)是可求长的，其长度定义为\\(\\gamma\\)的上确界。\n光滑曲线\n如果\\(\\gamma'(t)=x'(t)+iy'(t)\\)存在，且\\(y'(t)\\neq 0\\)，那么\\(\\gamma\\)在每一点都有切线，\\(\\gamma'(t)\\)就是曲线\\(\\gamma\\)在\\(\\gamma(t)\\)处的切向量，它与正实轴的夹角为\\(Arg\\gamma'(t)\\)，\n如果\\(\\gamma'(t)\\)是连续函数，那么\\(\\gamma\\)的切线随\\(t\\)而连续变动，这时称\\(\\gamma\\)为光滑曲线。\n此时\\(\\gamma\\)的长度为\n\\[\\int^b_a \\sqrt{(x'(t))^2+(y'(t))^2}dt = \\int^b_a|\\gamma'(t)|dt \\]\n曲线\\(\\gamma\\)称为逐段光滑的。\n如果存在\\(t_0,t_1,\\cdots,t_n\\)，使得\\(a=t_0\u003c t_1\u003c\\cdots\u003c t_n=b\\)，\\(\\gamma\\)在每个参数区间\\([t_{j-1},t_j]\\)上是光滑的，那么在每个分点\\(t_1,\\cdots,t_{n-1}\\)处\\(\\gamma\\)的左右导数存在。\n连通性\n平面点集\\(E\\)称为是联通的，如果对任意两个不相交的非空集\\(E_1\\)和\\(E_2\\)满足\n\\[E = E_1\\bigcup E_2 \\]\n那么\\(E_1\\)必含有\\(E_2\\)的极限点，或者\\(E_2\\)必含有\\(E_1\\)的极限点，也就是说，\\(E_1\\cap\\bar E_2\\)和\\(E_2\\cap\\bar E_1\\)至少有一个非空。\n定理1\n平面上的非空开集\\(E\\)是连通的充分必要条件是：\\(E\\)中任意两点可用位于\\(E\\)中的折线连接起来。\n域\n非空的连通开集称为域\nJordan定理\n一条简单闭曲线\\(\\gamma\\)吧复平面分成两个域，其中一个是有界的，称为\\(\\gamma\\)的内部；另一个是无界的，称为\\(\\gamma\\)的外部，而\\(\\gamma\\)是这两个域的共同的边界。\n单连通与多连通\n域\\(D\\)称为是单连通的，如果\\(D\\)内任意简单闭曲线的内部仍在\\(D\\)内。\n不是单连通的域称为多连通的。\n如果域\\(D\\)是由\\(n\\)跳简单闭曲线围成的，就称\\(D\\)是\\(n\\)连通的，简单闭曲线中也可以有退化成一条简单曲线或一点的。\n复变函数的极限和连续性 设\\(E\\)是复平面上一点集，如果对每一个\\(z\\in E\\)，按照某一规则有一确定复数\\(\\omega\\)与之对应，我们就说在\\(E\\)上确定了一个单值复变函数，记为\\(\\omega=f(z)\\)或\\(f:E\\to C\\)。\n\\(E\\)称为\\(f\\)的定义域，点集\\(\\{f(z):z\\in E\\}\\)称为\\(f\\)的值域。\n如果对于\\(z\\in E\\)，对应的\\(\\omega\\)有几个或无穷多个，则称在\\(E\\)上确定了一个多值函数。\n复变函数是定义在平面点集上的，而它的值域也是一个平面点集，因此复变函数也称为映射，它把一个平面点集映成另一个平面点集。\n设\\(z=x+iy\\)，用\\(u\\)和\\(v\\)记\\(\\omega=f(z)\\)的实部和虚部，则有\n\\[\\omega=f(z)=u(z)+iv(z)=u(x,y)+iv(x,y) \\]\n这就是说，一个复变函数等价于两个二元的实变函数。\n极限\n设\\(f\\)是定义在点集\\(E\\)上的一个复变函数，\\(z_0\\)是\\(E\\)的一个极限点，\\(a\\)是给定的一个复数。如果对任意的\\(\\varepsilon\u003e0\\)，存在于\\(\\varepsilon\\)有关的\\(\\delta\u003e0\\)，使得当\\(z\\in E\\)且\\(0\u003c|z-z_0|\u003c\\delta\\)时有\\(|f(z)-a|\u003c\\varepsilon\\)，就说当\\(z\\to z_0\\)时\\(f(z)\\)有极限\\(a\\)，记作\\(\\lim_{z\\to z_0}f(z)=a\\)。\n\\(\\lim_{z\\to z_0}f(z)=a\\)的充分必要条件是\n\\[\\lim_{x\\to x_0,y\\to y_0}u(x,y)=\\alpha,\\lim_{x\\to x_0,y\\to y_0}v(x,y)=\\beta \\]\n连续\n我们说\\(f\\)在点\\(z_0\\in E\\)连续，如果\n\\[\\lim_{z\\to z_0}f(z)=f(z_0) \\]\n如果\\(f\\)在集\\(E\\)中每点都连续，就说\\(f\\)在集\\(E\\)上连续。\n定理\n设\\(E\\)是\\(\\bm C\\)中的紧集，\\(f:E\\to\\bm C\\)在\\(E\\)上连续，那么\n\\(f\\)在\\(E\\)上有界 \\(|f|\\)在\\(E\\)上能取得最大值和最小值，即存在\\(a,b\\in E\\)使得对于每个\\(z\\in E\\)都有 \\[|f(z)|\\leq |f(a)|，|f(z)|\\geq|f(b)| \\]\n\\(f\\)在\\(E\\)上一致连续。即对任意\\(\\varepsilon\u003e0\\)，存在只与\\(\\varepsilon\\)有关的\\(\\delta\u003e0\\)，对\\(E\\)上任意的\\(z_1,z_2\\)，只要\\(|z_1-z_2|\u003c\\delta\\)，就有\\(|f(z_1)-f(z_2)|\u003c\\varepsilon\\) 全纯函数/解析函数 复变函数的导数 设\\(f:D\\to\\bm C\\)是定义在域\\(D\\)上的函数，\\(z_0\\in D\\)，如果极限\n\\[\\lim_{z\\to z_0}\\frac{f(z)-f(z_0)}{z-z_0} \\]\n存在，就说\\(f\\)在\\(z_0\\)处复可导或可微，这个极限称为在此处的导数或微商。\n如果\\(f\\)在\\(D\\)中每点都可微，就称\\(f\\)是域\\(D\\)中的全纯函数或解析函数。\n如果\\(f\\)在\\(z_0\\)的一个邻域中全纯，就称\\(f\\)在\\(z_0\\)处全纯。\n定理1\n如果\\(f\\)在\\(z_0\\)处可微，则必在\\(z_0\\)处连续。反过来说则不一定成立。\n求复变函数的导数时，跟一元实变函数几乎没有什么区别，例如\\(f(z)=z^3, f'(z)=3z^2\\)。但是更加严格的一点时，在复平面上任何一个方向上的导数都要相等，而不是一元实变函数左右相等。\n实变函数的四则运算的求导法则在全纯函数中也成立。\n定理2\n设\\(D_1,D_2\\)是\\(\\bm C\\)中的两个域，且\n\\[f:D_1\\to D_2\\\\ g:D_2\\to\\bm C \\]\n都是全纯函数，那么\\(h=g\\circ f\\)是\\(D_1\\to \\bm C\\)的全纯函数，并且\\(h'(z)=g'(f(z))f'(z)\\)\nCauchy-Riemann方程 实可微\n设\\(f(z)=u(x,y)+iv(x,y)\\)是定义在域\\(D\\)上的函数，\\(z_0=x_0+iy_0\\in D\\).我们说\\(f\\)在\\(z_0\\)处实可微，是指\\(u,v\\)作为\\(x,y\\)的二元函数在\\((x_0,y_0)\\)处可微。\n设\\(f:D\\to C\\)是定义在域\\(D\\)上的函数，\\(z_0\\in D\\)，那么\\(f\\)在\\(z_0\\)处实可微的充要条件是下式成立\n\\[f(z_0+\\Delta z)-f(z_0)=\\frac{\\partial f}{\\partial z}(z_0)\\Delta z+\\frac{\\partial f}{\\partial \\bar z}(z_0)\\Delta z+o(|\\Delta z|) \\]\n其中算子定义如下\n\\[\\frac{\\partial}{\\partial z}=\\frac{1}{2}\\left(\\frac{\\partial}{\\partial x}-i\\frac{\\partial}{\\partial y}\\right) \\]\n\\[\\frac{\\partial}{\\partial \\bar z}=\\frac{1}{2}\\left(\\frac{\\partial}{\\partial x}+i\\frac{\\partial}{\\partial y}\\right) \\]\n在进行微分运算时，可以把\\(z,\\bar z\\)看成独立的变量。\n柯西-黎曼方程\n设\\(f\\)是定义在域\\(D\\)上的函数，\\(z_0\\in D\\)，那么\\(f\\)在\\(z_0\\)处可微的充要条件是\\(f\\)在\\(z_0\\)处实可微且\\(\\frac{\\partial f}{\\partial \\bar z}(z_0)=0\\).\n在可微的情况下，\\(f'(z_0)=\\frac{\\partial f}{\\partial z}(z_0)\\).\n其中\\(\\frac{\\partial f}{\\partial \\bar z}(z_0)=0\\)就称为柯西-黎曼方程。\n将\\(u,v\\)代入以及算子展开，可以得到其等价于\n\\[\\left\\{\\begin{matrix} \\frac{\\partial u}{\\partial x}=\\frac{\\partial v}{\\partial y} \\\\ \\frac{\\partial u}{\\partial y}=-\\frac{\\partial v}{\\partial x} \\end{matrix}\\right. \\]\n设\\(D\\)是\\(\\bm C\\)中的域，用\\(C(D)\\)表示\\(D\\)上连续函数的全体，\\(H(D)\\)表示\\(D\\)上全纯函数的全体。\n用\\(C^1(D)\\)记\\(\\frac{\\partial f}{\\partial x},\\frac{\\partial f}{\\partial y}\\)在\\(D\\)上连续的\\(f\\)的全体。\n\\(C^k(D)\\)记在\\(D\\)上有\\(k\\)阶连续偏导数的函数的全体，\\(C^\\infty(D)\\)记在\\(D\\)上有任意阶连续偏导数的函数的全体。\n之后我们用柯西积分公式证明，有\n\\[H(D)\\subset C^\\infty(D)\\subset C^k(D)\\subset C^1(D)\\subset C(D) \\]\n即域\\(D\\)上的全纯函数在\\(D\\)上有任意阶的连续偏导数。\n调和函数\n设\\(u\\)是域\\(D\\)上的实值函数（或称二元实变函数），如果\\(u\\in C^2(D)\\)，且对于任意\\(z\\in D\\)，有\n\\[\\Delta u(z)=\\frac{\\partial^2u(z)}{\\partial x^2}+\\frac{\\partial^2u(z)}{\\partial y^2}=0 \\]\n就称\\(u\\)是\\(D\\)中的调和函数。\n\\[\\Delta=\\frac{\\partial^2}{\\partial x^2}+\\frac{\\partial^2}{\\partial y^2} \\]\n称为拉普拉斯算子。\n定理1\n设\\(f=u+iv\\in H(D)\\)，那么\\(u,v\\)都是\\(D\\)上的调和函数。\n共轭调和函数\n设\\(u,v\\)是\\(D\\)上的一对调和函数，如果它们还满足柯西-黎曼方程，\n\\[\\left\\{\\begin{matrix} \\frac{\\partial u}{\\partial x}=\\frac{\\partial v}{\\partial y} \\\\ \\frac{\\partial u}{\\partial y}=-\\frac{\\partial v}{\\partial x} \\end{matrix}\\right. \\]\n就称\\(v\\)为\\(u\\)的共轭调和函数。\n定理1\n设\\(u\\)是单连通域\\(D\\)上的调和函数，则必存在\\(u\\)的共轭函数\\(v\\)，使得\\(u+iv\\)是\\(D\\)上的全纯函数。\n其中\n\\[v(x,y) = \\int^{(x,y)}_{(x_0,y_0)}\\dfrac{\\partial v}{\\partial x}dx+\\dfrac{\\partial v}{\\partial y}dy = \\int^{(x,y)}_{(x_0,y_0)}-\\dfrac{\\partial u}{\\partial y}dx+\\dfrac{\\partial u}{\\partial x}dy \\]\n且这个积分与路径无关。\n反过来说如果有\\(v\\)，则也必存在\\(u\\)\n\\[u(x,y) = \\int^{(x,y)}_{(x_0,y_0)}\\dfrac{\\partial u}{\\partial x}dx+\\dfrac{\\partial u}{\\partial y}dy = \\int^{(x,y)}_{(x_0,y_0)}\\dfrac{\\partial v}{\\partial y}dx-\\dfrac{\\partial v}{\\partial x}dy \\]\n导数的几何意义 过\\(z_0\\)点作一条光滑曲线\\(\\gamma\\)，它的方程为\n\\[z = \\gamma(t),a\\leq t\\leq b \\]\n设\\(\\gamma(a)=z_0,\\gamma'(a)\\neq 0\\)。\\(\\gamma\\)在点\\(z_0\\)处的切线与正实轴的夹角为\\(Arg\\gamma'(a)\\)。设\\(\\omega = f(z)\\)把曲线\\(\\gamma\\)映为\\(\\sigma\\)，它的方程为\n\\[\\omega=\\sigma(t)=f(\\gamma(t)),a\\leq t\\leq b \\]\n由于\\(\\sigma'(a)=f'(\\gamma(a))\\gamma'(a)=f'(z_0)\\gamma'(a)\\neq 0\\)，所以\\(\\sigma\\)在\\(\\omega_0=f(z_0)\\)处的切线与正实轴的夹角为\n\\[Arg\\sigma'(a) = Argf'(z_0)+Arg\\gamma'(a) \\]\n或者写为\n\\[Arg\\sigma'(a) - Arg\\gamma'(a) = Argf'(z_0) \\]\n这就说明像曲线\\(\\sigma\\)在\\(\\omega_0\\)处的切线与正实轴的夹角与原曲线\\(\\gamma\\)在\\(z_0\\)处的切线与正实轴的夹角之差总是\\(Argf'(z_0)\\)，而与曲线\\(\\gamma\\)无关，\\(Argf'(z_0)\\)就称为映射\\(\\omega=f(z)\\)在\\(z_0\\)处的转动角。\n过点\\(z_0\\)作两条光滑曲线\\(\\gamma_1,\\gamma_2\\)，它们的方程分别为\n\\[z=\\gamma_1(t),a\\leq t\\leq b \\]\n和\n\\[z=\\gamma_2(t),a\\leq t\\leq b \\]\n且\\(\\gamma_1(a)=\\gamma_2(a)=z_0\\)。映射\\(\\omega=f(z)\\)把它们分别映为过\\(\\omega_0\\)点的两条光滑曲线\\(\\sigma_1\\)和\\(\\sigma_2\\)，他们的方程分别为\n\\[\\omega = \\sigma_1(t)=f(\\gamma_1(t)),a\\leq t\\leq b \\]\n\\[\\omega = \\sigma_2(t)=f(\\gamma_2(t)),a\\leq t\\leq b \\]\n因为\\(\\sigma'(a)=f'(\\gamma(a))\\gamma'(a)=f'(z_0)\\gamma'(a)\\neq 0\\)，所以有\n\\[Arg\\sigma'(a) = Argf'(z_0)+Arg\\gamma'(a) \\]\n或者写为\n\\[Arg\\sigma'(a)-Arg\\gamma'(a) = Argf'(z_0) \\]\n由此就有\n\\[Arg\\sigma_1'(a)-Arg\\gamma_1'(a) = Argf'(z_0) = Arg\\sigma_2'(a)-Arg\\gamma_2'(a) \\]\n上式说明，如果\\(f'(z_0)\\neq 0\\)，那么在映射\\(\\omega=f(z)\\)的作用下，过\\(z_0\\)点的任意两条光滑曲线的夹角的大小与旋转方向都是保持不变的。\n我们把这种性质的映射称为在\\(z_0\\)点是保角的。\n定理\n全纯函数在其导数不为零的点处是保角的。\n导数的模的几何意义\n\\(|f'(z_0)|\\)为\\(f\\)在\\(z_0\\)处的伸缩率。\n像点之间的距离与原像之间的距离之比只与\\(z_0\\)有关，而与\\(\\gamma\\)无关。\n共形映射的概念\n综合导数辐角和模的几何意义，我们看到：如果\\(f'(z_0)\\neq0\\)，在\\(z_0\\)的邻域中，作一个以\\(z_0\\)为顶点的小三角形，这个小三角形被\\(f\\)映射为一个曲边三角形，它的微分三角形和原来的小三角形相似。因此，我们把这样的一个映射称为共形映射。\n更形式化的定义是：设函数\\(\\omega=f(z)\\)在\\(z_0\\)的领域内有定义，且在\\(z_0\\)处具有保角性和伸缩率的不变性，那么称映射\\(\\omega=f(z)\\)是共形映射。如果对\\(D\\)内每一点都是共形的，那么\\(\\omega=f(z)\\)是在\\(D\\)内的共形映射。\n如果\\(\\omega=f(z)\\)在\\(z_0\\)全纯，\\(f'(z_0)\\neq 0\\)，那么其在\\(z_0\\)是共形的。\n如果\\(\\omega=f(z)\\)只保证伸缩率的不变性和夹角的绝对值不变（但方向相反），那么称为第二类共形映射，之前提到的属于第一类共形映射。\n初等全纯函数 指数函数 设\\(z=x+iy\\)，定义\n\\[e^z = e^x(\\cos y+i\\sin y) \\]\n具有如下性质\n\\((e^z)'=e^z\\) 复数的三角表示\\(z=r(\\cos\\theta+i\\sin\\theta)\\)可以表示为\\(z=re^{i\\theta}\\) 对于任意\\(z\\in \\bm C,e^z\\neq 0\\)，这是因为 \\[|e^z|=e^x\u003e0 \\]\n对于任意\\(z_1,z_2\\)，有 \\[e^{z_1}e^{z_2}=e^{z_1+z_2} \\]\n\\(e^z\\)是以\\(2\\pi i\\)为周期的周期函数。 单叶\n设\\(f:D\\to \\bm C\\)是一个复变函数，如果对于\\(D\\)中的任意两点\\(z_1,z_2(z_1\\neq z_2)\\)，必有\\(f(z_1)\\neq f(z_2)\\)，就称\\(f\\)在\\(D\\)中是单叶的，\\(D\\)称为\\(f\\)的单叶性域。\n\\(\\omega=e^z\\)的单叶性域有\n\\[\\{z=x+iy:2k\\pi\u003c y\u003c2(k+1)\\pi\\},k=0,\\pm1,\\cdots \\]\n对数函数 对于给定的\\(z\\in C\\)，满足方程\\(e^\\omega=z\\)的\\(\\omega\\)称为\\(z\\)的对数，记为\\(\\omega=Logz\\)。\n设\\(z=re^{i\\theta}\\)，\\(\\omega=u+iv\\)，则\\(e^{u+iv}=re^{i\\theta}\\)，所以\\(e^u=r,v=\\theta+2k\\pi\\)。所以有\n\\[Logz=log|z|+iargz+2k\\pi i=log|z|+iArgz \\]\n所以，\\(Logz\\)是一个多值函数，它的多值性是由\\(z\\)的辐角\\(Argz\\)的多值性产生的。\n定理1\n如果\\(D\\)是不包含原点和无穷远点的单连通域，则必在\\(D\\)上存在无穷多个单值全纯函数\\(\\varphi_k,k=0,\\pm1,\\cdots\\)，使得在\\(D\\)上成立\n\\[e^{\\varphi_k(z)}=z,k=0,\\pm1,\\cdots; \\]\n而且对每一个\\(k\\)，有\\(\\varphi_k'(z)=\\frac{1}{z}\\).其中的每一个\\(\\varphi_k\\)都称为\\(Logz\\)在\\(D\\)上的单值全纯分支。\n至于为什么不包含原点和无穷远点：如果包含原点，那么\\(D\\)中就包含绕原点\\(z=0\\)的简单闭曲线\\(\\gamma\\)，当\\(z\\)从\\(\\gamma\\)上的一点\\(z_0\\)沿\\(\\gamma\\)的正方向（即逆时针）回到\\(z_0\\)时，\\(z\\)的辐角增加了\\(2\\pi\\)，\\(\\varphi_{k_0}(z_0)\\)的值连续地变为\\(\\varphi_{k_0+1}(z_0)\\)，而不再回到原来的\\(\\varphi_{k_0}(z_0)\\)。因此再这样的域中就不可能分出单值的全纯分支。无穷远点同理。\n定义1\n如果当\\(z\\)沿着\\(z_0\\)的充分小邻域中的任意简单闭曲线绕一圈时，多值函数的值就从一支变到另一支，那么称\\(z_0\\)为该多值函数的一个支点。\n以对数函数为例，\\(z=0,z=\\infty\\)就是\\(Logz\\)的支点。\n幂函数 \\(\\omega=z^\\mu\\)称为幂函数，这里\\(\\mu=a+bi\\)，分情况讨论\n1. \\(\\mu=n\\)，是一个自然数\n按照导数的定义，可以直接算出\n\\[(z^n)'=nz^{n-1} \\]\n其在\\(C\\)上每一点都是全纯的。这种函数也称作整函数\n它的单叶性域是\n\\[\\bigg\\{z:\\alpha \u003c argz\u003c\\beta,0\u003c\\beta-\\alpha\\leq\\frac{2\\pi}{n}\\bigg\\} \\]\n2. \\(\\mu=\\frac{1}{n}\\)，n是一个自然数\n对于一个给定的\\(z\\)，\\(z^{1/n}\\)有\\(n\\)个值，所以它是一个多值函数。多值性由\\(Argz\\)产生，\\(0,\\infty\\)是其支点。\\(C\\)去掉正实轴后所成的域上可以分出\\(n\\)个单值的全纯分支，它们是\n\\[\\omega = \\varphi_k(z) = \\sqrt[n]{|z|}\\bigg(\\cos\\frac{\\theta+2k\\pi}{n}+i\\sin\\frac{\\theta+2k\\pi}{n}\\bigg) \\]\n\\[k=0,1,\\cdots,n-1 \\]\n其中\\(\\theta=argz\\)，变化范围在\\(0\u003c argz\u003c2\\pi\\)\n3. \\(\\mu = a+bi\\)，是一个复数\n一般的幂函数\\(\\omega=z^\\mu\\)定义为\n\\[\\omega = z^\\mu=e^{\\mu Logz} \\]\n显然这也是个多值函数\n\\[\\omega = exp(alog|z|-b(argz+2k\\pi))exp(i[blog|z|+a(argz+2k\\pi)]) \\]\n\\[k=0,\\pm1,\\cdots \\]\n若\\(b=0,a=n\\)是一个整数，则\\(\\omega=z^n\\)是一个单值函数 若\\(b=0,a=p/q\\)是一个有理数，不妨设\\(p\u003c q\\)，这时 \\[\\omega=z^\\mu=z^{p/q}=|z|^{p/q}exp(i\\frac{p}{q}(argz+2k\\pi)) \\]\n当\\(k=0,1,\\cdots,q-1\\)时，\\(\\omega\\)有\\(q\\)个不同的值\n若\\(b=0,a\\)是一个无理数，这时 \\[\\omega = z^\\mu = |z|^aexp(iaargz)exp(i2k\\pi a) \\]\n此时\\(z^a\\)是一个无穷值函数\n若\\(b\\neq 0\\)，则\\(\\omega=z^\\mu\\)是一无穷值函数。 三角函数 由欧拉公式知道\n\\[e^{ix} = \\cos x+i\\sin x\\\\ e^{-ix} = \\cos x -i\\sin x \\]\n可以得到\n\\[\\cos z = \\frac{1}{2}(e^{iz}+e^{-iz})\\\\ \\sin z = \\frac{1}{2i}(e^{iz}-e^{-iz}) \\]\n有如下性质\n正弦余弦都是整函数，并且 \\[(\\cos z)' = -\\sin z\\\\ (\\sin z)' = \\cos z \\]\n以\\(2\\pi\\)为周期 \\(\\cos z\\)是偶函数，\\(\\sin z\\)是奇函数 对任意\\(z_1,z_2\\) \\[\\cos (z_1+z_2) = \\cos z_1\\cos z_2 - \\sin z_1\\sin z_2\\\\ \\sin (z_1+z_2) = \\sin z_1\\cos z_2 + \\cos z_1\\sin z_2\\\\ \\]\n\\(\\cos^2 z+\\sin^2 z=1,\\quad \\sin 2z = 2\\sin z\\cos z\\) \\(\\sin z\\)仅在\\(z=k\\pi\\)处为零，\\(\\cos z\\)仅在\\(k\\pi+\\pi/2\\)处为零，\\(k=0,\\pm1,\\cdots\\) \\(\\cos z,\\sin z\\)不是有界函数 同样我们就能定义正切余切\n\\[\\tg z = \\frac{\\sin z}{\\cos z} \\]\n\\[\\ctg z = \\frac{\\cos z}{\\sin z} \\]\n前者在除掉\\(z=\\pi/2+k\\pi\\)的开平面上全纯，后者在除掉\\(z=k\\pi\\)的开平面上全纯，\\(k=0,\\pm1,\\cdots\\)。\n之后我们也能定义双曲函数\n\\[chz=\\frac{e^z+e^{-z}}{2},shz=\\frac{e^z-e^{-z}}{2} \\]\n并且有\n\\[(chz)'=shz,(shz)'=chz \\]\n反三角函数有\n\\[Arcsinz=-iLn(iz+\\sqrt{1-z^2}) \\]\n\\[Arccosz=-iLn(z+\\sqrt{z^2-1}) \\]\n\\[Arctanz=-\\frac{i}{2}Ln\\frac{1+iz}{1-iz} \\]\n反双曲函数有\n\\[Arshz = Ln(z+\\sqrt{z^2+1}) \\]\n\\[Archz = Ln(z+\\sqrt{z^2-1}) \\]\n\\[Arthz = \\frac{1}{2}Ln\\frac{1+z}{1-z} \\]\n分式线性变换 形如\\(\\omega=T(z)=\\frac{az+b}{cz+d}\\)的映射称为分式线性变换或Mobius变换，其中\\(a,b,c,d\\)是复常数，且满足\\(ad-bc\\neq 0\\)，如果等于\\(0\\)原式就是常数或无意义，没有讨论价值。\n如果\\(c\\neq 0\\)，则除去点\\(z=-\\frac{d}{c}\\)外，\\(T(z)\\)在\\(\\bm C\\)上是全纯的，而且\n\\[T'(z)=\\frac{ad-bc}{(cz+d)^2}\\neq 0 \\]\n所以分式线性变换在\\(z\\neq -\\frac{d}{c}\\)处是保角变换。\n若\\(c=0\\)，则必\\(d\\neq 0\\)，此时\\(T(z)=Az+B(A=a/d,B=b/d)\\)，称为整线性变换，它是一个整函数。\n从方程\\(\\omega=T(z)\\)中把\\(z\\)解出来，得\n\\[z = T^{-1}(\\omega)=\\frac{-d\\omega+b}{c\\omega-a} \\]\n称为\\(\\omega=T(z)\\)的逆变换，它仍然是一个分式线性变换。由此可知\\(\\omega=T(z)\\)在\\(\\bm C\\)上是单叶的，当\\(c\\neq 0\\)时，规定\\(T(-\\frac{d}{c})=\\infty,T(\\infty)=\\frac{a}{c}\\)。当\\(c=0\\)时，规定\\(T(\\infty)=\\infty\\)，于是\\(\\omega=T(z)\\)把\\(\\bm C_\\infty\\)单叶地映射为\\(C_\\infty\\)。\n设\\(S,T\\)是两个分式线性变换，那么\\(S\\circ T\\)也是分式线性变换。且对每一个\\(T\\)，都有逆变换\\(T^{-1}\\)，即\\(T(T^{-1}(z))=z\\)\n分式线性变换有如下性质\n保角性 分式线性变换把圆周变成圆周（保圆性） 分式线性变换也能拆成多个变换，例如\n\\[\\omega = \\dfrac{az+b}{cz+d} \\]\n就可以拆成三个变换\n\\[z' = cz+d\\\\ z'' = \\dfrac{1}{z'}\\\\ \\omega=\\alpha+\\beta z'' \\]\n其中\\(\\alpha = \\dfrac{a}{c},\\beta=\\dfrac{bc-ad}{c}\\)。\n这个变换中第一个第三个是整线性变换，也就是进行了伸缩和平移变换。当然圆在伸缩和平移后还是一个圆。我们同样可以证明\\(\\omega=\\dfrac{1}{z}\\)把圆周变为圆周，此时我们证明了分式线性变换把圆周变为圆周。\n交比是分式线性变换的不变量 命题1\n分式线性变换\\(T\\)最多只有两个不动点，除非是恒等变换，即\\(T(z)\\equiv z\\)\n定义1\n设\\(z_1,z_2,z_3,z_4\\)是给定的四个点，其中至少有三个点是不相同的，称比值\n\\[\\frac{z_1-z_3}{z_1-z_4}\\bigg /\\frac{z_2-z_3}{z_2-z_4} \\]\n为这四个点的交比，记为\\((z_1,z_2,z_3,z_4)\\)\n规定\n\\[(\\infty,z_2,z_3,z_4)=\\frac{z_2-z_4}{z_2-z_3} \\]\n\\[(z_1,\\infty,z_3,z_4)=\\frac{z_1-z_3}{z_1-z_4} \\]\n\\[(z_1,z_2,\\infty,z_4)=\\frac{z_2-z_4}{z_1-z_4} \\]\n\\[(z_1,z_2,z_3,\\infty)=\\frac{z_1-z_3}{z_2-z_3} \\]\n按照交比的定义，有\n\\[(z,z_2,z_3,z_4)=\\frac{z-z_3}{z-z_4}\\cdot\\frac{z_2-z_4}{z_2-z_3} \\]\n它是一个分式线性变换，若把它记为\\(L(z)\\)，那么\n\\[L(z_2)=1,\\\\ L(z_3)=0,\\\\ L(z_4)=\\infty. \\]\n定理1\n有且只有一个分式线性变换把\\(\\bm C_\\infty\\)上三个不同的点\\(z_2,z_3,z_4\\)映为事先给定的\\(\\bm C_\\infty\\)上的三个点\\(\\omega_2,\\omega_3,\\omega_4\\)\n定理2\n交比是分式线性变换的不变量。也就是说，如果分式线性变换\\(T\\)把\\(z_1,z_2,z_3,z_4\\)映为\\(T(z_1),T(z_2),T(z_3),T(z_4)\\)，那么\n\\[(z_1,z_2,z_3,z_4)=(T(z_1),T(z_2),T(z_3),T(z_4)) \\]\n定理3\n如果\\(f(z_1,z_2,z_3,z_4)\\)是分式线性变换下的不变量，即对任意分式线性变换\\(T\\)都有\n\\[f(z_1,z_2,z_3,z_4) = f(T(z_1),T(z_2),T(z_3),T(z_4)) \\]\n那么\\(f\\)只能是交比\\((z_1,z_2,z_3,z_4)\\)的函数。\n命题2\n四点\\(z_1,z_2,z_3,z_4\\)共圆的充要条件是\n\\[Im(z_1,z_2,z_3,z_4)=0 \\]\n定义2\n设\\(\\bm C_\\infty\\)上的圆周\\(\\gamma\\)把平面分成\\(g_1\\)和\\(g_2\\)两个域，\\(z_1,z_2,z_3\\)是\\(\\gamma\\)上有序的三个点。如果当我们从\\(z_1\\)走到\\(z_2\\)再走到\\(z_3\\)时，\\(g_1\\)和\\(g_2\\)分别在我们的左边和右边，就分别称\\(g_1\\)和\\(g_2\\)为\\(\\gamma\\)关于走向\\(z_1,z_2,z_3\\)的左边和右边\n命题3\n\\(z_1,z_2,z_3\\)是\\(\\bm C_\\infty\\)上的圆周\\(\\gamma\\)上有序的三个点，那么\\(\\gamma\\)关于走向\\(z_1,z_2,z_3\\)的右边和左边的点\\(z\\)分别满足\n\\[Im(z,z_1,z_2,z_3)\u003e0\\\\ Im(z,z_1,z_2,z_3)\u003c0 \\]\n定理4\n设\\(\\gamma_1\\)和\\(\\gamma_2\\)是\\(\\bm C_\\infty\\)中的两个圆周，\\(z_1,z_2,z_3\\)是\\(\\gamma_1\\)上有序的三个点，如果分式线性变换\\(T\\)把\\(\\gamma_1\\)映为\\(\\gamma_2\\)，那么它一定把\\(\\gamma_1\\)关于走向\\(z_1,z_2,z_3\\)的右边和左边分别变为\\(\\gamma_2\\)关于走向\\(T(z_1),T(z_2),T(z_3)\\)的右边和左边。\n对称点及其在分布线性变换下的不变性 定义1\n设\\(\\gamma\\)是以\\(a\\)为中心，以\\(R\\)为半径的圆周，如果点\\(z,z^*\\)在从\\(a\\)出发的射线上，且满足\n\\[|z-a||z^*-a|=R^2 \\]\n则称\\(z,z^*\\)是关于\\(\\gamma\\)对称的。如果\\(\\gamma\\)是直线时，则当\\(\\gamma\\)是线段\\([z,z^*]\\)的垂直平分线时，称\\(z,z^*\\)关于\\(\\gamma\\)是对称的。\n其中\n\\[z^* = a+\\dfrac{R^2}{\\bar{z}-\\bar{a}} \\]\n命题1\n设\\(\\gamma\\)是\\(\\bm C_\\infty\\)中的圆周，那么\\(z,z^*\\)关于\\(\\gamma\\)对称的充要条件是对\\(\\gamma\\)上任意三点\\(z_1,z_2,z_3\\)，有\n\\[(z^*,z_1,z_2,z_3)=\\overline{(z,z_1,z_2,z_3)} \\]\n对于直线的情形，可以看做无限半径的圆。\n定理1\n对称点在分式线性变换下不变。这就是说，设分式线性变换\\(T\\)把圆周\\(\\gamma\\)变为\\(\\Gamma\\)，如果\\(z,z^*\\)是关于\\(\\gamma\\)的对称点，那么\\(T(z),T(z^*)\\)是关于\\(\\Gamma\\)的对称点。\n全纯函数的积分表示 复变函数的积分 设\\(z=\\gamma(t)(a\\leq t\\leq b)\\)是一条可求长曲线，\\(f\\)是定义在\\(\\gamma\\)上的函数，沿\\(\\gamma\\)的正方向取分点\\(\\gamma(a)=z_0,z_1,z_2,\\cdots,z_n=\\gamma(b)\\)，在\\(\\gamma\\)中从\\(z_{k-1}\\)到\\(z_k\\)的弧段上任取点\\(\\zeta_k,k=1,\\cdots,n\\)，作Riemann和\n\\[\\sum_{k=1}^n f(\\zeta_k)(z_k-z_{k-1}) \\]\n用\\(s_k\\)记弧段\\(z_{k-1}z_k\\)的长度，如果\\(\\lambda=max\\{s_k\\}\\to 0\\)时，不论\\(\\zeta_k\\)的取法，上式总有一确定的极限，就称次极限为\\(f\\)沿\\(\\gamma\\)的积分，记为\n\\[\\int_{\\gamma}f(z)dz = \\lim_{\\lambda\\to 0}\\sum_{k=1}^n f(\\zeta_k)(z_k-z_{k-1}) \\]\n只要\\(f\\)在\\(\\gamma\\)上连续，上述积分、上述极限一定存在。\n命题1\n设\\(f=u+iv\\)在可求长曲线\\(\\gamma\\)上连续，则有\n\\[\\int_{\\gamma}f(z)dz = \\int_{\\gamma}udx-vdy+i\\int_{\\gamma}vdx+udy \\]\n或者便于记忆\n\\[f(z)dz = (u+iv)(dx+idy) = (udx-vdy)+i(vdx+udy) \\]\n如果曲线光滑，还可以通过曲线的参数方程来计算积分。\n命题2\n如果\\(z=\\gamma(t)(a\\leq t\\leq b)\\)是光滑曲线，\\(f\\)在\\(\\gamma\\)上连续，那么\n\\[\\int_{\\gamma}f(z)dz = \\int^b_af(\\gamma(t))\\gamma'(t)dt \\]\n命题3\n如果\\(f,g\\)在可求长曲线\\(\\gamma\\)上连续，那么\n\\(\\int_{\\gamma^-}f(z)dz=-\\int_{\\gamma}f(z)dz\\)，\\(\\gamma^-\\)是与\\(\\gamma\\)反向的曲线 \\(\\int_{\\gamma}f(\\alpha f(z)+\\beta g(z))dz=\\alpha\\int_{\\gamma}f(z)dz+\\beta \\int_{\\gamma}g(z)dz\\)，\\(\\alpha,\\beta\\)是两个复常数 \\(\\int_{\\gamma}f(z)dz=\\int_{\\gamma_1}f(z)dz+\\int_{\\gamma_2}f(z)dz\\)，这里\\(\\gamma\\)是由\\(\\gamma_1\\)和\\(\\gamma_2\\)组成的曲线。 命题4\n如果\\(\\gamma\\)的长度为\\(L\\)，\\(M=\\sup|f(z)|\\)（即上确界），那么\n\\[\\bigg |\\int_\\gamma f(z)dz\\bigg |\\leq ML \\]\nCauchy积分定理 Cauchy定理\n设\\(D\\)是\\(\\bm C\\)中的单连通域，\\(f\\in H(D)\\)（即全纯函数），且\\(f'\\)在\\(D\\)中连续，则对\\(D\\)中任意的可求长闭曲线\\(\\gamma\\)，均有\n\\[\\int_\\gamma f(z)dz = 0 \\]\n注意，只要使得\\(f\\)的不全纯的点在\\(\\gamma\\)包围的区域中（而不是必须在\\(\\gamma\\)上）就不能使用这个定理。\n引理1\n设\\(f\\)是域\\(D\\)中的连续函数，\\(\\gamma\\)是\\(D\\)内的可求长曲线，对于任给的\\(\\varepsilon\u003e0\\)，一定存在一条\\(D\\)中的折线\\(P\\)，使得\n\\(P\\)和\\(\\gamma\\)有相同的起点和终点，\\(P\\)中其他的顶点都在\\(\\gamma\\)上 \\(|\\int_\\gamma f(z)dz-\\int_P f(z)dz|\u003c\\varepsilon\\) Cauchy-Goursat定理\n设\\(D\\)是\\(\\bm C\\)中的单连通域，如果\\(f\\in H(D)\\)，那么对\\(D\\)中任意的可求长闭曲线\\(\\gamma\\)，均有\n\\[\\int_\\gamma f(z)dz = 0 \\]\n注意点同上。\n这个定理也意味着积分和路径无关，只与始末位置有关。\n定理1\n设\\(D\\)是可求长简单闭曲线\\(\\gamma\\)的内部，若\\(f\\in H(D)\\bigcap C(\\bar D)\\)（即在\\(D\\)上全纯且在\\(\\bar D\\)（闭包）上连续），则\n\\[\\int_\\gamma f(z)dz = 0 \\]\n定理2\n设\\(\\gamma_0,\\gamma_1,\\cdots,\\gamma_n\\)是\\(n+1\\)条可求长简单闭曲线，\\(\\gamma_1,\\cdots,\\gamma_n\\)都在\\(\\gamma_0\\)内部，\\(\\gamma_1,\\cdots,\\gamma_n\\)中的每一条都在其他\\(n-1\\)条的外部，\\(D\\)是由这\\(n+1\\)条曲线围成的域，用\\(\\gamma\\)记\\(D\\)的边界，如果\\(f\\in H(D)\\bigcap C(\\bar D)\\)，那么\n\\[\\int_\\gamma f(z)dz = 0 \\]\n或者也可以写作\n\\[\\int_{\\gamma_0} f(z)dz = \\int_{\\gamma_1} f(z)dz+\\cdots+\\int_{\\gamma_n} f(z)dz \\]\n全纯函数的原函数 定义1\n设\\(f:D\\to \\bm C\\)是定义在域\\(D\\)上的一个函数，如果存在\\(F\\in H(D)\\)，使得\\(F'(z)=f(z)\\)在\\(D\\)上成立，就称\\(F\\)是\\(f\\)的一个原函数\n定理1\n设\\(f\\)在\\(D\\)中连续，且对\\(D\\)中任意可求长闭曲线\\(\\gamma\\)均有\n\\[\\int_\\gamma f(z)dz=0 \\]\n那么\n\\[F(z) = \\int^z_{z_0}f(\\zeta)d\\zeta \\]\n是\\(D\\)中的全纯函数，且在\\(D\\)中有\\(F'(z)=f(z)\\)，这里\\(z_0\\)是\\(D\\)中一固定点。\n定理2\n设\\(D\\)是\\(\\bm C\\)中的单连通域，\\(f\\in H(D)\\)，那么\\(F(z)=\\int^z_{z_0}f(\\zeta)d\\zeta\\)是\\(f\\)在\\(D\\)中的一个原函数。\n定理3\n设\\(D\\)是\\(\\bm C\\)中的单连通域，\\(f\\in H(D)\\)，\\(\\varPhi\\)是\\(f\\)的任一原函数，那么\n\\[\\int^z_{z_0}f(\\zeta)d\\zeta = \\varPhi(z)-\\varPhi(z_0) \\]\nCauchy积分公式 定理1\n设\\(D\\)是由可求长简单闭曲线\\(\\gamma\\)围成的域，如果\\(f\\in H(D)\\bigcap C(\\bar D)\\)，那么对任意\\(z\\in D\\)，均有\n\\[f(z) = \\frac{1}{2\\pi i}\\int_\\gamma \\frac{f(\\zeta)}{\\zeta-z}d\\zeta \\]\n定理2\n设\\(\\gamma\\)是\\(C\\)中的可求长曲线，\\(g\\)是\\(\\gamma\\)上的连续函数，那么由Cauchy型积分确定的函数\n\\[G(z) = \\frac{1}{2\\pi i}\\int_\\gamma \\frac{g(\\zeta)}{\\zeta-z}d\\zeta \\]\n在\\(C\\setminus y\\)（差集）上有任意阶导数，而且\n\\[G^{(n)}(z)=\\frac{n!}{2\\pi i}\\int_\\gamma\\frac{g(\\zeta)}{(\\zeta-z)^{n+1}}d\\zeta,n=1,2,\\cdots \\]\n定理3\n设\\(D\\)是由可求长简单闭曲线\\(\\gamma\\)围成的域，如果\\(f\\in H(D)\\bigcap C(\\bar D)\\)，那么\\(f\\)在\\(D\\)上有任意阶导数，而且对任意\\(z\\in D\\)，有\n\\[f^{(n)}(z)=\\frac{n!}{2\\pi i}\\int_\\gamma\\frac{f(\\zeta)}{(\\zeta-z)^{n+1}}d\\zeta,n=1,2,\\cdots \\]\n定理4\n如果\\(f\\)是域\\(D\\)上的全纯函数，那么\\(f\\)在\\(D\\)上有任意阶导数。\n定理5\n设\\(\\gamma_0,\\gamma_1,\\cdots,\\gamma_k\\)是\\(k+1\\)条可求长简单闭曲线，\\(\\gamma_1,\\cdots,\\gamma_k\\)都在\\(\\gamma_0\\)的内部，\\(\\gamma_1,\\cdots,\\gamma_k\\)中的每一条都在其他\\(k-1\\)条的外部，\\(D\\)是由这\\(k+1\\)条曲线围成的域，\\(D\\)的边界\\(\\gamma\\)由\\(\\gamma_0,\\gamma_1,\\cdots,\\gamma_k\\)所组成，如果\\(f\\in H(D)\\bigcap C(\\bar D)\\)，则对任意\\(z\\in D\\)，有\n\\[f(z) = \\frac{1}{2\\pi i}\\int_\\gamma \\frac{f(\\zeta)}{\\zeta-z}d\\zeta \\]\n\\(f\\)在\\(D\\)内有任意阶导数，且\n\\[f^{(n)}(z)=\\frac{n!}{2\\pi i}\\int_\\gamma\\frac{f(\\zeta)}{(\\zeta-z)^{n+1}}d\\zeta,n=1,2,\\cdots \\]\nCauchy积分公式的一些重要推论 Cauchy不等式\n设\\(f\\)在\\(B(a,R)\\)中全纯，且对任意\\(z\\in B(a,R)\\)，有\\(|f(z)|\\leq M\\)，那么\n\\[|f^{(n)}(a)|\\leq\\frac{n!M}{R^n},n=1,2,\\cdots \\]\nLiouville定理\n有界整函数必为常数\n代数学基本定理\n任意复系数多项式\n\\[P(z)=a_0z^n+a_1z^{n-1}+\\cdots+a_n,a_0\\neq 0 \\]\n在\\(\\bm C\\)中必有零点\nMorera定理\n如果\\(f\\)是域\\(D\\)上的连续函数，且沿\\(D\\)内任一可求长闭曲线的积分为零，那么\\(f\\)在\\(D\\)上全纯\n非齐次Cauchy积分公式 TODO\n一维\\(\\bar\\partial\\)问题的解 TODO\n全纯函数的Taylor展开及其应用 Weierstrass定理 设\\(z_1,z_2,\\cdots\\)是\\(\\bm C\\)中的一列复数，称\n\\[\\sum^\\infty_{n=1}z_n = z_1+z_2+\\cdots \\]\n为一个复数项级数。这个级数称为是收敛的，如果它的部分和数列\\(S_n=\\sum^n_{k=1}z_k\\)收敛，如果\\(\\{S_n\\}\\)的极限为\\(S\\)，就说这个级数的和为\\(S\\)，记为\\(\\sum^\\infty_{n=1}z_n = S\\)\n从数列的Cauchy收敛准则马上可得级数的Cauchy收敛准则：\n级数收敛的充要条件是对任意\\(\\varepsilon\u003e0\\)，存在正整数\\(N\\)，使得当\\(n\u003eN\\)时，不等式\n\\[z_{n+1}+z_{n+2}+\\cdots+z_{n+p}\u003c\\varepsilon \\]\n对任意自然数\\(p\\)成立\n从收敛准则即得\\(\\sum^\\infty_{n=1}z_n\\)收敛的必要条件是\\(\\lim_{n\\to \\infty}z_n=0\\)\n如果\\(\\sum^\\infty_{n=1}|z_n|\\)收敛，就说级数\\(\\sum^\\infty_{n=1}z_n\\)绝对收敛。同样，绝对收敛的级数一定收敛，反之不一定成立。并且有\\(\\sum^\\infty_{n=1}|z_n|\\geq|\\sum^\\infty_{n=1}z_n|\\)\n另外，\\(\\sum^\\infty_{n=1}z_n\\)收敛的充要条件是其实部和虚部构成的数列分别都收敛。\n设\\(E\\)是\\(\\bm C\\)中的一个点集，\\(f_n:E\\to \\bm C\\)是定义在\\(E\\)上的一个函数列，如果对于每一个\\(z\\in E\\)，级数\n\\[\\sum^\\infty_{n=1}f_n(z)=f_1(z)+f_2(z)+\\cdots \\]\n收敛到\\(f(z)\\)，就说其在\\(E\\)上收敛，其和函数为\\(f\\)，记为\\(\\sum^\\infty_{n=1}f_n(z)=f(z)\\)\n一致连续\n设\\(\\sum^\\infty_{n=1}f_n(z)\\)是定义在点集\\(E\\)上的级数，我们说\\(\\sum^\\infty_{n=1}f_n(z)\\)在\\(E\\)上一致收敛到\\(f(z)\\)，是指对任意\\(\\varepsilon\u003e0\\)，存在正整数\\(N\\)，当\\(n\u003eN\\)时，不等式\n\\[|S_n(z)-f(z)|\u003c\\varepsilon \\]\n对所有的\\(z\\in E\\)成立，这里，\\(S_n(z)=\\sum^n_{k=1}f_k(z)\\)是级数的部分和。\nCauchy收敛准则\n级数\\(\\sum^\\infty_{n=1}f_n(z)\\)在\\(E\\)上一致收敛的充要条件是对任意\\(\\varepsilon\u003e0\\)，存在正整数\\(N\\)，当\\(n\u003eN\\)时，不等式\n\\[|f_{n+1}(z)+f_{n+2}(z)+\\cdots+f_{n+p}(z)|\u003c\\varepsilon \\]\n对所有\\(z\\in E\\)及任意自然数\\(p\\)成立。\nWeierstrass一致收敛判别法\n设\\(f_n:E\\to \\bm C\\)是定义在\\(E\\)上的函数列，且在\\(E\\)上满足\\(|f_n(z)|\\leq a_n,n=1,2,\\cdots\\)，如果\\(\\sum^\\infty_{n=1}a_n\\)收敛，那么\\(\\sum^\\infty_{n=1}f_n(z)\\)在\\(E\\)上一致收敛。\n定理1\n设级数\\(\\sum^\\infty_{n=1}f_n(z)\\)在点集\\(E\\)上一致收敛到\\(f(z)\\)，如果每个\\(f_n(n=1,2,\\cdots)\\)都是\\(E\\)上的连续函数，那么\\(f\\)也是\\(E\\)上的连续函数。\n定理2\n设级数\\(\\sum^\\infty_{n=1}f_n(z)\\)在可求长曲线\\(\\gamma\\)上一致收敛到\\(f(z)\\)，如果每个\\(f_n(n=1,2,\\cdots)\\)都在\\(\\gamma\\)上连续，那么\n\\[\\int_\\gamma f(z)dz=\\sum^\\infty_{n=1}\\int_\\gamma f_n(z)dz \\]\n内闭一致收敛\n如果级数\\(\\sum^\\infty_{n=1}f_n(z)\\)在域\\(D\\)的任意紧子集上一致收敛，就称\\(\\sum^\\infty_{n=1}f_n(z)\\)在\\(D\\)中内闭一致收敛。\n定义1\n如果\\(D\\)的子集\\(G\\)满足\n\\(\\bar G\\subset D\\) \\(\\bar G\\)是紧的 就说\\(G\\)相对于\\(D\\)是紧的，记为\\(G\\subset\\subset D\\)\n引理1\n设\\(D\\)是\\(\\bm C\\)中的域，\\(K\\)是\\(D\\)中的紧子集，且包含在相对于\\(D\\)是紧的开集\\(G\\)中，即\\(K\\subset G\\subset\\subset D\\)，那么对任意\\(f\\in H(D)\\)，均有\n\\[sup\\{|f^{(k)}|:z\\in K\\}\\leq Csup{|f(z)|:z\\in G} \\]\n这里，\\(k\\)是任意自然数，\\(C\\)是与\\(k,K,G\\)有关的常数。\nWeierstrass定理\n设\\(D\\)是\\(\\bm C\\)中的域，如果\n\\(f_n\\in H(D),n=1,2,\\cdots\\) \\(\\sum^\\infty_{n=1} f_n(z)\\)在\\(D\\)中内闭一致收敛到\\(f(z)\\) 那么\n\\(f\\in H(D)\\) 对任意自然数\\(k\\)，\\(\\sum^\\infty_{n=1} f_n^{(k)}(z)\\)在\\(D\\)中内闭一致收敛到\\(f^{(k)}(z)\\) 幂级数 幂级数，是指形如\n\\[\\sum^\\infty_{n=0}a_n(z-z_0)^n = a_0+a_1(z-z_0)+a_2(z-z_0)^2+\\cdots \\]\n的级数，其中\\(a_n,z_0\\)都是复常数。\n定义1\n如果存在常数\\(R\\)，使得当\\(|z|\u003c R\\)时，级数\\(\\sum^\\infty_{n=0}a_nz^n\\)收敛；当\\(|z|\u003eR\\)时，级数发散，就称\\(R\\)为该级数的收敛半径，\\(\\{z:|z|\u003c R\\}\\)称为该级数的收敛圈。\n定理1\n\\(\\sum^\\infty_{n=0}a_nz^n\\)的收敛半径为\n\\[R=1\\bigg/\\overline{\\lim_{n\\to\\infty}}\\sqrt[n]{|a_n|} \\]\n其中\\(\\overline\\lim\\)是上极限\nAbel定理\n如果\\(\\sum^\\infty_{n=0}a_nz^n\\)在\\(z=z_0\\neq 0\\)处收敛，则必在\\(\\{z:|z|\u003c|z_0|\\}\\)中内闭绝对一致收敛。\n定理2\n幂级数在其收敛圆内确定一个全纯函数。\n非切向极限\n设\\(g\\)是定义在单位圆中的函数，\\(e^{i\\theta_0}\\)是单位圆周上一点，\\(S_\\alpha(e^{i\\theta_0})\\)如下图所示，其中\\(\\alpha\u003c\\frac{\\pi}{2}\\)，如果当\\(z\\)在\\(S_\\alpha(e^{i\\theta_0})\\)中趋于\\(e^{i\\theta_0}\\)时，\\(g(z)\\)有极限\\(l\\)，就称\\(g\\)在\\(e^{i\\theta_0}\\)处有非切向极限\\(l\\)，记为\n\\[\\lim_{z\\to e^{i\\theta_0},z\\in S_\\alpha(e^{i\\theta_0})}g(z)=l \\]\n1.jpg\rAbel第二定理\n设\\(f(z)=\\sum^\\infty_{n=0}a_nz^n\\)的收敛半径\\(R=1\\)，且级数在\\(z=1\\)处收敛于\\(S\\)，那么\\(f\\)在\\(z=1\\)处有非切向极限\\(S\\)，即\n\\[\\lim_{z\\to 1,z\\in S_\\alpha(1)}f(z)=S \\]\n其他一些求收敛半径的方法\n总体上和高等数学差别不大\n比值法\n如果\\(\\lim_{n\\to \\infty}|c_{n+1}/c_n|=\\lambda\\neq 0\\)，那么半径为\\(R=1/\\lambda\\)\n根值法\n如果\\(\\lim_{n\\to \\infty}\\sqrt[n]{|c_n|}=\\mu\\neq 0\\)，那么半径为\\(R=1/\\mu\\)\n定理3\n设幂级数\\(\\sum^\\infty_{n=0}c_n(z-z_0)^n\\)的收敛半径为\\(R\\)，那么\n它的和函数\\(f(z)\\)，即 \\[f(z) = \\sum^\\infty_{n=0}c_n(z-a)^n \\]\n是收敛圆：\\(|z-a|\u003c R\\)内的解析函数\n\\(f(z)\\)在收敛圆内的导数可将其幂级数逐项求导得到，即 \\[f'(z) = \\sum^\\infty_{n=0}nc_n(z-a)^{n-1} \\]\n\\(f(z)\\)在收敛圆内可以逐项积分，即 \\[\\int_C f(z)dz = \\sum^\\infty_{n=0}c_n\\int_C(z-a)^ndz, C\\in|z-a|\u003c R \\]\n或\n\\[\\int_0^zf(z)dz = \\sum^\\infty_{n=0}\\frac{c_n}{n+1}(z-a)^{n+1} \\]\n全纯函数的Taylor展开 前面已经证明，幂级数在它的收敛圆内表示一个全纯函数，而在一个圆内全纯的函数也一定可以展开成幂级数。\n定理1\n若\\(f\\in H(B(z_0,R))\\)，则\\(f\\)可以在\\(B(z_0,R)\\)中展开成幂级数\n\\[f(z)=\\sum_{n=0}^\\infty\\frac{f^{(n)}(z_0)}{n!}(z-z_0)^n,z\\in B(z_0,R) \\]\n右端的级数称为\\(f\\)的Taylor级数\n定理2\n\\(f\\)在点\\(z_0\\)处全纯的充要条件是\\(f\\)在\\(z_0\\)的邻域内可以展开成幂级数\n\\[f(z)=\\sum_{n=0}^\\infty a_n(z-z_0)^n \\]\n定义1\n设\\(f\\)在\\(z_0\\)点全纯且不恒为零，如果\n\\[f(z_0)=0,f'(z_0)=0,\\cdots,f^{(m-1)}(z_0)=0,f^{(m)}(z_0)\\neq 0 \\]\n则称\\(z_0\\)是\\(f\\)的\\(m\\)阶零点。\n命题1\n\\(z_0\\)为\\(f\\)的\\(m\\)阶零点的充要条件是\\(f\\)在\\(z_0\\)的邻域内可以表示为\n\\[f(z)=(z-z_0)^mg(z) \\]\n这里，\\(g\\)在\\(z_0\\)点全纯，且\\(g(z_0)\\neq 0\\)\n事实上，如果\\(z_0\\)是\\(f(z)\\)的\\(m\\)阶零点，那么\\(f(z)\\)可以表示成上述的形式，设\\(g(z)\\)在\\(z_0\\)处的泰勒展开为\n\\[g(z) = c_0+c_1(z-z_0)+c_2(z-z_0)^2+\\cdots \\]\n其中\\(c_0=g(z_0)\\neq 0\\)，从而\n\\[f(z) = c_0(z-z_0)^m+c_1(z-z_0)^{m+1}+\\cdots \\]\n也就是前\\(m\\)项系数都为0.\n命题2\n设\\(D\\)是\\(\\bm C\\)中的域，\\(f\\in H(D)\\)，如果\\(f\\)在\\(D\\)中的小圆盘\\(B(z_0,\\varepsilon)\\)上恒等于零，那么\\(f\\)在\\(D\\)上恒等于\\(0\\)。\n命题3\n设\\(D\\)是\\(\\bm C\\)中的域，\\(f\\in H(D), f(z)\\not\\equiv 0\\)，那么\\(f\\)在\\(D\\)中的零点是孤立的。即若\\(z_0\\)为\\(f\\)的零点，则必存在\\(z_0\\)的领域\\(B(z_0,\\varepsilon)\\)，使得\\(f\\)在\\(B(z_0,\\varepsilon)\\)中除了\\(z_0\\)外不再有其他的零点。\n唯一性定理\n设\\(D\\)是\\(\\bm C\\)中的域，\\(f_1,f_2\\in H(D)\\)，如果存在\\(D\\)中的点列\\(\\{z_n\\}\\)，使得\\(f_1(z_n)=f_2(z_n),n=1,2,\\cdots\\)，且\\(\\lim_{n\\to\\infty}z_n=a\\in D\\)，那么在\\(D\\)中有\\(f_1(z)=\\equiv f_2(z)\\)\n常见的泰勒展开\n以下都是在\\(z=0\\)处的展开式\n\\[\\frac{1}{1-z}=\\sum^\\infty_{n=0}z^n,|z|\u003c1 \\]\n\\[\\frac{1}{1+z}=\\sum^\\infty_{n=0}(-1)^nz^n,|z|\u003c1 \\]\n\\[e^z = \\sum^\\infty_{n=0} \\frac{z^n}{n!},z\\in\\bm C \\]\n\\[cosz = \\sum^\\infty_{n=0} (-1)^n\\frac{z^{2n}}{(2n)!},z\\in\\bm C \\]\n\\[sinz = \\sum^\\infty_{n=0} (-1)^n\\frac{z^{2n+1}}{(2n+1)!},z\\in\\bm C \\]\n\\[\\log(1+z) = \\sum^\\infty_{n=1} (-1)^{n-1}\\frac{z^n}{n},|z|\u003c1 \\]\n\\[exp[a\\log(1+z)] = \\sum^\\infty_{n=0}\\binom{a}{n}z^n,|z|\u003c1 \\]\n辐角原理和Rouche定理 TODO\n最大模原理和Schwarz引理 TODO\n全纯函数的Laurent展开及其应用 前面证明了，圆盘中的全纯函数一定可以在圆盘中展开成幂级数。但圆环中的全纯函数不一定，但是一定可以展开成洛朗级数。\n全纯函数的Laurent展开 称级数\n\\[\\sum^\\infty_{n=-\\infty}a_n(z-z_0)^n=\\sum^\\infty_{n=0}a_n(z-z_0)^n+\\sum^\\infty_{n=1}a_{-n}(z-z_0)^{-n} \\]\n为洛朗级数。由两部分组成，第一部分是幂级数，第二部分为负幂项的级数。如果这两个级数都收敛，则整个洛朗级数收敛。\n定理1\n如果洛朗级数\n\\[\\sum^\\infty_{n=-\\infty}a_n(z-z_0)^n=\\sum^\\infty_{n=0}a_n(z-z_0)^n+\\sum^\\infty_{n=1}a_{-n}(z-z_0)^{-n} \\]\n的收敛域为圆环\\(D=\\{z:r\u003c |z-z_0|\u003c R\\}\\)，那么它在\\(D\\)中绝对收敛且内闭一致收敛，它的和函数在\\(D\\)中全纯。\n上述级数的幂级数部分称为全纯部分，负幂项级数部分称为主要部分。\n该定理的逆定理也成立。\n设\\(D=\\{z:r\u003c|z-z_0|\u003c R\\}\\)，如果\\(f\\in H(D)\\)，那么\\(f\\)在\\(D\\)上可以展开为洛朗级数\n\\[f(z) = \\sum^\\infty_{n=-\\infty}a_n(z-z_0)^n \\]\n其中\n\\[a_n = \\frac{1}{2\\pi i}\\int_{\\gamma_\\rho}\\frac{f(\\zeta)}{(\\zeta-z_0)^{n+1}}d\\zeta \\]\n\\[\\gamma_\\rho = \\{\\zeta:|\\zeta-z_0|=\\rho\\}(r\u003c\\rho\u003c R) \\]\n并且这个展开式是唯一的。\n孤立奇点 如果\\(f\\)在无心圆盘\\(\\{z:0\u003c|z-z_0|\u003c R\\}\\)中全纯（而在圆心不全纯），就称\\(z_0\\)是\\(f\\)的孤立奇点。在奇点附近有三种情况\n\\(\\lim_{z\\to z_0}f(z)=a,a\\)是一有限数，这时称\\(z_0\\)是\\(f\\)的可去奇点 \\(\\lim_{z\\to z_0}f(z)=\\infty\\)，这时称\\(z_0\\)是\\(f\\)的极点 \\(\\lim_{z\\to z_0}f(z)\\)不存在，这时称\\(z_0\\)是\\(f\\)的本性奇点 定理1\n\\(z_0\\)是\\(f\\)的可去奇点的充要条件是\\(f\\)在\\(z_0\\)附近有界。\n命题1\n\\(z_0\\)是\\(f\\)的极点的充要条件是\\(z_0\\)为\\(1/f\\)的零点。\n定义1\n如果\\(z_0\\)是\\(1/f(z)\\)的\\(m\\)阶零点，就称\\(z_0\\)是\\(f\\)的\\(m\\)阶极点。\n定理2\n\\(z_0\\)是\\(f\\)的\\(m\\)阶极点的充要条件是\\(f\\)在\\(z_0\\)附近的洛朗级数为\n\\[f(z) = \\frac{a_{-m}}{(z-z_0)^m}+\\cdots+\\frac{a_{-1}}{z-z_0}+a_0+a_1(z-z_0)+\\cdots \\]\n其中\\(a_{-m}\\neq 0\\)\n定理3\n\\(f\\)在可去奇点处的特征是洛朗级数没有主要部分，只有全纯部分\n\\(f\\)在极点处的特征是洛朗级数的主要部分只有有限项。最高负幂项为\\(t^{-m}\\)，则为\\(m\\)级极点。\n\\(f\\)在本性奇点处的特征是洛朗级数的主要部分有无限项。\n定理4\n设\\(z_0\\)是\\(f\\)的本性奇点，那么对任意\\(A\\in\\bm C_\\infty\\)，必存在趋于\\(z_0\\)的点列\\(\\{z_n\\}\\)，使得\\(\\lim_{n\\to\\infty}f(z_n)=A\\)\n定理5\n全纯函数在本性奇点的邻域内无穷多次地取到每个有穷复值，最多只有一个例外\n定义2\n我们讨论无穷远点。如果\\(f\\)在无穷远点的邻域（不包括无穷远点）\\(\\{z:0\\leq R\u003c|z|\u003c\\infty\\}\\)中全纯，\\(\\infty\\)就是\\(f\\)的孤立奇点。\n记\n\\[g(\\zeta)=f(\\frac{1}{\\zeta}) \\]\n如果\\(\\zeta=0\\)是\\(g\\)的可去奇点、\\(m\\)阶极点或本性奇点，那么我们相应地称\\(z=\\dfrac{1}{\\zeta}=\\infty\\)是\\(f\\)的可去奇点、\\(m\\)阶极点或本性奇点。\n整函数与亚纯函数 如果\\(f\\)在整个复平面\\(\\bm C\\)上全纯，就称\\(f\\)为整函数\n定理1\n在无穷远处全纯的整函数一定是常数。\n定理2\n如果无穷远点是整函数\\(f\\)的一个\\(m\\)阶极点，那么\\(f\\)是一个\\(m\\)次多项式。\n如果\\(f\\)在整个复平面\\(\\bm C\\)上除去极点外没有其他的奇点，就称\\(f\\)是一个亚纯函数。整函数显然是亚纯函数。\n此外有理函数\n\\[f(z) = \\frac{P_n(z)}{Q_m(z)} \\]\n也是亚纯函数，这里，\\(P_n(z),Q_m(z)\\)是两个既约（分式最简）的多项式\n定理3\n若\\(z=\\infty\\)是亚纯函数\\(f\\)的可去奇点或极点，则\\(f\\)一定是有理函数。\n反过来也成立。\n残数定理 定义1\n设\\(a\\)是\\(f\\)的一个孤立奇点，\\(f\\)在\\(a\\)点的邻域\\(B(a,r)\\)中的洛朗级数为\\(f(z)=\\sum^\\infty_{n=-\\infty}c_n(z-a)^n\\)，称\\(c_{-1}\\)为\\(f\\)在\\(a\\)点的残数，记为\n\\[Res(f,a) = c_{-1} \\]\n或\n\\[\\underset{z=a}{Res}f = c_{-1} \\]\n根据洛朗级数的计算方法，我们知道\n\\[c_{-1} = \\frac{1}{2\\pi i}\\int_\\gamma f(\\zeta)d\\zeta \\]\n结合上上式就有\n\\[\\int_\\gamma f(z)dz = 2\\pi iRes(f,a) \\]\n这里，\\(\\gamma=\\{z:|z-a|=\\rho\\},0\u003c\\rho\u003c r\\)\n若\\(z=\\infty\\)是\\(f\\)的孤立奇点，即\\(f\\)在\\(R\u003c|z|\u003c\\infty\\)中全纯，我们定义\\(f\\)在\\(z=\\infty\\)处的残数为\n\\[Res(f,\\infty) = -\\frac{1}{2\\pi i}\\int_\\gamma f(z)dz \\]\n这里，\\(\\gamma=\\{z:|z|=\\rho\\},R\u003c\\rho\u003c\\infty\\)\n命题1\n若\\(a\\)是\\(f\\)的\\(m\\)阶极点，则\n\\[Res(f,a) = \\frac{1}{(m-1)!}\\lim_{z\\to a}\\frac{d^{m-1}}{dz^{m-1}}\\{(z-a)^mf(z)\\} \\]\n命题2\n若\\(a\\)是\\(f\\)的\\(1\\)阶极点，则\n\\[Res(f,a) = \\lim_{z\\to a}(z-a)f(z) \\]\n命题3\n设\\(f=\\frac{g}{h}\\)，\\(g,h\\)都在\\(a\\)处全纯，且\\(g(a)\\neq 0\\)，\\(h(a)=0\\)，\\(h'(a)\\neq 0\\)，那么\n\\[Res(f,a) = \\frac{g(a)}{h'(a)} \\]\n残数定理\n设\\(D\\)是复平面上的一个有界区域，它的边界\\(\\gamma\\)由一条或若干条简单闭曲线组成，如果\\(f\\)在\\(D\\)中除去孤立奇点\\(z_1,\\cdots,z_n\\)外是全纯的，在闭域\\(\\overline{D}\\)上除去\\(z_1,\\cdots,z_n\\)外是连续的，那么\n\\[\\int_\\gamma f(z)dz = 2\\pi i\\sum^n_{k=1} Res(f,z_k) \\]\n定理1\n若\\(f\\)在\\(\\bm C\\)中除去\\(z_1,\\cdots,z_n\\)外是全纯的，则\\(f\\)在\\(z_1,\\cdots,z_n\\)及\\(z=\\infty\\)处的残数之和为零。\n这个定理可以用在，在用残数定理求积分时，如果里面的众多奇点不好算，就可以转化为算无穷远点的残数来代替。\n定理2\n\\[Res[f(z),\\infty] = -Res\\bigg[f\\bigg(\\frac{1}{z}\\bigg)\\cdot\\frac{1}{z^2},0\\bigg] \\]\n利用残数定理计算定积分 \\(\\int^\\infty_{-\\infty}f(x)dx\\)型\n设\\(f\\)在上半平面\\(\\{z: Imz\u003e0\\}\\)中除去\\(a_1,\\cdots,a_n\\)外是全纯的，在\\(\\{z: Imz\\geq0\\}\\)中除去\\(a_1,\\cdots,a_n\\)外是连续的，如果\\(\\lim_{z\\to\\infty}zf(z)=0\\)，那么\n\\[\\int^\\infty_{-\\infty}f(x)dx = 2\\pi i\\sum^n_{k=1}Res(f,a_k) \\]\n推论1\n设\\(P,Q\\)是两个既约多项式，\\(Q\\)没有实的零点，且\\(degQ-degP\\geq2\\)，那么\n\\[int^\\infty_{-\\infty}\\frac{P(x)}{Q(x)}dx = 2\\pi i\\sum^n_{k=1}Res\\bigg(\\frac{P(z)}{Q(z)},a_k\\bigg) \\]\n这里\\(a_k\\)为\\(Q\\)在上半平面中的全部零点，\\(degP,degQ\\)为\\(P,Q\\)的次数。\nJordan引理\n设\\(f\\)在\\(\\{z:R_0\\leq|z|\u003c\\infty,Imz\\geq0\\}\\)上连续，且\\(\\lim_{z\\to\\infty,Imz\\geq0}f(z)=0\\)，则对任意\\(a\u003e0\\)，有\n\\[\\lim_{R\\to\\infty}\\int_{\\gamma_R}e^{iaz}f(z)dz = 0 \\]\n这里\\(\\gamma_R=\\{z:z=Re^{i\\theta},0\\leq\\theta\\leq\\pi,R\\geq R_0\\}\\)\n定理1\n设\\(f\\)在上半平面\\(\\{z: Imz\u003e0\\}\\)中除去\\(a_1,\\cdots,a_n\\)外是全纯的，在\\(\\{z: Imz\\geq0\\}\\)中除去\\(a_1,\\cdots,a_n\\)外是连续的，如果\\(\\lim_{z\\to\\infty}f(z)=0\\)，那么对任意\\(\\alpha\u003e0\\)，有\n\\[\\int^\\infty_{-\\infty}e^{i\\alpha x}f(x)dx = 2\\pi i\\sum^n_{k=1}Res(e^{i\\alpha z}f(z),a_k) \\]\n推论2\n\\[\\int^\\infty_{-\\infty}f(x)\\cos\\alpha xdx = Re\\{ 2\\pi i\\sum^n_{k=1}Res(e^{i\\alpha z}f(z),a_k) \\} \\]\n\\[\\int^\\infty_{-\\infty}f(x)\\sin\\alpha xdx = Im\\{ 2\\pi i\\sum^n_{k=1}Res(e^{i\\alpha z}f(z),a_k) \\} \\]\n引理1\n设\\(f\\)在扇形域\n\\[G = \\{z=a+\\rho e^{i\\theta}:0\u003c\\rho\\leq \\rho_0,\\theta_0\\leq\\theta\\leq\\theta_0+\\alpha\\} \\]\n上连续，如果\\(\\lim_{z\\to a}(z-a)f(z) = A\\)，那么\n\\[\\lim_{\\rho\\to 0}\\int_{\\gamma_\\rho}f(z)dz = iA\\alpha \\]\n这里，\\(\\gamma_\\rho = \\{z=a+\\rho e^{i\\theta}:\\theta_0\\leq\\theta\\leq\\theta_0+\\alpha\\}\\)，它的方向是沿着辐角增加的方向。\n\\(\\int^\\infty_0f(x)dx\\)型\nTODO\n\\(\\int^b_af(x)dx\\)型\n对于一种重要的又穷限积分\n\\[\\int^{2\\pi}_0 R(\\sin\\theta,\\cos\\theta)d\\theta \\]\n一种办法是\n\\[\\int^{2\\pi}_0 R(\\sin\\theta,\\cos\\theta)d\\theta = 2\\int^\\infty_{-\\infty}R\\bigg(\\frac{2t}{1+t^2},\\frac{1-t^2}{1+t^2}\\bigg)\\frac{1}{1+t^2}dt \\]\n另一种办法是\n\\[\\int^{2\\pi}_0 R(\\sin\\theta,\\cos\\theta)d\\theta = \\int_{|z|=1}R\\bigg(\\frac{1}{2i}\\bigg(z-\\frac{1}{z}\\bigg),\\frac{1}{2}\\bigg(z+\\frac{1}{z}\\bigg)\\bigg)\\frac{1}{iz}dz \\]\n对于另一种重要的又穷限积分\n\\[\\int^b_a(x-a)^r(b-x)^sf(x)dx \\]\nTODO\nFresnel积分\n\\[\\int^\\infty_0 \\cos x^2dx = \\int^\\infty_0 \\sin x^2dx = \\frac{1}{2}\\sqrt{\\frac{\\pi}{2}} \\]\nPoisson积分\n\\[\\int^\\infty_0 e^{-ax^2}\\cos bxdx = \\frac{1}{2}\\sqrt{\\frac{\\pi}{a}}exp\\bigg(-\\frac{b^2}{4a}\\bigg) \\]\n共形映射 分式线性变换 见前\n几个初等函数所构成的映射 幂函数 \\(\\omega=z^n(n\\in N,n\\geq2)\\)这个函数在\\(z\\)平面内处处可导，当\\(z\\neq 0\\)时\\(\\omega'\\neq 0\\)，也就是说除了原点外处处共形映射。\n幂函数映射的特点是：把以原点为顶点的角形域映射为以原点为顶点的角形域。但张角变成了原来的\\(n\\)倍。\n指数函数 \\(\\omega=e^z\\)，易知在全平面上都是一个共形映射。\n其特点是：把水平的带形区域\\(0\u003c Im(z)\u003c a(a\\leq 2\\pi)\\)映射成角形域\\(0\u003c arg\\omega\u003c a\\)。\n几个常见的分式线性变换 把单位圆映为单位圆 \\[w = e^{i\\varphi}\\bigg(\\dfrac{z-\\alpha}{1-\\bar{\\alpha}z}\\bigg),|\\alpha|\u003c1,\\varphi\\in R \\]\n把上半平面映为单位圆 \\[w = e^{i\\theta}\\bigg(\\dfrac{z-\\lambda}{z-\\bar{\\lambda}}\\bigg),Im(\\lambda)\u003e0,\\theta\\in R \\]\n","date":"2022-09-01T13:44:54+08:00","permalink":"https://kegalas.top/p/%E5%A4%8D%E5%8F%98%E5%87%BD%E6%95%B0%E6%95%B4%E7%90%86/","title":"复变函数整理"},{"content":"基本概念 随机试验E 针对随机现象的观察、记录、试验（广义）。\n特点：\n可以在相同的条件下重复进行 每次试验的可能结果不止一个，并且能事先明确试验的所有可能结果 但一次试验前不能确定哪个结果会出现 样本空间\\(\\Omega\\) 随机试验\\(E\\)的所有结果构成的集合为\\(E\\)的样本空间\\(\\Omega\\)，记为\\(\\Omega\\{\\omega\\}\\)，每个结果\\(\\omega\\)是\\(\\Omega\\)中的一个元素，称为样本点。\n频率 在相同的条件下，进行了\\(n\\)次试验，其中事件\\(A\\)发生的次数\\(n_A\\)称为事件\\(A\\)发生的频数，比值\\(n_A/n\\)称为事件\\(A\\)发生的频率，记为\\(f_n(A)\\)\n概率 定义1: 事件A发生频率的稳定值\\(p\\)称为它的概率\\(P(A)\\)，即\\(P(A)=p\\)\n定义2: 随机试验\\(E\\)，样本空间\\(\\Omega\\)，对于\\(E\\)的每一事件\\(A\\)赋予一个实数，记为\\(P(A)\\)，如果集合函数满足以下条件，P(A)称为事件A的概率\n非负性: 对于每一个事件\\(A\\)，有\\(P(A)\\geq0\\) 规范性: 对于必然事件\\(\\Omega\\)，有\\(P(\\Omega)=1\\) 可列可加性: 设\\(A_1,A_2,\\cdots\\)是两两不相容的事件，即对于\\(A_iA_j=\\empty,i\\neq j(i,j=1,2,\\cdots)\\) \\[P(\\bigcup^\\infty_{i=1}A_i)=\\sum^\\infty_{i=1}P(A_i) \\]\n性质\n\\(P(\\empty)=0\\) 可列可加性（见上） 若\\(A\\subset B\\)，则\\(P(B-A)=P(B)-P(A)\\) 任意事件\\(A\\)，\\(P(A)\\leq 1\\) 任意事件\\(A\\)，\\(P(\\overline{A})=1-P(A)\\) 加法公式，对任意事件\\(A,B\\)，\\(P(A\\cup B)=P(A)+P(B)-P(AB)\\)，扩展情况同容斥原理。 极限性：设\\(A_1\\subset A_2\\subset\\cdots\\)，则\\(\\lim_{n\\to\\infty}P(A_n)=P(\\bigcup^{\\infty}_{i=1}A_i)\\)；设\\(A_1\\supset A_2\\supset\\cdots\\)，则\\(\\lim_{n\\to\\infty}P(A_n)=P(\\bigcap^{\\infty}_{i=1}A_i)\\) 注意，没有以下性质\n\\(P(A)=0\\)不能推出\\(A=\\empty\\) \\(P(A)=1\\)不能推出\\(A=\\Omega\\) \\(P(A)=P(B)\\)不能推出\\(A=B\\) 古典概率 定义 设一个试验有\\(N\\)个等可能的结果，而事件\\(E\\)恰包含其中的\\(M\\)个结果，则事件\\(E\\)的概率，记为\\(P(E)\\)，定义为\n\\[P(E)=\\frac{M}{N} \\]\n一些有用的公式 n个相异物件取\\(r(1\\leq r\\leq n)\\)个的不同排列总数 \\[P^n_r=n(n-1)(n-2)\\cdots(n-r+1) \\]\nn个相异物体取\\(r(1\\leq r\\leq n)\\)个的不同组合总数 \\[C^n_r = \\frac{P^n_r}{r!}=\\frac{n!}{r!(n-r)!}=\\frac{n(n-1)(n-2)\\cdots(n-r+1)}{r!}=\\binom{n}{r} \\]\n另外，只要\\(r\\)为非负整数，不论\\(n\\)为任何实数，都有意义。例如\n\\[\\binom{-1}{r} = \\frac{(-1)(-2)\\cdots(-r)}{r!}=(-1)^r \\]\n二项式系数 \\[(a+b)^n=\\sum_{i=0}^n\\binom{n}{i}a^ib^{n-i} \\]\n令\\(a=b=1\\)\n\\[\\binom{n}{0}+\\binom{n}{1}+\\cdots+\\binom{n}{n}=2^n \\]\n令\\(a=-1,b=1\\)\n\\[\\binom{n}{0}-\\binom{n}{1}+\\binom{n}{2}+\\cdots+(-1)^n\\binom{n}{n}=0 \\]\n还有\n\\[\\binom{m+n}{k}=\\sum_{i=0}^k\\binom{m}{i}\\binom{n}{k-i} \\]\n\\(n\\)个相异物件分成\\(k\\)堆，各堆物件数分别为\\(r_1,\\cdots,r_k\\)的分法是 \\[\\frac{n!}{r_1!\\cdots r_n!} \\]\n以上是有序堆的情况，无序堆时\n\\[\\frac{n!}{P^k_k(r_1!\\cdots r_n!)} \\]\n几何概率 古典概率的样本空间为有限集，如果样本空间是无限集，就应该使用几何概率。\n直线上的几何概率：设线段\\(l\\)是\\(L\\)的一部分，向\\(L\\)上随机投一点，投中\\(l\\)的概率为 \\[P=\\frac{l的长度}{L的长度} \\]\n平面、体积上的概率：类似于直线上，通过总体的面积或体积，以及事件所代表的面积或体积来计算。 事件的运算 蕴含、包含和相等 在同一试验下的两个事件\\(A,B\\)，若\\(A\\)发生时\\(B\\)必发生，则称\\(A\\)蕴含\\(B\\)，或者说\\(B\\)包含\\(A\\)，记为\\(A\\subset B\\)，若它们互相蕴含，则称为相等，记为\\(A=B\\)\n互斥和对立 若\\(A,B\\)不能在同一次试验中都发生（但可以都不发生），则称他们是互斥的（不相容的）。\n对立事件是互斥事件的一种特殊情况。若\\(A\\)为一事件，则事件\n\\[B=\\{A不发生\\} \\]\n称为\\(A\\)的对立事件，记为\\(\\bar{A}\\)\n事件的和 \\[C=\\{A发生，或B发生\\}=\\{A，B至少发生一个\\}=A+B=A\\cup B \\]\n概率的加法定理 若干个互斥事件之和的概率，等于各事件的概率之和\n\\[P(A_1+A_2+\\cdots)=P(A_1)+P(A_2)+\\cdots \\]\n若不是两两互斥的事件，则要考虑用容斥原理来计算。\n上式能推出\n\\[P(\\bar A)=1-P(A) \\]\n事件的积 \\[C=\\{A,B都发生\\}=AB=A\\cap B \\]\n事件的差 \\[C=\\{A发生，B不发生\\}=A-B \\]\n显然有\n\\[A-B = A\\bar B \\]\n两个重要公式 \\[\\overline{A_1A_2\\cdots A_n}=\\sum_{i=1}^n\\bar{A_i} \\]\n\\[\\overline{A_1+A_2+\\cdots+A_n}=\\prod_{i=1}^n\\bar{A_i} \\]\n条件概率 设有两个事件\\(A,B\\)，而\\(P(B)\\neq0\\)。则“在给定\\(B\\)发生的条件下\\(A\\)的条件概率”，记为\\(P(A|B)\\)，定义为\n\\[P(A|B)=P(AB)/P(B) \\]\n但并不一定要用这个公式去计算，有时直接用加入了条件的情况去算会更为方便。\n事件的独立性、概率乘法定理 若\\(P(A)=P(A|B)\\)，则\\(B\\)的发生与否对\\(A\\)发生的可能性毫无影响。这时，在概率论上称\\(A,B\\)两事件独立。\n同时就有\n\\[P(AB) = P(A)P(B) \\]\n若两事件\\(A,B\\)满足上式，则称\\(A,B\\)独立。反过来说独立的两个事件就有上式，也称为概率的乘法定理。\n将其推广，设\\(A_1,A_2,\\cdots\\)为有限或无限个事件。如果从其中任意取出有限个\\(A_{i_1},A_{i_2},\\cdots,A_{i_m}\\)，都有\n\\[P(A_{i_1}A_{i_2}\\cdots A_{i_m})=P(A_{i_1})P(A_{i_2})\\cdots P(A_{i_m}) \\]\n则称\\(A_1,A_2,\\cdots\\)互相独立。互相独立的几个事件则具有以上的乘积性质。\n等价的来说也有\n\\[P(A_{i_1}|A_{i_2}\\cdots A_{i_m})=P(A_{i_1}) \\]\n可以推出：独立事件的任一部分也独立。\n还有：若一列事件相互独立，则将其中任一部分改为对立事件时，所有事件仍然相互独立。\n全概率公式 设\\(B_1,B_2,\\cdots\\)为有限或无限个事件，它们两两互斥且在每次试验中至少发生一个。即\n\\[B_iB_j=\\empty(i\\neq j) \\]\n\\[B_1+B_2+\\cdots = \\Omega（必然事件） \\]\n有时，这样的一组事件称为完备事件群。\n现有任一事件\\(A\\)，有\\(A=A\\Omega=AB_1+AB_2+\\cdots\\)。而\\(B_1,B_2,\\cdots\\)两两互斥，则\\(AB_1,AB_2,\\cdots\\)也两两互斥，固有\n\\[P(A) = P(AB_1)+P(AB_2)+\\cdots \\]\n再由条件概率\\(P(AB_i)=P(B_i)P(A|B_i)\\)，得\n\\[P(A) = P(B_1)P(A|B_1) + P(B_2)P(A|B_2) + \\cdots \\]\n上式称为全概率公式。\n贝叶斯公式 由全概率公式，有\n\\[P(B_i|A)=P(AB_i)/P(A)\\\\=P(B_i)P(A|B_i)/\\sum_jP(B_j)P(A|B_j) \\]\n随机变量及其分布 随机变量的概念 随机变量就是其值随机会而定的变量。例如从一大批产品中随机抽出100个，其中所含的废品数为\\(X\\)。这个\\(X\\)就是一个随机变量。\n随机变量区分为两大类\n离散型随机变量。其特征是只能取有限个值，或者虽然能取无限个，但可以一个一个地排列出来（类似于可数无限）。 连续性随机变量。不仅是无穷多的，而且类似于不可数无限，充满一个区间。 离散型随机变量 定义1\n设\\(X\\)为离散型随机变量，其全部可能值为\\(\\{a_1,a_2,\\cdots\\}\\)，则\n\\[p_i=P(X=a_i)\\quad(i=1,2,\\cdots) \\]\n称为\\(X\\)的概率函数\n显然有\n\\[p_i\\geq 0,\\quad p_1+p_2+\\cdots = 1 \\]\n定义2\n设\\(X\\)为一随机变量，则函数\n\\[P(X\\leq x) = F(x)\\quad(-\\infty\u003c x\u003c\\infty) \\]\n称为\\(X\\)的分布函数。这里不限制\\(X\\)是离散型的。\n\\[F(x) = P(X\\leq x) = \\sum_{\\{i|a_i\\leq x\\}}p_i \\]\n分布函数具有如下性质\n\\(F(x)\\)是单调非降的：\\(x_1\\leq x_2\\)时，有\\(F(x_1)\\leq F(x_2)\\) \\(x\\to \\infty\\)时，\\(F(x)\\to 1\\)。\\(x\\to -\\infty\\)时，\\(F(x)\\to 0\\) 连续型随机变量 与离散型的有限或可数无限不同，这是一种充满整个区间的随机变量，或者说不可数无限。\n刻画连续型随机变量可以用之前提到的概率分布函数，但是更常用概率密度函数。\n概率密度函数 设连续型随机变量\\(X\\)有概率分布函数\\(F(x)\\)，则\\(F(x)\\)的导数\\(f(x)=F'(x)\\)称为\\(X\\)的概率密度函数。\n具有如下性质\n\\(f(x)\\geq 0\\) \\(\\int^\\infty_{-\\infty}f(x)dx=1\\) 对于任何常数\\(a\u003c b\\)，有 \\[P(a\\leq X\\leq b)=F(b)-F(a) = \\int^b_af(x)dx \\]\n多维随机变量（随机向量） 离散型随机向量的分布 一般的，设\\(X=(X_1,X_2,\\cdots,X_n)\\)为一个\\(n\\)维向量，其每个分量，即\\(X_1,\\cdots,X_n\\)都是一维随机变量，则称\\(X\\)是一个\\(n\\)维随机向量或\\(n\\)维随机变量。\n如果一个随机向量\\(X\\)，其每一个分量\\(X_i\\)都是一维离散型随机变量，则称\\(X\\)是离散型的。\n以\\(\\{a_{i1},a_{i2},\\cdots\\}\\)记\\(X_i\\)的全部可能值，则事件\\(\\{X_1=a_{1j_1}, X_2=a_{2j_2},\\cdots,X_n=a_{nj_n}\\}\\)的概率\n\\[p(j_1,j_2,\\cdots,j_n)=P(X_1=a_{1j_1}, X_2=a_{2j_2},\\cdots,X_n=a_{nj_n}) \\]\n称为随机向量\\(X\\)的概率函数或概率分布，其应该满足\n\\[p(j_1,j_2,\\cdots,j_n)\\geq 0,\\sum_{j_n}\\cdots\\sum_{j_2}\\sum_{j_1}p(j_1,j_2,\\cdots,j_n) = 1 \\]\n连续型随机向量的分布 设\\(X\\)是一个\\(n\\)维随机向量，其取值可视为\\(n\\)维欧式空间\\(\\mathbb{R} ^n\\)中的一个点。如果\\(X\\)的全部取值能充满\\(\\mathbb{R} ^n\\)中某一区域，则称它是连续型的。\n若\\(f(x_1,\\cdots,x_n)\\)是定义在\\(\\mathbb{R} ^n\\)上的非负函数，使对\\(\\mathbb{R} ^n\\)中的任何集合\\(A\\)，有\n\\[P(X\\in A) = \\int\\cdots\\int f(x_1,\\cdots,x_n)dx_1\\cdots dx_n \\]\n则称\\(f\\)是\\(X\\)的概率密度函数\n如果把\\(A\\)取成\\(\\mathbb{R} ^n\\)，则有\n\\[\\int^\\infty_{-\\infty}\\cdots\\int^\\infty_{-\\infty} f(x_1,\\cdots,x_n)dx_1\\cdots dx_n = 1 \\]\n对于二维情况\n\\[F(x,y) = \\int^y_{-\\infty}\\int^x_{-\\infty}f(u,v)dudv \\]\n\\[\\frac{\\partial^2 F(x,y)}{\\partial x\\partial y}=f(x,y) \\]\n在\\(\\Delta x,\\Delta y\\)很小时，有\\(P(x\u003c X\u003c x+\\Delta x,y\u003c Y\u003c y+\\Delta y)\\approx f(x,y)\\Delta x\\Delta y\\)\n若\\(G\\)为\\(xOy\\)内的任意区域，点\\((x,y)\\)落在\\(G\\)内的概率为\n\\[P\\{(X,Y)\\in G\\}=\\iint_G f(x,y)dxdy \\]\n与一维的情况一样，也可以用概率分布函数去描述多维随机向量的概率分布，其定义为\n\\[F(x_1,x_2,\\cdots,x_n)=P(X_1\\leq x_1, X_2\\leq x_2,\\cdots,X_n\\leq x_n) \\]\n其基本性质，以二维为例，有\n\\(F(x,y)\\)是\\(x,y\\)的不减函数 \\(0\\leq F(x,y)\\leq 1,F(-\\infty,-\\infty) = 0,F(\\infty,\\infty)=1\\) 对于任意\\(x\\)，\\(F(x,-\\infty)=0\\)，对于任意\\(y\\)，\\(F(-\\infty,y)=0\\)\n\\(F(x,y)\\)关于\\(x,y\\)均为右连续，\\(F(x+0,y) = F(x,y)\\)，\\(F(x,y+0) = F(x,y)\\) 若\\(x_1\u003c x_2,y_1\u003c y_2\\)，则\\(F(x_2,y_2)+F(x_1,y_1)-F(x_2,y_1)-F(x_1,y_2)\\geq 0\\) 另外，有\n\\[f(x,y) = \\frac{\\partial^2F(x,y)}{\\partial x\\partial y} \\]\n边缘分布 设\\(X=(X_1,\\cdots,X_n)\\)为一个\\(n\\)维随机向量。\\(X\\)有一定的分布\\(F\\)，这是一个\\(n\\)维分布，因为\\(X\\)的每个分量\\(X_i\\)都是一维随机变量，故它们都有各自的分布\\(F_i\\)，这些都是一维分布，称为随机向量\\(X\\)或其分布\\(F\\)的边缘分布。边缘分布完全由原分布\\(F\\)确定。\n例如，在离散型的情况下，边缘分布\\(P(X_1=a_{1k})\\)就等于\n\\[P(X_1=a_{1k})=\\sum_{j_2,\\cdots,j_n}p(k,j_2,\\cdots,j_n) \\]\n对于连续型的情况，例如求\\(f_1(x_1)\\)\n\\[f_1(x_1) = \\int^\\infty_{-\\infty}\\cdots \\int^\\infty_{-\\infty}f(x_1,x_2,\\cdots,x_n)dx_2\\cdots dx_n \\]\n当然，如果题目有要求变量的范围，则积分上下限要改成相应的值。\n直观上的理解，就是将其他变量的所有情况的概率全部加起来。\n联合分布 边缘分布指的是随机向量中的一个分量的分布。\n而相对应的联合分布，就是强调\\((X_1,\\cdots,X_n)\\)的分布是把\\(X_1,\\cdots,X_n\\)作为一个有联系的整体来考虑的。\n当然有些时候边缘分布也可以指众多分量中几个分量的分布。\n条件概率分布 概念同前面提到的条件概率。\n离散型 同之前计算条件概率相同，只不过通常此时要用到边缘分布等概念。\n例如设\n\\[p_{ij}=P(X_1=a_i,X_2=b_j) \\]\n则\n\\[P(X_1=a_i|X_2=b_j) = P(X_1=a_i,X_2=b_j)/P(X_2=b_j) = p_{ij}/P(X_2=b_j) \\]\n连续型 以二维情况为例\n\\[P(X_1\\leq x_1|a\\leq X_2\\leq b)=P(X_1\\leq x_1,a\\leq X_2\\leq b)/P(a\\leq X_2\\leq b) \\]\n写成积分形式\n\\[=\\int^{x_1}_{-\\infty}dt_1\\int^b_af(t_1,t_2)dt_2\\bigg/\\int^b_af_2(t_2)dt_2 \\]\n\\(a=b\\)的情况下，可以通过极限求出\n\\[f_1(x_1|x_2) = f(x_1,x_2)/f_2(x_2) \\]\n可改写为\n\\[f(x_1,x_2) = f_1(x_1|x_2)f_2(x_2) \\]\n可以推广到\n\\[f(x_1,\\cdots,x_n) = g(x_1,\\cdots,x_k)h(x_{k+1},\\cdots,x_n|x_1,\\cdots,x_k) \\]\n随机变量的独立性 定义1\n设\\(n\\)维随机向量\\((X_1,\\cdots,X_n)\\)的联合密度函数为\\(f(x_1,x_2,\\cdots,x_n)\\)，而\\(X_i\\)的边缘密度函数为\\(f_i(x_i)\\)，如果\n\\[f(x_1,\\cdots,x_n) = f_1(x_1)\\cdots f_n(x_n) \\]\n则称随机变量\\(X_1,\\cdots,X_n\\)相互独立。\n定理1\n如果连续变量\\(X_1,\\cdots,X_n\\)相互独立，则对任何\\(a_i\u003c b_i\\)，则由下式定义的\\(n\\)个事件也独立\n\\[A_1=\\{a_1\\leq X_1\\leq b_1\\},\\cdots,A_n=\\{a_n\\leq X_n\\leq b_n\\} \\]\n反之，若对任何\\(a_i\u003c b_i\\)，事件\\(A_1,\\cdots,A_n\\)独立，则变量\\(X_1,\\cdots,X_n\\)独立。\n定理2\n若随机向量\\((X_1,\\cdots,X_n)\\)的概率密度函数\\(f(x_1,x_2,\\cdots,x_n)\\)可表示为\\(n\\)个函数\\(g_1,\\cdots,g_n\\)之积，其中\\(g_i\\)只依赖于\\(x_i\\)，即\n\\[f(x_1,x_2,\\cdots,x_n) = g_1(x_1)\\cdots g_n(x_n) \\]\n则\\(X_1,\\cdots,X_n\\)相互独立，且\\(X_i\\)的边缘密度函数\\(f_i(x_i)\\)与\\(g_i(x_i)\\)只相差一个常数因子。\n定理3\n若\\(X_1,\\cdots,X_n\\)相互独立，而\n\\[Y_1=g_1(X_1,\\cdots,X_m), Y_2 = g_2(X_{m+1},\\cdots,X_n) \\]\n则\\(Y_1,Y_2\\)独立。\n定义2\n设\\(X_1,\\cdots,X_n\\)是离散型随机变量，若对任何常数\\(a_1,\\cdots,a_n\\)都有\n\\[P(X_1=a_1,\\cdots,X_n=a_n) = P(X_1=a_1)\\cdots P(X_n=a_n) \\]\n则称\\(X_1,\\cdots, X_n\\)相互独立。\n随机变量的函数的概率分布 在理论和应用上，经常碰到这种情况：已知某个或某些随机变量\\(X_1,\\cdots,X_n\\)的分布，现另有一些随机变量\\(Y_1,\\cdots,Y_m\\)，它们都是\\(X_1,\\cdots,X_n\\)的函数：\n\\[Y_i=g_i(X_1,\\cdots,X_n) \\]\n要求\\((Y_1,\\cdots,Y_m)\\)的概率分布。\n离散型分布的情况 离散分布的情况比较简单，只需要列举\\(Y_i=y_i\\)时的所有\\(X\\)的可能就可以了。\n连续型分布的情况的一般讨论 先考虑一个变量的情况，设\\(X\\)有密度函数\\(f(x)\\). 设\\(Y=g(x)\\)。\\(g\\)严格上升或下降。所以\\(g'\\)存在，反函数\\(X=g^{-1}(Y)\\)存在，且\\((g^{-1})'\\)也存在。\n则\\(Y\\)的密度函数为\n\\[f_Y(y)=f(g^{-1}(y))|(g^{-1}(y))'| \\]\n现在考虑多个变量，以两个变量为例，设\\((X_1,X_2)\\)的密度函数为\\(f(x_1,x_2)\\)，以及\n\\[Y_1=g_1(X_1,X_2),\\quad Y_2=g_2(X_1,X_2) \\]\n要求\\(f_Y(y_1,y_2)\\)，假定上式是一一对应变换，则有逆变换\n\\[X_1=g^{-1}_1(Y_1,Y_2),\\quad X_2=g^{-1}_2(Y_1,Y_2) \\]\n假设\\(g_1,g_2\\)都有一阶连续偏导数，则其反函数也有一阶连续偏导数，且雅克比行列式\n\\[J(y_1,y_2)= \\begin{vmatrix} \\partial g^{-1}_1/\\partial y_1 \u0026 \\partial g^{-1}_1/\\partial y_2\\\\ \\partial g^{-1}_2/\\partial y_1 \u0026 \\partial g^{-1}_2/\\partial y_2 \\end{vmatrix} \\]\n不为\\(0\\). 有\n\\[f_Y(y_1,y_2) = f(g^{-1}_1(y_1,y_2),g^{-1}_2(y_1,y_2))|J(y_1,y_2)| \\]\n随机变量和的密度函数 设\\((X_1,X_2)\\)的联合密度函数为\\(f(x_1,x_2)\\)，要求\n\\[Y=X_1+X_2 \\]\n的密度函数。\n有\n\\[f_Y(y) = \\int^\\infty_{-\\infty}f(x_1,y-x_1)dx_1=\\int^\\infty_{-\\infty}f(x,y-x)dx \\]\n或者作变量代换也有\n\\[f_Y(y) = \\int^\\infty_{-\\infty}f(y-x,x)dx \\]\n如果\\(X_1,X_2\\)独立，则\\(f(x_1,x_2)=f_1(x_1)f_2(x_2)\\)，有\n\\[f_Y(y) = \\int^\\infty_{-\\infty}f_1(x)f_2(y-x)dx = \\int^\\infty_{-\\infty}f_1(y-x)f_2(x)dx \\]\n随机变量商的密度函数 设\\((X_1,X_2)\\)有密度函数\\(f(x_1,x_2)\\)，\\(Y=X_2/X_1\\)，要求\\(Y\\)的密度函数\n\\[f_Y(y) = \\int^\\infty_0 |x_1|f(x_1,x_1y)dx_1 \\]\n若\\(X_1,X_2\\)独立，则\n\\[f_Y(y) = \\int^\\infty_0 |x_1|f_1(x_1)f_2(x_1y)dx_1 \\]\n随机变量积的密度函数 设\\((X_1,X_2)\\)有密度函数\\(f(x_1,x_2)\\)，\\(Y=X_1X_2\\)，要求\\(Y\\)的密度函数\n\\[f_Y(y) = \\int^\\infty_0 \\frac{1}{|x_1|}f(x_1,\\frac{y}{x_1})dx_1 \\]\n若\\(X_1,X_2\\)独立，则\n\\[f_Y(y) = \\int^\\infty_0 \\frac{1}{|x_1|}f_1(x_1)f_2(\\frac{y}{x_1})dx_1 \\]\n常见的分布 0-1分布 设某个事件\\(A\\)在一次试验中发生的概率为\\(p\\)，重复试验\\(1\\)次，以\\(X\\)记\\(A\\)在\\(1\\)次试验中发生的次数，则\n\\[P(X=i)=p^i(1-p)^{1-i}\\quad (i=0,1) \\]\n数学期望 \\[p \\]\n方差 \\[p(1-p) \\]\n二项分布 设某个事件\\(A\\)在一次试验中发生的概率为\\(p\\)，重复试验\\(n\\)次，以\\(X\\)记\\(A\\)在\\(n\\)次试验中发生的次数，则\n\\[p_i=b(i;n,p)=\\binom{n}{i}p^i(1-p)^{n-i}\\quad (n=0,1,\\cdots,n) \\]\n服从有两个条件\n各次试验的条件是稳定的 各次试验的独立性 如果抽检后放回，则每次抽出废品的概率是相等的。如果抽检后不放回，则废品率发生了变化，试验条件不稳定，不符合二项分布。但是如果总数远大于抽出的数量，则不放回也几乎不影响，可以近似地作为二项分布。\n通常也会记作，\\(B(n,p)\\)\n数学期望 \\[np \\]\n方差 \\[np(1-p) \\]\n泊松分布 若随机变量\\(X\\)的可能取值为\\(0,1,2,\\cdots\\)，且概率分布为\n\\[P(X=i)=e^{-\\lambda}\\lambda^i/i! \\]\n则称\\(X\\)服从泊松分布。记为\\(X\\sim P(\\lambda)\\)。\\(\\lambda\u003e0\\)是某一常数。式子右边对\\(i=0,1,\\cdots\\)求和的结果为\\(1\\)。可以从\\(e^\\lambda=\\sum^\\infty_{i=0}\\lambda^i/i!\\)得出。\n这个分布多出现在当\\(X\\)表示在一定时间或空间内出现的事件个数的场合。比如一定时间内某交通路口所发生的事故个数。\n泊松分布可以看做二项分布的极限。若\\(X\\sim B(n,p)\\)中\\(n\\)很大，\\(p\\)很小，而\\(np=\\lambda\\)不太大时，\\(X\\)的分布接近与泊松分布\\(P(\\lambda)\\)。推导如下：\n\\[P(X=i)=\\binom{n}{i}\\left(\\frac{\\lambda}{n}\\right)^i\\left(1-\\frac{\\lambda}{n}\\right)^{n-i} \\]\n当\\(n\\to\\infty\\)时\n\\[\\binom{n}{i}/n^i\\to 1/i!,\\quad \\left(1-\\frac{\\lambda}{n}\\right)^{n-i}\\to e^{-\\lambda} \\]\n则有\n\\[P(X=i)=e^{-\\lambda}\\lambda^i/i! \\]\n显然通常我们不会遇到\\(n\\)无限的情况，只会遇到\\(n\\)较大的情况，所以只能说接近泊松分布。\n数学期望 \\[\\lambda \\]\n我们可以证明\\(X\\)服从泊松分布时\n\\[E(X) = \\sum^\\infty_{i=0}i\\frac{\\lambda^i}{i!}e^{-\\lambda}=\\lambda \\]\n方差 \\[\\lambda \\]\n超几何分布 以\\(X\\)记从含\\(M\\)个废品的\\(N\\)个产品中随机抽出\\(n\\)个里面所含有的废品数，\\(X\\)的分布为\n\\[P(X=m)=\\binom{M}{m}\\binom{N-M}{n-m}\\bigg/\\binom{N}{n} \\]\n这是一种抽检不放回的试验，如果\\(N\\)特别大，\\(n\\)不够大时，放回与不放回差别不大。可以当作二项分布来看。或者说，若\\(X\\)服从超几何分布，则当\\(n\\)固定时，\\(M/N=p\\)固定；\\(N\\to \\infty\\)时，\\(X\\)近似服从二项分布\\(B(n,p)\\)。\n数学期望 \\[\\frac{nM}{N} \\]\n方差 \\[\\frac{nM(N-M)(N-n)}{N^2(N-1)} \\]\n负二项分布 先指定一个自然数\\(r\\)，一个一个地从一批产品中抽样检查，直到发现第\\(r\\)个废品，以\\(X\\)记此时已经抽出的合格产品个数。\n显然\\(\\{X=i\\}\\)这个事件发生时，需要满足\n在前\\(i+r-1\\)次抽取中，正好有\\(r-1\\)个废品 第\\(i+r\\)次抽出废品 所以有\n\\[P(X=i) = b(r-1;i+r-1,p)p \\]\n\\[=\\binom{i+r-1}{r-1}p^r(1-p)^i \\]\n负二项分布的名称来源于\n\\[(1-x)^{-r}=\\sum_{i=0}^{\\infty}\\binom{-r}{i}(-x)^i=\\sum_{i=0}^{\\infty}\\binom{i+r-1}{i}x^i \\]\n\\[=\\sum_{i=0}^{\\infty}\\binom{i+r-1}{r-1}x^i \\]\n其中令\\(x=1-p\\)，两边乘以\\(p^r\\)，得\n\\[1 = p^r[1-(1-p)]^{-r}=\\sum_{i=0}^{\\infty}\\binom{i+r-1}{r-1}p^r(1-p)^i \\]\n几何分布 当负二项分布中的\\(r=1\\)时，有\n\\[P(X=i) = p(1-p)^i \\]\n数学期望 \\[\\frac{1}{p} \\]\n方差 \\[\\frac{1-p}{p^2} \\]\n多项分布 设\\(A_1,A_2,\\cdots,A_n\\)是某一试验之下的完备事件群，即事件\\(A_1,\\cdots,A_n\\)两两互斥，其和为必然事件。分别以\\(p_1,p_2,\\cdots,p_n\\)记每个事件对应的概率。\n现将试验独立重复\\(N\\)次，而以\\(X_i\\)记载着\\(N\\)次试验中事件\\(A_i\\)出现的次数。\\(X\\)的概率分布就叫做多项分布，有时记为\\(M(N;p_1,\\cdots,p_n)\\)。其概率有\n\\[P(X_1=k_1,X_2=k_2,\\cdots,X_n=k_n)=\\frac{N!}{k_1!k_2!\\cdots k_n!}p_1^{k_1}p_2^{k_2}\\cdots p_n^{k_n} \\]\n正态分布 如果一个随机变量具有概率密度函数\n\\[f(x)=(\\sqrt{2\\pi}\\sigma)^{-1}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\quad (-\\infty \u003c x \u003c + \\infty ) \\]\n则称\\(X\\)为正态随机变量，并记为\\(X\\sim N(\\mu,\\sigma^2)\\)。\\(\\mu,\\sigma^2\\)是常数，\\(\\mu\\in R,0\u003c\\sigma^2\u003c\\infty\\)，它们称为这个分布的参数。由后续的方差一节，\\(Var(X)=\\sigma^2\\)，就是分布的方差。\n正态分布的概率密度函数的图像关于\\(x=\\mu\\)对称，中间高两边低。\n当\\(\\mu=0,\\sigma^2=1\\)时，称为标准正态分布\\(N(0,1)\\)\n\\[f(x)=e^{-x^2/2}/\\sqrt{2\\pi} \\]\n通常\\(N(0,1)\\)的密度函数和分布函数也会记为\\(\\varphi(x)\\)和\\(\\varPhi(x)\\)。\n任意一个正态分布都可以转化为标准正态分布，便于查表。\n\\[if\\quad X\\sim N(\\mu,\\sigma^2),then\\quad Y=(X-\\mu)/\\sigma\\sim N(0,1) \\]\n例如\\(X\\sim N(1.5,2^2)\\)，要计算\\(P(-1\\leq X\\leq 2)\\)，则因\\((X-1.5)/2\\sim N(0,1)\\)，有\n\\[P(-1\\leq X\\leq 2) = P\\left(\\frac{-1-1.5}{2}\\leq\\frac{X-1.5}{2}\\leq\\frac{2-1.5}{2}\\right) \\]\n\\[=P(-1.25\\leq(X-1.5)/2\\leq 0.25) \\]\n\\[=\\varPhi(0.25)-\\varPhi(-1.25) \\]\n可以查表代入。但是通常只有非负数的值，对于负数\\(x\\)，有\n\\[\\varPhi(x) = 1-\\varPhi(-x) \\]\n正态分布的线性组合性质 对于正态分布，设\\(X_1,X_2\\)分别服从正态分布\\(N(\\mu_1,\\sigma_1^2),N(\\mu_2,\\sigma_2^2)\\)，对于\\(Y=X_1+X_2\\)\n\\(X_1,X_2\\)独立，则\\(Y\\sim N(\\mu_1+\\mu_2, \\sigma_1^2+\\sigma_2^2)\\)。并且反过来说\\(Y\\)符合正态分布，而\\(Y\\)可以表示为两个独立变量的和\\(Y=X_1+X_2\\)，则\\(X_1,X_2\\)必须服从正态分布。 \\(X_1,X_2\\)不独立，但其联合分布为二维正态分布\\(N(\\mu_1,\\mu_2, \\sigma_1^2,\\sigma_2^2,\\rho)\\)，则\\(Y\\)仍然服从正态分布\\(Y\\sim N(\\mu_1+\\mu_2, \\sigma_1^2+\\sigma_2^2+2\\rho\\sigma_1\\sigma_2)\\) 同样可以推广到多维情况，\\(X_1,\\cdots,X_n\\)相互独立，分别服从\\(N(\\mu_1,\\sigma_1^2),\\cdots,N(\\mu_n,\\sigma_n^2)\\)，则\\(X_1+\\cdots+X_n\\)服从\\(N(\\mu_1+\\cdots+\\mu_n,\\sigma_1^2+\\cdots+\\sigma_n^2)\\)\n对于不全为\\(0\\)的常数\\(C_0,C_1,\\cdots,C_n\\)，线性组合\n\\[C_0+C_1X_1+\\cdots+C_nX_n\\sim N(C_0+C_1\\mu_1+\\cdots+C_n\\mu_n,C_1^2\\sigma_1^2+\\cdots+C_n^2\\sigma_n^2) \\]\n数学期望 \\[\\mu \\]\n方差 \\[\\sigma^2 \\]\n上\\(\\alpha\\)分位点 标准正态分布的上\\(\\alpha\\)分位点查表可知，具有一个性质为\\(w_{1-\\alpha}=-w_\\alpha\\)。对于非标准的则和中位数对称。\n二维正态分布 \\[f(x_1,x_2)=(2\\pi\\sigma_1\\sigma_2\\sqrt{1-\\rho^2})^{-1}\\exp\\left[-\\frac{1}{2(1-\\rho^2)}\\left(\\frac{(x_1-a)^2}{\\sigma_1^2}-\\frac{2\\rho(x_1-a)(x_2-b)}{\\sigma_1\\sigma_2}+\\frac{(x_2-b)^2}{\\sigma_2^2}\\right)\\right] \\]\n常把这个分布记为\\(N(a,b,\\sigma_1^2,\\sigma_2^2,\\rho)\\)\nn维正态随机变量 定义1\n设\\((X_1,X_2)\\)的四个二阶中心矩都存在，把\n\\[\\begin{bmatrix} Cov(X_1) \u0026 Corr(X_1,X_2) \\\\ Corr(X_2,X_1) \u0026 Cov(X_2) \\end{bmatrix} \\]\n称为随机变量\\((X_1,X_2)\\)的协方差矩阵。\n扩展到\\(n\\)维就是\n\\[\\begin{bmatrix} Cov(X_1) \u0026 Corr(X_1,X_2) \u0026 \\cdots \u0026 Corr(X_1,X_n)\\\\ Corr(X_2,X_1) \u0026 Cov(X_2) \u0026 \\cdots \u0026 Corr(X_2,X_n)\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ Corr(X_n,X_1) \u0026 Corr(X_n,X_2) \u0026 \\cdots \u0026 Cov(X_n) \\end{bmatrix} \\]\n当然所有的协方差必须存在。\n对于二维正态分布\n\\[f(x_1,x_2)=\\\\ (2\\pi\\sigma_1\\sigma_2\\sqrt{1-\\rho^2})^{-1}\\exp\\left[-\\frac{1}{2(1-\\rho^2)}\\left(\\frac{(x_1-\\mu_1)^2}{\\sigma_1^2}-\\frac{2\\rho(x_1-\\mu_1)(x_2-\\mu_2)}{\\sigma_1\\sigma_2}+ \\frac{(x_2-\\mu_2)^2}{\\sigma_2^2}\\right)\\right] \\]\n其中\\(\\rho\\)是\\(X,Y\\)的相关系数\n所以\\((X_1,X_2)\\)的协方差矩阵是\n\\[B = \\begin{bmatrix} \\sigma_1^2 \u0026 \\rho\\sigma_1\\sigma_2 \\\\ \\rho\\sigma_1\\sigma_2 \u0026 \\sigma_2^2 \\end{bmatrix} \\]\n定义\n\\[X=\\begin{bmatrix} X_1 \\\\ X_2 \\end{bmatrix}, \\mu = \\begin{bmatrix} \\mu_1 \\\\ \\mu_2 \\end{bmatrix} \\]\n则\\(f(x_1,x_2)\\)也可以写为\n\\[f(x_1,x_2)=(2\\pi|B|^{1/2})exp\\bigg[-\\frac{1}{2}(X-\\mu)^TB^{-1}(X-\\mu)\\bigg] \\]\n扩展到\\(n\\)维，则有\n\\[f(x_1,x_2,\\cdots,x_n)=[(2\\pi)^{n/2}|B|^{1/2}]exp\\bigg[-\\frac{1}{2}(X-\\mu)^TB^{-1}(X-\\mu)\\bigg] \\]\nn维正态变量的性质\n\\(n\\)维正态随机变量\\((X_1,X_2,\\cdots,X_n)\\)的每一个分量\\(X_i\\)都是正态随机变量；反之若\\(X_1,X_2,\\cdots,X_n\\)都是正态随机变量且相互独立，则\\((X_1,X_2,\\cdots,X_n)\\)是\\(n\\)维正态随机变量 \\((X_1,X_2,\\cdots,X_n)\\)是\\(n\\)维正态随机变量的充要条件是\\(X_1,X_2,\\cdots,X_n\\)的任意线性组合\\(l_1X_1,l_2X_2,\\cdots,l_nX_n\\)服从一维正态分布（其中\\(l_1,l_2,\\cdots,l_n\\)不全为\\(0\\)） 若\\((X_1,X_2,\\cdots,X_n)\\)服从\\(n\\)维正态分布，设\\(Y_1,Y_2,\\cdots,Y_k\\)是\\(X_i\\)的线性变换，则\\((Y_1,Y_2,\\cdots,Y_k)\\)也服从\\(k\\)维正态分布 若\\((X_1,X_2,\\cdots,X_n)\\)是\\(n\\)维正态随机变量，\\(m \u003c n\\)，则\\((X_1,X_2,\\cdots,X_n)\\)的任意\\(m\\)个分量是\\(m\\)维正态随机变量 设\\((X_1,X_2,\\cdots,X_n)\\)是\\(n\\)维正态随机变量，则“\\(X_1,X_2,\\cdots,X_n\\)相互独立”与“\\(X_1,X_2,\\cdots,X_n\\)两两不相关”等价。 指数分布 若随机变量\\(X\\)有概率密度函数\n\\[f(x)=\\left\\{\\begin{matrix} \\lambda e^{-\\lambda x},\\quad x\u003e0\\\\ 0,\\quad x\\leq 0 \\end{matrix}\\right. \\]\n则\\(X\\)服从指数分布，其中\\(\\lambda\u003e0\\)是参数。通常记作\\(E(\\lambda)\\)\n其概率分布函数为\n\\[F(x)=\\left\\{\\begin{matrix} 1-e^{-\\lambda x},\\quad x\u003e0\\\\ 0,\\quad x\\leq 0 \\end{matrix}\\right. \\]\n数学期望 \\[\\frac{1}{\\lambda} \\]\n方差 \\[\\frac{1}{\\lambda^2} \\]\n威布尔分布 满足\n\\[f(x)=\\left\\{\\begin{matrix} \\lambda\\alpha x^{\\alpha-1} e^{-\\lambda x^\\alpha},\\quad x\u003e0\\\\ 0,\\quad x\\leq 0 \\end{matrix}\\right. \\]\n其概率分布函数是\n\\[F(x)=\\left\\{\\begin{matrix} 1-e^{-\\lambda x^\\alpha},\\quad x\u003e0\\\\ 0,\\quad x\\leq 0 \\end{matrix}\\right. \\]\n可见，指数分布是威布尔分布的一个特例。\n均匀分布 满足\n\\[f(x)=\\left\\{\\begin{matrix} 1/(b-a),\\quad a\\leq x\\leq b\\\\ 0,\\quad else \\end{matrix}\\right. \\]\n其概率分布函数是\n\\[F(x)=\\left\\{\\begin{align*} \u00260, \u0026\u0026x\\leq a\\\\ \u0026(x-a)/(b-a), \u0026\u0026a \u003c x \u003c b\\\\ \u00261, \u0026\u0026x\\geq b \\end{align*}\\right. \\]\n常记作\\(R(a,b),U(a,b)\\)\n数学期望 \\[\\frac{a+b}{2} \\]\n方差 \\[\\frac{(b-a)^2}{12} \\]\n二维随机向量的均匀分布 \\[f(x_1,x_2)= \\left\\{\\begin{matrix} 1/[(b-a)(d-c)],\\quad a\\leq x_1\\leq b, c\\leq x_2\\leq d\\\\ 0,\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad other\\quad\\quad\\quad\\quad\\quad\\quad \\end{matrix}\\right. \\]\n以上是矩形情况的密度函数\n如果扩展到任意形状的图形，只要求出来其面积，那么密度函数在图形内部就是\\(1/S\\)，图形外部是\\(0\\)\n最大值分布 设\\(M=max\\{X,Y\\}\\)，\\(X,Y\\)相互独立，则\n\\[F_{max}(z)=P(M\\leq z)=P(X\\leq z, Y\\leq z)=P(X\\leq z)P(Y\\leq z) \\]\n\\[F_{max}(z) = F_X(z)F_Y(z) \\]\n扩展到多维情况\n\\[F_{max}(z) = F_{X_1}(z)F_{X_2}(z)\\cdots F_{X_n}(z) \\]\n最小值分布 设\\(N=min\\{X,Y\\}\\)，\\(X,Y\\)相互独立，则\n\\[F_{min}(z)=P(N\\leq z)=1-P(N\u003ez)=1-P(X\u003ez, Y\u003ez)=1-P(X\u003ez)P(Y\u003ez) \\]\n\\[F_{min}(z) = 1-[1-F_X(z)][1-F_Y(z)] \\]\n扩展到多维情况\n\\[F_{min}(z) = 1-[1-F_{X_1}(z)][1-F_{X_2}(z)]\\cdots [1-F_{X_n}(z)] \\]\n卡方分布 \\(\\Gamma\\)函数\n通过积分\n\\[\\Gamma(x) = \\int^\\infty_0 e^{-t}t^{x-1}dt(x\u003e0) \\]\n来定义\n\\(\\Beta\\)（Beta）函数\n通过积分\n\\[\\Gamma(x) = \\int^1_0 t^{x-1}(1-t)^{y-1}dt(x\u003e0 ,y\u003e0) \\]\n来定义\n\\(\\Gamma\\)函数的性质\n\\(\\Gamma(1)=1\\) \\(\\Gamma(1/2)=\\sqrt{\\pi}\\) \\(\\Gamma(x+1)=x\\Gamma(x)\\) 因此可知，\\(n\\)为正整数时\n\\[\\Gamma(n) = (n-1)! \\]\n\\(n\\)为正奇数时\n\\[\\Gamma(n/2) = 1\\cdot 3\\cdot 5\\cdots(n-2)2^{-(n-1)/2}\\sqrt{\\pi} \\]\n其中\\(\\Gamma\\)与\\(\\Beta\\)函数之间有重要的关系式\n\\[\\Beta(x,y)=\\Gamma(x)\\Gamma(y)/\\Gamma(x+y) \\]\n卡方分布\n由\\(\\Gamma\\)函数的定义可知，若\\(n\u003e0\\)，则函数\n\\[k_n(x)=\\left\\{\\begin{align*} \u0026\\frac{1}{\\Gamma(n/2)2^{n/2}}e^{-x/2}x^{(n-2)/2} \u0026,\\quad x\u003e0\\\\ \u00260 \u0026,\\quad x\\leq 0 \\end{align*}\\right. \\]\n是概率密度函数。它称为“自由度为\\(n\\)的皮尔逊卡方密度”，常记为\\(\\mathcal{X}{}_n^2\\)\n定理1\n若\\(X_1,\\cdots,X_n\\)相互独立，都服从正态分布\\(N(0,1)\\)，则\\(Y=X_1^2+\\cdots+X_n^2\\)服从自由度为\\(n\\)的卡方分布\\(\\mathcal{X}{}_n^2\\)\n卡方分布有如下性质\n设\\(X_1,X_2\\)独立，\\(X_1\\sim \\mathcal{X}_m^2,X_2\\sim \\mathcal{X}_n^2\\)，则\\(X_1+X_2\\sim \\mathcal{X}_{m+n}^2\\) 若\\(X_1,\\cdots,X_n\\)独立，且都服从指数分布，则 \\[X=2\\lambda(X_1+\\cdots+X_n)\\sim \\mathcal{X}_{2n}^2 \\]\n期望\n若\\(X\\sim\\mathcal{X}_n^2\\)，\\(E(X)=n\\)\n方差\n若\\(X\\sim\\mathcal{X}_n^2\\)，\\(D(X)=2n\\)\n上\\(\\alpha\\)分位点\n可由查表得到。有一个性质，当\\(n\\)充分大，如\\(n\u003e40\\)时，则其上\\(\\alpha\\)分位点约为\n\\[\\dfrac{1}{2}\\bigg(w_\\alpha+\\sqrt{2n-1}\\bigg)^2 \\]\n其中\\(w_\\alpha\\)是标准正态分布的上\\(\\alpha\\)分位点\nt分布 若\\(X\\sim N(0,1),Y\\sim\\mathcal{X}_n^2\\)，且\\(X,Y\\)相互独立\n\\(t=X/\\sqrt{Y/n}\\)的密度函数为\n\\[t_n(y)=\\frac{\\Gamma((n+1)/2)}{\\sqrt{n\\pi}\\Gamma(n/2)}\\bigg(1+\\frac{y^2}{n}\\bigg)^{-\\frac{n+1}{2}} \\]\n这个密度函数称为“自由度为\\(n\\)的\\(t\\)分布”的密度函数，常简记为\\(t_n\\)\n\\(n\\)充分大时\n\\[\\lim_{n\\to\\infty}t_n(y)=\\frac{1}{\\sqrt{2\\pi}}e^{-t^2/2} \\]\n上\\(\\alpha\\)分位点\n查表可知。\n具有对称性\\(w_{1-\\alpha}=-w_\\alpha\\)\n当\\(n\\)充分大，如\\(n\u003e45\\)时，其分位点和标准正态分布近似。\nF分布 设\\(U\\sim\\mathcal{X}_{n_1}^2,V\\sim\\mathcal{X}_{n_2}^2\\)，且\\(U,V\\)相互独立，则称随机变量\n\\[F = \\frac{U/n_1}{V/n_2} \\]\n服从自由度为\\((n_1,n_2)\\)的\\(F\\)分布，概率密度为\n\\[f_{n_1,n_2}(y) = n_1^{n_1/2}n_2^{n_2/2}\\frac{\\Gamma(\\frac{n_1+n_2}{2})}{\\Gamma(\\frac{n_1}{2})\\Gamma(\\frac{n_2}{2})}y^{n_1/2-1}(n_1y+n_2)^{-(n_1+n_2)/2} \\]\n性质\n若\\(F\\sim F(n_1,n_2)\\)，则\\(\\frac{1}{F}\\sim F(n_2,n_1)\\)\n上\\(\\alpha\\)分位点\n查表可知。\n性质如下：\n\\[F_{1-\\alpha}(n_1,n_2) = \\dfrac{1}{F_\\alpha(n_2,n_1)} \\]\n八大分布 单正态总体 设\\(X\\sim N(\\mu,\\sigma^2)\\)，而\\(X_1,X_2,\\cdots,X_n\\)是来自正态总体\\(N(\\mu,\\sigma^2)\\)的样本，\\(\\overline{X}\\)和\\(S^2\\)分别是样本均值和样本方差，则有\n\\[\\overline{X}\\sim N(\\mu,\\sigma^2/n)\\quad\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt n}\\sim N(0,1) \\]\n\\[\\frac{\\sum^n_{i=1}(X_i-\\mu)^2}{\\sigma^2}\\sim \\mathcal{X}^2_n \\]\n\\[\\frac{(n-1)S^2}{\\sigma^2}\\sim\\mathcal{X}^2_{n-1}\\quad \\frac{\\sum^n_{i=1}(X_i-\\overline X)^2}{\\sigma^2}\\sim \\mathcal{X}^2_{n-1}且\\overline X与S^2相互独立 \\]\n\\[\\frac{\\overline X-\\mu}{S/\\sqrt n}\\sim t(n-1) \\]\n双正态总体 设\\((X_1,\\cdots,X_{n_1})\\)和\\((Y_1,\\cdots,Y_{n_2})\\)分别是来自正态总体\\(N(\\mu_1,\\sigma_1^2)\\)和\\(N(\\mu_2,\\sigma_2^2)\\)的样本，且这两个样本相互独立，设\\(\\overline X,\\overline Y\\)分别是样本均值\n\\[\\frac{(\\overline X-\\overline Y)-(\\mu_1-\\mu_2)}{\\sqrt{\\sigma_1^2/n_1+\\sigma_2^2/n_2}}\\sim N(0,1) \\]\n当\\(\\sigma_1=\\sigma_2\\)未知时 \\[\\frac{(\\overline X-\\overline Y)-(\\mu_1-\\mu_2)}{S_W\\sqrt{1/n_1+1/n_2}}\\sim t(n_1+n_2-2) \\]\n其中\n\\[S_W = \\sqrt{\\frac{(n_1-1)S_1^2+(n_2-1)S_2^2}{n_1+n_2-2}} \\]\n\\[\\frac{n_2\\sigma_2^2\\sum^{n_1}_{i=1}(X_i-\\mu_1)^2}{n_1\\sigma_1^2\\sum^{n_2}_{i=1}(Y_i-\\mu_2)^2}\\sim F(n_1,n_2) \\]\n\\[\\frac{S_1^2/S_2^2}{\\sigma_1^2/\\sigma_2^2}\\sim F(n_1-1,n_2-1) \\]\n随机变量的数字特征 数学期望与中位数 定义 定义1\n设随机变量\\(X\\)只取有限个可能值\\(a_1,\\cdots,a_m\\)，其概率分布为\\(P(X=a_i)=p_i(i=1,\\cdots,m)\\)，则\\(X\\)的数学期望，记为\\(E(X)\\)或\\(EX\\)，定义为\n\\[E(X) = a_1p_1+a_2p_2+\\cdots+a_mp_m \\]\n如果取无穷个值\\(a_1,a_2,\\cdots\\)，而概率分布为\\(P(X=a_i)=p_i(i=1,\\cdots)\\)，则有其数学期望为\n\\[E(X) = \\sum^\\infty_{i=1}a_ip_i（式1） \\]\n这个期望存在，必须要求这个级数收敛，并且是绝对收敛。\n定义2\n如果\n\\[\\sum^\\infty_{i=1}|a_i|p_i\u003c\\infty \\]\n则称式1的右边的级数之和为\\(X\\)的数学期望\n定义3\n设\\(X\\)有概率密度函数\\(f(x)\\)，如果\n\\[\\int^\\infty_{-\\infty}|x|f(x)dx\u003c\\infty \\]\n则称\n\\[E(X) = \\int^\\infty_{-\\infty}xf(x)dx \\]\n为\\(X\\)的数学期望。\n性质 定理1\n若干个随机变量之和的期望等于各变量的期望之和\n\\[E(X_1+X_2+\\cdots+X_n) = E(X_1)+E(X_2)+\\cdots+E(X_n) \\]\n定理2\n若干个独立（注意独立）随机变量之积的期望等于各变量期望之积\n\\[E(X_1X_2\\cdots X_n) = E(X_1)E(X_2)\\cdots E(X_n) \\]\n随机变量函数的期望\n设随机变量\\(X\\)为离散型，有分布\\(P(X=a_i)=p_i(i=1,2,\\cdots)\\)；或者为连续型，有概率密度函数\\(f(x)\\)，则\n\\[E(g(x)) = \\sum_i g(a_i)p_i（要求绝对收敛） \\]\n或\n\\[E(g(x)) = \\int^\\infty_{-\\infty}g(x)f(x)dx（要求\\int^\\infty_{-\\infty}|g(x)|f(x)dx\u003c\\infty） \\]\n有一个特例是，若\\(c\\)为常数，则\n\\[E(cX) = cE(X) \\]\n多维情况 以二维为例\n设\\(Z\\)是随机变量\\(X,Y\\)的函数，\\(Z=g(X,Y)\\)，\\(g\\)是连续函数，\\(Z\\)是一维随机变量\n离散情况\n设\\((X,Y)\\)的分布律为\\(P(X=x_i,Y=y_j)=p_{ij}\\)\n\\[E(Z) = E[g(X,Y)] = \\sum_j\\sum_i g(x_i,y_j)p_{ij} \\]\n连续情况\n设\\((X,Y)\\)的概率密度是\\(f(x,y)\\)，则有\n\\[E(Z)=E[g(X,Y)]=\\int^{+\\infty}_{-\\infty}\\int^{+\\infty}_{-\\infty}g(x,y)f(x,y)dxdy \\]\n更高维可以同理推出。\n条件数学期望 \\[E(Y|x) = \\int^\\infty_{-\\infty}yf(y|x)dy \\]\n类似于全概率公式，我们可以求得无条件的数学期望的一个重要公式\n\\[E(Y) = \\int^\\infty_{-\\infty}E(Y|x)f_1(x)dx \\]\n其中\n\\[f_1 = \\int^\\infty_{-\\infty}f(x,y)dy \\]\n如果将\\(g(x)=E(Y|x)\\)，则\n\\[E(Y) = \\int^\\infty_{-\\infty}g(x)f_1(x)dx=E(g(X))=E(E(Y|X)) \\]\n整理得到\n\\[E(Y) = E[E(Y|X)] \\]\n如果是多维的，也有\n\\[E(Y) = \\int^\\infty_{-\\infty}\\cdots\\int^\\infty_{-\\infty}E(Y|x_1,\\cdots,x_n)f(x_1,\\cdots,x_n)dx_1\\cdots dx_n \\]\n如果是离散的，有\\(P(X=a_i)=p_i\\)，则\n\\[E(Y) = \\sum^\\infty_{i=1}p_iE(Y|a_i) \\]\n中位数 定义1\n设连续型随机变量\\(X\\)的分布函数为\\(F(x)\\)，则满足条件\n\\[P(X\\leq m)=F(m)=1/2 \\]\n的数\\(m\\)称为\\(X\\)或分布\\(F\\)的中位数。\n而连续的时候，有\n\\[P(X\\leq m) = P(X \u003c m) = P(X \u003e m) = P(X\\geq m) = 1/2 \\]\n方差与矩 方差与标准差 定义1\n设\\(X\\)为随机变量，分布为\\(F\\)，则\n\\[Var(X) = E(X-EX)^2 \\]\n称为\\(X\\)的方差，有时会记为\\(DX\\)，其算术平方根称为标准差。\n将其展开得\n\\[Var(X)=E(X^2)-(EX)^2 \\]\n定理1\n常数的方差为\\(0\\) 若\\(c\\)为常数，则\\(Var(X+c)=Var(X)\\) 若\\(c\\)为常数，则\\(Var(cX)=c^2Var(X)\\) \\(Var(X)=0\\)的充要条件为，\\(P(X=E(X))=1\\) 定理2\n独立（注意独立）随机变量之和的方差等于各变量的方差之和，即\n\\[Var(X_1+X_2+\\cdots+X_n) = Var(X_1)+Var(X_2)+\\cdots+Var(X_n) \\]\n如果不要求独立，二维有\n\\[Var(X+Y)=Var(X)+Var(Y)+2E\\{[X-E(X)][Y-E(Y)]\\} \\]\n矩 定义1\n设\\(X\\)为随机变量，\\(c\\)为常数，\\(k\\)为正整数，则量\\(E[(X-c)^k]\\)称为\\(X\\)关于\\(c\\)点的\\(k\\)阶矩\n\\(c=0\\)时称为\\(X\\)的\\(k\\)阶原点矩，记作\\(\\mu_k\\) \\(c=E(X)\\)时称为\\(X\\)的\\(k\\)阶中心矩，记作\\(v_k\\)。 另外\n\\(\\mu_{kl}=E(X^kY^l)\\)称为\\(X,Y\\)的\\(k+l\\)阶混合原点矩，简称\\(k+l\\)混合矩 \\(v_{kl}=E[(X-E(X))^k(Y-E(Y))^l]\\)称为\\(X,Y\\)的\\(k+l\\)阶混合中心矩 协方差与相关系数 对于二维随机向量\\((X,Y)\\)，\\(X,Y\\)本身都是一维随机变量，可以定义其均值、方差，我们记为\n\\[E(X)=m_1,E(Y)=m_2,Var(X)=\\sigma_1^2,Var(Y)=\\sigma_2^2 \\]\n定义1\n称\\(E[(X-m_1)(Y-m_2)]\\)为\\(X,Y\\)的协方差，并记为\\(Cov(X,Y)\\)\n显然有\\(Cov(X,Y)=Cov(Y,X)\\)\n也有\n对常数\\(c_1,c_2,c_3,c_4\\)，有 \\[Cov(c_1X+c_2,c_3Y+c_4)=c_1c_3Cov(X,Y) \\]\n\\(Cov(X,Y)=E(XY)-m_1m_2=E(XY)-E(X)E(Y)\\) \\(Cov(X,X)=Var(X)\\) \\(Cov(X_1+X_2,Y)=Cov(X_1,Y)+Cov(X_2,Y)\\) \\(Var(X\\pm Y)=Var(X)+Var(Y)\\pm 2Cov(X,Y)\\) 定理1\n若\\(X,Y\\)独立，则\\(Cov(X,Y)=0\\) \\([Cov(X,Y)]^2\\leq\\sigma_1^2\\sigma_2^2\\)，等号当且仅当\\(X,Y\\)之间有严格线性关系（即存在常数\\(a,b\\)使\\(Y=a+bX\\)）时成立。 定义2\n称\\(Cov(X,Y)/(\\sigma_1\\sigma_2)\\)为\\(X,Y\\)的相关系数，并记为\\(Corr(X,Y)\\)，有时也记为\\(\\rho_{XY}\\)\n可以将相关系数看做标准尺度下的协方差。\n定理2\n若\\(X,Y\\)独立，则\\(Corr(X,Y)=0\\)，当然也要求方差大于\\(0\\)才有定义。 \\(-1\\leq Corr(X,Y)\\leq 1\\)，等号当且仅当\\(X,Y\\)之间有严格线性关系时达到。 需要注意几点：\n当\\(Corr(X,Y)=0\\)（或\\(Cov(X,Y)=0\\)）时，称\\(X,Y\\)不相关，通常我们只能由“独立”推出“不相关”，而不能反过来。但是对于服从二维正态分布的\\(X,Y\\)，“独立”和“不相关”是一回事。 相关系数也常称为“线性相关系数”，相关系数并不是刻画\\(X,Y\\)之间一般关系的程度，而只刻画了“线性”关系的程度。上述定理的第二条提供了一个依据。 如果\\(0\u003c |Corr(X,Y)|\u003c 1\\)，则解释为\\(X,Y\\)之间有一定程度的线性关系。 线性相关的意义还可以从最小二乘法的角度去解释。 大数定理和中心极限定理 大数定理 定义1\n设\\(X_1,X_2,\\cdots\\)是随机变量序列，如果存在数列\\(a_1,a_2,\\cdots\\)使得对任意的\\(\\varepsilon\u003e0\\)，有\n\\[\\lim_{n\\to\\infty}P\\bigg(\\bigg|\\frac{1}{n}\\sum^n_{i=1}X_i-a_n\\bigg|\\geq\\varepsilon\\bigg)=0 \\]\n则称随机变量序列\\(\\{X_i\\}\\)服从大数定律。\n定义2\n设\\(X_1,X_2,\\cdots\\)是随机变量序列，\\(X\\)是随机变量，若对任意的\\(\\varepsilon\u003e0\\)，有\n\\[\\lim_{n\\to\\infty}P(|X_n-X|\\geq \\varepsilon)=0 \\]\n此时我们称\\(\\{X_i\\}\\)依概率收敛到\\(X\\)，记为\n\\[X_n\\stackrel{P}\\rightarrow X,n\\to\\infty \\]\n马尔科夫不等式\n若\\(Y\\)为只取非负值的随机变量，则对任给常数\\(\\varepsilon\u003e0\\)，有\n\\[P(Y\\geq \\varepsilon)\\leq E(Y)/\\varepsilon \\]\n切比雪夫不等式\n若\\(Var(Y)\\)存在，则\n\\[P(|Y-EY|\\geq\\varepsilon)\\leq Var(Y)/\\varepsilon^2 \\]\n可以推知\n\\[P(|Y-EY|\u003c\\varepsilon)\\leq 1-Var(Y)/\\varepsilon^2 \\]\n切比雪夫大数定理\n设\\(X_1,X_2,\\cdots,X_n,\\cdots\\)是相互独立的随机变量，具有相同的期望和方差，记它们的均值都为\\(a\\)。又设它们的方差存在并记为\\(\\sigma^2\\)。则对任意给定的\\(\\varepsilon\u003e0\\)，有\n\\[\\lim_{n\\to \\infty}P(|\\bar X_n-a|\\geq \\varepsilon) = 0 \\]\n更一般的形式\n设\\(X_1,X_2,\\cdots,X_n,\\cdots\\)是相互独立的随机变量序列，具有相同的期望\\(\\mu\\)，如果存在常数\\(C\u003e0\\)，使得\\(D(X_k)\\leq C\\)，则对于任意\\(\\varepsilon\u003e0\\)，有\n\\[\\lim_{n\\to\\infty}P\\bigg(\\bigg|\\frac{1}{n}\\sum^n_{k=1}X_k-\\mu\\bigg|\\geq\\varepsilon\\bigg)=0 \\]\n马尔科夫大数定律\n设\\(X_1,X_2,\\cdots,X_n,\\cdots\\)是随机变量序列，且\n\\[\\lim_{n\\to\\infty}\\frac{1}{n^2}D\\bigg[\\sum^n_{k=1}X_k\\bigg]=0 \\]\n则对于任意\\(\\varepsilon\u003e0\\)，有\n\\[\\lim_{n\\to\\infty}P\\bigg(\\bigg|\\frac{1}{n}\\sum^n_{k=1}X_k-\\frac{1}{n}\\sum^n_{k=1}E(X_k)\\bigg|\\geq\\varepsilon\\bigg)=0 \\]\n辛钦大数定律\n设\\(X_1,X_2,\\cdots,X_n,\\cdots\\)是相互独立且同分布的随机变量序列，具有有限的数学期望，记为\\(\\mu\\)。则对于任意\\(\\varepsilon\u003e0\\)，有\n\\[\\lim_{n\\to\\infty}P\\bigg(\\bigg|\\frac{1}{n}\\sum^n_{k=1}X_k-\\mu\\bigg|\\geq\\varepsilon\\bigg)=0 \\]\n伯努利大数定律\n设\\(n_A\\)是\\(n\\)次独立重复实验（\\(n\\)重伯努利实验）事件\\(A\\)发生的次数，\\(p\\)是事件\\(A\\)在每次试验中发生的概率，即\\(P(A)=p\\)，则对任意的\\(\\varepsilon\u003e0\\)，有\n\\[\\lim_{n\\to\\infty} P\\bigg(\\bigg|\\frac{n_A}{n}-p\\bigg|\\geq\\varepsilon\\bigg)=0 \\]\n中心极限定理 定理1\n设\\(X_1,X_2,\\cdots,X_n,\\cdots\\)为独立同分布的随机变量，\\(E(X_i)=\\mu,Var(X_i)=\\sigma^2(0\u003c\\sigma^2\u003c\\infty)\\)。则对任何实数\\(x\\)，有\n\\[\\lim_{n\\to\\infty}P\\bigg(\\frac{1}{\\sqrt{n} \\sigma}(X_1+\\cdots+X_n-n\\mu)\\leq x\\bigg)=\\varPhi(x) \\]\n这里，\\(\\varPhi(x)\\)是标准正态分布\\(N(0,1)\\)的分布函数。\n也就是说，当\\(n\\)充分大时，有\n\\[\\sum_{k=1}^n X_k\\sim N(n\\mu,n\\sigma^2),\\quad \\frac{\\sum_{k=1}^nX_k-n\\mu}{\\sqrt{n}\\sigma}\\sim N(0,1) \\]\n\\[P\\bigg(\\sum^n_{k=1}X_k\\leq x\\bigg)\\approx\\Phi\\bigg(\\frac{x-n\\mu}{\\sqrt n\\sigma}\\bigg),\\quad P\\bigg(a\u003c\\sum^n_{k=1}X_k\\leq b\\bigg)\\approx\\Phi\\bigg(\\frac{b-n\\mu}{\\sqrt n\\sigma}\\bigg)-\\Phi\\bigg(\\frac{a-n\\mu}{\\sqrt n\\sigma}\\bigg) \\]\n\\[\\bar X\\approx N(\\mu,\\sigma^2/n),\\quad \\frac{\\bar X-\\mu}{\\sigma/\\sqrt{n}}\\approx N(0,1) \\]\n李雅普诺夫中心极限定理\n设\\(X_1,X_2,\\cdots,X_n,\\cdots\\)相互独立，其具有如下数学期望和方差：\\(E(X_k)=\\mu_k,D(X_k)=\\sigma_k^2\u003e0\\)，记\\(B_n^2=\\sum^n_{k=1}\\sigma^2_k\\)\n若存在正数\\(\\delta\\)使得当\\(n\\to\\infty\\)时\n\\[\\frac{1}{B^{2+\\delta}}\\sum^n_{k=1}E\\bigg[|X_i-\\mu_i|^{2+\\delta}\\bigg]\\to 0 \\]\n则\n\\[\\lim_{n\\to\\infty}P\\bigg(\\frac{\\sum^n_{k=1}X_k-\\sum^n_{k=1}\\mu_k}{B_n}\\leq x\\bigg)=\\Phi(x) \\]\n棣莫弗-拉普拉斯中心极限定理\n设\\(n_A\\)是\\(n\\)次独立重复实验（\\(n\\)重伯努利实验）事件\\(A\\)发生的次数，\\(p\\)是事件\\(A\\)在每次试验中发生的概率，即\\(P(A)=p\\)，\n\\[\\lim_{n\\to\\infty}P\\bigg(\\frac{n_A-np}{\\sqrt{np(1-p)}}\\leq x\\bigg)=\\Phi(x) \\]\n即，若\\(X\\sim B(n,p)\\)，\\(n\\)充分大时\n\\[X\\sim N(np,np(1-p)) \\]\n\\[P(X\\leq x)\\approx\\Phi\\bigg(\\frac{x-np}{\\sqrt{np(1-p)}}\\bigg),\\quad P(a \u003c X\\leq b)\\approx\\Phi\\bigg(\\frac{b-np}{\\sqrt{np(1-p)}}\\bigg)-\\Phi\\bigg(\\frac{a-np}{\\sqrt{np(1-p)}}\\bigg) \\]\n参数估计 数理统计学的基本概念 总体 总体是指与所研究的问题有关的对象（个体）的全体所构成的集合。\n赋有一定概率分布的总体就称为统计总体。\n在数理统计学中，“总体”这个基本概念的要旨——总体就是一个概率分布，当总体分布为指数分布时，称为指数分布总体；当总体分布为正态分布时，称为正态分布总体，或简称正态总体。\n总体分布是一个概率分布族。这个分布族包含一个参数时，称为单参数分布族，例如指数分布。包含两个参数时，称为两参数分布族，例如正态分布。如果总体分布不能通过若干个未知参数表达出来，这种情况称为非参数总体。\n样本 样本是按一定的规定从总体中抽出的一部分个体，所谓“按一定的规定”，就是指总体中的每一个个体有同等的被抽出的机会。\n样本表现为若干个数据\\(X_1,\\cdots,X_n,n\\)称为“样本大小”或“样本容量”、“样本量”，样本\\(X_1,\\cdots,X_n\\)中的每一个\\(X_i\\)也称为样本。有时\\(X_1,\\cdots,X_n\\)称为一组样本，而\\(X_i\\)称为其中的第\\(i\\)个样本。\n统计量 完全由样本所决定的量叫做统计量。统计量只以来于样本，而不能依赖于任何其他未知的量。\n简单随机样本 设\\(X\\)是具有分布函数\\(F\\)的随机变量，若\\(X_1,\\cdots,X_n\\)是相互独立，且与\\(X\\)具有相同分布函数\\(F\\)的随机变量，则称\\(X_1,\\cdots,X_n\\)是一个来自总体\\(X\\)的容量为\\(n\\)的简单随机样本，简称样本。\n一个样本\\(X_1,\\cdots,X_n\\)的观察值\\(x_1,\\cdots,x_n\\)，称为样本值。\n联合分布函数为\n\\[F^*(x_1,x_2,\\cdots,x_n) = \\prod^n_{i=1}F(x_i) \\]\n如果是离散型，有\n\\[p^*(X_1=x_1,X_2=x_2,\\dots,X_n=x_n)=\\prod^n_{i=1}p(x_i) \\]\n如果是连续型，有\n\\[f^*(x_1,x_2,\\cdots,x_n) = \\prod^n_{i=1}f(x_i) \\]\n经验分布函数 设\\(X_1,\\cdots,X_n\\)是来自总体\\(X\\)的一个样本，\\(x_1,\\cdots,x_n\\)，是样本\\(X_1,\\cdots,X_n\\)的一组样本值，将其从小到大排列，并且重新编号为\\(x_1,\\cdots,x_n\\)，则称函数\n\\[F_n(x)=\\frac{x_1,\\cdots,x_n中小于等于x的样本值的个数}{n} = \\left\\{\\begin{matrix} 0,\u0026x \u003c x_1 \\\\ k/n,\u0026x_k \u003c x_{k+1} \\\\ 1,\u0026x\\geq x_n \\end{matrix}\\right. \\]\n为总体\\(X\\)的经验分布函数。\n常用统计量 样本均值\n\\[\\overline{X} = \\frac{1}{n}\\sum^n_{i=1}X_i \\]\n其样本值为\n\\[\\overline{x} = \\frac{1}{n}\\sum^n_{i=1}x_i \\]\n样本方差\n\\[S^2 = \\frac{1}{n-1}\\sum^n_{i=1}(X_i-\\overline{X})^2 = \\frac{1}{n-1}\\bigg(\\sum^n_{i=1}X_i^2-n\\overline{X}^2\\bigg) \\]\n其样本值为\n\\[s^2 = \\frac{1}{n-1}\\sum^n_{i=1}(x_i-\\overline{x})^2 = \\frac{1}{n-1}\\bigg(\\sum^n_{i=1}x_i^2-n\\overline{x}^2\\bigg) \\]\n样本标准差\n\\[S = \\sqrt{\\frac{1}{n-1}\\sum^n_{i=1}(X_i-\\overline{X})^2} \\]\n其样本值为\n\\[s = \\sqrt{\\frac{1}{n-1}\\sum^n_{i=1}(x_i-\\overline{x})^2} \\]\n样本\\(k\\)阶原点矩\n\\[a_k = \\frac{1}{n}\\sum^n_{i=1}X_i^k \\]\n样本值略。\n样本\\(k\\)阶中心矩\n\\[m_k = \\frac{1}{n}\\sum^n_{i=1}(X_i-\\overline{X})^k \\]\n样本值略\n定理1\n设总体\\(X\\)均值为\\(\\mu\\)，方差为\\(\\sigma^2\\)（无论何种分布），\\(X_1,X_2,\\cdots,X_n\\)是来自总体\\(X\\)的一个样本，\\(\\overline{X}\\)和\\(S^2\\)分别是样本均值和样本方差，则有\n\\[E(\\overline{X})=\\mu,D(\\overline{X})=\\sigma^2/n,E(S^2) = \\sigma^2 \\]\n矩估计、极大似然估计和贝叶斯估计 参数的点估计问题 设总体的分布为\\(f(x;\\theta_1,\\cdots,\\theta_k)\\)，其形式已知（我们这里不区分连续和离散，具体情况具体处理就行），而有\\(k\\)个未知参数\\(\\theta_1,\\cdots,\\theta_k\\)。例如对正态总体\\(N(\\mu,\\sigma^2)\\)，有\\(\\theta_1=\\mu,\\theta_2=\\sigma^2\\)\n参数估计一般的方法就是使用总体中抽出的样本\\(X_1,\\cdots,X_n\\)，去对参数\\(\\theta_1,\\cdots,\\theta_k\\)的未知值做出估计。\n为了估计\\(\\theta_1\\)，我们需要构造出适当的统计量\\(\\hat \\theta_1=\\hat \\theta_1(X_1,\\cdots,X_n)\\)，每当有了样本\\(X_1,\\cdots,X_n\\)，就代入函数\\(\\hat \\theta_1(X_1,\\cdots,X_n)\\)中算出一个值，用来作为\\(\\theta_1\\)的估计值。\n为这样的特定目的而构造的统计量\\(\\hat\\theta_1\\)叫做\\(\\theta_1\\)的估计量。由于未知参数\\(\\theta_1\\)是数轴上的一个点，用\\(\\hat\\theta_1\\)去估计\\(\\theta_1\\)，等于用一个点去估计另一个点，所以这样的估计叫做点估计。\n矩估计法 设总体分布为\\(f(x;\\theta_1,\\cdots,\\theta_k)\\)，则它的矩（原点矩和中心矩都可以，此处以原点矩为例）\n\\[\\alpha_m = \\int^\\infty_{-\\infty}x^mf(x;\\theta_1,\\cdots,\\theta_k)dx \\]\n或\n\\[\\sum_i x^m_if(x_i;\\theta_1,\\cdots,\\theta_k) \\]\n依赖于\\(\\theta_1,\\cdots,\\theta_k\\)。另一方面，至少样本大小\\(n\\)较大时，\\(\\alpha_m\\)又应接近于样本的原点矩\\(a_m\\)；于是\n\\[\\alpha_m = \\alpha_m(\\theta_1,\\cdots,\\theta_k)\\approx a_m = \\sum^n_{i=1}X_i^m/n \\]\n取\\(m=1,\\cdots,k\\)，并将上面的近似式改为等式，就得到一个方程组\n\\[\\alpha_m(\\theta_1,\\cdots,\\theta_k)= a_m\\quad (m=1,\\cdots,k) \\]\n解此方程组，得到根\\(\\hat\\theta_i=\\hat\\theta_i(X_1,\\cdots,X_n)(i=1,\\cdots,k)\\)，就以\\(\\hat\\theta_i\\)作为\\(\\theta_i\\)的估计。如果要估计的是\\(\\theta_1,\\cdots,\\theta_k\\)的某函数\\(\\theta_1,\\cdots,\\theta_k\\)，则用\\(\\hat g = \\hat g(X_1,\\cdots,X_k) = g(\\hat\\theta_1,\\cdots,\\hat\\theta_k)\\)去估计它。这样定出的估计量叫做矩估计。\n正态总体的估计\n例如，设\\(X_1,\\cdots,X_n\\)是从正态总体\\(N(\\mu,\\sigma^2)\\)中抽出的样本，要估计\\(\\mu\\)和\\(\\sigma^2\\)。可以用样本的一阶原点矩即样本均值\\(\\overline{X}\\)去估计\\(\\mu\\)，而用样本的二阶中心距\\(m_2\\)去估计\\(\\sigma^2\\)。\n这确实是可以的，但是我们更常用的是使用样本方差\\(S^2\\)而不是使用\\(m_2\\)，即做出了一定修正，理由之后介绍。\n估计标准差也可以用\\(\\sqrt{m_2}\\)，但更常用\\(S\\)。\n有时要估计\\(\\sigma/\\mu\\)，称为总体的变异系数，其是以均值为单位去恒量的总体的标准差。可以用\\(\\sqrt{m_2}/\\overline X\\)，一般用\\(S/\\overline X\\)\n指数分布总体的估计\n又如指数分布的参数\\(\\lambda\\)，因为\\(1/\\lambda\\)是总体分布的均值，所以我们可以用\\(\\overline X\\)去估计。\n又因为其总体方差为\\(1/\\lambda^2\\)，所以\\(1/\\lambda\\)也可以用\\(\\sqrt{m_2}\\)或\\(S\\)去估计，具体哪种好之后回去讨论。但通常我们能用低阶矩就不用高阶矩。\n极大似然估计法 设总体分布为\\(f(x;\\theta_1,\\cdots,\\theta_k)\\)，\\(X_1,\\cdots,X_n\\)为自这个总体中抽出的样本，则样本\\((X_1,\\cdots,X_n)\\)的分布（即其概率密度函数或概率密度）为\n\\[f(x_1;\\theta_1,\\cdots,\\theta_k)f(x_2;\\theta_1,\\cdots,\\theta_k)\\cdots f(x_n;\\theta_1,\\cdots,\\theta_k) \\]\n记为\\(L(x_1,\\cdots,x_n;\\theta_1,\\cdots,\\theta_k)\\)\n当把\\(\\theta_1,\\cdots,\\theta_k\\)而看作\\(x_1,\\cdots,x_n\\)的函数时，\\(L\\)是一个概率密度函数或概率函数。\\(L(Y_1,\\cdots,Y_n;\\theta_1,\\cdots,\\theta_k)\u003eL(X_1,\\cdots,X_n;\\theta_1,\\cdots,\\theta_k)\\)意味着在观察时出现\\(Y_1,\\cdots,Y_n\\)这个点的概率比出现\\(X_1,\\cdots,X_n\\)这个点的可能性大。\n而反过来，\\(L(X_1,\\cdots,X_n;\\theta_1',\\cdots,\\theta_k')\u003eL(X_1,\\cdots,X_n;\\theta_1'',\\cdots,\\theta_k'')\\)，则被估计的参数\\(\\theta_1,\\cdots,\\theta_k\\)是\\(\\theta_1',\\cdots,\\theta_k'\\)的可能性比它是\\(\\theta_1'',\\cdots,\\theta_k''\\)的可能性大。此时\\(L\\)称作似然函数。\n所以我们的极大似然估计法就是用似然程度最大的那个点\\((\\theta_1^*,\\cdots,\\theta_k^*)\\)，即满足条件\n\\[L(X_1,\\cdots,X_n;\\theta^*_1,\\cdots,\\theta^*_k)=\\underset{\\theta_1,\\cdots,\\theta_k}{\\max}L(X_1,\\cdots,X_n;\\theta_1,\\cdots,\\theta_k) \\]\n的\\((\\theta_1^*,\\cdots,\\theta_k^*)\\)作为\\((\\theta_1,\\cdots,\\theta_k)\\)的估计值。这个估计值就叫做极大似然估计，估计函数\\(g(\\theta_1,\\cdots,\\theta_n)\\)就用\\(g(\\theta_1^*,\\cdots,\\theta_n^*)\\)\n因为\n\\[\\ln L = \\sum^n_{i=1}\\ln f(X_i;\\theta_1,\\cdots,\\theta_k) \\]\n为使\\(L\\)最大，则建立似然方程组如下\n\\[\\dfrac{\\partial\\ln L}{\\partial\\theta_i} = 0\\quad(i=1,\\cdots,k) \\]\n如果有唯一解，且是极大值点，则它必是使\\(L\\)达到最大的点。但有时候解不唯一，并且判断哪个使\\(L\\)达到极大也不容易。\n有时\\(f\\)不连续，或者不可导，这时就不能列方程，要回到最原始的定义。\n正态总体\n作为例子，正态总体用极大似然估计是可以的，它连续，并且可导，计算后得到的是\\(\\mu^*=\\overline X,\\sigma^{*2}=m_2\\)\n指数分布总体\n估计得\\(\\lambda=1/\\overline X\\)\n上面的两个例子，其和矩估计恰好一致，但这只是一种巧合，更多时候是不一致的。但这两种估计方法结果一致，说明这些估计是良好的。\n另外我们也可以应用样本中位数\\(\\hat m\\)去估计正态总体的\\(\\mu\\)，这个统计量可以在矩估计不能使用（主要体现为矩为无限大等场景）和极大似然法求根不容易等场景。\n贝叶斯法 在矩估计和极大似然估计时，在我们心目中，未知参数\\(\\theta\\)就简单地是一个未知数，在抽取样本之前，我们对\\(\\theta\\)没有任何了解，所有的信息全来自样本。\n贝叶斯学派则不然，它的出发点是：在进行抽样之前，我们已对\\(\\theta\\)有一定的知识，叫做先验知识，即试验之前的知识，也叫做验前知识。\n贝叶斯学派进一步要求：这种先验知识必须用\\(\\theta\\)的某种概率分布表达出来，这个概率分布就叫做\\(\\theta\\)的“先验分布”或“验前分布”。这个分布总结了我们在试验之前对未知参数\\(\\theta\\)的知识。\n比如我们可以使用工厂以前制造的产品废品率来作为先验知识。以\\(h(\\theta)\\)代表先验密度。但如果这个工厂是新开的，无法得到\\(h(\\theta)\\)，则我们必须设法定出一个\\(h(\\theta)\\)，甚至是自己的主观估计也可以。\n当我们确定先验密度后，设总体有概率密度\\(f(X,\\theta)\\)，从这个总体中抽样本\\(X_1,\\cdots,X_n\\)，则这组样本的密度为\\(f(X_1,\\theta)\\cdots f(X_n,\\theta)\\)。它可视为在给定\\(\\theta\\)时\\((X_1,\\cdots,X_n)\\)的密度，\\((\\theta,X_1,\\cdots,X_n)\\)的联合密度为\n\\[h(\\theta)f(X_1,\\theta)\\cdots f(X_n,\\theta) \\]\n由此，算出\\((X_1,\\cdots,X_n)\\)的边缘密度为\n\\[p(X_1,\\cdots,X_n) = \\int h(\\theta)f(X_1,\\theta)\\cdots f(X_n,\\theta)d\\theta \\]\n积分的范围依\\(\\theta\\)的具体范围而定。然后有\n\\[h(\\theta|X_1,\\cdots,X_n) = h(\\theta)f(X_1,\\theta)\\cdots f(X_n,\\theta)/p(X_1,\\cdots,X_n) \\]\n按照贝叶斯学派的观点，这个条件密度代表了我们现在取得样本\\(X_1,\\cdots,X_n\\)后对\\(\\theta\\)的知识，它综合了先验知识和样本的信息。这个式子称为后验（验后）密度。\n贝叶斯学派也指出，在得出后验分布后，对参数\\(\\theta\\)的任何统计推断都只能基于这个后验分布。\n点估计的优良性准则 估计量的无偏性 设某统计总体的分布包含未知参数\\(\\theta_1,\\cdots,\\theta_k\\)，\\(X_1,\\cdots,X_n\\)是从该总体中抽出的样本，要估计\\(g(\\theta_1,\\cdots,\\theta_k)\\)，\\(g\\)为一已知函数，设\\(\\hat g(X_1,\\cdots,X_n)\\)是一个估计量。如果对任何可能的\\(\\theta_1,\\cdots,\\theta_k\\)都有\n\\[E_{\\theta_1,\\cdots,\\theta_k}[\\hat g(X_1,\\cdots,X_n)]=g(\\theta_1,\\cdots,\\theta_k) \\]\n则称\\(\\hat g\\)是\\(g(\\theta_1,\\cdots,\\theta_k)\\)的一个无偏估计量。\n估计量的无偏性有两个含义：\n没有系统性的误差 根据大数定理，若估计量有无偏性，则在大量次数使用取平均时，能以接近于\\(100\\%\\)的把握无限逼近被估计的量。如果没有无偏性，那么估计值会和真值保持一定距离，这个距离就是系统误差。 可以证明\n例1\n设\\(X_1,\\cdots,X_n\\)是从总体中抽出的样本，则样本均值\\(\\overline X\\)是总体分布均值\\(\\theta\\)的无偏估计。\n例2\n样本方差\\(S^2\\)是总体分布方差\\(\\sigma^2\\)的无偏估计。（而不是二阶中心矩）\n最小方差无偏估计 一个参数往往有不止一个无偏估计，我们要从中调出一个最优的。\n均方误差 设\\(X_1,\\cdots,X_n\\)是从某一带参数\\(\\theta\\)的总体中抽出的样本，要估计\\(\\theta\\)。若我们采用估计量\\(\\hat\\theta = \\hat\\theta(X_1,\\cdots,X_n)\\)，则其误差为\\(\\hat\\theta(X_1,\\cdots,X_n)-\\theta\\)。这个误差随样本的具体值而定，也是随机的，无法作为优良性的指标。我们取\n\\[M_{\\hat\\theta}(\\theta)=E_\\theta[\\hat\\theta(X_1,\\cdots,X_n)-\\theta]^2 \\]\n作为\\(\\hat\\theta\\)的误差大小从整体角度的一个衡量。这个量越小，就表示\\(\\hat\\theta\\)的误差平均来讲比较小，因而也就越优。\\(M_{\\hat\\theta}\\)就称为估计量\\(\\theta\\)的“均方误差”\n最小方差无偏估计 从前面的讨论看到：若局限于无偏估计的范围，且采用均方误差的准则，则两个无偏估计\\(\\hat\\theta_1\\)和\\(\\hat\\theta_2\\)的比较归结为其方差的比较：方差小者为优。\n最小方差无偏估计简记为MVU估计。\n克拉美-劳不等式 TODO\n估计量的相合性与渐近正态性 相合性 设总体分布依赖于参数\\(\\theta_1,\\cdots,\\theta_k,g(\\theta_1,\\cdots,\\theta_k)\\)是\\(\\theta_1,\\cdots,\\theta_k\\)的一个给定函数，设\\(X_1,\\cdots,X_n\\) 为自该总体中抽出的样本，\\(T(X_1,\\cdots,X_n)\\)是\\(g(\\theta_1,\\cdots,\\theta_k)\\)的一个估计量，如果对任给\\(\\varepsilon\u003e0\\)有\n\\[\\lim_{n\\to\\infty}P_{\\theta_1,\\cdots,\\theta_k}(|T(X_1,\\cdots,X_n)-g(\\theta_1,\\cdots,\\theta_k)|\\geq\\varepsilon) = 0 \\]\n而且这对\\((\\theta_1,\\cdots,\\theta_k)\\)一切可能取的值都成立，则称\\(T(X_1,\\cdots,X_n)\\)是\\(g(\\theta_1,\\cdots,\\theta_k)\\)的一个相合估计。\n渐近正态性 正如在中心极限定理中所显示的，当\\(n\\)很大时，和的分布渐近于正态分布。理论上可以证明，这不只是和所独有的，许多形状复杂的统计量，当样本大小\\(n\\to\\infty\\)时，其分布都渐近于正态分布。这称为统计量的“渐近正态性”。\n区间估计 基本概念 点估计是用一个点去估计未知参数。区间估计就是用一个区间去估计未知参数，即未知参数的值也会估计在一个区间之内。\n设\\(X_1,\\cdots,X_n\\)是从该总体中抽出的样本。所谓\\(\\theta\\)的区间估计，就是以满足条件\\(\\hat\\theta_1(X_1,\\cdots,X_n)\\leq\\hat\\theta_2(X_1,\\cdots,X_n)\\)的两个统计量\\(\\hat\\theta_1,\\hat\\theta_2\\)为端点的区间\\([\\hat\\theta_1,\\hat\\theta_2]\\)。一旦有了样本\\(X_1,\\cdots,X_n\\)，就把\\(\\theta\\)估计在区间\\([\\hat\\theta_1(X_1,\\cdots,X_n),\\hat\\theta_2(X_1,\\cdots,X_n)]\\)之内。有两个要求\n\\(\\theta\\)要以很大的可能性落在\\([\\hat\\theta_1,\\hat\\theta_2]\\)之内，也就是说 \\[P_\\theta(\\hat\\theta_1\\leq\\theta\\leq\\hat\\theta_2) \\]\n要尽可能大。\n估计的精密度要尽可能高。比方说，要求区间的长度\\(\\hat\\theta_2-\\hat\\theta_1\\)尽可能小，或某种能体现这个要求的其他准则。 置信系数、置信区间、置信水平\n给定一个很小的数\\(\\alpha\u003e0\\)。如果对参数\\(\\theta\\)的任何值，\\(P_\\theta(\\hat\\theta_1\\leq\\theta\\leq\\hat\\theta_2)\\)都等于\\(1-\\alpha\\)，则层区间估计\\([\\hat\\theta_1,\\hat\\theta_2]\\)的置信系数为\\(1-\\alpha\\)，而这个区间叫做置信区间。\n有时，我们无法证明恰好等于\\(1-\\alpha\\)，但我们能证明它大于等于\\(1-\\alpha\\)，那我们称\\(1-\\alpha\\)是\\([\\hat\\theta_1,\\hat\\theta_2]\\)的置信水平。当然，如果\\(0.8\\)是，那么\\(0.7,0.6\\)等等也都是，置信系数就是置信水平中的最大者。\n枢轴变量法 找一个与要估计的参数\\(g(\\theta)\\)有关的统计量\\(T\\)，一般是其一个良好的点估计 设法找出\\(T\\)和\\(g(\\theta)\\)的某一函数\\(S(T,g(\\theta))\\)，其分布\\(F\\)要与\\(\\theta\\)无关，\\(S\\)称为枢轴变量。 对任何常数\\(a\u003c b\\)，不等式\\(a\\leq S(T,g(\\theta))\\leq b\\)要能改写为等价的形式\\(A\\leq g(\\theta)\\leq B\\)，\\(A,B\\)只与\\(T,a,b\\)有关，而与\\(\\theta\\)无关 取分布\\(F\\)的上\\(\\alpha/2\\)分位点\\(w_{\\alpha/2}\\)和上\\(1-\\alpha/2\\)分位点\\(w_{1-\\alpha/2}\\)，则有\\(F(w_{\\alpha/2})-F(w_{1-\\alpha/2})=1-\\alpha\\)，因此 \\[P(w_{1-\\alpha/2}\\leq S(T,g(\\theta))\\leq w_{\\alpha/2})=1-\\alpha \\]\n然后根据第三条改写为\\(A\\leq g(\\theta)\\leq B\\)，则\\([A,B]\\)就是\\(g(\\theta)\\)的一个置信系数为\\(1-\\alpha\\)的区间估计。\n上\\(\\beta\\)分位点的含义是，对于任何分布\\(F\\)，满足条件\\(F(v_\\beta)=1-\\beta\\)的点\\(v_\\beta\\)就是分布函数\\(F\\)的上\\(\\beta\\)分位点。\n下面给出一些常见的枢轴量\n单正态总体\n检验均值\\(\\mu\\)\n若\\(\\sigma^2\\)已知，则枢轴量\n\\[U = \\dfrac{\\overline X-\\mu}{\\sigma/\\sqrt n}\\sim N(0,1) \\]\n若\\(\\sigma^2\\)未知，则枢轴量\n\\[t = \\dfrac{\\overline X-\\mu}{S/\\sqrt n}\\sim t(n-1) \\]\n检验方差\\(\\sigma^2\\)\n若\\(\\mu\\)已知，则枢轴量\n\\[\\mathcal{X}^2 = \\dfrac{\\displaystyle\\sum^n_{i=1}(X_i-\\mu)^2}{\\sigma^2}\\sim \\mathcal{X}^2_n \\]\n若\\(\\mu\\)未知，则枢轴量\n\\[\\mathcal{X}^2 = \\dfrac{(n-1)S^2}{\\sigma^2}\\sim \\mathcal{X}^2_{n-1} \\]\n两个相互独立的正态总体\n检验均值差\\(\\mu_1-\\mu_2\\)\n若\\(\\sigma^2_1,\\sigma^2_2\\)已知，则枢轴量\n\\[U = \\dfrac{(\\overline X-\\overline Y)-(\\mu_1-\\mu_2)}{\\sqrt{\\sigma^2_1/n_1+\\sigma^2_2/n_2}}\\sim N(0,1) \\]\n若\\(\\sigma^2_1=\\sigma^2_2=\\sigma^2\\)未知，则枢轴量\n\\[t = \\dfrac{(\\overline X-\\overline Y)-(\\mu_1-\\mu_2)}{S_W\\sqrt{1/n_1+1/n_2}}\\sim t(n_1+n_2-2) \\]\n检验方差比\\(\\sigma_1^2/\\sigma_2^2\\)\n若\\(\\mu_1,\\mu_2\\)已知，则枢轴量\n\\[F = \\dfrac{n_2\\sigma_2^2\\sum^{n_1}_{i=1}(X_i-\\mu_1)^2}{n_1\\sigma_1^2\\sum^{n_2}_{i=1}(Y_i-\\mu_2)^2}\\sim F(n_1,n_2) \\]\n若\\(\\mu_1,\\mu_2\\)未知，则枢轴量\n\\[F = \\dfrac{\\sigma^2_2S_1^2}{\\sigma_1^2S_2^2}\\sim F(n_1-1,n_2-1) \\]\n枢轴量的使用方法\n我们最终要从枢轴量中得到置信区间，例如检验均值\\(\\mu\\)\n若\\(\\sigma^2\\)已知，则枢轴量\n\\[U = \\dfrac{\\overline X-\\mu}{\\sigma/\\sqrt n}\\sim N(0,1) \\]\n也就是我们要\n\\[P(w_{1-\\alpha/2}\\leq U\\leq w_{\\alpha/2}) = P(-w_{\\alpha/2}\\leq U\\leq w_{\\alpha/2})=1-\\alpha \\]\n我们就将\\(\\mu\\)的表达式写出来为\\([\\overline X - \\dfrac{\\sigma}{\\sqrt n}w_{\\alpha/2},\\overline X + \\dfrac{\\sigma}{\\sqrt n}w_{\\alpha/2}]\\)\n其他的使用办法也是类似的。\n大样本法 TODO\n置信界 设\\(X_1,\\cdots,X_n\\)是从某一总体中抽出的样本，总体分布包含未知参数\\(\\theta\\)，\\(\\overline{\\theta}=\\overline{\\theta}(X_1,\\cdots,X_n)\\)和\\(\\underline{\\theta}=\\underline{\\theta}(X_1,\\cdots,X_n)\\)都是统计量，则\n若对\\(\\theta\\)的一切可取的值，有 \\[P_\\theta(\\overline{\\theta}(X_1,\\cdots,X_n)\\geq\\theta)=1-\\alpha \\]\n则称\\(\\overline\\theta\\)是\\(\\theta\\)的一个置信系数为\\(1-\\alpha\\)的置信上界。\n若对\\(\\theta\\)的一切可取的值，有 \\[P_\\theta(\\underline{\\theta}(X_1,\\cdots,X_n)\\leq\\theta)=1-\\alpha \\]\n则称\\(\\underline\\theta\\)是\\(\\theta\\)的一个置信系数为\\(1-\\alpha\\)的置信下界。\n单侧置信区间使用枢轴量的方法类似，只不过要将\\(P\\)函数代成单侧的情况的。对于置信上界，置信区间的下限为\\(-\\infty\\)，对于置信下界，置信区间的上限为\\(+\\infty\\)\n贝叶斯法 TODO\n假设检验 基本概念 在显著性水平\\(\\alpha\\)之下，检验假设\\(H_0\\)和\\(H_1\\)。\\(H_0\\)称为原假设或零假设，\\(H_1\\)称为备择假设，备择假设是指与原假设相矛盾的假设。\n双边假设检验\n\\[H_0 : \\mu=\\mu_0\\quad H_1 : \\mu\\neq\\mu_0 \\]\n单边假设检验\n右边假设\n\\[H_0 : \\mu\\leq\\mu_0\\quad H_1 : \\mu\u003e\\mu_0 \\]\n左边假设\n\\[H_0 : \\mu\\geq\\mu_0\\quad H_1 : \\mu\u003c\\mu_0 \\]\n仅涉及总体分布未知参数的假设称为参数假设。而对总体分布类型或分布的某些特征提出的假设称为非参数假设。\n能够对原假设\\(H_0\\)是真或不真做出回答的统计量称为假设检验统计量。\n使得原假设\\(H_0\\)为真的假设检验统计量取值范围称为假设检验的接受域；拒绝原假设\\(H_0\\)的假设检验统计量取值范围称为拒绝域；拒绝域的边界点称为临界点。\n由于样本的随机性，进行判断时，可能会发生错误，发生错误也是一个随机事件\n第I类错误（弃真）：\\(H_0\\)为真但拒绝\\(H_0\\)\n\\[P(拒绝H_0/H_0为真时) = \\alpha \\]\n第II类错误（存伪）：\\(H_0\\)不真但接受\\(H_0\\)\n\\[P(接受H_0/H_0不真时) = \\beta \\]\n给定样本容量，如果减小第I类错误的概率，则第II类错误的概率往往增大。如果要使两类错误的概率都减小，需要增大样本容量。\n我们一般控制第I类错误的概率使其不大于\\(\\alpha\\)，通常取\\(\\alpha\\)为\\(0.1,0.05,0.01,0.005\\)\n只控制第I类错误的概率，而不考虑第II类错误的概率的假设检验称为显著性检验，称\\(\\alpha\\)为显著性水平。\n正态总体假设检验的接受域\n设总体\\(X\\sim N(\\mu,\\sigma^2),\\mu\\)未知，\\(\\sigma^2\\)已知，设\\(X_1,X_2,\\cdots,X_n\\)是来自总体的样本，给定显著性水平为\\(\\alpha\\)\n双边假设\n接受域为\n\\[|u| = \\bigg|\\dfrac{\\bar x-\\mu_0}{\\sigma/\\sqrt n}\\bigg| \u003c z_{\\alpha/2} \\]\n左边假设\n接受域为\n\\[u = \\dfrac{\\bar x-\\mu_0}{\\sigma/\\sqrt n}\u003e-z_\\alpha \\]\n右边假设\n接受域为\n\\[u = \\dfrac{\\bar x-\\mu_0}{\\sigma/\\sqrt n} \u003c z_\\alpha \\]\n求未知参数假设检验的步骤\n根据实际问题，提出原假设\\(H_0\\)和备择假设\\(H_1\\) 确定检验统计量及其在\\(H_0\\)为真时的分布 根据显著性水平\\(\\alpha\\)和样本容量\\(n\\)，按照\\(P(当H_0为真时拒绝H_0)=\\alpha\\)求出临界点，确定接受域或拒绝域 计算检验统计量的样本观测值 根据样本观测值做出决策，是接受原假设\\(H_0\\)还是拒绝\\(H_0\\) 双边假设的两个临界点：上\\(\\alpha/2\\)分位点、上\\(1-\\alpha/2\\)分位点\n左边假设的一个临界点：上\\(1-\\alpha\\)分位点\n右边假设的一个临界点：上\\(\\alpha\\)分位点\n单正态总体和双正态总体参数的假设检验 可以直接用之前提到枢轴量，以及其分位点来计算，具体形式和“正态总体假设检验的接受域”一小节类似，不再介绍。\n","date":"2022-08-30T10:41:24+08:00","image":"https://kegalas.top/p/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E6%95%B4%E7%90%86/cover_hu60f44b771e1522f4fa1d5246713b9a75_57927_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E6%95%B4%E7%90%86/","title":"概率论与数理统计整理"},{"content":"\r1.jpg\r情况如图所示，_ZSt28__throw_bad_array_new_lengthv无法被定位。\n经过检查，通过mingw64.exe运行的g++版本是12.1.0。这也是通过官网的教程安装的版本。并且我们通常会把msys2\\mingw64\\bin\\作为环境变量。\n而通过安装gcc（命令是pacman -S gcc，而不是官网的教程提供的命令），然后用msys2.exe运行的g++版本是11.3.0。将环境变量换为msys2\\usr\\bin\\，此时编译的程序可以正常运行不报错。\n推测原因是版本问题，或者是msys2和mingw64有什么差别。\n另外，通过mingw64打开的命令行来运行编译出来的exe文件不会报错。\n另外，如果遇到failed to synchronize all databases (unable to lock database)，而经过检查又没有发现/var/lib/pacman/db.lck这个文件的存在，可以考虑用管理员身份打开msys2.exe。如果能够打开就说明是权限问题，可以将整个msys2的权限进行修改，允许非管理员用户完全控制。\n2023.5.7 后记，msys2和mingw确实有区别，新博客文章见链接。另外本文上述办法没法完美解决，如果发给别人，他电脑上没有msys-2.0.dll，那么没法运行msys2编译的程序。\n","date":"2022-08-28T16:18:50+08:00","image":"https://kegalas.top/p/msys2%E4%B8%AD%E4%BD%BF%E7%94%A8mingw64%E7%9A%84g-%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8C%E6%8A%A5%E9%94%99%E6%97%A0%E6%B3%95%E6%89%BE%E5%88%B0%E5%85%A5%E5%8F%A3/1_hu8fe568a15a37a7bd8c510c832a970168_16486_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/msys2%E4%B8%AD%E4%BD%BF%E7%94%A8mingw64%E7%9A%84g-%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8C%E6%8A%A5%E9%94%99%E6%97%A0%E6%B3%95%E6%89%BE%E5%88%B0%E5%85%A5%E5%8F%A3/","title":"Msys2中使用mingw64的G++编译，运行报错无法找到入口"},{"content":"动画原理 根据视觉暂留现象，只要离散的画面切换的足够快，在人眼看起来就是连续的。\n一般电影是24fps，一般视频是30fps以上，VR是90fps以上。\n关键帧动画 重要的动作节点，会作为关键帧。而中间的帧会作为动作间的过渡。\n关键帧一般是画出来的。过渡帧也可以画，现在也有不少的软件可以自动生成过渡帧。\n关键帧插值 自动生成过渡帧就用到了关键帧插值。\n有线性插值，也有更光滑的插值。\n物理模拟 将各种各样的物理公式用来计算物体的运动，称为物理模拟、物理仿真。\n质点弹簧系统 最简单的单位是：一个弹簧连接了两个质点。\n假设两个点为\\(a,b\\)\n则\n\\[\\bm f_{a\\to b}=k_s(\\bm{b}-\\bm{a})\\\\ \\bm f_{b\\to a}=-\\bm f_{a\\to b} \\]\n上述情况的条件是弹簧长度为\\(0\\),若弹簧原始长度为\\(l\\)，则\n\\[\\bm f_{a\\to b}=k_s\\frac{\\bm b-\\bm a}{||\\bm b-\\bm a||}(||\\bm b-\\bm a||-l) \\]\n上述情况假设没有能量损失，如果假设存在阻力，如\\(b\\)物体的阻力是\n\\[\\bm f=-k_d\\dot{\\bm b} \\]\n其中\\(\\dot{\\bm b}\\)是\\(\\bm b\\)的一阶导数，即速度。\n考虑整个物体，此时要考虑两个物体的相对速度，则施加在\\(b\\)上面的阻力为\n\\[\\bm f_b=-k_d\\frac{\\bm b-\\bm a}{||\\bm b-\\bm a||}\\cdot(\\dot{\\bm b}-\\dot{\\bm a})\\cdot\\frac{\\bm b-\\bm a}{||\\bm b-\\bm a||} \\]\n弹簧组成的结构 例如组成一个网状结构、立方体结构等等。\n结构的行为更多的取决于弹簧的连接方式。\n粒子系统 直接定义众多小粒子，来描述更宏观的运动现象。通常可能比物理意义上的粒子（如原子）要大得多。\n它便于理解和实现，并且有较好的扩展性。\n但是有时需要大量粒子，如模拟流体；还需要加速结构。\n对于每一帧动画：\n如果需要，创造新的粒子 计算每个粒子上收到的力 更新粒子的位置和速度 如果需要，移除一些粒子 渲染粒子 粒子系统中的力：引力、电磁力、摩擦力、空气阻力等等。粒子系统还有碰撞。\n单粒子模拟 速度场\n描述了在某个位置，某个时间上的粒子的速度。（这里的x我推测是向量）\n\\[v(x,t) \\]\n然后有常微分方程(ODE)\n\\[\\frac{dx}{dt}=\\dot{x}=v(x,t) \\]\n欧拉方法\n用前一帧的量去估计下一帧的量\n\\[x_{t+\\Delta t}=x_t+\\Delta t\\dot{x}_t\\\\ \\dot{x}_{t+\\Delta t}=\\dot{x}_t+\\Delta t\\ddot{x}_t \\]\n问题：非常不准确，非常不稳定。主要是步长\\(\\Delta t\\)的存在导致的问题。这其实也是用数值方法来计算的共有问题。\n解决（降低）不稳定性的方法有：中点法、自适应步长法、隐式欧拉方法、基于位置的方法等等。\n中点法\n\\[x_{mid}=x(t)+\\Delta t/2\\cdot v(x(t),t)\\\\ x(t+\\Delta t)=x(t)+\\Delta t\\cdot v(x_{mid},t) \\]\n自适应步长法\n定义一个threshold 计算以\\(T\\)为步长，计算一次欧拉方法，得到\\(x_T\\) 以\\(T/2\\)为步长，计算两次欧拉方法，得到\\(x_{T/2}\\) 计算error，即\\(x_T-x_{T/2}\\) 如果error\u0026gt;threshold，则减小步长\\(T\\)，重试。 隐式欧拉方法\n\\[x_{t+\\Delta t}=x_t+\\Delta t\\dot{x}_{t+\\Delta t}\\\\ \\dot{x}_{t+\\Delta t}=\\dot{x}_t+\\Delta t\\ddot{x}_{t+\\Delta t} \\]\n解这个非线性方程，求出\\(x_{t+\\Delta t},\\dot{x}_{t+\\Delta t}\\)。用求根的算法，例如牛顿迭代法或者下述Runge-Kutta方法。隐式欧拉方法稳定性很好。\nRunge-Kutta 方法\n非常擅长解非线性方程。其中RK4最常被使用。\n首先，我们知道\n\\[\\frac{dy}{dt}=f(t,y),\\quad y(t_0)=y_0 \\]\n则\n\\[y_{n+1}=y_n+\\frac{1}{6}h(k_1+2k_2+2k_3+k_4)\\\\ t_{n+1}=t_n+h \\]\n其中\\(h\\)是步长\n\\[k_1=f(t_n,y_n)\\\\ k_2=f(t_n+h/2,y_n+hk_1/2)\\\\ k_3=f(t_n+h/2,y_n+hk_2/2)\\\\ k_4=f(t_n+h,y_n+hk_3) \\]\n基于位置的方法\n在修正欧拉方法的步长后，约束粒子的位置以防止其不稳定 使用约束位置计算速度 但是这会导致能量损失。\n刚体模拟 和粒子的模拟相似。\n需要考虑转角，角速度等。仍然可以使用欧拉方法。\n流体模拟 基于位置的方法 假设水都是由很多刚体小球组成的。\n假设水是不可压缩的。\n拉格朗日方法和欧拉方法 对于处理大量的物体\n拉格朗日方法是将每个物体看成质点去处理。\n欧拉法发是将空间切分为网格，对格子进行处理。\nMaterial Point Method 混合了欧拉方法和拉格朗日方法。\n正向运动学 关节骨骼模型\n拓扑的（什么连向了什么） 关节的几何关系 树状结构 关节的类型：\n类似于钉子的关节（只有一维旋转） 类似于球的关节（可以在两个维度内旋转） 平移关节 只要提供骨骼的长度和关节旋转的角度，就能知道尖端处于什么位置。\n逆向运动学 控制尖端的位置，然后自动计算合理的关节、骨骼位置。\n有时候解不唯一，并且解很难以求得。\nRigging 类似于提线木偶，也可以说是逆向运动学的一种应用。\n主要是给角色的一些部分以更高级的控件（控制点），可以进行鼠标拖动位置等修改。像是贝赛尔曲线。\n动作捕捉 把现实中的数据应用到Rigging上的操作。\n","date":"2022-08-10T12:54:34+08:00","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%8A%A8%E7%94%BB%E4%B8%8E%E6%A8%A1%E6%8B%9F/","title":"计算机图形学基础学习笔记-动画与模拟"},{"content":"全光函数 \\[P(\\theta,\\phi,\\lambda,t,V_x,V_y,V_z) \\]\n记录了在某个位置，往某个方向看，在某个时间，某种颜色的的光的强度\n其中\\(\\theta,\\phi\\)决定了看的方向，\\(\\lambda\\)决定光的频率，也即颜色，\\(t\\)决定时间，\\(V_x,V_y,V_z\\)决定了相机位置。\n光线 \\[P(\\theta,\\phi,V_x,V_y,V_z) \\]\n五个变量，了，两个描述了方向，三个描述了起点，这样就描述了一条射线。\n在非色散介质中，一个二维的点和一个二维的方向能定义光线。见光场。\n光场 一个物体发出的光可以映射到包围盒上。对于摄影机来说，看到的样子是不会改变的。（实际上应该是映射到和摄像机方向垂直的平面上）\n光场就是在任何一个位置，往任何一个方向去的光的强度。（实际上听上去和光线就是一个意思，只不过可能是将光线由物体表面发出换到了某个等效平面上发出）\n由于三维物体的表面是一个二维的。所以可以从物体表面发出一个二维方向来定义光线。\n好处在于，从任何位置看向这个物体，可以用四个变量得到光的信息。\n另外，可以把包围盒当成一个发光的盒子，看向这个物体直接查询盒子的光场，而不用考虑物体本身。\n如果只采用一个包围盒，则可以用平面上的一个点和其与法线的夹角定义光场。\n如果采用两个包围盒(一大一小，大的包含小的)，可以用两个点来描述光场。对于里面的平面上有一个点\\((u,v)\\)，外面的平面上有一个点\\((s,t)\\)，连接两点就是光场。\n光场相机 普通的透镜相机记录的是Irradiance，而光场相机通过将传感器上的像素替换为透镜，对不同颜色的光进行分光记录，就能够达到记录光场的效果。也就是记录Radiance。\n这样就可以先拍照，在后期处理的时候再聚焦。\n缺点：分辨率不足、成本高。\n可见光光谱 可见光光谱分布在400nm到700nm之间。\n谱功率密度（SPD） 可以通过SPD，描述某种东西发出的光在各个波长上的能量。\n其具有线性性质。可以直接相加。\n颜色的生物学基础 颜色是人的感知，而不是某一波长光的属性。\n视网膜上的感光细胞有两种，一种是棒状的视杆细胞，感觉光的强度。一种是锥形的视锥细胞，感觉光的颜色。视锥细胞要更少一点。\n视锥细胞分为三类：S、M、L；S感知较短波长的光，M感知中间波长的，L感知较长波长的。\n不同的人，三种细胞的分布会不一样，差异有时很大。\n实际上感知到的光，是每个细胞所能感知的波长范围内，每个波长乘以其强度再相加得到的结果（亦或者积分）。总共得到\\(S,M,L\\)三个数传输给大脑。\n同色异谱现象 不同的光谱，其进过积分后得到的三个数可能是相同的，也意味着在人看来是同一个颜色。\n颜色混合 通过将RGB三种颜色加起来来获得其他颜色。\n颜色空间 标准RGB 先让一个机器做好，其他机器以此为标准 广泛采用 色域有限 Gamut（色域） Gamut是一个原色集生成的所有色度。\n不同的颜色空间表示不同范围的颜色，同时也就具有不同的色域。\nHSV 由色调（各种颜色）、饱和度（决定接近白色还是接近某个特定颜色）和亮度组成\n","date":"2022-08-09T12:14:21+08:00","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%89%E5%9C%BA%E9%A2%9C%E8%89%B2%E5%92%8C%E6%84%9F%E7%9F%A5/","title":"计算机图形学基础学习笔记-光场、颜色和感知"},{"content":"小孔成像 和初中介绍的一致。以此原理做成的相机叫做针孔相机。\n透镜成像 通过透镜进行成像，和初中介绍的一致。现在大多数相机都是透镜成像的。\n快门 控制曝光时间。\n运动模糊 在快门打开的时间内，物体已经发生了明显移动（或者相机动了），就会导致模糊。\n果冻效应 如果某个物体的运动速度非常快，在快门时间内曝光就会产生扭曲效果。仅存在于卷帘快门相机中。\n传感器 捕捉光，并记录的部件。记录的实际上是Irradiance。\n为什么不能用传感器直接收集光，而非要加一个透镜？\n因为传感器上的每一个点都会采集物体上每一个点发出的光，然后所有的像素就会因此变得相似。换言之因为传感器记录的是Irradiance\n针孔相机 没有深度可言，换言之，每个区域都是清晰地。而不像透镜相机，会出现景深效果等等。而光线追踪是以针孔相机的模型来做的，也不会得到景深效果。\n视场(FOV,Field of View) 设传感器的垂直长度为\\(h\\)，透镜到传感器的距离为\\(f\\)，则\n\\[FOV=2arctan\\left(\\frac{h}{2f}\\right) \\]\n由此定义了垂直FOV。同理可以定义水平FOV。\n通常，以35mm格式的胶片为传感器标准大小，通过焦距的不同得到不同的FOV。\n例如17mm的胶片FOV是104°，50mm的是47°，200mm的是12°。\n但是对于手机摄像机，传感器并不是35mm格式的，要经过等效来换算焦距。\n当视场越窄，看到的东西越远。\n当然传感器尺寸也会影响FOV。想要保持FOV而减小传感器尺寸，则焦距也要变小。\n曝光 \\[H=T\\times E\\\\ Exposure = time\\times irradiance \\]\n其中time由快门控制，irradiance由物体自己和光圈控制。\n总结，物体亮度，或者说曝光由以下东西控制：\n光圈大小 快门速度 ISO增益，这是后期的处理，而不是原始的数据。有软件和硬件的实现。 光圈 F-Number 描述光圈的大小。通常写作FN或F/N。\n一个不太正式的理解，N是直径的倒数。N越大，光圈越小。\n景深 成像最锐利的点在像距平面上，但是传感器的平面并不总会在像距上，因此会导致模糊。\n理论上，物距上一个点发出的光会在像距上形成一个点，但是如果传感器不在像距上，像就会在传感器上形成一个圈（CoC）。\n设光圈直径为\\(A\\)，CoC直径为\\(C\\)，像距为\\(z_i\\)，透镜到传感器的距离为\\(z_s\\)，则有\n\\[\\frac{C}{A}=\\frac{|z_s-z_i|}{z_i} \\]\n而通常我们改变的是光圈大小，也即，大光圈导致模糊，小光圈成像清晰。\nF-Number的明确定义：焦距除以光圈直径。\n所以有\n\\[C=A\\frac{|z_s-z_i|}{z_i}=\\frac{f}{N}\\frac{|z_s-z_i|}{z_i} \\]\n如果CoC足够小，从相机中还是不容易看得出模糊。也就是说在CoC的一小个范围内，成像都是清晰的。这也对应了一个距离，称为Depth of focus。也可以知道物体能够清晰成像的距离范围，称为Depth of field。\n高速摄影 非常快的快门时间。也会因此降低亮度。为了抵消这种影响，就需要用更大的光圈，或者用ISO。\n低速摄影 非常慢的快门时间。可以出现“拉丝效果”。\n透镜 理想薄凸透镜 物距\\(z_o\\)，像距\\(z_i\\)，焦距\\(f\\)有如下关系\n\\[\\frac{1}{f}=\\frac{1}{z_i}+\\frac{1}{z_o} \\]\n模拟薄凸透镜的光线追踪 初始化：\n定义传感器大小，定义凸透镜的焦距、光圈大小。 设置物距，并计算像距。 渲染：\n对传感器上的每个像素x' 随机在透镜上选择点x'' 通过凸透镜定理得到物距平面上的点x\u0026rsquo;'' 计算x\u0026rsquo;\u0026rsquo;-\u0026gt;x\u0026rsquo;\u0026lsquo;\u0026lsquo;上的Radiance ","date":"2022-08-08T12:12:03+08:00","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%9B%B8%E6%9C%BA%E4%B8%8E%E9%80%8F%E9%95%9C/","title":"计算机图形学基础学习笔记-相机与透镜"},{"content":"非表面模型 参与介质(Participating Media) 例如云、雾等。\n其中的小晶体、小分子等会吸收光、反射光等。\n使用相位函数(Phase Function)来描述如何反射等。\n渲染思路：\n随机选择一个方向来反射 随机选择一个距离来传播 在每个反射点来连接光源进行着色 头发材质 Kajiya-Kay 模型\n效果不是很好，只考虑了头发上的反射。\nMarschner 模型\n广泛应用，更进一步地考虑了光线透过头发。\n但是这个模型不能很好地表现动物毛发。\n这个模型将头发认为是有颜色的实心圆柱体。\n但实际上头发中不是均一的某种物质，其中还有一个更小的圆柱体含有髓质。头发的髓质较少，但是其他毛发的髓质较多。\n双圆柱模型\n同上文描述，即考虑了髓质的存在。\n颗粒(Granular)材质 例如盐、白砂糖、米、沙子等。\n表面模型 半透明(Translucent)材质 例如玉石、水母等。\n次表面反射\n也就是，在材质内部反射，然后从某个方向离开表面。\nBSSRDF：作为BRDF的延伸，决定了光从某个方向进来，某个点进来，某个方向出去，某个点出去时光照。也会改变渲染方程。\nDipole Approximation\n通过在物体内部加一个虚拟光源来达到次表面反射的效果\n布料 可以当做表面来渲染，用BRDF进行。\n也可以当做参与介质来渲染，效果比当做平面要好，但是慢。\n也可以直接暴力地将每一根纤维渲染出来，类似头发，效果好，速度慢。\n有细节的材质 例如遍布金属表面的小划痕。\n可以用法线贴图，以及微表面模型来渲染，虽然效果很好，但是十分的慢。\n解决办法：在像素意义上使用BRDF。\n有时候，物体表面反射出来的是各种颜色。例如照射一块铝片，反射出来的宏观上是银色，但是细细的观察会发现有很多不同的颜色。这需要波动光学的帮助。\n程序化生成表面 不用纹理而是用一个噪声函数定义表面。\n可以生成地形、木纹、铁锈等等。\n","date":"2022-08-07T15:46:35+08:00","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E7%BA%A7%E5%A4%96%E8%A7%82%E6%A8%A1%E5%9E%8B/","title":"计算机图形学基础学习笔记-高级外观模型"},{"content":"无偏差(Unbiased)光传播方法 无偏差的蒙特卡洛方法不会造成任何系统误差。其求出的期望值永远会是正确的值，无论有多少采样点。\n双向路径追踪(Bidirectional Path Tracing, BDPT) 即通过从相机和光同时发出光线，然后让其在某一表面相遇的办法。\n如果光源发出的光传播很复杂，比如一束光直接达到天花板来照亮整个环境。那么双向的效果会比单向的好。\n问题在于实现困难和速度较慢。\nMetropolis光传播(MLT) 在蒙特卡洛积分中使用马尔科夫链。从当前样本估计周围的样本。\n给一条路径可以生成很多相似的路径。以处理局部光路复杂的情况。例如镜面反射-漫反射-镜面反射的情况。\n问题在于：难以估计收敛速度；每个像素的收敛速度不同，导致图面比较脏；不适合用于动画渲染。\n有偏差(Biased)光传播方法 有偏差的蒙特卡洛方法，其期望值随着采样点的增加会趋向正确的值。\n光子映射 特别适合处理镜面反射-漫反射-镜面反射的情况，以及生成焦散线(Caustics)，或者说由于聚焦作用形成的各种图案。\n有众多实现办法，其中一种：\n从光源处射出光子，经过各种反射、折射，直到打到漫反射材料，并记录。 从摄像机射出路径，经过各种反射、折射，直到打到漫反射材料，并记录。 对第二次打到的点，取周围的最近的\\(n\\)个光子，算其密度，来计算亮度。 其有偏的原因是\n\\[\\frac{dN}{dA}\\neq\\frac{\\Delta N}{\\Delta A} \\]\n当光子趋近于无限时，上式趋于相等。\n\\(N\\)比较小时，图片有很多噪声。\\(N\\)比较大时，图片比较模糊。如果足够多，就可以收敛到不模糊的结果。\nVertex Connection and Merging 其实就是双向路径追踪和光子映射的结合。\n实时辐射度 有时也叫做多光源方法。\n光源发出来的光线，打到某些地方，则把这些地方看做新的光源。\n渲染场景时将这些虚拟光源看作是光源。\n好处是：速度快，并且对于漫反射处理比较好。\n问题是：有些地方莫名的会发光；不 能做金属材质（Glossy）的渲染。\n","date":"2022-08-07T14:57:59+08:00","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E7%BA%A7%E5%85%89%E7%BA%BF%E4%BC%A0%E6%92%AD/","title":"计算机图形学基础学习笔记-高级光线传播"},{"content":"题意：有\\(N\\)个方块，初始时站在\\(1\\)方块上。每个方块上有一个数\\(a_i\\)，等概率地随机选一个\\(0\\sim a_i\\)的数，假设在\\(x\\)方块上选到了\\(y\\)，则跳到\\(x+y\\)方块。求跳到\\(N\\)上时，选取次数的期望值。\n设\\(dp[i]\\)是从\\(i\\)走到\\(N\\)的期望，那么\\(dp[N]=0\\)。\n记\n\\[s = dp[i+1]+dp[i+2]+\\cdots+dp[i+a_i] \\]\n然后有\n\\[dp[i] = \\frac{s+a_i}{a_i+1}+\\frac{1}{a_i+1}\\left(\\frac{s+2a_i}{a_i+1}\\right)+\\cdots \\]\n\\[=\\sum_{n=1}^\\infty\\left(\\frac{1}{a_i+1}\\right)^{n-1}\\left(\\frac{s+na_i}{a_i+1}\\right) \\]\n\\[=\\sum_{n=1}^\\infty\\frac{s}{(a_i+1)^n}+\\sum_{n=1}^\\infty\\frac{na_i}{(a_i+1)^{n}} \\]\n\\[=\\frac{s}{1-\\frac{1}{a_i+1}}-s+1+\\frac{1}{a_i} \\]\n\\[=\\frac{s+1}{a_i}+1 \\]\n最终\n\\[dp[i]=\\frac{dp[i+1]+dp[i+2]+\\cdots+dp[i+a_i]+1+a_i}{a_i} \\]\n其中\\(s\\)可以用前缀和优化。\n\\[\\frac{s+a_i}{a_i+1}=\\frac{dp[i+1]+1+dp[i+2]+1+\\cdots+dp[i+a_i]+1}{a_i+1} \\]\n其实就是非常朴素的选择次数除以概率再相加。然后如果某一次选中了0就再往下算。\n最终的代码如下\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cmath\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;map\u0026gt; #include \u0026lt;set\u0026gt; #include \u0026lt;queue\u0026gt; #include \u0026lt;stack\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;cstdint\u0026gt; #include \u0026lt;cstdio\u0026gt; #include \u0026lt;bitset\u0026gt; #include \u0026lt;deque\u0026gt; #define LL long long #define ULL unsigned long long #define i128 __int128 #define debug(a) std::cout\u0026lt;\u0026lt;#a\u0026lt;\u0026lt;\u0026#34;=\u0026#34;\u0026lt;\u0026lt;a\u0026lt;\u0026lt;std::endl #define lth(i,x,y) for(int i=x;i\u0026lt;=y;i++) #define htl(i,x,y) for(int i=x;i\u0026gt;=y;i--) #define mms(x) memset(x, 0, sizeof(x)) const int MAXN = 200005; const int INF = 0x7fffffff; const double EPS = 1e-8; const int MOD = 998244353; const double PI = acos(-1); LL arr[MAXN]; LL inv[MAXN]; LL sum[MAXN]; LL dp[MAXN]; LL qPowMod(LL a, LL n, LL b){ LL ans = 1; while(n){ if(n\u0026amp;1){ ans = ans%b*a%b; } a = a%b*a%b; n\u0026gt;\u0026gt;=1; } return ans; } LL fermat_inv(LL a, LL b){ return qPowMod(a,b-2,b); } void init(int n){ for(int i=1;i\u0026lt;=n;i++){ inv[i] = fermat_inv(i,MOD); } } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n; std::cin\u0026gt;\u0026gt;n; init(n); for(int i=1;i\u0026lt;=n-1;i++){ std::cin\u0026gt;\u0026gt;arr[i]; } dp[n] = 0; sum[n] = 0; for(int i=n-1;i\u0026gt;=1;i--){ dp[i] = (((sum[i+1]-sum[i+arr[i]+1]+arr[i]+1+MOD)%MOD)*(inv[arr[i]]%MOD))%MOD; sum[i] = (sum[i+1]+dp[i])%MOD; } std::cout\u0026lt;\u0026lt;dp[1]\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 其中第74行的\ndp[i] = (((sum[i+1]-sum[i+arr[i]+1]+arr[i]+1+MOD)%MOD)*(inv[arr[i]]%MOD))%MOD; 不能写为\ndp[i] = (((sum[i+1]-sum[i+arr[i]+1]+arr[i]+1)%MOD)*(inv[arr[i]]%MOD))%MOD; 原因应当是，会出现负数。虽然按照原本的想法，sum[i+1]肯定是大于等于sum[i+arr[i]]。但是sum本身也在进行取余运算，可能会导致小于的情况，导致负数的出现。此时要加一个998244353。\n","date":"2022-08-07T12:57:17+08:00","permalink":"https://kegalas.top/p/atcoder-beginner-conteset-263-e%E6%A6%82%E7%8E%87dp/","title":"Atcoder Beginner Conteset 263 E（概率DP）"},{"content":" 注：本文内容可能不再推荐使用，因为pandoc无法生成正确的代码高亮，也没有更多的参数可以选择。并且添加目录的方式比较DIY，而我本人暂时不会Go语言相关的东西，无法进一步跟进官方版本的更新。\n现在推荐去给Hugo默认的goldmark引擎添加mathjax支持。\n详情见这篇文章为hugo安装goldmark-mathjax插件来更好地支持输入公式\n根据https://github.com/olOwOlo/hugo-theme-even/issues/139，hugo无法正确生成目录的原因是，没有加入\u0026ndash;toc参数。\n其中@jdhao所说的https://github.com/gohugoio/hugo/blob/master/helpers/content.go#L735这一部分代码现在（编辑日期时）已经转移到了https://github.com/gohugoio/hugo/blob/master/markup/pandoc/convert.go#L67。按他的办法来说应该改成\nargs := []string{\u0026#34;--mathjax\u0026#34;,\u0026#34;--toc\u0026#34;} 实际上并没有那么简单，即使是加入了\u0026ndash;toc参数也不能生成目录。笔者又找到一份他人修改的版本https://github.com/bigshans/hugo。这个版本的convert.go明显是修改过的，能够正确生成目录。\n将其克隆、编译，然后替换掉原来的hugo.exe。经测试可以正常使用。目前发现的唯一可以称得上是一个问题的是，代码没有高亮。\n编译方法见hugo的github readme。\n如果因为网络问题无法编译，可以给powershell设置代理，见之前的文章。\n如果cgo exit status 2，那么可能是g++的问题，笔者的电脑上g++是msys2滚动更新的，更换为8.1.0版本成功编译了。（后注：要区分msys环境和mingw64环境，见这篇文章MSYS2,MinGW64,Cygwin的使用区别浅谈）\n","date":"2022-08-06T16:41:53+08:00","permalink":"https://kegalas.top/p/%E9%87%8D%E6%96%B0%E7%BC%96%E8%AF%91hugo%E6%9D%A5%E4%BD%BF%E5%BE%97pandoc%E5%8F%AF%E4%BB%A5%E7%94%9F%E6%88%90%E7%9B%AE%E5%BD%95/","title":"重新编译hugo来使得pandoc可以生成目录"},{"content":"通常，v2rayN设置中的ip是127.0.0.1，http协议的端口是10809，在PowerShell中临时使用代理，需要输入如下命令\n$env:HTTP_PROXY=\u0026#34;http://127.0.0.1:10809\u0026#34;\r$env:HTTPS_PROXY=\u0026#34;http://127.0.0.1:10809\u0026#34; 之后输入\ncurl www.google.com 来检验是否成功。如果v2rayN本身是能够连接到谷歌的，那么得到的结果应该类似于下方：\nStatusCode : 200\rStatusDescription : OK\rContent : \u0026lt;!doctype html\u0026gt;\u0026lt;html itemscope=\u0026#34;\u0026#34; itemtype=\u0026#34;http://schema.org/WebPage\u0026#34; lang=\u0026#34;en\u0026#34;\u0026gt;\u0026lt;head\u0026gt;\u0026lt;meta conten\rt=\u0026#34;Search the world\u0026#39;s information, including webpages, images, videos and more. Google has many spe\rci...\rRawContent : HTTP/1.1 200 OK\r...... 另外不要使用ping命令去测试，虽然不明原因但是确实无法ping到谷歌。\n","date":"2022-08-06T16:33:44+08:00","permalink":"https://kegalas.top/p/%E5%9C%A8powershell%E4%B8%AD%E4%BD%BF%E7%94%A8v2rayn%E4%BB%A3%E7%90%86/","title":"在PowerShell中使用v2rayN代理"},{"content":"材质 某种意义上来说，材质就是决定双向反射分布函数(BRDF)的东西。\n漫反射材质 漫反射，代表着光均匀地反射到每一个方向。\n假设入射光也是均匀的。\n则\\(f_r,L_i(\\omega_i)\\)就是常数。那么渲染方程：\n\\[L_o(\\omega_o)=\\int_{H^2}f_rL_i(\\omega_i)cos\\theta_i d\\omega_i \\]\n\\[=f_rL_i\\int_{H^2}cos\\theta_i d\\omega_i \\]\n\\[=\\pi f_rL_i \\]\n所以有\n\\[f_r=\\frac{\\rho}{\\pi} \\]\n其中\\(\\rho\\)是反射率。\n有光泽的(Glossy)材质 金属材质是一类，金属材质的反射较为集中，但又不是镜子那样的镜面反射。\n折射材质 有时会有像玻璃这样的材质，既有反射又有折射。\n反射定律 反射角\\(\\theta_o\\)等于入射角\\(\\theta_i\\)。\\(\\theta=\\theta_o=\\theta_i\\)\n并且反射光线和入射光线在同一平面呢。\n或者入射光线的立体角\\(\\omega_i\\)与反射光线的立体角\\(\\omega_o\\)与反射面的法单位向量\\(\\bm n\\)之间的关系是\n\\[\\omega_i+\\omega_o=2cos\\theta\\cdot\\bm n \\]\n折射定律 入射角\\(\\theta_i\\)、入射材质的折射率\\(\\eta_i\\)和折射角\\(\\theta_t\\)、折射材质的折射率\\(\\eta_t\\)有如下关系\n\\[\\eta_i sin\\theta_i=\\eta_t sin\\theta_t \\]\n并且入射光线和折射光线在同一平面内。\n如果发生全反射，要从光密介质射到光疏介质里。并且因为：\n\\[cos\\theta_t=\\sqrt{1-sin^2\\theta_t}=\\sqrt{1-\\left(\\frac{n_i}{n_t}\\right)^2sin^2\\theta_i} \\]\n所以全反射时满足\n\\[1-\\left(\\frac{n_i}{n_t}\\right)^2sin^2\\theta_i\u003c0 \\]\n菲涅尔反射 经常观察到一些现象，比如木桌子上，低角度看过去有反射，高角度看过去没有反射。或者正对玻璃能看到外面，斜对着玻璃可能只能看到反射。\n这说明反射率和入射角有关。实际上这和光的偏振有关。\n一定功率的入射光被界面反射的比例称为反射比\\(R\\)；折射的比例称为透射比\\(T\\)。有\n\\[R+T=1 \\]\n如果入射光的电矢量垂直于光平面（由入射、反射、折射光线构成的平面）（即\\(s\\)偏振），则反射比为：\n\\[R_s=\\left[\\frac{sin(\\theta_t-\\theta_i)}{sin(\\theta_t+\\theta_i)}\\right]^2 \\]\n如果入射光的电矢量在光平面内（即\\(p\\)偏振），反射比为：\n\\[R_p=\\left[\\frac{tan(\\theta_t-\\theta_i)}{tan(\\theta_t+\\theta_i)}\\right]^2 \\]\n这两个式子都可以用折射定律和三角恒等式展开。透射比无论如何都满足\\(T=1-R\\)\n如果入射光是无偏振的，即含有等量的\\(s,p\\)偏振，那么\n\\[R=\\frac{R_s+R_p}{2} \\]\n显然近垂直入射时\n\\[R=\\left(\\frac{n_i-n_t}{n_i+n_t}\\right)^2 \\]\n在图形学中，这个计算过于麻烦，通常会采用Schlick近似\n\\[R(\\theta)=R_0+(1-R_0)(1-cos\\theta)^5 \\]\n\\[R_0=\\left(\\frac{n_i-n_t}{n_i+n_t}\\right)^2 \\]\n微表面材质 假设物体表面是粗糙的。从远处看是平的、粗糙的；从近处看能看到凹凸不平，每一个小平面都是镜面反射。\n如果没有凹凸，则是镜面材质。\n如果凹凸变化不是很剧烈（法线分布比较均匀），那么会得到一个Glossy的材质。\n如果凹凸变化的比较剧烈（法线分布不均匀），那么会得到一个漫反射材质。\n微表面材质的BRDF可以如下写\n设\\(\\omega_i\\)是入射光线的立体角，\\(\\omega_o\\)是反射光线的立体角，\\(h\\)是它们的半程向量。\\(n\\)是宏观表面的法向量，则\n\\[f_r(\\omega_i,\\omega_o)=\\frac{F(w_i,h)G(\\omega_i,\\omega_o,h)D(h)}{4(n\\cdot\\omega_i)(n\\cdot\\omega_o)} \\]\n其中\\(F\\)是菲涅尔项；\\(G\\)是几何项（阴影遮挡函数），光线可能会被微平面互相遮挡而影响，所以引入此函数；\\(D\\)是微表面分布函数，决定了有多少微表面的法线朝向\\(h\\)\n各向同性/异性材料 各向异性的材料，由于观察的方位角不同，BRDF不同（即使入射角和反射角相对不变）。\nBRDF的性质 非负\n\\[f_r\\geq 0 \\]\n线性性质\n可以把各个方向的BRDF加起来，得到的结果和对这些方向和的BRDF一样。反之也可以拆分BRDF。\n可逆性\n\\[f_r(\\omega_r\\to\\omega_i)=f_r(\\omega_i\\to\\omega_r) \\]\n能量守恒\n能量不会变多，如果物体没有吸收，那么入射多少就会反射多少。\n对于各向同性材质\nBRDF与方位角无关；方位角指的是光线投影到材质平面上，在材质平面上的角。\nBRDF的测量 由于图形学中的公式有估计的成分，BRDF可能与实际值相差很大，有时会用到测量的办法。\n","date":"2022-08-06T10:57:51+08:00","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%89%A9%E4%BD%93%E6%9D%90%E8%B4%A8/","title":"计算机图形学基础学习笔记-物体材质"},{"content":"为什么需要光线追踪 光栅化不能很好地处理全局效果。例如软阴影，以及光照的多次反射。\n虽然光栅化很快，但是质量不非常好、不真实。\n相比之下光线追踪效果会好很多，但是也非常慢。在过去算力不发达的时候，光栅化是一个实时的算法，而光线追踪是一个离线的算法。\n基础的光线追踪算法 光线投射 对每一个像素投射一条光线来生成一张图 对光源发射一条光线来检查阴影 Pinhole Camera Model\n首先从眼睛，或者说相机发出一条光线，穿过图像平面上的一个像素。然后和空间中的一个物体边缘相交。当然可以和一个物体多次、或者和多个物体相交，我们需要的是最近的。\n然后对最近的这个交点进行着色计算。例如使用Blinn-Phong模型。\nRecursive(Whitted-Style) Ray Tracing\n仍然从相机发出一条光线，穿过图像平面上的一个像素。然后和空间中的一个物体边缘相交。当然，如果是较为镜面的物体，会继续反射光线的路径和下一个物体边缘相交。直到不出现镜面反射。如果是玻璃等透射物质，则要沿着折射光线继续，直到不透明物体。\n光线的数学表示 光线由光源点和方向向量表示。\n\\[\\bm r(t) = \\bm o+t\\bm d\\quad 0\\leq t\u003c\\infty \\]\n其中\\(t\\)是时间，\\(\\bm o\\)是光源向量，\\(\\bm d\\)是方向向量。\n光线相交 对于隐式表示的物体\n判断是否相交，例如一个球面：\n\\[(\\bm{p}-\\bm{c})^2-R^2=0 \\]\n其中\\(\\bm p\\)是球面上的点，\\(\\bm c\\)是球心，和\n\\[\\bm r(t) = \\bm o+t\\bm d\\quad 0\\leq t\u003c\\infty \\]\n相交，则要满足\n\\[(\\bm o+t\\bm d-\\bm c)^2-R^2=0 \\]\n只有\\(t\\)一个未知数，解即可。\n其他的隐式表示的，或者说用代数形式表示的物体都可以这么判断相交。\n对于三角形网格\n首先，三角形一定能够确定一个平面。所以先判断光线和平面的相交，以及计算交点。再计算交点是否在三角形内。\n一个平面可以表述为上面的一点和平面的法向量。\n所有在平面上的点满足如下等式\n\\[(\\bm p-\\bm p')\\cdot \\bm N = 0 \\]\n其中，\\(\\bm p'\\)是平面上已知一点，\\(\\bm N\\)是平面法向量。\n判断光线和平面的交点：\n和\n\\[\\bm r(t) = \\bm o+t\\bm d\\quad 0\\leq t\u003c\\infty \\]\n联立，得\n\\[(\\bm o+t\\bm d-\\bm p')\\cdot \\bm N = 0 \\]\n解得\n\\[t = \\frac{(\\bm p'-\\bm o)\\cdot \\bm N}{\\bm d\\cdot\\bm N} \\]\n应确保\\(0\\leq t\u003c\\infty\\)\n直接计算出交点重心坐标的方法\nMoller Trumbore Algorithm:\n\\[\\bm O+t\\bm D = (1-b_1-b_2)\\bm P_0+b_1\\bm P_1+b_2\\bm P_2 \\]\n\\[\\begin{bmatrix} t \\\\ b_1 \\\\ b_2 \\end{bmatrix}= \\frac{1}{\\bm S_1\\cdot\\bm E_1} \\begin{bmatrix} \\bm S_2\\cdot\\bm E_2 \\\\ \\bm S_1\\cdot\\bm S \\\\ \\bm S_2\\cdot\\bm D \\end{bmatrix} \\]\n其中：\n\\[\\bm E_1=\\bm P_1 - \\bm P_0 \\]\n\\[\\bm E_2=\\bm P_2 - \\bm P_0 \\]\n\\[\\bm S=\\bm O - \\bm P_0 \\]\n\\[\\bm S_1=\\bm D \\times \\bm E _2 \\]\n\\[\\bm S_2=\\bm S \\times \\bm E _1 \\]\n光线追踪加速 包围盒 一个物体被完整地包含在一个长方体中，这个长方体称之为包围盒。有时有多个物体在内。\n显然如果光线没有击中包围盒，光线也就不会击中物体。\n由于长方体的六个面确定了六个平面，长方体又可以看作是三组平行平面的交叉。\n我们通常会使用轴对齐的包围盒。即三组平面都平行于坐标面。\n对每一组平面都求光线和其交点，都会求出一个近点和远点。将三组近点和远点比较，求出最远的近点和最近的远点，就是和包围盒的交点。当然同时注意\\(t\\geq 0\\)\n使用轴对齐的包围盒可以减少算法常数\n例如对齐x轴时\n\\[t = \\frac{(\\bm p'-\\bm o)\\cdot \\bm N}{\\bm d\\cdot\\bm N}=\\frac{\\bm p'_x-\\bm o_x}{\\bm d_x} \\]\n空间均匀分割 找到一块区域，均匀地划分成正方形（三维情况为正方体）网格。在每个网格记录物体边缘的重叠情况。\n对于光线穿过的每个网格中，枚举和网格有交集的所有物体，检测是否和光线相交。\n网格划分太少，则很难于无划分区分开来。划分太多，则会有很多和网格的计算。\n一个启发式的算法是，网格数等于C乘以物体数。在三维中C为27.\n处理较好的情况是，有很多物体的情况。而处理不好的情况是，一个体育馆中心有一个茶壶等类似情况时。\n不均匀的分割 见数据结构笔记KD-Tree。\n下面讲解光线和KD-Tree中的小空间的相交处理。\n首先从根节点开始。光线首先会和根节点表述的空间有两个交点。\n然后判断和两个子节点是否有相交。如果没有则忽略。如果有，则持续往下分割。直到没有子节点，就判断小空间内的物体是否和光线相交。\n层次包围盒(BVH) 见数据结构笔记。\n辐射度量学 辐射能量 辐射能量是电磁辐射的能量。以焦耳（J）做单位，\\(Q\\)为符号。\n辐射通量(Radiant Flux) 辐射通量是每单位时间接收、发射、反射、传输的能量。\n\\[\\Phi\\equiv\\frac{dQ}{dt} \\]\n单位是瓦特（W），或流明（lm）。\n但流明和瓦特略有不同，流明作为光通量的单位，只考虑了可见光的通量，而瓦特作为辐射通量考虑了电磁波的全部通量。\n辐射强度(Radiant Intensity) 辐射强度是每单位立体角所能从点光源接收到的辐射通量。\n\\[I(\\omega)\\equiv\\frac{d\\Phi}{d\\omega} \\]\n对于可见光单位是坎德拉（cd），对于一般电磁波是\\(W/sr\\)。\n立体角 圆的角：\n\\[\\theta = \\frac{l}{r} \\]\n其中\\(l\\)是弧长，以弧度制计算，总共有\\(2\\pi\\)\n对于球体的立体角\n\\[\\Omega = \\frac{A}{r^2} \\]\n其中\\(A\\)是球面上的面积，以弧度制计算，总共有\\(4\\pi\\)\n其微分如下\n\\[dA=(rd\\theta)(rsin\\theta d\\phi)=r^2sin\\theta d\\theta d\\phi \\]\n其中\\(\\theta\\)是与\\(z\\)轴的夹角，\\(\\theta\\)是与\\(x\\)轴的夹角。\n\\[d\\omega=\\frac{dA}{r^2}=sin\\theta d\\theta d\\phi \\]\n所以有\n\\[\\Phi = \\int_{S^2}Id\\omega=4\\pi I \\]\n\\[I = \\frac{\\Phi}{4\\pi} \\]\n从实践上来看，立体角是一个单位向量\n辐射通量密度、辐照度(Irradiance) 指辐射通量对每单位面积的量，注意传播方向，或者分量传播方向与那个单位平面垂直。或者说每投影单位面积。\n\\[E(x)\\equiv\\frac{d\\Phi(x)}{dA} \\]\n对于可见光，单位为\\(lm/m^2=lux\\)，对于一般电磁波，单位为\\(W/m^2\\)\n要求传播方向与平面垂直，和前面提到的Lambert\u0026rsquo;s Cosine Law是相应的。\n辐射率(Radiance) 是辐射强度对于每投影单位面积的量。\n\\[L(p,\\omega) = \\frac{d^2\\Phi(p,\\omega)}{d\\omega dAcso\\theta} \\]\n其中\\(\\theta\\)是传播方向与平面法线的夹角。\n对于可见光，单位是\\(cd/m^2=lm/(sr\\cdot m^2)=nit\\)。对于一般电磁波，单位是\\(W/(sr\\cdot m^2)\\)\n显然可以推断出，辐射率是辐射通量在每立体角和每投影面积的量，也是辐照度每立体角的量。\n入射辐射率(Incident Radiance) 是辐射度对每单位立体角的量，其中辐射是到达平面。\n\\[L(p,\\omega)=\\frac{dE(p)}{d\\omega cos\\theta} \\]\n出射辐射率(Exiting Radiance) 是辐射强度对每单位投影面积的量，其中辐射是从平面发出\n\\[L(p,\\omega) = \\frac{dI(p,\\omega)}{dAcos\\theta} \\]\nRadiance和Irradiance \\[dE(p,\\omega) = L_i(p,\\omega)cos\\theta d\\omega \\]\n\\(dE(p,\\omega)\\)，指的就是每个立体角的Irradiance，也即\\(dA\\)接收到\\(d\\omega\\)发来的能量。而计算各个方向上的\\(dE\\)之和，算出来的就是Radiance，也即\\(dA\\)从各个方向接收的能量。这个各个方向通常指的是单位半球的各个立体角。单位半球记作\\(H^2\\)。\n\\[E(p)=\\int_{H^2}L_i(p,\\omega)cos\\theta d\\omega \\]\n双向反射分布函数(Bidirectional Reflectance Distribution Function) 在某一点的反射过程 首先，从某个立体角\\(\\omega_i\\)射过来的Radiance，变为了某个面积\\(dA\\)的能量。\n然后，这个能量从这个面积再辐射出Radiance到任意其他立体角\\(\\omega\\)\n入射的Radiance是\\(dE(\\omega_i)=L(\\omega_i)cos\\theta(i)d\\omega_i\\)\n出射的Radiance，对于某个立体角是\\(dL_r(\\omega_r)\\)\n而BRDF就是描述了，会有多少光从每个入射光线，反射到某个立体角\\(\\omega_r\\)。\n\\[f_r(\\omega_i\\to\\omega_r)=\\frac{dL_r(\\omega_r)}{dE_i(\\omega_i)}=\\frac{dL_r(\\omega_r)}{L(\\omega_i)cos\\theta(i)d\\omega_i} \\]\n单位是\\(1/sr\\)\n反射方程 \\[L_r(p,\\omega_r)=\\int_{H^2}f_r(p,\\omega_i\\to\\omega_r)L_i(p,\\omega_i)cos\\theta_i d\\omega_i \\]\n这个方程会遇到一些问题：如果入射光也有其他物体的反射光，会导致递归方程。\n渲染方程 如果一个物体自己会发光，反射方程需要添加一项。\n\\[L_o(p,\\omega_o)=L_e(p,\\omega_o)\\\\ +\\int_{\\Omega^+}L_i(p,\\omega_i)f_r(p,\\omega_i,\\omega_o)(n\\cdot w_i) d\\omega_i \\]\n简化的写法可以写作\n\\[L(u)=e(u)+\\int L(v)K(u,v)dv \\]\n再进一步可以写作算子形式\nL = E+KL\n可以被离散化成一个简单的矩阵方程，\\(L,E\\)是向量，\\(K\\)是光传播矩阵。\n如果考虑物体的反射作为新的入射光线，就会导致递归方程。将算子做如下运算\n\\[L=E+KL\\\\ (I-K)L=E\\\\ L=(I-K)^{-1}E \\]\n将中间的\\((I-K)^{-1}\\)展开成幂级数\n\\[L=(I+K+K^2+K^3+\\cdots)E\\\\ L=E+KE+K^2E+K^3E+\\cdots \\]\n其中第一项代表光源直接射过来的光，第二项表示光源经过一次反射过来的光，第三项表示光源经过一次反射过来的光。以此类推。这也是全局光照的基础。\n路径追踪 Whitted-Style Ray Tracing的错误之处：无法正确处理略有磨砂感的金属表面，无法正确处理漫反射。\n但是渲染方程是正确的。但缺陷是，要在半球面上解定积分，以及有递归运算。\n一个简单情况下的蒙特卡罗积分 假设我们要渲染一个像素(点)，只考虑直接照射的光线。假设这个点不发光。渲染方程如下：\n\\[L_o(p,\\omega_o)=\\int_{\\Omega^+}L_i(p,\\omega_i)f_r(p,\\omega_i,\\omega_o)(n\\cdot \\omega_i) d\\omega_i \\]\n蒙特卡洛积分中的\\(f(x)\\)为：\n\\[L_i(p,\\omega_i)f_r(p,\\omega_i,\\omega_o)(n\\cdot \\omega_i) \\]\n蒙特卡洛积分中的pdf是（假设均匀采样）：\n\\[p(\\omega_i)=\\frac{1}{2\\pi} \\]\n所以最终：\n\\[L_o(p,\\omega_o)=\\int_{\\Omega^+}L_i(p,\\omega_i)f_r(p,\\omega_i,\\omega_o)(n\\cdot \\omega_i) d\\omega_i \\]\n\\[\\approx\\frac{1}{N}\\sum_{i=1}^N\\frac{L_i(p,\\omega_i)f_r(p,\\omega_i,\\omega_o)(n\\cdot \\omega_i)}{p(\\omega_i)} \\]\n这对于直接光照来说是一个正确的光栅化算法。\n伪代码如下\nshade(p,wo) Randomly choose N directions wi~pdf Lo=0.0 For each wi Trace a ray r(p,wi) If ray r hit the light Lo+=(1/N)*L_i*f_r*cosine/pdf(wi) Return Lo 全局光照情况下 解决反射导致的光线数量爆炸 间接光照也要考虑的情况下，我们很容易得到一个伪代码：\nshade(p,wo) Randomly choose N directions wi~pdf Lo=0.0 For each wi Trace a ray r(p,wi) If ray r hit the light Lo+=(1/N)*L_i*f_r*cosine/pdf(wi) Else If ray r hit an object at q Lo+=(1/N)*shade(q,-wi)*f_r*cosine/pdf(wi) Return Lo 这会导致一个问题，如果是一个不太光滑的物体，第一次反射后有100个方向的漫反射，一直递归下去，就有\\(100^n\\)条光线，这是不能接受的。而且，显然只有在，反射后只有1个方向的光线时，才不会出现指数爆炸。此时叫做路径追踪。伪代码如下：\nshade(p,wo) Randomly choose ONE directions wi~pdf Trace a ray r(p,wi) If ray r hit the light Return L_i*f_r*cosine/pdf(wi) Else if ray r hit an object at q Return shade(q,-wi)*f_r*cosine*pdf(wi) 如果反射后的光线方向不止一个，那么称作分布式光线追踪，这已经是一个过时的想法了。\n虽然解决了指数爆炸问题，但是，这会导致很多的噪声。\n解决噪声的办法是，对于每一个像素，发出更多的光线，最后取Radiance的平均。伪代码如下\nray_generation(camPos, pixel) Uniformly choose N sample position within the pixel pixel_radiance = 0.0 For each sample in the pixel Shoot a ray r(camPos, cam_to_sample) If ray r hit the scene at p pixel_radiance+=1/N*shade(p,sample_to_cam) Return pixel_radiance 解决光线反射次数无限的问题 多次反射导致指数爆炸的问题解决了，还有一个问题是递归问题。\nshade函数并没有给出明确的函数停止的条件，这会导致无限递归。且粗暴的设定一个硬性条件则会导致能量的丢失。\n有一个俄罗斯转盘（RR）算法。\n之前，我们总是对一个像素射出光线来得到着色结果\\(Lo\\)。\n现在，假设我们手动设定了一个概率\\(P(0\u003c P\u003c1)\\)。\n当我们遇到概率为\\(P\\)的情况时，射出一个光线，并且返回着色结果，再讲这个结果除以\\(P\\)，得到\\(Lo/P\\)\n遇到概率为\\(1-P\\)的情况时，不射出光线，得到的结果为\\(0\\)。\n最后的能量为：\n\\[E=P*(Lo/P)+(1-P)*0=Lo \\]\n伪代码如下\nshade(p,wo) Manually specify a probability P_RR Randomly select ksi in a uniform dist. in[0,1] If (ksi\u0026gt;P_RR) Return 0.0 Randomly choose ONE directions wi~pdf Trace a ray r(p,wi) If ray r hit the light Return L_i*f_r*cosine/pdf(wi)/P_RR Else if ray r hit an object at q Return shade(q,-wi)*f_r*cosine*pdf(wi)/P_RR 提升效率 在着色点上反射光线，如果光源面积很大，则几根光线就可以打到光源。如果光源很小、接近点光源，则要很多光线才能打到。因为我们是均匀地往四周反射光线，或者说，我们的pdf是一个常数。\n可以考虑将在半球上的积分转化为在光源上的积分。\n需要找到\\(d\\omega\\)（半球立体角）和\\(dA\\)（光源上的面积）的关系。\n显然，这是一个投影关系，又因为半球的半径是\\(1\\)，有如下关系\n\\[d\\omega = \\frac{dAcos\\theta'}{||x'-x||^2} \\]\n其中\\(x'\\)是光源微平面的坐标，\\(x\\)是着色点的坐标，\\(\\theta'\\)是光源微平面法向量和\\(x-x'\\)向量的夹角。\n渲染方程重写为\n\\[L_o(x,\\omega_o)= \\int_{\\Omega^+}L_i(x,\\omega_i)f_r(x,\\omega_i,\\omega_o)cos\\theta d\\omega_i\\\\ \\]\n\\[=\\int_A L_i(x,\\omega_i)f_r(x,\\omega_i,\\omega_o)\\frac{cos\\theta cos\\theta'}{||x'-x||^2} dA \\]\n\\(\\theta\\)是着色点微平面的法向量和\\(x'-x\\)向量的夹角。\n蒙特卡洛积分的\\(f(x)\\)变为\n\\[L_i(x,\\omega_i)f_r(x,\\omega_i,\\omega_o)\\frac{cos\\theta cos\\theta'}{||x'-x||^2} \\]\npdf变为\\(1/A\\)\n之后，我们对光源不使用RR，对其他反射使用RR。\n另外，转化为\\(dA\\)后，要考虑中间是否有物体挡住光源。\n最终伪代码如下\nshade(p,wo) # Contribution from the light source. L_dir = 0.0 Uniformly sample the light at x\u0026#39; (pdf_light = 1/A) Shoot a ray from p to x\u0026#39; If the ray is not blocked in the middle L_dir = L_i*f_r*cos1*cos2/|x\u0026#39;-p|^2/pdf_light # Contribution from other reflectors L_indir = 0.0 Test Russian Roulette with probability P_RR Uniformly samplethe hemisphere toward wi(pdf_hemi = 1/2pi) Trace a ray r(p,wi) If ray r hit a non-emitting object at q L_indir = shade(q,-wi)*f_r*cos1/pdf_hemi/P_RR Return L_dir+L_indir ","date":"2022-07-28T17:36:32+08:00","image":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA/cover_huee16c3054c7900bea9817aac8584ab5c_32954_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA/","title":"计算机图形学基础学习笔记-光线追踪"},{"content":"基础乐理部分 和声小调与旋律小调 为了制造导音，和声小调需要在自然小调的基础上升高\\(\\hat{7}\\)音。\n为了加强和声小调的旋律平滑性，旋律小调在上行时需要在和声小调的基础上升高\\(\\hat{6}\\)音，下行时则是在自然小调的基础上不做改动。\n关系大小调的推断 享有共同调号的两个调。\n一个小调的关系大调位于该小调主音上方三个-半音级。反之可以推大调的关系小调。\n平行大小调 享有共同的主音的大小调。\n近关系调 调号只相差一个升号或降号的两个调。也是五度循环圈中相邻的两个调。\n通过调号判断主音 大调意义上，调号中最后一个升号向上半级的音是主音。例如最后一个升号是#F，则主音是G。最后一个升号是#B，则主音是#C。（C大调没有升号，主音C）\n大调意义上，调号中倒数第二个降号是主音。例如调号中有♭B,♭E,♭A,♭D，主音就是♭A。（C大调没有降号，主音C，F大调有一个降号，♭B，主音是F）\n然后可以根据关系大小调推出相应的关系小调。\n音程的协和与不协和 完全协和音程：P1(纯一度),P5,P8\n不完全协和音程：M3（大三度）,m3（小三度）,M6,m6\n不协和音程：各种二度、七度、四度（有时四度是协和的），所有的增、减音程。\n旋律的写作 对于初学者给出了如下建议\n以主三和弦的成分开始（即\\(\\hat{1},\\hat{3},\\hat{5}\\)音），用\\(\\hat{2}-\\hat{1}\\)或\\(\\hat{7}-\\hat{1}\\)结束。这也称为旋律终止。 旋律的音区限制在10度以内，尽量保持基本音域在6度。 旋律进行主要是级进，有时可以小跳（三度）或大跳（四度及以上）。 不要含有太多跳进，最好跳进也不要超过小六度。以三度跳进为主。 不用不协和的跳进，如减四度。和声小调中的\\(\\hat{6}-\\hat{7}\\)是增二度，避免出现。 导音必须上行到主音，除非是\\(\\hat{1}-\\hat{7}-\\hat{6}-\\hat{5}\\)的一部分。 跳进后最好反向进行。 可以连用两个小跳，第二个小跳后变向。 避免反复音与重复音型，或模进（如1-2-3,2-3-4,3-4-5），显得无趣。如果要用应控制次数，最多一次。 旋律应当有拱形，缓慢的抬升到高点，再折返到起点。 关于调性是否有色彩 这不在本书的讨论范围内，但是根据资料搜索，十二平均律使得大调之间以及小调之间的差异被抹除了。(大小调之间（和声小调）由于其和弦性质不同，存在色彩差异。)可以说各大调之间和各小调之间的色彩没有差异。但是乐器可能在各个频率发出的音色是不同的，这在某种情况下确实导致了听感的不同。另外作曲家选择调性时，通常也会考虑到乐器在某个调演奏是否方便，或者歌手的音域是否能够较为轻松的达到。\n音级的别名 \\(\\hat{1}\\)主音，\\(\\hat{2}\\)上主音，\\(\\hat{1}\\)中音，\\(\\hat{4}\\)下属音，\\(\\hat{5}\\)属音，\\(\\hat{6}\\)下中音，\\(\\hat{7}\\)导音，\n拍号 对于简单拍号，\n上方数字 含义 2 每小节两拍 3 每小节三拍 4 每小节四拍 下方数字 含义 2 以二分音符为一拍 4 以四分音符为一拍 8 以八分音符为一拍 以此类推 当我们要用带附点的音符作为一拍时，我们就引入了复拍子\n上方数字 含义 6 每小节两个附点拍 9 每小节三个附点拍 12 每小节四个附点拍 下方数字 含义 2 以三个二分音符为一拍（也就是带附点的全音符） 4 以三个四分音符为一拍（也就是带附点的二分音符） 8 以三个八分音符为一拍（也就是带附点的四分音符） 以此类推 注意到都是三倍关系\n非对称节拍 如果小节中的拍数（上方数字）既不是二的倍数（简单拍子），也不是三的倍数（复拍子），或者小节中的拍数不在上面给出的表中，则可能是非对称节拍。\\({}^5_8\\)可能是3+2，也有可能是2+3，而\\({}^{10}_4\\)经常会是2+3+3+2。注意，有些时候\\({}^9_8\\)拍可能也不是复拍子，而是由2+3+2+2组合而来，看作曲家的标注决定。\n切分 音乐上的重音出现在节奏上非强拍或拍子的弱势部位，称之为切分。\n这里，音乐上的重音，根据我的理解，举个例子，比如使用了重音记号，或者其他让你觉得这里很重的奏法记号。也有可能是乐器在这里突然一起发声。这些叫做音乐上的重音，而节拍上的重音就是指例如四四拍的强、弱、次强、弱。强拍是重音，当然如果把强拍分为两个八分音符，则第一个八分音符是重音，第二个的不是。切分就是在弱势部位放了音乐上的重音。\n三对二 举个例子，四三拍的音乐中，音乐重音是每两拍一个，也就是说，拍子的重音是强、弱、弱、强、弱、弱，强、弱、弱；而音乐重音是强、弱、强、弱、强、弱、强、弱、强。这样的交错形式叫做三对二。\n对位法部分 第一类对位法 规则：\n两声部间只允许P5、P8、M3、m3、M6、m6、P1。不允许P4。 反向进行最具有独立性。平行进行削弱独立性。同向进行能使对位更有效果。为了能在平行进行中尽量多地保持独立性和能动性，可以使用3、6度平行，但不能平行进行超过三次。 两个声部之间由纯音程进行到另一种纯音程是禁止的，例如纯五到纯八。也不能从一个完全协和音程平行进行到同一种完全协和音程。同样也不能用同向进行去处置完全协和音程。 不能同向进行到纯音程，进入到纯音程一般采取反向进行。有一种情况除外：上方声部级进时，可以同向进行到纯音程. 为了保持旋律平滑，避免两个声部同时进行跳进。 对位的开始与结束都是在\\(\\hat{1}\\)上。固定旋律是下方声部时，可以从\\(\\hat{5}\\)开始。 小调中，使用自然小调。只在最后升高\\(\\hat{7}\\)创建导音，如果前面有\\(\\hat{6}\\)也要升高。 指南\n对位声部尽可能级进，偶尔有跳进以增加趣味性。跳进后反向级进。 尽可能多用反向进行。 第二类对位法 规则\n强拍必须是协和音程。 避免下列情况的平行纯音程： 连续的两个强拍之间。 弱拍和强拍之间。 从弱拍到强拍的进行要避免同向进入到纯音程（定向性进行）。 唯一允许的不协和音是弱拍经过音（不协和音必须在两个强拍间通过级进的方式填补旋律三度的空间）。 对位声部在CF（固定旋律）下方时必须从\\(\\hat{1}\\)开始。在上方时可以从\\(\\hat{1},\\hat{3},\\hat{5}\\)开始。可以用二分休止符开始。倒数第二小节可以有一或两个音，最后一小节必须有一个全音。 同第一类对位法规则7。 指南\n尽可能多结合运用不协和经过音。 运用和弦跳进平衡不协和经过音。 大跳安排在小节内，不要出现在小节间。 弱拍上的协和音程\n只有一种方式构建协和的级进运动：\\(\\hat{5}-\\hat{6}\\)或\\(\\hat{6}-\\hat{5}\\)。称为5-6技术。\n和声学部分 三和弦概论 三和弦分为四种：\n大三和弦：大三度+小三度 小三和弦：小三度+大三度 减三和弦：小三度+小三度 增三和弦：大三度+大三度 大小三和弦都是协和的。增减三和弦都是不协和的。\n共性写作时期的音乐中，只有大三和弦、小三和弦与减三和弦用作和声的单元。增三和弦并不具有独立的音响性，但它是对位旋律线汇聚的结果。其功能可见增六和弦部分。\n三和弦的转位\n根音是最低音称为原位；三音是最低音称为第一转位，数字低音为\\({}_3^6\\)或\\({}^6\\)；五音是最低音称为第二转位，数字低音为\\({}_4^6\\)。其稳定性依次递减。\n数字低音中的符号\n首先是数字，数字几就代表在根音上方几度有音，这个几度并没有明显的区分出音程的性质，它指的是在调内的音程。\n其次是数字旁边的符号：\n♭ 代表该数字对应的音临时降低。其指的不是把某个音变成带♭号的音，而是指调内的这个音降低半音。 # 代表该数字对应的音临时升高。同上。 /、+ 代表升高一个半音。 ♮ 代表还原一个音。而且并不是还原成调内的音，而是还原成白键上的音。 - 代表某个音延长或者进行。 自然大调中的三和弦性质\n如下：I、ii、iii、IV、V、vi、vii°\n和声小调中三和弦的性质\n如下：i、ii°、III、iv、V、VI、vii°\n偶尔能见到IV,v,VII，不过并不是和声小调中的。\n三和弦的重复音\n四个声部显然要重复三和弦中的某个音，最常重复的是根音。其他规则见后。\n流行中的表示\n性质\nC大三和弦：C C小三和弦：c、C- C减三和弦：C° C增三和弦：C+ 转位\n如C的第一转位C/E，C°的第一转位C°/♭E。前面写和弦性质，后面写低音。\n七和弦概论 七和弦都是不协和的。\n七和弦分类\n大七和弦：大三和弦+大七度 大-小七和弦：大+小 小七和弦：小+小 半-减七和弦：减+小 减七和弦：减+减 其中大-小七和弦通常称为属七和弦，因为它通常出现在属音上。\n七和弦转位\n根音为最低音，第一转位，\\({}^7\\);根音为三音，第二转位，\\({}_5^6\\);根音为五音，第二转位，\\({}_3^4\\);根音为七音，第三转位，\\({}_2^4\\)或\\({}^2\\);\n大调中的三和弦的性质\n如下：I\\({}^7\\)大七，ii\\({}^7\\)小七，iii\\({}^7\\)小七，IV\\({}^7\\)大七，V\\({}^7\\)属七，vi\\({}^7\\)小七，vii\\({}^{\\phi7}\\)半减七。\n和声小调中的三和弦的性质\n如下：i\\({}^7\\)小七，ii\\({}^{\\phi7}\\)半减七，III\\({}^7\\)大七，iv\\({}^7\\)小七，V\\({}^7\\)属七，VI\\({}^7\\)大七，vii°\\({}^7\\)减七。\n流行中的表示\n性质\nC大小七和弦：C7 C大七和弦：CM7、C\\(\\Delta\\) 7 C小七和弦：cm7、c7、c-7，Cm7 C半减七和弦：C7dim5,C\\(^{\\phi}\\) 7 C减七和弦：C°7 转位\n类似于三和弦。\nT-D-T进行 即I-V-I的和声进行，它是整个调性和声的基础。有时导和弦可以代替V。\nT-PD-D-T进行与乐句模式 主-预属-属-主。不可反向。这是二级分析意义上的。\n当预属和弦的低音是以级进接入属时，高音声部要反向进行。\n小调中，属功能中的导音要从上方级进。从下方会导致增二度。\n一个乐句中一般要包含T-PD-D-T或T-D-T以形成正格终止，T-PD-D或T-D形成半终止。其中主到预属的长度通常远远长于预属到属。而属持续的时间通常也要长于预属。有时可以用大量的和弦装饰扩展来延长主和属。\n有时会在主和弦中内嵌T-PD-D-T来扩展主和弦，这也称为嵌入乐句模式（EPMs）。为了防止听众误以为是结构上的、二级分析意义上的，需要弱化终止。例如将V7的七音放到根音位置，I使用第一转位。\nI-ii、IV-V、ii6-V中两个外声部反向进行。\n终止式 正格终止 原位的属和弦到原位的主和弦，叫正格终止，或叫完全终止，标注为AC。\n完全正格终止，PAC：高音声部是\\(\\hat{2}-\\hat{1}\\)或\\(\\hat{7}-\\hat{8}\\)，低音是\\(\\hat{5}-\\hat{1}\\)。\n不完全正格终止，IAC：如果高音声部结束在\\(\\hat{5},\\hat{3}\\)。\n对位终止，IAC的一种特定类型：低音不是\\(\\hat{5}-\\hat{1}\\)的IAC。\n皮卡迪三度：小调中结束全曲的主和弦不是小三和弦，而是使用升高三音的大三和弦。此风格被称作皮卡迪三度。\n半终止 结束在原位属和弦上的终止，标注为HC。\n弗里吉亚终止 这是一种特殊的半终止。由下属六和弦进行到原位属三和弦。通常小调更有效果。标注为PHRY。低音进行为\\(\\hat{6}-\\hat{5}\\)。\n巴洛克时期的作曲家都倾向于用其结束多乐章作品中的慢乐章，给听众留下一种强烈的预感，主和弦将在下一乐章的开始出现。\n规避终止 防止在主和弦的扩展中出现较强的终止，或者阻止听众对强烈终止的预期。常常将V-I的正格终止改为V2-I6等。\n变格终止 IV-I的终止。通常出现在教堂音乐中，又叫阿门终止。比正格终止弱得多，前面通常已经出现了一个正格终止。\n对位终止 使用V或I的转位或同时使用，所成的终止式叫对位终止。有时用到vii°6参与终止。一般会用在EPMs中。\n规避终止 V进行到vi。再之后回到预属或者主，再之后接正格终止。\n可以留下悬念以及对主和弦的期待。\n声部进行概论 合唱风格 女高音、女中音、男高音、男低音（SATB）\n使用四行五线谱（开放总谱）、或者使用两行五线谱（缩编谱）中，男低男高在低音谱表，女中女高在高音谱表的风格。\n注意缩编谱中，S、T符干始终向上，另外两个始终向下。\n键盘风格 SAT三声部在高音谱表，B在低音谱表。S符干向上，AT符干向下。\n声部进行规则 解决趋向音（如导音与和弦的不协和音）要用级进。导音在内声部中不一定要上行解决，可以下到\\(\\hat{5}\\)解决。和弦的七音在V\\({}^7\\)中总是下行解决。 不要有平行进行的同度、五度、八度。也不要在这三个音程中反向进行。 不要重复趋向音。如导音、不协和音、半音变音。 上方三声部，两个相邻的声部间不要超过八度。最下方两个声部可以超过八度。 不要四部同向。 声部进行的建议 一般可以保留两个和弦的共同音 上方三个声部的进行主要是二度、三度；大跳后要反向级进。 避免增音程跳进。可以跳进到减音程，随后要反向级进。 上方任意两个声部同时出现大于三度的跳进，有可能会出现问题。尽量使用转位音高。 避免出现声部交叉，如男高比女中高。避免出现声部重叠，如男高音走到了女中音前一个音的上方。 高音声部与低音声部间避免八度与五度的同向进行，除非高音声部是级进进行（称为定向八度与五度）。 总体上讲，用完整的和弦。有时可以省略五音。 通常重复根音。为了声部进行正确也可以重复其他音。重复五音比三音好。但是绝对不能重复导音。 先写两个外声部。 上声部的运行与低音成反向。高音声部基本级进。 和声、节奏、旋律、节拍的互动 和声变换节奏 变换到一个新的和声上，会产生一个重音。最好在重拍上切换和弦。避免切分的和声节奏。\n但在四三拍上经常遇到在第3拍上切换和声，有助于强化三拍子。切分的和声节奏在四三拍的终止式中第2拍为属和弦并持续到第3拍时是允许的。\n装饰和弦与和声的二级分析 旋律中会有装饰音，为装饰音配和弦，这个和弦不具有功能，只是作为原和声的扩展。\n和声的一级分析就是将和弦标注出来。而二级分析就是区分重要的、功能性的和声和装饰的和声。\n结构性和声与从属性和声 结构性和声\n是进行性 具有和声功能（主、属、下属） 通常在强拍 通常是原位 是和声序进的组成成分 第二等级分析中保留罗马数字 从属性和声\n是延伸性 具有旋律功能 通常在弱拍 通常是转位 是对位进行的组成部分 第二等级分析中标注为装饰音 主和弦 主三和弦(I) 功能\n主功能，一般不用做装饰。\n主六和弦(I6) 功能\n主功能（较少） 作为低音的跳进和弦：I-I6-V，扩展I，低音由五度变成两个三度。 作为经过和弦：ii-I6-ii6，扩展ii。 主四六和弦(I46) 功能\n主功能（较少，不和谐），属功能（终止四六和弦时）。 作为弱位置上的持续四六和弦：V-I46-V，扩展V。其中属和弦的低音可以保持住，只改动三音五音。在一级分析中记为I\\({}_4^6\\)。二级分析中记为V-Ped\\({}^6_4\\)-V，或者V\\({}^{5-6-5}_{3-4-3}\\) 作为弱位置上的经过四六和弦：IV-i46-IV6，扩展IV。二级分析中记为P\\({}^6_4\\) 作为弱位置上的琶音四六和弦：I-I46-I6下行，扩展I。二级分析中记为Arp\\({}^6_4\\) 作为强位置上的终止四六和弦：I46-V-I，成为正格终止。也能I46-V成为半终止。二级分析记为V\\({}^{6-5}_{4-3}\\) 准备\n准备终止四六和弦的两种方式：\n用共同音做准备。I46前面是I(共同音为\\(\\hat{1}、\\hat{3}\\))或者IV（共同音是\\(\\hat{1}\\)）。 用级进准备。I46前面是预属和声。通常表现为ii6-I46-V-I。 解决\n终止四六和弦解决总是表现为级进下行到V。\n其他\n终止四六和弦在V7前，其进行为\\(\\hat{8}-\\hat{7},\\hat{6}-\\hat{5},\\hat{4}-\\hat{3}\\) 终止四六和弦可以参与到规避终止中，例如I46-V-V2-I6。 终止四六和弦绝对不会接在属功能之后。这会削弱其效果。 终止四六和弦出现在节奏强拍上。（部分书籍会要求不能比后面接的V弱，且不能比后面接的V时间短） 四六和弦重复低音。 四六和弦的进出都是共同音或者级进。 属和弦 属三和弦(V) 功能\n属功能，一般不用做装饰。\n解决\n解决到主三和弦。\n\\(\\hat{7}\\)到\\(\\hat{1}\\)，\\(\\hat{2}\\)到\\(\\hat{1}\\)或\\(\\hat{3}\\)，\\(\\hat{5}\\)到\\(\\hat{1}\\)\n属七和弦（V7） 功能\n属功能，一般不用做装饰。\n准备\n不协和音需要准备，有多种方式，级进的准备是首选的方式。\n解决\n不协和音只有一种解决的方式：三音出现在高音声部时上行，七音总是下行。\n由于三音和七音构成三全音，当为减五度时解决到三度，为增四度时解决到六度。除非选择不解决内部的导音。\n一般来说，完整的属七解决到不完整的主三和弦，不完整的属七解决到完整的主三和弦。也有完整到完整的情况，即内声部的导音进行到\\(\\hat{5}\\)。\n转位的解决类似。\n其他\nV可以进行到V7，但是不能反向。\n属六和弦(V6) 功能\n属功能（较少） 作为低音的跳进和弦：V-V6-I，扩展V，低音由四度变成三度与二度。 作为低音的邻音和弦：I-V6-I，扩展I，低音进行为\\(\\hat{1}-\\hat{7}-\\hat{1}\\)。通常\\(\\hat{5}\\)在高音声部。 作为不完整邻音和弦：I6-V6-I，扩展I，由下行三度变为下行四度再上行二度。 属四六和弦(V46) 功能\n属功能（较少） 作为弱位置上的经过和弦：I-V46-I6，扩展I。二级分析中可以标记为P\\({}^6_4\\) 作为弱位置上的琶音四六和弦：V-V46-V6下行，扩展V。二级分析中记为Arp\\({}^6_4\\) 其他\n四六和弦重复低音。 四六和弦的进出都是共同音或者级进。 属五六和弦(V56) 功能\n属功能（较少）。 作为邻音和弦：I-V56-I，扩展I。 跟随在V或者V6之后，扩展V，随后解决到I。 属三四和弦（V34） 功能\n属功能（较少）。 作为邻音和弦：I-V34-I，扩展I。 作为经过和弦：I-V34-I6，扩展I。 属二和弦（V2） 功能\n属功能（较少）。 作为不完整邻音和弦：I-V2-I6，扩展I，低音由上行3度变为上行4度再下行2度。 作为邻音和弦：I6-V2-I6，扩展I。 属七和弦转位的注意事项 解决与准备同原位和弦。 V7转位必须作为完整的形式出现。 V7转位往往在弱拍，通常连接到强拍上较稳定的主三和弦。 这些修饰和弦可以连用。 返回相关的属和弦 延伸了前面的主和弦却没有解决到主和弦。例如I-V-vi（不作为规避终止时），I-V-ii\n下属和弦 下属和弦经常被选作预属和弦，因为I-IV的进行是五度下行，是调性和声中最强劲的原位进行。\n下属三和弦（IV或iv） 功能\n预属功能。 作为邻音和弦：I6-IV-I6，扩展I。（较少） 其他\n进行到属和弦时注意低音和其他声部反向。 最好重复根音。 下属六和弦(IV6或iv6) 功能\n预属功能。（较少） 作为低音琶音和弦：I-IV6-I6，扩展I，由下行六度变为三度和四度。 作为经过音和弦：V-IV6-V6，扩展V，由三度变为两个二度。注意小调中要升高\\(\\hat{6}\\)以防止增二度。上方声部要与低音反向，防止平行五八。 进行到V形成弗里吉亚终止。 下属四六和弦(IV46或iv46) 功能\n预属功能。（较少） 作为弱位置上的持续四六和弦：I-IV46-I，扩展I。其中主和弦的低音可以保持住，只改动三音五音。在一级分析中记为IV\\({}_4^6\\)。二级分析中记为I-Ped\\({}^6_4\\)-I，或者I\\({}^{5-6-5}_{3-4-3}\\) 作为弱位置上的琶音四六和弦：IV-IV46-IV6下行，扩展IV。二级分析中记为Arp\\({}^6_4\\) 其他\n四六和弦重复低音。 四六和弦的进出都是共同音或者级进。 下属七和弦(IV7或iv7) 不如ii7常见，但也颇具色彩\n功能\n预属功能。 声部进行\n见后\n其他\n为了避免平行五度，通常不接V，而接V7，或者终止四六和弦。如果省略五音重复根音可以借V，既避免平行五度又准备了七音。\n下属五六和弦(IV56或iv56) 功能\n预属功能 声部进行\n见后\n其他\n通常后面接V56。\n导和弦 导减三和弦（vii°） 远不如第一转位常用，因为它有三全音，而第一转位会削弱三全音。\n导减六和弦（vii°6） 功能\n代替属和弦作为属功能（较少）。 作为低音中的经过音和弦：I-vii°6-I6，扩展I，由三度变为两个二度。ii不适合做这个经过和弦的原因是，ii是一个更强势的和声。 作为低音中的邻音和弦：I-vii°6-I，扩展I。 解决\n如果有可能，解决三全音。除非：\n走向完整的主和弦。 没有涉及低音。尤其是三全音表现为增四度。 低音与高音是平行十度。 其他\n不要重复导音。重叠三音(\\(\\hat{2}\\))时走向\\(\\hat{1}\\)或\\(\\hat{3}\\)，有时也可以重叠五音。 导减七和弦(vii°7) 功能\n代替属和弦作为属功能。（较少） 像V56，作为邻音和弦：I-vii°7-I，扩展I。 准备\n七音（\\(\\hat{6}\\)）用级进进入或共同音进入。 解决\n\\(\\hat{6}-\\hat{5}\\) \\(\\hat{4}-\\hat{3}\\) \\(\\hat{2}-\\hat{3}\\)（通常，尽管会重复主和弦的三音），有时也能\\(\\hat{2}-\\hat{1}\\) \\(\\hat{7}-\\hat{1}\\) 转位的准备与解决类似。\n导减五六和弦(vii°56) 功能\n属功能（较少）。 像V34，作为经过和弦：I-vii°56-I6，扩展I。 导减三四和弦(vii°34) 功能\n属功能（较少）。 像V2，作为经过和弦：V-vii°34-I6，扩展V。 像V2，作为邻音和弦：I6-vii°34-I6，扩展I。 导减二和弦(vii°2) 这个和弦比较罕见。\n功能\n属功能（较少）。 作为原位V的邻音和弦：V-vii°2-V，扩展V。 导半减七和弦(viiø7) 在大调中出现的概率要远低于在小调中出现导减七和弦的概率。并且大多以原位出现，很少有转位。\n功能\n作为邻音和弦：I-viiø7-I，扩展I。 作为和弦跳进：V-viiø7-V6，扩展V。 上主音和弦 上主音和弦是最常见的预属和弦。因为：\nii-V是五度下行，是调性和声中最强劲的原位进行。 形成对比。大调中ii是小三和弦，I与V是大三和弦；小调中ii°是减三和弦，i是小三和弦，而V是大三和弦。 ii-V-I的序进中高音声部时常为\\(\\hat{2}-\\hat{7}-\\hat{1}\\)，力度比IV-V-I的\\(\\hat{1}-\\hat{7}-\\hat{1}\\)弱。也是围绕\\(\\hat{1}\\)的双重邻音的旋律性进行，使得终止尤为强烈。 上主音小三和弦(ii) 即大调中的形式。\n功能\n预属功能。一般不用作装饰。\n其他\n最好重复根音。\n上主音减三和弦（ii°） 即小调中的形式。建议不用，因为存在三全音。更常用的是第一转位的形式，可以削弱三全音。\n上主音减六和弦(ii°6) 即小调中的形式。\n功能\n预属功能。一般不用作装饰。\n其他\n最好重复低音。\n上主音七和弦(ii°7或iiø7) 功能\n预属功能 声部进行\n见后\n上主音五六和弦(ii°56或iiø56) 比其他转位常见得多\n功能\n预属功能 声部进行\n见后\n下中音和弦 下中音三和弦（vi或VI） 功能\n作为琶音和弦：I-vi-IV，扩展I，或者是准备IV或ii。二级分析中视为从属于T。 作为五度圈下行中的和弦：VI-ii-V-I五度下行。 取代主和弦，作为规避终止：在V-I的终止中替代I，形成上行二度的V-vi，这是一种虚假运动。二级分析中写作“T”。其后跟着预属和弦或者主和弦，然后跟着正格终止。 预属功能。（较少） 属和弦修饰下中音和弦：I-V-vi的进行中，vi会使得V黯然失色，尤其是vi强拍而V弱拍时。 主和弦修饰下中音和弦：类似于上条，尤其是vi强拍而I弱拍。 貌似下中音和弦：不具有结构性意义而是声部进行的附属品。 声部进行\n按照之前的共同规则即可。\n规避终止中，高音宜采用\\(\\hat{2}-\\hat{1}\\)或\\(\\hat{7}-\\hat{1}\\)。注意小调中\\(\\hat{7}-\\hat{6}\\)会形成增二度，从而VI和弦必须重复三音。\n中音和弦 中音三和弦(iii或III) 功能\n作为琶音和弦：I-iii-V或I-iii-IV-V，扩展I。 五度下行中的中音和弦：iii-vi-ii-V-I。 声部进行\n进出iii时尽量将上访声部与低音反向。 iii用于支撑\\(\\hat{7}\\)时，高音采用\\(\\hat{1}-\\hat{7}-\\hat{6}\\)的旋律线条。 其他规则同一般规则。 其他\n小调中使用比大调多 中音和弦的准备：V/III-III，会在小调中出现VII和弦。并且更多时候用的是V6/III。 非属七和弦概论 有些七和弦不具备属音或导音七和弦的属功能性质，被归类到非属七和弦。它们用途宽广，富有色彩，易于实施。\n声部写作注意事项\n必须准备和弦的七音，同音（首选）或者高半音的方式接入 必须解决七音，级进下行到下一个和弦 转位和弦必须是完整的。原位和弦可以省略五音重复根音来避免平行五八。 装饰音 分为两类，弱拍装饰音和强拍装饰音。\n弱拍装饰音有：和弦大跳进、经过音、邻音、先现音等。还将进一步细化为协和的（和弦大跳进）与不协和的（大多数经过音与邻音）。协和的无须准备和解决。不协和的几乎总是出现在协和音之间并且是级进运动。\n强拍装饰音有：强经过音、强邻音、延留音、持续音和倚音等。他们是音乐中最富有情感的元素。\n琶音(ARP)\n如果连续出现了三个或以上以上的和弦音(CS)，那么可以称为琶音。\n经过音(P、PT)\n弥补和弦的音程。通常是三度。\n邻音(N)、上邻音(UN)、下邻音(LN)、不完整邻音(IN)、双重邻音(DN)\n邻音指从和弦音上行或下行二度后又回到原来的音。\n不完整邻音指跳进到与和弦音相邻的音，然后级进解决到和弦音。\n双重邻音指同时出现了上邻音和下邻音再解决到和弦音。\n和弦大跳(CL)\n从一个和弦音跳到另一个和弦音。允许不协和跳进，如三全音。\n强经过音(APT)\n弱拍强位上的经过音。通常发生在下行线条中。7-6、4-3最常用。\n半音经过音(CPT)\n用半音弥补两个自然音中的间隙。\n强邻音(AN)\n强拍上的邻音。\n半音邻音(CN)\n含一个或数个非自然音高。\n倚音(APP)、亦或不完整强邻音\n未准备的不协和音出现在强拍上，实质上是不完整的强邻音。由级进解决，通常与跳进方向相反。最常用的是4-3、9-8\n延留音(SUS)\n最重要的强拍装饰音，其中短暂地延缓了级进式的旋律下行，并在该线条继续之前构成一个不协和音 展开的三阶段 准备：弱拍和弦音 延留：延留准备音持续到强拍上的和弦变换。它此时变成了和弦外音 解决：延留音通过向下级进到弱拍上的和弦音 上声部的常见类型：9-8，7-6，4-3 低音的常见类型：2-3（9-10） 先现音(ANT)\n不协和音，即将出现的和弦的结构音提前进入。\n持续音(PED)\n大多数是在低音中，具有主功能或属功能；表面的和声序进往往是在其上方展开。\n调性音乐中的三种基本根音运动 五度下行(D5)。是调性音乐中最强劲的原位进行。如V-I 二度上行(A2)。如IV-V。 三度下行(D3)。如I-vi。 低音级进下行 例如低音为\\(\\hat{1}-\\hat{7}-\\hat{6}-\\hat{5}\\)，则可以配I-V6-IV6-V。小调（旋律小调）则是i-v6-iv6-V。\n级进下行低音经常有在作品中不断重复，形成一个坚实的和声基础。这样的重复叫做固定音型。以此为基础的作品叫固定低音或恰空。\n隐伏和声 通过复合旋律的分析可以分析出三和弦或者七和弦。但少部分情况仍然不完整，这就需要推断出确实的和弦音。\n和声模进 书上的定义不是很直白，简单说就是和弦级数（根音级数）按某一特定规律变化的进行。例如先下降五级在上升四级（也可以理解为连续下降五级），变成I-IV-vii°-III-vi-ii-V-I。\n分为两类，延伸模进（扩展一种功能，如T-T），离调模进（从一种功能到另一种功能，如T-PD）。总的来讲，模进是在主和弦扩展之后并在PD与D功能之前出现。\n下行二度(D2)模进 D2(-5/+4)模进，即先下行五度在上行四度，称为下行二度模进。毫无疑问也可以先上行四度再下行五度。\nI-IV-vii°-III-vi-ii-V-I中，间隔的两个和弦会有声部进行问题，而插入的那一个和弦正好解决了这个问题。称作声部进行和弦。另外IV-vii和vi-ii的进行中根音会出现三全音跳进，但在模进中是可以接受且必须的。\n在这个模进中，出现原位的减和弦是允许的。\n下行二度模进转位\n原位模进的低音有些跳进。通常会将模进中的每第二个和弦使用第一转位。\n下行三度(D3)模进 D3(-4/+2)模进与D2模进形成鲜明对比。\n同样有声部进行和弦避免平行问题。\n大调中I-V-vi-iii-IV-vii°-I。小调中i-v-VI-III-iv-V7-i。这是书中给出的例子，关于为什么会有倒数第二个属和弦，书中没给出解释，我认为是为了保持乐句模式。注意小调中第二个是小和弦，防止出现增二度。\n帕赫贝尔的卡农的形式是：I-V-vi-iii-IV-I-ii56-V-I。可以认为三度下行只有I-V-vi-iii-IV-I，后面接终止式以保持乐句模式。\n下行三度模进转位\n同样给每第二个和弦使用第一转位来平滑低音的运动。也称之为下行5-6模进，因为往往每第一个和弦每第二个和弦之间，有一个声部保持稳定，而低音下行二度，形成了5度-6度的关系。它的转位比原位更常用。\n上行二度(A2)模进 A2(+5/-4)比D2罕见，它几乎没有目标导向。常见的只发生在原位，I-V-ii-vi-iii-。然后通常接到预属。小调中为i-v-ii°-Vi-III-。注意小v。\n另一种A2(-3/+4)，同样也是引导向预属功能。通常每第二个和弦使用第一转为，也称作上行5-6模进。\n写和声模进的指南 确保前三个和弦的声部进行是正确的，后面的都是复制，不会导致新的问题。 是种都是用低音与高音声部开始；尽量使两个外声部之间成反向级进。 模句中的两个外声部之间至少要有一个不完全协和的音程。 在乐句模式中写作模进 比如要在四小节的乐句中确立主和弦，用D2模进，并且PAC结束。\n可以采用很快的节奏来处理模进和弦。 可以只采用模进的一部分。可以不用前几个，也可以提前结束模进。 加长乐句。 自然音七和弦的模进 可以将自然七音添加到每一个D2(-5/+4)模进中，也可以隔一个和弦添加一个七音。两个都可以使每个七音都有共同音准备并级进下行解决。前者叫带连锁七和弦的D2(-5/+4)\n写作指南\n设计好前三个和弦的链接。注意每个七音都要准备和解决。 交替出现的七和弦可以是完整的。 连锁七和弦中，相邻的两个七和弦一个是完整的一个是不完整的。 转位\n第一转位、第三转位较为常见。转位一定要是完整的和弦。\n平行第一转位三和弦 写作一连串平行运动的和弦，只有采用三和弦的第一转位一种方式。用于延长和声或者和声功能之间的离调。\n四声部写作时，三个声部平行运动，一个内声部重复高音、重复低音、重复高音、重复低音进行（也可以从低音开始）。\n副属和弦 概论 作为副属功能的和弦，必须表现得像个属和弦。也就是，必须是大三和弦或是属七和弦，并且通常要进行到其主和弦上。\n推断副属和弦，例如c小调中V的副属和弦。首先V是G大三和弦，就确定G大和弦（或者说G大调）的副属和弦，G大和弦的副属和弦是D大和弦。标注为V的V，即V/V。在预属和属前面增加其副属和弦是常见的。小调中在III前面加副属也常见。\n注意减和弦不能有副属和弦。副属和弦在二级分析中标注为其主和弦相同的功能。\n转位\n可以通过转位平滑低音线条。\n声部进行\n不能重复导音和七音。 导音在外声部要向上级进解决。 七音总是向下解决。 副导和弦 由vii°6和vii°7（以及少见的viiø7）是属和弦的替代品。他们也能参与到副属和弦中，作为副导和弦。比如说vii°6/ii。\n副属和弦运用在乐句中 没有新的规则。不过副属和弦布局在弱位置上是很常见的，因为含有导音，参与的运动是通往强位置的目标。\n带副属和弦的模进 D2(-5/+4)\n显然，这样有五度下行的结构，是可以运用副属和弦的。并且可以交替使用副属和弦，也可以连锁使用。\nD3(-4/+2)\n将每第二个和弦换为下一个和弦的副属和弦，从D3(-4/+2)变为D3(+3/-5)。可以用转位来平滑低音。也可以用副导七和弦变为D3(-4/+1)。\nA2(-3/+4)\n比A2(+5/-4)结合副属和弦常见。\n每第二个和弦采用第一转位时，只要低音升高半音就可以构建副属和弦。\n离调与转调 扩展离调 用副属和弦就是一种离调。副属和弦解决到其主和弦的过程是可以扩展的，使用那个调上的和弦进行扩展。在二级分析中这些都是该调主和弦的功能。罗马数字分析中，可以将离调的部分写作该调的和弦级数，再将离调的部分括号括起来标注临时主和弦。\n转调 长久的离调，其能占据作品的一整个段落，被称之为转调。虽然没有一条明确的分界线。但是：\n离调通常出现在乐句之中。 转调含有新调中强烈的终止式，并且新调在终止式之后还在延续。 近关系调 总体上讲，调性音乐中转调是从本调进行到任何其近关系调。\n有两种方式确定近关系调：\n本调上各音级上构筑自然音三和弦。所有的协和三和弦（大三和弦和小三和弦）都构成了主调的近关系调。 调号与原调号只差一个升降号的大调和小调。 虽然可以转到任何大小自然调，但是最常见的是（有先后）：\n大调转到V、vi和iii 小调转到III，v和VI 转调分析 有三种重要信息：\n新调在原调中的位置 新调在作品或作品段落中整体和声序进中的功能 新调与原调瞬间融合的点位 采用如下方式分析转调：\n在原调中开始处写罗马数字 一直分析和弦，直到罗马数字因调性变化而变得复杂或没有意义 为新调标出罗马数字，从终止式往回写，直到出现两个调中都用简单的罗马数字标记的第一个和弦。即中介和弦。 中介和弦转调 在理解中这和共同和弦转调是一个意思。\n中介和弦在两个调中都是自然音和弦。终止四六和弦不是优选，因为它们在新调中是强烈终止的一部分。中介和弦通常在新调中是PD功能的。\n写作指南\n新调和原调的两个调域的持续时间段是均衡的。中介和弦配置在转调乐句的中间位置，各调中都至少要用数个和弦。 找出两个调中的所有中介和弦。最佳的中介和弦应该能作为新调的PD和弦。为了避免刺耳音响，不能用新调的属和弦作为中介和弦。 中介和弦之后不要立刻冲进完全正格终止。插入一段对位终止或EPM。 在新调中采用级进式高音线条进行到最强的终止，即终止四六和弦的PAC。 较大音乐语境中的转调 几乎没有什么作品开始的与结束的调不同。考虑到作品的整体性，转调从未取代过主调。调性音乐中的转调只是参与到单一的整体和声运动中。\n例如，c小调的作品在引导向属和声并返回到c小调结束前可以转调到♭E大调与f小调。这构成了一个大型序进：i-III-iv-V-i。\n在模进中转调 在和声模进中，提早放弃模进并将其和弦之一重新解释成进行到属的预属，就可以有效地进入到一个新调。\n混合调式 18世纪晚期到19世纪初期的音乐，经常会有一种半音的类型，无法说成是附属功能以及离调所派生的。事实上只是非功能的出现，来为音乐的旋律与和声外表增添色彩。\n借用平行调式和声的技术称之为混合调式，简称混合。\n皮卡迪三度也是一种混合调式，大调中使用减七和弦也属于混合调式。\n虽然平行大小调之间可以借用和声，但是一般常见的是从小调中借用和弦给大调使用。因为小调中\\(\\hat{6},\\hat{7}\\)会根据情况有两种形式。在大调中引入这样的变化音非常特别。\n变音的预属和声 涉及ii°与iv\n涉及混合调式的最常见的音级是\\(\\hat{6}\\)，因为：\n\\(\\hat{6}\\)最不可能破坏本调与调式的完整性 降低\\(\\hat{6}\\)就能产生强力的半音级进运动到属和弦 混合调式援引\\(\\hat{6}\\)为所有的PD和声增添了色彩 主三和弦外唯一能用\\(\\hat{1}\\)级音位于低音的和声协和支撑的音级就是\\(\\hat{6}\\)。因此，是5-6运动的成分。 改变了和弦性质但没有改变根音的半音变化，称之为混合旋律。\n变音的下中音和声 涉及♭VI，和上一个一样变的是\\(\\hat{6}\\)，但这次是在根音情况。这种变化根音的情况叫做混合和声。\n只将\\(\\hat{6}\\)降低会形成增三和弦，通常也要同时降低\\(\\hat{3}\\)来形成大三和弦。\n它仍是作为下中音和弦的功能：\n参与到下行琶音 参与到下行五度运动 作为预属功能至于属和弦前 虚假运动中接到属和弦后代替主和弦 由于降低的\\(\\hat{6}\\)和属和弦仅相差半音，可以用作扩展V的上邻音。 变音的主音和声 涉及i，即降低\\(\\hat{3}\\)。将大调主和弦转换成小调主和弦，但是这种并置会引发整首作品的调式问题，所以i只能用于暗示而不能用作正式的陈述。\n十九世纪，有些作曲家，如舒伯特，大量使用小调元素，使得24个大小调融入到12个大-小调中。如果一首作品中D大调和d小调的音出现的数量差不多，就只能说成是D调作品。\n变音的中音和声 涉及♭III，降低了\\(\\hat{3}\\)和\\(\\hat{7}\\)构成大三和弦。功能仍然是中音和弦的功能：\nI和V之间的，将五度划分成两个三度的和弦。 T与PD之间的过渡。 参与到下行五度运动中，尽管比ii少见许多。 作为PD，引导向V34。 其之前添加副属和弦。 作为I6的替代品，不如iii常见。 混合和声的声部进行 避免重复变音，除非变音是根音 ♭\\(\\hat{6}\\)可以做邻音和下行经过音，要由级进运动做准备并解决。并且应该保持在同一声部中。 只要引入了混合调式，就必须一直持续到抵达属功能。 半音级进式低音下行 小调中\\(\\hat{6},\\hat{7}\\)有两种形式，所以半音级进式低音下行是可能的。\n有了混合调式，就能将其引入到大调中。\n变格运动 指下属和弦、上主音和弦与下中音和弦直接进行到主和弦。二级分析中缩写为PL功能。\n混合调式与副属和弦 离调与属功能密切相关 混合调式通常出现在预属功能中 半音转调 最常见的是转到♭VI和♭III，较少到VI和III。\n半音中介和弦转调 往往半音转调的时候，两个调没有共同和弦。但是本调的关系调和新调有中介和弦。也就是说，这个中介和弦必须是本调的混合和弦。\n写作指南\n在新调中添加必要的临时符号，或者调号。 中介和弦必须总是原子混合调式。通常由很好效果的是用i来作为新调的vi或iii。 尽量构建浑然一体的音乐进行，在新调中扩展PD，可通过转位或短暂的离调。 无准备的半音转调 即直接在某个停顿后突然进入到另一个调。\n半音共同音转调 例如D大调的\\(\\hat{1}\\)和♭B大调的\\(\\hat{3}\\)是同一个音，彼此间隔三度，进行转调。从书上给的例子看，舒伯特写了两小节长度的纯D音，不含别的成分，然后再进行到新调。\n那不勒斯和弦 概论 建立在♭\\(\\hat{2}\\)上的大三和弦称为那不勒斯和弦。\n通常以第一转位出现，为♭II6，重复低音，有时也可以重复\\(\\hat{6}\\)，不能重复♭\\(\\hat{2}\\)。\n作为预属功能强力推向V。出现在小调中比大调多，在大调中是混合调式的结果，大调中同时也要降低\\(\\hat{6}\\)，并且要避免增二度进行，\\(\\hat{1}\\)-♭\\(\\hat{2}\\)，而不是\\(\\hat{3}\\)-♭\\(\\hat{2}\\)。\n通常出现在终止式中，也能用于EPM。\n♭II6-V的序进是高音声部中有♭\\(\\hat{2}$-\\)\\hat{7}\\(的进行，这个减三度是可以接受的。也可以添加\\)\\hat{1}$作为经过音，此时配置终止四六和弦或者为V配置副减导七和弦。\n扩展 低音中的和弦跳进来延长，♭II-♭II6 作品的第一分句配置在主和声上，随后上移半音级进到♭II。 加入副属和弦，小调中的VI，大调中的♭VI。 无论怎么扩展，始终都是作为预属功能。\n模进 在模进中结合那不勒斯和弦，好处是，小调时二级和弦是减和弦，不能使用副属和弦。换成那不勒斯和弦后可以使用副属和弦。\n用作中介和弦的那不勒斯和弦 转调到自然音以及半音调时，那不勒斯和弦是一个有效的中结合线。如c小调转到♭A大调，则c小调中的♭II6和♭A大调中的IV6是共同和弦。\n增六和弦 概论 书上虽然没说，但是指的不是增三和弦的第一转位，而是含有增六度的和弦。\n通常是\\(\\hat{4}\\)上的和弦，升高\\(\\hat{4}\\)，然后第一转位。（小调上）\n同大多数半音和弦一样，作为预属功能。它更多地出现在小调中\n解决到属和弦，低音♭\\(\\hat{6}\\)级进下行到\\(\\hat{5}\\)，#\\(\\hat{4}\\)上行到\\(\\hat{5}\\)。内声部重复\\(\\hat{1}\\)，并且反向运动。（书上虽然说的是降六级，但是我怀疑打错了，小调中的五六级就是半音。大调中要降六级）\n如果直接解决到V7，会出现省略式解决。#\\(\\hat{4}\\)没有上行到\\(\\hat{5}\\)，而是到\\(\\hat{4}\\)并到\\(\\hat{3}\\).\n类型 基本成分是：\n\\(\\hat{6}\\)位于低音声部（书上没说，但是大调降六级） #\\(\\hat{4}\\)位于上声部（通常是高音声部） \\(\\hat{1}\\)是重复音 意大利增六和弦\n就是只含有基本成分的增六和弦，标注为It6\n德意志增六和弦\n意大利增六和弦是重复\\(\\hat{1}\\)。德国增六和弦不重复，而是增加了一个\\(\\hat{3}\\)音，大调♭\\(\\hat{3}\\)。标注为Ger56。\n法兰西增六和弦\n不重复，而是增加\\(\\hat{2}\\)音，形成增四度。大调也是增加\\(\\hat{2}\\)。标注为Fr34。\n瑞士增六和弦\n只存在于大调，就是法国增六和弦增加的是#\\(\\hat{2}\\)，构成倍增四度。也称为瑞士倍增六和弦。标注为Sw34。\nVI与增六和弦 通常(♭)VI是进行到预属。但有时也会直接作为预属，进行到V，来利用富有戏剧性的半音运动(♭)\\(\\hat{6}-\\hat{5}\\)。由于直接用(♭)VI-V有声部问题，所以经常会将(♭)VI转化为德国增六和弦。因为它们有三个共同音。\n作为预属扩展部分的增六和弦 鉴于两个声部都具有明确的到\\(\\hat{5}\\)的目标导向，增六和弦通常也就成为了到属和弦之前的最后一个环节，紧跟着前置的iv(6)或VI。\n在极为罕见的情况下，德国增六和弦会用到\\(\\hat{4}\\)低音位置，此时构成了德国减三和弦。记作Ger7。\n增六和弦与转调 由于有两个半音趋向于\\(\\hat{5}\\)，它比一般PD更富有同向属和弦的线性驱动力。因此，当其出现在中介和弦之后尤其有助于稳固新调。\n增六和弦作为转调的中介和弦 意大利增六和弦实际上和某个调的不完整V7（缺5音）是同音异名的关系。德意志增六和弦则和某个完整的V7是同音异名关系。一般是在降二级上的调。\n从而，有时会用这个和弦去进行中介和弦转调。\n曲式学部分 动机 最出名的动机之一就是命运交响曲的开头。\n动机类型 分为两种：独立的音型和主题的构件。具体如何区分书中并没有说得太清楚，疑似也不重要。\n动机的重复 严格重复 在动机的称述之间保持同样的音高-节奏结构。\n通常相对少见，但是在作品刚开始时进行严格重复是很适合的，可以帮助听众迅速掌握动机。\n为了避免枯燥，可以进行模仿，即在一个声部首先陈述动机，然后在另外的声部中重复（通常指八度模仿，不改变动机的音级）。也可以对动机进行重配和声。\n修饰重复 常见的修饰办法有：加入装饰音、将动机进行移位等。\n移位有很多种，可以把整个动机移位，也可以把动机中的几个音移位（比如把某个音提高八度，这很有效果）。\n移位分为两种，调内移位（这会改变音程性质）和完全移位（不改变音程性质的移位，会用到非自然音）。\n两次及以上的，同度的移位成为模进。\n修饰重复意义下，模仿不限于八度，可以在任意音程内，不过五度较为常见。\n如果动机的两次重复有时间上的重叠，则称为密接和应。\n镜像（或倒影）\n即将动机以某个音为水平面，将整个动机上下镜像翻转。节奏对于旋律来说可能比音高更为重要，即使翻转了，节奏不变还是能够有较强关联。\n逆行\n将动机左右翻转，第一个音变成最后一个音，依次进行。不如镜像常见，因为会改变节奏，难以辨认关系。\n逆行倒影\n即将倒影和逆行结合，更加难以辨认关系。\n节奏变形\n前文提到节奏比音高稍微重要，变化节奏容易导致动机难以辨认。更多情况下，会对整个动机扩增时值或者缩减时值。\n展开重复 这会导致动机的重大改变，虽然不容易听出来，但是某种意义上更为重要。\n插补\n可以说是加了很多音在动机之中，从而与添加装饰音的修饰重复区分开来。\n裂变\n将动机的一部分拿出来使用。通常会使用动机的头部。\n隐含重复\n十分重要。例如可以隐含在和声的轨迹中。能从一个乐章跨越到另一个乐章。\n单音程动机 只有一个音程的动机，具有高度的可塑性。\n乐句 通常是展示一小段完整的音乐的最短单位（不是书上的定义），通常具有四小节、六小节、八小节长度。每个乐句只有一个功能性的和声进行。可以理解为只有一个终止式。\n分乐句 一个完整的乐句是由两个或更多分乐句组成的，特点是具有断句（句读）。但是有句读不能保证有分乐句，有分乐句也可以没有句读。\n复合乐句 由三个分乐句组成的乐句成为复合乐句。和乐句一样，只有一个结构性的和声进行。\n有两种类型：各分句的和声功能不同；前几个分句都是主和声，最后一个分句是PD、D、T。\n乐段 当一个结论性不强的乐句搭配一个有很强结论意味的乐句时，我们将这种组配单位称之为乐段。通常起句是半终止，结句是正格终止。\n相似乐句、对比乐句\n乐段中的两个乐句彼此间有旋律的相似性，称之为相似乐句。而旋律不同的，称之为对比乐句。\n阻碍乐段\n如果第一乐句的半终止在第二乐句的开头解决到主和弦，则称为阻碍乐段。\n延续乐段\n如果第一乐句的半终止在第二乐句中没有解决，而是延续属功能直到正格终止，则称为延续乐段。\n当然有时也会在半终止后，第二乐句中接预属功能，形成返回相关的属和弦。\n有时也会让第一乐句结束在预属和弦的正格终止上，后接属功能在第二乐句。比如第一乐句结束在ii、IV、vi上（书上没有提到和声的正格终止是什么，估计是vi-ii的终止）。\n分段式乐段\n第一乐句结束在IAC上（亦即旋律未结束在\\(\\hat{1}\\)上），而第二乐句结束在PAC上（亦即旋律结束在\\(\\hat{1}\\)上）。\n进行式乐段\n第二乐句结束在另外一个调上，称为进行式乐段。第一乐句可以是HC或IAC。\n分类与使用频率\n相似阻碍乐段（PIP，常用），对比阻碍乐段（CIP，少用），相似分段乐段（PSP，有时用），对比分段乐段（CSP，有时用），相似延续乐段（PCP，少用），对比延续乐段（CCP，有时用），相似进行乐段（PPP，常用），对比进行乐段（CPP，常用）。\n句式结构 通常由三个更小的部分组成，形成短-短-长（通常比例为1：1：2）的结构，称为句式结构。比如2小节+2小节+4小节的结构。通常是a-a\u0026rsquo;-b的结构。\n如果b中嵌套了另一个句式，比如4小节的B中嵌套了另一套a-a\u0026rsquo;-b（1+1+2），那么称为嵌套句式。\n这种句式结构可以替换乐句在乐段中使用。\n复乐段 当一个乐段的起句和结句都能在更小的层面上划分起句与结句，那么称之为复乐段。\n例如一个乐段由4+4的两个乐句组成。而一个复乐段可能更长，由8+8的两个乐句组成，而这两个乐句又可以分为4+4的部分。这个更小的乐句的终止式有很多组合，常见的有HC-HC-HC-PAC、IAC-HC-IAC-PAC等。\n至于为什么不分成两个乐段处理，即是因为只有正格终止足以结束乐段，如果划分为两个乐段可能有一个无法真正的结束。\n非对称乐段 3乐句、5乐句等单数乐句的乐段，称为非对称乐段。\n非对称乐段的各乐句都要用终止式结束，但要弱于最后的终止式。如果最后的终止太弱，都不能称为乐段，只能称为乐句组。\n构建方式：\n立刻重复起句或结句，如aab和abb。 应用新的材料，如abc。 结合上述两种，如aabbc、aabcc。 二段曲式（二部曲式） 二段曲式，说的是一部完整的作品能够解析为两个段落。二段曲式中的两个段落几乎总是标写了重复标记，因此又叫二段-重复曲式。\n虽然书上没有明说，但是这个两个段落指的应该通常是乐段。\n简单式\n当两个段落并未共享旋律材料时，称为简单式。\n分段式\n当第一段结尾的终止式是结束在主和弦上，称为分段式。\n延续式\n第一段结束游离了主和弦，紧接着的段落又延续了这个和弦，称为延续式。\n回旋式\n第二段的旋律材料在开始时与第一段不同，或者称为游离。但在之后又全部或部分的重复第一段的材料，称之为再现。这种结构叫做回旋式。\n平衡式\n可以看作是简单式或者回旋式的修改，第二段的材料不同，但是在最后终止时，采用了第一段的结尾。这称作平衡式。\n变奏曲式 延续变奏 延续变奏组曲中，主题相对简短（通常为一个乐句），留下不完整的效果是为了让每段变奏能浑然一体地接入到下一段变奏。并且往往通过（在时间上）重叠变奏来实现，一段变奏结束的主和弦同时作为下一变奏的开始。或者固定低音趋向V，而下一段变奏解决。\n延续变奏大多是用重复的乐思，称为固定音型，而不是一段抒情的曲调。固定音型为变奏的骨架，在此基础上改变音区、织体以及动机设计。\n固定音型一半出现在下方声部，并能直接作为重复的低音音型，称之为固定低音；重复和声音型，称之为恰空；既重复低音同时又重复和声音型的称之为帕萨卡利亚。通常情况下这三个术语可以互换使用。\n分段变奏 在分段变奏组曲中，主题与各变奏常常是用二段曲式（往往是回旋延续式二段曲式。）结束在本调上，因此他们是彼此分离的。\n在分段变奏组曲中，变奏之间往往会有很大的改变。\n三部曲式 三部曲式具有三部分旋律的设计（ABA或ABA\u0026rsquo;）以及三部分的调性结构（本调-对比调-本调）。回旋二段曲式虽然也有三部分旋律设计，但是调性结构只有两个部分（实际上书中给的图例说只有一个调）。\n分类 收拢性三部曲式\n假设三部曲式的三个段落各自都结束在其主和弦上，则称为收拢性三部曲式。\n分段性三部曲式\n当A段（不常见）或B段（常见）未在其主和弦上结束且这种收拢性结尾为该段调性运动不可或缺的一部分时，称之为分段性三部曲式。\n延续性三部曲式\n当AB都未结束在主和弦上，称之为延续性三部曲式。\n有时很难区分它和回旋二段曲式。要考虑B部在多大程度上依附于A部。假设没多少关联，则是三部曲式。假如主题或动机有关联且调性很少变化或不变，则二段曲式更合适。\n连接部与回头过渡 为了形成连续感，会写作过门段落。主调与新调之间的过门材料（A到B）称之为连接部。从对比掉返回主调的过门材料称之为回头过渡。\n再现的曲式：复三部曲式 在复三部曲式中，每一段都可以被分为小的二段曲式。\n书上给出的两个例子，两者都是收拢性三部曲式，小的二段曲式都是回旋二段曲式。\n返始咏叹调 是巴洛克时期最重要的三部曲式结构。给出的例子是分段性三部曲式。\n小步舞曲-三声中部曲式 ABA，A是小步舞曲，B是三声中部。\n回旋曲式 概论 可以看做是扩展的三部曲式。\n五段回旋曲式的结构为A1-B-A2-C-A3\n七段的为A1-B1-A2-C-A3-B2-A4\n其中交替循环的A1、A2、A3称为叠部。对比性材料如B、C称为插部。\n通常插部的调和原调不一样。\n古典主义晚期的五段回旋曲式的调性结构为：i-III-i-v-i。书上还给出的结构有I-V-I-i-I。\n七段回旋曲式的典型调性布局：\n大调\nI-V、i或IV-I-i、IV或vi-I-I或i-I\n小调\ni-III或v-i-iv、IV、III、VI或I-i-I-i\n尾声、连接部与回头过渡 在最后可能会出现一个新的段落，并不像是叠部，而仅仅只是用于确认本调并提供一个完美的结束。这一段称之为尾声。\n连接部与回头过渡同三部曲式。\n复回旋曲式 同三部曲式，是在回旋曲式的每一段内部嵌入二段曲式。书上的例子同样嵌入了回旋二段曲式。\n奏鸣曲式 概论 奏鸣曲式不是一套刚性规则，它是一种基本的作曲方式：\n开始的材料在主调上陈述（呈示部） 在对比调上陈述附加材料（展开部） 在主调上重述所有的材料（再现部） 奏鸣曲式的二段模式 奏鸣曲式可以看作是平衡与回旋延续式二段曲式的结合。\n呈示部与再现部根据和声的定义划分成两个部分。\n在第一调域（FTA）中，材料在主调上呈示；在第二调域（STA）中，初始呈示的材料是在对比调中（通常为大调中的V和小调中的III）。\nFTA是基于回旋二段曲式的特性，原材料在游离（展开部）之后返回（再现部），并用半终止中断。\nSTA是基于平衡二段曲式的特点，第二段（STA，往往用新的主题）在第一段（呈示部）结尾处出现，在这首作品（再现部）的结尾处返回主调。\n这就是奏鸣曲原则。\n和声布局是I(FTA)-V(STA)-HC(半终止)-I(FTA)-I(STA)。\n其中呈示部主要成分是FTA，末尾会出现STA（不在本调）。然后进入展开部，继续发展STA，直到一个半终止。之后切换到FTA开始再现部，FTA完成后要在本调上写STA。\n连接部 FTA到STA中往往会有一小段，称之为连接部（Tr），有两种类型：\n非独立连接部（DTr），用重述FTA的初始主题开始。 独立连接部（ITr），用新的主题材料。 这两种类型都是转调到STA并结束在新的主调或新的属调上。\n在再现部中，FTA和STA都保持在主调中，但是连接部可以不用保持，但连接部往往会重现于再现部。\n结尾段 用于结束呈示部。STA后紧接着的终止段，称之为结尾段（Cl）。这个结尾段紧跟着出现了STA中对比性的主体材料，并且是那段和声材料的结论性终止。目的是为了加强新调。结尾段往往长于STA。\n展开部与回头过渡 展开部通常是奏鸣曲式中最自由的段落，类似于二段曲式中的游离。\n回头过渡（RTr）是展开部的最后一个部分，属调准备在再现部中折返到属调。\n再现部与尾声 通常，再现部都会重复许多呈示部的音乐，但它会有一些重要的变化，其中最重要的不仅仅只是FTA的材料，而且还有STA与结尾段的材料并返回到主调。\n尾声出现在再现部之后。它们也可出现在呈示部的结尾，它们在那里被称之为小尾声。\n奏鸣曲式的其他特点与要素 单主题奏鸣曲式\nFTA开始的主题又在STA中出现了。\n缓慢的引子\n有些用奏鸣曲式塑造的乐章带有缓慢的引子，它涉及外来的和声领域、半音调、并结合了混合调式。尤其常见于交响曲中。缓慢的引子通常是开始在主调上（尽管I不太好确立），并最终进行到半终止结束。这种引子听上去像一个巨大的弱拍，要解决到FTA的主调上。\n和声的变异\n假再现\nFTA的主题出现在错误的调中；而真正的再现部是用主调，通常紧随其后。假再现实际上还是发展部的一部分。\n下属返回\n再现部没有从I而是从IV上开始。\n其他各种调性策略 三调呈示部\n常见于大调作品。STA进行到自然三度音的关系调，将传统的I-V分为了两步走，传统意义的属调是在呈示部的结尾才被确立。\n不便于分类的部分 对位转位 从书上看起来和对位法没有关系，故放在这个部分。\n对位转位指的是，声部之间的旋律互相交换出现在后续部分。这能使得作曲家从单一乐思中得到双倍的音乐价值。并且能使音乐保持明晰的统一。\n主要有：八度转位（音程的协和性质不变，并且不协和音的处理在转位中也是正确的。除了五度会被转成四度。）、十二度等等。\n复合旋律 有时会遇到只有一个或两个声部的作品，没有明晰表现的三和弦与七和弦。比如巴赫的作品。\n而不采用完整的和弦也能隐含和声的功效的重要技术之一就是复合旋律。\n通过依靠旋律在音区中的跳进，就能使得一条单线的隐伏配置到有音域划分的多个声部中。比如阿尔贝替低音这样的分解和弦就是一种方法。\n","date":"2022-07-24T13:25:42+08:00","permalink":"https://kegalas.top/p/%E5%AE%8C%E5%85%A8%E9%9F%B3%E4%B9%90%E7%90%86%E8%AE%BA%E6%95%99%E7%A8%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","title":"《完全音乐理论教程》读书笔记"},{"content":"不均匀分割空间的数据结构 有Oct-Tree，KD-Tree，BSP-Tree。\nOct-Tree是均匀地将一个正方体分为八个小正方体的结构。可以根据物体在某一部分的密度来决定是否往下分。\nKD-Tree是将空间分为两部分，可以是不均匀的。但是分的时候是轴对齐的。\nBSP-Tree也是分为两部分，但分的时候可以不轴对称。\nKD-Tree KD-Tree的要求如下\n对于中间节点，存储：\n分割空间的平面垂直的坐标轴 分割空间的平面在坐标轴上的坐标 指向儿子节点的指针 不存储任何物体的信息 对于叶子节点，存储\n包含的物体列表 层次包围盒(BVH) 这也是一种树，根节点是所有物体的包围盒。\n然后对节点进行分割，使得该节点划分为两个部分，每个部分都是一个包围盒，一个物体仅在一个包围盒中。\n如果一个节点被分割了，它就不再作为含有物体的包围盒。只有叶子节点含有包围盒。\n其中有几个注意事项：\n选择节点中的最长轴，如果物体有沿\\(x\\)轴分布的形状，则在\\(x\\)轴上将物体分为两部分。 分割节点选择在中间的物体。 当一个节点只有很少物体时停止分割 ","date":"2022-07-20T15:09:04+08:00","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","title":"计算机图形学基础学习笔记-数据结构"},{"content":"三角形网格的细分 Loop细分 Loop Subdivision分为两步\n创建更多三角形（顶点） 改变三角形顶点的位置 创建更多的三角形非常简单，只用将三角形每条边的中点相连，我们就得到了四个三角形。\n对于顶点的位置，新的顶点和老的顶点都需要更改。\n对于新的顶点：\n1.jpg\r对于老的顶点\n2.jpg\r更一般的网格的细分 Catmull-Clark细分 对于不是方形的面和度数（所连边数）不等于4的点要进行细分\n步骤如下：\n在每个面的上添加顶点 在每条边的上添加顶点 连接新顶点 添加的规则如下\n3.jpg\r网格简化 二次误差度量 4.jpg\r对于如上图的情况，不应该对顶点求平均值，而应该使得新的顶点到原来顶点的平方距离之和最小\n坍缩边的方法 通过坍缩某些边，然后使边的端点重合在一起，使得三角形减少。\n一个想法是将边的中点进行二次误差度量。\n5.jpg\r一个更好地想法是选择那些拥有最小二次误差的点。可以用优先队列来维护。\n","date":"2022-07-20T15:08:04+08:00","image":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9B%B2%E9%9D%A2%E7%BB%86%E5%88%86/cover_hu9da4564469e95373a7893edcdf989008_27817_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9B%B2%E9%9D%A2%E7%BB%86%E5%88%86/","title":"计算机图形学基础学习笔记-曲面细分"},{"content":"有两种方法描述几何：隐式的、显式的。\n几何的隐式表示 取决于某些点是否符合表达式。\n例如描述一个球面\\(x^2+y^2+z^2=1\\)，所有符合这个表达式的点就是一个球面。\n更一般的情况：满足\\(f(x,y,z)=0\\)的所有点。\n它的特点是，采样比较困难，但判断一个点在集合体内外或者在几何体上非常方便。\n隐式表示包含：\n代数方程表示(Algebraic Surfaces) 通过布尔表达式对几何体进行运算(Constructive Solid Geometry) 距离函数(Distance Functions) Blending Distance Functions 水平集(Level Set) 分形(Fractals) 几何的显式表示 所有的点直接给出，或者通过参数映射地给出。\n比如从二维映射到三维\n\\[f:\\mathbb{R^2\\to R^3};(u,v)\\to(x,y,z) \\]\n特点是，采样简单，但是判断关系较为困难。\n显式表示包含：\n点云(Point Cloud) 多边形网格(Polygon Mesh) 贝赛尔曲线(Bezier Curves) 贝塞尔曲线 Casteljau算法\n考虑平面上的三个点\\(b_0,b_1,b_2\\)，用线性差值的办法插入一个点到每一条边上。\n1.jpg\r将新增的两个点再利用相同的办法插入一个点。\n2.jpg\r然后对于插值的比例值\\([0,1]\\)上的所有点进行这个算法。\n3.jpg\r对于更多点，因为每次在边上进行插值后，新的点比原来的点少一个，反复进行这个算法直到只有一个点。\n4.jpg\r将这个过程公式化，对于三个点的情况，即为\n\\[b_0^1(t)=(1-t)b_0+tb_1\\\\ b_1^1(t)=(1-t)b_1+tb_2\\\\ b_0^2(t)=(1-t)b_0^1+tb_1^1 \\]\n\\[\\therefore b_0^2(t) = (1-t)^2b_0+2t(1-t)b_1+t^2b_2 \\]\n对于更多点的情况：\n\\[b^n(t) = b^n_0(t)=\\sum^n_{j=0}b_jB^n_j(t) \\]\n其中\n\\[B^n_i(t)=\\binom{n}{i}t^i(1-t)^{n-1} \\]\n也可以用递归的方法计算，比较简便。\n贝赛尔曲线的一些性质\n\\(t=0\\)是起点，\\(t=1\\)是终点。 曲线与端点段相切 仿射变换中，对控制点仿射变换再画曲线，和对已经画出来的曲线做仿射变换，得到的曲线是一样的。 曲线一定在控制点的凸包内 分段的贝赛尔曲线及其算法\n四个顶点构成的贝赛尔曲线为一段，再将许多贝赛尔曲线接到一起。\n这样的曲线一定是连续的，但光滑还有一个条件。即第一条曲线的第3、4个点的线段和第二条曲线的第1、2个点的线段长度、方向均相同。\n样条(Spline) TODO\n贝塞尔曲面 对于\\(4\\times 4\\)的控制点，首先在\\(u\\)方向上画出四条贝赛尔曲线，然后再在\\(v\\)方向上，根据四条贝塞尔曲线计算出四个控制点，再计算出曲面上的点。\n","date":"2022-07-20T13:47:39+08:00","image":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%87%A0%E4%BD%95%E7%9A%84%E8%A1%A8%E7%A4%BA%E6%96%B9%E6%B3%95/cover_hu6f2ff40bfc84c7f47df65f54ecbd43e8_39003_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%87%A0%E4%BD%95%E7%9A%84%E8%A1%A8%E7%A4%BA%E6%96%B9%E6%B3%95/","title":"计算机图形学基础学习笔记-几何的表示方法"},{"content":"纹理映射 纹理映射流程如下\n对于每个光栅化的屏幕采样点\\((x,y)\\)（通常是像素的中心点）\n令\\((u,v)\\)为纹理上对应于\\((x,y)\\)的坐标 对纹理上\\((u,v)\\)进行采样 将采样得到的颜色作为光栅化需要使用的颜色 纹理映射函数 从世界坐标\\((x,y,z)\\)映射到纹理坐标\\((u,v)\\)的函数。\n平面投影\n直接忽略掉\\(z\\)坐标（或者根据理解，是忽略掉法向量那个方向的坐标）（世界空间是\\([-1,1]^3\\)）：\n\\[\\phi(x,y,z)=(u,v)\\quad where\\quad \\begin{bmatrix} u \\\\ v \\\\ * \\\\ 1 \\end{bmatrix}=M_t \\begin{bmatrix} x \\\\ y \\\\ z \\\\ 1 \\end{bmatrix} \\]\n其中，\\(M_t\\)是一个仿射变换矩阵，而星号代表我们不在乎这个坐标。\n这个映射对于比较平的面的效果较好，但是对于一些闭合曲面（例如一个正方体）效果不佳。\n用透视投影替代正交投影，我们可以得到一个投影的纹理坐标\n\\[\\phi(x,y,z)=(\\tilde{u}/\\omega,\\tilde{v}/\\omega)\\quad where\\quad \\begin{bmatrix} \\tilde{u} \\\\ \\tilde{v} \\\\ * \\\\ \\omega \\end{bmatrix}=P_t \\begin{bmatrix} x \\\\ y \\\\ z \\\\ 1 \\end{bmatrix} \\]\n其中矩阵\\(P_t\\)代表着一个投影变换。这个投影纹理坐标在阴影贴图中有重要的作用。\n球体坐标\n从球体上的点\\((x,y,z)\\)映射到纹理上\\((u,v)\\)，假设球心在原点，并且世界空间是\\([-1,1]^3\\)，则因为\n\\[x = rcos\\phi sin\\theta\\\\ y = rsin\\phi sin\\theta\\\\ z = rcos\\theta \\]\n有\n\\[\\theta = acos(z/\\sqrt{x^2+y^2+z^2})\\\\ \\phi = atan2(y,x) \\]\n再转化为\\((u,v)\\)的形式，有：\n\\[\\phi(x,y,z) = ([\\pi+atan2(y,x)]/2\\pi,[\\pi-acos(z/||x||)]/\\pi) \\]\n圆柱体坐标\n世界空间是\\([-1,1]^3\\)，圆柱体中心在原点\n\\[\\phi(x,y,z)=([\\pi+atan2(y,x)]/2\\pi,[1+z]/2) \\]\n注，Fundamentals Of Computer Graphics中写的是\\(\\phi(x,y,z)=(\\frac{1}{2\\pi}[\\pi+atan2(y,x)]/2\\pi,\\frac{1}{2}[1+z])\\)，怀疑有误。\n纹理放大 双线性插值 现在假设纹理上需要采样的点的坐标为(x,y)，显然这个点会落在某个\\(2\\times2\\)的像素矩形中。\n设左下角的像素为\\(u_{00}\\)，左上\\(u_{01}\\)，右下\\(u_{10}\\)，右上\\(u_{11}\\)\n设左下角像素中心点为原点建立坐标系。横轴记为\\(s\\),纵轴记为\\(t\\)。则\\(u_{00}=(0,0)\\)，\\(u_{10}=(1,0)\\)，\\(u_{01}=(0,1)\\)，\\(u_{11}=(1,1)\\)\n记采样点(x,y)在这个坐标系下的坐标为\\((s,t)\\)\n设函数\\(lerp(x,v_0,v_1)=v_0+x(v_1-v_0)\\)\n这个函数的意义是，假设直线上两个点的值为\\(v_0,v_1\\)，\\(x\\)为这两个点间的坐标，\\(x\\)在\\(x_0\\)处等于\\(0\\)，在\\(x_1\\)处等于\\(1\\)。此时所得的函数值为\\(x\\)处的插值。\n现在我们可以对\\((s,t)\\)这个点进行插值，首先定义\n\\[u_0 = lerp(s,u_{00},u_{10}) u_1 = lerp(s,u_{01},u_{11}) \\]\n得到这两个点后再进行一次插值得\n\\[f(x,y) = lerp(t,u_0,u_1) \\]\n当然也可以先进行垂直的插值，再水平插值。\n双立方插值 TODO\n纹理缩小 Mipmap 当一个像素代表了纹理中的一大块时，需要进行纹理缩小。\n之前介绍的超采样等是可以使用的，只不过这样会导致开销过大。\n我们需要找到一种办法直接对区间求平均值。\n引入Mipmap的概念。它允许快速的、近似的（而非准确的）、方形的范围均值查询。\n假设第0层是原纹理图像（方形）。\n则第1层是将长宽各缩小为一半，所所放出来的纹理。第2层则为第1层缩小一半，以此类推直到只有一个像素。\n额外占用的存储空间只有原纹理的\\(1/3\\)。\n我们要计算应该使用第几层，首先确定我们要光栅化的像素的坐标(x,y)，然后将其对应到纹理上的坐标记为\\((u,v)\\)。\n找到它的邻居像素，例如右边像素，然后如图进行计算。\n1.jpg\r存在的一个问题就是，层数是不连续的，但我们的空间是连续的。所以每一层mipmap在纹理映射时会出现块状的、不连续的现象。\n三线性插值 为了解决mipmap不连续的现象，引入三线性插值。\n在\\(D\\)层进行双线性插值 在\\(D+1\\)层进行双线性插值 对\\(D,D+1\\)层进行一次线性插值 Mipmap的缺陷 相较于超采样，在远处会出现模糊现象。原因在于，只能查询一个方形取余、近似的、以及是插值得到的。\n解决（部分的）办法：各向异性过滤。\n比各向异性过滤更好的：EWA过滤。\n纹理的应用 环境光贴图 将整个环境做成贴图，可以给比较镜面光滑的物体使用，使之反射出环境的样子。\n除了保存成方形的贴图，还可以保存在球面上。\n保存在球面上带来的问题是，越靠近上下的地方，越会出现变形。此时可以将球上的点映射到一个立方体上，来解决这种变形。\n2.jpg\r法线贴图 储存一个相对高度，从而改变某一点的法线，从而改变光照效果，从而实现凹凸不平的视觉效果。\n新的法向量的计算方法：\n二维情况：\n假设原来\\(p\\)点的法向量\\(n(p)=(0,1)\\)。\n将\\(p\\)点通过法线贴图的相对高度移到对应位置，则\\(p\\)点此时的导数为\\(dp=c[h(p+1)-h(p)]\\)，其中\\(c\\)是常数，\\(h(x)\\)是高度函数。\n则新的法向量为\\(n(p)=(-dp,1).normalized()\\)\n三维情况\n原始法向量为\\(n(p)=(0,0,1)\\)\n导数为\n\\[\\frac{dp}{du} = c_1[h(u+1)-h(u)] \\]\n\\[\\frac{dp}{dv} = c_2[h(v+1)-h(v)] \\]\n新的法向量为\\((-dp/du,-dp/dv,1)\\)\n法向量的一般情况\n对于原法向量为\\(\\bm n=(x,y,z)\\)的，首先令\n\\[\\bm t = \\left(\\frac{xy}{\\sqrt{x^2+z^2}},\\sqrt{x^2+z^2},\\frac{zy}{\\sqrt{x^2+z^2}}\\right) \\]\n\\[\\bm b = \\bm n\\times\\bm t \\]\n\\[TBN = [\\bm{t,b,n}] \\]\n\\[dU = kh\\cdot kn\\cdot(h(u+1/w,v)-h(u,v)) \\]\n\\[dV = kh\\cdot kn\\cdot(h(u,v+1/h)-h(u,v)) \\]\n其中\\(kh,kn\\)是常数，\\(h(u,v)\\)是高度函数,\\(h,w\\)是纹理的高度和宽度。\n\\[\\bm{ln} = (-dU,-dV,1) \\]\n那么最终得到的法向量为\n\\[\\bm n = normalize(TBN\\cdot \\bm{ln}) \\]\n将法线的XYZ坐标以RGB的形式存储\n有些法线贴图会将法线的xyz坐标以RGB的形式存储。要得到\\([-1,1]\\)上的法线方向坐标，要经过两次转换。首先将\\(0\\sim 255\\)的\\(RGB\\)换到\\([0,1]\\)的形式，然后再转换到\\([0,1]*2-1=[-1,1]\\)。\n这在有些时候比从模型中顶点的法向量来插值计算内部点的法向量要更有细节。\n切线空间存储法向量\n在切线空间存储法向量时，会直接存储某个值的值作为颜色（当然也要转化到\\([-1,1]\\)），我们要做的就是计算出切线空间的基，然后将其转化为世界坐标中的法向量。\n对于一个三角形上的三个点\\(p_0,p_1,p_2\\)，以及这个三角形的法向量\\(\\bm n\\)。设\\(u_0,u_1,u_2\\)分别为三个点的纹理上的\\(u\\)坐标，\\(v_0,v_1,v_2\\)为\\(v\\)坐标。那么就有\n\\[\\bm i = A^{-1}\\begin{pmatrix} u_1-u_0 \\\\ u_2-u_0 \\\\ 0 \\end{pmatrix} \\]\n\\[\\bm j = A^{-1}\\begin{pmatrix} v_1-v_0 \\\\ v_2-v_0 \\\\ 0 \\end{pmatrix} \\]\n其中\n\\[A = \\begin{pmatrix} \\overrightarrow{p0p1} \\\\ \\overrightarrow{p0p2} \\\\ \\bm n \\end{pmatrix} \\]\n之后切线空间的基就是\\((\\bm i,\\bm j,\\bm n)\\)，将其乘以纹理中提取到的值，就得到世界坐标中的法向量。\n位移贴图 与法线贴图类似，但是位移贴图真正地移动了顶点的位置，很多时候比法线贴图真实。\n噪声 TODO\n对纹理进行环境光预处理 TODO\n3D贴图和体积渲染 TODO\n阴影贴图 将光源也当作一个相机，进行光栅化，只计算zbuffer的信息。\n然后在相机光栅化时，判断两个zbuffer是否相等，相等才能被相机和光源看见。不相等的则在阴影中。\n","date":"2022-07-14T16:53:03+08:00","image":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%B4%B4%E5%9B%BE/cover_hu19fc7c044e05b48ede368f76a4a534a3_160946_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%B4%B4%E5%9B%BE/","title":"计算机图形学基础学习笔记-贴图"},{"content":"点光源 假设点光源的光的强度（能流密度）是\\(E=I\\)，由于点光源向外发送能量是以球面波的形式发送。在距离光源\\(r\\)处的波面上，光的强度是\\(E=\\frac{I}{r^2}\\)。这一点与大学物理相同。\nBlinn-Phong反射模型 首先给出以下定义：\n对于某个物体上需要被着色的某一点。其单位法向量为\\(\\bm n\\)，这一点指向相机的单位向量为\\(\\bm v\\)，指向光源的向量为\\(\\bm l\\)。\n漫反射 漫反射意味着，从四面八方看过来，这个位置的颜色是一致的。\n我们主要关注，这个位置与光源的角度关系，从而得出这个点的颜色。\nLambert\u0026rsquo;s cosine law\n假设光源到达这个点的强度是\\(E=I\\)，那么经过漫反射后，其强度变为\\(E=Icos\\theta\\)，即\\(E=I\\cdot\\bm l\\cdot\\bm n\\)\n结合点光源，以及漫反射系数，可得\n\\[L_d=k_d(\\frac{I}{r^2})max(0,\\bm n\\cdot\\bm l) \\]\n其中，\\(k_d\\)是漫反射系数，与材质有关。\\(I\\)是点光源的强度，\\(r\\)是点光源到需要着色的点的距离。后面max的作用是，防止从“内部”或者“下面”射来的光线影响了“表面”的颜色。\n通常，\\(k_d\\)是一个三维向量，如果将纹理颜色赋值给\\(k_d\\)，则会起到给模型贴纹理的效果。\n\\(L_d\\)和\\(I\\)也是三维向量，\\(I\\)不仅可以代表光的强度，也可以表示光的颜色。\\(k_d\\)与\\(I\\)的乘法是元素之间相乘。在Eigen中使用cwiseProduct函数。\n镜面反射 即，某些材质中，反射角等于入射角，或者反射角很接近入射角时，出现的光强明显大于其他角度的情况。\n此时\\(\\bm v\\)非常接近反射角，或者有，半程向量非常接近于法向量\\(\\bm n\\)。\n半程向量即是\\(\\bm l,\\bm v\\)的角平分线的单位向量。有\n\\[\\bm h = \\frac{\\bm v+\\bm l}{||\\bm v+\\bm l||} \\]\n此时相机收到的光强为\n\\[L_s = k_s(\\frac{I}{r^2})max(0,\\bm n\\cdot\\bm h)^p \\]\n其中\\(k_s\\)是镜面反射系数，\\(p\\)决定了\\(\\bm v\\)和反射角有多接近才算能触发镜面反射。\\(p\\)越大触发镜面反射的角度范围越小。通常会取到\\(100\\)以上。\n\\(k_s,L_s,I\\)仍然是三维向量，乘法规则同前，只不过这里的\\(k_s\\)通常会采用比较亮的白色，而不会采用其他颜色。\n环境光反射 即通过整个环境其他物体的反射，再次射入该物体，给该物体提供亮度。\n在Blinn-Phong模型中，我们选择添加常数的亮度。\n\\[L_a = k_aI_a \\]\n\\(k_a\\)是环境光反射常数。\n\\(k_a,L_a,I_a\\)仍然是三维向量，乘法规则同前，只不过这里的\\(k_s\\)通常会采用比较暗的白色，而不会采用其他颜色。\n注意，有多个光源时，不要重复添加环境光反射。\n三个反射混合 \\[L = L_a+L_d+L_s \\]\n","date":"2022-07-13T21:49:11+08:00","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B/","title":"计算机图形学基础学习笔记-光照模型"},{"content":"光栅化 线段绘制 对于一条给定线段\n\\[f(x,y)\\equiv(y_0-y_1)x+(x_1-x_0)y+x_0y_1-x_1y_0=0 \\]\n假设\\(x_0\\leq x_1\\)，否则交换两个点。\n设\n\\[m=\\frac{y_1-y_0}{x_1-x_0} \\]\n下面的讨论建立在\\(m\\in (0,1]\\)上，其他的取值情况类似。\n给出伪代码如下\ny=y0 for x=x0 to x1 do draw(x,y) if(some condition) then y = y+1 其中\\(x,y\\)都取整数。\n一种判断\\(y=y+1\\)的方法是，假设当前画出来的点的坐标（而不是序号下标）是\\((x,y)\\)（根据本书的规则，左下角的像素的中心点是原点），则下一个要画的点只有两种情况，要么是右边的点，要么是右上角的点。即\\((x+1,y),(x+1,y+1)\\)，我们取中点，即\\((x+1,y+0.5)\\)，如果直线在这个点的下方，则画右边的点；如果直线在这个点的上方，则画右上方的点。\n如果直线在上方（或者点在下方），那么\\(f(x+1,y+0.5)\u003c0\\)，在下方则大于0.如果刚好等于零，可以任意画。\n所以可以写伪代码如下\nif f(x+1,y+0.5)\u0026lt;0 then y=y+1 对于这个算法有优化的办法。主要是针对每次都要调用\\(f\\)计算来进行的优化。\n注意到我们可能计算过\\(f(x-1,y+0.5),f(x-1,y-0.5)\\)，并且我们有\n\\[f(x+1,y)=f(x,y)+(y_0-y_1) \\]\n\\[f(x+1,y+1) = f(x,y)+(y_0-y_1)+(x_1-x_0) \\]\n有如下伪代码\ny = y0 d = f(x0+1,y0+0.5) for x = x0 to x1 do draw(x,y) if d\u0026lt;0 then y = y+1 d = d+(x1-x0)+(y0-y1) else d = d+(y0-y1) 三角形绘制 高洛德插值(Gouraud Interpolation)\n运用重心坐标系，我们可以对颜色进行插值。\n假设三个点的颜色值分别为\\(\\bm c_0,\\bm c_1,\\bm c_2\\)。假设我们要绘制的点的重心坐标为\\((\\alpha,\\beta,\\gamma)\\)，则其颜色为\n\\[\\bm c = \\alpha\\bm c_0+\\beta\\bm c_1+\\gamma\\bm c_2 \\]\n暴力光栅化算法\n伪代码如下\nfor all x do for all y do compute(alpha,beta,gamma) for (x,y) if(alpha,beta,gamma in [0,1]) then c = alpha*c0+beta*c1+gamma*c2 drawpixel(x,y) with color c 优化后的算法\nxMin = floor(xi) xMax = ceiling(xi) yMin = floor(yi) yMax = ceiling(yi) for y = yMin to yMax do for x = xMin to xMax do alpha = f12(x,y)/f12(x0,y0) beta = f20(x,y)/f20(x1,y1) gamma = f01(x,y)/f01(x2,y2) if(alpha,beta,gamma\u0026gt;0) then c=alpha*c0+beta*c1+gamma*c2 drawpixel(x,y) with color c 其中的\\(f_{ij}\\)为\n\\[f_{01}(x,y) = (y_0-y_1)x+(x_1-x_0)y+x_0y_1-x_1y_0\\\\ f_{12}(x,y) = (y_1-y_2)x+(x_2-x_1)y+x_1y_2-x_2y_1\\\\ f_{20}(x,y) = (y_2-y_0)x+(x_0-x_2)y+x_2y_0-x_0y_2 \\]\n对于公共边上的点的处理\nxMin = floor(xi) xMax = ceiling(xi) yMin = floor(yi) yMax = ceiling(yi) fAlpha = f12(x0,y0) fBeta = f20(x1,x1) fGamma = f01(x2,y2) for y = yMin to yMax do for x = xMin to xMax do alpha = f12(x,y)/fAlpha beta = f20(x,y)/fBeta gamma = f01(x,y)/fGamma if(alpha,beta,gamma\u0026gt;=0) then if(alpha\u0026gt;0 or fAlpha*f12(-1,-1)\u0026gt;0)and (beta\u0026gt;0 or fBeta*f20(-1,-1)\u0026gt;0)and (gamma\u0026gt;0 or fGamma*f01(-1,-1)\u0026gt;0) then c=alpha*c0+beta*c1+gamma*c2 drawpixel(x,y) with color c 用Z-Buffer处理覆盖问题 为了处理方便，假设\\(z\\)始终为正，且更小的\\(z\\)意味着更近，更大的\\(z\\)意味着更远。\n算法如下\n首先给\\(z-buffer\\)赋值无限大。\n在光栅化过程中，执行如下伪代码\nfor (each triangle T) for (each sample (x,y,z) in T) if(z\u0026lt;zbuffer[x,y]) framebuffer[x,y] = rgb; zbuffer[x,y] = z; else ; 即为，对每个三角形的采样像素，如果他的深度坐标，即\\(z\\)更小，那么在缓冲区更新这个像素的颜色，并且更新最小的\\(z\\)。\n该算法的复杂度是\\(O(n)\\)，对于\\(n\\)个三角形。\n着色频率的问题（Shading Frequencies） 对每个平面着色 又叫Flat着色。\n对每个顶点着色 又叫Gouraud着色。\n一个顶点的单位法向量，可以由以这个点为顶点的所有三角形的法向量求出。\n\\[N_v=\\frac{\\sum_iN_i}{||\\sum_iN_i||} \\]\n然后这个单位法向量可以用于Blinn-Phong反射模型中。\n再之后，对于平面内的点的着色，需要使用插值算法。\n对每个片元（像素）着色 又称Phong着色。\n对于每个像素的单位法向量，假设我们已经知道顶点的法向量，我们可以采用重心坐标插值的算法来计算出每个像素的单位法向量。\n图形管线的工作流程 程序输入顶点 将顶点在屏幕中定位 根据顶点在屏幕中定位三角形 根据三角形进行光栅化 对于光栅化后的片元进行着色 输出到帧缓冲，最后输出到屏幕。 ","date":"2022-07-03T15:21:12+08:00","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%89%E6%A0%85%E5%8C%96%E4%B8%8E%E7%9D%80%E8%89%B2%E9%A2%91%E7%8E%87/","title":"计算机图形学基础学习笔记-光栅化与着色频率"},{"content":"分辨率与坐标 假设屏幕分辨率是\\(n_x\\times n_y\\)，则，按照本书的规则，左下角的像素的中心点定为原点，那么有坐标范围为\\([-0.5,n_x-0.5]\\times [-0.5,n_y-0.5]\\)。若按照games101的规则，则坐标范围为\\([0,n_x]\\times[0,n_y]\\)。\nRGB格式 出于方便目的，RGB的三个分量的取值范围都是\\([0,1]\\)。在具体实现时，如8-bit图片，每个分量的所有可能的取值为\\(0,1/255,2/255,\\cdots,254/255,1\\)。\n","date":"2022-07-03T15:05:15+08:00","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%85%89%E6%A0%85%E5%8C%96%E5%9B%BE%E5%83%8F%E7%9A%84%E6%A0%87%E5%87%86/","title":"计算机图形学基础学习笔记-光栅化图像的标准"},{"content":"在MSYS2中安装程序时遇到如下问题：\nerror: mingw-w64-x86_64-mpc: signature from \u0026#34;David Macek \u0026lt;david.macek.0@gmail.com\u0026gt;\u0026#34; is unknown trust 尝试通过https://packages.msys2.org/中提供的方法，安装了key，解决问题。\n或者直接输入pacman -S msys2-keyring\n","date":"2022-07-01T12:05:59+08:00","permalink":"https://kegalas.top/p/msys2%E6%8A%A5%E9%94%99david-macek-is-unknown-trust/","title":"MSYS2报错David Macek is unknown trust"},{"content":"Viewing Transformations 视口变换（Viewport Transformation） 将\\([-1,1]^2\\)的正方形映射到屏幕上。这个屏幕宽\\(n_x\\)像素，高\\(n_y\\)像素。并且由于左下角像素中心点位置为原点，我们要有负0.5个像素，即映射到\\([-0.5,n_x-0.5]\\times[-0.5,n_y-0.5]\\)。（注，在games101中映射到的是\\([0,n_x]\\times[0,n_y]\\)）\n需要如下变换\n\\[\\begin{bmatrix} x_{screen} \\\\ y_{screen} \\\\ 1 \\end{bmatrix}= \\begin{bmatrix} n_x/2 \u0026 0 \u0026 (n_x-1)/2\\\\ 0 \u0026 n_y/2 \u0026 (n_y-1)/2\\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} x_{canonical}\\\\ y_{canonical}\\\\ 1 \\end{bmatrix} \\]\n三维形式有\n\\[M_{vp}= \\begin{bmatrix} n_x/2 \u0026 0 \u0026 0 \u0026 (n_x-1)/2\\\\ 0 \u0026 n_y/2 \u0026 0 \u0026 (n_y-1)/2\\\\ 0 \u0026 0 \u0026 1 \u00260\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n正交投影变换（Orthographic Projection Transformation） 将一个\\([l,r]\\times[b,t]\\times[f,n]\\)矩阵变换到\\([-1,1]^3\\)。\n其中\\(l\\)即left是\\(x\\)坐标小的平面，\\(r\\)即right是\\(x\\)坐标大的平面。\n其中\\(b\\)即bottom是\\(y\\)坐标小的平面，\\(t\\)即top是\\(y\\)坐标大的平面。\n其中\\(f\\)即far是\\(z\\)坐标小的平面，\\(n\\)即near是\\(z\\)坐标大的平面。\n注意\\(z\\)可能与常识不太相同，因为我们的相机所看的方向是\\(-z\\)方向。\n这也导致了OpenGL使用左手坐标系。\n完成这个变换的矩阵是\n\\[\\begin{bmatrix} \\frac{2}{r-l} \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 \\frac{2}{t-b} \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 \\frac{2}{n-f} \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 -\\frac{r+l}{2}\\\\ 0 \u0026 1 \u0026 0 \u0026 -\\frac{t+b}{2}\\\\ 0 \u0026 0 \u0026 1 \u0026 -\\frac{n+f}{2}\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix}= \\]\n\\[\\begin{bmatrix} \\frac{2}{r-l} \u0026 0 \u0026 0 \u0026 -\\frac{r+l}{r-l}\\\\ 0 \u0026 \\frac{2}{t-b} \u0026 0 \u0026 -\\frac{t+b}{t-b}\\\\ 0 \u0026 0 \u0026 \\frac{2}{n-f} \u0026 -\\frac{n+f}{n-f}\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n相机变换（Camera Transformation） 首先知道三个向量：\n\\(\\bm e\\)，相机位置（eye position）向量 \\(\\hat{\\bm g}\\)，相机视线（gaze）方向。 \\(\\hat{\\bm t}\\)，相机头顶方向。（和视线方向正交） 我们要将相机位置变换到原点，将视线方向定为\\(-z\\)方向，头顶方向为\\(y\\)方向。同时所有物体都跟随相机变换，最终结果相机看到的画面不变。\n首先，显然的，将相机位置变换到原点的矩阵是\n\\[T_{view} \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 -x_e\\\\ 0 \u0026 1 \u0026 0 \u0026 -y_e\\\\ 0 \u0026 0 \u0026 1 \u0026 -z_e\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n然后对两个另外两个向量进行旋转，直接想不太方便，可以反过来由\\(z\\)和\\(y\\)变换到\\(-\\hat g\\)和\\(\\hat t\\)，\\(x\\)变换到\\(\\hat g\\times \\hat t\\)\n\\[R_{view}^{-1}= \\begin{bmatrix} x_{\\hat g\\times \\hat t} \u0026 x_{\\hat t} \u0026 x_{-\\hat{g}} \u0026 0\\\\ y_{\\hat g\\times \\hat t} \u0026 y_{\\hat t} \u0026 y_{-\\hat{g}} \u0026 0\\\\ z_{\\hat g\\times \\hat t} \u0026 z_{\\hat t} \u0026 z_{-\\hat{g}} \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n然后再得到逆变换，由于这是个正交矩阵，逆矩阵就是转置矩阵\n\\[R_{view}= \\begin{bmatrix} x_{\\hat g\\times \\hat t} \u0026 y_{\\hat g\\times \\hat t} \u0026 z_{\\hat g\\times \\hat t} \u0026 0\\\\ x_{\\hat t} \u0026 y_{\\hat t} \u0026 z_{\\hat t} \u0026 0\\\\ x_{-\\hat{g}} \u0026 y_{-\\hat{g}} \u0026 z_{-\\hat{g}} \u0026 0\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n另一种算法\n假设我们初始时相机在\\((0,0,0)\\)，相机视线方向为\\((0,0,1)\\)，相机的上方向为\\((0,1,0)\\)。\n此时相机变换到\\(e\\)，我们保持相机上向量相对不变，而左向量\\(x\\)轴方向就为\\(\\hat r=((\\hat g-e)\\times (0,1,0)).normalized\\)，从而新的上方向则变为\\(\\hat t=(\\hat g-e)\\times\\hat r\\)。\n如果想改变上方向，则就把初始的上方向改变即可，整个变换矩阵同上。\n透视投影（Perspective Projection） 由正交投影变换到透视投影，矩阵如下\n\\[P= \\begin{bmatrix} n \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 n \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 n+f \u0026 -fn\\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\end{bmatrix} \\]\n直观上的理解就是，将视锥中远平面压小到等于近平面。\n以上是games101的解释。\n在Real-Time Rendering的解释中，假设我们的相机在原点，我们想将任意一个点\\(p\\)，映射到平面\\(z=-d(d\u003e0)\\)上，得到一个新点\\(q=(q_x,q_y,-d)\\)。显然根据相似三角形，我们有\n\\[\\frac{q_x}{p_x}=\\frac{-d}{p_z}\\Rightarrow q_x = -d\\frac{p_x}{p_z} \\]\n对于\\(y\\)坐标也是同样的，所以能得到矩阵\n\\[P_p = \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 1 \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \u0026 0\\\\ 0 \u0026 0 \u0026 -1/d \u0026 0 \\end{bmatrix} \\]\n因为\n\\[q=P_pp= \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 1 \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \u0026 0\\\\ 0 \u0026 0 \u0026 -1/d \u0026 0 \\end{bmatrix} \\begin{bmatrix} p_x \\\\ p_y \\\\ p_z \\\\ 1 \\end{bmatrix}= \\begin{bmatrix} p_x \\\\ p_y \\\\ p_z \\\\ -p_z/d \\end{bmatrix}\\Rightarrow \\begin{bmatrix} -dp_x/p_z \\\\ -dp_y/p_z \\\\ -d \\\\ 1 \\end{bmatrix} \\]\n但我们通常要做的不是把点都映射到一个平面上，而是要把视锥压缩到一个\\([-1,1]^3\\)的立方体上。\n这个视锥体是一个四棱椎，相机在椎顶，近平面\\(n\\)，远平面\\(f\\)，有\\(0\u003en\u003ef\\)。因此四棱锥被截成了四棱台。以相机的角度，上下侧面分别为\\(t,b\\)，左右侧面分别为\\(l,r\\)。\n对于近平面，左下角是\\((l,b,n)\\)，右上角是\\((r,t,n)\\)，决定了我们能看到的画面的大小，或称作视野范围。\n将这样的视锥变为\\([-1,1]^3\\)的矩阵是\n\\[P_p=\\begin{bmatrix} \\frac{2n}{r-l} \u0026 0 \u0026 -\\frac{r+l}{r-l} \u0026 0\\\\ 0 \u0026 \\frac{2n}{t-b} \u0026 -\\frac{t+b}{t-b} \u0026 0\\\\ 0 \u0026 0 \u0026 \\frac{f+n}{f-n} \u0026 -\\frac{2fn}{f-n}\\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\end{bmatrix} \\]\n也正好和上方games101的正交投影矩阵*透视投影矩阵相同。\n然后，不在\\(n,f\\)平面之间的物体将会被剔除，不被渲染。\n如果远平面是无穷远，那么有\n\\[P_p=\\begin{bmatrix} \\frac{2n}{r-l} \u0026 0 \u0026 -\\frac{r+l}{r-l} \u0026 0\\\\ 0 \u0026 \\frac{2n}{t-b} \u0026 -\\frac{t+b}{t-b} \u0026 0\\\\ 0 \u0026 0 \u0026 1 \u0026 -2n\\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\end{bmatrix} \\]\nOpenGL中的透视矩阵\n虽然都是右手系，但是OpenGL中zNear和zFar都是正数，透视矩阵就变为\n\\[P_p=\\begin{bmatrix} \\frac{2n}{r-l} \u0026 0 \u0026 \\frac{r+l}{r-l} \u0026 0\\\\ 0 \u0026 \\frac{2n}{t-b} \u0026 \\frac{t+b}{t-b} \u0026 0\\\\ 0 \u0026 0 \u0026 -\\frac{f+n}{f-n} \u0026 -\\frac{2fn}{f-n}\\\\ 0 \u0026 0 \u0026 -1 \u0026 0 \\end{bmatrix} \\]\n另外，OpenGL默认（指glm库）有\\(r=-l,t=-d\\)，就有\n\\[P_p=\\begin{bmatrix} c/a \u0026 0 \u0026 0 \u0026 0\\\\ 0 \u0026 c \u0026 0 \u0026 0\\\\ 0 \u0026 0 \u0026 -\\frac{f+n}{f-n} \u0026 -\\frac{2fn}{f-n}\\\\ 0 \u0026 0 \u0026 -1 \u0026 0 \\end{bmatrix} \\]\n其中\\(a\\)是显示分辨率的宽高比，\\(c\\)是\\(1/tan(fovY/2)\\)\n另外，将\\(z\\)轴上的\\([-0.1,-100]\\)映射到\\([-1,1]\\)上，不是均匀的，不精确的说，可能\\([-0.1+,1.0]\\)这一段映射到了\\([-1,0.5]\\)上，剩下的\\([1.0,100]\\)映射到了\\([0.5,1]\\)上，这在zbuffer、深度值中可能是需要注意的事。\n可以看https://learnopengl-cn.github.io/04 Advanced OpenGL/01 Depth testing/#_3了解具体的关系。\n视野（Field-of-View） 通常，对于近平面，我们可以用\\(l,r,b,t\\)描述（假设\\(l=-r,b=-t\\)，即平面中心位于\\(-z\\)轴上，且平面与\\(-z\\)垂直），也可以用垂直视野\\(fovY\\)和近平面的宽高比来表示。\n首先相机到近平面的距离为\\(|n|\\)，则有如下关系\n\\[tan\\frac{fovY}{2} = \\frac{t}{|n|} \\]\n\\[aspect = \\frac{r}{t} \\]\n","date":"2022-06-28T12:14:24+08:00","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%A7%86%E8%A7%92/","title":"计算机图形学基础学习笔记-视角"},{"content":"放缩 \\[scale(s_x,s_y)= \\begin{bmatrix} s_x \u0026 0\\\\ 0 \u0026 s_y \\end{bmatrix} \\]\n\\[\\begin{bmatrix} s_x \u0026 0\\\\ 0 \u0026 s_y \\end{bmatrix} \\begin{bmatrix} x\\\\ y \\end{bmatrix}= \\begin{bmatrix} s_xx\\\\ s_yy \\end{bmatrix} \\]\n例如长宽各缩小为0.5倍，有\n\\[scale(0.5,0.5)= \\begin{bmatrix} 0.5 \u0026 0\\\\ 0 \u0026 0.5 \\end{bmatrix} \\]\n切变 切变，想象一个由四根木条和四个钉子组装而成的正方形，我们可以将其“推”成一个平行四边形。但是在图形学中，长和高不变，意味着有两条边的长度会发生变化。\n\\[shear-x(s)=\\begin{bmatrix} 1 \u0026 s\\\\ 0 \u0026 1 \\end{bmatrix}, shear-y(s)=\\begin{bmatrix} 1 \u0026 0\\\\ s \u0026 1 \\end{bmatrix} \\]\n另外一种关于切变的理解是，仅仅对着x坐标或者y坐标进行了旋转操作，例如正向旋转（逆时针）\\(\\phi\\)，则有\n\\[\\begin{bmatrix} 1 \u0026 tan\\phi\\\\ 0 \u0026 1 \\end{bmatrix} or \\begin{bmatrix} 1 \u0026 0\\\\ tan\\phi \u0026 1 \\end{bmatrix} \\]\n旋转 顺时针转过\\(\\phi\\)，则\n\\[rotate(\\phi) = \\begin{bmatrix} cos\\phi \u0026 -sin\\phi\\\\ sin\\phi \u0026 cos\\phi \\end{bmatrix} \\]\n镜像 即关于\\(x\\)轴或\\(y\\)轴将整个图像颠倒过来，有\n\\[reflect-y = \\begin{bmatrix} -1 \u0026 0\\\\ 0 \u0026 1 \\end{bmatrix}, reflect-x = \\begin{bmatrix} 1 \u0026 0\\\\ 0 \u0026 -1 \\end{bmatrix} \\]\n线性变换的复合 对于两个变换\\(\\bm S,R\\)\n\\[first,\\bm v_2=\\bm{Sv}_1,then,\\bm v_3=\\bm{Sv}_2 \\]\n那么就可以写作\n\\[\\bm v_3=\\bm R(\\bm{Sv}_1) \\]\n根据结合律，写作\n\\[\\bm v_3=(\\bm{RS})\\bm{v}_1 \\]\n则\\(\\bm{M=RS}\\)就是复合变换，其中变换顺序是从右到左的。\n线性变换的拆分 例如，有一个\\(2\\times 2\\)正方形的左下角在点\\((1,1)\\)处，我们想要将它绕\\((1,1)\\)旋转\\(\\phi\\)度，我们就可以拆分成三个变换。首先，左下角平移到原点；然后，进行旋转；最后再平移回去。\n三维线性变换 总体来说，三维线性变换就是二维的扩展\n\\[scale(s_x,s_y,s_z)= \\begin{bmatrix} s_x \u0026 0 \u0026 0\\\\ 0 \u0026 s_y \u0026 0\\\\ 0 \u0026 0 \u0026 s_z \\end{bmatrix} \\]\n\\[rotate-z(\\phi)= \\begin{bmatrix} cos\\phi \u0026 -sin\\phi \u0026 0\\\\ sin\\phi \u0026 cos\\phi \u0026 0\\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n\\[rotate-x(\\phi)= \\begin{bmatrix} 1 \u0026 0 \u0026 0\\\\ 0 \u0026 cos\\phi \u0026 -sin\\phi\\\\ 0 \u0026 sin\\phi \u0026 cos\\phi \\end{bmatrix} \\]\n\\[rotate-y(\\phi)= \\begin{bmatrix} cos\\phi \u0026 0 \u0026 sin\\phi\\\\ 0 \u0026 1 \u0026 0\\\\ -sin\\phi \u0026 0 \u0026 cos\\phi \\end{bmatrix} \\]\n\\[shear-x(d_y,d_z)= \\begin{bmatrix} 1 \u0026 d_y \u0026 d_z\\\\ 0 \u0026 1 \u0026 0\\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n如果要绕过原点的固定轴\\(\\bm n\\)旋转，可以有罗德里格斯公式如下\n\\[\\bm R(\\bm n,\\alpha) = cos(\\alpha)\\bm I+(1-cos(\\alpha))\\bm{nn}^T+sin(\\alpha)\\bm N \\]\n其中\\(\\bm I\\)是单位矩阵，\n\\[\\bm N= \\begin{bmatrix} 0 \u0026 -n_z \u0026 n_y\\\\ n_z \u0026 0 \u0026 -n_x\\\\ -n_y \u0026 n_x \u0026 0 \\end{bmatrix} \\]\n平移 平移不能被写作矩阵的形式，所以它不是线性变换。\n\\[\\begin{bmatrix} x'\\\\ y' \\end{bmatrix}= \\begin{bmatrix} a \u0026 b\\\\ c \u0026 d \\end{bmatrix} \\begin{bmatrix} x\\\\ y \\end{bmatrix}+ \\begin{bmatrix} t_x\\\\ t_y \\end{bmatrix} \\]\n但是我们仍然有办法用矩阵来表示平移，这需要转化为齐次矩阵。\n为坐标（二维坐标）添加第三维，\n对于二维点，\\((x,y,1)^T\\) 对于二维向量，\\((x,y,0)^T\\) 于是我们有平移变换如下\n\\[\\begin{bmatrix} x'\\\\ y'\\\\ w' \\end{bmatrix}= \\begin{bmatrix} 1 \u0026 0 \u0026 t_x\\\\ 0 \u0026 1 \u0026 t_y\\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix}\\cdot \\begin{bmatrix} x\\\\ y\\\\ 1 \\end{bmatrix}= \\begin{bmatrix} x+t_x\\\\ y+t_y\\\\ 1 \\end{bmatrix} \\]\n并且这样定义点和向量有好处，向量加向量是向量，点减点是向量，点加向量是向量。\n平移一个向量，对于自由向量来说，起点都是远点，所以平移向量不会改变向量的坐标表示。为此设置第三维为0是合理的。\n同样地，在复合变换时，用矩阵乘法来复合。\n如果一个向量仅仅代表方向，例如法向量、平行光方向向量，不希望平移变换影响到这些向量，那么可以把第三维（对于三维向量是第四维）设置为零。此时除了平移，其他变换仍然能正常工作。\n三维平移 \\[\\bm T(t_x,t_y,t_z)=\\ \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 t_x\\\\ 0 \u0026 1 \u0026 0 \u0026 t_y\\\\ 0 \u0026 0 \u0026 1 \u0026 t_z\\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix} \\]\n仿射变换 即线性变换加上一个平移\n\\[\\begin{bmatrix} x'\\\\ y' \\end{bmatrix}= \\begin{bmatrix} a \u0026 b\\\\ c \u0026 d \\end{bmatrix}\\cdot \\begin{bmatrix} x\\\\ y \\end{bmatrix}+ \\begin{bmatrix} t_x\\\\ t_y \\end{bmatrix} \\]\n\\[\\begin{bmatrix} x'\\\\ y'\\\\ 1 \\end{bmatrix}= \\begin{bmatrix} a \u0026 b \u0026 t_x\\\\ c \u0026 d \u0026 t_y\\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix}\\cdot \\begin{bmatrix} x\\\\ y\\\\ 1 \\end{bmatrix} \\]\n显然知道，这个矩阵先进行线性变换，再进行平移。\n逆变换 变换\\(\\bm M^{-1}\\)是变换\\(\\bm M\\)在矩阵和几何意义上的逆变换。\n显然，根据变换的复合，变换和其逆变换的复合相当于没变，两个变换矩阵的乘积是单位矩阵。故逆变换矩阵是变换矩阵的逆矩阵。\n坐标变换 TODO\n","date":"2022-06-27T16:25:19+08:00","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%8F%98%E6%8D%A2%E7%9F%A9%E9%98%B5/","title":"计算机图形学基础学习笔记-变换矩阵"},{"content":"本章内容为线性代数，在线性代数整理中涵盖了大部分内容，不再重复，介绍一些那篇文章没有覆盖的内容。\nSVD（奇异值分解） 与对角化不同的是，计算SVD时，两边的正交矩阵不要求相同。例如：\n\\[\\bm A=\\bm{USV}^T \\]\n其中\\(\\bm S\\)是一个对角阵，并且对角线上的元素就是奇异值。当\\(\\bm A\\)是对称的并且都是非负特征值，此时SVD和对角化相同。\n有一个特征值和奇异值之间的关系可以帮助我们计算奇异值\n\\[M = \\bm{AA}^T=(\\bm{USV}^T)(\\bm{USV}^T)^T = \\bm{US}(\\bm V^T\\bm V)\\bm{SU}^T \\]\n\\[=\\bm{US}^2\\bm U^T \\]\n","date":"2022-06-27T15:29:29+08:00","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/","title":"计算机图形学基础学习笔记-线性代数"},{"content":"Cartesian Product（笛卡尔积） 内容同离散数学。\n几个特别的集合 \\(S^2\\)，在单位球面上的三维点的集合。\n映射、函数、反函数 内容同离散数学。\n三角学 书中提到的正弦余弦定理、半角公式、和差公式都已在高中学过，记录一些没学过的。\n正切定理\n\\[\\frac{a+b}{a-b}=\\frac{tan\\left(\\frac{A+B}{2}\\right)}{tan\\left(\\frac{A-B}{2}\\right)} \\]\n海伦公式\n\\[S = \\frac{1}{4}\\sqrt{(a+b+c)(-a+b+c)(a-b+c)(a+b-c)} \\]\n重心坐标系 可以用三个点\\(\\bm{a,b,c}\\)表示三角形。\n假设三点不共线，则\\(\\bm{c-a},\\bm{b-a}\\)线性无关，即可以作为二维坐标的一组基底。\n二维空间中任何一点都可以由\n\\[\\bm{p}=\\bm a+\\beta(\\bm{b-a})+\\gamma(\\bm{c-a}) \\]\n表示\n整理得\n\\[\\bm{p}=(1-\\beta-\\gamma)\\bm a+\\beta\\bm{b}+\\gamma\\bm{c} \\]\n令\n\\[\\alpha\\equiv 1-\\beta-\\gamma \\]\n则有\n\\[\\bm p(\\alpha,\\beta,\\gamma)=\\alpha\\bm a+\\beta\\bm{b}+\\gamma\\bm{c} \\]\n其中\n\\[\\alpha+\\beta+\\gamma = 1 \\]\n一个点在三角形内部当且仅当\n\\[0\u003c\\alpha\u003c1,0\u003c\\beta\u003c1,0\u003c\\gamma\u003c1 \\]\n同时成立。也可以用向量叉乘的办法判断是否在内部。\n对于三角形三个点\\(A,B,C\\)，平面中一点\\((x,y)\\)可以表示为\n\\[(x,y) = \\alpha A+\\beta B+\\gamma C \\]\n\\[\\alpha+\\beta+\\gamma=1 \\]\n其中有\n\\[\\alpha = \\frac{-(x-x_B)(y_C-y_B)+(y-y_B)(x_C-x_B)}{-(x_A-x_B)(y_C-y_B)+(y_A-y_B)(x_C-x_B)} \\]\n\\[\\beta = \\frac{-(x-x_C)(y_A-y_C)+(y-y_C)(x_A-x_C)}{-(x_B-x_C)(y_A-y_C)+(y_B-y_C)(x_A-x_C)} \\]\n\\[\\gamma = 1-\\alpha-\\beta \\]\n运用重心坐标系进行颜色插值见第九章笔记。\n另外，从另一个角度思考\n\\[\\bm p = \\alpha\\bm a+\\beta\\bm b+\\gamma\\bm c\\\\ \\alpha+\\beta+\\gamma = 1 \\]\n有\n\\[\\bm p = (1-\\beta-\\gamma)\\bm a+\\beta\\bm b+\\gamma\\bm c \\]\n\\[\\bm p = \\bm a+\\beta\\overrightarrow{AB}+\\beta\\overrightarrow{AC} \\]\n\\[0 = \\overrightarrow{PA}+\\beta\\overrightarrow{AB}+\\gamma\\overrightarrow{AC} \\]\n也就是说，\n\\[\\begin{bmatrix} 1 \u0026 \\beta \u0026 \\gamma \\end{bmatrix} \\begin{bmatrix} PA_x \\\\ AB_x \\\\ AC_x \\end{bmatrix}=0 \\]\n\\[\\begin{bmatrix} 1 \u0026 \\beta \u0026 \\gamma \\end{bmatrix} \\begin{bmatrix} PA_y \\\\ AB_y \\\\ AC_y \\end{bmatrix}=0 \\]\n也就是说，向量\\((1,\\beta,\\gamma)\\)是向量\\((PA_x,AB_x,AC_x)\\)和\\((PA_y,AB_y,AC_y)\\)的叉积。根据向量第一位是1可以转变一下符号。\n这个方法代码相较于上一个方法比较简单。\n向量 同高中和线性代数\n积分 内容同高数。不过在计算机图形学里我们更注重数值而不是分析。\n曲线、曲面 内容同高数。\nLinear Interpolation（线性内插） \\[f(x)=y_i+\\frac{x-x_i}{x_{i+1}-x_i}(y_{i+1}-y_i) \\]\n概率论 随机变量 \\(X\\)，表示任意一个可能取值。\n概率密度函数(PDF) \\(X\\sim p(x)\\)，表示随机过程取值为\\(x\\)的相对概率。\n概率的一些属性 \\(p_i\\geq 0\\) \\(\\sum_{i=1}^np_i=1\\) 期望 \\[E[X] = \\sum_{i=1}^nx_ip_i \\]\n连续的情况 当随机变量\\(X\\)可以取一个连续的区间上的值。\n显然此时也会有连续的概率密度函数。\n并且\n\\[p(x)\\geq 0,\\int p(x)dx=1 \\]\n\\[E[x]=\\int xp(x)dx \\]\n随机变量的函数 随机变量的函数也是一个随机变量。\n\\[X\\sim p(x)\\\\ Y=f(X) \\]\n\\[E[Y]=E[f(X)]=\\int f(x)p(x)dx \\]\n蒙特卡罗积分 蒙特卡洛积分的目的：想计算一个定积分，但是难以从分析意义上解出，希望在数值上求解。\n方法：通过平均函数值的随机样本来估计函数的积分。\n定义定积分如下：\n\\[\\int_a^b f(x)dx \\]\n随机变量如下\n\\[X_i\\sim p(x) \\]\n则蒙特卡洛估计值是：\n\\[F_N=\\frac{1}{N}\\sum_{i=1}^N\\frac{f(X_i)}{p(X_i)} \\]\n如果随机变量是均匀的，或者说\n\\[X_i\\sim p(x)=C \\]\n\\(C\\)是一个常数\n那么，\n\\[\\int_a^b p(x)dx=1 \\]\n\\[\\int_a^b Cdx=1 \\]\n\\[C=\\frac{1}{b-a} \\]\n此时基础蒙特卡洛估计值(Basic Monte Carlo Estimator)为\n\\[F_N=\\frac{b-a}{N}\\sum_{i=1}^N f(X_i) \\]\n","date":"2022-06-27T15:17:29+08:00","permalink":"https://kegalas.top/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/","title":"计算机图形学基础学习笔记-数学基础"},{"content":"以Hugo站点为根目录，首先将\\themes\\hugo-theme-stack\\layouts\\partials\\sidebar\\中的left.html复制到\\layouts\\partials\\sidebar\\中。\n然后修改复制后的文件，如下图。\n1.jpg\r第41行中选中的部分原来是relLangURL，改成absURL。\n不过这个方法是否会导致其他问题还有待观察。\n","date":"2022-06-25T23:46:57+08:00","image":"https://kegalas.top/p/hugo%E7%9A%84stack%E7%9A%AE%E8%82%A4%E4%B8%AD%E4%BD%BF%E5%BE%97mailto%E8%B6%85%E9%93%BE%E6%8E%A5%E8%83%BD%E5%A4%9F%E7%9B%B4%E6%8E%A5%E6%89%93%E5%BC%80%E7%94%B5%E5%AD%90%E9%82%AE%E4%BB%B6%E5%AE%A2%E6%88%B7%E7%AB%AF/cover_hu378ddc8c04e53c565ec514b2115f7fb1_40855_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/hugo%E7%9A%84stack%E7%9A%AE%E8%82%A4%E4%B8%AD%E4%BD%BF%E5%BE%97mailto%E8%B6%85%E9%93%BE%E6%8E%A5%E8%83%BD%E5%A4%9F%E7%9B%B4%E6%8E%A5%E6%89%93%E5%BC%80%E7%94%B5%E5%AD%90%E9%82%AE%E4%BB%B6%E5%AE%A2%E6%88%B7%E7%AB%AF/","title":"Hugo的Stack皮肤中使得mailto超链接能够直接打开电子邮件客户端"},{"content":"加减法 \\[(a\\pm b)\\%p = [(a\\%p)\\pm (b\\%p)]\\%p \\]\n乘法 \\[(a\\times b)\\%p = [(a\\%p)\\times (b\\%p)]\\%p \\]\n除法 \\[(a/b)\\%p = (a\\times b^{-1})\\%p=[(a\\%p)\\times (b^{-1}\\%p)]\\%p \\]\n其中，\\(b^{-1}\\)是\\(b\\)在模\\(p\\)意义下的乘法逆元。\n","date":"2022-06-25T23:37:59+08:00","permalink":"https://kegalas.top/p/%E5%8F%96%E4%BD%99%E8%BF%90%E7%AE%97%E7%9A%84%E5%88%86%E9%85%8D%E5%BE%8B/","title":"取余运算的分配律"},{"content":"[TOC]\n运动学 位移 位移：\\(\\Delta\\bm{r}\\)\n位移的大小：\\(|\\Delta\\bm{r}|\\)\n位矢大小的增量：\\(|\\Delta r|\\)\n其中后两者一般是不相等的，不能搞混。\n速度 平均速度 \\[\\overline{\\bm{v}}=\\frac{\\bm{r}(t+\\Delta t)-\\bm{r}(t)}{\\Delta t}=\\frac{\\Delta\\bm{r}}{\\Delta t} \\]\n平均速度的大小 \\[|\\overline{\\bm{v}}|=\\left|\\frac{\\Delta\\bm{r}}{\\Delta t}\\right| \\]\n同样的一般有\n\\[|\\overline{\\bm{v}}|\\neq\\left|\\frac{\\Delta r}{\\Delta t}\\right| \\]\n瞬时速度 \\[\\bm{v}=\\frac{d\\bm{r}}{dt} \\]\n速度的大小常称速率。\n\\[|\\bm{v}|=\\left|\\frac{d\\bm{r}}{dt}\\right| \\]\n同样一般有\n\\[|\\bm{v}|\\neq \\left|\\frac{dr}{dt}\\right| \\]\n加速度 平均加速度 \\[\\overline{\\bm{a}}=\\frac{\\Delta\\bm{v}}{\\Delta t} \\]\n瞬时加速度 \\[\\bm{a}=\\frac{d\\bm{v}}{dt} \\]\n关于加速度的大小和一般不相等与（）的性质类似于速度，不再介绍。\n直角坐标表示运动 其位移、速度、加速度都可以分成几个坐标分量来计算，总的位移、速度、加速度则是勾股定理的形式，不再介绍。\n自然坐标法表示运动 \\[\\bm{v}=\\frac{ds}{dt}\\bm{\\tau} \\]\n其中\\(\\bm{\\tau}\\)是切向量。\n\\[\\bm{a}_n=a_n\\bm{n}=\\frac{v^2}{r}\\bm{n} \\]\n其中\\(n\\)是法向量，\\(r\\)是曲率半径，曲率半径计算见高数上整理。\n\\[\\bm{a}_\\tau=a_\\tau\\bm{\\tau}=\\frac{dv}{dt}\\bm{\\tau} \\]\n\\[\\bm{a=a}_n+\\bm{a}_\\tau \\]\n圆周运动的角量表示 角坐标 \\[\\theta=\\theta(t) \\]\n角速度和角平均速度 \\[\\overline{\\omega}=\\frac{\\Delta\\theta}{\\Delta t} \\]\n\\[\\omega=\\frac{d\\theta}{dt} \\]\n角加速度和角平均加速度 \\[\\overline{\\beta}=\\frac{\\Delta\\omega}{\\Delta t} \\]\n\\[\\beta=\\frac{d\\omega}{dt}=\\frac{d^2\\theta}{dt^2} \\]\n线速度、加速度与角速度的关系 \\[v=r\\omega\\\\ a_\\tau=r\\beta\\\\ a_n=r\\omega^2 \\]\n坐标系变换 \\[\\bm{v}_a=\\bm{v}_r+\\bm{u} \\]\n即绝对速度等于相对于坐标系的速度与坐标系的绝对速度的矢量和。\n\\[\\bm{a}_a=\\bm{a}_r+\\bm{a}_e \\]\n类似。\n牛顿运动定律 第一定律 \\[R=\\sum_i\\bm{F}_i=0 \\]\n也可以将\\(\\bm{F}\\)写成坐标分量的形式。\n第二定律 \\[\\bm{R}=\\sum_i\\bm{F}_i=\\frac{d(m\\bm{v})}{dt} \\]\n质量为常量时\n\\[\\bm{R}=m\\frac{d\\bm{v}}{dt}=m\\bm{a} \\]\n可以写作坐标分量和切向量、法向量分量的形式。\n第三定律 \\[\\bm{F}_1=\\bm{F}_2 \\]\n刚体的平动 任意时刻，平动刚体上个点的速度、加速度都相同。\n力学 常见的几种力 万有引力 \\[\\bm{F}_{21}=-G\\frac{m_1m_2}{r^2}\\bm{r}^0\\\\ G=6.67\\times10^{-11}\\quad m^2/(kg\\cdot s^2) \\]\n弹性力 \\[F_x=-kx \\]\n摩擦力 静摩擦力\n\\[f_{max}=\\mu_0N \\]\n前者为静摩擦系数，后者为支持力。\n滑动摩擦力\n\\[f=\\mu N \\]\n前者为滑动摩擦系数。\n力矩 \\[M_O=\\bm{r}\\times\\bm{F} \\]\n单位：\\(N\\cdot m\\)\n转动惯量 \\[J_z=\\int_Vr^2dm \\]\n常见物体的转动惯量计算公式 5.2\r平行轴定理 5.11\r\\[J_z'=J_z+Mh^2 \\]\n转动惯量和力矩的关系 \\[M_z=J_z\\beta \\]\n功和能 功 恒力做功 \\[A=\\bm{F}\\cdot\\bm{s}=Fscos\\theta \\]\n变力做功 \\[A=\\int^b_{a(L)}\\bm{F}\\cdot d\\bm{r} \\]\n通常会拆分成对坐标系求曲线积分。\n平均功率 \\[P=\\frac{\\Delta A}{\\Delta t} \\]\n瞬时功率 \\[P=\\frac{dA}{dt} \\]\n\\[P=\\frac{\\bm{F}\\cdot d\\bm{r}}{dt}=\\bm{F}\\cdot \\bm{v}=Fvcos\\theta \\]\n几种常见力的功 重力的功 \\[A=mg(z_1-z_2) \\]\n万有引力的功 \\[A=GmM(\\frac{1}{r_2}-\\frac{1}{r_1}) \\]\n弹性力的功 \\[A=\\frac{1}{2}k\\lambda_1^2-\\frac{1}{2}k\\lambda_2^2 \\]\n动能定理 质点动能定理 \\[dA=d(\\frac{1}{2}mv^2) \\]\n\\[A=\\frac{1}{2}mv_1^2-\\frac{1}{2}mv_2^2 \\]\n质点系动能定理 \\[\\sum_i A_i=E_{k2}-E_{k1} \\]\n势能、机械能守恒定律 保守力 做功只与始末位置有关而与路径无关的力。\n势能 零势能点\\(M_0\\)，空间中的某个点\\(M\\)\n\\[E_p=\\int_M^{M_0}\\bm{F}\\cdot d\\bm{r} \\]\n重力势能 \\[E_p=mgz \\]\n万有引力势能 \\[E_p=-G\\frac{mM}{r} \\]\n弹性势能 \\[A=\\frac{1}{2}kx_1^2-\\frac{1}{2}kx_2^2 \\]\n绕定轴转动刚体的动能、动能定理 动能 \\[E=\\frac{1}{2}J_z\\omega^2 \\]\n力矩的功 \\[A=\\int_{\\theta_1}^{\\theta_2}M_z(\\bm{F})d\\theta \\]\n动能定理 \\[A=\\frac{1}{2}J_z\\omega_2^2-\\frac{1}{2}J_z\\omega_1^2 \\]\n冲量、动量、角动量 质点系动量定理 \\[d(m\\bm{v})=\\bm{F}dt \\]\n\\[\\bm{I}=m\\bm{v}_2-m\\bm{v}_1=\\int^{t_2}_{t_1}\\bm{F}dt \\]\n如果是恒力\n\\[m\\bm{v}_2-m\\bm{v}_1=\\bm{F}(t_2-t_1) \\]\n质点系动量定理 \\[\\sum_i m_i\\bm{v}_i-\\sum_i m\\bm{v}_{i0}=\\sum_i\\int^{t}_{t_0}\\bm{F}_i dt \\]\n质点系动量守恒定律 作用在质点系上的所有外力的矢量和为零，则该质点系的动量保持不变。\n如果某个方向的矢量和为零，则这个方向上的动量保持不变。\n\\[\\sum_i m_i\\bm{v}_{ix}=C \\]\n\\(C\\)是常量\n质心、质心运动定理 质心位置 见高数下整理\n质心运动定理 质点系质心的运动，可以看成为一个质点的运动，这个质点集中了整个质点系的质量，也集中了质点系收到的所有外力。\n动量矩和动量矩守恒定律 动量矩 \\[\\bm{L}_O=\\bm{r}\\times m\\bm{v} \\]\n\\[L_z=J_z\\omega \\]\n动量矩定理 \\[\\frac{d\\bm{L_O}}{dt}=\\bm{r}\\times\\bm{F}=\\bm{M}_O \\]\n动量矩守恒定律 当作用在质点上的合理对固定点之矩总是为零时，质点动量对该点的矩为常矢量。即\n\\[\\bm{M}_O=0\\Rightarrow \\bm{L}_O=\\bm{C} \\]\n\\(\\bm{C}\\)是常矢量。\n刚体绕定轴转动的动量矩定理 \\[(J_z\\omega)_t-(J_z\\omega)_{t_0}=\\int^t_{t_0}M_zdt \\]\n刚体绕定轴转动的动量矩守恒定律 \\[M_z=0\\Rightarrow J_z\\omega=C \\]\n机械振动 简谐振动 \\[x=Acos(\\omega t+\\varphi) \\]\n\\[v=\\overset{\\cdot}{x}=-A\\omega sin(\\omega t+\\varphi) \\]\n\\[a=\\overset{\\cdot\\cdot}{x}=-A\\omega^2 cos(\\omega t+\\varphi) \\]\n对于弹簧振子的周期：\n\\[T=\\frac{2\\pi}{\\omega}=2\\pi\\sqrt{\\frac{m}{k}} \\]\n对于单摆的周期：\n\\[T=2\\pi\\sqrt{\\frac{l}{g}} \\]\n弹簧串联并联和弹性系数 串联 \\[k=\\frac{k_1k_2}{k_1+k_2} \\]\n并联 \\[k=k_1+k_2 \\]\n注：有一种两根弹簧中间连了物体的，是一种并联。\n谐振动的能量 \\[E=\\frac{1}{2}kA^2 \\]\n一个周期内，动能和势能的平均大小：\n\\[\\overline{E_p}=\\frac{1}{4}kA^2 \\]\n\\[\\overline{E_k}=\\frac{1}{4}kA^2 \\]\n谐振动的合成 同方向，同频率的合成 频率不变\n\\[A=\\sqrt{A_1^2+A_2^2+2A_1A_2cos(\\varphi_2-\\varphi_1)} \\]\n\\[\\varphi = arctan\\frac{A_1sin\\varphi_1+A_2sin\\varphi_2}{A_1cos\\varphi_1+A_2cos\\varphi_2} \\]\n同方向不同频率的合成 \\[A=\\sqrt{A_1^2+A_2^2+2A_1A_2cos(\\omega_2-\\omega_1)t} \\]\n\\[\\tau=\\frac{2\\pi}{|\\omega_2-\\omega_1|} \\]\n\\[\\nu=\\frac{|\\omega_2-\\omega_1|}{2\\pi}=|\\nu_2-\\nu_1| \\]\n\\(\\nu\\)为拍频。\n两个相互垂直谐振动的合成 根据参数方程求出平面解析式。\n机械波 机械波的产生和传播 拉紧的绳子，横波的波速为\n\\[u_t=\\sqrt{\\frac{T}{\\mu}} \\]\n其中\\(T\\)是绳子的张力，\\(\\mu\\)是线密度。\n平面简谐波 波函数 正向传播：\n\\[y(x,t)=Acos\\left[\\omega\\left(t-\\frac{x}{u}\\right)+\\varphi_0\\right] \\]\n或者写成\n\\[y(x,t)=Acos\\left[2\\pi\\left(\\frac{t}{T}-\\frac{x}{\\lambda}\\right)+\\varphi_0\\right] \\]\n负向传播：\n\\[y(x,t)=Acos\\left[\\omega\\left(t+\\frac{x}{u}\\right)+\\varphi_0\\right] \\]\n波的能量 能量 设绳子每单位长度的质量为\\(\\mu\\)，线元总机械能：\n\\[W=W_k+W_p=\\mu\\Delta xA^2\\omega^2sin^2\\left[\\omega\\left(t-\\frac{x}{u}\\right)+\\varphi_0\\right] \\]\n能量密度 把单位体积中波的能量称为波的能量密度：\n\\[w=\\frac{W}{\\Delta V}=\\frac{W}{\\Delta x\\Delta S}=\\rho A^2\\omega^2sin^2\\left[\\omega\\left(t-\\frac{x}{u}\\right)+\\varphi_0\\right] \\]\n能流密度（波的强度） \\[I=\\overline{w}u \\]\n\\[I=\\frac{1}{2}\\rho A^2\\omega^2u \\]\n\\[\\bm{I}=\\overline{w}\\bm{u} \\]\n\\[w_{max}=2\\overline{w} \\]\n\\[I=\\frac{P}{S} \\]\n其中\\(P\\)是功率，\\(S\\)是波面面积。\n平面波和球面波的振幅 平面简谐波在理想无吸收的、均匀媒质中传播时振幅不变。\n球面波在均匀、无吸收媒质中传播，有\n\\[\\frac{A_1}{A_2}=\\frac{r_2}{r_1} \\]\n即该点的振幅和到波源的距离成反比\n波的吸收 \\[I=I_0e^{-ax} \\]\n波的干涉 干涉条件：频率相同、振动方向相同、相位差恒定。\n\\[A^2=A_1^2+A_2^2+2A_1A_2cos\\Delta\\varphi \\]\n\\[I=I_1+I_2+2\\sqrt{I_1I_2}cos\\Delta\\varphi \\]\n其中上面两式中\n\\[\\Delta\\varphi=(\\varphi_2-\\varphi_1)-2\\pi\\frac{r_2-r_1}{\\lambda} \\]\n如果两个波源的初相位相同，则\\(\\Delta\\varphi\\)只取决于波程差\\(\\delta=r_1-r_2\\)，于是干涉相长的条件为：\n\\[\\delta=r_1-r_2=\\pm k\\lambda,\\quad k=0,1,2,\\cdots \\]\n干涉相消的条件为：\n\\[\\delta=r_1-r_2=\\pm (2k+1)\\frac{\\lambda}{2},\\quad k=0,1,2,\\cdots \\]\n驻波 形成驻波的条件： \\[L=n\\frac{\\lambda}{2},\\quad n=1,2,3,\\cdots \\]\n驻波波函数 \\[y=2Acos2\\pi\\frac{x}{\\lambda}\\cdot cos2\\pi\\nu t \\]\n多普勒效应 波源\\(S\\)静止，观察者相对于波源的速度为\\(v_O\\)，靠近为正值，远离为负值。则观察者接收到的频率为： \\[\\nu=(1+\\frac{v_O}{u})\\nu_0 \\]\n观察者静止，波源相对于观察者的速度为\\(v_S\\)，靠近为正值，远离为负值。则观察者接收到的频率为： \\[\\nu=\\frac{u}{u-v_S}\\nu_0 \\]\n波动光学 光的干涉 相干叠加的条件：频率相同、光矢量振动方向平行、相位差恒定。\n杨氏双缝干涉 干涉加强的条件：\n\\[\\delta=\\pm 2k\\frac{\\lambda}{2} \\]\n干涉相消的条件：\n\\[\\delta=\\pm(2k+1)\\frac{\\lambda}{2} \\]\n屏上相邻明条纹或相邻暗条纹之间的间距为\n\\[\\Delta x=\\frac{D\\lambda}{d} \\]\n\\(D\\)是双缝到屏的距离，\\(d\\)是双缝间距。\n洛埃镜 半波损失的条件：\n波从波疏介质射向波密介质时反射过程中，反射波会相对于入射波有相位突变\\(\\pi\\)\n光程与光程差 数值上，光程等于介质折射率乘以光在介质中传播的路程，经过多重介质时，光程\\(=\\sum_in_ir_i\\)\n光程差：\n\\[\\delta=n_2r_2-n_1r_1 \\]\n薄膜干涉 等厚干涉 干涉图样中同一干涉条纹对应于薄膜上厚度相同点的连线，这种条纹称为等厚干涉条纹。\n劈尖干涉 显然要考虑半波损失，假设为垂直入射，则明条纹的条件为\n\\[\\delta=2d+\\frac{\\lambda}{2}=2k\\frac{\\lambda}{2},\\quad k=1,2,3,\\cdots \\]\n暗条纹的条件是\n\\[\\delta=2d+\\frac{\\lambda}{2}=(2k+1)\\frac{\\lambda}{2},\\quad k=0,1,2,\\cdots \\]\n牛顿环 \\(R\\)是平凸透镜的曲率半径，\\(r\\)是条纹半径。\n明条纹：\n\\[r=\\sqrt{(2k-1)\\frac{R\\lambda}{2}},\\quad k=1,2,3,\\cdots \\]\n暗条纹：\n\\[r=\\sqrt{k\\lambda R} \\]\n等倾干涉 因干涉图样中同一干涉条纹是来自薄膜表面的等倾角光纤经透镜聚焦后的轨迹，故称为等倾干涉条纹。\n迈克尔逊干涉仪 若视场从最亮到第\\(N\\)次最亮出现时，反光镜移动的距离为\n\\[\\Delta d=N\\frac{\\lambda}{2} \\]\n相干长度 两个分光束产生干涉效应的最大光程差\\(\\delta_m\\)为波列长度\\(L\\)，称为相干长度\n相干时间 \\[\\Delta t=\\frac{\\delta_m}{c} \\]\n惠更斯-菲涅尔原理 同一波前上各点发出的次波是相干波，经过传播在空间某点相遇时的叠加是相干叠加。\n单缝的夫琅禾费衍射 菲涅尔半波带法研究分布 \\(a\\)是夹缝宽度\n暗条纹：\n\\[asin\\varphi = \\pm 2k\\frac{\\lambda}{2},\\quad k=1,2,3,\\cdots \\]\n明条纹：\n\\[asin\\varphi=\\pm(2k+1)\\frac{\\lambda}{2},\\quad k=1,2,3,\\cdots \\]\n其中中央零级明条纹：\n\\[asin\\varphi=0 \\]\n中央明纹的宽度是\n\\[-\\lambda \u003c asin \\varphi \u003c \\lambda \\]\n当\\(\\varphi\\)很小时，有\\(sin\\varphi\\approx\\varphi\\approx\\frac{\\lambda}{a}\\)\n振幅矢量合成法研究强度 假设中央明纹的光强为\\(I_0\\)，则某一点\\(P\\)的光强为\n\\[I=I_0\\left(\\frac{sinu}{u}\\right)^2 \\]\n艾里斑 \\[\\theta_0\\approx sin\\theta_0=1.22\\frac{\\lambda}{D} \\]\n\\(D\\)是圆孔直径。\n衍射光栅及光栅光谱 刻痕间距为\\(a\\)，刻痕宽度为\\(b\\)，则\\(d=a+b\\)称为光栅常数。\\(N\\)是光栅的缝数，\\(n\\)是光栅一定长度内的缝数，单位通常为条/\\(mm\\)。并且有\\(d=1/n\\)\n光栅方程 光栅方程，或衍射明条纹的条件如下（只考虑干涉而不考虑各个缝的衍射的情况）\n\\[(a+b)sin\\varphi=\\pm k\\lambda,\\quad k=0,1,2,\\cdots \\]\n主极大条纹 满足光栅方程的明条纹称为主极大条纹。\n缺级 现在来考虑各个缝的衍射。\n同时满足\n\\[(a+b)sin\\varphi=\\pm k\\lambda \\]\n和\n\\[asin\\varphi=\\pm k'\\lambda,\\quad k'=1,2,\\cdots \\]\n的为光谱线的缺级\n缺级的级数为\n\\[k=k'\\frac{a+b}{a} \\]\n暗纹条件 \\[N(a+b)sin\\varphi=\\pm m\\lambda \\]\n其中\\(m=1,2,\\cdots,(N-1),(N+1),\\cdots,(2N-1),(2N+1),\\cdots\\)，即除去\\(N\\)的整倍数。\n易知，两个主极大条纹间有\\((N-1)\\)条暗纹，以及\\((N-2)\\)条次级大。\n线偏振光、自然光 线偏振光 光矢量只限于单一方向振动的光。\n自然光 无论哪一个方向的振动都不比其他方向占优势。\n偏振片的起偏和检偏、马吕斯定律 起偏和检偏 自然光获得偏振光的过程叫起偏。\n对偏振光透过偏振片的角度的观察叫检偏。\n马吕斯定律 \\[I=I_0cos^2\\alpha \\]\n对于自然光透过偏振片\n\\[I=I_0/2 \\]\n反射和折射产生的偏振、布儒斯特定律 反射和折射产生的偏振 反射光为偏振方向垂直入射面成分较多的部分偏振光。\n布儒斯特定律 当入射角\\(i\\)与反射角\\(\\gamma\\)之和为\\(90\\degree\\)时，反射光称为光矢量与入射面垂直的完全偏振光。\n公式表示为\n\\[tani=\\frac{n_2}{n_1} \\]\n双折射现象 晶体的双折射现象：\n其中一束折射光始终在入射面内，并遵守折射定律，称为寻常光，简称\\(o\\)光。另一束折射光一般不在入射面内，且不遵守折射定律，称为非常光，简称为\\(e\\)光。\n热力学 平衡态、理想气体状态方程 \\[t=T-273.15 \\]\n理想气体状态方程（克拉伯龙方程）：\n\\[pV=\\nu RT \\]\n注，大学物理一般用\\(n\\)表示分子数密度，而用\\(\\nu\\)表示物质的量\n功、热量、内能、热力学第一定律 绝热过程中外界对系统做功，则内能变化为\n\\[E_2-E_1=A_Q \\]\n假设外界不对系统做功，系统内能变化和外界给系统的热量的关系：\n\\[E_2-E_1=Q \\]\n热力学第一定律\n\\[Q=(E_2-E_1)+A \\]\n即系统从外界吸收能力，一部分转化为内能，一部分则对外界做功\n对于无限小的变化过程\n\\[dQ=dE+dA \\]\n准静态过程中功和热量的计算 功 在一个优先的准静态过程中，当气体的体积变化时，气体对外界所做的功为\n\\[A=\\int_{V_1}^{V_2}pdV \\]\n应用上述结果，热力学第一定律可以表示为\n\\[Q=(E_2-E_1)+\\int_{V_1}^{V_2}pdV \\]\n热量、热容 \\[Q=mc(T_2-T_1) \\]\n\\(c\\)是物体的比热容。不同物质的比热容值不同，并且同一物质的比热容值一般随温度而变。但在温度变化不大时，可以看做常量。\n假定\\(1mol\\)气体在等体过程中温度升高\\(\\Delta T\\)时，吸收的热量为\\(Q_V\\)，则气体的摩尔定体热容定义为\n\\[C_V=\\lim\\limits_{\\Delta T\\to 0}\\frac{Q_V}{\\Delta T}=\\left(\\frac{dE}{dT}\\right)_V \\]\n假定\\(1mol\\)气体在等压过程中温度升高\\(\\Delta T\\)时，吸收的热量为\\(Q_p\\)，则气体的摩尔定压热容定义为\n\\[C_V=\\lim\\limits_{\\Delta T\\to 0}\\frac{Q_p}{\\Delta T}=\\left(\\frac{dE}{dT}\\right)_p+p\\left(\\frac{dV}{dT}\\right)_p \\]\n理想气体的内能和\\(C_V\\)、\\(C_p\\) 气体的内能仅仅是其温度的函数，与体积等无关\n\\[E=E(T) \\]\n\\[C_p=C_V+R \\]\n即迈耶公式，单位一般为\\(J/(mol\\cdot K)\\)，\\(R=8.31\\)\n比热容比：\n\\[\\gamma=\\frac{C_p}{C_V} \\]\n对单原子分子\n\\[C_V\\approx \\frac{3}{2}R \\]\n对双原子气体分子\n\\[C_V\\approx \\frac{5}{2}R \\]\n热力学第一定律对理想气体在典型准静态过程中的应用 等体过程 \\[Q_V=E_2-E_1=\\nu C_V(T_2-T_1) \\]\n由克拉伯龙公式\n\\[Q_V=\\frac{V}{R}C_V(p_2-p_1) \\]\n等压过程 \\[A=p(V_2-V_1)=\\nu R(T_2-T_1) \\]\n\\[Q_p=vC_p(T_2-T_1) \\]\n\\[E_2-E_1=Q_p-A=\\nu C_V(T_2-T_1) \\]\n等温过程 等温膨胀过程中，吸收的热量全部用来对外做功\n\\[Q_T=A=\\nu RTln\\frac{p_1}{p_2} \\]\n绝热过程 绝热过程中\\(Q=0\\)，所以有\\(A=E_1-E_2=-vC_V(T_2-T_1)\\)\n\\[A=\\frac{1}{\\gamma-1}(p_1V_1-p_2V_2)=-\\frac{\\nu R}{\\gamma-1}(T_2-T_1) \\]\n循环过程 循环过程 \\[A=Q_1-Q_2 \\]\n循环效率 \\[\\eta=\\frac{A}{Q_1}=1-\\frac{Q_2}{Q_1} \\]\n制冷系数 \\[w=\\frac{Q_2}{A} \\]\n绝对零度不可达原理 不可能用有限的步骤使物体达到绝对零度。\n热力学第二定律 开尔文表述 不可能只从单一热源吸收热量，使之完全转化为功而不引起其他变化。\n克劳修斯表述 不可能使热量从低温物体传向高温物体而不引起其他变化。\n可逆与不可逆过程 如果过程的每一步都可沿相反的方向进行，同时不引起外界的任何变化，则称可逆过程。对于某一过程，用任何方法都不能使系统和外界恢复到原来状态，称为不可逆过程。\n热力学第二定律揭示了，自然界的一切自发过程都是单方向进行的不可逆过程。\n卡诺热机 卡诺循环 两个等温过程和两个绝热过程组成。\n\\[\\eta = 1-\\frac{T_2}{T_1} \\]\n\\[w=\\frac{T_2}{T_1-T_2} \\]\n卡诺定理 温度为\\(T_1,T_2\\)的两个给定热源之间工作的一切可逆热机，效率相同，都等于理想气体可逆卡诺热机的效率。这两个热源之间工作的一切不可逆热机，其效率都不可能大于卡诺热机。\n气体动理论 气体分子的热运动 平衡状态下，平均速度\n\\[\\overline{v_x}=\\overline{v_y}=\\overline{v_z}=0 \\]\n统计平均值为\n\\[\\overline{v^2_j}=\\frac{\\sum_i\\Delta N_iv^2_{ij}}{N},\\quad j=x,y,z \\]\n且有\n\\[\\overline{v^2_x}=\\overline{v^2_y}=\\overline{v^2_z}=\\overline{v^2}/3 \\]\n大量分子平均平动动能的统计平均值为\n\\[\\overline{\\varepsilon}=\\frac{1}{2}\\mu\\overline{v^2}=\\frac{\\mu\\sum_i\\Delta N_iv^2_{i}}{2N} \\]\n其中\\(\\mu\\)为一个分子的质量\n理想气体的压强公式 \\[p=\\frac{2}{3}n(\\frac{1}{2}\\mu\\overline{v^2})=\\frac{2}{3}n\\overline{\\varepsilon} \\]\n麦克斯韦速度分布定律 麦克斯韦速度分布定律 \\[f(v)=4\\pi\\left(\\frac{\\mu}{2\\pi kT}\\right)^{3/2}v^2e^{-\\frac{\\mu v^2}{2kT}} \\]\n其中\n\\[k=\\frac{R}{N_A}=\\frac{8.31}{6.022\\times 10^{23}}=1.38\\times 10^{-23} J/K \\]\n称为玻尔兹曼常数。\n\\[\\frac{dN}{N}=f(v)dv \\]\n\\[\\int_0^\\infty f(v)dv=1 \\]\n分子速率的三种统计平均值 \\[\\overline{v}=\\sqrt\\frac{8kT}{\\pi\\mu}=1.59\\sqrt{\\frac{RT}{M}} \\]\n\\[\\sqrt{\\overline{v^2}}=\\sqrt\\frac{3kT}{\\mu}=1.73\\sqrt{\\frac{RT}{M}} \\]\n\\[v_p=\\sqrt\\frac{2kT}{\\mu}=1.41\\sqrt{\\frac{RT}{M}} \\]\n温度的微观本质 \\[\\overline{\\varepsilon}=\\frac{1}{2}\\mu\\overline{v^2}=\\frac{3}{2}kT \\]\n能量按自由度均分定理 能量按自由度均分定理 处于平衡态的理想气体分子，无论作何种运动，相应于分子每个自由度的平均动能都相等，并且都等于\\(kT/2\\)。\n如果气体分子有\\(i\\)个自由度，那么每个分子的平均总动能为\\(ikT/2\\)\n理想气体的内能 \\(1mol\\)气体中有\\(N_0\\)个分子，若不考虑振动能量，则\\(1mol\\)理想气体的内能为\n\\[E=N_0\\frac{i}{2}kT=\\frac{i}{2}RT \\]\n气体的摩尔热容 \\[C_V=\\frac{i}{2}R \\]\n\\[C_p=\\frac{(i+2)}{2}R \\]\n\\[\\gamma=\\frac{i+2}{i} \\]\n玻尔兹曼分布律 \\[n=n_0e^{-\\frac{\\varepsilon_p}{kT}} \\]\n\\(n_0\\)是零势能面的分子数密度。\n可以推知\n\\[p=nkT=p_0e^{-\\frac{\\varepsilon_p}{kT}} \\]\n分子的平均自由程 平均碰撞频率 \\[\\overline{z}=\\sqrt{2}\\pi d^2\\overline{v}n \\]\n分子的平均自由程 \\[\\overline{\\lambda}=\\frac{\\overline{v}}{\\overline{z}}=\\frac{1}{\\sqrt{2}\\pi d^2n}=\\frac{kT}{\\sqrt{2}\\pi d^2p} \\]\n静电场 电荷、库仑定律 电荷守恒定律\n在一个封闭系统内，不论进行怎样的变化过程，系统内正负电荷量的代数和保持不变。\n基尔霍夫第一定律\n根据电荷守恒定律，在稳恒电路中，节点处各支路电流的代数和应该为零。\n库伦定律\n在真空中两个静止点电荷之间的静电作用力为：\n\\[F=\\frac{1}{4\\pi\\varepsilon_0}\\frac{q_1q_2}{r^2} \\]\n作用力的方向沿着两个点电荷的连线。\n其中\\(q_1,q_2\\)是两个点电荷的电量，\\(r\\)是它们之间的距离。\\(\\varepsilon_0\\)是真空电容率，或者叫真空介电常数。其值为\\(8.854187817\\times 10^{-12} F/m\\)\n用向量来表示，则有\n\\[\\bm F = \\frac{1}{4\\pi\\varepsilon_0}\\frac{q_1q_2}{r^2} \\bm r^0 \\]\n电场 静电力是通过电场来传递的。电荷\\(q_1\\)对\\(q_2\\)施加的力是通过\\(q_1\\)产生的电场来传播的。并且这个电场不会对自身有作用力。\n电场的传播速度是光速。\n电场中某点的电场强度E的大小等于单位电荷在该点受力的大小，其方向为正电荷在该点受力的方向。\n\\[\\bm E=\\frac{\\bm F}{q_0} \\]\n电场强度叠加原理\n点电荷系在某点\\(P\\)产生的电场的电场强度等于各点电荷单独在该点产生的电场强度的矢量和。\n电偶极矩\n两个大小相等的异号点电荷\\(+q\\)和\\(-q\\)，相距为\\(l\\)，如果要计算电场强度的各场点相对这一对电荷的距离\\(r\\)比\\(l\\)大很多（\\(r\u003e\u003el\\)），这样一对点电荷称为电偶极子。定义\n\\[\\bm p = q\\bm l \\]\n为电偶极子的电偶极矩，\\(\\bm l\\)的方向规定为由负电荷指向正电荷。\n一些常见带电体产生的电场强度 10.1-1.jpg\r10.1-2.jpg\r电通量、高斯定理 电场线 形象描述场强分布的空间曲线。\n曲线上每一点的切斜方向为电场方向\n通过垂直于电场方向单位面积电场线数为该点电场强度的大小。\n特点\n始于正电荷（或无穷远），终于负电荷（或无穷远），不会在没有电荷的地方中断 若体系正负电荷一样多，则正电荷发出的电场线全部终止与负电荷 电场线不是闭合曲线，电场线不会相交。 电通量 穿过某一有向曲面的电场线条数，称为通过该面的电通量，用\\(\\varPhi_e\\)表示。\n\\[d\\varPhi_e=E_ndS=Ecos\\theta dS \\]\n直观上理解，就是将这个微小平面投影到垂直于电场线的平面上。用向量表示为\n\\[d\\varPhi_e = \\bm E\\cdot d\\bm S \\]\n积分得\n\\[\\varPhi_e=\\int d\\varPhi_e = \\int_S\\bm E\\cdot d\\bm S \\]\n高斯定理 真空中的任何静电场中，穿过任一闭合曲面的电通量，在数值上等于该闭合曲面内包围的电量的代数和乘以\\(1/\\varepsilon_0\\)。\n显然可以推知，如果高斯面内不包围电荷，电荷在它的外面，则电通量为0.\n对于不连续分布的源电荷\n\\[\\varPhi_e=\\oint_S\\bm E\\cdot d\\bm S=\\frac{1}{\\varepsilon_0}\\sum_{(内)}q_i \\]\n对于连续分布的源电荷\n\\[\\varPhi_e=\\oint_S\\bm E\\cdot d\\bm S=\\int_V\\frac{1}{\\varepsilon_0}\\rho dV \\]\n很容易联想到能否用这个公式反过来求电场强度。对于一般的电场很难来求，但是对于一些对称的电荷分布来说，是可以使用的。具体案例见教材。\n静电场的环路定理、电势能 静电力的功\n设一正的实验电荷\\(q_0\\)在静止的点电荷\\(q\\)产生的电场中，由\\(a\\)点经过某一路径\\(L\\)移动到\\(b\\)点，则静电力对\\(q_0\\)做功为\n\\[A_{ab}=\\int^b_{a(L)}\\bm F\\cdot d\\bm l=\\int^b_{a(L)}q_0\\bm E\\cdot d\\bm l \\]\n\\[=\\frac{qq_0}{4\\pi\\varepsilon_0}\\int^{r_b}_{r_a}\\frac{1}{r^2}dr=\\frac{qq_0}{4\\pi\\varepsilon_0}\\left(\\frac{1}{r_a}-\\frac{1}{r_b}\\right) \\]\n显然可知，这个功只取决于初末位置，而与路径无关。\n可以扩展到任何静电场。\n静电场的环路定理\n从上文可以得知，在静电场中，电场强度沿任一闭合路径的线积分（或称电场强度的环流）恒为零。静电场是无旋有源场，静电场的电场线不可能是闭合的。静电场是保守场。\n电势能\n电荷在电场中某点的电势能，在量值上等于把电荷从该点移动到电势能零参考点时，静电力所做的功\n\\[W_a=A_{a\"0\"}=\\int^{\"0\"}_aq_0\\bm E\\cdot d\\bm l \\]\n电势、电势差 电场中某点的电势，其量值等于单位正电荷在该点所具有的电势能。\n\\[u_a=\\frac{W_a}{q_0} \\]\n电场中某点的电势，其量值等于把单位正电荷从该点沿任意路径移动到电势能零参考点时，静电力所做的功。\n\\[u_a = \\frac{A_{a\"0\"}}{q_0}=\\int^{\"0\"}_a\\bm E\\cdot d\\bm l \\]\n由电势的定义可知，电势差可以表示为\n\\[U_{ab}=\\frac{W_a}{q_0}-\\frac{W_b}{q_0}=\\frac{A_{ab}}{q_0}=\\int^b_a\\bm E\\cdot d\\bm l \\]\n电场中\\(a,b\\)两点的电势差，在量值上等于把单位正电荷从\\(a\\)移动到\\(b\\)时，静电力所做的功。电势差与电势的零参考点的选择无关。\n可以计算电势能如下\n\\[W_a=qu_a \\]\n可以计算电场做功如下\n\\[A_{ab}=q(u_a-u_b) \\]\n电势叠加原理\n在点电荷系产生的电场中，某点的电势是各个点电荷单独存在时，在该点产生的电势的代数和。\n常见带电体产生的电势（以无穷远为电势零点） 10.2.jpg\r等势面 类似于用电场线来描绘电场强度的空间分布，也可以用等势面来描绘电势的空间分布。\n电势值相等的点联成的面称为等势面。\n在静电场中，电场线与等势面处处正交。\n电势与电场强度的关系 \\[E=-\\frac{du}{dn} \\]\n此式说明在任意一场点\\(P\\)处，电场强度的大小等于沿过该点等势面法线方向上电势的变化率。\n而\n\\[E_l=-\\frac{du}{dl} \\]\n表明，电场强度在\\(d\\bm l\\)方向的投影等于电势沿该方向变化率的负值。\n而显然有\\(dl\\geq dn\\)，所以\n\\[\\frac{du}{dl}\\leq\\frac{du}{dn} \\]\n即电势沿等势面法线方向的变化率最大。\n电场强度也可以表示为\n\\[\\bm E = E_x+E_y+E_z = -\\left(\\frac{\\partial u}{\\partial x}\\bm i+\\frac{\\partial u}{\\partial y}\\bm j+\\frac{\\partial u}{\\partial z}\\bm k\\right) \\]\n导体的静电平衡 当导体内部的电场强度处处为零，导体上的电势处处相等时，导体达到静电平衡状态。\n静电平衡的导体有以下性质\n其表面上任意一点的电场强度方向与该点处导体表面垂直。并且设该处导体表面上电荷面密度为\\(\\sigma\\)，则 \\[\\bm E = \\frac{\\sigma}{\\varepsilon_0}\\bm n \\]\n对于静电平衡状态的带电导体，未被抵消的净电荷只能分布在导体的表面上。 处于静电平衡状态的孤立导体，其表面上电荷密度的大小与表面的曲率有关。 电介质 电介质是指在通常条件下导电性能极差的物质，例如云母、变压器油等。电工中一般认为电阻率超过\\(10^8\\Omega\\cdot m\\)的物质为电介质。\n除了具有电气绝缘性能外，在电场作用下的电极化是它的一个重要特性。\n电容为\\(C_0\\)的平行板电容器（边缘效应不计），充电后两基板间电势差为\\(U_0\\)，这时极板上的电荷量为\\(Q_0=C_0U_0\\)。断开电源，并在两极板间注满各向同性的均匀电介质，再测量两极板间电势差，发现\n\\[U = \\frac{U_0}{\\varepsilon_r} \\]\n并且同时有\n\\[E = \\frac{E_0}{\\varepsilon_r} \\]\n由于电荷量\\(Q_0\\)不变。所以有\n\\[C = \\frac{Q_0}{U} = \\frac{\\varepsilon_rQ_0}{U_0}=\\varepsilon_rC_0 \\]\n其中\\(\\varepsilon_r\\)对于各向同性的均匀电介质为一常数，称为该介质的相对介电常数，是无量纲量。\n电介质分子的电结构 根据分子电结构的不同，可把电介质分为两类：\n无极分子。指分子中负电荷对称地分布在正电荷周围，以致在无外电场作用时，分子的正负电荷中心重合，分子无电偶极矩。无外电场作用时，对外呈现电中性。 有极分子。在无外电场作用时，分子的正负电荷中心不重合。这时，等量的分子正负电荷形成电偶极子，具有电偶极矩\\(\\bm p\\)。在无外电场作用时，由于分子的不规则热运动，各分子电偶极矩取向杂乱无章，因此宏观上也呈现电中性。 电介质的极化、束缚电荷 将有极分子电介质放在均匀外电场中，各分子的电偶极子受到外电场力偶的作用，都要转向外电场方向，并有序地排列起来。\n由于分子的热运动，这种分子电偶极子的排列不可能是整齐的。然而，从总体来看，这种转向排列的结果，使电介质沿电场方向前后两个侧面分别出现正负电荷。\n这种不能在电介质内自由移动，也不能离开电介质表面的电荷，称为束缚电荷。\n在外电场作用下，电介质分子的电偶极矩趋于外电场方向排列，结果在电介质的侧面出现束缚电荷的现象称为电介质的极化现象。有极分子电介质的极化常称为取向极化。\n将无极分子电介质放在外电场中，由于分子中的正负电荷受到相反方向的电场力，因而正负电荷中心将发生微小的相对位移，从而形成电偶极子，其电偶极矩将沿外电场方向排列起来。\n这时，沿外电场方向电介质的前后两侧面也将分别出现正负束缚电荷，这也是一种电介质的极化现象。无极分子电介质的极化常称为位移极化。\n一般来说，外电场越强，极化现象越显著，电介质两侧面束缚电荷的面密度也就越大，电极化程度也就越高。\n另外，在各向同性均匀电介质内部的任何体积元内，都不会有净束缚电荷。\n电介质内的电场强度 在电介质内部，合电场强度\\(E\\)总是小于自由电荷产生的电场强度\\(E_0\\)\n电介质内任意一点的电场强度\\(\\bm E\\)，应等于极板上自由电荷在该点产生的电场强度\\(\\bm E_0\\)与分布在电介质两平行端面上的束缚电荷在该点产生的电场强度\\(\\bm E'\\)的矢量和，即\n\\[\\bm E = \\bm E_0+\\bm E' \\]\n\\[E = \\frac{\\sigma_0}{\\varepsilon_0}-\\frac{\\sigma '}{\\varepsilon_0} \\]\n如果电介质满足\n\\[E=\\frac{E_0}{\\varepsilon_r} \\]\n则一定要有该各向同性的均匀电介质要充满电场所在空间。进一步研究表明，各向同性均匀电介质虽未充满电场所在空间，但只要电介质的表面是等势面，上式就成立。\n另外上式和上上式可以得出\n\\[\\sigma'=(1-\\frac{1}{\\varepsilon_r})\\sigma_0 \\]\n电介质中的高斯定理、电位移矢量D 在平板电容器中，作一封闭圆柱形高斯面，使得面积为\\(S\\)的两个端面平行于电容器极板，且一个端面在导体极板内，另一个在电介质中。\n设自由电荷和束缚电荷面密度分别为\\(\\sigma_0,\\sigma'\\)，对所作高斯面应用高斯定理，有\n\\[\\oiint_S \\bm E\\cdot d\\bm S = \\frac{1}{\\varepsilon_0}(\\sigma_0-\\sigma')S \\]\n但是\\(\\sigma'\\)通常难以预先知道，所以上式不方便使用。\n而（电介质充满时）\n\\[\\sigma'=(1-\\frac{1}{\\varepsilon_r})\\sigma_0 \\]\n所以有\n\\[\\frac{1}{\\varepsilon_0}(\\sigma_0-\\sigma')=\\frac{\\sigma_0}{\\varepsilon_0\\varepsilon_r} \\]\n代入得\n\\[\\oiint_S \\bm E\\cdot d\\bm S = \\frac{\\sigma_0}{\\varepsilon_0\\varepsilon_r}S \\]\n或者写成\n\\[\\oiint_S \\varepsilon_0\\varepsilon_r\\bm E\\cdot d\\bm S = \\sigma_0S = q_0 \\]\n令\n\\[\\bm D = \\varepsilon_0\\varepsilon_r\\bm E \\]\n称为电位移矢量（又称电通密度）\n最后可以写成\n\\[\\oiint_S\\bm D\\cdot d\\bm S = q_0 \\]\n通过任意闭合曲面\\(S\\)的总电位移通量，等于该比和曲面所包围的自由电荷量的代数和，与束缚电荷以及闭合曲面之外的自由电荷无关。\n孤立导体的电容 一个带电量为\\(q\\)的孤立导体，在静电平衡时，具有一定的电势\\(u\\)。当带电量增加时，电势也增加，且比值不变\n\\[C=\\frac{q}{u} \\]\n其中\\(C\\)是和\\(u,q\\)无关的常量，值只取决于导体的大小形状等因素。\n电容器的电容 若电容器两极板上分别带电量为\\(+q,-q\\)，两极板间的电势差为\\(u_1-u_2\\)，则\n\\[C=\\frac{q}{u_1-u_2} \\]\n并且可以推导出，若两极板相对面积为\\(S\\)，相距\\(d\\)，则有\n\\[C=\\frac{\\varepsilon_0 S}{d} \\]\n如果充入电介质，其相对介电常数为\\(\\varepsilon_r\\)\n\\[C=\\frac{\\varepsilon_0\\varepsilon_r S}{d} \\]\n电容器的串并联 串联\n\\[\\frac{1}{C} = \\frac{1}{C_1}+\\frac{1}{C_2}+\\frac{1}{C_3}+\\cdots \\]\n电容越串越小，但是耐压值提高了\n并联\n\\[C=C_1+C_2+C_3+\\cdots \\]\n电容越并越大，但是耐压值不会改变。\n静电能 电极板上迁移电荷，需要做功\n\\[dA=U(t)dq=\\frac{q(t)}{C}dq \\]\n\\[A = \\int dA = \\int^Q_0\\frac{q(t)}{C}dq=\\frac{Q^2}{2C} \\]\n另外因\\(Q=CU\\)，上式也可以写作\n\\[A=\\frac{1}{2}CU^2=\\frac{1}{2}QU \\]\n也就是电容器中储存的能量\n\\[W = \\frac{Q^2}{2C} = \\frac{1}{2}CU^2=\\frac{1}{2}QU \\]\n在平行板电容器中，如果忽略边缘效应，两极板间的电场是均匀的。因此，单位体积内储存的能量（能量密度）\\(\\omega\\)也应该是均匀的。因\\(U=Ed,C=\\varepsilon_0S/d\\)，有\n\\[W = \\frac{1}{2}\\varepsilon_0E^2Sd=\\frac{1}{2}\\varepsilon_0E^2V \\]\n而\n\\[\\omega=\\frac{W}{V}=\\frac{1}{2}\\varepsilon_0E^2 \\]\n只要空间任一处存在着电场，电场强度为\\(E\\)，该处单位体积中就储藏着\\(\\varepsilon_0E^2/2\\)的能量。\n恒定电流的磁场 磁感应强度 当\\(Id\\bm l\\)与磁感应强度方向垂直时，所受的磁场力最大，\n\\[B = \\frac{dF_{max}}{Idl} \\]\n力的方向由左手定则确定。\n电流元\\(Id\\bm l\\)在磁场中受到的磁场力\\(d\\bm F\\)如下\n\\[d\\bm F = Id\\bm l\\times \\bm B \\]\n毕奥-萨伐尔定律 电流元\\(Id\\bm l\\)在空间某点\\(P\\)出产生的磁感应强度为\n\\[dB = \\frac{\\mu_0}{4\\pi}\\frac{Idl\\sin\\theta}{r^2} \\]\n其中\\(r\\)是距离，\\(\\theta\\)是矢量\\(\\bm r\\)和\\(d\\bm l\\)的夹角。\\(\\mu_0=4\\pi\\times 10^{-7}N/A^2\\)，称为真空磁导率。\n\\(d\\bm B\\)的方向由右手螺旋法则确定。写成矢量形式如下\n\\[d\\bm B = \\frac{\\mu_0}{4\\pi}\\frac{Id\\bm l\\times \\bm r^0}{\\bm r^2} \\]\n运动电荷的磁场\n因为\\(I=nqvS\\)，代入有\n\\[d\\bm B = \\frac{\\mu_0}{4\\pi}\\frac{nqvSd\\bm l\\times \\bm r^0}{\\bm r^2} \\]\n因为\\(\\bm v\\)和\\(d\\bm l\\)方向相同，又令\\(dN = nSdl\\)，故有\n\\[d\\bm B = \\frac{\\mu_0}{4\\pi}\\frac{(dN)q\\bm v\\times \\bm r^0}{\\bm r^2} \\]\n此时，对于单个带电\\(q\\)的粒子，有\n\\[\\bm B = \\frac{d\\bm B}{dN} = \\frac{\\mu_0}{4\\pi}\\frac{q\\bm v\\times \\bm r^0}{\\bm r^2} \\]\n常用的磁感应强度公式 11.2.jpg\r磁通量 类似于电场线，可以用磁感应线描绘恒定磁场，规定\n磁力线上各点的切线方向与该点处的磁感应强度\\(\\bm B\\)的方向一致 在磁场中的某点处，垂直于该点\\(\\bm B\\)的单位面积上，穿过磁力线的数目等于该点处\\(\\bm B\\)的大小 磁场是无源场，磁力线既无起点又无终点。磁力线的环绕方向与电流的方向及环形电流绕行方向与磁力线方向都遵守右手螺旋法则。\n磁通量定义为\n\\[d\\varPhi_m=\\bm B\\cdot d\\bm S=Bcos\\theta dS \\]\n也就有\n\\[\\varPhi_m=\\int_S \\bm B\\cdot d\\bm S \\]\n磁场的高斯定理 穿过任一闭合曲面的总磁通量恒等于零，即\n\\[\\oint_S\\bm B\\cdot d\\bm S = 0 \\]\n安培环路定理 磁场中\\(B\\)矢量沿闭合路径的线积分和闭合路径的形状大小无关，只与闭合路径包围的电流有关 当电流的方向与闭合路径绕行方向之间满足右螺旋法则时，I取正值；反之取负值 \\[\\oint_L \\bm B\\cdot d\\bm l=\\mu_0\\sum_{内}I_i \\]\n磁场对电流的作用 磁场对载流导线的作用力\n\\[\\bm F = \\int_L Id\\bm l\\times \\bm B \\]\n如果导线上各电流源的受力方向不一致，就要沿坐标轴分解力来计算。\n另外闭合载流线圈在匀强磁场中受到的安培力矢量和为零\n均匀磁场对载流线圈的作用\n磁力矩为\n\\[\\bm M=\\bm p_m\\times B = IS\\bm n\\times \\bm B \\]\n其中\\(I\\)是线圈的电流，\\(S\\)是线圈面积，\\(\\bm n\\)是线圈法向量。\n磁力的功\n当回路中电流不变时，磁力所作的供等于电流乘以通过回路所包围面积内的磁通量的增量\n\\[A=I\\Delta\\varPhi \\]\n带电粒子在电场和磁场中的运动 在电场中\n\\[q\\bm E = m\\bm a=m\\frac{d\\bm v}{dt} \\]\n在磁场中\n\\[\\bm F=q\\bm v\\times \\bm B \\]\n洛伦兹力\\(F\\)的一个重要特点是它始终垂直于速度\\(v\\)，因此洛伦兹力只改变带电运动粒子的运动方向，而不改变它的速度的大小。\n霍尔效应\n霍尔元件上下两面的电势差为\n\\[U_{ab}=\\frac{IB}{nqd}=K\\frac{IB}{d} \\]\n其中\\(B\\)是与电流\\(I\\)垂直的，如果把电流方向记为霍尔元件的长度方向，那么宽度记为\\(d\\)（也就是\\(B\\)方向的长度），\\(n\\)为单位体积内载流子的数量，\\(q\\)为载流子的电荷量。\n如果载流子是电子，则称为\\(n\\)型半导体。如果是空穴，则为\\(p\\)型。\n磁介质 磁介质的分类\n磁介质是指放在磁场中经磁化后能反过来影响原来磁场的物质\n原来的磁场记作\\(\\bm B_0\\)，磁介质产生的记作\\(\\bm B'\\)，则磁介质中的磁感应强度是其矢量和\n\\[\\bm B=\\bm B_0+\\bm B' \\]\n相对磁导率定义为\n\\[\\mu_r=\\frac{B}{B_0} \\]\n顺磁质。顺磁质的\\(\\mu_r\u003e1\\)。产生的磁场和原来的磁场同方向 抗磁质。抗磁质的\\(\\mu_r\u003c1\\)。产生的磁场和原来的磁场反方向 铁磁质。铁磁质的\\(\\mu_r\u003e\u003e1\\)。产生的磁场和原来的磁场同方向 铁磁质是强磁性物质，其他称为弱磁性物质（非磁性）物质\n对于非磁性物质，其相对磁导率接近\\(1\\)，通常用磁化率来替代表示，即\n\\[\\mathcal{X}_m=\\mu_r-1 \\]\n磁介质中的环路定理\n将安培环路定理应用到磁介质中，并取以\\(r\\)为半径的闭合同心圆周为积分路径，则有\n\\[\\oint_L \\bm B\\cdot d\\bm l = \\mu_0(NI+I_s) \\]\n其中\\(I_s\\)是束缚电流，是线圈电流导致的在磁介质中产生的电流。顺磁质电流方向相同，抗磁质则相反。\n通常我们无法预先知道\\(I_s\\)，所以我们代换得\n\\[\\oint_L \\bm B\\cdot d\\bm l = \\mu_0\\mu_rNI \\]\n令\\(\\mu=\\mu_0\\mu_r\\)称为磁导率,则\n\\[\\oint_L \\frac{\\bm B}{\\mu}\\cdot d\\bm l = \\sum_{内}I \\]\n令\\(\\frac{\\bm B}{\\mu}=\\bm H\\)称为磁场强度，则\n\\[\\oint_L \\bm H\\cdot d\\bm l = \\sum_{内}I \\]\n电磁感应与电磁场 电动势 法拉第通过研究发现，不论用什么办法，只要使穿过道题闭合回路的磁通量发生变化，此回路中就会产生电流。\n电动势的定义为：非静电力把单位正电荷从负极通过电荷内部搬移到正极所做的功，用\\(\\varepsilon\\)表示。如果用\\(A_k\\)表示在电源内非静电力把正电荷\\(q\\)从负极搬到正极所做的功，则\n\\[\\varepsilon = \\frac{A_k}{q} \\]\n同样的，我们定义单位正电荷所受的非静电力定义为非静电性电场强度。若用\\(F_k\\)表示正电荷\\(q\\)所受的非静电力，用符号\\(E_k\\)表示非静电性电场强度，则\n\\[\\bm E_k=\\frac{\\bm F_k}{q} \\]\n结合两式，有\n\\[A_k = \\int^+_- \\bm F_k\\cdot d\\bm l = q\\int^+_- \\bm E_k\\cdot d\\bm l \\]\n\\[\\varepsilon = \\int^+_- \\bm E_k\\cdot d\\bm l \\]\n如果一个闭合回路\\(L\\)上处处都有非静电力\\(F_k\\)存在，这时整个闭合回路内的总电动势是\n\\[\\varepsilon = \\oint \\bm E_k\\cdot d\\bm l \\]\n对于有非静电力\\(F_k\\)存在的一段电路\\(ab\\)上的电动势为\n\\[\\varepsilon = \\int^b_a \\bm E_k\\cdot d\\bm l \\]\n法拉第电磁感应定律 导体回路中产生的感应电动势\\(\\varepsilon_i\\)的大小与穿过回路的磁通量的变化率\\(d\\varPhi/dt\\)成正比\n\\[\\varepsilon_i =-\\frac{d\\varPhi}{dt} \\]\n具体方向由右手螺旋定则确定。\n如果有多匝线圈，并且穿过各线圈的磁通量相同，则总磁通量\\(\\varPsi=N\\varPhi\\)\n楞次定律\n闭合回路中，感应电流的方向总是使得它自身所产生的磁通量反抗引起感应电流的磁通量的变化。\n动生电动势 由于导体或导体回路在恒定磁场中运动，导体或导体回路内产生的感应电动势。\n若长为\\(l\\)的导体棒\\(ab\\)，在恒定的均匀磁场中以匀速\\(\\bm v\\)沿垂直于磁场\\(\\bm B\\)的方向运动。\n导体棒\\(ab\\)上的动生电动势为\n\\[\\varepsilon_i = \\int^b_a \\bm E_k\\cdot d\\bm l = \\int^b_a (\\bm v\\times \\bm B)\\cdot d\\bm l \\]\n可以根据左手定则判断电动势方向。\n感生电动势 导体或导体回路不动，由于磁场随时间变化，导体或导体回路中产生的感应电动势。\n变化的磁场在周围空间激发出电场线为闭合曲线的电场，称其为感生电场或有旋电场。有旋电场的出现与是否存在导体没有关系。\n当回路固定不动，磁通量\\(\\varPsi\\)的变化仅来自磁场的变化时，电动势为\n\\[\\varepsilon_i = \\oint_L \\bm E_V\\cdot \\bm l=-\\iint_S\\frac{\\partial\\bm B}{\\partial t}\\cdot d\\bm S \\]\n自感现象 导体回路中由于自身电流的变化，而在自身回路中产生感应电动势的现象。产生的电动势称为自感电动势。\n设一回路通有电流\\(I\\)，根据毕奥-萨伐尔定律，总磁通\n\\[\\varPsi = LI \\]\n式中比例系数\\(L\\)称为该回路的自感系数，简称自感。如果回路周围不存在铁磁质，自感\\(L\\)是与电流\\(I\\)无关，仅由回路的匝数、几何形状、大小，以及周围介质的磁导率决定的物理量。\n若回路的自感\\(L\\)保持不变，则通过回路的总磁通\\(\\varPsi\\)仅随回路中电流的变化而变化，根据法拉第电磁感应定律，自感电动势为\n\\[\\varepsilon_L = -\\frac{d\\varPsi}{dt} = -L\\frac{dI}{dt} \\]\n式中的负号表明自感电动势产生的感应电流的方向总是反抗回路中电流\\(I\\)的变化。\n互感现象 由于某一个导体回路中的电流发生变化，而在邻近导体回路内产生感应电动势的现象，称为互感现象。\n类似于自感系数。设\\(\\varPsi_{21}\\)表示回路\\(1\\)中通有电流\\(I_1\\)时，它激发的磁场在回路\\(2\\)中产生的总磁通。\n\\[\\varPsi_{21} = M_{21}I_1 \\]\n同样也有\n\\[\\varepsilon_M = -\\frac{d\\varPsi}{dt} = -M\\frac{dI}{dt} \\]\n磁能 一个自感为\\(L\\)通有电流\\(I\\)的线圈，其中所储存的磁能\n\\[W_m=\\frac{1}{2}LI^2 \\]\n称为自感磁能。\n储存在线圈中的能量可以用描述磁场的物理量\\(B\\)或\\(H\\)来表示。长直螺线管的自感为\\(L=\\mu n^2 V\\)，其磁能为\n\\[W_m = \\frac{1}{2}\\mu n^2 I^2V \\]\n对于长直螺线管，有\n\\[H = nI;B=\\mu n I \\]\n有\n\\[W_m = \\frac{1}{2}BHV=\\frac{1}{2}\\mu H^2V=\\frac{1}{2}\\frac{B^2}{\\mu} V \\]\n其中\\(\\mu\\)是其磁导率，\\(n\\)是每单位长度的匝数，\\(V\\)是螺线管的体积，所以能量密度为\n\\[w_m = \\frac{1}{2}BH \\]\n进一步的研究表明，某点磁场的能量密度只与该点的磁感应强度\\(B\\)和介质的性质有关。\n\\[dW_m = w_mdV = \\frac{1}{2}BHdV \\]\n\\[W_m = \\int_V dW_m=\\frac{1}{2}\\int_V BHdV \\]\n位移电流 对于非恒定电流，例如电路中加一个电容器，那么原始的安培环路定理则不再适用，因为将曲面穿过两极板之间得到的结果是0. 不符合事实。\n于是麦克斯韦提出了位移电流的概念，即在电容器的两个极板中也有电流。定义为\n\\[I_D=\\frac{d\\varPhi_D}{dt} \\]\n设极板的面积为\\(S\\)，某时刻极板上自由电荷面密度为\\(\\sigma\\)，则电位移为\\(D=\\sigma\\)，于是极板间的电位移通量\\(\\varPhi_D=DS=\\sigma S\\)。电位移通量的时间变化率为\n\\[\\frac{d\\varPhi_D}{dt} = \\frac{d}{dt}\\sigma S=\\frac{dq}{dt} \\]\n其中\\(dq/dt\\)就是导线中的传到电流。\n于是可以把安培环路定理推广为\n\\[\\oint_L \\bm H\\cdot d\\bm l=I+I_D \\]\n麦克斯韦方程组的积分形式，电磁场 \\[\\oint_S \\bm D\\cdot d\\bm S = \\sum_i q_i \\]\n\\[\\oint_L \\bm E\\cdot d\\bm l = -\\iint_S\\frac{\\partial \\bm B}{\\partial t}\\cdot d\\bm S \\]\n\\[\\oint_S \\bm B\\cdot d\\bm S = 0 \\]\n\\[\\oint_L \\bm H\\cdot d\\bm l = \\sum(I_D+I) \\]\n狭义相对论基础 力学相对性原理 在彼此作匀速直线运动的所有惯性系中，物体运动所遵循的力学规律是完全相同的，应具有完全相同的数学表达形式。也就是说，对于描述力学现象的规律而言，所有惯性系都是等价的。这称为力学相对性原理\n绝对时空观 狭义相对论之前，科学家们普遍认为时间和空间都是绝对的，可以脱离物质运动而存在，并且时间和空间也没有任何联系。\n这就是经典力学的时空观，也称为绝对时空观。\n伽利略坐标变换式 设有两个惯性参考系\\(S,S'\\)，取坐标系\\(Oxyz,O'x'y'z'\\)，简单起见他们的坐标轴相互平行且\\(x,x'\\)相互重合，设\\(S'\\)沿\\(x\\)轴方向以恒定速度\\(\\bm u\\)相对\\(S\\)运动，并且\\(O,O'\\)重合时\\(t=t'=0\\)\n则在\\(S\\)中一点\\((x,y,z)\\)在\\(S'\\)中的坐标为\n\\[\\left.\\begin{matrix} x'=\u0026x-ut \\\\ y'=\u0026y \\\\ z'=\u0026z \\end{matrix}\\right\\} \\]\n根据绝对时间概念，有\n\\[t' = t \\]\n这就是这两个坐标系间的伽利略坐标变换式。\n牛顿运动定律具有伽利略变换的不变性 经典力学所有的基本定律都满足经典力学相对性原理，但是之后发现麦克斯韦方程组并不满足。\n狭义相对论的两个基本假设 光速的伽利略变换未能被实验证实\n光是电磁波，由麦克斯韦方程组可知\n\\[c=\\frac{1}{\\sqrt{\\varepsilon_0\\mu_0}}=2.998\\times 10^8 m/s \\]\n也就是说光速是恒定的，与传播方向和参考系的选择无关。\n如果伽利略变换是正确的，则在\\(S'\\)中光速应该是\\(c-u\\)，但迈克耳孙-莫雷实验证实了光速都是\\(c\\)，发现了经典力学和光速的不相容性。\n假设1\n在所有惯性系中，一切物理学定律都相同，即具有相同的数学表达形式。或者说，对于描述一切物理现象的规律来说，所有惯性系都是等价的。这也称为狭义相对论的相对性原理。\n假设2\n在所有惯性系中，真空中光沿各个方向传播的速率都等于同一个恒量\\(c\\)，与光源和观察者的运动状态无关。这也称为光速不变原理。\n“同时性”的相对性 在\\(S'\\)系中异地同时发生的两个事件，在\\(S\\)系看来并不同时。反过来也是这样。\n需要说明的是，在一个惯性系同一地点发生的两个同时事件，对于其他惯性系也是同时的。\n产生“同时性”的相对性的原因是，光在不同惯性系中具有相同的速率和光的速率是有限的。\n时间延缓 将在一个惯性系中测得的、发生在该惯性系中同一地点的两个事件之间的时间间隔称为原时。\n时间的测量具有相对性，在不同惯性系中测量给定的两个事件之间的时间间隔，测得的结果以原时最短，这一现象称为时间延缓效应。\n时间延缓效应还可陈述为，运动时钟走的速率比静止时钟走的速率要慢。\n时间延缓效应也是相对的，运动的\\(S'\\)的时钟相对于静止的\\(S\\)的时钟要慢。反过来也是这样。\n以公式来说，设两件事发生的间隔在静止的\\(S\\)看来是\\(\\tau\\)，而在运动的\\(S'\\)看来是\\(\\tau_0\\)（即原时，事件是在\\(S'\\)中同一地点发生的），\\(S'\\)相对于\\(S\\)以\\(\\bm u\\)的速率运动则\n\\[\\tau = \\frac{\\tau_0}{\\sqrt{1-\\beta^2}}=\\gamma\\tau_0 \\]\n其中\\(\\beta=u/c,\\gamma = 1/\\sqrt{1-\\beta^2}\\)\n长度收缩 设地面上有一静止的尺子，车（\\(S'\\)系）以速度\\(\\bm u\\)相对地面（\\(S\\)系）沿尺子长度方向运动。\n若地面上的人观察到尺子长为\\(L\\)，也称为原长，则车上的人观察到\n\\[L'=L\\sqrt{1-\\bigg(\\frac{u}{c}\\bigg)^2} \\]\n其表明，沿尺长度方向运动的观测者测得的尺长，较相对尺静止观测者测得的同一尺的原长\\(L\\)要短，或者说，各惯性系中测量同一尺长，以原长为最长。\n洛伦兹坐标和时间变换式 条件设置和伽利略坐标变换式一致，只是增加了第四维时间，即\\(S\\)系中坐标为\\((x,y,z,t)\\)，\\(S'\\)系中为\\((x',y',z',t')\\)，洛伦兹坐标和事件变换式为\n\\[x'=\\frac{x-ut}{\\sqrt{1-\\beta^2}},\\quad t'=\\frac{t-\\frac{u}{c^2}x}{\\sqrt{1-\\beta^2}} \\]\n\\[y'=y,\\quad z'=z \\]\n逆变换为\n\\[x=\\frac{x'+ut'}{\\sqrt{1-\\beta^2}},\\quad t=\\frac{t'+\\frac{u}{c^2}x'}{\\sqrt{1-\\beta^2}} \\]\n\\[y=y',\\quad z=z' \\]\n在低速时，即\\(u\u003c\u003c c\\)时，\\(\\beta\\approx0\\)，此时洛伦兹变换与伽利略变换几乎一致，也就是说低速情况我们可以使用伽利略变换。\n真空中的光速\\(c\\)是一切物体运动速率的极限。\n空间间隔和时间间隔是紧密联系着的，即\n\\[\\Delta x'=\\frac{\\Delta x-u\\Delta t}{\\sqrt{1-\\beta^2}},\\quad \\Delta t'=\\frac{\\Delta t-\\frac{u}{c^2}\\Delta x}{\\sqrt{1-\\beta^2}} \\]\n逆变换\n\\[\\Delta x=\\frac{\\Delta x'+u\\Delta t'}{\\sqrt{1-\\beta^2}},\\quad \\Delta t=\\frac{\\Delta t'+\\frac{u}{c^2}\\Delta x'}{\\sqrt{1-\\beta^2}} \\]\n洛伦兹变换与狭义相对论时空观 “同时性”的相对性\n设在\\(S'\\)系中不同地点、同时发生了两个事件，则在\\(S\\)看来发生的时间间隔为\n\\[\\Delta t= \\bigg(\\frac{u}{c^2}\\Delta x'\\bigg)\\bigg/\\sqrt{1-\\beta^2} \\]\n时间延缓\n\\(S'\\)中在同一地点、不同时间发生的两个事件，对于\\(S\\)来说事件间隔为\n\\[\\Delta t = \\frac{\\Delta t'}{\\sqrt{1-\\beta^2}}=\\frac{\\tau_0}{\\sqrt{1-\\beta^2}} \\]\n长度收缩\n设尺沿\\(x'\\)方向静止在\\(S'\\)系中，\\(S'\\)系中观测者测得尺长\\(L_0=\\Delta x'\\)为尺的原长，\\(S\\)系中观测者要测量运动尺的长度\\(L\\)，必须要在\\(S\\)系中同时确定尺两端的坐标\\(x_1,x_2\\)，这样\\(L=x_2-x_1\\)\n\\[L=\\Delta x=L_0\\sqrt{1-\\beta^2} \\]\n爱因斯坦速度相加定律 \\[v_x' = \\frac{v_x-u}{1-\\frac{u}{c^2}v_x} \\]\n\\[v_y' = \\frac{v_y\\sqrt{1-\\beta^2}}{1-\\frac{u}{c^2}v_x} \\]\n\\[v_z' = \\frac{v_z\\sqrt{1-\\beta^2}}{1-\\frac{u}{c^2}v_x} \\]\n相对论动量和质量 质量是一个和速率有关的量\n\\[m(v) = \\frac{m_0}{\\sqrt{1-(\\frac{v}{c})^2}} \\]\n式中\\(m_0\\)是质点静止时的质量，即由相对该质点静止的观察者测得的质量，称为静止质量。\n于是动量为\n\\[\\bm p = m\\bm v = \\frac{m_0}{\\sqrt{1-(\\frac{v}{c})^2}}\\bm v \\]\n同时，力为\n\\[\\bm F = \\frac{d\\bm p}{dt} = \\frac{d}{dt}\\bigg(\\frac{m_0}{\\sqrt{1-(\\frac{v}{c})^2}}\\bm v\\bigg) \\]\n相对论动能 \\[E_k = \\int\\bm F\\cdot d\\bm r = \\int_0^v d(mv)\\cdot \\bm v \\]\n\\[E_k = \\int^m_{m_0}c^2dm = mc^2-m_0c^2 \\]\n质能关系式 \\[E=mc^2\\\\ E_0=m_0c^2 \\]\n光子的静质量为零，而频率为\\(\\nu\\)的光子所对应的能量为\\(E=h\\nu\\)，所以光子的动质量为\n\\[m_\\varphi = \\frac{E}{c^2} = \\frac{h\\nu}{c^2} \\]\n相对论能量和动量的关系 \\[E^2 = p^2c^2 + E_0^2 \\]\n对于光子\n\\[p = \\frac{h\\nu}{c} = \\frac{h}{\\lambda} \\]\n量子物理基础 普朗克量子假设 物体由其温度所决定的电磁辐射称为热辐射\n当辐射和吸收达到平衡时，物体的温度不再变化而处于热平衡状态，这时的热辐射称为平衡热辐射。\n物体的辐射本领越大，其吸收本领也越大，反之亦然\n为描述物体热辐射能量按波长的分布规律，引入单色辐射出射度（简称单色辐出度）。其定义为：物体单位表面积在单位时间内发射的，波长在\\(\\lambda\\to\\lambda+d\\lambda\\)范围内的辐射能\\(dM_\\lambda\\)与波长间隔\\(\\lambda\\)的比值\n\\[M_\\lambda(T) = \\frac{dM_\\lambda}{d\\lambda} \\]\n能够全部吸收各种波长的辐射能而完全不发生反射和透射的物体称为绝对黑体，简称黑体。\n维恩公式在短波部分和实验曲线吻合的很好，但在长波部分相差较大。\n瑞利金斯公式在波长很长的部分与实验曲线吻合，但在短波部分，随着波长的减小，理论结果会趋于无穷大，这被称作紫外灾难。\n普朗克找到一个经验公式，在一定温度\\(T\\)下，黑体单色辐出度为\n\\[M_{B\\lambda}(T) = 2\\pi hc^2\\lambda^{-5}\\frac{1}{exp(\\frac{hc}{k\\lambda T})-1} \\]\n其中\\(c\\)是光速，\\(k\\)是玻尔兹曼常数，\\(h\\)是普朗克常量，其值为\\(h=6.6260755\\times 10^{-34} J\\cdot s\\)\n普朗克发现，要导出这个公式，必须引进一个假设：腔壁中带电谐振子的能量不能连续变化，频率为\\(\\nu\\)的振子的能量\\(\\varepsilon\\)只能取\\(h\\nu\\)的整数倍，即\\(\\varepsilon = nh\\nu,n\\)称为量子数。谐振子和腔内辐射场交换能量（即发射和吸收辐射能）也只能是\\(h\\nu\\)的整数倍。谐振子能量的这个最小单位称为能量子，上述假设称为普朗克的量子假设。\n光电效应的实验规律 金属及其化合物在光照射下发射电子的现象称为光电效应。\n研究表明光电效应有如下规律\n阴极\\(K\\)在单位时间内所发射的光电子数与照射光的光强\\(I\\)成正比。 存在截止频率。当照射光频率\\(\\nu\\)小于某个最小值\\(\\nu_0\\)时，不管光强多大，照射时间多长，都没有光电子溢出。这个最小频率就叫做截止频率，也叫做红限。 光电子的最大初动能与照射光的强度无关，而与其频率成线性关系。给光电子施加反向电势差，使得光电流为零，此时反向电势差的绝对值称为遏止电压。 遏止电压和最大初动能的关系为\n\\[\\frac{1}{2}mv_m^2=eU_a \\]\n与频率的关系为\n\\[U_a = K(\\nu-\\nu_0) \\]\n式中\\(K\\)为\\(U_a-\\nu\\)图线的斜率。\\(K\\)是一个与材料性质无关的普适常量。\\(\\nu_0\\)是图线在横轴上的截距，它等于该种金属的光电效应红限。\n光子是即时发射的，滞后时间不超过\\(10^{-9}s\\) 经典物理难以解释光电效应 根据波动理论作出的预言和上述实验规律不符。例如它预言不存在红限、初动能和光强正相关而和频率无关、发射不是即时的等等。\n爱因斯坦光子假说和光电效应方程 爱因斯坦假设说，一束光就是一束以光速运动的粒子流，这些粒子称为光子；频率为\\(\\nu\\)的每一光子所具有的能量为\\(h\\nu\\)，它不能再分割，而只能整个地被吸收或产生出来。\n光电效应方程为\n\\[h\\nu = A + \\frac{1}{2}mv^2_m \\]\n式中\\(\\frac{1}{2}mv_m^2\\)是光电子的最大初动能。也就是电子从金属表面逸出时所具有的最大初动能，内部电子逸出时所需做的功大于逸出功\\(A\\)，因而初动能较小。\n显然我们可以解释最低频率\\(\\nu_0\\)为\n\\[\\nu_0 = \\frac{A}{h} \\]\n另外照射光的光强就是单位时间到达被照物单位垂直表面积的能量，是由单位时间内到达单位垂直面积的光子数\\(N\\)决定的，即\\(I = Nh\\nu\\)\n光（电磁辐射）的波粒二象性 光子的质量为\n\\[m_\\varphi = \\frac{E}{c^2} = \\frac{h\\nu}{c^2} = \\frac{h}{c\\lambda} \\]\n动量为\n\\[p = m_{\\varphi}c=\\frac{h}{\\lambda} \\]\n康普顿效应 康普顿发现，单色\\(X\\)射线被物质散射时，散射线中有两种波长，其中一种波长比入射线的长，且波长改变量与入射线波长无关，而随散射角的增大而增大，这种波长变大的散射现象称为康普顿散射，或康普顿效应。\n实验结果显示，对任一散射角\\(\\theta\\)都测量到两种波长\\(\\lambda_0\\)和\\(\\lambda\\)的散射线，且\\(\\Delta\\lambda = \\lambda - \\lambda_0\\)随\\(\\theta\\)增大而增大，而与\\(\\lambda_0\\)及散射物质无关。\n实验还表明对轻元素，波长变大的散射线相对较强，而对重元素，波长变大的散射线相对较弱。\n康普顿效应的微观机制是：自由电子吸收一个入射光子后发射一个波长较长的光子，且电子与光子沿不同方向运动，由于动量和能量都守恒，因此康普顿散射过程可以看成是入射光子与自由电子的弹性碰撞。\n波长改变量为\n\\[\\Delta\\lambda = \\lambda-\\lambda_0 = \\frac{c}{\\nu}-\\frac{c}{\\nu_0} = \\frac{h}{m_0c}(1-cos\\theta) \\]\n也通常写为\n\\[\\lambda-\\lambda_0 = \\frac{2h}{m_0c}sin^2\\frac{\\theta}{2} = 2\\lambda_C\\sin^2\\frac{\\theta}{2} \\]\n其中\\(\\lambda_C = \\frac{h}{m_0c}\\)\n氢原子光谱 实验发现，各种元素的原子光谱都由分立的谱线所组成，并且谱线所组成，并且谱线的分布具有确定的规律。氢原子的是最简单的，其实验规律如下\n氢原子光谱是彼此分立的线状光谱，每一条谱线具有确定的波长（或频率） 每一条光谱线的波数\\(\\~\\nu=1/\\lambda\\)都可以表示为两项之差，即 \\[\\~\\nu = \\dfrac{1}{\\lambda} = T(k) - T(n) = R_H\\left(\\dfrac{1}{k^2}-\\dfrac{1}{n^2}\\right) \\]\n式中\\(k\\)和\\(n\\)均为正整数，且\\(n\u003ek\\)。\\(R_H\\)称为氢光谱的里伯德常数，近代测量值为\\(R_H=1.0973731\\times 10^7m^{-1},T(n)=R_H/n^2\\)称为氢的光谱项。上式称为里德伯-里兹并和原则。\n当整数\\(k\\)取一定值时，\\(n\\)取大于\\(k\\)的各整数所对应的各条谱线构成一谱线系；每一谱线系都有一个线系的极限，对应于\\(n\\to\\infty\\)的情况。\\(k=1(n=2,3,\\cdots)\\)的谱线系称为赖曼系，\\(k=2(n=3,4,\\cdots)\\)的谱线系称为巴耳末系。 玻尔理论对氢原子光谱的解释是：\n原子只能处在一系列具有不连续能量的稳定状态，简称定态。所以核外电子只能在一系列不连续的圆轨道上运动，但并不辐射电磁波。 当原子从一个能量为\\(E_k\\)的定态跃迁到另一个能量为\\(E_n\\)的定态时，会发射或吸收一个频率为\\(\\nu_{kn}\\)的光子 \\[\\nu_{kn}=\\dfrac{|E_k-E_n|}{h} \\]\n电子在稳定圆轨道上运动时，其轨道角动量\\(L=mvr\\)必须等于\\(\\dfrac{h}{2\\pi}\\)的整数倍，即 \\[L = mvr = n\\dfrac{h}{2\\pi} = n\\hbar (n=1,2,3,\\cdots) \\]\n其中\\(\\hbar = \\dfrac{h}{2\\pi}\\)，称为约化普朗克常数。上式称为角动量量子化条件，\\(n\\)称为量子数。\n玻尔还推出，原子处于第\\(n\\)个定态时的电子轨道半径为\n\\[r_n = n^2r_1 \\]\n其中\\(r_1\\)是氢原子中电子的最小轨道半径，称为玻尔半径，其值为\n\\[r_1=\\dfrac{\\varepsilon_0h^2}{\\pi me^2}=0.529\\times 10^{-10}m \\]\n\\(n=1\\)的定态称为基态，\\(n=2,3,4,\\cdots\\)各态均称为受激态。\n氢原子能量等于电子的动能和电势能之和，处在量子数为\\(n\\)的定态时，能量为\n\\[E_n = -\\dfrac{1}{8\\pi\\varepsilon_0}\\dfrac{e^2}{r_n} = -\\dfrac{1}{n^2}\\left(\\dfrac{me^4}{8\\varepsilon_0^2h^2}\\right)\\quad n=1,2,3,\\cdots \\]\n这称为能量量子化，这种量子化的能量叫做能级。令\\(n=1\\)，则\n\\[E_1 = -\\left(\\dfrac{me^4}{8\\varepsilon_0^2h^2}\\right) = -13.6 eV \\]\n这个能量是基态能级的能量，也是氢原子的电离能。\n微观粒子的波粒二象性 德布罗意假设：不仅光具有波粒二象性，一切实物粒子如电子、原子、分子等也都具有波粒二象性。他给出如下公式\n\\[E = mc^2 = h\\nu \\]\n\\[p = mv = \\dfrac{h}{\\lambda} \\]\n上二式可写成\n\\[\\nu = \\dfrac{E}{h} = \\dfrac{mc^2}{h} = \\dfrac{m_0c^2}{h\\sqrt{1-v^2/c^2}} \\]\n\\[\\lambda = \\dfrac{h}{p} = \\dfrac{h}{mv} = \\dfrac{h}{m_0v}\\sqrt{1-\\dfrac{v^2}{c^2}} \\]\n上面的\\(\\lambda\\)称为德布罗意波或物质波的波长，该式称为德布罗意关系式。\n德布罗意指出，电子在玻尔轨道上运动与这个电子的物质波沿轨道传播相联系，满足驻波条件\n\\[2\\pi r = n\\lambda \\]\n代入\\(\\lambda = \\dfrac{h}{mv}\\)就可以得到玻尔理论中的角动量量子化条件。\n物质波的实验证明 德布罗意关于物质波的假设，首先在1927年由戴维孙-革末实验证实。\n二人在做电子束在晶体表面散射实验时，观察到了和\\(X\\)射线在晶体表面衍射想类似的电子衍射现象。\n1961年他人还做了电子束的单缝、双缝等等实验。\n除了电子，也有人做了中子、原子的实验。\n不确定关系 在经典力学中，质点在任何时刻都有完全确定的位置、动量、能量、角动量等。与此不同，微观粒子具有明显的波动性，以致它的某些成对物理量不可能同时具有确定的量值。例如，位置坐标和动量、角坐标和角动量等，其中一个量确定越准确，另一个量的不确定程度就越大。\n海森堡根据量子力学推出，一个粒子的位置坐标的不确定量\\(\\Delta x\\)和其同一时刻的动量不确定量\\(\\Delta p_x\\)，满足\n\\[\\Delta x\\Delta p_x \\geq \\dfrac{\\hbar}{2} \\]\n称为海森堡坐标和动量的不确定关系式。\n不确定关系不仅存在于坐标和动量之间，也存在于能量和时间之间，如果微观体系处于某一状态的时间为\\(\\Delta t\\)，则其能量必有一个不确定量\\(\\Delta E\\)，由量子力学可推出\n\\[\\Delta E\\Delta t\\geq\\dfrac{\\hbar}{2} \\]\n上式称为能量和时间不确定关系式。\n将其应用于原子系统可以讨论原子各受激态能级宽度\\(\\Delta E\\)和该能级平均寿命\\(\\Delta t\\)之间的关系。\n原子通常处于能量最低的基态，在受激发后将跃迁到各个能量较高的受激态，停留一段时间后又自发跃迁进入能量较低的定态。大量同类原子在同一高能级上停留时间长短不一，但平均停留时间为一定值，称为该能级的平均寿命。\\(\\Delta t\\)越长的能级越稳定，宽度\\(\\Delta E\\)越小。由于能级有一定宽度，光谱线也就有一定宽度了。\n有些原子具有一种特殊的受激态，寿命可长达\\(10^{-3}s\\)或更长，这类受激态称为亚稳态。\n波函数及其统计解释 波函数是时间和空间坐标的函数，表示为\n\\[\\varPsi(\\bm r,t) \\]\n假设粒子只沿\\(x\\)轴正方向运动，且不受外力（即自由粒子）。则其德布罗意波的波函数可以表示为\n\\[\\varPsi(x,t) = \\psi_0e^{-i2\\pi(\\nu t-\\frac{x}{\\lambda})} = \\psi_0e^{-\\frac{i}{\\hbar}(Et-px)} \\]\n其中\\(\\nu\\)是其物质波的频率，\\(\\lambda\\)是波长，\\(E\\)是能量，\\(p\\)是动量。\\(\\psi_0\\)是一个待定常数，\\(\\psi_0e^{\\frac{i}{\\hbar}px}\\)相当于\\(x\\)处波函数的复振幅，而\\(e^{-\\frac{i}{\\hbar}Et}\\)则反映波函数随时间的变化。\n玻恩指出，实物粒子的德布罗意波是一种概率波；\\(t\\)时刻粒子在空间\\(\\bm r\\)处附近的体积元\\(dV\\)中出现的概率\\(dW\\)与该处波函数绝对值的平方成正比，可以写成\n\\[dW = |\\varPsi(\\bm r,t)|^2dV = \\varPsi(\\bm r,t)\\varPsi^*(\\bm r,t) dV \\]\n其中\\(\\varPsi^*(\\bm r,t)\\)是\\(\\varPsi(\\bm r,t)\\)的共轭复数。\n波函数绝对值平方\\(|\\varPsi(\\bm r,t)|^2\\)代表\\(t\\)时刻粒子在空间\\(r\\)处的单位体积中出现的概率，又称为概率密度。\n波函数必须单值、有限、连续，不符合这三个条件的波函数是没有物理意义的。又因为粒子必定要在空间中的某一点出现，因此粒子在空间各点出现的概率总和等于\\(1\\)，即应有\n\\[\\iiint|\\varPsi(\\bm r,t)|^2dxdydz = 1 \\]\n上式又称为波函数的归一化条件，其中积分区域遍及粒子可能到达的整个空间。\n定态薛定谔方程 薛定谔建立了适用于低速情况的、描述微观粒子在外力场中运动的微分方程，也就是物质波波函数\\(\\varPsi(\\bm r,t)\\)满足的方程，称为薛定谔方程。\n质量为\\(m\\)的粒子在外力场中运动时，一般情况下，其势能\\(V\\)可能是空间坐标和时间的函数，即\\(V=V(\\bm r,t)\\)，薛定谔方程为\n\\[\\bigg[-\\dfrac{\\hbar^2}{2m}\\bigg(\\dfrac{\\partial^2}{\\partial x^2}+\\dfrac{\\partial^2}{\\partial y^2}+\\dfrac{\\partial^2}{\\partial z^2}\\bigg)+V(\\bm r,t)\\bigg]\\varPsi(\\bm r,t) = i\\hbar\\dfrac{\\partial \\varPsi(\\bm r,t)}{\\partial t} \\]\n粒子在稳定力场中运动时，势能函数\\(V\\)与时间无关，\\(V=V(\\bm r)\\)。此时也有\\(|\\varPsi(\\bm r,t)|^2=|\\varPsi(\\bm r)|^2\\)，即概率密度与时间无关。定态波函数的空间部分\\(\\varPsi(\\bm r)\\)也叫做定态波函数。其满足\n\\[\\bigg(\\dfrac{\\partial^2}{\\partial x^2}+\\dfrac{\\partial^2}{\\partial y^2}+\\dfrac{\\partial^2}{\\partial z^2}\\bigg)\\varPsi(\\bm r)+\\dfrac{2m}{\\hbar^2}(E-V)\\varPsi(\\bm r) = 0 \\]\n上式称为定态薛定谔方程，也称不含时间的薛定谔方程。\n如果粒子在一维空间中运动，则\n\\[\\dfrac{d^2\\varPsi(x)}{dx^2}+\\dfrac{2m}{\\hbar^2}(E-V)\\varPsi(x)=0 \\]\n上式称为一维定态薛定谔方程。\n在关于微观粒子的各种定态问题中，把势能函数\\(V(\\bm r)\\)的具体形式代入薛定谔方程中即可求解，得到定态波函数。\n一维无限深势阱中的粒子 以金属中电子的运动为例，讨论薛定谔方程的应用。实际情况是相当复杂的，为简单起见，假定电子只能作沿\\(x\\)轴的一维运动，且其势能函数具有如下的形式\n\\[\\left.\\begin{align*} V(x) = 0,\u0026\\quad 0 \u003c x \u003c a\\\\ V(x) = \\infty,\u0026\\quad x \u003c 0\\ or\\ x \u003e a \\end{align*}\\right\\} \\]\n这种形式的力场叫做一维无限深（方）势阱。由于力和势能的关系\\(F_x = -\\dfrac{\\partial V}{\\partial x}\\)，在金属内部，电子不受力的作用；在金属表面处势能突变，受到指向金属内部的无限大作用力，因此不可能越出金属表面。不过这个模型过于简单和粗略。\n我们可以推知，一维无限深势阱中粒子能量为\n\\[E_n = \\dfrac{\\hbar^2k^2}{2m} = n^2\\dfrac{h^2}{8ma^2},\\quad n = 1,2,3,\\cdots \\]\n由此可见，一维无限深势阱中粒子能量是量子化的，\\(n\\)称为量子数。\\(E_1\\)是最小能量，也称为零点能。其余各级能量可以表示为\\(E_n = n^2E_1\\)\n量子数为\\(n\\)的定态波函数为\n\\[\\varPsi_n(x) = \\pm\\sqrt{\\dfrac{2}{a}}\\sin\\dfrac{n\\pi}{a}x,\\quad n=1,2,3,\\cdots \\]\n束缚在无限深势阱中的粒子的定态波函数具有驻波的形式，且波长\\(\\lambda_n\\)满足\n\\[a = n\\dfrac{\\lambda_{n}}{2},\\quad,n=1,2,3,\\cdots \\]\n氢原子的量子力学结论 能量量子化 \\[E_n = -\\dfrac{1}{n^2}\\dfrac{me^4}{8\\varepsilon_0^2h^2},\\quad,n=1,2,3,\\cdots \\]\n这是氢原子的总能量，\\(n\\)称为主量子数。\n角动量量子化 \\[L = \\sqrt{l(l+1)}\\hbar,\\quad l = 0,1,2,\\cdots,n-1 \\]\n式中的\\(l\\)为小于\\(n\\)的正整数，称为副量子数。\n角动量空间量子化 电子绕核运动的角动量\\(\\bm L\\)在外磁场\\(\\bm B\\)方向的投影\\(L_z\\)，量子力学给出的结果是\n\\[L_z = m_l\\hbar,\\quad m_l = 0,\\pm1,\\pm2,\\cdots,\\pm l \\]\n式中的\\(m_l\\)称为磁量子数。上式说明\\(\\bm L\\)在空间的取向也是量子化的，称为空间量子化。\n施特恩-盖拉赫实验、电子自旋 电子自旋角动量的大小\\(S\\)及其在外磁场方向的投影\\(S_z\\)分别为\n\\[S = \\sqrt{\\dfrac{1}{2}\\bigg(\\dfrac{1}{2}+1\\bigg)}\\hbar = \\sqrt{\\dfrac{3}{4}}\\hbar \\]\n\\[S_z = \\pm \\dfrac{1}{2}\\hbar \\]\n自旋磁量子数\\(m_s=\\pm\\dfrac{1}{2}\\)，它决定了电子自旋角动量\\(\\bm S\\)在外磁场中的取向。\n原子的电子壳层结构 泡利不相容原理 在一个原子中不能有两个或两个以上的电子处在完全相同的量子态。也就是说，任何两个电子都不可能具有一组完全相同的量子数\\((n,l,m_l,m_s)\\)。\n根据泡利不相容原理不难算出各壳层上最多可容纳的电子数为\n\\[Z_n = \\sum_{l=0}^{n-1}2(2l+1) = 2n^2 \\]\n在\\(n=1,2,3,4,\\cdots\\)的\\(K,L,M,N,\\cdots\\)各壳层上，最多可容纳\\(2,8,18,32,\\cdots\\)个电子。而在\\(l=0,1,2,3,\\cdots\\)的各支壳层上，最多可容纳\\(2,6,10,14,\\cdots\\)个电子。\n能量最小原理 原子处于正常状态时，每个电子都趋向占据可能的最低能级。\n固体物理 固体 固体是具有确定形状和体积的物体。\n通常分为两类：晶体和非晶体。\n晶体具有规则的几何形状，在晶体内，其构成微粒周期性重复排列，这种排列称为晶格，或空间点阵。\n规则排列、长程有序是晶体最基本的特征。\n此外，晶体具有确定的熔点，在宏观上各向异性。\n而非晶体没有确定的几何形状和熔点，宏观上各向同性，微观上原子无序排列。\n电子共有化 价电子不再为单个原子所有而为整个晶体所共有的现象，称为电子的共有化。\n两个氢原子相距较远时，电子的势能曲线如同势阱。\n两个氢原子靠近时，势能曲线会出现一个势垒。由于隧道效应，电子可穿透势垒，在两原子之间运动，被两个原子所共有。\n当大量同类原子在晶体内作规则排列时，将形成周期性势场\n能带和能带中电子的分布 理论结果表明，当\\(N\\)个相同原子组成晶体时，由于电子在周期性势场中运动，晶体里每个原子的每一能级都分裂为\\(N\\)个能级。分裂后新能级间的间距及位置取决于点阵间距\\(r\\).\n组成晶体的原子数\\(N\\)越多，分裂后的能级数也越多，能级越密集，一个能级分裂后者密集的能量范围\\(\\Delta E\\)叫做能带。\n能级分裂程度的大小不仅与原子间距离有关，还与能级的级数有关。原子间距离越小，能级分裂的程度越大。晶体点阵间距越小，能带越宽，越大。外层电子共有化显著，能带越宽。\n价电子能量高，势垒宽度小，其穿透势垒概率大，可在整个晶体内运动，被整个晶体所共有，能级分裂程度较高。\n内层电子能量低，势垒宽度大，其穿透势垒概率小，被束缚在母原子核周围运动，共有化程度低，能级分裂程度低。\n由于原子数巨大，分裂后各能级的间距非常小，可以认为能带中电子的能量是连续变化的。\n由于能带是由原子能级分裂而形成的，因此可以沿用原子能级的符号\\(s,p,d,\\cdots\\)来表示能带。\n能带中的电子填充方式同样服从泡利不相容原理以及能量最小原理。\n能带的分类\n两个相邻的能带之间，可能有一个能量间隔，在这个能量间隔中，不存在电子的稳定能态，这个能量间隔称为禁带。\n如果一个能带中的各能级都被电子填满，这样的能带称为满带。\n由价电子能级分裂而形成的能带称为价带。\n与各原子的激发能级相应的能带，在未被激发的正常情况下没有电子填入，称为空带。\n未被电子填满的能带也称为导带。空带也是导带。\n能带的性质决定物质导电特性\n满带中的电子不参与导电过程，不具备导电特性。因为满带中的电子都处于束缚态，只能在母原子核周围运动，不能在晶体内自由运动。\n绝缘体、导体、半导体 绝缘体的能带结构\n有些晶体，它的价带都被价电子所填满，形成满带。此满带与它上面最近空带（即激发能带）间的禁带宽度\\(\\Delta E_g\\)较大（通常为几个电子伏特）。一般的热激发、光照、外电场作用不强时，满带中的电子只有极个别能被激发到空带中，没什么导电作用。\n半导体的能带结构\n导电性介于导体与绝缘体之间的一大类物质称为半导体。\n半导体的能带结构和绝缘体的能带结构很相似，只是禁带宽度比绝缘体小得多。\n导体的能带结构\n各种金属都是导体，它们的能带结构大致有三种形式。\n价带中只填入部分电子，称为导带 价带填满并与空带重叠，没有禁带 价带未满并且也和空带重叠 本征半导体 本征半导体是没有杂质和缺陷的理想半导体。参与导电的电子和空穴称为本征载流子。其中满带中是空穴导电，空带中是电子导电，整体是它们的混合导电。\n本征半导体的导电率很低，一般没有多少使用价值。\n半导体中载流子的数目对光和热极其敏感，这称为半导体的光敏性和热敏性。\n杂质半导体 在纯净的半导体晶体中掺入微量其他元素的原子，将会显著地改变半导体的导电性能。\n由于是不同的原子，杂质原子不参与晶体中的电子共有化。杂质原子的能级处于禁带之中，所以会对导电性能产生重要影响。\nn型半导体\n在通常所用的本征半导体四价元素硅（或锗）的晶体中，用扩散等方法掺入少量的五价元素如砷（或磷）等杂质，就形成n型半导体。\n五价原子在晶体中替代四价原子的位置，构成与硅相同的四电子结构，而多出的一个价电子在杂质离子的电场范围内运动。\n处在杂质能级上的杂质价电子在受到激发时，很容易跃迁到导带上去，所以这种杂质能级又称为施主能级。\np型半导体\n在四价元素中掺入少量三价元素，如硼或镓，替代原来四价原子的位置，构成四电子结构时，缺少一个电子，形成了空穴。空穴也在禁带中。\n在温度不很高的情况下，满带中的电子很容易被激发而跃迁到杂质能级上去，同时在满带汇总形成空穴。由于这样的杂质能级接受从满带跃迁来的电子，所以又称为受主能级。\n激光 定义\n极光是基于受激辐射放大原理产生的一种相干光辐射。\n粒子从能级\\(E_2\\)跃迁到能级\\(E_1(E_2\u003eE_1)\\)（辐射过程）和从\\(E_1\\)跃迁到\\(E_2\\)（吸收过程），都应满足频率条件\n\\[\\nu = \\dfrac{|E_2-E_1|}{h} \\]\n自发辐射、受激辐射、受激吸收 自发辐射\n处于高能级的粒子，在没有外界影响的情况下，有一定概率自发地向低能级跃迁，并发出一个光子，这种过程称为自发辐射。\n自发辐射的特点是发生辐射的各粒子互不相关，自发辐射的光波是非相干的。\n单位时间内自发辐射的粒子数只与高能级上的粒子数\\(N_2\\)成正比，可写成\n\\[\\bigg(\\dfrac{dN_{21}}{dt}\\bigg)_{自发}=A_{21}N_2 \\]\n\\(A_{21}\\)称为自发辐射系数，对给定粒子的两个确定能级，\\(A_{21}\\)为常数。\n粒子在某激发态停留时间的平均值称为该激发态的平均寿命，用\\(\\tau\\)表示。一般\\(\\tau\\)为\\(10^{-8}s\\)数量级。也有一些激发能级可达\\(10^{-3}s\\)或更长，这样的激发态称为亚稳态。亚稳态在形成激光的过程中有着重要的意义。\n受激辐射\n处于高能级\\(E_2\\)的粒子，在频率为\\(\\nu=(E_2-E_1)/h\\)、光强为\\(I\\)的入射光照射激励下，跃迁到低能级\\(E_1\\)上去，同时发射一个与入射光子完全相同的光子，这种过程称为受激辐射。\n与自发辐射不同，受激辐射发出的是相干光。\n显然，单位时间内发生受激辐射的粒子数，与高能级\\(E_2\\)上的粒子数\\(N_2\\)及入射单色光的光强\\(I\\)成正比，可写成\n\\[\\bigg(\\dfrac{dN_{21}}{dt}\\bigg)_{受激}=kN_2IB \\]\n式中\\(k\\)为比例系数，\\(B\\)称为受激辐射系数。对给定粒子的两个确定能级，\\(B\\)是常数。\n受激吸收\n处于低能级\\(E_1\\)的粒子，在频率为\\(\\nu = (E_2-E_1)/h\\)，光强为\\(I\\)的入射光照射下，吸收一个光子而跃迁到高能级\\(E_2\\)，这种过程称为受激吸收。\n单位时间内发生受激吸收的粒子数，应与低能级\\(E_1\\)上的粒子数\\(N_1\\)及入射单色光的光强\\(I\\)成正比，可写成\n\\[\\bigg(\\dfrac{dN_{12}}{dt}\\bigg)_{吸收} = kN_1IB' \\]\n式中\\(k\\)为比例系数，\\(B'\\)称为受激吸收系数。当\\(E_2\\)和\\(E_1\\)两能级的简并度相同（相同温度和光照条件）时，受激辐射系数与受激吸收系数相等，即\\(B=B'\\)。\n\\(B=B'\\)时，受激吸收、受激辐射的强弱由\\(N_1,N_2\\)决定。\n若\\(N_1\u003eN_2\\)，则受激吸收\\(\u003e\\)受激辐射，只能使光强减弱。 若\\(N_2\u003eN_1\\)，则受激辐射\\(\u003e\\)受激吸收，可形成受激辐射光放大。 粒子数翻转和光放大 1. 粒子数正常分布\n温度为\\(T\\)的热平衡状态下，粒子数按能级的分布规律遵从玻尔兹曼分布律，即处于能级\\(E_i\\)的原子数\\(N_i\\)满足如下关系\n\\[N_i\\propto \\exp\\bigg(-\\dfrac{E_i}{kT}\\bigg) \\]\n所以有\n\\[\\dfrac{N_2}{N_1} = \\exp\\bigg(-\\dfrac{E_2-E_1}{kT}\\bigg)\u003c1 \\]\n热平衡状态下，低能级原子数\\(N_1\u003e\\)高能级原子数\\(N_2\\)\n当原子在热平衡状态正常分布时，受激吸收\\(\u003e\\)受激辐射，即\\(\\Delta I\u003c0\\)，不可能产生激光。\n2. 粒子数反转分布\n产生激光的必要条件：高能级原子数\\(N_2\u003e\\)低能级原子数\\(N_1,\\Delta I\u003e0\\)\n如何实现粒子数反转分布？\n激活物质（工作物质）——必须存在寿命较长的亚稳态能级 能量输入系统——使物质中有尽可能多的粒子吸收能量后跃迁到高能态。该能量输入过程称为激励或泵浦。激励的方式有：光激励、气体放电激励、化学激励等。 根据运行过程中所涉及的能级数，激活介质可分为三能级系统和四能级系统。\n三能级的缺点：因基态总是有大量的原子，因此实现粒子数反转需要有非常强的光泵浦（光抽运能力）\n激光器的基本构成 基本构成 工作物质（激活介质） 激励能源 光学谐振腔 激光的形成：光束在谐振腔内来回震荡，在激活介质中的传播，通过占主导的受激辐射使光得以放大，并输出激光。 光学谐振腔的作用 产生和维持振荡 提高光强 选择光束的传播方向 选择光振荡的频率 激光的特性和作用 激光的主要特性 方向性好 单色性好，氪灯单色性最好 能量集中亮度高 高相干性 激光的应用 方向性好：可用于定位、准直、定向、测距、导航等领域 相干性好：可广泛用于光学干涉测量和全息摄影、全息防伪等领域 能量集中度高：已被广泛应用于打孔、切割、焊接等精密机械加工；在医学上用于激光外科手术；在军事上用于作激光武器等 ","date":"2022-06-13T19:13:12+08:00","image":"https://kegalas.top/p/%E5%A4%A7%E5%AD%A6%E7%89%A9%E7%90%86%E5%85%AC%E5%BC%8F%E6%95%B4%E7%90%86/cover_huc6be90ba175cec12cafc892e1709e648_57796_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E5%A4%A7%E5%AD%A6%E7%89%A9%E7%90%86%E5%85%AC%E5%BC%8F%E6%95%B4%E7%90%86/","title":"大学物理公式整理"},{"content":"命题逻辑 联结词 否定联结词 \\(P\\) \\(\\neg P\\) 0 1 1 0 合取联结词 \\(P\\) \\(Q\\) \\(P\\wedge V\\) 0 0 0 0 1 0 1 0 0 1 1 1 析取联结词 \\(P\\) \\(Q\\) \\(P\\vee V\\) 0 0 0 0 1 1 1 0 1 1 1 1 条件联结词 \\(P\\) \\(Q\\) \\(P\\to V\\) 0 0 1 0 1 1 1 0 0 1 1 1 双条件联结词 \\(P\\) \\(Q\\) \\(P\\leftrightarrow V\\) 0 0 1 0 1 0 1 0 0 1 1 1 联结词的运算优先级 从高到低依次为，否定、合取、析取、条件、双条件\n命题公式 一些定义 定义1，命题变元与常元\n用于代表取值为真\\((T、1)\\)或假\\((F、0)\\)之一的变量，称为命题变元，通常用大写字母或带下标或上标的大写字母表示，如\\(P、Q、R、P_1、P_2\\)等。将\\(T\\)和\\(F\\)称为命题常元。\n通常把由命题常元、命题变元、联结词以及括弧组成的式子称为表达式,但是只有按照特定组合规则所形成的表达式才有实际意义。\n定义2，命题公式\n命题合式公式(简称命题公式):\n(1)(基础)单个命题常元或命题变元是命题合式公式\n(2)(归纳)如果A和B是命题公式,则\\(\\neg A\\)、\\((A\\wedge B)\\)、\\((A\\vee B)\\)、\\((A\\to B)\\)、\\((A\\leftrightarrow B)\\)是命题合式公式。\n(3)(极小性)只有有限次地应用条款(1)和(2)生成的表达式オ是命题合式公式\n定义3，子公式\n若\\(B\\)是命题公式\\(A\\)的一个连续段且\\(B\\)也是命题公式,则称\\(B\\)是\\(A\\)的个子公式。\n命题公式的赋值 对于有\\(n\\)个变元的公式，有\\(2^n\\)种不同赋值。\n永真式（重言式）\n一个命题公式在任何赋值下，其真值都为\\(T\\)，则称这个公式为永真式（重言式）\n永假式（矛盾式）\n一个命题公式在任何赋值下，其真值都为\\(F\\)，则称这个公式为永假式（矛盾式）\n偶然式\n既不是永真式也不是永假式，则为偶然式\n可满足式\n一个命题公式至少有一个赋值，使其真值为\\(T\\)，则称这个公式为可满足式。也即永真式和偶然式都是可满足式。不是可满足式的称为矛盾式。\n逻辑等价与蕴含 等价 定义\n给定两个命题公式\\(A\\)和\\(B4\\),设\\(P_1,P_2,\\cdots,P_n\\)为所有出现在A和B中的命题变元，但\\(P_i\\)不一定在\\(A\\)和\\(B\\)中同时出现，若对于\\(P_1,P_2,\\cdots,P_n\\)的任一赋值,\\(A\\)和\\(B\\)的真值都相同，则称\\(A\\)和\\(B\\)逻辑等价，记做\\(A\\Leftrightarrow B\\),读做“\\(A\\)等价于\\(B\\)”。\n下面列出常见的命题等价公式\n1.3.3-1\r1.3.3-2\r几个定理\n定理1（代入规则）\n设\\(A\\)、\\(B\\)是命题公式，其中\\(A\\)是重言式，\\(P\\)是\\(A\\)中的命题变元，如果将\\(A\\)中每一处出现的P均用B代入，则所得命题公式\\(A\\)仍然是一个重言式\n定理2\n设\\(A\\)、\\(B\\)是命题公式，则\\(A\\)和\\(B\\)逻辑等价,当且仅当\\(A\\leftrightarrow B\\)是一个重言式。\n定理3（替换规则）\n设\\(A\\)、\\(X\\)、\\(Y\\)是命题公式，\\(X\\)是\\(A\\)的子公式,且有\\(X\\Leftrightarrow Y\\)。如果将\\(A\\)中的\\(X\\)用\\(Y\\)来替换(不必每一处都替换)，则所得到的公式\\(B\\)与\\(A\\)等价,即\\(B\\Leftrightarrow A\\)。\n定理4（传递规则）\n设\\(A\\)、\\(B\\)、\\(C\\)是命题公式，若\\(A\\Leftrightarrow B\\)且\\(B\\Leftrightarrow C\\),则有\\(A\\Leftrightarrow C\\)。\n蕴含 设\\(A\\)、\\(B\\)是命题公式，如果\\(A\\to B\\)是一个重言式,则称\\(A\\)蕴含\\(B\\),记做\\(A\\Rightarrow B\\)。\n一些常见的蕴含公式\n1.3.7-1\r1.3.7-2\r证明蕴含式\\(A\\Rightarrow B\\)的一些方法：\n肯定前件法。假设\\(A\\)为\\(T\\)，如果能够推出\\(B\\)为\\(T\\)，则有\\(A\\Rightarrow B\\) 否定后件法。假设\\(B\\)为\\(F\\)，如果能够推出\\(A\\)为\\(F\\)，则有\\(A\\Rightarrow B\\) 几个定理\n定理1\n设\\(A\\)和\\(B\\)是任意两个命题公式，\\(A\\Leftrightarrow B\\)当且仅当\\(A\\Rightarrow B\\)且\\(B\\Rightarrow A\\).\n几个性质\n性质1\n设\\(A\\)、\\(B\\)是命题公式，如果\\(A\\Rightarrow B\\)且\\(A\\)是重言式，则\\(B\\)也是重言式\n性质2\n蕴含关系是传递的，即\\(A\\Rightarrow B\\)且\\(B\\Rightarrow C\\)，则\\(A\\Rightarrow C\\).\n性质3\n如果\\(A\\Rightarrow B\\)且\\(A\\Rightarrow C\\)，则\\(A\\Rightarrow B\\wedge C\\)\n性质4\n如果\\(A\\Rightarrow C\\)且\\(B\\Rightarrow C\\)，则\\(A\\vee B\\Rightarrow C\\)\n对偶式 定义\n设有命题公式\\(A\\)，其中仅含有联结词\\(\\neg,\\vee,\\wedge\\)，如果将\\(A\\)中的\\(\\vee\\)替换为\\(\\wedge\\)，\\(\\wedge\\)替换为\\(\\vee\\)，常元\\(T,F\\)也互相替换，所得到的公式记为\\(A^*\\)，则称\\(A^*\\)为\\(A\\)的对偶式。\n显然有，\\(A\\)也是\\(A^*\\)的对偶式，并且\\((A^*)^*=A\\)\n几个定理\n定理1\n设\\(A\\)和\\(A^*\\)是对偶公式，其中仅含有联结词\\(\\neg,\\vee,\\wedge\\)；\\(P_1,P_2,\\cdots,P_n\\)是出现在\\(A\\)和\\(A^*\\)中的所有命题变元，于是有\n\\[\\neg A(P_1,P_2,\\cdots,P_n)\\Leftrightarrow A^*(\\neg P_1,\\neg P_2,\\cdots,\\neg P_n) \\]\n\\[A(\\neg P_1,\\neg P_2,\\cdots,\\neg P_n)\\Leftrightarrow\\neg A^*(P_1,P_2,\\cdots,P_n) \\]\n定理2\n设\\(A,B\\)是命题公式，则有\n如果\\(A\\Leftrightarrow B\\)，则\\(A^*\\Leftrightarrow B^*\\) 如果\\(A\\Rightarrow B\\)，则\\(B^*\\Rightarrow A^*\\) 范式 析取范式和合取范式 析取式\n仅由若干命题变元和若干命题变元之否定通过联结词\\(\\vee\\)构成的命题公式。\n合取式\n仅由若干命题变元和若干命题变元之否定通过联结词\\(\\wedge\\)构成的命题公式。\n析取范式\n一个命题公式被称为析取范式，当且仅当它具有如下形式\n\\[A_1\\vee A_2\\vee\\cdots\\vee A_n \\]\n其中\\(A_1,A_2,\\cdots,A_n\\)是合取式。\n合取范式\n一个命题公式被称为合取范式，当且仅当它具有如下形式\n\\[A_1\\wedge A_2\\wedge\\cdots\\wedge A_n \\]\n其中\\(A_1,A_2,\\cdots,A_n\\)是析取式。\n主析取范式 极小项\n一个含\\(n\\)个命题变元的合取式，如果其中每个变元和其否定不同时存在，但两者之一必须出现且仅出现一次，则称该合取式为极小项。\n\\(n\\)个命题变元\\(P_1,P_2,\\cdots,P_n\\)可构成\\(2^n\\)个不同的极小项，其形式为：\n\\[\\tilde{P_1}\\wedge \\tilde{P_2}\\wedge\\cdots\\wedge \\tilde{P_n} \\]\n其中\\(\\tilde{P_i}\\)或者是\\(P_i\\)，或者是\\(\\neg P_i\\)\n可以用\\(n\\)位二进制编码表示极小项，例如\n\\[m_{010}=\\neg P_1\\wedge P_2\\wedge\\neg P_3 \\]\n有如下三个性质：\n每一个极小项当其编码与赋值相同时，其真值为\\(T\\)，在其余\\(2^n-1\\)种赋值下其真值均为\\(F\\). 任意两个不同的极小项的合取式永假。 所有极小项的析取式永真。 主析取范式\n设\\(P_1,P_2,\\cdots,P_n\\)是命题公式\\(A\\)中包含的所有命题变元，若由\\(P_1,P_2,\\cdots,P_n\\)的若干极小项析取所构成的析取范式与\\(A\\)等价，则称该析取范式是\\(A\\)的主析取范式。\n有如下定理\n定理1\n在一个命题公式\\(A\\)的真值表中，使\\(A\\)的真值为\\(T\\)的所有赋值所对应的极小项构成的析取范式即为\\(A\\)的主析取范式。\n主合取范式 极大项\n一个含\\(n\\)个命题变元的析取式，如果其中每个变元和其否定不同时存在，但两者之一必须出现且仅出现一次，则称改合取式为极大项。\n\\(n\\)个命题变元\\(P_1,P_2,\\cdots,P_n\\)可构成\\(2^n\\)个不同的极小项，其形式为：\n\\[\\tilde{P_1}\\vee \\tilde{P_2}\\vee\\cdots\\vee \\tilde{P_n} \\]\n其中\\(\\tilde{P_i}\\)或者是\\(P_i\\)，或者是\\(\\neg P_i\\)\n可以用\\(n\\)位二进制编码表示极大项，例如\n\\[M_{101}=\\neg P_1\\vee P_2\\vee\\neg P_3 \\]\n（编码注意与极小项意义相反）\n有如下三个性质：\n每一个极大项当其真值赋值与编码相同时，其真值为\\(F\\)，在其余\\(2^n-1\\)种赋值下其真值均为\\(T\\). 任意两个不同的极大项的析取式永真。 所有极大项的合取式永假。 主合取范式\n设\\(P_1,P_2,\\cdots,P_n\\)是命题公式\\(A\\)中包含的所有命题变元，若由\\(P_1,P_2,\\cdots,P_n\\)的若干极大项合取所构成的合取范式与\\(A\\)等价，则称该合取范式是\\(A\\)的主合取范式。\n有如下定理\n定理1\n在一个命题公式\\(A\\)的真值表中，使\\(A\\)的真值为\\(F\\)的所有赋值所对应的极大项构成的合取范式即为\\(A\\)的主合取范式。\n定理\n设\\(A\\)的主析取范式的各个极小项的下标转为十进制，组成的集合为\\(S_1\\{i_1,i_2,\\cdots,i_k\\}\\)；主合取范式的各个极大项的下标转为十进制，组成的集合为\\(S_2=\\{j_1,j_2,\\cdots,j_t\\}\\)，则有\n\\[S_1\\cap S_2=\\phi \\]\n\\[S_1\\cup S_2=\\{0,1,2,\\cdots,2^n-1\\} \\]\n范式的计算 除了可以用真值表来算，还可以通过德摩根定律等将“\\(\\to\\)”等不是析取、合取、否定的联结词转化，直到只剩析取、合取、否定。再通过添加、删除括号转化为主合取范式或主析取范式。\n命题逻辑的推理理论 推理规则 P规则：在推导过程中，前提可以在任何步骤引入。 T规则：在推导过程中，如果由已经推出的一个或多个公式蕴含\\(S\\)，则公式\\(S\\)可以引入到推导过程中。 证明方法 无义证明法。如果能证明\\(P\\)恒为假，则有\\(P\\to Q\\)恒为真，即\\(P\\Rightarrow Q\\) 平凡证明法。如果能证明\\(Q\\)恒为真，则有\\(P\\to Q\\)恒为真，即\\(P\\Rightarrow Q\\) 直接证明法。从一组前提出发，利用公认的推理规则，逻辑演绎得到有效结论。 归谬法（即反证法）。 定理\n\\(H_1,H_2,\\cdots,H_m,C\\)是公式，如果存在公式\\(R\\)，使得\\(H_1,H_2,\\cdots,H_m,\\neg C\\Rightarrow R\\wedge\\neg R\\)，则有\\(H_1,H_2,\\cdots,H_m\\Rightarrow C\\)\nCP规则法。 \\(H_1,H_2,\\cdots,H_n,R,C\\)是命题公式，根据输出律\\(E_{22}\\)推知\n\\[(H_1\\wedge H_2\\wedge\\cdots\\wedge H_n)\\to(R\\to C)\\Leftrightarrow(H_1\\wedge H_2\\wedge\\cdots\\wedge H_n\\wedge R)\\to C \\]\n因此，如果能够证明\\(H_1,H_2,\\cdots,H_n,R\\Rightarrow C\\)，则有\\(H_1,H_2,\\cdots,H_n\\Rightarrow R\\to C\\)\n谓词逻辑 谓词和量词 谓词 刻画单个个体的特性或者多个个体间关系的模式称为谓词。\n量词 全称量词\\(\\forall\\) 存在量词\\(\\exist\\) 几个规则\n应当使用\\(\\forall x(H(x)\\to D(x))\\)，而不能表示为\\(\\forall x(H(x)\\wedge D(x))\\)。\n应当使用\\(\\exist x(H(x)\\wedge D(x))\\)，而不能表示为\\(\\exist x(H(x)\\to D(x))\\)。\n谓词公式 定义\n谓词逻辑的合式公式（简称谓词公式）可由以下步骤生成\n原子公式（不出现联结词和量词的单个谓词）是谓词公式。 如果\\(A\\)和\\(B\\)是谓词公式，则\\(\\neg A,(A\\wedge B),(A\\vee B),(A\\to B),(A\\leftrightarrow B)\\)是谓词公式 如果\\(A\\)是谓词公式，并且\\(A\\)中有未被量化的个体变元\\(x\\)，则\\(\\forall xA(x)\\)和\\(\\exist xA(x)\\)是谓词公式。 只有有限次应用步骤1、2、3所得到的的公式才是谓词公式。 子公式\n若\\(B\\)是谓词公式\\(A\\)的一个连续段且\\(B\\)也是谓词公式，则称\\(B\\)是\\(A\\)的一个子公式。\n辖域\n紧跟\\(\\forall x\\)和\\(\\exist x\\)之后的最小的子公式称为该量词的辖域。\n约束变元\n在\\(\\forall x\\)和\\(\\exist x\\)辖域内\\(x\\)的一切出现称之为约束出现，这个\\(x\\)叫做约束变元。\n自由变元\n个体变元的非约束出现称为自由出现，自由出现的个体变元称为自由变元。\n约束变元的换名规则\n对某个约束变元换名时，需对量词的作用变元以及该量词辖域内所有受该量词约束的约束变元一起换名。 换名后的变元符号应是量词辖域内未出现的符号，最好是整个公式中未出现的符号。 谓词验算的永真公式 谓词公式的赋值 定义1\n对于一个谓词公式，若给它指定一个个体域\\(E\\)，再给所有谓词符均指派出确定的关系(具体的特性或关系)，给所有命题变元指派出确定命题(或者指定\\(T\\)或\\(F\\))，并为所有自由变元（注意不包含约束变元）分别指派\\(E\\)上确定的个体，则称为对谓词公式的一个赋值(指派或结识)。谓词公式经过赋值之后就变成了具有确定真值的命题。\n定义2\n设\\(A\\)是谓词公式，如果对于特定论域\\(E\\)上的任何赋值，\\(A\\)的真值都为真，则称谓词公式\\(A\\)在\\(E\\)上永真;如果对于特定论域\\(E\\)上的任何赋值，\\(A\\)的真值都为假，则称谓词公式\\(A\\)在\\(E\\)上永假;若特定论域\\(E\\)上存在一种赋值，使得\\(A\\)的真值都为真，则称谓词公式\\(A\\)在\\(E\\)上可满足。\n定义3\n设\\(A\\)是谓词公式，如果对于任何赋值，\\(A\\)的真值都为真，则称谓词公式\\(A\\)是永真式;如果对于任何赋值，\\(A\\)的真值都为假，则称谓词公式\\(A\\)是永假式;若存在一种赋值，使得\\(A\\)的真值为真，则称谓词公式\\(A\\)是可满足式。\n谓词演算的基本永真式 命题逻辑的等价式和蕴含式可在谓词逻辑中推广使用 量词的否定律 \\[\\neg\\forall xP(x)\\Leftrightarrow \\exist x\\neg P(x) \\]\n\\[\\neg\\exist xP(x)\\Leftrightarrow \\forall x\\neg P(x) \\]\n量词辖域的扩张与收缩律 2.3.2.3\r量词的分配律 2.3.2.4-1\r2.3.2.4-2\r多重量词律 2.3.2.5-1\r2.3.2.5-2\r其他 \\(\\forall xP(x)\\Rightarrow P(y)\\)，\\(y\\)是论域中的任一确定个体。\n\\(P(y)\\Rightarrow\\exist xP(x)\\)，\\(y\\)是论域中的某个确定个体。\n\\(\\forall xP(x)\\Rightarrow\\exist xP(x)\\)\n谓词逻辑的推理理论 存在指定原则（ES） \\[\\frac{\\exist xP(x)}{\\therefore P(a)} \\]\n\\(a\\)是个体常元，注意所指定的个体常元要使得谓词为真。\n全称指定原则（US） \\[\\frac{\\forall xP(x)}{\\therefore P(y)} \\]\n\\(y\\)是自由变元，也可以指定到个体常元\\(a\\)\n\\[\\frac{\\forall xP(x)}{\\therefore P(a)} \\]\n注意如果同时指定\\(\\exist xP(x)\\)和\\(\\forall xQ(x)\\)，应当先指定\\(P(a)\\)，再指定\\(Q(a)\\)，才能保证两者都为真。\n存在推广原则（EG） \\[\\frac{P(a)}{\\therefore\\exist xP(x) } \\]\n全称推广原则（UG） \\[\\frac{\\Gamma\\Rightarrow P(x)}{\\therefore\\Gamma\\Rightarrow\\forall xP(x)} \\]\n\\(\\Gamma\\)是已知公理和前提的合取，\\(\\Gamma\\)中没有自由变元\\(x\\)的出现。\n集合 集合的表示方法 列举法 描述法：用自然语言或谓词描述集合中元素的共同特征。 归纳定义法（见后） 集合间的关系 外延性公理\n两个集合\\(A,B\\)相等，记为\\(A=B\\)，当且仅当它们有相同的元素，即\n\\[A=B\\Leftrightarrow \\forall x(x\\in A\\leftrightarrow x\\in B) \\]\n两个集合不相等，通常记为\\(A\\neq B\\)\n子集\n设\\(A、B\\)是任意的两个集合，若集合\\(A\\)的每个元素都是集合\\(B\\)的元素，则称\\(A\\)为\\(B\\)的子集或称\\(B\\)包含\\(A\\),记为\\(A\\subseteq B\\)或\\(B\\supseteq A\\)，用逻辑公式表示为\n\\[A\\subseteq B\\Leftrightarrow\\forall x(x\\in A\\to x\\in B) \\]\n如果\\(A\\)不是\\(B\\)的子集，通常记为\\(A\\nsubseteq B\\)\n真子集\n如果集合\\(A\\)的每一个元素都属于\\(B\\)，但集合\\(B\\)中至少有一个元素不属于\\(A\\)，则称\\(A\\)为\\(B\\)的真子集，记为\\(A\\subset B\\)，用逻辑公式表示为\n\\[A\\subset B\\Leftrightarrow\\forall x(x\\in A\\to x\\in B)\\wedge \\exist y(y\\in B\\wedge y\\notin A)\\Leftrightarrow(A\\subseteq B)\\wedge(A\\neq B) \\]\n全集\n在一定范围内所有事物组成的集合称为该范围内的全集记为\\(U\\)，用逻辑公式表示为\n\\[U = \\{x|P(x)\\vee\\neg P(x)\\} \\]\n其中，\\(P(x)\\)是任意的谓词\n空集\n不含任何元素的集合称为空集，记为\\(\\phi\\)，用逻辑公式表示为\n\\[\\phi = \\{x|P(x)\\wedge\\neg P(x)\\} \\]\n其中，\\(P(x)\\)是任意的谓词，并且显然有\\(|\\phi|=0\\)\n几个定理\n定理1\n空集是任一集合的子集，并且是任何非空集合的真子集。\n定理2\n设\\(A,B,C\\)是集合，若\\(A\\subseteq B\\)且\\(B\\subseteq C\\)，则\\(A\\subseteq C\\)。\n定理3\n集合\\(A,B\\)相等的充要条件是\\(A,B\\)互为子集。\n定理3.1\n对于任何集合\\(A\\)，有\\(A\\subseteq A\\)\n定理4\n空集是唯一的。\n集合的运算 集合的交，交集\n\\[A\\cap B = \\{x|x\\in A\\wedge x\\in B\\} \\]\n集合的并，并集\n\\[A\\cup B = \\{x|x\\in A\\vee x\\in B\\} \\]\n集合的差，相对补集\n\\[A-B=\\{x|x\\in A\\wedge x\\notin B\\} \\]\n集合的补，绝对补集\n\\[\\bar{A}=U-A=\\{x|x\\in U\\wedge x\\notin A\\} \\]\n集合的对称差\n\\[A\\oplus B=(A-B)\\cup(B-A)=\\{x|(x\\in A\\wedge x\\notin B)\\vee(x\\in B\\wedge x\\notin A)\\} \\]\n集合的环积\n\\[A\\otimes B=\\overline{A\\oplus B}=(A\\cap B)\\cup(\\bar{A}\\cap\\bar{B})=\\{x|(x\\in A\\wedge x\\in B)\\vee(x\\notin A\\wedge x\\notin B)\\} \\]\n满足如下运算律\n3.2.1\r幂集\n给定集合\\(A\\)，由\\(A\\)所有子集为元素构成的集合，称为\\(A\\)的幂集，记作\\(\\rho(A)\\)。若\\(|A|=n\\)，则有\\(|\\rho(A)=2^n|\\)\n容斥原理 定理1\n设\\(A_1,A_2\\)是有限集合，其元素个数分别为\\(|A_1|,|A_2|\\)，则\\(|A_1\\cup A_2|=|A_1|+|A_2|-|A_1\\cap A_2|\\)\n容斥原理\n将上式推广，得\n\\[|A_1\\cup A_2\\cup\\cdots\\cup A_n|=\\sum_{i=1}^n|A_i|-\\sum_{1\\leq i \u003c j\\leq n}|A_i\\cap A_j|+\\\\ \\sum_{1\\leq i \u003c j \u003c k\\leq n}|A_i\\cap A_j\\cap A_k|-\\cdots+(-1)^{n+1}|A_1\\cap A_2\\cap\\cdots\\cap A_n| \\]\n归纳证明 集合的归纳定义 基础条款：指出某些事物属于\\(S\\)，其功能是给集合\\(S\\)指定初始元素使其不为空。 归纳条款：指出由集合\\(S\\)中的已有元素构造新元素的办法。 极小性条款：断言一个事物除非能有限次应用基础条款和归纳条款构成，否则它不在集合\\(S\\)中。 归纳法证明 基础步骤。对于基础条款中的指定的每个初始元素\\(t\\)，证明命题\\(P(t)\\)为真。 归纳步骤。证明如果事物\\(x,y,\\cdots\\)有\\(P\\)性质，那么用归纳条款指定的方法组合它们所得的新元素也具有性质\\(P\\) 数学归纳法 第一原理\n（归纳基础）证明\\(P(0)\\)为真（可以用任何办法） （归纳假设）任取\\(n(n\\ge0)\\)，假设\\(P(n)\\)为真。 （归纳推理）由\\(P(n)\\)为真，推出\\(P(n+1)\\)也为真。 第二原理\n（归纳基础）证明\\(P(0)\\)为真（可以用任何办法） （归纳假设）假设对任意的\\(n \u003c k\\)，均有\\(P(k)\\)为真。 （归纳推理）证明\\(P(n)\\)也为真。 集合的笛卡尔积 序偶\n两个元素\\(a\\)和\\(b\\)组成的具有固定次序的序列称为序偶或二元组，记为\\(\u003c a,b\u003e\\)。对于序偶\\(\u003c a,b\u003e\\)，\\(a\\)称为第\\(1\\)元素，\\(b\\)称为第\\(2\\)元素。\n序偶的相等\n两个序偶\\(\u003c a,b\u003e\\)和\\(\u003c c,d\u003e\\)相等，记为\\(\u003c a,b\u003e=\u003c c,d\u003e\\)，当且仅当\\(a=c\\)且\\(b=d\\)。\n笛卡尔积（叉积）\n\\[A\\times B=\\{\u003c a,b\u003e|a\\in A,b\\in B\\} \\]\n对于多个集合，有\n\\[A_1\\times A_2\\times\\cdots\\times A_n=\\{\u003c a_1,a_2, \\cdots,a_n\u003e|a_i\\in A_i,1\\leq i\\leq n\\} \\]\n其中\\(A\\times A\\times\\cdots\\times A\\)（\\(n\\)个）可以记作\\(A^n\\)\n规定\\(\u003c a_1,a_2, \\cdots,a_n\u003e=\u003c\u003c a_1,a_2, \\cdots,a_{n-1}\u003e,a_n\u003e\\)，而不等于\\(\u003c a_1,\u003c a_2, \\cdots,a_n\u003e\u003e\\)等等其他序偶。\n关于笛卡尔积有如下定理\n定理1\n\\(A\\times(B\\cup C)=(A\\times B)\\cup(A\\times C)\\) \\(A\\times(B\\cap C)=(A\\times B)\\cap(A\\times C)\\) \\((A\\cup B)\\times C=(A\\times C)\\cup(B\\times C)\\) \\((A\\cap B)\\times C=(A\\times C)\\cap(B\\times C)\\) 定理2\n如果\\(A_i(i=1,2,\\cdots,n)\\)都是有限集合，那么\n\\[|A_1\\times A_2\\times\\cdots\\times A_n|=|A_1|\\cdot|A_2|\\cdot\\cdots\\cdot|A_n| \\]\n二元关系 关系的定义 两个集合\\(A\\)和\\(B\\)的笛卡儿积\\(A\\times B\\)的任一子集\\(R\\),称为集合\\(A\\)到\\(B\\)上的二元关系。二元关系\\(R\\)是由序偶构成的集合，若\\(\u003c x,y\u003e\\in R\\)，则称\\(x\\)与\\(y\\)有\\(R\\)关系，也记为\\(xRy\\);否则,\\(\u003c x,y\u003e\\notin R\\)，称\\(x\\)与\\(y\\)没有\\(R\\)关系，也记为\\(x\\cancel{R}y\\)。\n设\\(R\\)是集合\\(A\\)到\\(B\\)的二元关系。集合\\(A\\)称为\\(R\\)的前域，集合\\(B\\)称为\\(R\\)的陪域。集合\\(\\{x|(\\exist y)(\u003c x,y\u003e\\in R)\\}\\)称为\\(R\\)的定义域，记为\\(domR\\)。集合\\(\\{y|(\\exist x)(\u003c x,y\u003e)\\in R)\\}\\)称为\\(R\\)的值域，记为\\(ranR\\)。显然, \\(domR\\subseteq A\\)和\\(ranR\\subseteq B\\)。\n关系的表示 关系矩阵 \\[r_{ij}= \\left\\{\\begin{matrix} 1, if\u003c a_i,b_j\u003e\\in R\\\\ 0, if\u003c a_i,b_j\u003e\\notin R \\end{matrix}\\right. \\]\n关系图 3.6.2\r关系的运算 所有集合的运算对于二元关系同样适用。\n复合运算\n设\\(R\\)为集合\\(A\\)到\\(B\\)的二元关系，\\(S\\)为\\(B\\)到\\(C\\)的二元关系，令\n\\[R\\circ S=\\{\u003c a,c\u003e|a\\in A\\wedge c\\in C\\wedge(\\exist b)(b\\in B\\wedge\u003c a,b\u003e\\in R\\wedge \u003c b,c\u003e\\in S)\\} \\]\n称\\(R\\circ S\\)为\\(R\\)与\\(S\\)的复合关系。\n复合运算可以通过关系的矩阵的运算来实现\n\\[\\bm{M}_{R\\circ S}=\\bm{M}_R\\odot\\bm{M}_S \\]\n其中\\(\\odot\\)是布尔乘法运算，\\(c_{ij}=\\bigvee_{k=1}^{n}(a_{ik}\\wedge b_{kj})\\)\n复合运算有如下定理\n定理1\n\\((R\\circ S)\\circ T=R\\circ(S\\circ T)\\)\n关系的逆，逆关系\n\\[R^{-1}=\\{\u003c b,a\u003e|\u003c a,b\u003e\\in R\\} \\]\n关系矩阵即为原矩阵的转置\n关系图即将箭头反向\n有如下定理\n定理1\n\\((R^{-1})^{-1}=R\\) \\((R_1\\cup R_2)^{-1}=R_1^{-1}\\cup R_2^{-1}\\) \\((R_1\\cap R_2)^{-1}=R_1^{-1}\\cap R_2^{-1}\\) \\((\\overline{R})^{-1}=\\overline{R^{-1}}\\)，其中\\(\\overline{R}=(A\\times B)-R\\)，\\(\\overline{R^{-1}}=(B\\times A)-R^{-1}\\)。 \\((R_1-R_2)^{-1}=R_1^{-1}-R_2^{-1}\\) 定理2\n\\[(R\\circ S)^{-1}=S^{-1}\\circ R^{-1} \\]\n集合上的二元关系及其特性 集合上的二元关系 集合\\(A\\)与\\(A\\)的笛卡尔积\\(A\\times A\\)的子集称为\\(A\\)上的二元关系。\n相等关系\n\\[I_A=\\{\u003c a,a\u003e|a\\in A\\} \\]\n\\(R\\)的幂次\n设\\(R\\)是\\(A\\)上的二元关系，\\(n\\in Z^+\\)，称\\(R\\circ R\\circ\\cdots\\circ R\\)(n个)为\\(R\\)的\\(n\\)次幂。记为\\(R^n\\)\n约定\\(R^0=I_A\\)\n有如下定理\n定理1\n\\(R^m\\circ R^n=R^{m+n}\\) \\((R^m)^n=R^{mn}\\) 定理2\n设存在\\(i,j\\in R\\)，使得\\(R^i=R^j\\)，则有\n对任意\\(k\\ge 0, R^{i+k}=R^{j+k}\\) 对任意\\(k,m\\ge 0, R^{i+md+k}=R^{i+k}\\)，其中\\(d=j-i\\) 记\\(S=\\{R_0,R^1,\\cdots,R^{j-1}\\}\\)，对于任意\\(n\\in N\\)，均有\\(R^n\\in S\\) 二元关系的特性 自反性。对于\\(A\\)中的每个元素\\(a\\)，都有\\(aRa\\)，则称\\(R\\)在\\(A\\)上是自反的。 反自反性。对于\\(A\\)中的每个元素\\(a\\)，都有\\(a\\cancel{R}a\\)。空集上的空关系即是自反的也是反自反的。 对称性。对于任意\\(a,b\\in A\\)，若有\\(aRb\\)，则必有\\(bRa\\)。 反对称性。对于任意\\(a,b\\in A\\)，若有\\(aRb\\)且\\(bRa\\)，则必有\\(a=b\\)。若关系图上只有零个或多个自回路，则既是对称的，又是反对称的。 传递性。对于任意\\(a,b,c\\in A\\)，若\\(aRb,bRc\\)则必有\\(aRc\\)。 关系的闭包运算 设\\(R\\)是集合\\(A\\)上的二元关系，如果\\(A\\)上另外一个二元关系\\(R'\\)满足：\n\\(R'\\)是自反的（对称的，传递的） \\(R'\\subseteq R\\) 对于\\(A\\)上任何自反的（对称的，传递的）关系\\(R''\\)，若\\(R''\\subseteq R\\)，有\\(R''\\subseteq R'\\)，则称\\(R'\\)是\\(R\\)的自反（对称，传递）闭包，记为\\(r(R)(s(R),t(R))\\)。 有如下定理\n定理1\n\\(R\\)是自反的当且仅当\\(r(R)=R\\) \\(R\\)是对称的当且仅当\\(s(R)=R\\) \\(R\\)是传递的当且仅当\\(t(R)=R\\) 定理2\n\\(r(R)=R\\cup I_A\\) \\(s(R)=R\\cup R^{-1}\\) \\(t(R)=\\bigcup_{i=1}^{\\infty}R^i\\) 定理3\n假设\\(|A|=n\\)，那么\\(t(R)=\\bigcup_{i=1}^{n}R^i\\)\n定理4\n如果\\(R\\)是自反的，那么\\(s(R),t(R)\\)也是自反的。 如果\\(R\\)是对称的，那么\\(r(R),t(R)\\)也是对称的。 如果\\(R\\)是传递的，那么\\(r(R)\\)也是传递的。 定理5\n\\(sr(R)=rs(R)\\)，（\\(sr(R)=s(r(R))\\)以下运算顺序相同）。 \\(tr(R)=rt(R)\\) \\(ts(R)\\subseteq st(R)\\) 等价关系 集合的划分 给定非空集合\\(A\\)和集合簇\\(\\pi=\\{A_1,A_2,\\cdots,A_m\\}\\)，如果\n\\(A_i\\subseteq A\\)且\\(A_i\\neq\\phi\\) \\(A=\\bigcup_{i=1}^{m}A_i\\) \\(A_i\\cap A_j=\\phi, i\\neq j\\) 那么称\\(\\pi\\)是\\(A\\)的一个划分，若\\(\\pi\\)满足1.2.则称\\(\\pi\\)是\\(A\\)的一个覆盖。\n等价关系和等价类 等价关系\n\\(R\\)是\\(A\\)上的二元关系，若\\(R\\)是自反的、对称的、传递的，则称\\(R\\)是等价关系。\n等价类\n设\\(R\\)是非空集合\\(A\\)上的等价关系，对于任意\\(a\\in A\\)，称集合\\([a]_R=\\{x|x\\in A,xRa\\}\\)为\\(a\\)关于\\(R\\)的等价类，\\(a\\)称为等价类\\([a]_R\\)的代表元素。如果等价类个数有限，则\\(R\\)的不同等价类的个数叫做\\(R\\)的秩，否则秩是无限的。\n有如下定理\n定理1\n设\\(R\\)是非空集合\\(A\\)上的等价关系，对于\\(a,b\\in A\\)有\\(aRb\\)，当且仅当\\([a]_R=[b]_R\\)\n商集\n设\\(R\\)是集合\\(A\\)上的等价关系，由\\(R\\)确定的所有等价类组成的集合，称为集合\\(A\\)上关于\\(R\\)的商集，记为\\(A/R\\)\n\\[A/R = \\{[x]_R|x\\in A\\} \\]\n有如下定理\n定理1\n任取\\(x\\in A\\)，\\([x]_R\\neq\\phi\\) 任取\\(x,y\\in A\\)，要么\\([x]_R=[y]_R\\)，要么\\([x]_R\\cap[y]_R=\\phi\\) \\(\\bigcup_{x\\in A}[x]_R=A\\) 定理2\n设\\(\\pi\\)是非空集合\\(A\\)的一个划分，则\\(A\\)上的二元关系\\(R=\\bigcup_{B\\in\\pi} B\\times B\\)是\\(A\\)上的等价关系（称为由划分\\(\\pi\\)诱导的\\(A\\)上的等价关系）。\n定理3\n设\\(R_1\\)和\\(R_2\\)是非空集合\\(A\\)上的等价关系，则\\(R_1=R_2\\Leftrightarrow A/R_1=A/R_2\\)\n定理4\n设\\(R\\)是非空集合\\(A\\)上的任意一个等价关系,\\(\\pi\\)是\\(A\\)的任意一个划分，那么\\(R\\)诱导出\\(\\pi\\)当且仅当\\(\\pi\\)诱导出\\(R\\)。即说明等价关系和集合的划分是一一对应的。\n序关系 偏序集合的概念与表示 偏序\n如果\\(A\\)上的关系\\(R\\)是自反的，反对称的和传递的，那么\\(R\\)是\\(A\\)上的偏序，通常用符号\\(\\preceq\\)表示，称序偶\\(\u003c A,\\preceq\u003e\\)为偏序集合。通常用\\(x\\prec y\\)表示\\(x\\preceq y\\)且\\(x\\neq y\\)\n可比与不可比\n在偏序集合\\(\u003c A,\\preceq\u003e\\)中，对于元素\\(a,b\\in A\\)，如果\\(a\\preceq b\\)或者\\(b\\preceq a\\)，那么称\\(a\\)或\\(b\\)是可比的，否则不可比的。\n盖住\n在偏序集合\\(\u003c A,\\preceq\u003e\\)中，对于\\(x,y\\in A\\)，如果\\(x\\prec y\\)且没有其他元素\\(z\\in A\\)满足\\(x\\prec z\\prec y\\)，则称\\(y\\)盖住\\(x\\)\n哈斯图\n3.10.1\r链\n设\\(\u003c A,\\preceq\u003e\\)是一个偏序集合，\\(B\\subseteq A\\)。如果\\(B\\)中的任意两个元素都是可比的，那么称\\(B\\)为\\(\u003c A，\\preceq\u003e\\)中的链，\\(B\\)中元素的个数称为该链的长度。如果\\(B\\)中的任意两个不同的元素都是不可比的，那么称\\(B\\)为\\(\u003c A，\\preceq\u003e\\)中的反链。\n偏序集合中的特殊元素 极大元\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。如果\\(b\\in B\\)，且\\(B\\)中不存在元素\\(x\\)，使得\\(x\\neq b\\)且\\(b\\preceq x\\)，那么\\(b\\)称为\\(B\\)的极大元。\n极小元\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。如果\\(b\\in B\\)，且\\(B\\)中不存在元素\\(x\\)，使得\\(x\\neq b\\)且\\(x\\preceq b\\)，那么\\(b\\)称为\\(B\\)的极小元。\n最大元\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。如果\\(b\\in B\\)，对于任意元素\\(x\\in B\\)，均有\\(x\\preceq b\\)，那么\\(b\\)称为\\(B\\)的最大元。\n最小元\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。如果\\(b\\in B\\)，对于任意元素\\(x\\in B\\)，均有\\(b\\preceq x\\)，那么\\(b\\)称为\\(B\\)的最小元。\n有如下定理\n定理1\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。如果\\(B\\)有最大（最小元），那么它是唯一的。\n上界\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。如果\\(a\\in A\\)，对于任意元素\\(b\\in B\\)，均有\\(b\\preceq a\\)，那么\\(a\\)称为\\(B\\)的上界。\n下界\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。如果\\(a\\in A\\)，对于任意元素\\(b\\in B\\)，均有\\(a\\preceq b\\)，那么\\(a\\)称为\\(B\\)的下界。\n最小上界（上确界）\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。\\(a\\)为\\(B\\)的上界，若对\\(B\\)的任意上界\\(a'\\)均有\\(a\\preceq a'\\)，则称\\(a\\)为\\(B\\)的最小上界或上确界。\n最大下界（下确界）\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。\\(a\\)为\\(B\\)的下界，若对\\(B\\)的任意下界\\(a'\\)均有\\(a'\\preceq a\\)，则称\\(a\\)为\\(B\\)的最大下界或下确界。\n有如下定理\n定理1\n若\\(B\\)有最小上界（最大下界），那么它是唯一的。\n定理2\n设\\(\u003c A, \\preceq\u003e\\)是偏序集合，且\\(B\\subseteq A\\)。\n若\\(b\\)是\\(B\\)的最大元，则\\(b\\)是\\(B\\)的极大元。 若\\(b\\)是\\(B\\)的最大元，则\\(b\\)是\\(B\\)的最小上界。 \\(b\\in B\\)，若\\(b\\)是\\(B\\)的上界，当且仅当\\(b\\)是\\(B\\)的最小上界。 若\\(b\\)是\\(B\\)的最小元，则\\(b\\)是\\(B\\)的极小元。 若\\(b\\)是\\(B\\)的最小元，则\\(b\\)是\\(B\\)的最大下界。 \\(b\\in B\\)，若\\(b\\)是\\(B\\)的下界，当且仅当\\(b\\)是\\(B\\)的最大下界。 定理3\n设\\(\u003c A,\\preceq\u003e\\)是非空有限偏序集，则\\(A\\)中必存在极大元和极小元。\n定理4\n设\\(\u003c A,\\preceq\u003e\\)是偏序集合，如果\\(A\\)中最长链的长度为\\(n\\)，则\\(A\\)中元素能划分为\\(n\\)个互不相交的反链。\n线序和良序 设\\(\u003c A, \\preceq\u003e\\)是偏序集合，如果任取\\(a,b\\in A\\)，都有\\(a\\preceq b\\)或者\\(b\\preceq a\\)，那么称\\(\\preceq\\)为\\(A\\)上的线序或全序。称\\(\u003c A. \\preceq\u003e\\)为线序集合，称\\(A\\)为链。\n如果\\(A\\)上的一个二元关系\\(R\\)是一个线序，且\\(A\\)的每一非空子集都有最小元，那么称\\(R\\)为\\(A\\)上的良序，称\\(\u003c A,R\u003e\\)为良序集合。\n有如下定理\n定理\n每一有限线序集合都是良序集合。\n函数与无限集合 函数的定义 注意对于每个\\(x\\in A\\)，都只和唯一一个\\(y\\in Y\\)有\\(f\\)关系。\\(y\\)是\\(x\\)的函数值或像，\\(x\\)是\\(y\\)的原像。\n定义域必须是整个前域，值域可以不是整个陪域。一般\\(X,Y\\)指的是前域和陪域。\n函数相等\n\\(f:A\\to B\\), \\(g:C\\to D\\)，如果\\(A=C,B=D\\)，且对于所有的\\(x\\in A\\)有\\(f(x)=g(x)\\)，则称\\(f,g\\)相等，记作\\(f=g\\)\n多元函数\n前域是\\(n\\)个集合的笛卡尔积，称为\\(n\\)元函数，像记作\\(f(x_1,x_2,\\cdots,x_n)\\)\n递归定义的函数 前域是归纳定义的集合时，可以采用递归定义方法来定义函数。规则是：用已经得到的元素函数值和给定的函数来计算新元素的函数值。\n特殊函数 单射\n任取\\(x_1,x_2\\in X\\)，如果\\(x_1\\neq x_2\\)，那么\\(f(x_1)\\neq f(x_2)\\)，则称\\(f\\)为单射函数，也称一对一函数。\n满射\n若任取\\(y\\in Y\\)，存在\\(x\\in X\\)，使得\\(f(x)=y\\)，则称为满射函数。\n双射\n既是单射又是满射，称为双射函数。也称一一对应函数。\n有如下定理\n定理1\n设\\(X,Y\\)是有限集合，\\(f:X\\to Y\\)\n若\\(f\\)是单射，则必有\\(|X|\\leq|Y|\\) 若\\(f\\)是满射，则必有\\(|X|\\ge|Y|\\) 若\\(f\\)是双射，则必有\\(|X|=|Y|\\) 定理2\n设\\(X\\)和\\(Y\\)是有限集合，\\(f\\)是从集合\\(X\\)到\\(Y\\)的函数。若\\(|X|=|Y|\\)，则\\(f\\)是单射，当且仅当\\(f\\)是满射。\n常数函数\n存在\\(c\\in Y\\)，对任意\\(x\\in X\\)，\\(f(x)=c\\)\n恒等函数\n\\(f(x)=x\\)\n置换（排列）\n对于函数\\(f:X\\to X\\)，若\\(f\\)是双射的，则称\\(f\\)为\\(X\\)上的置换或排列。\\(X\\)上的恒等函数称为恒等置换或者幺置换。\\(|X|=n\\)时称为\\(n\\)次置换，\\(|X|\\)无限时称为无限次置换。\n通常写成\n\\[P= \\begin{pmatrix} x_1 \u0026 x_2 \u0026 \\cdots \u0026 x_n\\\\ f(x_1) \u0026 f(x_2) \u0026 \\cdots \u0026 f(x_n) \\end{pmatrix} \\]\n复合函数和逆函数 类似于关系的复合运算\n但是注意书写顺序。\\(g\\diamond f\\)和\\(f\\circ g\\)的顺序正好相反\n定理1\n\\(f:X\\to Y,g:Y\\to Z\\)，那么\\(g\\diamond f\\)是\\(X\\)到\\(Z\\)的函数。\n定理2\n\\(h\\diamond(g\\diamond f)=(h\\diamond g)\\diamond f\\)\n\\(f^0=I_x\\) \\(f^{n+1}=f\\diamond f^n\\) 定理3\n\\(f:X\\to Y,g:Y\\to Z\\)\n若\\(f,g\\)满射，则\\(g\\diamond f\\)满射。 若\\(f,g\\)单射，则\\(g\\diamond f\\)单射。 若\\(f,g\\)双射，则\\(g\\diamond f\\)双射。 若\\(g\\diamond f\\)满射，则\\(g\\)满射 若\\(g\\diamond f\\)单射，则\\(f\\)单射 若\\(g\\diamond f\\)双射，则\\(g\\)满射，\\(f\\)单射。 逆函数 设\\(f\\)是双射函数，则\\(f^{-1}=\\{\u003c y,x\u003e|\u003c x,y\u003e\\in f\\}\\)。显然逆函数也是双射函数。\n定理1\n\\((f^{-1})^{-1}=f\\) \\(f^{-1}\\diamond f=I_X\\) \\(f\\diamond f^{-1}=I_X\\) 定理2\n\\((g\\diamond f)^{-1}=f^{-1}\\diamond g^{-1}\\)\n可数与不可数集合 集合的基数 基数\n度量\\(A\\)大小的数称为基数或势，记为\\(|A|\\)。\n等势\n若\\(A\\)到\\(B\\)能建立起双射函数，则称\\(A,B\\)等势，记为\\(A\\sim B\\)，或\\(|A|=|B|\\)\n定理1\n等势是任何集合簇上的等价关系。即是自反的、对称的、传递的。\n有限集合、无限集合\n含有有限个（包含0）元素的集合称为有限集合，不是有限集合的称为无限集合。\n定理1\n有限集合的任意子集是有限集合。无限集合的超集是无限集合。\n定理2\n无限集合存在与其等势的真子集。\n可数集 与自然数集\\(N\\)等势的集合称为可数无限集合，简称可数集。可数集的基数用\\(\\alef_0\\)表示。\n有限集和可数集通称为至多可数集。\n枚举\n设\\(A\\)是一个集合，如果\\(f\\)是从\\(N\\)或从\\(N_k=\\{0,1,2,\\cdots,k-1\\}\\)到\\(A\\)的一个满射函数，则称\\(f\\)为\\(A\\)的一个枚举。如果\\(f\\)是双射的，则称为无重复枚举，否则称为重复枚举。\n定理1\n一个无限集合\\(A\\)是可数集，当且仅当存在\\(A\\)的枚举。\n定理2\n可数无限集的任一无限子集是可数集。\n定理3\n任意两个可数集的并是可数集。\n定理4\n\\(N\\times N\\)是可数集。\n定理5\n可数个可数集的并是可数集。\n不可数集 与自然数集不等势的无限集称为不可数集\n定理1\n实数集的子集\\((0,1)\\)是不可数集\n基数的比较 Zemelo三歧性定理\n以下三条恰有一条成立\n|A|\u0026lt;|B| |A|\u0026gt;|B| |A|=|B| Cantor-Schroder-Bernstein定理\n\\(|A|\\leq|B|\\)且\\(|A|\\ge|B|\\)，则\\(|A|=|B|\\)\n定理3\n设\\(A\\)是任意有限集合，则\\(|A|\u003c\\alef_0\u003c\\alef\\)\n定理4\n任意无限集合必定存在可数无限子集\n定理5\n\\(\\alef_0\\)是最小的无限集基数\nCantor定理\n\\(|M|\u003c|\\rho (M)|\\)\n图论 图的基本概念 按边是否有方向，图可以分为有向图、无向图和混合图。\n设\\(G\\)是一个有向图，如果将\\(G\\)中的每条边的方向去掉就能得到一个无向图\\(G'\\)，则称\\(G'\\)为\\(G\\)的底图。\n邻接点\n关联于同一条边的两个结点被称为邻接点。\n邻接边\n关联于一个结点的两条边被称为邻接边。\n孤立结点\n不与任何结点邻接的结点称之为孤立节点\n零图\n仅由若干个孤立节点构成的图称为零图。\n平凡图\n仅由单个孤立节点组成的图称为平凡图。\n平行边\n\\(e_1=e_2=\\{u,v\\}\\)，若\\(e_1,e_2\\)是两条不同的边，则称\\(e_1,e_2\\)为平行边。\n自回路（环）\n\\(e=\\{u,u\\}\\)\n多重图\n有平行边的图。\n线图\n不含平行边的图。\n简单图\n不含自回路的图。\n结点的度数 与结点\\(v\\)关联的边数称为结点\\(v\\)的度数（无向图），记为\\(deg(v)\\)。\n如果是有向图，则以结点\\(v\\)为终点的边数称为入度\\(deg^-(v)\\)，为始点的边数称为出度\\(deg^+(v)\\)。显然有\\(deg(v)=deg^-(v)+deg^+(v)\\)\n有如下定理\n握手定理\n任何图中，所有节点的度数之和等于边数的两倍。\n定理2\n任何图中，奇数度的节点必有偶数个。\n定理3\n任何有向图中，所有节点的入度等于所有节点的出度。\n特殊图 无向完全图\n无向简单图中，任何两个不同结点间都恰有一条边相连。\\(n\\)个结点的无向完全图记为\\(K^n\\)。\n有向完全图\n有向图\\(G=\u003c V,E\u003e\\)满足\\(E=V\\times V\\)。记为\\(D_n\\)。\n二部图\n非零图，节点集合\\(V\\)可以划分成两个不相交的子集\\(X\\)和\\(Y\\)，使\\(G\\)中的每一条边的一个端点在\\(X\\)中而另一个端点在\\(Y\\)中，则称\\(G\\)为二部图，记为\\(G=\u003c X,E,Y\u003e\\)\n可以通过标号法确定一个图是不是二部图。\n二部图必无自回路，但可以有平行边。\n子图与补图 子图\n设\\(G=\u003c V,E\u003e\\)，\\(G'=\u003c V',E'\u003e\\)，若有\\(E'\\subseteq E\\)且\\(V'\\subseteq V\\)，则称\\(G'\\)是\\(G\\)的子图。\n生成子图\n\\(V'=V\\)时，\\(G'\\)是\\(G\\)的生成子图。\n导出子图\n设\\(G'\\)是\\(G\\)的子图，\\(V'\\)仅由\\(E'\\)中边相关联的结点组成，则称\\(G'\\)为由边集\\(E'\\)导出的子图。\n补图\n给定一个图\\(G\\)，由\\(G\\)中所有的结点及所有能使\\(G\\)成为完全图的添加边组成的图，称为\\(G\\)相对于完全图的补图，简称为\\(G\\)的补图，记为\\(\\bar{G}\\)。\n图的同构 设\\(G=\u003c V,E\u003e,G'=\u003c V',E'\u003e\\)，如果存在双射函数\\(f:V\\to V',g:E\\to E'\\)，对于任何\\(e\\in E,e=[v_i, v_j]\\)当且仅当\\(g(e)=[f(v_i),f(v_j)]\\)。则称\\(G,G'\\)同构，记作\\(G\\cong G'\\)。\n相互同构的图只是画法不同或者结点与边的命名不同而已。\n两幅图同构的必要条件\n结点数相同 边数相同 度数相同的结点数目相同 图的连通性 路和回路 通路\n经过的结点不重复的路。\n迹\n经过的边不重复的路。回路为闭迹，非回路为开迹。\n圈\n除始点和终点外没有相同结点的闭迹称为圈。长度为\\(k\\)的圈称为\\(k\\)圈，又可根据\\(k\\)分为奇圈和偶圈。\n定理1\n在一个具有\\(n\\)个节点的图中，如果两个结点连通，则两个结点间必有一条长度小于\\(n\\)的路（也存在小于\\(n\\)的通路）。\n定理2\n在一个具有\\(n\\)个节点的图中，如果存在闭迹，则必存在一条长度小于等于\\(n\\)的圈。\n定理3\n设\\(G\\)是一个无向图，若\\(G\\)中每个结点的度数大于等于\\(2\\)，\\(G\\)中必含有圈。\n定理4\n\\(G=\u003c V,E\u003e\\)是无向图，\\(|E|\u003e0\\)，\\(G\\)是二部图当且仅当\\(G\\)中不含有奇圈。\n无向图的连通性 割点与割点集\n删除某个结点和其相连边后，图变成不连通的，则称为割点。删除某个点集中的所有点和所连接边，图变成不连通的，并且删除该点集的任意真子集图仍然连通，则称这个点集为割点集。\nk连通\n由\\(G\\)产生一个不连通子图最少需要删去\\(k\\)个结点。则称\\(G\\)为\\(k\\)连通图。\n定理1\n无向图中，一个结点是割点，当且仅当存在两个结点间的每条路都要通过该节点。\n割边与割边集\n与割点相似。\nk边连通\n与\\(k\\)连通相似。\n定理1\n无向图中，一条边是割边，当且仅当它不包含在任一圈中。\n有向图的连通性 强连通，单侧连通，弱连通\n强连通则是两个结点双向可达。单侧连通则是单向可达。若联通则是看成无向图。\n定理1\n有向图是强连通的，当且仅当它存在一条回路，至少包含每个结点一次。\n最短路 见算法竞赛模板。\n图的矩阵表示 邻接矩阵 \\(AA^T\\)\n\\(G\\)中刚好有\\(b_{ij}\\)个结点，从\\(v_i\\)和\\(v_j\\)均有边引出到这些节点。\n\\(A^TA\\)\n\\(G\\)中刚好有\\(b_{ij}\\)个结点，以这些节点为始边，既有边到\\(v_i\\)又有边到\\(v_j\\)。\n\\(A\\times A\\)\n从\\(v_i\\)到\\(v_j\\)的路，长度为2的有\\(b_{ij}\\)条。\n同理可知\\(A^{(m)}\\)的含义。\n可达矩阵 \\(P(G)=A^{(0)}\\vee A^{(1)}\\vee\\cdots\\vee A^{(n-1)}\\)\n定理\n无向图是连通图，当且仅当可达矩阵所有元素都为1. 有向图是强连通图，当且仅当可达矩阵所有元素都为1. 有向图是单侧连通图，当且仅当\\(P\\vee P^T\\)所有元素都为1. 有向图是弱连通图，当且仅当以\\(A\\vee A^T\\)作为邻接矩阵求出来的可达矩阵\\(P'\\)所有元素都为1. 求传递闭包的快速算法 设\\(R\\)是集合\\(V\\)上的二元关系，\\(n\\in \\bm{Z}^+\\)，对于任意\\(a,b\\in V,\u003c a,b\u003e\\in R^n\\)，当且仅当\\(R\\)的关系图\\(G=\u003c V,E\u003e\\)中存在从\\(a\\)到\\(b\\)有长度为\\(n\\)的有向路。\n设\\(\\bm{M}_R\\)是\\(V\\)上二元关系\\(R\\)的关系矩阵，则\n\\[\\bm{M}_{t(R)}=\\bm{M}_R\\vee\\bm{M}_R^{(2)}\\vee\\cdots\\vee\\bm{M}_R^{(n)} \\]\n欧拉图与汉密尔顿图 欧拉图 欧拉路（欧拉迹）\n包含图中所有边的开迹。\n欧拉回路\n包含图中所有边的闭迹。\n欧拉图\n包含欧拉回路的图称为欧拉图。\n定理1\n无向图是欧拉图当且仅当图是连通的并且每个结点的度均为偶数。\n无向图中存在一条欧拉路，当且仅当图是联通的，并且图中恰有两个奇数度的点。并且这两个点是起点和终点。\n定理2\n有向图是欧拉图，当且仅当它是联通的，并且每个结点的出度等于入度。\n有向图有欧拉路，当且仅当它是联通的，并且除了两个结点以外都出度等于入度，这两个结点必须一个出度比入度大一，另一个入度比出度大一。\n汉密尔顿图 包含图中每个结点一次且仅一次的通路称为汉密尔顿路。包含图中每个结点一次且仅一次的圈叫汉密尔顿回路。含汉密尔顿回路的图叫做汉密尔顿图。\n定理1（必要条件）\n若\\(G\\)是汉密尔顿图，则对于结点集\\(V\\)的每一个非空子集\\(S\\)都有\n\\[\\omega(G-S)\\leq|S| \\]\n其中\\(\\omega(G-S)\\)表示\\(G\\)删除\\(S\\)中所有结点后得到的连通分支的个数。\n定理2（必要条件）\n设\\(G=\u003c X,E,Y\u003e\\)是无向连通二部图，其中\\(|X|=m,|Y|=n\\)，若\\(m\\neq n\\)，则必不是汉密尔顿图。\n若\\(|m-n|\u003e1\\)，则必不存在汉密尔顿路。\n定理3（充分条件）\n设\\(G=\u003c V,E\u003e\\)是含有\\(n(n\\ge3)\\)个节点的简单无向图，如果\\(G\\)中的任何两个不同结点的度数之和都大于等于\\(n-1\\)，则\\(G\\)中存在汉密尔顿路。\n如果都大于等于\\(n\\)，则存在汉密尔顿回路。\n平面图 平面嵌入\n将一个平面图\\(G\\)重新排列得到边不相交的图\\(G'\\)，\\(G'\\)称为一个平面嵌入。\n面的次数\n面\\(r\\)的边界回路长度称为面的次数，记作\\(deg(r)\\)\n定理1\n连通平面图，所有面的次数之和等于边数的两倍\n定理2\n连通平面图，有\\(n\\)个节点，\\(m\\)条边，\\(r\\)个面，则有\\(n-m+r=2\\)成立。\n若\\(n\\ge3\\)，则\\(m\\leq3n-6\\)\n若每个面至少由\\(k\\)边围成，则有\\(m\\leq\\frac{k(n-2)}{k-2}\\)\n同胚\n给定两个图\\(G_1\\)和\\(G_2\\)，如果它们本身是同构的，或者通过反复插入度为2的结点(在某边上嵌入结点)或反复删除度为2的结点(仅去除结点,其关联边拼接)后，能够使\\(G_1\\)和\\(G_2\\)同构，则称\\(G_1\\)和\\(G_2\\)在\\(2\\)度结点内同构，亦称同胚。\n库拉托夫斯基定理\n一个图是平面图，当且仅当它不包含与\\(K_{3,3}\\)和\\(K_5\\)同胚的子图。\n图的着色 图的结点着色 正常着色\n无向图，给每个结点指定一种颜色，若满足邻接的两个结点颜色不同，则称为正常着色。\n可k-着色\n可以用\\(k\\)种不同的颜色给无向图正常着色。\nk色图\n对无向图正常着色所需要的最少的颜色数，称为顶着色数，简称色数，记为\\(\\mathcal{X}(G)\\)。色数为\\(k\\)的图称为\\(k\\)色图\nWelch Powell着色法\n将图\\(G\\)中的结点按度数递减的次序进行排列。 用一种与已着色结点所着颜色不同的新的颜色\\(C\\)对排列最前的尚未着色的节点着色，并按排列次序对与前面已着上颜色\\(C\\)的结点均不相邻的每一结点着同样的颜色\\(C\\)。 重复2知道着色结束。 定理1\n任何图均满足\\(\\mathcal{X}(G)\\leq \\Delta(G)+1\\)。\\(\\Delta(G)=max\\{d(u)|u\\in V\\}\\)\n定理2\n\\(\\mathcal{X}(G)=2\\)，当且仅当\\(G\\)是二部图。\n平面图的着色 对偶图\n设\\(G=\u003c V,E\u003e\\)是平面图，\\(G'\\)是\\(G\\)的一个平面嵌入，\\(F(G')\\)是\\(G'\\)的面集合。构造图\\(G^*\\)，若\\(G^*\\)的结点集合\\(V(G^*)=F(G')\\)，且任取两个结点\\(f_1,f_2\\in V(G^*)\\)，\\(f_1\\)和\\(f_2\\)之间存在边\\(e\\)当且仅当\\(f_1\\)和\\(f_2\\)在\\(G'\\)中有一条公共边，则称\\(G^*\\)是\\(G\\)的对偶图。\n定理\n设\\(G=\u003c V,E\u003e\\)是一个连通简单平面图，且\\(|V|\\ge 3,|E|=m\\)，则\\(G\\)中必存在结点\\(u\\in V\\)，满足\\(deg(u)\\leq 5\\)。\n希伍德五色定理\n任何一个连通简单平面图都是5可着色的。\n四色定理\n平面图的色数不超过4。\n树 无向树的定义 平凡树\n只有一个孤立节点的树。\n定理1\n对于一个含有\\(n\\)个结点\\(m\\)条边的无向树，以下定义等价\n无圈且连通 无圈且\\(m=n-1\\) 连通且\\(m=n-1\\) 无圈，但任意新增一条边，恰得到一个圈 连通，且每条边都是割边 每一对结点有且只有一条通路 定理2\n任何一颗非平凡树中至少有两片树叶\n生成树 定理1\n任何一个无向连通图至少有一颗生成树\n定理2\n连通图中的一个圈与其任何一棵生成树的补至少有一条公共边。\n定理3\n一个边割集和任何一棵生成树至少有一条公共边。\n最小生成树及其算法\n见竞赛模板。\n根树及其应用 根树\n一棵有向树，恰有一个节点入度为0，其余节点入度都为1。\nm元树\n每个结点的出度均小于等于\\(m\\)的根树。\n每个节点的出度均等于\\(0\\)或\\(m\\)的根树称为正则\\(m\\)元树。\n定理1\n正则\\(m\\)元树\\(T\\)，其树叶数为\\(t\\)，分支结点数为\\(i\\)，则有\\((m-1)i=t-1\\)\n带权树\n如果一颗二元树\\(T\\)共有\\(n\\)片树叶，分别带权\\(\\omega_1,\\omega_2,\\cdots,\\omega_n\\)。定义这棵二元树\\(T\\)的权值为，\n\\[W(T)=\\sum_{i=1}^{n}\\omega_iL(\\omega_i) \\]\n其中\\(L(\\omega_i)\\)为带权\\(\\omega_i\\)的树叶的深度（根深度为0）。在所有带这些权的二元树中，具有最小权的二元树称为最优二元树。\n定理1\n最优二元树是一颗正则二元树。\n定理2\n最优二元树中，层数最大的分支节点的两个儿子所带权分别为最小的两个权。\n最优二元树的构造方法\n7.7.12\r前缀码\n给定一个以\\(0,1\\)组成序列为元素的集合，若没有一个序列是另一个序列的前缀，则该集合称为前缀码。\n利用有序正则二元树解决前缀码问题\n7.7.13\r","date":"2022-06-06T08:44:57+08:00","image":"https://kegalas.top/p/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6%E6%95%B4%E7%90%86/cover_huf80a3777f066c3f01437aeed10211fe1_29240_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6%E6%95%B4%E7%90%86/","title":"离散数学整理"},{"content":"[TOC]\n矩阵 几个特殊矩阵 方阵 行数与列数相同的矩阵\\(\\bold{A}_{n\\times n}\\)称为\\(n\\)阶矩阵或\\(n\\)阶方阵\n零矩阵 元素都是零的矩阵称为零矩阵，记作\\(\\bold O\\)\n三角矩阵 上三角矩阵\n主对角线以下的元素全为零的方阵，即\n\\[\\bold{A}_n=\\begin{bmatrix} a_{11} \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n}\\\\ 0 \u0026 a_{22} \u0026 \\cdots \u0026 a_{2n}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ 0 \u0026 0 \u0026 \\cdots \u0026 a_{nn} \\end{bmatrix} \\]\n下三角矩阵\n主对角线以上的元素全为零的方阵，即\n\\[\\bold{A}_n=\\begin{bmatrix} a_{11} \u0026 0 \u0026 \\cdots \u0026 0\\\\ a_{21} \u0026 a_{22} \u0026 \\cdots \u0026 0\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{n1} \u0026 a_{n2} \u0026 \\cdots \u0026 a_{nn} \\end{bmatrix} \\]\n对角阵 主对角线（左上到右下的对角线；右上到左下的是副对角线）以外的元素全为零的方阵，即\n\\[\\bold{A}_n=\\begin{bmatrix} a_{11} \u0026 \u0026 \u0026 \\\\ \u0026 a_{22} \u0026 \u0026 \\\\ \u0026 \u0026 \\ddots \u0026 \\\\ \u0026 \u0026 \u0026 a_{nn} \\end{bmatrix} \\]\n对角矩阵常记为\\(\\Lambda\\)或\\(diag(a_{11},a_{22},\\cdots,a_{nn})\\)\n单位矩阵 主对角线上全为1的对角矩阵称为单位矩阵，记作\\(\\bold{E}_n\\)，即\n\\[\\bold{E}_n=\\begin{bmatrix} 1 \u0026 \u0026 \u0026 \\\\ \u0026 1 \u0026 \u0026 \\\\ \u0026 \u0026 \\ddots \u0026 \\\\ \u0026 \u0026 \u0026 1 \\end{bmatrix} \\]\n系数矩阵 对于线性方程组\n\\[\\left\\{\\begin{matrix} 2x_1-2x_2+6x_4=-2 \\\\ 2x_1-x_2+2x_3+4x_4=-2 \\\\ 3x_1-x_2+4x_3+4x_4=-3 \\\\ x_1+x_2+x_3+8x_4=2 \\end{matrix}\\right. \\]\n其系数矩阵为\n\\[\\bold{A}=\\begin{bmatrix} 2 \u0026 -2 \u0026 0 \u0026 6\\\\ 2 \u0026 -1 \u0026 2 \u0026 4\\\\ 3 \u0026 -1 \u0026 4 \u0026 4\\\\ 1 \u0026 1 \u0026 1 \u0026 8 \\end{bmatrix} \\]\n增广矩阵 由线性方程组所有系数和常数项所构成的矩阵称为线性方程组的增广矩阵，并记为\\(\\tilde{\\bold{A}}=(\\bold{A,b})\\)或\\(\\tilde{\\bold{A}}=[\\bold{A,b}]\\)\n\\[\\tilde{\\bold{A}}=[\\bold{A,b}]=\\begin{bmatrix} 2 \u0026 -2 \u0026 0 \u0026 6 \u0026 -2\\\\ 2 \u0026 -1 \u0026 2 \u0026 4 \u0026 -2\\\\ 3 \u0026 -1 \u0026 4 \u0026 4 \u0026 -3\\\\ 1 \u0026 1 \u0026 1 \u0026 8 \u0026 2 \\end{bmatrix} \\]\n对称矩阵 满足\\(\\bold{A}^T=\\bold{A}\\)的矩阵称为对称矩阵，满足\\(\\bold{A}^T=-\\bold{A}\\)的矩阵称为反对称矩阵。\n行阶梯型矩阵 满足以下两个条件\n如果有零行（元素全为0的行），则零行位于非零行的下方 非零行（元素不全为0的行）的首个非零元素，其前面零元素的个数逐行增加。 最简行阶梯型矩阵：进一步满足非零行的首非零元均为1，且所在列的其余元素为0.\n初等矩阵 由\\(n\\)阶单位矩阵\\(\\bold{E}\\)经过一次初等变换所得到的矩阵称为初等矩阵或初等方阵。\n奇异矩阵 行列式为0的矩阵称为奇异矩阵。不为0的称为非奇异矩阵。\n可逆矩阵 见后\n伴随矩阵 矩阵\\(\\bold{A}\\)的各个元素的代数余子式\\(A_{ij}\\)所构成的如下矩阵\n\\[\\bold{A}^*= \\begin{bmatrix} A_{11} \u0026 A_{21} \u0026 \\cdots \u0026 A_{n1}\\\\ A_{12} \u0026 A_{22} \u0026 \\cdots \u0026 A_{n2}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ A_{1n} \u0026 A_{2n} \u0026 \\cdots \u0026 A_{nn} \\end{bmatrix} \\]\n即\\(\\bold{A}^*=(A_{ij})^T_{n\\times n}\\)，称为\\(A\\)的伴随矩阵。\n并且伴随矩阵满足\\(\\bold{AA^*}=\\bold{A^*A}=\\bold{|A|E}\\)\n并且可推知，当\\(\\bold{|A|}\\ne 0\\)时，有\\(\\bold{|A^*|}=\\bold{|A|}^{n-1}\\)\n另外注意，伴随矩阵的序号和原矩阵的序号相当于进行了转置。\n正交矩阵 见后\n矩阵的运算 加减法 对于矩阵\\(\\bold{A}=(a_{ij})_{m\\times n},\\bold{B}=(b_{ij})_{m\\times n}\\)，定义\n\\[\\bold{A\\pm B}=\\begin{bmatrix} a_{11}\\pm b_{11} \u0026 a_{12}\\pm b_{12} \u0026 \\cdots \u0026 a_{1n}\\pm b_{1n}\\\\ a_{21}\\pm b_{21} \u0026 a_{22}\\pm b_{22} \u0026 \\cdots \u0026 a_{2n}\\pm b_{2n}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{m1}\\pm b_{m1} \u0026 a_{m2}\\pm b_{m2} \u0026 \\cdots \u0026 a_{mn}\\pm b_{mn} \\end{bmatrix} \\]\n数乘 \\[\\lambda\\bold{A}=\\begin{bmatrix} \\lambda a_{11} \u0026 \\lambda a_{12} \u0026 \\cdots \u0026 \\lambda a_{1n}\\\\ \\lambda a_{21} \u0026 \\lambda a_{22} \u0026 \\cdots \u0026 \\lambda a_{2n}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ \\lambda a_{m1} \u0026 \\lambda a_{m2} \u0026 \\cdots \u0026 \\lambda a_{mn} \\end{bmatrix} \\]\n线性运算的运算规律 矩阵的加减法和数乘统称为矩阵的线性运算，满足以下运算律\n\\(\\bold{A+B=B+A}\\) \\(\\bold{(A+B)+C=A+(B+C)}\\) \\(\\bold{A+O=A}\\) \\(\\bold{A+(-A)=O}\\) \\(1\\bold{A=A}\\) \\((\\lambda\\mu)\\bold{A}=\\lambda(\\mu\\bold{A})=\\mu(\\lambda\\bold{A})\\) \\((\\lambda+\\mu)\\bold{A}=\\lambda\\bold{A}+\\mu\\bold{A}\\) \\(\\lambda(\\bold{A+B})=\\lambda \\bold{A}+\\lambda \\bold{B}\\) 乘积 设矩阵\\(\\bold{A}=(a_{ij})_{m\\times s},\\bold{B}=(b_{ij})_{s\\times n}\\)，其乘积是一个\\(m\\times n\\)矩阵，记为\\(\\bold{C}=(c_{ij})_{m\\times n}\\)\n\\[c_{ij}=\\sum^{s}_{k=1}a_{ik}b_{kj}=a_{i1}b_{1j}+a_{i2}b_{2j}+\\cdots+a_{is}b_{sj} \\]\n\\[(i=1,2,\\cdots,m;j=1,2,\\cdots,n) \\]\n由定义知，只有左边矩阵的列数等于右边矩阵的行数时，两个矩阵才能相乘。\n矩阵乘法满足如下运算规律\n\\(\\bold{(AB)C=A(BC)}\\) \\(\\bold{A(B+C)=AB+AC,(A+B)C=AC+BC}\\) \\(\\lambda(\\bold{AB})=(\\lambda\\bold{A)B}=\\bold{A}(\\lambda\\bold{B})\\) \\(\\bold{A}_{m\\times n}\\bold{E}_n=\\bold{E}_m\\bold{A}_{m\\times n}=\\bold{A}_{m\\times n}\\) \\(\\bold{A}^k\\bold{A}^l=\\bold{A}^{k+l},(\\bold{A}^k)^l=\\bold{A}^{kl}\\) 注意，由于矩阵乘法不满足交换律，故一般情况下，\\((\\bold{AB}^k)\\ne\\bold{A}^k\\bold{B}^k\\)\n转置 将矩阵\\(\\bold{A}\\)中的行换成同序数的列而得到的矩阵，称之为\\(\\bold{A}\\)的转置矩阵，记作\\(\\bold{A}^T\\)或\\(\\bold{A}'\\)，即若\n\\[\\bold{A}=\\begin{bmatrix} a_{11} \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n}\\\\ a_{21} \u0026 a_{22} \u0026 \\cdots \u0026 a_{2n}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{m1} \u0026 a_{m2} \u0026 \u0026 a_{mn} \\end{bmatrix} \\]\n\\[\\bold{A}^T=\\begin{bmatrix} a_{11} \u0026 a_{21} \u0026 \\cdots \u0026 a_{m1}\\\\ a_{12} \u0026 a_{22} \u0026 \\cdots \u0026 a_{m2}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{1n} \u0026 a_{2n} \u0026 \u0026 a_{mn} \\end{bmatrix} \\]\n转置满足以下运算律\n\\((\\bold{A}^T)^T=\\bold{A}\\) \\((\\bold{A+B})^T=\\bold{A}^T+\\bold{B}^T\\) \\((\\lambda\\bold{A})^T=\\lambda\\bold{A}^T\\) \\((\\bold{AB})^T=\\bold{B}^T\\bold{A}^T\\) 可逆矩阵 设\\(\\bold{A}\\)为\\(n\\)阶方阵，若存在\\(n\\)阶方阵\\(\\bold{B}\\)，使得\\(\\bold{AB=BA=E}_n\\)，则称\\(\\bold{A}\\)为可逆矩阵，或称其为可逆的。称\\(\\bold{B}\\)为\\(\\bold{A}\\)的逆矩阵。\\(\\bold{B}=\\bold{A}^{-1}\\).\n设\\(\\bold{A},\\bold{B}\\)都为\\(n\\)阶方阵，若\\(\\bold{AB=E}_n\\)，则\\(\\bold{A},\\bold{B}\\)都可逆，并且\n\\[\\bold{A}^{-1}=\\bold{B},\\bold{B}^{-1}=\\bold{A} \\]\n可逆矩阵的性质 若\\(\\bold{A}\\)可逆，则\\(\\bold{A}\\)的逆矩阵唯一. 若\\(\\bold{A}\\)可逆，则\\(\\bold{A}^{-1}\\)也可逆，并且\\(\\bold{A}=(\\bold{A}^{-1})^{-1}\\) 若\\(\\bold{A}\\)可逆，数\\(\\lambda\\ne0\\)，则\\(\\lambda\\bold{A}\\)可逆，并且\\((\\lambda\\bold{A})^{-1}=\\frac{1}{\\lambda}\\bold{A}^{-1}\\) 若\\(\\bold{A}\\)、\\(\\bold{B}\\)均为\\(n\\)阶可逆方阵，则\\(\\bold{A}\\bold{B}\\)也可逆，且\\((\\bold{A}\\bold{B})^{-1}=\\bold{B}^{-1}\\bold{A}^{-1}\\) 若\\(\\bold{A}\\)可逆，则\\(\\bold{A}^{T}\\)也可逆，并且\\((\\bold{A}^T)^{-1}=(\\bold{A}^{-1})^{T}\\) 逆矩阵的求法 借用伴随矩阵和行列式，见行列式一章 初等变换法 设有方阵\\(\\bm A\\)，将其和同阶单位阵写在一起\\((A,E)\\)，然后通过初等行变换（只能是行变换），化成\\((E,A')\\)的形式，然后\\(A'\\)就是逆矩阵。\n分块矩阵 加减法、数乘、乘法与普通矩阵相似。转置时除了将整个矩阵，还要将每个元素本身转置。\n初等变换 下面三种变换称之为初等行变换\n交换两行的位置 以非零数\\(k\\)乘某行 把某一行的\\(k\\)倍加到另一行上 初等列变换只用把上述的行换成列即可。两种变换通称初等变换。显然初等变换是可逆的。\n矩阵等价 如果矩阵\\(\\bold{A}\\)经有限次初等变换成矩阵\\(\\bold{B}\\)，那么称这两个矩阵等价，记作\\(\\bold{A} \\sim \\bold{B}\\)\n等价关系具有：自反性、对称性、传递性。\n相似一定等价，等价不一定相似。 合同一定等价，等价不一定合同。 合同不一定相似，相似不一定合同。\n矩阵的秩 设\\(\\bold{A}\\)为\\(m\\times n\\)矩阵，\\(\\bold{B}\\)是与\\(\\bold{A}\\)等价的行阶梯型矩阵，若矩阵\\(\\bold{B}\\)的非零行数为\\(r\\)，则称矩阵\\(\\bold{B}\\)的秩为\\(r\\)，矩阵\\(\\bold{A}\\)的秩也为\\(r\\)，记作\\(R(\\bold{A})=R(\\bold{B})=r\\)\n矩阵的秩的性质 \\(0\\leq R(\\bold{A}_{m\\times n})\\leq min\\{m,n\\}\\) \\(R(\\bold{A})=0\\Leftrightarrow \\bold{A=O}\\) \\(R(\\bold{A}^T)=R(\\bold{A})\\) 若\\(\\bold{A}\\sim\\bold{B}\\)，则\\(R(\\bold{A})=R(\\bold{B})\\) 若\\(\\bold{P},\\bold{Q}\\)可逆，则\\(R(\\bold{A})=R(\\bold{PA})=R(\\bold{AQ})=R(\\bold{PAQ})\\)（可逆矩阵不影响矩阵的秩）（初等变换不影响矩阵的秩） \\(max\\{R(\\bold{A}),R(\\bold{B})\\}\\leq R(\\bold{A,B})\\leq R(\\bold{A})+R(\\bold{B})\\) \\(R(\\bold{A\\pm B})\\leq R(\\bold{A})+R(\\bold{B});R(\\bold{AB})\\leq min\\{R(\\bold{A}),R(\\bold{B})\\}\\) 若\\(\\bold{A}_{m\\times n}\\bold{B}_{n\\times l}=\\bold{O}\\)，则\\(R(\\bold{A})+R(\\bold{B})\\leq n\\) \\(\\bold{A}_{m\\times n}\\)行满秩\\(\\Leftrightarrow R(\\bold{A})=m\\Leftrightarrow\\bold{A}\\)的等价标准型为\\((\\bold{I}_m,\\bold{O})\\)（\\(\\bold{I}\\)是单位矩阵）。\\(\\bold{A}_{m\\times n}\\)列满秩\\(\\Leftrightarrow R(\\bold{A})=n\\Leftrightarrow\\bold{A}\\)的等价标准型为\\((\\bold{I}_n,\\bold{O})^T\\)。 若\\(\\bold{A}\\)为\\(n\\)阶方阵，则\\(R(\\bold{A})=n\\Leftrightarrow \\bold{A}\\)是可逆矩阵 若\\(\\bold{A},\\bold{B}\\)均为\\(n\\)阶方阵，则\\(R(\\bold{AB})\\ge R(\\bold{A})+R(\\bold{B})-n\\) \\(R(\\bold{ABC})\\ge R(\\bold{AB})+R(\\bold{BC})-R(\\bold{B})\\) \\(R(\\bold{A}_{m\\times n})=n\\Leftrightarrow\\)齐次线性方程组\\(\\bold{Ax=0}\\)只有零解。 \\[R\\begin{pmatrix} \\bold{A} \u0026 0\\\\ 0 \u0026 \\bold{B} \\end{pmatrix}=R(\\bold{A})+R(\\bold{B}) \\]\n矩阵的秩等于矩阵的行秩也等于矩阵的列秩 对于一个矩阵一些相互等价的命题 第一组 设\\(\\bold{A}\\)为\\(n\\)阶方阵，那么下列命题等价\n满秩 非奇异 可逆 \\(\\bold{Ax=0}\\)只有零解 \\(|\\bold{A}|\\ne0\\) \\(\\bold{A}\\)可以经过有限次初等行变换华为单位矩阵\\(\\bold{E}_n\\) \\(\\bold{A}\\)可以表示为有限个初等矩阵的乘积。 特征值均非零 第二组 设\\(\\bold{A}\\)为\\(n\\)阶方阵，那么下列命题等价\n降秩 奇异 不可逆 \\(\\bold{Ax=0}\\)不只有零解 \\(|\\bold{A}|=0\\) \\(\\bold{A}\\)不可以经过有限次初等行变换华为单位矩阵\\(\\bold{E}_n\\) \\(\\bold{A}\\)不可以表示为有限个初等矩阵的乘积。 特征值至少有一个为零 第三组 设\\(f(x_1,\\cdots,x_n)=\\bm{x}^T\\bm{Ax}\\)是\\(n\\)元实二次型，则下列命题等价\n\\(f=\\bm{x}^T\\bm{Ax}\\)是正定二次型，即\\(\\bm{A}\\)是正定矩阵 \\(\\bm{A}\\)的特征值均为正数 \\(f=\\bm{x}^T\\bm{Ax}\\)的正惯性指数为\\(n\\) \\(\\bm{A}\\)与单位矩阵\\(\\bm{E}\\)合同 存在可逆矩阵\\(\\bm B\\)，使得\\(\\bm{A=B}^T\\bm B\\) 顺序主子式均大于零 第四组 设\\(f(x_1,\\cdots,x_n)=\\bm{x}^T\\bm{Ax}\\)是\\(n\\)元实二次型，则下列命题等价\n\\(f\\)是负定二次型 \\(f\\)的负惯性指数为\\(n\\) \\(\\bm A\\)的特征值全为负数 \\(\\bm A\\)合同于\\(-\\bm E\\) \\(\\bm A\\)的奇数阶顺序主子式均为负数，偶数阶顺序主子式均为负数 行列式 二阶行列式 \\[D=\\begin{vmatrix} a_{11} \u0026 a_{12} \\\\ a_{21} \u0026 a_{22} \\end{vmatrix}=a_{11}a_{22}-a_{12}a_{21} \\]\nn阶行列式 余子式与代数余子式 在\\(n\\)阶行列式\n\\[D=\\begin{vmatrix} a_{11} \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n}\\\\ a_{21} \u0026 a_{22} \u0026 \\cdots \u0026 a_{2n}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{n1} \u0026 a_{n2} \u0026 \\cdots \u0026 a_{nn} \\end{vmatrix} \\]\n中划掉元素所在的第\\(i\\)行与第\\(j\\)列后，剩下的\\((n-1)^2\\)个元素按原来的次序构成的\\(n-1\\)阶行列式称为元素\\(a_{ij}\\)的余子式，记为\\(M_{ij}\\)，并称\\((-1)^{i+j}M_{ij}\\)为元素\\(a_{ij}\\)的代数余子式，记为\\(A_{ij}\\)。\n计算 \\[D=\\begin{vmatrix} a_{11} \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n}\\\\ a_{21} \u0026 a_{22} \u0026 \\cdots \u0026 a_{2n}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{n1} \u0026 a_{n2} \u0026 \\cdots \u0026 a_{nn} \\end{vmatrix} \\]\n\\[=a_{11}A_{11}+a_{12}A_{12}+\\cdots+a_{1n}A_{1n}=\\sum_{k=1}^{n}a_{k1}A_{k1} \\]\n上式为该行列式按第一行的展开定义。也可以按其他行（或者列）展开。\n易知对于对角矩阵和上下三角矩阵，其行列式为对角线上元素的乘积。对次三角矩阵则不等于副对角线上元素的乘积。单位矩阵的行列式等于\\(1\\).\n行列式的性质 行列式与其转置行列式相等，\\(|\\bold{A}|=|\\bold{A}^T|\\)\n行列式中某行（或列）元素的公因子可以提到行列式之外\n某行（或列）元素全为零的行列式等于0 对于\\(n\\)阶矩阵\\(\\bold{A}\\)，有\\(|k\\bold{A}|=k^n|\\bold{A}|\\) 交换某两行（或列）的位置，行列式的值变号.\n如果行列式中有两行（或两列）元素相同，则行列式为0. 行列式中若有两行（或两列）对应元素成比例，则行列式为0 若行列式某一行（或列）的元素是两项之和，则该行列式可以写成两个行列式之和，即\n\\[\\begin{vmatrix} a_{11} \u0026 \\cdots \u0026 a_{1j} \u0026 \\cdots \u0026 a_{1n}\\\\ \\vdots \u0026 \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{i1}+b_{i1} \u0026 \\cdots \u0026 a_{ij}+b_{ij} \u0026 \\cdots \u0026 a_{in}+b_{in}\\\\ \\vdots \u0026 \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{n1} \u0026 \\cdots \u0026 a_{nj} \u0026 \\cdots \u0026 a_{nn} \\end{vmatrix} \\]\n\\[=\\begin{vmatrix} a_{11} \u0026 \\cdots \u0026 a_{1j} \u0026 \\cdots \u0026 a_{1n}\\\\ \\vdots \u0026 \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{i1} \u0026 \\cdots \u0026 a_{ij} \u0026 \\cdots \u0026 a_{in}\\\\ \\vdots \u0026 \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{n1} \u0026 \\cdots \u0026 a_{nj} \u0026 \\cdots \u0026 a_{nn} \\end{vmatrix}+ \\begin{vmatrix} a_{11} \u0026 \\cdots \u0026 a_{1j} \u0026 \\cdots \u0026 a_{1n}\\\\ \\vdots \u0026 \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ b_{i1} \u0026 \\cdots \u0026 b_{ij} \u0026 \\cdots \u0026 b_{in}\\\\ \\vdots \u0026 \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{n1} \u0026 \\cdots \u0026 a_{nj} \u0026 \\cdots \u0026 a_{nn} \\end{vmatrix} \\]\n将某一行（或列）的任意\\(k\\)倍加到另一行（或列）上去，行列式的值不变 对于\\(n\\)阶行列式D，有 \\[\\sum_{j=1}^na_{ij}A_{kj}= \\left\\{\\begin{matrix} D,i=k\\\\ 0,i\\ne k \\end{matrix}\\right. \\]\n\\[\\sum_{i=1}^na_{ij}A_{ik}= \\left\\{\\begin{matrix} D,j=k\\\\ 0,j\\ne k \\end{matrix}\\right. \\]\n设\\(\\bold{A,B}\\)均为\\(n\\)阶方阵，则\\(|\\bold{AB}|=\\bold{|A||B|}\\) 范德蒙行列式 \\[V_n=\\begin{vmatrix} 1 \u0026 1 \u0026 1 \u0026 \\cdots \u0026 1\\\\ x_1 \u0026 x_2 \u0026 x_3 \u0026 \\cdots \u0026 x_n\\\\ x_1^2 \u0026 x_2^2 \u0026 x_3^2 \u0026 \\cdots \u0026 x_n^2\\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ x_1^{n-1} \u0026 x_2^{n-1} \u0026 x_3^{n-1} \u0026 \\cdots \u0026 x_n^{n-1} \\end{vmatrix} \\]\n有\n\\[V_n=\\prod_{1\\leq j \u003c i\\leq n}(x_i-x_j) \\]\n行列式求逆矩阵 \\(\\bold{A}\\)为可逆矩阵的充分必要条件是\\(|\\bold{A}|\\ne 0\\)，且有\n\\[\\bold{A}^{-1}=\\frac{1}{|\\bold{A}|}\\bold{A}^* \\]\n行列式求解非齐次线性方程组（克莱默法则） 对于线性方程组\\(\\bold{Ax=b}\\)，定义\n\\[D=|\\bold{A}|\\\\ D_1=|[\\bold{b},\\bold{a}_2,\\bold{a}_3,\\cdots,\\bold{a}_n]|\\\\ D_2=|[\\bold{a}_1,\\bold{b},\\bold{a}_3,\\cdots,\\bold{a}_n]|\\\\ \\cdots\\\\ D_n=|[\\bold{a}_1,\\bold{a}_2,\\bold{a}_3,\\cdots,\\bold{b}]|\\\\ \\]\n当\\(D\\ne0\\)时，该方程组有唯一解，其解为\n\\[x_1=\\frac{D_1}{D},x_2=\\frac{D_2}{D},\\cdots,x_n=\\frac{D_n}{D} \\]\nn维向量与向量空间 前提：本章默认为列向量。\n向量的运算 线性运算 加减法和数乘和矩阵一样，不再介绍。\n向量乘法 也和矩阵一样，但只有两种情况\n\\[\\bm{\\alpha}^T\\bm{\\beta}= \\begin{bmatrix} a_1\u0026a_2\u0026\\cdots\u0026a_n \\end{bmatrix}\\begin{bmatrix} b1\\\\b2\\\\\\vdots\\\\b3 \\end{bmatrix}= a_1b_1+a_2b_2+\\cdots+a_nb_n \\]\n\\[\\bm{\\alpha}\\bm{\\beta}^T= \\begin{bmatrix} a_1\\\\a_2\\\\\\vdots\\\\a_n \\end{bmatrix}\\begin{bmatrix} b1\u0026b2\u0026\\cdots\u0026b3 \\end{bmatrix}= \\begin{bmatrix} a_1b_1 \u0026 a_1b_2 \u0026 \\cdots \u0026 a_1b_n\\\\ a_2b_1 \u0026 a_2b_2 \u0026 \\cdots \u0026 a_2b_n\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_nb_1 \u0026 a_nb_2 \u0026 \\cdots \u0026 a_nb_n \\end{bmatrix} \\]\n向量运算的性质 和矩阵相同，看成行或列为1的矩阵即可。\n向量组的线性相关性 向量组的线性表示 设\\(n\\)维向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_s\\)，对于任何一组实数\\(k_1,k_2,\\cdots,k_s\\)，称\\(k_1\\bm{\\alpha}_1,k_2\\bm{\\alpha}_2,\\cdots,k_s\\bm{\\alpha}_s\\)为向量组的一个线性组合。\n设\\(\\bm{b}\\)为\\(n\\)维向量，若存在一组数\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_s\\)使得\\(\\bm{b}=\\lambda_1\\bm{\\alpha}_1,\\lambda_2\\bm{\\alpha}_2,\\cdots,\\lambda_s\\bm{\\alpha}_s\\)，则称\\(\\bm{b}\\)可由\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_s\\)线性表示。\n线性方程组\\(\\bm{Ax=b}\\)有解的充分必要条件是\\(\\bm{b}\\)可由\\(\\bm{A}\\)的列向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_n\\)线性表示.\n向量组的线性相关性定义及性质 设有\\(n\\)维向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)，如果存在不全为零的数\\(k_1,k_2,\\cdots,k_m\\)，使得\n\\[k_1\\bm{\\alpha}_1+k_2\\bm{\\alpha}_2+\\cdots+k_m\\bm{\\alpha}_m=0 \\]\n则称向量组线性相关，否则称线性无关。\n可以得到如下结论：\n包含零向量的向量组必线性相关 当向量组只包含一个向量时，若为零向量，则线性相关；否则线性无关。 非零向量组若只有两个向量，则线性相关的充要条件是两个向量的对应分量成比例。 向量组线性相关的充要条件是至少存在其中的一个向量可由其余向量线性表示 当\\(t\u003en\\)，含有\\(t\\)个\\(n\\)维向量的向量组必线性相关。 向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)线性无关，而向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m,\\bm{b}\\)线性相关，则\\(\\bm{b}\\)可由\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)唯一线性表示 \\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)线性无关，则任一部分组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r(r\u003c m)\\)必线性无关 \\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)线性相关，则增加向量后的向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_s(s\u003em)\\)必线性相关。 设\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)为\\(m\\)个\\(m\\)维列向量。则\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)线性无关\\(\\Leftrightarrow\\)行列式\\(|[\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m]|\\ne0$;\\)\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\(线性相关\\)\\Leftrightarrow\\(行列式\\)|[\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m]|=0$ 从几何角度理解：设\\(\\bm{\\alpha,\\beta,\\gamma}\\)为三维向量，向量组\\(\\bm{\\alpha,\\beta}\\)线性相关\\(\\Leftrightarrow\\bm{\\alpha,\\beta}\\)共线;向量组\\(\\bm{\\alpha,\\beta,\\gamma}\\)线性相关\\(\\Leftrightarrow\\bm{\\alpha,\\beta,\\gamma}\\)共面 向量组的秩和极大无关组 设有两个向量组，每个向量组中的每一个向量都可以由另一个向量组线性表示，则称两个向量组等价。\n设有向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_s\\)，而\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)是向量组中的\\(r\\)个向量\\((r\\leq s)\\)，若满足\n向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)线性无关; 向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_s\\)中的任\\(r+1\\)个向量（如果有）线性相关 则称向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)是向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_s\\)的一个极大无关组，极大无关组所含向量个数\\(r\\)称为向量组的秩，记作\\(R(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_s)=r\\).\n只含零向量的向量组，规定秩为0；向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_s\\)线性无关时，其秩为\\(s\\).\n有如下定理\n阶梯型矩阵\\(J\\)的行秩和列秩相等，恰等于\\(J\\)的非零行数，并且\\(J\\)的主元（非零行的首个元素）所在的列构成列向量组的一个极大无关组。 矩阵的初等行（列）变换不改变矩阵的列（行）（注意与前一句相反）向量组的线性相关性，从而不改变矩阵的列（行）秩。 矩阵的秩等于矩阵的行秩等于矩阵的列秩。 设\\(\\bm{A}\\)是\\(m\\times n\\)矩阵，则 矩阵\\(A\\)的列向量组线性相关（无关）的充要条件为\\(R(\\bm{A})\u003c n(R(\\bm{A})=n)\\)\n矩阵\\(A\\)的行向量组线性相关（无关）的充要条件为\\(R(\\bm{A})\u003c m(R(\\bm{A})=m)\\)\n若向量组\\(I\\)可由向量组\\(II\\)线性表示，则\\(I\\)的秩不超过\\(II\\)的秩； 等价向量组的秩相等。 极大无关组表示其他向量 1.jpg\r转化为行最简形为\n2.jpg\r显然极大无关组是\\(\\alpha_1,\\alpha_3,\\alpha_5\\)。\n并且有\\(\\alpha_2=3\\alpha_1,\\alpha_4=-2\\alpha_1+\\alpha_3,\\alpha_6=\\alpha_1+2\\alpha_3-\\alpha_5\\)\n向量空间 向量空间的定义 设\\(\\bm{V}\\)是非空\\(n\\)维向量的集合，如果\\(\\bm{V}\\)对向量的加法和数乘封闭，即\n若\\(\\bm{a,b\\in V}\\)，有\\(\\bm{a+b}\\in V\\); 若\\(\\bm{a\\in B},\\lambda\\in R\\)，有\\(\\lambda\\bm{a\\in V}\\)（特别注意\\(\\lambda=0\\)的情况） 则称\\(\\bm{V}\\)为一个向量空间\n向量空间必须含有零向量。\n子空间的定义\n设\\(\\bm{V}\\)和\\(\\bm{H}\\)都是向量空间，若\\(\\bm{H}\\subset V\\)，则称\\(\\bm{H}\\)是\\(\\bm{V}\\)的子空间。\n线性变换的定义\n已知\\(\\bm{A}\\)为\\(n\\)阶方阵，则称映射\\(f:\\bm{R}^n\\to \\bm{R}^n,\\bm{x}\\to \\bm{y},\\bm{y}=\\bm{Ax}\\)为\\(\\bm{R}^n\\)上的线性变换，\\(\\bm{A}\\)称为线性变换矩阵.\n向量的内积与正交矩阵 向量的内积\n设\\(n\\)维向量\\(\\bm{x}=[x_1,x_2,\\cdots,x_n]^T\\)，\\(\\bm{y}=[y_1,y_2,\\cdots,y_n]^T\\)，称\n\\[\u003c\\bm{x},\\bm{y}\u003e=x_1y_1+x_2y_2+\\cdots+x_ny_n \\]\n为向量\\(\\bm{x,y}\\)的内积。\n内积具有以下性质\n\\(\u003c\\bm{x},\\bm{y}\u003e=\u003c\\bm{y},\\bm{x}\u003e\\) \\(\u003c k\\bm{x},\\bm{y}\u003e=\u003c\\bm{x},k\\bm{y}\u003e=k\u003c\\bm{x},\\bm{y}\u003e\\)，\\(k\\)是实数 \\(\u003c\\bm{x+y},\\bm{z}\u003e=\u003c\\bm{x},\\bm{z}\u003e+\u003c\\bm{y},\\bm{z}\u003e\\) \\(\u003c\\bm{x},\\bm{x}\u003e\\ge0,\u003c\\bm{x},\\bm{x}\u003e=0\\)当且仅当\\(\\bm{x}=\\bm{0}\\) 柯西-施瓦茨不等式：\\(\u003c\\bm{x},\\bm{y}\u003e^2\\leq\u003c\\bm{x},\\bm{x}\u003e\u003c\\bm{y},\\bm{y}\u003e\\) 向量的范数\n设\\(n\\)维向量\\(\\bm{x}=[x_1,x_2,\\cdots,x_n]^T\\)，称\n\\[||\\bm{x}||=\\sqrt{\\bm{x}^T\\bm{x}}=\\sqrt{\u003c\\bm{x},\\bm{x}\u003e}=\\sqrt{x_1^2+x_2^2+\\cdots+x_n^2} \\]\n为向量\\(\\bm{x}\\)的范数。\n范数具有以下性质\n\\(||\\bm{x}||\\ge0,||\\bm{x}||=0\\)当且仅当\\(\\bm{x}=\\bm{0}\\) \\(||k\\bm{x}||=|k|||\\bm{x}||\\)，k为实数 \\(||\\bm{x}+\\bm{y}||\\leq||\\bm{x}||+||\\bm{y}||\\) 向量的夹角与正交\n设\\(\\bm{x,y}\\)是\\(n\\)维非零向量，称\n\\[\\theta=\\arccos\\frac{\\bm{x}^T\\bm{y}}{||\\bm{x}||||\\bm{y}||}=\\arccos\\frac{\u003c\\bm{x},\\bm{y}\u003e}{||\\bm{x}||||\\bm{y}||} \\]\n为向量\\(\\bm{x,y}\\)的夹角。特别的，当\\(\u003c\\bm{x},\\bm{y}\u003e=0时\\)，\\(\\theta=\\pm\\frac{\\pi}{2}\\)，称两向量正交（或垂直）。\n两两正交的向量组称为正交向量组。由单位向量构成的正交向量组称为标准（规范）标准正交组\n有如下定理：\n不含零向量的正交向量组必线性无关。 施密特正交化方法\n设向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)线性无关，令\n\\[\\bm{\\beta}_1=\\bm{\\alpha}_1\\\\ \\bm{\\beta}_2=\\bm{\\alpha}_2-\\frac{\u003c\\bm{\\alpha}_2,\\bm{\\beta}_1\u003e}{\u003c\\bm{\\beta}_1,\\bm{\\beta}_1\u003e}\\bm{\\beta}_1\\\\ \\bm{\\beta}_3=\\bm{\\alpha}_3-\\frac{\u003c\\bm{\\alpha}_3,\\bm{\\beta}_1\u003e}{\u003c\\bm{\\beta}_1,\\bm{\\beta}_1\u003e}\\bm{\\beta}_1-\\frac{\u003c\\bm{\\alpha}_3,\\bm{\\beta}_2\u003e}{\u003c\\bm{\\beta}_2,\\bm{\\beta}_2\u003e}\\bm{\\beta}_2\\\\ \\cdots\\\\ \\bm{\\beta}_m=\\bm{\\alpha}_m-\\sum_{j=1}^{m-1}\\frac{\u003c\\bm{\\alpha}_m,\\bm{\\beta}_j\u003e}{\u003c\\bm{\\beta}_j,\\bm{\\beta}_j\u003e}\\bm{\\beta}_j \\]\n则\\(\\bm{\\beta}_1,\\bm{\\beta}_2,\\cdots,\\bm{\\beta}_m\\)是与\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)等价的正交向量组\n若进一步单位化，即令\\(\\bm{\\eta}_j=\\frac{\\bm{\\beta}j}{||\\bm{\\beta}_j||}\\)，则\\(\\bm{\\eta}_1,\\bm{\\eta}_2,\\cdots,\\bm{\\eta}_m\\)是一个与\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)等价的标准正交向量组.\n正交矩阵\n设\\(\\bm{A}\\)为\\(n\\)阶方阵，若满足\\(\\bm{A}^T\\bm{A}=\\bm{E}\\)，则称\\(\\bm{A}\\)为正交矩阵。\n有如下性质：\n若\\(\\bm{A}\\)为正交矩阵，则\\(\\bm{A}^T=\\bm{A}^{-1}\\) 若\\(\\bm{A}\\)为正交矩阵，则\\(\\bm{A}^T\\)和\\(\\bm{A}^{-1}\\)和\\(\\bm{A}^{*}\\)也为正交矩阵 若\\(\\bm{A},\\bm{B}\\)为\\(n\\)阶正交矩阵，则\\(\\bm{AB}\\)也为正交矩阵 若\\(\\bm{A}\\)为正交矩阵，则\\(|\\bm{A}|=\\pm1\\) 有如下定理：\n\\(n\\)阶方阵\\(\\bm{A}\\)为正交矩阵的充要条件是\\(\\bm{A}\\)的列（行）向量组是标准向量组。\n基、维数与坐标 向量空间的基与维数 设\\(\\bm{V}\\)是向量空间，如果向量\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\in\\bm{V}\\)，满足\n\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)线性无关 \\(\\bm{V}\\)中任一向量都可以由\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)线性表示 则称向量组\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)是向量空间\\(\\bm{V}\\)的一组基，\\(r\\)称为向量空间的维数，记为\\(dim\\bm{V}=r\\)，规定零向量构成的向量空间的维数为0.\n类似的还有正交基和标准（规范）正交基的概念。\n向量的坐标 设\\(\\bm{V}\\)是\\(r\\)维向量空间，\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)是\\(\\bm{V}\\)的一组基，则\\(\\bm{V}\\)中的任一向量\\(\\bm{x}\\)可由\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)唯一线性表示为\\(\\bm{x}=x_1\\bm{\\alpha}_1+\\cdots+x_r\\bm{\\alpha}_r\\)，数组\\(x_1,x_2,\\cdots,x_r\\)称为向量\\(\\bm{x}\\)在基\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)下的坐标。\n过渡矩阵与基变换公式\n设\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_r\\)和\\(\\bm{\\beta}_1,\\bm{\\beta}_2,\\cdots,\\bm{\\beta}_r\\)是\\(r\\)维向量空间\\(\\bm{V}\\)的两组基，则两个向量组等价，从而有\\(\\bm{\\beta}_j=k_{1j}\\bm{\\alpha}_1+\\cdots+k_{rj}\\bm{\\alpha}_r\\)，即\n\\[[\\bm{\\beta}_1,\\cdots,\\bm{\\beta}_r]=[\\bm{\\alpha}_1,\\cdots,\\bm{\\alpha}_r] \\begin{bmatrix} k_{11} \u0026 \\cdots \u0026 k_{1r}\\\\ \\vdots \u0026 \u0026 \\vdots\\\\ k_{r1} \u0026 \\cdots \u0026 k_{rr} \\end{bmatrix} =[\\bm{\\alpha}_1,\\cdots,\\bm{\\alpha}_r]\\bm{K} \\]\n称\\(\\bm{K}\\)是由\\(\\bm{A}\\)到\\(\\bm{B}\\)的过度矩阵，上式为基变换公式。另外\\(\\bm{K}\\)一定是可逆矩阵。\n坐标变换公式\n设\\(\\bm{\\alpha}\\)在两组基\\(\\bm{A,B}\\)下的坐标分别为\\([x_1,\\cdots,x_r]^T\\)和\\([y_1,\\cdots,y_r]^T\\)，则有\n\\[\\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_r \\end{bmatrix} =\\bm{K} \\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_r \\end{bmatrix} or \\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_r \\end{bmatrix} =\\bm{K}^{-1} \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_r \\end{bmatrix} \\]\n一般有\\(\\bm{K}=\\bm{A}^{-1}\\bm{B}\\)\n线性方程组 解法 高斯消元法 即通过对增广矩阵进行初等行变换（只能是行变换），化为简单的形式进行求解。\n克莱默法则 见前\n性质定理 齐次线性方程组\\(\\bold{A}_{m\\times n}\\bold{x=0}\\)有非零解的充要条件是\\(R(\\bold{A})=r\u003c n\\)，且有无穷多解，自由量为\\(n-r\\)个（解空间的维数为\\(n-r\\)）。这个充要条件可以替换为\\(|\\bm A|=0\\)及其他等价命题。\n非齐次线性方程组\\(\\bold{A}_{m\\times n}\\bold{x=b}\\)有解的充要条件是\\(R(\\bold{A})=R(\\~\\bold{A})=r\\)，且当\n\\(r=n\\)时有唯一解，称为适定线性方程组 \\(r\u003c n\\)时有无穷多解，自由量是\\(n-r\\)个，称为欠定线性方程组 线性方程组解的结构 齐次情况 设\\(\\bm{\\xi}_1,\\bm{\\xi}_2,\\cdots,\\bm{\\xi}_t\\)是\\(\\bm{Ax=0}\\)的解，则\\(c_1\\bm{\\xi}_1+c_2\\bm{\\xi}_2+\\cdots+c_t\\bm{\\xi}_t\\)也是解，\\(c_i\\)为任意常数。\n齐次线性方程组\\(\\bm{Ax=0}\\)的解空间的一组基\\(\\bm{\\xi}_1,\\bm{\\xi}_2,\\cdots,\\bm{\\xi}_{n-r}\\)也称为方程组的一个基础解系。\n换言之，基础解系\\(\\bm{\\xi}_1,\\bm{\\xi}_2,\\cdots,\\bm{\\xi}_{n-r}\\)是\\(\\bm{Ax=0}\\)的解向量，且满足\n\\(\\bm{\\xi}_1,\\bm{\\xi}_2,\\cdots,\\bm{\\xi}_{n-r}\\)线性无关 \\(\\bm{Ax=0}\\)的任一解都可由\\(\\bm{\\xi}_1,\\bm{\\xi}_2,\\cdots,\\bm{\\xi}_{n-r}\\)线性表示 通过基础解系可以写出通解为\\(\\bm{x}=c_1\\bm{\\xi}_1+c_2\\bm{\\xi}_2+\\cdots+c_{n-r}\\bm{\\xi}_{n-r}\\)，\\(c_i\\)为任意常数。\n非齐次情况 有如下性质：\n设\\(\\bm{x}=\\bm{\\eta}_1+\\bm{\\eta}_2+\\cdots+\\bm{\\eta}_{t}\\)为\\(\\bm{Ax=b}\\)的解，令\\(\\bm{\\eta}=c_1\\bm{\\eta}_1+c_2\\bm{\\eta}_2+\\cdots+c_{t}\\bm{\\eta}_{t}\\)，当\\(c_1+\\cdots+c_t=0\\)时，\\(\\bm{\\eta}\\)为\\(\\bm{Ax=0}\\)的解，当\\(c_1+\\cdots+c_t=1\\)时\\(\\bm{\\eta}\\)为\\(\\bm{Ax=b}\\)的解 设\\(\\bm\\xi\\)为\\(\\bm{Ax=0}\\)的解，\\(\\bm\\eta\\)为\\(\\bm{Ax=b}\\)的解，则\\(\\bm{x=\\xi+\\eta}\\)仍为\\(\\bm{Ax=b}\\)的解。 非齐次线性方程组的解集关于加法和数乘不封闭，因此不构成向量空间 由此可知，\\(\\bm{Ax=b}(R(\\bm{A})=R(\\~{\\bm{A}})=r\\)的通解为\n\\[\\bm x=k_1\\bm{\\xi}_1+\\cdots+k_{n-r}\\bm{\\xi}_{n-r}+\\bm\\eta^* \\]\n其中\\(\\bm{x}=\\bm{\\xi}_1+\\bm{\\xi}_2+\\cdots+\\bm{\\xi}_{n-r}\\)为导出组\\(\\bm{Ax=0}\\)的一个基础解系，\\(\\bm\\eta^*\\)为\\(\\bm{Ax=b}\\)的任意一个解，称为特解。\n相似矩阵与二次型 特征值和特征向量 设\\(\\bm{A}\\)为\\(n\\)阶矩阵，如果存在数\\(\\lambda\\)和\\(n\\)维非零（注意非零）列向量\\(\\bm\\alpha\\)使得\n\\[\\bm A\\bm\\alpha=\\lambda\\bm\\alpha \\]\n则称\\(\\lambda\\)为\\(\\bm A\\)的特征值，\\(\\bm\\alpha\\)为\\(\\bm A\\)对于这个\\(\\lambda\\)的特征向量。\n由上式可知，\\(\\bm\\alpha\\)必是如下方程的非零解\n\\[(\\lambda\\bm E-\\bm A)\\bm x=\\bm 0 \\]\n显然有非零解当且仅当\\(|\\lambda\\bm E-\\bm A|=0\\)，\\(\\lambda\\bm E-\\bm A\\)称为特征矩阵，\\(|\\lambda\\bm E-\\bm A|\\)称为特征多项式，\\(|\\lambda\\bm E-\\bm A|=0\\)称为特征方程。\n特征值和特征向量的求解步骤\n求\\(|\\lambda\\bm E-\\bm A|=0\\)的全体根，记为\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_n\\) 对于每个特征值\\(\\lambda_i\\)，求出对应其次线性方程组\\((\\lambda_i\\bm E-\\bm A)\\bm x=\\bm0\\)的一个基础解系\\(\\bm{\\alpha}_1,\\cdots,\\bm{\\alpha}_s\\)，并以此求出\\(\\lambda_i\\)对应的全部特征向量\\(k_1\\bm{\\alpha}_1,\\cdots,k_s\\bm{\\alpha}_s\\)。其中\\(k_1,\\cdots,k_s\\)是任意不全为零的常数。 特征值和特征向量的性质 设\\(\\lambda\\)为\\(\\bm A\\)的任一特征值，\\(\\bm\\alpha\\)为其对应的特征向量，则\\(f(\\lambda)\\)是\\(f(\\bm A)\\)的特征值，其对应的特征向量还是\\(\\bm\\alpha\\)，其中\\(f(x)\\)是\\(x\\)的\\(m\\)次多项式。\n设\\(\\lambda\\)为\\(\\bm A\\)的任一非零特征值，\\(\\bm\\alpha\\)为其对应的特征向量，则\\(\\bm A^*\\)的特征值为\\(|\\bm A|/\\lambda\\)。特征向量仍为\\(\\bm\\alpha\\)\n若矩阵\\(\\bm A\\)可逆，则\\(1/\\lambda\\)是\\(A^{-1}\\)的特征值。特征向量仍为\\(\\bm\\alpha\\)\n转置矩阵由于行列式不变，所以特征值不变。但是特征向量并不一定一样。\n设\\(n\\)阶矩阵\\(\\bm A\\)的\\(n\\)个特征值为\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_n\\)（重根按重数计算），则\n\\(\\lambda_1+\\lambda_2+\\cdots+\\lambda_n=a_{11}+a_{22}+\\cdots+a_{nn}=tr(\\bm A)\\)，\\(tr(\\bm A)\\)称之为矩阵的迹 \\(\\lambda_1\\lambda_2\\cdots\\lambda_n=|\\bm A|\\) 矩阵可逆\\(\\Leftrightarrow\\)所有特征值均非0\n若\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_m\\)是\\(\\bm A\\)的互不相同的特征值，\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)是对应的特征向量，则\\(\\bm{\\alpha}_1,\\bm{\\alpha}_2,\\cdots,\\bm{\\alpha}_m\\)线性无关\n设\\(\\lambda\\)是\\(k\\)重特征值，对于\\(\\lambda\\)的线性无关的特征向量的最大个数为\\(l\\)，则\\(k\\ge l\\)\n相似矩阵 相似矩阵的定义和性质 设\\(\\bm{A,B}\\)为\\(n\\)阶矩阵，若存在\\(n\\)阶可逆矩阵\\(\\bm P\\)，使得\n\\[\\bm P^{-1}\\bm A\\bm P=\\bm B \\]\n则称\\(\\bm A\\)与\\(\\bm B\\)相似，记作\\(\\bm A\\sim \\bm B\\)\n具有以下性质：自反性、传递性、对称性。\n以及\n如果两矩阵相似，则具有相同的特征多项式，从而有相同的特征值。但特征向量不一定相同。并且特征多项式相同并不能推出两矩阵相似。 两矩阵相似，则具有相同的秩。 两矩阵相似，则具有相同的迹。 两矩阵相似，则具有相同的行列式。 若\\(\\bm A\\sim \\bm B\\)，且\\(\\bm A\\)可逆，则\\(\\bm B\\)可逆，并且有\\(\\bm A^{-1}\\sim \\bm B^{-1}\\) 若\\(\\bm A\\sim \\bm B\\)，则对任一多项式\\(g(x)\\)，有\\(g(\\bm A)\\sim g(\\bm B)\\) 矩阵可对角化的条件 设\\(\\bm A\\)为\\(n\\)阶矩阵，如果存在一个\\(n\\)阶可逆矩阵\\(\\bm P\\)，使得\\(\\bm P^{-1}\\bm A\\bm P\\)为对角矩阵，则称\\(\\bm A\\)可对角化。\n有如下定理：\n\\(\\bm A\\)可对角化的充要条件是\\(\\bm A\\)有\\(n\\)个线性无关的特征向量。 \\(n\\)阶矩阵\\(\\bm A\\)的\\(n\\)个特征值互不相同\\(\\Rightarrow\\bm A\\)可对角化 \\(\\bm A\\)可对角化的充要条件是对于\\(\\bm A\\)的每个\\(k\\)重特征值\\(\\lambda\\)，都有\\(R(\\lambda\\bm E-\\bm A)=n-k\\) 实对称矩阵的对角化 实对称矩阵一定能对角化\n并且有如下定理：\n实对称矩阵的特征值都为实数 实对称矩阵的不同特征值所对应的特征向量必正交 设\\(\\bm A\\)为\\(n\\)阶实对称矩阵，则存在正交矩阵\\(\\bm Q\\)使得 \\[\\bm Q^T\\bm{AQ}=\\bm Q^{-1}\\bm{AQ}= \\begin{bmatrix} \\lambda_1 \u0026 \u0026 \u0026 \\\\ \u0026 \\lambda_2 \u0026 \u0026 \\\\ \u0026 \u0026 \\ddots \u0026 \\\\ \u0026 \u0026 \u0026 \\lambda_n \\end{bmatrix} \\]\n其中\\(\\lambda_i\\)为\\(\\bm A\\)的特征值。\n设\\(\\bm A\\)为\\(n\\)阶实对称矩阵，\\(\\lambda\\)为\\(\\bm A\\)的\\(k\\)重特征值，则\\(\\bm A\\)必有\\(k\\)个对于特征值\\(\\lambda\\)的线性无关的特征向量 求解对角阵的方法\n求\\(\\bm A\\)的全部不同特征值\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_s\\) 对于每个不同的特征值，求出齐次线性方程组\\((\\lambda_i\\bm E-\\bm A)\\bm x=\\bm 0\\)的基础解系，将其正交化、单位化 将所得的正交单位特征向量作为列向量组构成正交矩阵（注意特征向量和特征值的顺序）\\(\\bm Q\\)，则\\(\\bm Q^T\\bm{AQ}=\\bm Q^{-1}\\bm{AQ}=diag(\\lambda_1,\\lambda_2,\\cdots,\\lambda_n)\\) 二次型及其标准型 n元二次型的定义如下 \\[f(x_1,\\cdots,x_n)=a_{11}x_1^2+2a_{12}x_1x_2+\\cdots+2a_{1n}x_1x_n+a_{22}x_2^2+2a_{2n}x_2x_n+\\cdots+a_{nn}x_{n}^2\\\\= (x_1,\\cdots,x_n) \\begin{bmatrix} a_{11}x_1+a_{12}x_2+\\cdots+a_{1n}x_n\\\\ a_{21}x_1+a_{22}x_2+\\cdots+a_{2n}x_n\\\\ \\vdots\\\\ a_{n1}x_1+a_{n2}x_2+\\cdots+a_{nn}x_n \\end{bmatrix}\\\\= (x_1,\\cdots,x_n) \\begin{bmatrix} a_{11} \u0026 a_{12} \u0026 \\cdots \u0026 a_{1n}\\\\ a_{21} \u0026 a_{22} \u0026 \\cdots \u0026 a_{2n}\\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots\\\\ a_{n1} \u0026 a_{n2} \u0026 \\cdots \u0026 a_{nn} \\end{bmatrix} \\begin{bmatrix} x_1\\\\ x_2\\\\ \\vdots\\\\ x_n \\end{bmatrix} \\]\n亦可表示为\\(f(\\bm x)=\\bm x^T\\bm {Ax}\\)。其中\\(\\bm A^T=\\bm A\\)为实对称矩阵。\\(\\bm A\\)称为二次型式的矩阵，其秩称为二次型式的秩。\n仅含平方项的二次型称之为标准型。\n显然\\(\\bm x^T\\bm {Ax}\\)为标准型的充要条件是\\(\\bm A\\)为对角矩阵。\n\\(\\bm A\\)可以直接读出，先写一个对角矩阵，对角线的元素值即为平方项的系数，对角线以上的元素找对应项的系数除以2，之后再将对角线以上的元素“对称地”写到对角线以下的元素\n矩阵的合同 设\\(\\bm{A,B}\\)为\\(n\\)阶矩阵，若存在\\(n\\)阶可逆矩阵\\(\\bm C\\)，使得\\(\\bm C^{T}\\bm A\\bm C=\\bm B\\)则称\\(\\bm A\\)与\\(\\bm B\\)合同，记作\\(\\bm A\\simeq \\bm B\\)\n具有以下性质：自反性、传递性、对称性。\n以及若\\(\\bm{A,B}\\)合同，且\\(\\bm A\\)为对称矩阵，则\\(\\bm B\\)也为对称矩阵，且\\(R(\\bm A)=R(\\bm B)\\)\n化二次型为标准型 有三种方法\n1.正交变换法\n若\\(\\bm Q\\)为正交矩阵，则称线性变换\\(\\bm{x=Qy}\\)为正交变换。\n对于任意\\(n\\)元二次型\n\\[f(x_1,x_2,\\cdots,x_n)=\\bm{x}^T\\bm{Ax} \\]\n总存在正交变换\\(\\bm{x=Qy}\\)，使得\n\\[f(x_1,x_2,\\cdots,x_n)\\xlongequal{\\bm{x=Qy}}\\lambda_1y_1^2+\\lambda_2y_2^2+\\cdots+\\lambda_ny_n^2 \\]\n其中\\(\\lambda_1,\\lambda_2,\\cdots,\\lambda_n\\)为\\(\\bm A\\)的全部特征值。\n\\(\\bm Q\\)的计算方法：\n求\\(\\bm A\\)的特征向量 将所有特征向量正交化、单位化 再将得到的向量组成列向量组，即为\\(\\bm Q\\)。注意组合的顺序 2.配方法\n例如：\n\\[f(x_1,x_2.x_3)=2(x_1^2+2x_1x_2+4x_1x_3)+x_2^2+14x_2x_3-x_3^2\\\\ =2(x_1+x_2+2x_3)^2-(x_2-3x_3)^2 \\]\n令\n\\[\\left\\{\\begin{matrix} y_1=x_1+x_2+2x_3 \\\\ y_2=x_2-3x_3 \\\\ y_3=x_3 \\end{matrix}\\right. \\]\n则有\n\\[\\left\\{\\begin{matrix} x_1=y_1-y_2-5y_3 \\\\ x_2=y_2+3y_3 \\\\ x_3=y_3 \\end{matrix}\\right. \\]\n即\n\\[\\bm x= \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} 1 \u0026 -1 \u0026 -5 \\\\ 0 \u0026 1 \u0026 3 \\\\ 0 \u0026 0 \u0026 1 \\end{bmatrix} =\\bm{Qy} \\]\n3.初等变换法\n对\\(2n\\times n\\)矩阵实施一次初等列变换及相应的初等行变换，直至把\\(\\bm A\\)化为对角矩阵\\(\\bm \\Lambda\\)，即\n\\[\\begin{bmatrix} \\bm A \\\\ \\bm E \\end{bmatrix} \\sim \\begin{bmatrix} \\bm \\Lambda \\\\ \\bm Q \\end{bmatrix} \\]\n且有\\(\\bm{Q}^T\\bm{AQ}=\\bm\\Lambda\\)\n二次型的规范型 设实二次型\\(f(x_1,x_2,\\cdots,x_n)\\)经过可逆线性变换转化为标准型\n\\[f(x_1,x_2,\\cdots,x_n)=d_1y_1^2+\\cdots+d_py_p^2-d_{p+1}y_{p+1}^2-\\cdots-d_ry_r^2 \\]\n其中\\(r\\)是二次型的秩，\\(d_i\u003e0\\)，则可以再做一次线性变换\n\\[\\left\\{\\begin{matrix} y_1=\\frac{1}{\\sqrt{d_1}}z_1 \\\\ \\vdots \\\\ y_r = \\frac{1}{\\sqrt{d_r}}z_r \\\\ y_{r+1}=z_{r+1} \\\\ \\vdots\\\\ y_n=z_n \\end{matrix}\\right. \\]\n则得到\n\\[f(x_1,x_2,\\cdots,x_n)=z_1^2+\\cdots+z_p^2-z_{p+1}^2-\\cdots-z_r^2 \\]\n称为规范标准型，简称规范型。\n二次型的标准型是不唯一的，但规范标准型是唯一的（并且对于实二次型来说一定存在规范型）。这也被称作惯性定律。\n标准型中正平方项的个数\\(p\\)称为正惯性指数，负平方项的个数\\(q\\)称为负惯性指数。\\(p-q\\)称为二次型的符号差。\n并且有如下定理\n定理\n任何实对称矩阵必合同于如下形式的对角矩阵\n\\[\\begin{bmatrix} \\bm{E}_p \u0026 \u0026 \\\\ \u0026 -\\bm{E}_q \u0026 \\\\ \u0026 \u0026 \\bm{0} \\end{bmatrix} \\]\n正定二次型 对于任何非零（强调非零）向量\\(\\bm{x}=(x_1,\\cdots,x_n)\\)都有\n\\[f(x_1,\\cdots,x_n)=\\bm{x}^T\\bm{Ax}\u003e0(\u003c0) \\]\n则称\\(f\\)是正定（负定）二次型，\\(\\bm{A}\\)称为正定（负定）矩阵。\n如果上式取\\(\\ge(\\leq)\\)，则为半正定（半负定）二次型。\n如果\\(f\\)既不是半正定的，也不是半负定的，则称为不定的。\n有如下定理\n定理1\n可逆的线性变换不改变二次型的正定性\n定理2\n\\(\\bm{A,B}\\)合同，则\\(\\bm{A}\\)正定的充要条件是\\(\\bm{B}\\)正定。\n定理3\n若\\(\\bm A\\)是\\(n\\)阶正定矩阵，则\n\\(\\bm A\\)的主对角线元\\(a_{ii}\u003e0\\) \\(|\\bm A|\u003e0\\) \\(k\\)阶顺序主子式\n设\\(\\bm A\\)为\\(n\\)阶方阵，依次取\\(\\bm A\\)的前\\(k\\)行与前\\(k\\)列所构成的子式的行列式称为矩阵\\(\\bm A\\)的\\(k\\)阶顺序主子式。\n显然\\(n\\)阶方阵\\(\\bm A\\)的顺序主子式有且只有\\(n\\)个。\n有如下定理\n霍尔维茨定理\n\\(n\\)元实二次型\\(f=\\bm{x}^T\\bm{Ax}\\)正定的充要条件是\\(\\bm A\\)的\\(n\\)个顺序主子式均大于零。\n","date":"2022-06-04T12:11:53+08:00","image":"https://kegalas.top/p/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E6%95%B4%E7%90%86/cover_hu670730d9bdf70a44294ca8d2a00a2ced_185066_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E6%95%B4%E7%90%86/","title":"线性代数整理"},{"content":"[TOC]\n向量代数与空间解析几何 方向角与方向余弦 非零向量\\(\\bold{r}\\)与三条坐标轴的夹角\\(\\alpha\\)、\\(\\beta\\)、\\(\\gamma\\)称为向量\\(\\bold{r}\\)的方向角。设\\(\\overrightarrow{OM}=\\bold{r}=(x,y,z)\\)，则有\n\\[(cos\\alpha,cos\\beta,cos\\gamma)=\\left(\\frac{x}{|\\bold{r}|},\\frac{y}{|\\bold{r}|},\\frac{z}{|\\bold{r}|}\\right)=\\frac{1}{|\\bold{r}|}(x,y,z)=\\frac{\\bold{r}}{|\\bold{r}|}=\\bold{e} \\]\n\\(cos\\alpha,cos\\beta,cos\\gamma\\)称为向量\\(\\bold{r}\\)的方向余弦。并且有\n\\[cos^2\\alpha+cos^2\\beta+cos^2\\gamma = 1 \\]\n数量积的运算规律 交换律 \\(\\bold{a}\\cdot\\bold{b}=\\bold{b}\\cdot\\bold{a}\\)\n分配律 \\((\\bold{a+b})\\cdot \\bold{c}=\\bold{a\\cdot c+b\\cdot c}\\)\n如下的结合律 \\((\\lambda \\bold{a})\\cdot\\bold{b}=\\lambda(\\bold{a\\cdot b})\\)，\\(\\lambda\\)为数\n向量积的运算规律 \\(\\bold{b\\times a=-a\\times b}\\)\n分配律 \\(\\bold{(a+b)\\times c=a\\times c+b\\times c}\\)\n如下的结合律 \\((\\lambda \\bold{a})\\times \\bold{b}=\\lambda(\\bold{a\\times b})\\)，\\(\\lambda\\)为数\n平面的点法式方程 当平面\\(\\Pi\\)上一点\\(M_0(x_0,y_0,z_0)\\)和它的一个法线向量\\(\\bold{n}=(A,B,C)\\)已知时，有平面的点法式方程：\n\\[A(x-x_0)+B(y-y_0)+C(z-z_0)=0 \\]\n平面的一般方程 \\[Ax+By+Cz+D=0 \\]\n其中这个平面的法向量为\\(\\bold{n}=(A,B,C)\\)\n平面的截距式方程 \\[\\frac{x}{a}+\\frac{y}{b}+\\frac{z}{c}=1 \\]\n其中\\(a,b,c\\)分别为\\(x,y,z\\)轴上的截距\n两平面夹角 \\[cos\\theta=\\frac{|A_1A_2+B_1B_2+C_1C_2|}{\\sqrt{A_1^2+B_1^2+C_1^2}\\sqrt{A_2^2+B_2^2+C_2^2}} \\]\n点到平面距离公式 点\\(P_0(x_0,y_0,z_0)\\)到平面\\(Ax+By+Cz+D=0\\)的距离公式\n\\[d=\\frac{|Ax_0+By_0+Cz_0+D|}{\\sqrt{A^2+B^2+C^2}} \\]\n空间直线的一般方程 \\[\\left\\{\\begin{matrix} A_1x+B_1y+C_1z+D_1=0\\\\ A_2x+B_2y+C_2z+D_2=0 \\end{matrix}\\right. \\]\n即两个平面的交线\n另外两个平面的法向量的向量积可以算出直线的切向量\n平面束方程 由上述空间直线方程可知，通过这一直线的平面还有\n\\[\\lambda(A_1x+B_1y+C_1z+D_1)+\\mu(A_2x+B_2y+C_2z+D_2)=0 \\]\n其中\\(\\lambda=1\\)时\n\\[(A_1x+B_1y+C_1z+D_1)+\\mu(A_2x+B_2y+C_2z+D_2)=0 \\]\n表示除了\\(A_2x+B_2y+C_2z+D_2=0\\)，之外的过直线的平面束。\n空间直线的对称式方程(点向式方程) 若已知直线过一点\\(M_0(x_0, y_0, z_0)\\)和它的一个方向向量\\(\\bold{s}=(m,n,p)\\)。则有方程\n\\[\\frac{x-x_0}{m}=\\frac{y-y_0}{n}=\\frac{z-z_0}{p} \\]\n空间直线的参数方程 若设\n\\[\\frac{x-x_0}{m}=\\frac{y-y_0}{n}=\\frac{z-z_0}{p}=t \\]\n则有\n\\[\\left\\{\\begin{matrix} x=x_0+mt \\\\ y=y_0+nt \\\\ z=z_0+pt \\end{matrix}\\right. \\]\n两直线的夹角 设两直线方向向量分别为\\(\\bold{s_1}=(m_1,n_1,p_1)\\)和\\(\\bold{s_2}=(m_2,n_2,p_2)\\)\n\\[cos\\varphi = \\frac{|m_1m_2+n_1n_2+p_1p_2|}{\\sqrt{m_1^2+n_1^2+p_1^2}\\sqrt{m_2^2+n_2^2+p_2^2}} \\]\n直线与平面的夹角 设直线方向向量和平面法向量分别为\\(\\bold{s}=(m,n,p)\\)和\\(\\bold{n}=(A,B,C)\\)\n\\[sin\\varphi = \\frac{|Am+Bn+Cp|}{\\sqrt{A^2+B^2+C^2}\\sqrt{m^2+n^2+p^2}} \\]\n旋转曲面 设在\\(yOz\\)坐标面上有一已知曲线\\(f(y,z)=0\\)\n则把这个曲线绕z轴旋转一周，得到的曲面为\\(f(\\pm\\sqrt{x^2+y^2},z)=0\\)\n绕y轴旋转则为\\(f(y,\\pm\\sqrt{x^2+z^2})=0\\)\n在其他坐标面上的曲线类似。\n二次曲面举例 椭圆锥面 \\[\\frac{x^2}{a^2}+\\frac{y^2}{b^2}=z^2 \\]\n8-47.jpg\r椭球面 \\[\\frac{x^2}{a^2}+\\frac{y^2}{b^2}+\\frac{z^2}{c^2}=1 \\]\n8-49.jpg\r单叶双曲面 \\[\\frac{x^2}{a^2}+\\frac{y^2}{b^2}-\\frac{z^2}{c^2}=1 \\]\n8-40.jpg\r双叶双曲面 \\[\\frac{x^2}{a^2}-\\frac{y^2}{b^2}-\\frac{z^2}{c^2}=1 \\]\n8-41.jpg\r椭圆抛物面 \\[\\frac{x^2}{a^2}+\\frac{y^2}{b^2}=z \\]\n8-50\r双曲抛物面 \\[\\frac{x^2}{a^2}-\\frac{y^2}{b^2}=z \\]\n8-51\r空间曲线及其方程 一般方程 即两个曲面的交线\n\\[\\left\\{\\begin{matrix} F(x,y,z) = 0 \\\\ G(x,y,z) = 0 \\end{matrix}\\right. \\]\n参数方程 \\[\\left\\{\\begin{matrix} x=x(t) \\\\ y=y(t) \\\\ z=z(t) \\end{matrix}\\right. \\]\n多元函数微分法及其应用 多元函数的极限 注意极限存在，当且仅当从各个方向趋近那个点时得到的值存在并相等。\n例如\\(f(x,y)=\\frac{xy}{x^2+y^2},x^2+y^2\\neq 0;f(x,y)=0,x^2+y^2=0\\)，有沿x轴y轴趋近\\((0,0)\\)极限都为0，但沿直线\\(y=kx\\)趋近时极限随\\(k\\)变化。故极限不存在。\n偏导数 注意有时利用定义求解偏导数会更优\n例如关于\\(x\\)的偏导数\n\\[\\lim_{\\Delta x \\to 0}\\frac{f(x_0+\\Delta x,y_0)-f(x_0,y_0)}{\\Delta x} \\]\n在如\\(x_0=0,y_0=0\\)或者其他性质比较好的点，会更容易求。\n高阶偏导数 注意分母上，求导顺序为从左到右。\n如果函数\\(z=f(x,y)\\)的两个二阶混合偏导数\\(\\frac{\\partial^2z}{\\partial y\\partial x}\\)及\\(\\frac{\\partial^2z}{\\partial x\\partial y}\\)在区域\\(D\\)内连续，那么在该区域内这两个二阶混合偏导数必相等。\n全微分 必要条件 如果函数\\(z=f(x,y)\\)在点\\((x,y)\\)可微分（蕴含着函数在该点上连续），那么该函数在点\\((x,y)\\)的偏导数\\(\\frac{\\partial z}{\\partial x}\\)与\\(\\frac{\\partial z}{\\partial y}\\)必定存在，且该函数在该点的全微分为\n\\[dz=\\frac{\\partial z}{\\partial x}\\Delta x+\\frac{\\partial z}{\\partial y}\\Delta y \\]\n但这只是必要条件。\n形式上的全微分\\(\\Delta z\\)(和上文的\\(dz\\)一个意思)应该满足\n\\[\\frac{\\Delta z-[f_x(x_0,y_0)\\cdot\\Delta x+f_y(x_0,y_0)\\cdot\\Delta y]}{\\rho} \\]\n随着\\(\\rho\\to0\\)而趋于\\(0\\)。\n其中\n\\[\\rho=\\sqrt{(\\Delta x)^2+(\\Delta y)^2} \\]\n才能可微。\n充分条件 如果函数\\(z=f(x,y)\\)的偏导数\\(\\frac{\\partial z}{\\partial x}\\)、\\(\\frac{\\partial z}{\\partial y}\\)在\\((x,y)\\)连续，那么该函数在该点可微分。\n多元复合函数的求导法则 一元函数与多元函数复合的情形 如果函数\\(u=\\varphi(t)\\)及\\(v=\\psi(t)\\)都在点\\(t\\)可导，函数\\(z=f(u,v)\\)在对应点\\((u,v)\\)具有连续偏导数，那么复合函数\\(z=f[\\varphi(t),\\psi(t)]\\)在t可导，且有\n\\[\\frac{dz}{dt}=\\frac{\\partial z}{\\partial u}\\frac{du}{dt}+\\frac{\\partial z}{\\partial v}\\frac{dv}{dt} \\]\n多元函数与多元函数复合的情形 \\[u=\\varphi(x,y),v=\\psi(x,y),z=f(u,v) \\]\n若都在对应点\\((x,y)\\)具有连续偏导数，则\n\\[\\frac{\\partial z}{\\partial x}=\\frac{\\partial z}{\\partial u}\\frac{\\partial u}{\\partial x}+\\frac{\\partial z}{\\partial v}\\frac{\\partial v}{\\partial x} \\]\n\\[\\frac{\\partial z}{\\partial y}=\\frac{\\partial z}{\\partial u}\\frac{\\partial u}{\\partial y}+\\frac{\\partial z}{\\partial v}\\frac{\\partial v}{\\partial y} \\]\n混合复合 根据每个复合函数是否含有自变量\\(x,y\\)进行偏导，例如\n\\[u=\\varphi(x,y),v=\\psi(y),z=f(u,v) \\]\n则\n\\[\\frac{\\partial z}{\\partial x}=\\frac{\\partial z}{\\partial u}\\frac{\\partial u}{\\partial x} \\]\n\\[\\frac{\\partial z}{\\partial y}=\\frac{\\partial z}{\\partial u}\\frac{\\partial u}{\\partial y}+\\frac{\\partial z}{\\partial v}\\frac{d v}{d y} \\]\n如果有两层复合函数，则要求导至将\\(x,y\\)这样的自变量暴露出来。\n全微分形式的不变性 设函数\\(z=f(u,v)\\)具有连续偏导数，则有全微分\n\\[dz=\\frac{\\partial z}{\\partial u}du+\\frac{\\partial z}{\\partial v}dv \\]\n若有\\(u=\\varphi(x,y),v=\\psi(x,y)\\)，有\n\\[dz=\\frac{\\partial z}{\\partial x}dx+\\frac{\\partial z}{\\partial y}dy \\]\n显然可以算出\\(\\frac{\\partial z}{\\partial x},\\frac{\\partial z}{\\partial y}\\)，代入有\n\\[dz=\\frac{\\partial z}{\\partial u}du+\\frac{\\partial z}{\\partial v}dv \\]\n此为全微分形式的不变性。\n隐函数的求导公式 一个方程的情形 \\[F(x,y)=0 \\]\n\\[\\frac{dy}{dx}=-\\frac{F_x}{F_y} \\]\n条件：F在某点的某一邻域内具有连续偏导数，\\(F_y\\)在该点不为0\n\\[F(x,y,z)=0 \\]\n\\[\\frac{\\partial z}{\\partial x}=-\\frac{F_x}{F_z},\\frac{\\partial z}{\\partial y}=-\\frac{F_y}{F_z} \\]\n条件类似于上条。\n方程组的情形 考虑如下方程组\n\\[\\left\\{\\begin{matrix} F(x,y,u,v)=0\\\\ G(x,y,u,v)=0 \\end{matrix}\\right. \\]\n一般四个变量只能有两个变量独立变化\n即\n\\[u(x,y),v(x,y) \\]\n两边应用求导法则得\n\\[F_x+F_u\\frac{\\partial u}{\\partial x}+F_v\\frac{\\partial v}{\\partial x}=0 \\]\n\\[G_x+G_u\\frac{\\partial u}{\\partial x}+G_v\\frac{\\partial v}{\\partial x}=0 \\]\n解方程求出偏导数，求关于\\(y\\)的偏导数同理。\n多元函数积分学的几何应用 一元向量值函数及其导数 空间曲线\\(\\Gamma\\)的参数方程为\n\\[\\left\\{\\begin{matrix} x=\\varphi(t), \\\\ y=\\psi(t), \\\\ z=\\omega(t) \\end{matrix}\\right. t\\in[\\alpha,\\beta] \\]\n写成向量形式，则为\n\\[\\bold{r}=x\\bold{i}+y\\bold{j}+z\\bold{k} \\]\n\\[\\bold{f}(t)=\\varphi(t)\\bold{i}+\\psi(t)\\bold{j}+\\omega(t)\\bold{k} \\]\n所以有\\(\\bold{r=f}(t)\\)， \\(\\bold{r}\\)称为向量函数\n向量值导数如下：\n\\[\\bold{f}'(t_0)=\\lim_{\\Delta t\\to 0}\\frac{\\Delta \\bold{r}}{\\Delta t} =\\lim_{\\Delta t\\to 0}\\frac{\\bold{f}(t_0+\\Delta t)-\\bold{f}(t_0)}{\\Delta t} \\]\n或者如下计算：\n\\[\\bold{f}'(t_0)=\\bold{f_1}'(t_0)\\bold{i}+\\bold{f_2}'(t_0)\\bold j+ \\bold{f_3}'(t_0)\\bold k \\]\n空间曲线的切线与法平面 还是上面那个曲线\\(\\Gamma\\)，则切线方程为\n\\[\\frac{x-x_0}{\\varphi'(t_0)}= \\frac{y-y_0}{\\psi'(t_0)}= \\frac{z-z_0}{\\omega'(t_0)} \\]\n法平面方程为\n\\[\\varphi'(t_0)(x-x_0)+ \\psi'(t_0)(y-y_0)+ \\omega'(t_0)(z-z_0)=0 \\]\n若\\(\\Gamma\\)变为\n\\[\\left\\{\\begin{matrix} x=x \\\\ y=\\varphi(x) \\\\ z=\\psi(x) \\end{matrix}\\right. \\]\n则切线方程变为\n\\[\\frac{x-x_0}{1}= \\frac{y-y_0}{\\varphi'(x_0)}= \\frac{z-z_0}{\\psi'(x_0)} \\]\n法平面方程变为\n\\[(x-x_0)+ \\varphi'(x_0)(y-y_0)+ \\psi'(x_0)(z-z_0)=0 \\]\n曲线为方程组情形时（三个变量一般只有一个自由变量，所以直接将\\(y,z\\)替换为\\(\\varphi(x),\\psi(x)\\)）\n\\[F[x,\\varphi(x),\\psi(x)]=0 \\]\n\\[G[x,\\varphi(x),\\psi(x)]=0 \\]\n两边求对\\(x\\)的全导数\n\\[\\frac{\\partial F}{\\partial x}+\\frac{\\partial F}{\\partial y} \\frac{dy}{dx}+\\frac{\\partial F}{\\partial z}\\frac{dz}{dx}=0 \\]\n\\[\\frac{\\partial G}{\\partial x}+\\frac{\\partial G}{\\partial y} \\frac{dy}{dx}+\\frac{\\partial G}{\\partial z}\\frac{dz}{dx}=0 \\]\n解出\\(\\bold{T}=(1,\\frac{dy}{dx},\\frac{dz}{dx})\\)，即\\(\\bold{T}=(1,\\varphi'(x_0),\\psi'(x_0))\\)，就是在此点的切向量，代入可知切线与法平面方程\n曲面的切平面与法线 若曲面由\\(F(x,y,z)=0\\)隐性给出，则在点\\(M(x_0,y_0,z_0)\\)切平面方程为\n\\[F_x(x-x_0)+F_y(y-y_0)+F_z(z-z_0)=0 \\]\n其中各个偏导数都是在M点的偏导数，法线方程如下\n\\[\\frac{x-x_0}{F_x}=\\frac{y-y_0}{F_y}=\\frac{z-z_0}{F_z} \\]\n考虑曲面方程为\\(z=f(x,y)\\)，则可令\\(F(x,y,z)=f(x,y)-z\\)\n显然有\n\\[F_x(x,y,z)=f_x(x,y),F_y(x,y,z)=f_y(x,y),F_z(x,y,z)=-1 \\]\n切平面、法线方程类似于上。\n方向导数与梯度 方向导数：\n\\[\\frac{\\partial f}{\\partial l}\\bigg|_{(x_0,y_0)}= \\lim _{t\\to 0^+}\\frac{f(x_0+tcos\\alpha,y_0+tcos\\beta)-f(x_0,y_0)}{t} \\]\n如果函数\\(f(x,y)\\)在点\\(P_0(x_0,y_0)\\)可微分，那么函数在该点沿任一方向\\(l\\)的方向导数存在，且有\n\\[\\frac{\\partial f}{\\partial l}\\bigg|_{(x_0,y_0)}= f_x(x_0,y_0)cos\\alpha+f_y(x_0,y_0)cos\\beta \\]\n其中\\(cos\\alpha,cos\\beta\\)是方向\\(l\\)的方向余弦。\n梯度：\n\\[\\bold{grad}f(x_0,y_0)=\\nabla f(x_0,y_0)=f_x(x_0,y_0)\\bold{i}+ f_y(x_0,y_0)\\bold{j} \\]\n如果方向导数存在，则\n\\[\\frac{\\partial f}{\\partial l}\\bigg|_{(x_0,y_0)}= f_x(x_0,y_0)cos\\alpha+f_y(x_0,y_0)cos\\beta =\\nabla f(x_0,y_0)\\cdot \\bold{e}_l=|\\nabla f|cos\\theta \\]\n其中\n\\[\\theta=\u003c\\nabla f,\\bold{e}_l\u003e \\]\n多元函数的极值及其求法 必要条件 设函数\\(z=f(x,y)\\)在点\\((x_0,y_0)\\)具有偏导数，且在点\\((x_0,y_0)\\)处有极值，则有\n\\[f_x(x_0,y_0)=0,f_y(x_0,y_0)=0 \\]\n充分条件 设函数\\(z=f(x,y)\\)在点\\((x_0,y_0)\\)的某领域内连续且有一阶和二阶连续偏导数，又\\(f_x(x_0,y_0)=0,f_y(x_0,y_0)=0\\)，令\n\\[f_{xx}(x_0,y_0)=A,f_{xy}(x_0,y_0)=B,f_{yy}(x_0,y_0)=C \\]\n若\n\\(AC-B^2\u003e0\\)时具有极值，\\(A\u003c0\\)时有极大值，\\(A\u003e0\\)时有极小值；\n\\(AC-B^2\u003c0\\)时没有极值\n\\(AC-B^2=0\\)时可能有也可能没有，需要另作讨论。\n拉格朗日乘数法 要找函数\\(z=f(x,y)\\)在附加条件\\(\\varphi(x,y)=0\\)下的可能极值点，先设\n\\[L(x,y)=f(x,y)+\\lambda\\varphi(x,y) \\]\n令\n\\[\\left\\{\\begin{matrix} L_x=f_x+\\lambda\\varphi_x=0 \\\\ L_y=f_y+\\lambda\\varphi_y=0 \\\\ L_{\\lambda}=\\varphi=0 \\end{matrix}\\right. \\]\n解出\\(x,y,\\lambda\\)，代入函数\\(f\\)中求得可能的极值点。\n多个条件时，如多加一个\\(\\psi(x,y)=0\\)，则设方程\n\\[L(x,y)=f(x,y)+\\lambda\\varphi(x,y)+\\mu\\psi(x,y) \\]\n分别求\\(L_x=0,L_y=0,L_\\lambda=0,L\\mu=0\\)，代入原函数中求可能的极值点。\n重积分 二重积分的概念与性质 性质：\n设\\(\\alpha,\\beta\\)为常数，则 \\[\\iint\\limits_{D}[\\alpha f(x,y)+\\beta g(x,y)]d\\sigma= \\alpha\\iint\\limits_{D}f(x,y)d\\sigma+\\beta\\iint\\limits_{D}g(x,y)d\\sigma \\]\n如果闭区域\\(D\\)被有限条曲线分为有限个部分闭区域，那么在\\(D\\)上的二重积分等于在各部分闭区域上的二重积分的和 \\[\\iint\\limits_{D}f(x,y)d\\sigma= \\iint\\limits_{D_1}f(x,y)d\\sigma+\\iint\\limits_{D_2}f(x,y)d\\sigma \\]\n如果在\\(D\\)上，\\(f(x,y)=1\\)，\\(\\sigma\\)为\\(D\\)的面积，那么 \\[\\sigma=\\iint\\limits_{D}1\\cdot d\\sigma=\\iint\\limits_{D}d\\sigma \\]\n如果在\\(D\\)上，\\(f(x,y)\\leq g(x,y)\\)，那么有 \\[\\iint\\limits_{D}f(x,y)d\\sigma\\leq\\iint\\limits_{D}g(x,y)d\\sigma \\]\n特别的，有\n\\[\\left|\\iint\\limits_{D}f(x,y)d\\sigma\\right|\\leq \\iint\\limits_{D}|f(x,y)|d\\sigma \\]\n设\\(M\\)和\\(N\\)分别是\\(f(x,y)\\)在闭区域\\(D\\)上的最大值和最小值，\\(\\sigma\\)是\\(D\\)的面积，则有 \\[m\\sigma\\leq\\iint\\limits_{D}f(x,y)d\\sigma\\leq M\\sigma \\]\n设函数\\(f(x,y)\\)在闭区域D上连续，\\(\\sigma\\)是\\(D\\)的面积，则在\\(D\\)上至少存在一点\\((\\xi,\\eta)\\)，使得 \\[\\iint\\limits_{D}f(x,y)d\\sigma=f(\\xi,\\eta)\\sigma \\]\n二重积分的计算法 利用直角坐标计算二重积分 10-4\r在如图的区域中，积分上限为上方曲线，积分下限为下方曲线。\n\\[\\iint\\limits_{D}f(x,y)d\\sigma=\\int_a^bdx\\int_{\\varphi_1(x)} ^{\\varphi_2(x)}f(x,y)dy \\]\n10-6\r如图则，积分上限为右侧曲线，下限为左侧曲线。\n\\[\\iint\\limits_{D}f(x,y)d\\sigma=\\int_c^ddy\\int_{\\psi_1(y)} ^{\\psi_2(y)}f(x,y)dx \\]\n利用极坐标计算二重积分 有\n\\[x=\\rho cos\\theta \\]\n\\[y=\\rho sin\\theta \\]\n且有对于下图\n10-18\r\\[\\iint\\limits_{D}f(x,y)d\\sigma=\\iint\\limits_{D}f(\\rho cos\\theta, \\rho sin\\theta)\\rho d\\rho d\\theta \\]\n\\[=\\int_\\alpha^\\beta d\\theta\\int_{\\varphi_1(\\theta)} ^{\\varphi_2(\\theta)}f(\\rho cos\\theta, \\rho sin\\theta)\\rho d\\rho \\]\n三重积分的计算 利用直角坐标计算三重积分 “先1后2法”，即先以\\(z\\)为积分变量计算 \\[\\iiint\\limits_\\Omega f(x,y,z)dv=\\int_a^bdx\\int_{y_1(x)}^{y_2(x)} dy\\int_{z_1(x,y)}^{z_2(x,y)}f(x,y,z)dz \\]\n\u0026ldquo;先2后1法\u0026rdquo;，即先以\\(xy\\)为积分变量计算 \\[\\iiint\\limits_\\Omega f(x,y,z)dv=\\int_{c_1}^{c_2}dz\\iint\\limits_{D_z} f(x,y,z)dxdy \\]\n利用柱面坐标计算 有\n\\[\\left\\{\\begin{matrix} x=\\rho cos\\theta \\\\ y=\\rho sin\\theta \\\\ z=z \\end{matrix}\\right. \\]\n有\n\\[\\iiint\\limits_{\\Omega}f(x,y,z)dxdydz= \\iiint\\limits_{\\Omega}F(\\rho,\\theta,z)\\rho d\\rho d\\theta dz \\]\n利用球面坐标计算 有\n\\[\\left\\{\\begin{matrix} x=rsin\\varphi cos\\theta \\\\ y=rsin\\varphi sin\\theta \\\\ z=rcos\\varphi \\end{matrix}\\right. \\]\n有\n\\[\\iiint\\limits_{\\Omega}f(x,y,z)dxdydz= \\iiint\\limits_{\\Omega}F(r,\\varphi,\\theta)r^2sin\\varphi drd\\varphi d\\theta \\]\n拆分被积函数 详细的证明没有在书中和老师的教学中找到，互联网搜索也较难\n书上有许多例子，如当\n\\[\\rho ^2\\leq z\\leq4,0\\leq\\rho\\leq2,0\\leq\\theta\\leq2\\pi \\]\n有\n\\[\\iiint\\limits_{\\Omega}zdxdydz=\\iiint\\limits_{\\Omega}z\\rho d\\rho d\\theta dz=\\int_0^{2\\pi}d\\theta\\int_0^2\\rho d\\rho\\int_{\\rho^2}^4zdz \\]\n推断为，首先被积函数要是\\(f(z)g(\\rho)\\)等用乘法连接的，如\\(z\\rho\\)，而不能是加法如\\(z+\\rho\\)，才能拆分。另外跟积分上下限的关系不明。\n如果是加法，如\\(x+y+z\\)可以从轮换对称性考虑（如果有）\n重积分的应用 曲面面积 设曲面为\\(z=f(x,y)\\)，则\n\\[A=\\iint\\limits_D\\sqrt{1+f_x^2(x,y)+f_y^2(x,y)}dxdy \\]\n质心 设有一平面薄片，占据\\(xOy\\)面上的闭区域\\(D\\)，在点\\((x,y)\\)处的面密度为\\(\\mu(x,y)\\)\n则有\n\\[M_y=\\iint\\limits_Dx\\mu(x,y)d\\sigma, M_x=\\iint\\limits_Dy\\mu(x,y)d\\sigma \\]\n\\[M=\\iint\\limits_D\\mu(x,y)d\\sigma \\]\n质心坐标为\n\\[\\bar{x}=\\frac{M_y}{M}= \\frac{\\iint\\limits_Dx\\mu(x,y)d\\sigma}{\\iint\\limits_D\\mu(x,y)d\\sigma} \\]\n\\[\\bar{y}=\\frac{M_x}{M}=\\frac{\\iint\\limits_Dy\\mu(x,y)d\\sigma}{\\iint\\limits_D\\mu(x,y)d\\sigma} \\]\n转动惯量 \\[I_x=\\iint\\limits_Dy^2\\mu(x,y)d\\sigma,I_y=\\iint\\limits_Dx^2\\mu(x,y)d\\sigma \\]\n引力 空间一物体对物体外一点\\(P_0(x_0,y_0,z_0)\\)的单位质量的质点的引力\n物体密度\\(\\rho(x,y,z)\\)，\n\\[\\bold{F}=(F_x,F_y,F_z) \\]\n\\[=\\left ( \\iiint\\limits_\\Omega\\frac{G\\rho(x,y,z)(x-x_0)}{r^3}dv, \\iiint\\limits_\\Omega\\frac{G\\rho(x,y,z)(y-y_0)}{r^3}dv, \\iiint\\limits_\\Omega\\frac{G\\rho(x,y,z)(z-z_0)}{r^3}dv \\right ) \\]\n曲线积分与曲面积分 对弧长的曲线积分 性质 设\\(\\alpha,\\beta\\)为常数，则 \\[\\int_L[\\alpha f(x,y)+\\beta g(x,y)]ds=\\alpha\\int_L f(x,y)ds+\\beta \\int_Lg(x,y)ds \\]\n若积分弧段\\(L\\)课分成两段光滑曲线弧\\(L_1\\)和\\(L_2\\)，则 \\[\\int_Lf(x,y)ds=\\int_{L_1}f(x,y)ds+\\int_{L_2}f(x,y)ds \\]\n设在\\(L\\)上\\(f(x,y)\\leq g(x,y)\\), 则 \\[\\int_L f(x,y)ds\\leq\\int_L g(x,y)ds \\]\n特别地，有\n\\[\\left|\\int_L f(x,y)ds\\right|\\leq\\int_L|f(x,y)|ds \\]\n对弧长的曲线积分的计算法 设\\(f(x,y)\\)在曲线弧\\(L\\)上有定义且连续，\\(L\\)的参数方程为\n\\[\\left\\{\\begin{matrix} x=\\varphi(t) \\\\ y=\\psi(t) \\end{matrix}\\right. (\\alpha\\leq t\\leq\\beta) \\]\n若\\(\\varphi(t)\\)、\\(\\psi(t)\\)在\\([\\alpha,\\beta]\\)上具有一阶连续导数，且\\(\\varphi'^2(t)+\\psi'^2(t)\\neq0\\)，则曲线积分\\(\\int_Lf(x,y)ds\\)存在，且\n\\[\\int_Lf(x,y)ds=\\int_\\alpha^\\beta f[\\varphi(t),\\psi(t)] \\sqrt{\\varphi'^2(t)+\\psi'^2(t)}dt (a\u003c\\beta) \\]\n注意\\(\\alpha\u003c\\beta\\)是一定要有的。\n对坐标的曲线积分 \\[\\int_LP(x,y)dx+Q(x,y)dy \\]\n也可以写作向量形式\n\\[\\int_L\\bold{F(x,y)}\\cdot d\\bold{r} \\]\n其中\\(\\bold{F}=P\\bold{i}+Q\\bold{j}\\)，\\(d\\bold{r}=dx\\bold{i}+dy\\bold{j}\\).\n性质 与上节相同\n与上节相同\n设\\(L\\)是有向光滑曲线弧，\\(L^-\\)是\\(L\\)的反向曲线弧，则\n\\[\\int_{L^-}\\bold F(x,y)d\\bold r = -\\int_L\\bold F(x,y)d\\bold r \\]\n对坐标的曲线积分的计算方法 条件相似，不再重复，查阅书籍\n\\[\\left\\{\\begin{matrix} x=\\varphi(t) \\\\ y=\\psi(t) \\end{matrix}\\right. \\]\n\\(t\\)单调地由\\(\\alpha\\)变到\\(\\beta\\)\n\\[\\int_LP(x,y)dx+Q(x,y)dy \\]\n\\[=\\int_\\alpha^\\beta\\{P[\\varphi(t),\\psi(t)]\\varphi'(t)+ Q[\\varphi(t),\\psi(t)]\\psi'(t)\\}dt \\]\n不需要\\(\\alpha\u003c\\beta\\)，有时有\\(x=x,y=y(x)\\)，类似的替换公式即可。\n两类曲线积分之间的联系 \\[\\int_LPdx+Qdy=\\int_L(Pcos\\alpha+Qcos\\beta)ds \\]\n易推广至三维\n也可以写成向量形式\n\\[\\int_L\\bold A\\cdot d\\bold r = \\int_L\\bold A\\cdot\\bm{\\tau}ds= \\int_LA_{\\tau}ds \\]\n格林公式 定理1，设闭区域\\(D\\)由分段光滑的曲线\\(L\\)围成，若函数\\(P(x,y)\\)及\\(Q(x,y)\\)在\\(D\\)上具有一阶连续偏导数，则有\n\\[\\iint\\limits_D(\\frac{\\partial Q}{\\partial x}-\\frac{\\partial P}{\\partial y}) dxdy=\\oint_LPdx+Qdy \\]\n其中\\(L\\)是\\(D\\)的取正向的边界曲线。\n对平面区域\\(D\\)的边界曲线\\(L\\)，规定正向如下：当观察者沿着\\(L\\)的这个方向行走时，\\(D\\)总在他的左边。\n定理2，设区域\\(G\\)是一个单连通域（复连通不是充要条件），若函数\\(P(x,y),Q(x,y)\\)在\\(G\\)内具有一阶连续偏导数，则曲线积分\\(\\int_LPdx+Qdy\\)在\\(G\\)内与路径无关（或沿着\\(G\\)内任意闭曲线的曲线积分为0）的充分必要条件是\n\\[\\frac{\\partial P}{\\partial y}=\\frac{\\partial Q}{\\partial x} \\]\n在\\(G\\)内恒成立。\n定理3，设区域\\(G\\)是一个单连通域（复连通不是充要条件，若函数\\(P(x,y),Q(x,y)\\)在\\(G\\)内具有一阶连续偏导数，则\\(P(x,y)dx+Q(x,y)dy\\)在\\(G\\)内为某一函数\\(u(x,y)\\)的全微分的充分必要条件是\n\\[\\frac{\\partial P}{\\partial y}=\\frac{\\partial Q}{\\partial x} \\]\n在\\(G\\)内恒成立。\n对面积的曲面积分 \\[\\iint\\limits_{\\Sigma}f(x,y,z)dS \\]\n\\[=\\iint\\limits_{D_{xy}}f[x,y,z(x,y)]\\sqrt{1+z_x^2(x,y)+z_y^2(x,y)}dxdy \\]\n对坐标的曲面积分 关于方向 假设某块小曲面\\(\\Delta S\\)与\\(z\\)轴的夹角为\\(\\gamma\\)角，在\\(xOy\\)面上的投影是\\((\\Delta\\sigma)_{xy}\\)，则规定\\(\\Delta S\\)在\\(xOy\\)面上的投影\\((\\Delta S)_{xy}\\)为\n\\[(\\Delta S)_{xy}=\\left\\{\\begin{matrix} (\\Delta\\sigma)_{xy}, cos\\gamma\u003e0 \\\\ -(\\Delta\\sigma)_{xy}, cos\\gamma\u003c0 \\\\ 0, cos\\gamma\\equiv 0 \\end{matrix}\\right. \\]\n投影到其他坐标面类似，总而言之向上、向右、向前是正向曲面。\n对坐标的曲面积分的计算法 如果曲面积分是在曲面\\(\\Sigma\\)上侧的，那么\n\\[\\iint\\limits_\\Sigma R(x,y,z)dxdy=\\iint\\limits_{D_{xy}}R[x,y,z(x,y)]dxdy \\]\n若在下侧，则\n\\[\\iint\\limits_\\Sigma R(x,y,z)dxdy=-\\iint\\limits_{D_{xy}}R[x,y,z(x,y)]dxdy \\]\n同理有\n\\[\\iint\\limits_\\Sigma P(x,y,z)dydz=\\pm\\iint\\limits_{D_{yz}}P[x(y,z),y,z]dydz \\]\n\\[\\iint\\limits_\\Sigma Q(x,y,z)dzdx=\\pm\\iint\\limits_{D_{zx}}Q[x,y(z,x),z]dzdx \\]\n两类曲面积分之间的联系 \\[\\iint\\limits_\\Sigma Pdydz+Qdzdx+Rdxdy=\\iint\\limits_\\Sigma(Pcos\\alpha+Qcos\\beta+Rcos\\gamma)dS \\]\n写成向量形式\n\\[\\iint\\limits_\\Sigma \\bold{A}\\cdot d\\bold{S}=\\iint\\limits_\\Sigma \\bold{A}\\cdot\\bold{n}dS \\]\n高斯公式 通量与散度 高斯公式 设空间闭区域\\(\\Omega\\)是由分片光滑的闭曲面\\(\\Sigma\\)所围成，若函数\\(P(x,y,z),Q(x,y,z),R(x,y,z)\\)在\\(\\Omega\\)上具有一阶连续偏导数，则有\n\\[\\iiint\\limits_\\Omega(\\frac{\\partial P}{\\partial x}+\\frac{\\partial Q}{\\partial y}+\\frac{\\partial R}{\\partial z})dv=\\oiint\\limits_\\Sigma Pdydz+Qdzdx+Rdxdy \\]\n或\n\\[\\iiint\\limits_\\Omega(\\frac{\\partial P}{\\partial x}+\\frac{\\partial Q}{\\partial y}+\\frac{\\partial R}{\\partial z})dv=\\oiint\\limits_\\Sigma(Pcos\\alpha+Qcos\\beta+Rcos\\gamma)dS \\]\n这里\\(\\Sigma\\)是\\(\\Omega\\)的整个边界曲面的外侧，\\(cos\\alpha、cos\\beta、cos\\gamma\\)是\\(\\Sigma\\)在点\\((x,y,z)\\)处的法向量的方向余弦。\n沿任意闭曲面的曲面积分为零的条件 设\\(G\\)是空间二维单连通区域，若\\(P(x,y,z),Q(x,y,z),R(x,y,z)\\)在\\(G\\)内具有一阶连续偏导数，则曲面积分\n\\[\\iint\\limits_\\Sigma Pdydz+Qdzdx+Rdxdy \\]\n在\\(G\\)内所取曲面\\(\\Sigma\\)无关而只取决于\\(\\Sigma\\)的边界曲线(或沿\\(G\\)内任一闭曲面的曲面积分为零)的充分必要条件是\n\\[\\frac{\\partial P}{\\partial x}+\\frac{\\partial Q}{\\partial y}+\\frac{\\partial R}{\\partial z}=0 \\]\n在\\(G\\)内恒成立。\n通量与散度 设有向量场\n\\[\\bold{A}(x,y,z) = P(x,y,z)\\bold i+Q(x,y,z)\\bold j+R(x,y,z)\\bold k \\]\n其中函数\\(P,Q,R\\)均有一阶连续偏导数，\\(\\Sigma\\)是场内的一片有向曲面，\\(\\bold n\\)是\\(\\Sigma\\)在点\\((x,y,z)\\)处的单位法向量，则积分\n\\[\\iint\\limits_\\Sigma \\bold A\\cdot \\bold ndS \\]\n称为向量场\\(\\bold A\\)通过曲面\\(\\Sigma\\)向着指定侧的通量（或流量）。 又可表达为\n\\[\\iint\\limits_\\Sigma \\bold A\\cdot \\bold ndS=\\iint\\limits_\\Sigma \\bold Ad\\bold S=\\iint\\limits_\\Sigma Pdydz+Qdzdx+Rdxdy \\]\n对于这个向量场，其散度记作\\(div\\bold A\\)，即\n\\[div\\bold A=\\frac{\\partial P}{\\partial x}+\\frac{\\partial Q}{\\partial y}+\\frac{\\partial R}{\\partial z} \\]\n利用向量微分算子\\(\\nabla\\)，也可以表示为\n\\[div\\bold A = \\nabla\\cdot\\bold A \\]\n利用向量场的通量和散度，高斯公式可以写成\n\\[\\iiint\\limits_{\\Omega}div\\bold Adv=\\iint\\limits_\\Sigma A_ndS \\]\n斯托克斯公式 环流量与旋度 斯托克斯公式 设\\(\\Gamma\\)为分段光滑的空间有向闭曲线，\\(\\Sigma\\)是以\\(\\Gamma\\)为边界的分片光滑的有向曲面，\\(\\Gamma\\)的正向与\\(\\Sigma\\)的侧符合右手规则，若函数\\(P(x,y,z),Q(x,y,z),R(x,y,z)\\)在曲面\\(\\Sigma\\)(连同边界\\(\\Gamma\\))上具有一阶连续偏导数，则有\n\\[\\iint\\limits_\\Sigma\\left(\\frac{\\partial R}{\\partial y}-\\frac{\\partial Q}{\\partial z}\\right)dydz+\\left(\\frac{\\partial P}{\\partial z}-\\frac{\\partial R}{\\partial x}\\right)dzdx+\\left(\\frac{\\partial Q}{\\partial x}-\\frac{\\partial P}{\\partial y}\\right)dxdy \\]\n\\[=\\oint_\\Gamma Pdx+Qdy+Rdz \\]\n空间曲线积分与路径无关的条件 设空间区域\\(G\\)是一维单连通域，若函数\\(P(x,y,z),Q(x,y,z),R(x,y,z)\\)在\\(G\\)内具有一阶连续偏导数，则空间曲线积分\\(\\int_\\Gamma Pdx+Qdy+Rdz\\)在\\(G\\)内与路径无关（或沿\\(G\\)内任意闭合曲线的曲线积分为零）的充分必要条件是\n\\[\\frac{\\partial P}{\\partial y}=\\frac{\\partial Q}{\\partial x},\\frac{\\partial Q}{\\partial z}=\\frac{\\partial R}{\\partial y},\\frac{\\partial R}{\\partial x}=\\frac{\\partial P}{\\partial z} \\]\n在\\(G\\)内恒成立\n环流量与旋度 设有向量场\n\\[\\bold{A}(x,y,z) = P(x,y,z)\\bold i+Q(x,y,z)\\bold j+R(x,y,z)\\bold k \\]\n其中函数\\(P,Q,R\\)均连续，\\(\\Gamma\\)是\\(\\bold A\\)的定义域内的一条分段光滑的有向闭曲线，\\(\\bm\\tau\\)是\\(\\Gamma\\)在点\\((x,y,z)\\)处的单位切向量，则积分\n\\[\\oint_L\\bold A\\cdot\\bm {\\tau}ds \\]\n称为向量场\\(\\bold A\\)沿有向闭曲线\\(\\Gamma\\)的环流量。\n又可表述为\n\\[\\oint_L\\bold A\\cdot\\bm {\\tau}ds=\\oint_L\\bold Ad\\bold r = \\oint_\\Gamma Pdx+Qdy+Rdz \\]\n向量场\\(\\bold A\\)的旋度，记作\\(\\bold{rotA}\\)，即\n\\[\\bold{rotA} = \\left(\\frac{\\partial R}{\\partial y}-\\frac{\\partial Q}{\\partial z}\\right)\\bold i+\\left(\\frac{\\partial P}{\\partial z}-\\frac{\\partial R}{\\partial x}\\right)\\bold j+\\left(\\frac{\\partial Q}{\\partial x}-\\frac{\\partial P}{\\partial y}\\right)\\bold k \\]\n\\[\\bold{rotA}=\\nabla\\times\\bold A \\]\n同样的，斯托克斯公式可以写成\n\\[\\iint\\limits_\\Sigma\\bold{rotA}\\cdot\\bold{n}dS=\\oint_\\Gamma\\bold{A}\\cdot\\bm{\\tau}ds \\]\n\\[\\iint\\limits_\\Sigma(\\bold{rotA})_ndS=\\oint_{\\Gamma}\\bold{A}_{\\tau} ds \\]\n无穷级数 常数项级数的概念和性质 常数项级数的概念 如果级数\\(\\sum^{\\infty}_{i=1}u_i\\)的部分和数列\\(\\{s_n\\}\\)有极限s，即\n\\[\\lim\\limits_{n\\to\\infty}s_n=s \\]\n那么称无穷级数\\(\\sum^{\\infty}_{i=1}u_i\\)收敛，这时极限\\(s\\)叫做这级数的和，并写成\n\\[s=u_1+u_2+\\dots+u_n+\\cdots \\]\n如果\\(\\{s_n\\}\\)没有极限，那么称无穷级数\\(\\sum^{\\infty}_{i=1}u_i\\)发散\n收敛级数的基本性质 性质1 如果级数\\(\\sum^{\\infty}_{n=1}u_n\\)收敛于和\\(s\\)，那么级数\\(\\sum^{\\infty}_{i=1}ku_i\\)也收敛，且其和为\\(ks\\).\n性质2 如果级数\\(\\sum^{\\infty}_{n=1}u_n\\)与\\(\\sum^{\\infty}_{n=1}v_n\\)分别收敛于\\(s,\\sigma\\)，那么级数\\(\\sum^{\\infty}_{n=1}(u_n\\pm v_n)\\)也收敛，且其和为\\(s\\pm\\sigma\\)\n性质3 在级数中去掉、加上或改变有限项，不会改变级数的收敛性\n性质4 如果级数\\(\\sum^{\\infty}_{n=1}u_n\\)收敛，那么对于这级数的项任意加括号后所成的级数仍收敛，且其和不变\n性质5（级数收敛的必要条件） 如果级数\\(\\sum^{\\infty}_{n=1}u_n\\)收敛，那么它的一般项\\(u_n\\)趋于0，即\n\\[\\lim\\limits_{n\\to\\infty}u_n=0 \\]\n常数项级数的审敛法 正项级数及其审敛法 定理1 正项级数\\(\\sum^{\\infty}_{n=1}u_n\\)收敛的充分必要条件是：它的部分和数列\\(\\{s_n\\}\\)有界\n定理2（比较审敛法） 设\\(\\sum^{\\infty}_{n=1}u_n\\)和\\(\\sum^{\\infty}_{n=1}v_n\\)都是正项级数，且\\(u_n\\leq v_n\\).若级数\\(\\sum^{\\infty}_{n=1}v_n\\)收敛，则级数\\(\\sum^{\\infty}_{n=1}u_n\\)收敛，若级数\\(\\sum^{\\infty}_{n=1}u_n\\)发散，则级数\\(\\sum^{\\infty}_{n=1}v_n\\)发散.\n推论 设\\(\\sum^{\\infty}_{n=1}u_n\\)和\\(\\sum^{\\infty}_{n=1}v_n\\)都是正项级数，如果级数\\(\\sum^{\\infty}_{n=1}v_n\\)收敛，且存在正整数\\(N\\)使当\\(n\\ge N\\)时有\\(u_n\\leq kv_n(k\u003e0)\\)成立，那么级数\\(\\sum^{\\infty}_{n=1}u_n\\)收敛；如果级数\\(\\sum^{\\infty}_{n=1}v_n\\)发散，且存在正整数\\(N\\)使当\\(n\\ge N\\)时有\\(u_n\\ge kv_n(k\u003e0)\\)成立，那么级数\\(\\sum^{\\infty}_{n=1}u_n\\)发散.\n定理3（比较审敛法的极限形式） 设\\(\\sum^{\\infty}_{n=1}u_n\\)和\\(\\sum^{\\infty}_{n=1}v_n\\)都是正项级数，\n如果\\(\\lim\\limits_{n\\to\\infty}\\frac{u_n}{v_n}=l(0\\leq l\u003c+\\infty)\\)，且级数\\(\\sum^{\\infty}_{n=1}v_n\\)收敛，那么级数\\(\\sum^{\\infty}_{n=1}u_n\\)收敛； 如果\\(\\lim\\limits_{n\\to\\infty}\\frac{u_n}{v_n}=l\u003e0\\)或\\(\\lim\\limits_{n\\to\\infty}\\frac{u_n}{v_n}=+\\infty\\)，且级数\\(\\sum^{\\infty}_{n=1}v_n\\)发散，那么级数\\(\\sum^{\\infty}_{n=1}u_n\\)发散； 定理4（比值审敛法，达朗贝尔判别法） 设\\(\\sum^{\\infty}_{n=1}u_n\\)是正项级数，如果\n\\[\\lim\\limits_{n\\to\\infty}\\frac{u_{n+1}}{u_n}=\\rho \\]\n那么当\\(\\rho\u003c1\\)时级数收敛，\\(\\rho\u003e1\\)(或\\(\\lim\\limits_{n\\to\\infty}\\frac{u_{n+1}}{u_n}=\\infty\\))时级数发散，\\(\\rho=1\\)时级数可能收敛也可能发散。\n定理5（根值审敛法，柯西判别法） 设\\(\\sum^{\\infty}_{n=1}u_n\\)是正项级数，如果\n\\[\\lim\\limits_{n\\to\\infty}\\sqrt[n]{u_n}=\\rho \\]\n那么当\\(\\rho\u003c1\\)时级数收敛，\\(\\rho\u003e1\\)(或\\(\\lim\\limits_{n\\to\\infty}\\sqrt[n]{u_n}=+\\infty\\))时级数发散，\\(\\rho=1\\)时级数可能收敛也可能发散。\n定理6（极限审敛法） \\(\\sum^{\\infty}_{n=1}u_n\\)是正项级数，\n如果\\(\\lim\\limits_{n\\to\\infty}nu_n=l\u003e0\\)(或\\(\\lim\\limits_{n\\to\\infty}nu_n=+\\infty\\))，那么该级数发散； 如果\\(p\u003e1\\)，而\\(\\lim\\limits_{n\\to\\infty}n^pu_n=l\u003e0(0\\leq l\u003c+\\infty)\\)，那么该级数收敛. 交错级数及其审敛法 定理7（莱布尼茨定理） 如果交错级数\\(\\sum^{\\infty}_{n=1}(-1)^{n-1}u_n\\)满足条件：\n\\(u_n\\ge u_{n+1}\\) \\(\\lim\\limits_{n\\to\\infty}u_n=0\\) 那么级数收敛，且其和\\(s\\leq u_1\\)，其余项\\(r_n\\)的绝对值小于等于\\(u_{n+1}\\)\n绝对收敛与条件收敛 对于级数\\(\\sum^{\\infty}_{n=1}u_n\\)，若\\(\\sum^{\\infty}_{n=1}|u_n|\\)收敛，那么称\\(\\sum^{\\infty}_{n=1}u_n\\)绝对收敛；如果\\(\\sum^{\\infty}_{n=1}u_n\\)收敛，而\\(\\sum^{\\infty}_{n=1}|u_n|\\)发散，则成\\(\\sum^{\\infty}_{n=1}u_n\\)条件收敛。\n定理8 如果级数\\(\\sum^{\\infty}_{n=1}u_n\\)绝对收敛，那么\\(\\sum^{\\infty}_{n=1}u_n\\)必定收敛。\n绝对收敛级数的性质 定理9 绝对收敛级数经改变项的位置后构成的级数也收敛，且与原级数有相同的和.\n定理10 （绝对收敛级数的乘法） 设\\(\\sum^{\\infty}_{n=1}u_n\\)和\\(\\sum^{\\infty}_{n=1}v_n\\)都是绝对收敛，其和分别为\\(s,\\sigma\\)，则它们的柯西乘积\n\\[u_1v_1+(u_1v_2+u_2v_1)+\\dots+(u_1v_n+u_2v_{n-1}+\\dots+u_nv_1)+\\cdots \\]\n也是绝对收敛的，且其和为\\(s\\sigma\\)\n幂级数 收敛域：开区间；收敛区间：要判断边界点\n定理1（阿贝尔定理) 如果级数\\(\\sum^{\\infty}_{n=0}a_nx^n\\)当\\(x=x_0\\neq0\\)时收敛，那么适合不等式\\(|x|\u003c|x_0|\\)的一切\\(x\\)使这幂级数绝对收敛，反之，如果级数\\(\\sum^{\\infty}_{n=0}a_nx^n\\)当\\(x=x_0\\neq0\\)当\\(x=x_0\\)时发散，那么适合不等式\\(|x|\u003e|x_0|\\)的一切\\(x\\)使这幂级数发散.\n推论 如果幂级数\\(\\sum^{\\infty}_{n=0}a_nx^n\\)不仅在\\(x=0\\)一点收敛，也不是在整个数轴上都收敛，那么必有一个确定的正数\\(R\\)存在，使得\n当\\(|x|\u003c R\\)时，幂级数绝对收敛\n当\\(|x|\u003eR\\)时，幂级数发散\n当\\(|x|=R\\)时，幂级数可能收敛也可能发散，如果收敛可能是绝对或条件收敛。\n正数\\(R\\)通常叫做收敛半径。\n定理2 如果\n\\[\\lim\\limits_{n\\to\\infty}\\left|\\frac{a_{n+1}}{a_n}\\right|=\\rho \\]\n其中\\(a_n,a_{n+1}\\)是幂级数\\(\\sum^{\\infty}_{n=0}a_nx^n\\)的相邻两项的系数，那么这幂级数的收敛半径\n\\[R=\\left\\{\\begin{matrix} \\frac{1}{\\rho}, \\rho\\ne0\\\\ +\\infty, \\rho=0 \\\\ 0, \\rho=+\\infty \\end{matrix}\\right. \\]\n注意如果级数的项中为\\(x^{2n}\\)等不能化为\\(x^n\\)的，不能用这个定理，只能用比值审敛法等通用手段。\n幂级数的运算 设\\(\\sum^{\\infty}_{n=0}a_nx^n\\)和\\(\\sum^{\\infty}_{n=0}b_nx^n\\)分别在区间\\((-R,R),(-R',R')\\)内收敛，则对于这两个幂级数，\n\\(\\sum^{\\infty}_{n=0}a_nx^n\\pm\\sum^{\\infty}_{n=0}b_nx^n=\\sum^{\\infty}_{n=0}(a_n\\pm b_n)x^n\\)在\\((-R,R),(-R',R')\\)中较小的区间内成立. \\(\\sum^{\\infty}_{n=0}a_nx^n\\sum^{\\infty}_{n=0}b_nx^n=a_0b_0+(a_0b_1+a_1b_0)x+\\dots+(a_0b_n+a_1b_{n-1}+\\dots+a_nb_0)x^n+\\cdots\\)，\\((-R,R),(-R',R')\\)中较小的区间内成立. \\(\\frac{\\sum^{\\infty}_{n=0}a_nx^n}{\\sum^{\\infty}_{n=0}b_nx^n}=\\sum^{\\infty}_{n=0}c_nx^n\\)，假设\\(b_0\\ne0\\)，\\(c\\)可以由下式求出 \\[a_0=b_0c_0\\\\ a_1=b_1c_0+b_0c_1\\\\ a_2=b_2c_0+b_1c_1+b_0c_2\\\\ \\cdots \\]\n幂级数\\(\\sum^{\\infty}_{n=0}c_nx^n\\)的收敛区间可能比原来两级数的收敛区间小得多。\n幂级数的和函数的性质\n性质1 幂级数\\(\\sum^{\\infty}_{n=0}a_nx^n\\)的和函数\\(s(x)\\)在其收敛域\\(I\\)上连续\n性质2 幂级数\\(\\sum^{\\infty}_{n=0}a_nx^n\\)的和函数\\(s(x)\\)在其收敛域\\(I\\)上可积，并有逐项积分公式\n\\[\\int_0^xs(x)dt=\\int_0^x[\\sum^{\\infty}_{n=0}a_nt^n]dt=\\sum^{\\infty}_{n=0}\\int_0^xa_nt^ndt=\\sum^{\\infty}_{n=0}\\frac{a_n}{n+1}x^{n+1}(x\\in I), \\]\n逐项积分后所得到的幂级数和原级数有相同的收敛半径。\n性质3 幂级数\\(\\sum^{\\infty}_{n=0}a_nx^n\\)的和函数\\(s(x)\\)在其收敛域\\(I\\)上可导，且有逐项求导公式\n\\[s'(x)=(\\sum^{\\infty}_{n=0}a_nx^n)'=\\sum^{\\infty}_{n=0}(a_nx^n)'=\\sum^{\\infty}_{n=1}na_nx^{n-1} \\]\n逐项求导后所得到的幂级数和原级数有相同的收敛半径.\n反复应用上述结论可得：\\(s(x)\\)在其收敛区间\\((-R,R)\\)内具有任意阶导数。\n函数展开成幂级数 泰勒级数和麦克劳林级数不再重复，见上册整理。\n\\(f(x)\\)能在某个邻域展开成泰勒级数的充要条件是\n\\[\\lim\\limits_{n\\to\\infty}R_n(x)=0, x\\in U(x_0) \\]\n除了直接展开外，通常也会有间接展开的办法。即通过四则运算、求导、积分、变量替换等等运算转化为一些常见的函数，再代入这些常见函数的展开式。\n下面给出一些常见函数的展开式\n\\[\\frac{1}{1-x}=\\sum_{n=0}^{\\infty}x^n,x\\in(-1,1) \\]\n\\[\\frac{1}{1+x}=\\sum_{n=0}^{\\infty}(-1)^nx^n,x\\in(-1,1) \\]\n\\[e^x=\\sum_{n=0}^{\\infty}\\frac{x^n}{n!},x\\in(-\\infty,\\infty) \\]\n\\[sinx=\\sum_{n=0}^{\\infty}\\frac{(-1)^n}{(2n+1)!}x^{2n+1},x\\in(-\\infty,\\infty) \\]\n\\[cosx=\\sum_{n=0}^{\\infty}\\frac{(-1)^n}{(2n)!}x^{2n},x\\in(-\\infty,\\infty) \\]\n\\[ln(1+x)=\\sum_{n=0}^{\\infty}\\frac{(-1)^n}{n+1}x^{n+1}= \\sum_{n=1}^{\\infty}\\frac{(-1)^{n-1}}{n}x^{n},x\\in(-1,1] \\]\n\\[(1+x)^m=1+mx+\\frac{m(m-1)}{2!}x^2+\\cdots+\\frac{m(m-1)\\cdots(m-n+1)}{n!}x^n+\\cdots \\]\n傅里叶级数 一个定义在\\((-\\infty,\\infty)\\)上周期为\\(2\\pi\\)的函数\\(f(x)\\)，如果它在一个周期上可积，那么一定可以做出\\(f(x)\\)的傅里叶级数\n\\[f(x) = \\frac{a_0}{2}+\\sum_{n=1}^{\\infty}(a_ncosnx+b_nsinnx) \\]\n其中\n\\[a_n=\\frac{1}{\\pi}\\int^\\pi_{-\\pi}f(x)\\cos nxdx,(n=0,1,2,3,\\cdots) \\]\n\\[b_n=\\frac{1}{\\pi}\\int^\\pi_{-\\pi}f(x)\\sin nxdx,(n=1,2,3,\\cdots) \\]\n定理 设\\(f(x)\\)是周期为\\(2\\pi\\)的周期函数，如果它满足：\n在一个周期内连续或只有有限个第一类间断点 在一个周期内至多只有有限个极值点 那么\\(f(x)\\)的傅立叶级数收敛，并且\n当\\(x\\)是\\(f(x)\\)的连续点时，级数收敛于\\(f(x)\\);\n当\\(x\\)是\\(f(x)\\)的间断点时，级数收敛于\\(\\frac{1}{2}[f(x^-)+f(x^+)]\\)\n如果函数只在\\([-\\pi,\\pi]\\)上有定义，可以使用周期延拓来展开成傅里叶级数。\n正弦级数和余弦级数 当\\(f(x)\\)为奇函数时，可以展开为正弦级数\n\\[\\sum_{n=1}^\\infty b_n\\sin nx \\]\n当\\(f(x)\\)为偶函数时，可以展开为余弦函数\n\\[\\frac{a_0}{2}+\\sum_{n=1}^\\infty a_n\\cos nx \\]\n一般周期的傅里叶级数 周期为\\(2l\\)\n\\[f(x)=\\frac{a_0}{2}+\\sum^\\infty_{n=1}\\left(a_ncos\\frac{n\\pi x}{l}+b_nsin\\frac{n\\pi x}{l}\\right)(x\\in C) \\]\n其中\n\\[a_n=\\frac{1}{l}\\int_{-l}^lf(x)cos\\frac{n\\pi x}{l}dx\\quad (n=0,1,2,\\cdots) \\]\n\\[b_n=\\frac{1}{l}\\int_{-l}^lf(x)sin\\frac{n\\pi x}{l}dx\\quad (n=1,2,3,\\cdots) \\]\n\\[C=\\left\\{x\\left|f(x)=\\frac{1}{2}[f(x^-) +f(x^+)]\\right. \\right\\} \\]\n","date":"2022-05-25T21:43:40+08:00","image":"https://kegalas.top/p/%E6%88%91%E7%9A%84%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E4%B8%8B%E5%86%8C%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/8-51_hu1c49316b400cd781c785bbdbc8d18c16_11689_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E6%88%91%E7%9A%84%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E4%B8%8B%E5%86%8C%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/","title":"我的高等数学下册资料整理"},{"content":"第一部分 第一篇 协和和弦——三和弦 第一章 大调式三和弦 自然大调的七个三和弦中，I、IV、V是大三和弦，II、III、VI是小三和弦，VII是减三和弦。\nI级上的三和弦称之为主和弦，IV上的为下属和弦，V上的称为属和弦。\n按功能分，主和弦组：I、VI；属和弦组：V、III；下属和弦组：IV、II；\n第二章 大调式三和弦的连接 对于初学者来说，根据低音写出另外三个声部的音，应当重复根音。\n除相邻的音级上建立的三和弦，任意两个三和弦至少有一个共同音。\n对于初学者，链接两个三和弦应当将共同音保持，不是共同音的音按照最近的方式排列；\n显然旋律音的位置受到共同音的影响，但是根音可以较为自由的上行或下行，如果一定要在六度跳进或是三度进行中做出选择，那后者应该更好。\n第三章 无共同音的三和弦连接 不允许有两个声部间出现平行五度和平行八度。按照之前的共同音保持法链接，显然不会出现平行五八。但如果两个和弦间没有共同音，则上方声部的音应当和根音做反向进行。并且上方声部的两个和弦之间，音的排列顺序不能相同。\n第四章 打破三和弦连接规则 打破规则的原因：如果坚持规则可能会导致某一声部的音太高。\n要注意的有：\n两个三和弦，上方声部连接时不能保持同样的音的排列顺序，否则必然出现平行五八。\n最上方声部不能跳进超过四度。\n低声部和高声部要反向进行，防止出现隐伏五八度。当两个声部通向进行到五度或八度，则会构成隐伏五八度。（注意高声部内部也不要出现隐伏五度）。\n不允许违背规则的情况：\n属和弦进行到主和弦时，如果属和弦的三音即导音位于最高声部，必须上行到主音。如果导音在内声部，可以下行三度进行。\n主和弦到下属和弦时，主和弦的三音类似导音，处理方式同上。\n第五章 和声模进 模进动机保持相同的声部排列位置。\nVII是减三和弦，使用的时候要特别谨慎，但在和弦模进中，它是允许的，因为可以作为动机重复和模进进行。\n当然减三和弦还可以作为两个和弦的经过和弦。这种连接必须同一声部保留共同音。\n第六章 小调式和声 小调式和声建立在和声小调之上。除七音升高半音外，其他与平行大调音阶上的音相同。\n和声小调上的三和弦：小三和弦：I、IV；大三和弦V、VI；减三和弦：II、VII；增三和弦：III。\n和声小调的和弦连接也应当遵从前面的规则。\n不协和和弦（除小三和大三）要有预备，可以与两个相邻的三和弦作正确连接，或是作为一个动机内的和弦。\n不协和和弦连接具体如下：\nVII级通常连到V级，而不连到II和IV级，因为此时会出现增二度进行，及其不悦耳。\nII级可以与IV、V、VI连接，但要避免隐伏五八、增二度进行；减三和弦与属三和弦连接时，上方三声部与低声部作反向进行就不会出现增二度。\nIII级与I、V、VI连接不会有问题。\n任何时候都要避免使用增二度。因此，导音（属和弦三音）要上行解决到VI级三和弦时，VI级三和弦应当重复三音。当VI进行到V时（比较少见），也应当重复VI的三音。\n第七章 密集排列与开放排列 声部之间的音排列比较密集，成为密集排列。否则称为开放排列。\n将密集排列改写为开放排列时，注意要一个声部整体移动八度，不能出现声部更换，也不能出现声部超越。\n第八章 三和弦的转位 将根音转移到上方其他声部，低声部不是根音的三和弦，被称为和弦的转位。\n第一转位，即最低声部为三音，被称为三六和弦，简称六和弦。\n第二转位，即最低声部为五音，被称为四六和弦。\n原位和弦因为具有纯五度，音响协和程度要高于两个转位和弦。\n和弦通常重复根音或者五音，重复三音不够自然，仅用在一些特殊位置（如可以获得更好的声部进行）。\n我们常常会碰到连续的六和弦级进进行。这种情况最好让两个声部与低音作同向进行，另一声部作反向进行。如果低音上行，首先重复五音；如果低音下行，首先重复根音。\n如果是属六和弦进行到主和弦，那么属六和弦的三音不能重复，因为其是导音。\n第九章 减三和弦与增三和弦的转位 减三和弦的第一转为接近协和和弦，所以用的比原位多。\n减六和弦与其他和弦的连接分为两种情况\n在主和弦之前。减三和弦的根音，即导音，必须上行解决，因为它不能重复。最好重复五音，偶尔可以重复三音。由于导音在任何时候都必须解决到主音，因此减三和弦中的五音位于根音上方时，不能上行，否则必定会出现禁止进行（平行五度）(所以必须让在根音上方的五音下行)。因此，我们必须避免减六和弦中的两个五音都位于根音上方(这样会导致两个五音之后一个上行一个下行)。\n除主和弦外的其他和弦之前。大多数重复根音（就像其他六和弦一样），因为这里根音不作为导音。\n小调中II级上的减六和弦也遵从这些规则。\n第二篇 不协和和弦——七和弦和九和弦 七和弦和九和弦都不是独立的和弦，都需要有准备，并要合理地进行到后面的和弦。不协和和弦进行到协和和弦，被称为“解决”。每一个七和弦都必须要解决到三和弦上。\n第十章 属七和弦 所有七和弦中，最重要，最常用的是V级上的七和弦，即属七和弦。属七和弦解决到主和弦。\n属七和弦的解决方式：七音级进下行解决到主和弦的三音。五音级进上行或下行解决到主和弦的三音或根音，更多解决到根音。三音（即导音）级进上行到主音，根音四度上行或五度下行到主和弦的根音。\n属七和弦的解决会产生缺五音的不完全主和弦。\n停更 ","date":"2021-12-31T22:44:43+08:00","permalink":"https://kegalas.top/p/%E5%AE%9E%E7%94%A8%E5%92%8C%E5%A3%B0%E5%AD%A6%E6%8C%87%E5%8D%97%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","title":"《实用和声学指南》读书笔记"},{"content":"函数与极限 等价无穷小 当\\(x\\to 0\\)时，有\n\\[sinx\\sim x\\qquad tanx\\sim x\\qquad ln(1+x)\\sim x\\qquad e^x-1\\sim x \\]\n\\[arcsinx\\sim x\\qquad arctanx\\sim x\\qquad log_a(1+x)\\sim \\frac{x}{lna} \\]\n\\[x-ln(1+x)\\sim \\frac{1}{2}x^2\\qquad 1-cosx\\sim\\frac{1}{2}x^2\\qquad ln(x+\\sqrt{1+x^2})\\sim x \\]\n\\[x-sinx\\sim \\frac{1}{6}x^3\\qquad tanx-x\\sim \\frac{1}{3}x^3\\qquad (1+x)^a-1\\sim ax \\]\n\\[arcsinx-x\\sim \\frac{1}{6}x^3\\qquad x-arctanx\\sim\\frac{1}{3}x^3\\qquad tanx-sinx\\sim\\frac{1}{2}x^3 \\]\n两个重要极限 \\[\\lim_{x\\to 0}\\frac{sinx}{x}=1 \\]\n\\[\\lim_{x\\to \\infty}(1+\\frac1x)^x=e \\]\n间断点的分类 第一类间断点 如果\\(x_0\\)是函数的间断点，且左极限\\(f(x_0^-)\\)及右极限\\(f(x_0^+)\\)都存在。\n若左极限和右极限相等，但不等于该点函数值或函数在该点无定义，则称为可去间断点。\n若左极限右极限不相等，则称为跳跃间断点。\n第二类间断点 不是第一类间断点的任何间断点称之为第二类间断点，包含震荡间断点，无穷间断点等。\n部分函数及其图像 双曲函数 \\[sh\\ x=\\frac{e^x-e^{-x}}{2}\\qquad ch\\ x=\\frac{e^x+e^{-x}}{2}\\qquad th\\ x=\\frac{sh\\ x}{ch\\ x}=\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\]\n函数图像如下\n其常用公式如下：\n\\[sh(x+y)=sh\\ xch\\ x+ch\\ xsh\\ y \\]\n\\[sh(x-y)=sh\\ xch\\ x-ch\\ xsh\\ y \\]\n\\[ch(x+y)=ch\\ xch\\ x+sh\\ xsh\\ y \\]\n\\[ch(x-y)=ch\\ xch\\ x-sh\\ xsh\\ y \\]\n\\[ch^2x-sh^2x=1\\qquad sh\\ 2x=2sh\\ xch\\ x\\qquad ch\\ 2x=ch^2x+sh^2x \\]\n反双曲函数如下\n\\[arsh\\ x=ln(x+\\sqrt{x^2+1}) \\]\n\\[arch\\ x=ln(x+\\sqrt{x^2-1}) \\]\n\\[arth\\ x=\\frac{1}{2}ln\\frac{1+x}{1-x} \\]\n部分三角函数和反三角函数 \\(cot\\ x,sec\\ x,csc\\ x\\)的函数图像如下\n反三角函数图像如下\n三角函数公式 和差化积 \\[sin\\alpha+sin\\beta=2sin\\dfrac{\\alpha+\\beta}{2}\\cdot cos\\dfrac{\\alpha-\\beta}{2} \\]\n​\n\\[sin\\alpha-sin\\beta=2cos\\frac{\\alpha+\\beta}{2}\\cdot sin\\frac{\\alpha-\\beta}{2} \\]\n​\n\\[cos\\alpha+cos\\beta=2cos\\frac{\\alpha+\\beta}{2}\\cdot cos\\frac{\\alpha-\\beta}{2} \\]\n​\n\\[cos\\alpha-cos\\beta=-2sin\\frac{\\alpha+\\beta}{2}\\cdot sin\\frac{\\alpha-\\beta}{2} \\]\n积化和差 \\[sin\\alpha cos\\beta=\\frac{1}{2}\\left[sin(\\alpha+\\beta)+sin(\\alpha-\\beta)\\right] \\]\n​\n\\[cos\\alpha sin\\beta=\\frac{1}{2}\\left[sin(\\alpha+\\beta)-sin(\\alpha-\\beta)\\right] \\]\n​\n\\[cos\\alpha cos\\beta=\\frac{1}{2}\\left[cos(\\alpha+\\beta)+cos(\\alpha-\\beta)\\right] \\]\n​\n\\[sin\\alpha sin\\beta=-\\frac{1}{2}\\left[cos(\\alpha+\\beta)-cos(\\alpha-\\beta)\\right] \\]\n半角公式 \\[sin\\frac{\\theta}{2}=\\pm \\sqrt{\\frac{1-cos\\alpha}{2}} \\]\n​\n\\[sin\\frac{\\theta}{2}=\\pm \\sqrt{\\frac{1+cos\\alpha}{2}} \\]\n​\n\\[tan\\frac{\\theta}{2}=\\pm \\sqrt{\\frac{1-cos\\alpha}{1+cos\\alpha}}=\\frac{sin\\alpha}{1+cos\\alpha}=\\frac{1-cos\\alpha}{sin\\alpha} \\]\n辅助角公式 \\[asin\\theta\\pm bcos\\theta=\\sqrt{a^2+b^2}sin(\\theta\\pm\\varphi),\\quad tan\\varphi=\\frac{b}{a} \\]\n\\(sin\\ x\\)和\\(cos\\ x\\)的\\(tan\\ \\frac x2\\)有理式表示 \\[sin\\ x=\\frac{2tan\\frac x2}{1+tan^2\\frac x2} \\]\n\\[cos\\ x=\\frac{1-tan^2\\frac x2}{1+tan^2\\frac x2} \\]\n导数与微分 反函数求导 如果函数\\(x=f(y)\\)在区间\\(I_y\\)内单调、可导且\\(f'(y)\\ne 0\\)，那么它的反函数\\(y=f^{-1}(x)\\)在区间\\(I_x = \\\\{ x | x = f(y) , y\\in I_y \\\\}\\)内也可导，且\n\\[[f^{-1}(x)]'=\\frac{1}{f'(y)}\\quad or \\quad \\frac{dy}{dx}=\\frac{1}{\\frac {dx}{dy}} \\]\n部分常用导数 \\[(tan\\ x)'=sec^2x\\qquad (cot\\ x)'=-csc^2x \\]\n\\[(sec\\ x)'=sec\\ xtan\\ x\\qquad (csc\\ x)'=-csc\\ xcot\\ x \\]\n\\[(a^x)'=a^xlna(a\u003e0,a\\ne 1)\\qquad (log_ax)'=\\frac{1}{xlna} \\]\n\\[(arcsin\\ x)'=\\frac{1}{\\sqrt{1-x^2}}\\qquad (arccosx)'=-\\frac{1} {\\sqrt{1-x^2}} \\]\n\\[(arctan\\ x)'=\\frac{1}{1+x^2}\\qquad (arccotx)'=-\\frac{1}{1+x^2} \\]\n\\[(sh\\ x)'=ch\\ x,\\ (ch\\ x)'=sh\\ x,\\ (th\\ x)'=\\frac{1}{ch^2x} \\]\n\\[(arsh\\ x)'=\\frac{1}{\\sqrt{x^2+1}},\\ (arch\\ x)'=\\frac{1}{\\sqrt{x^2-1}}, \\ (arth\\ x)'=\\frac{1}{1-x^2} \\]\n参数方程求导 对如下参数方程\n\\[x = \\varphi (t),\\ y = \\psi (t) \\]\n求导得\n\\[\\frac{dy}{dx}=\\frac{dy}{dt}\\cdot \\frac{1}{\\frac{dx}{dt}}= \\frac{\\psi'(t)}{\\varphi'(t)} \\]\n中值定理 罗尔定理 如果函数\\(f(x)\\)满足\n（1）在闭区间\\([a,b]\\)上连续\n（2）在开区间\\((a,b)\\)内可导\n（3）在区间端点处的函数值相等，即\\(f(a)=f(b)\\),\n那么在\\((a,b)\\)内至少有一点\\(\\xi\\ (a\u003c\\xi\u003c b)\\)，使得\\(f'(\\xi)=0.\\)\n拉格朗日中值定理 如果函数\\(f(x)\\)满足\n（1）在闭区间\\([a,b]\\)上连续；\n（2）在开区间\\((a,b)\\)内可导，\n那么在\\((a,b)\\)内至少有一点\\(\\xi (a\u003c\\xi\u003c b)\\)，使等式\n\\[f(b)-f(a)=f'(\\xi)(b-a) \\]\n成立\n柯西中值定理 如果函数\\(f(x)\\)及\\(F(x)\\)满足\n（1）在闭区间\\([a,b]\\)上连续\n（2）在开区间\\((a,b)\\)内可导\n（3）对任一\\(x\\in(a,b),F'(x)\\ne0\\)\n那么在\\((a,b)\\)内至少有一点\\(\\xi\\)，使等式\n\\[\\frac{f(b)-f(a)}{F(b)-F(a)}=\\frac{f'(x)}{F'(x)} \\]\n成立\n泰勒公式 在\\(x_0\\)处展开如下\n\\[f(x)=f(x_0)+f'(x_0)(x-x_0)+\\frac{f''(x_0)}{2!}(x-x_0)^2+\\dots+ \\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n+R_n(x) \\]\n皮亚诺余项 \\[R_n(x)=o((x-x_0)^n) \\]\n拉格朗日余项 \\[R_n(x)=\\frac{f^{(n+1)}(\\xi)}{(n+1)!}(x-x_0)^{(n+1)} \\]\n这里\\(\\xi\\)是\\(x_0\\)与\\(x\\)之间的某个值\n曲率 弧微分公式 \\[ds=\\sqrt{1+y'^2}dx \\]\n曲率表达式 对于\\(y=f(x)\\)，曲率\\(K\\)为\n\\[K=\\frac{|y''|}{(1+y'^2)^{3/2}} \\]\n对于\\(x = \\varphi (t),y = \\psi (t)\\)，有\n\\[K=\\frac{|\\varphi'(t)\\psi''(t)-\\varphi''(t)\\psi'(t)|}{[\\varphi'^2(t)+ \\psi'^2(t)]^{3/2}} \\]\n曲率圆与曲率半径 曲率半径与曲率的关系\n\\[\\rho = \\frac{1}{K},\\ K=\\frac{1}{\\rho} \\]\n曲率中心\\(D(\\alpha,\\beta)\\)\n\\[\\alpha = x-\\frac{y'(1+y'^2)}{y''},\\quad \\beta = y+\\frac{1+y'^2}{y''} \\]\n不定积分 常用积分表 \\[\\int\\frac{dx}{1+x^2}=arctan\\ x+C,\\quad \\int\\frac{dx}{\\sqrt{1-x^2}} =arcsin\\ x+C \\]\n\\[\\int\\frac{dx}{cos^2x}=\\int{sec^2x}dx=tan\\ x+C,\\quad\\int\\frac{dx}{sin^2x}= \\int csc^2xdx=-cot\\ x+C \\]\n\\[\\int sec\\ xtan\\ xdx=sec\\ x+C,\\quad \\int csc\\ xcot\\ xdx=-csc\\ x+C \\]\n\\[\\int sh\\ xdx=ch\\ x+C,\\quad \\int ch\\ xdx=sh\\ x+C \\]\n\\[\\int tan\\ xdx=-ln|cos\\ x|+C,\\quad \\int cot\\ xdx=ln|sin\\ x|+C \\]\n\\[\\int sec\\ xdx=ln|sec\\ x+tan\\ x|+C,\\quad \\int csc\\ xdx=ln|csc\\ x-cot\\ x|+C \\]\n\\[\\int \\frac{dx}{a^2+x^2}=\\frac{1}{a}arctan\\frac{x}{a}+C,\\quad \\int \\frac{dx}{x^2-a^2}=\\frac{1}{2a}ln\\left |\\frac{x-a}{x+a}\\right |+C \\]\n\\[\\int \\frac{dx}{\\sqrt{a^2-x^2}}=arcsin\\frac xa+C,\\quad \\int \\frac{dx}{\\sqrt{x^2+a^2}}=ln(x+\\sqrt{x^2+a^2})+C \\]\n\\[\\int \\frac{dx}{\\sqrt{x^2-a^2}}=ln|x+\\sqrt{x^2-a^2}|+C \\]\n换元积分法 第一类换元法 设\\(f(u)\\)具有原函数，\\(u=\\varphi(x)\\)可导，则有换元公式\n\\[\\int f[\\varphi(x)]\\varphi'(x)dx=\\left[\\int f(u)du \\right]_{u=\\varphi(x)} \\]\n设要求\\(\\int g(x)dx\\)，如果\\(g(x)\\)可以化为\\(g(x)=f[\\varphi(x)]\\varphi'(x)\\)的形式，那么\n\\[\\int g(x)dx= \\int f[\\varphi(x)]\\varphi'(x)dx=\\left[\\int f(u)du \\right]_{u=\\varphi(x)} \\]\n第二类换元法 设\\(x=\\psi(t)\\)是单调的可导函数，并且\\(\\psi'(t)\\ne 0\\).又设\\(f[\\psi(x)]\\psi'(x)dx\\)具有原函数 ，则有换元公式\n\\[\\int f(x)dx= \\left[\\int f[\\psi(t)]\\psi'(t)dt\\right]_{t=\\psi^{-1}(x)} \\]\n分部积分法 设函数\\(u=u(x)\\)及\\(v=v(x)\\)具有连续导数，则有\n\\[\\int uv'dx=uv-\\int u'vdx \\]\n定积分 积分上限的函数的导数 若\n\\[\\Phi(x)=\\int_{a}^{x}f(t)dt \\]\n则\n\\[\\Phi'(x)=f(x) \\]\n若\n\\[\\Phi(x)=\\int_{a}^{g(x)}f(t)dt \\]\n则\n\\[\\Phi'(x)=f(g(x))g'(x) \\]\n定积分在几何学上的应用 平面图形的面积 直角坐标 例如，以\\(x\\)为积分变量，求\\(f(x)\\)及直线\\(x=a\\), \\(x=b\\)与\\(x\\)轴围成的曲边梯形的面积\n\\[A=\\int_a^bf(x)dx \\]\n以y为积分变量，则求的是两直线、函数、与\\(y\\)轴围成的曲边梯形的面积\n极坐标 \\[dA=\\frac12(\\rho(\\theta))^2d\\theta \\]\n\\[A=\\int_\\alpha^\\beta\\frac12[\\rho(\\theta)]^2d\\theta \\]\n体积 旋转体的体积 \\[V=\\int_a^b\\pi[f(x)]^2dx \\]\n平行截面面积为已知的立体的体积 \\[V=\\int_a^bA(x)dx \\]\n平面曲线的弧长 参数方程 \\(x=\\varphi(t),\\quad y=\\psi(t).\\quad(\\alpha\\leq t\\leq\\beta)\\)\n\\[s=\\int_\\alpha^\\beta\\sqrt{\\varphi'^2(t)+\\psi'^2(t)}dt \\]\n直角坐标 \\[s=\\int_a^b\\sqrt{1+y'^2}dx \\]\n极坐标 \\[s=\\int_\\alpha^\\beta\\sqrt{\\rho^2(\\theta)+\\rho'^2(\\theta)}d\\theta \\]\n微分方程 齐次方程 如果一阶微分方程可化成\n\\[\\frac{dy}{dx}=\\varphi\\left(\\frac yx\\right) \\]\n的形式，那么就称这方程为齐次方程。在齐次方程中，引入新的未知函数\\(u=\\frac{y}{x}\\)，有\n\\[y=ux,\\ \\frac{dy}{dx}=u+x\\frac{du}{dx} \\]\n\\[u+x\\frac{du}{dx}=\\varphi(u) \\]\n用分离变量的办法求出关于\\(u\\)的积分，最后再以\\(\\frac yx\\)代替\\(u\\).\n一阶线性微分方程 方法一 方程\n\\[\\frac{dy}{dx}+P(x)y=Q(x) \\]\n的通解为\n\\[y=Ce^{-\\int P(x)dx}+e^{-\\int P(x)dx}\\int Q(x)e^{\\int P(x)dx}dx \\]\n方法二 先求对应齐次方程\n\\[\\frac{dy}{dx}+P(x)y=0 \\]\n的解，得到\n\\[y=Ce^{-\\int P(x)dx} \\]\n将\\(C\\)替换为\\(u\\)，再对上解求导得\\(\\frac{dy}{dx}\\)，将其代入原非齐次方程，解出\\(u\\)，则\n\\[y=ue^{-\\int P(x)dx} \\]\n可降阶的高阶微分方程 \\(y''=f(x,y')\\)型的微分方程\n设\\(y'=p\\)则\\(y''=\\frac{dp}{dx}=p'\\)，代入原方程中求解\\(p\\)，再求解\\(y\\)\n\\(y''=f(y,y')\\)型的微分方程\n设\\(y'=p\\)\n\\[y''=\\frac{dp}{dx}=\\frac{dp}{dy}\\cdot\\frac{dy}{dx}=p\\frac{dp}{dy} \\]\n代入原方程中求解\\(p\\)，再求解\\(y\\)\n高阶线性微分方程 定理1 如果函数\\(y_1(x)\\)与\\(y_2(x)\\)是方程\n\\[y''+P(x)y'+Q(x)y=0 \\]\n的两个特解，那么\n\\[y=C_1y_1(x)+C_2y_2(x) \\]\n也是方程的解\n定理2 如果函数\\(y_1(x)\\)与\\(y_2(x)\\)是方程的两个线性无关的特解，那么\n\\[y=C_1y_1(x)+C_2y_2(x) \\]\n就是 方程的通解\n定理3 设\\(y^*(x)\\)是方程\n\\[y''+P(x)y'+Q(x)y=f(x) \\]\n的一个特解，\\(Y(x)\\)是该方程对应的齐次方程的通解，则\n\\[y=Y(x)+y^*(x) \\]\n是该非齐次方程的通解\n定理4 设定理三种的非齐次线性方程的右端\\(f(x)\\)是两个函数之和，即\n\\[y''+P(x)y'+Q(x)y=f_1(x)+f_2(x) \\]\n而\\(y_1^* (x)\\)与\\(y_2^*(x)\\)分别是方程\n\\[y''+P(x)y'+Q(x)y=f_1(x) \\]\n与\n\\[y''+P(x)y'+Q(x)y=f_2(x) \\]\n的特解，则\\(y_1^*(x)+y_2^ *(x)\\)就是原方程的特解\n常系数齐次线性微分方程 二阶形式如下 \\[y''+py'+qy=0 \\]\n先求解如下方程\n\\[r^2+pr+q=0 \\]\n分为三种情况\n有两个不等实根\\(r_1,r_2\\)\n则通解为\n\\[y=C_1e^{r_1x}+C_2e^{r_2x} \\]\n有两个相等实根\\(r_{1,2}\\)\n则通解为\n\\[y=(C_1+C_2x)e^{r_1x} \\]\n有一对共轭复根\n\\[r_1=\\alpha+\\beta i,\\quad r_2=\\alpha-\\beta i \\]\n\\[\\alpha=-\\frac{p}{2},\\quad \\beta=\\frac{\\sqrt{4q-p^2}}{2} \\]\n则通解为\n\\[y=e^{\\alpha x}(C_1cos\\ \\beta x+C_2sin\\ \\beta x) \\]\nn阶形式如下 \\[y^{(n)}+p_1y^{(n-1)}+p_2y^{(n-2)}+\\dots+p_{n-1}y'+p_ny=0 \\]\n其中\\(p_1\\dots p_n\\)都是常数。\n其特征方程如下\n\\[r^n+p_1r^{n-1}+\\dots+p_{n-1}r+p_n=0 \\]\n分四种情况\n单实根\\(r\\)，给出一项：\\(Ce^{rx}\\)\n一对单复根\\(r_{1,2}=\\alpha\\pm\\beta i\\)，给出两项：\\(e^{\\alpha x}(C_1cos\\beta x+C_2sin\\beta x)\\)\nk重实根r，给出\\(k\\)项：\\(e^{rx}(C_1+C_2x+\\dots+C_kx^{k-1})\\)\n一对k重复根\\(r_{1,2}=\\alpha\\pm\\beta i\\)，给出\\(2k\\)项：\\(e^{\\alpha x}[(C_1+C_2x+\\dots+C_kx^{k-1})cos\\beta x+(D_1+D_2x+\\dots+D_kx^{k-1})sin\\beta x]\\)\n常系数非齐次线性微分方程 二阶常系数非齐次线性微分方程的一般形式是\n\\[y''+py'+qy=f(x) \\]\n求其通解只用求该方程的一个特解和上一节学到的求其对应齐次方程的通解，高数上册只介绍了\\(f(x)\\)的两种形式\n\\(f(x)=e^{\\lambda x}P_m(x)\\)，其中\\(\\lambda\\)是常数，\\(P_m(x)\\)是\\(x\\)的一个\\(m\\)次多项式\n\\[P_m(x)=a_0x^m+a_1x^{m-1}+\\dots+a_{m-1}x+a_{m} \\]\n\\(f(x)=e^{\\lambda x}[P_l(x)cos\\omega x+Q_n(x)sin\\omega x]\\)，其中\\(\\lambda,\\omega\\)是常数，\\(\\omega\\ne0\\)，\\(P_l(x),Q_n(x)\\)分别是\\(x\\)的\\(l\\)次、\\(n\\)次多项式，且仅有一个可为零.\n\\(f(x)=e^{\\lambda x}P_m(x)\\)型 \\[y^*=x^kR_m(x)e^{\\lambda x} \\]\n其中 \\(R_m(x)\\)是与\\(P_m(x)\\)同次的多项式，而\\(k\\)按\\(\\lambda\\)不是特征方程(即\\(r^2+pr+q=0\\))的根，是特征方程的单根或是特征方程的重根依次取值为0,1,2.\n其中\\(R_m(x)\\)中的每一个系数，应当代入原方程中进行计算。\n\\(f(x)=e^{\\lambda x}[P_l(x)cos\\omega x+Q_n(x)sin\\omega x]\\)型 \\[y^*=x^ke^{\\lambda x}[R^{(1)}_m(x)cos\\omega x+R^{(2)}_m(x)sin\\omega x] \\]\n其中\\(R^{(1)}_m(x)\\)、\\(R^{(2)}_m(x)\\)是\\(m\\)次多项式，\\(m=max\\\\{l,n\\\\}\\)，而\\(k\\)按\\(\\lambda+\\omega i\\)(或\\(\\lambda-\\omega i\\))不是特征方程的根、或是特征方程的单根依次取0或1\n","date":"2021-12-27T16:45:49+08:00","image":"https://kegalas.top/p/%E6%88%91%E7%9A%84%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E4%B8%8A%E5%86%8C%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/sec_huc4e91e2fedcb5d4446570ef1353d17fa_50913_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E6%88%91%E7%9A%84%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E4%B8%8A%E5%86%8C%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/","title":"我的高等数学上册资料整理"},{"content":"#include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cmath\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;map\u0026gt; #include \u0026lt;set\u0026gt; #include \u0026lt;queue\u0026gt; #include \u0026lt;stack\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;cstdint\u0026gt; #include \u0026lt;cstdio\u0026gt; #include \u0026lt;bitset\u0026gt; #include \u0026lt;deque\u0026gt; #include \u0026lt;regex\u0026gt; #include \u0026lt;list\u0026gt; #include \u0026lt;unordered_map\u0026gt; #include \u0026lt;unordered_set\u0026gt; #define debug(a) std::cout\u0026lt;\u0026lt;#a\u0026lt;\u0026lt;\u0026#34;=\u0026#34;\u0026lt;\u0026lt;(a)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34; #define rep(i,x,y) for(int i=(x);i\u0026lt;=(y);i++) #define rrep(i,x,y) for(int i=(x);i\u0026gt;=(y);i--) #define mms(x) memset((x), 0, sizeof(x)) #define pb push_back #define mkp std::make_pair #define fi first #define se second using LL = long long; using ULL = unsigned long long; using DB = double; using LD = long double; using ui = unsigned; using i128 = __int128; using pii = std::pair\u0026lt;int,int\u0026gt;; using pll = std::pair\u0026lt;LL,LL\u0026gt;; int const MAXN = 200005; int const INF = 0x7fffffff; DB const EPS = 1e-8; int const MOD = 998244353; DB const PI = acos(-1); int arr[MAXN]; void solve(){ int n; std::cin\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;arr[i]; } } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int T; std::cin\u0026gt;\u0026gt;T; //T=1; while(T--){ solve(); } return 0; } 字符串 KMP //复杂度n //kmp,luogu3375 std::vector\u0026lt;int\u0026gt; prefixFunc(std::string const \u0026amp; str){ //输入一个字符串，输出该字符串的前缀函数表 //前缀函数pi[i]是满足s[0...x-1]==s[i-x+1...i]的最大的x //如果输入不是字符串而是一个数组，也可以很方便的修改为vector int n = str.length(); std::vector\u0026lt;int\u0026gt; ans(n); for(int i=1, j=0;i\u0026lt;n;i++){ //ans[0]=0，因为只看真前缀和真后缀 while(j \u0026amp;\u0026amp; str[i]!=str[j]) j = ans[j-1]; if(str[i]==str[j]) j++; ans[i] = j; } return ans; } std::vector\u0026lt;int\u0026gt; KMP(std::string const \u0026amp; s, std::string const \u0026amp; p){ //输入主串和模式串，返回所有匹配的开始下标，下标从0开始 std::vector\u0026lt;int\u0026gt; vec; std::vector\u0026lt;int\u0026gt; pf = prefixFunc(p); int ns = s.size(), np = p.size(); for(int i=0, j=0;i\u0026lt;ns;i++){ while(j \u0026amp;\u0026amp; s[i]!=p[j]) j = pf[j-1]; if(s[i]==p[j]) j++; if(j==np){ vec.push_back(i-j+2); j = pf[j-1]; } } return vec; } //我们可以通过把模式串和主串拼在一起，p+#+s，然后求这个字符串的前缀函数表（#代表不在主串、模式串字符集内的一个符号），然后pi[i]如果等于模式串的长度，那么i是匹配模式串的子串的起点。 //关于最小循环结，设字符串下标从1开始，长度为n，则如果n%(n-pf[n])==0，则有循环节，并且长度为n-pf[n]（当然长度可以为n） 字典树(Trie) //复杂度 插入或查找一次 模板串长度 //luogu p8306 class Trie{ public: int nxt[MAXM][26]; int cnt; void init(){ for(int i=0;i\u0026lt;=cnt;i++) for(int j=0;j\u0026lt;26;j++) nxt[i][j] = 0; cnt = 0;//起始节点编号为0 } void insert(std::string const \u0026amp; s){ int cur = 0; for(auto c:s){ if(!nxt[cur][c-\u0026#39;a\u0026#39;]){ nxt[cur][c-\u0026#39;a\u0026#39;]=++cnt; } cur = nxt[cur][c-\u0026#39;a\u0026#39;]; } } bool find_prefix(std::string const \u0026amp; s){ int cur=0; for(auto c:s){ if (!nxt[cur][c-\u0026#39;a\u0026#39;]){ return false; } cur = nxt[cur][c-\u0026#39;a\u0026#39;]; } return true; } }; Trie trie; 字符串哈希 主要是用于判断两个字符串是否相等。通常我们的Hash函数会把字符串看成是某个进制下的自然数。把这个自然数对某个大质数取模得到Hash值。\n求Hash的复杂度是\\(O(n)\\)，如果我们要比较一大群字符串里有多少不同的，我们不应该两两比较，而要把它们的Hash全部记录下来，再去排序Hash、比较。\n这种哈希函数的性质为：\n设已知字符串\\(S\\)的Hash值为\\(H(S)\\)，那么添加一个字符\\(c\\)后的新字符串的Hash值为\\(H(S+c)=(H(S)*base+value[c])\\%MOD\\)。其中\\(value[c]\\)表示\\(c\\)代表的数值，如果用char类型直接把\\(c\\)转换为int或者ULL什么的就行了 已知\\(H(S)\\)和\\(H(S+T)\\)，则\\(H(T)=(H(S+T)-H(S)*base^{length(T)})\\%MOD\\)，直观理解的话，就是在\\(base\\)进制下，在S后面补\\(0\\)，把\\(S\\)左端和\\(S+T\\)左端对齐，相减得到\\(H(T)\\)。利用这个性质可以方便地先预处理字符串所有前缀的Hash，然后查询连续子串的Hash。 //自然溢出法，相当于对2^64取模的单哈希，是比较容易被特殊数据卡掉的 //luogu P3370 using ULL = unsigned long long; ULL H(std::string const \u0026amp; str){ ULL ret = 0; ULL const base = 131;//ascii也就128个字符，质数131作为底数足够 for(auto c:str){ ret = ret*base+(ULL)c; } return ret; } //双哈希法，两个字符串的两个哈希必须分别相同，才会被考虑为相同的字符串 //比起单哈希，更不容易被卡 //luogu P3370 ULL const MOD1 = 998244353; ULL const MOD2 = 1e9+7; ULL const base = 131; struct Data{//把字符串的两个哈希捆起来，便于排序比较等操作 ULL x,y; }; ULL H1(std::string const \u0026amp; str){ ULL ret = 0; for(auto c:str){ ret = (ret*base+(ULL)c)%MOD1; } return ret; } ULL H2(std::string const \u0026amp; str){ ULL ret = 0; for(auto c:str){ ret = (ret*base+(ULL)c)%MOD2; } return ret; } AC自动机 //复杂度 文本串长度+模板串长度之和 //AC自动机，luogu P3808 //AC自动机会把Trie修改掉，并不是插入时候的字典树了，实际上变成了一张图+fail指针。 //trie数组表示从当前状态添加一个字符后到达的状态，fail数组表示，目前为止匹配，但是添加下一个字符后不匹配了，跳转至最长的后缀状态（不包括添加的下一个字符）。可以反复跳转。 //注意，一个状态是可行状态，当且仅当它自己可行，或者fail指针指向的状态可行，或者fail[fail]可行，以此类推 class AC{ public: int trie[MAXN][26], total; int end[MAXN],fail[MAXN]; void init(int m){ for(int i=0;i\u0026lt;=m;i++){ end[i] = 0; fail[i] = 0; for(int j=0;j\u0026lt;26;j++) trie[i][j] = 0; } total = 0; } void insert(std::string const \u0026amp; str){ //插入模式串 int u = 0; for(auto c:str){ if(!trie[u][c-\u0026#39;a\u0026#39;]){ trie[u][c-\u0026#39;a\u0026#39;] = ++total; } u = trie[u][c-\u0026#39;a\u0026#39;]; } end[u]++; } void buildFail(){ //构建fail指针 std::queue\u0026lt;int\u0026gt; qu; for(int i=0;i\u0026lt;26;i++){ if(trie[0][i]) qu.push(trie[0][i]); } while(!qu.empty()){ int u = qu.front(); qu.pop(); for(int i=0;i\u0026lt;26;i++){ if(trie[u][i]){ fail[trie[u][i]] = trie[fail[u]][i];\tqu.push(trie[u][i]); } else{ trie[u][i] = trie[fail[u]][i]; } } } } int query(std::string const \u0026amp; str){ //查询主串str中出现了几个模式串 int u = 0, res = 0; for(auto c:str){ u = trie[u][c-\u0026#39;a\u0026#39;]; for(int j = u ; j \u0026amp;\u0026amp; end[j] != -1 ; j = fail[j]){ res += end[j]; end[j] = -1; } } return res; } }; 最小表示法 例如S = bcda, 则S的循环同构有cdab, dabc, abcd，其中字典序最小的是abcd，最小表示法就是求这个字典序最小的。当然题目里面可能是算数组里面字典序最小的。\n//最小表示法 //luogu P1368 //复杂度 O(n) int arr[MAXN]; int minStr(int n){//数组下标从0开始，共n个；返回最小表示的开始下标 int i=0, j=1, k=0; while(i\u0026lt;n \u0026amp;\u0026amp; j\u0026lt;n \u0026amp;\u0026amp; k\u0026lt;n){ if(arr[(i+k)%n]==arr[(j+k)%n]){ k++; } else if(arr[(i+k)%n]\u0026gt;arr[(j+k)%n]){//最大表示法时就把这一段和下一段换一下 i += k+1; k = 0; } else{ j += k+1; k = 0; } if(i==j) j++; } return std::min(i,j); } Manacher //manacher 算法 //luogu P3805 //复杂度O(n) std::vector\u0026lt;int\u0026gt; getD1(std::string const \u0026amp; str){ //返回字符串以某一位为中心的，最长的（奇数长度）回文子串的长度半径 //例如abcba中，d1[2] = 3 int n = str.size(); std::vector\u0026lt;int\u0026gt; d(n); for(int i=0,l=0,r=-1;i\u0026lt;n;i++){ int j = l+r-i; int dj = j\u0026gt;=0?d[j]:0; d[i] = std::max(std::min(dj,j-l+1),0); if(j-dj\u0026lt;l){ while(i-d[i]\u0026gt;=0 \u0026amp;\u0026amp; i+d[i]\u0026lt;n \u0026amp;\u0026amp; str[i-d[i]]==str[i+d[i]]) d[i]++; l = i-d[i]+1, r = i+d[i]-1; } } return d; } std::vector\u0026lt;int\u0026gt; getD2(std::string const \u0026amp; str){ //返回字符串以某一位的左边间隙为中心的，最长的（偶数长度）回文子串的长度半径 //例如abba中，d2[2] = 2 int n = str.size(); std::vector\u0026lt;int\u0026gt; d(n); for(int i=0,l=0,r=-1;i\u0026lt;n;i++){ int j = l+r-i; int dj = j\u0026gt;=0?d[j]:0; d[i] = std::max(std::min(dj,j-l),0); if(j-dj-1\u0026lt;l){ while(i-d[i]-1\u0026gt;=0 \u0026amp;\u0026amp; i+d[i]\u0026lt;n \u0026amp;\u0026amp; str[i-d[i]-1]==str[i+d[i]]) d[i]++; l = i-d[i], r = i+d[i]-1; } } return d; } Z函数 //Z函数，复杂度O(n) //luogu P5410 std::vector\u0026lt;int\u0026gt; zFunc(std::string const \u0026amp; str){ //求出一个字符串的z函数，即满足z[i]是s[0...x-1]==s[i...i+x-1]的最大的x，这个子串也叫做LCP //特别的z[0]=0，也有些题目是等于串长，需要自行调整 //kmp里面添加字符集外字符的操作在这里也可以用 int n = str.size(); std::vector\u0026lt;int\u0026gt; z(n); for(int i=1,l=0,r=0;i\u0026lt;n;i++){ if(z[i-l]\u0026lt;r-i+1) z[i] = z[i-l]; else{ z[i] = std::max(r-i+1,0); while(i+z[i]\u0026lt;n \u0026amp;\u0026amp; str[z[i]]==str[i+z[i]]) z[i]++; l = i, r = i + z[i] - 1; } } return z; } 后缀数组 首先是\\(O(n\\log^2n)\\)的，没有用到基数排序（因为我不排除会求某种只给出偏序关系的后缀数组）\n//求后缀数组，复杂度O(nlog^2n) //luogu p3809 int rk[MAXN\u0026lt;\u0026lt;1],sa[MAXN],tarr[MAXN\u0026lt;\u0026lt;1]; //rk[i]表示后缀i（从1开始，后缀i代表字符串从i开始到结束的子串）的排名，sa[i]表示所有后缀第i小的起点序号，排名和编号都从1开始 void getSA(std::string const \u0026amp; s){ int n = s.size(); if(n==1){ rk[1] = sa[1] = 1; return; } for(int i=1;i\u0026lt;=n;i++) sa[i] = i, rk[i] = s[i-1]; for(int w=1;w\u0026lt;n;w\u0026lt;\u0026lt;=1){ auto rp = [\u0026amp;](int x){return std::make_pair(rk[x],rk[x+w]);}; std::sort(sa+1,sa+n+1,[\u0026amp;](int x, int y){return rp(x)\u0026lt;rp(y);}); for(int i=1,p=0;i\u0026lt;=n;i++) tarr[sa[i]] = rp(sa[i-1])==rp(sa[i]) ? p:++p; std::copy(tarr+1,tarr+n+1,rk+1); } } 再给出\\(O(n\\log n)\\)的\n//求后缀数组，复杂度O(nlogn) //luogu p3809 int rk[MAXN\u0026lt;\u0026lt;1],sa[MAXN],tarr[MAXN\u0026lt;\u0026lt;1],cnt[MAXN],rkt[MAXN]; //rk[i]表示后缀i（从1开始，后缀i代表字符串从i开始到结束的子串）的排名，sa[i]表示所有后缀第i小的起点序号，排名和编号都从1开始 void getSA(std::string const \u0026amp; s){ int n = s.size(); if(n==1){ rk[1] = sa[1] = 1; return; } int m = 128; for(int i=1;i\u0026lt;=n;i++) ++cnt[rk[i]=s[i-1]]; for(int i=1;i\u0026lt;=m;i++) cnt[i] += cnt[i-1]; for(int i=n;i\u0026gt;=1;i--) sa[cnt[rk[i]]--] = i; for(int w=1;;w\u0026lt;\u0026lt;=1){ for(int i=n;i\u0026gt;n-w;i--) tarr[n-i+1] = i; for(int i=1,p=w;i\u0026lt;=n;i++) if(sa[i]\u0026gt;w) tarr[++p]=sa[i]-w; std::fill(cnt+1,cnt+m+1,0); for(int i=1;i\u0026lt;=n;i++) cnt[rkt[i] = rk[tarr[i]]]++; for(int i=1;i\u0026lt;=m;i++) cnt[i]+=cnt[i-1]; for(int i=n;i\u0026gt;=1;i--) sa[cnt[rkt[i]]--] = tarr[i]; m = 0; auto rp = [\u0026amp;](int x){return std::make_pair(rk[x],rk[x+w]);}; for(int i=1;i\u0026lt;=n;i++) tarr[sa[i]] = rp(sa[i-1])==rp(sa[i]) ? m:++m; std::copy(tarr+1,tarr+n+1,rk+1); if(n==m) break; } } 后缀自动机 //后缀自动机，构建SAM的复杂度为O(n)，空间复杂度为O(|S|n)，|S|为字符集的大小 //luogu p3804 //SAM是动态构建的，每次插入一个字符即可 struct State{ int fa,len,next[26];//似乎有些编译器next是保留字，需要注意 }; //endpos(p)为模式串p在s中所有出现的结束位置的集合，例如aababc中，ab出现了两次，结束位置是{3,5}。endpos等价类即，endpos相同的子串构成的集合。例如b和ab都是结束在{3,5}，则它们是等价类。这说明它们总是一起出现，可以归到一个节点，并且长度小的一定是长度大的的后缀。 //next[ch]表示接受ch后的状态；fa表示该状态在parent tree上的父节点；len表示该状态对应的endpos等价类中最长串的长度。 //假设b是a的fa，a等价类的最长字符串为s，则b的最长字符串为，s的所有后缀中，不在等价类a里的，最长的字符串。 //SAM可以接受字符串的所有后缀，但是它包含了所有子串的信息。也就是从任意一个状态开始的路径，都是字符串的子串。 //可行状态是last状态，以及fa[last]、fa[fa[last]]直到根节点（空字符串）。 //除了等价类的最长字符串长度len，我们也可以计算minlen。等价类里所有字符串的长度恰好覆盖[minlen,len]之间的每一个整数。除了根节点，st[i].minlen = st[fa[i]].len+1; //每个状态i对应的子串数量是st[i].len-st[st[i].fa].len //算法并没有维护endpos等效类中，字符串出现的位置个数，需要自己去树形dp。 //注意，aababb中，ab的等价类为{3,5}，根据ab前面一个字符不同可以划分不同的等价类，例如aab和bab划分为{3},{5}。但是a的等价类为{1,2,4}，因为第一个的前面一个字符是空字符，只能划分出两个，即aa{2},ba{4}，树形DP需要在parent tree上注意缺少的这一部分。在建SAM时预处理dp[cur] = 1 class SAM{ public: State st[MAXN\u0026lt;\u0026lt;1];//SAM总状态数不会超过2n-1，总转移数不超过3n-4 int cnt = 1, last = 1; //起始节点编号为1；last表示加入新字符前整个字符串所在的等价类 void insert(int ch){ ch = ch-\u0026#39;a\u0026#39;; int cur = ++cnt; int p = 0; st[cur].len = st[last].len + 1; for(p=last;p\u0026amp;\u0026amp;!st[p].next[ch];p=st[p].fa) st[p].next[ch] = cur; //对于每一个father状态，如果不存在ch的转移边，则连到cur int q = st[p].next[ch]; if(q==0){ //加入了从未加入的字符 st[cur].fa = 1; } else if(st[p].len + 1 == st[q].len){ //p到q是连续的转移 st[cur].fa = q; } else{ //不连续的转移 //会新增一个节点r,拥有q的所有出边，father与q相同 int r = ++cnt; st[r] = st[q]; st[r].len = st[p].len + 1; for(;p\u0026amp;\u0026amp;st[p].next[ch]==q;p=st[p].fa){ st[p].next[ch]=r; } st[cur].fa = st[q].fa = r; } last = cur; } }; SAM sam; 广义后缀自动机 //广义后缀自动机，其实就是插入多个字符串的后缀自动机，但只能离线build //luogu p6139 //后缀自动机的性质都可以用过来 struct State{ int fa,len,next[26];//似乎有些编译器next是保留字，需要注意 }; class GSA{ public: State st[MAXN\u0026lt;\u0026lt;1]; int cnt = 1;//起始节点编号为1 int insert(int last, int ch){ //传入的是即将插入的字符的父节点编号，以及该字符 //只用在build里，不要直接把字符串插入，应该先insertTrie再build int cur = st[last].next[ch]; int p = 0; st[cur].len = st[last].len + 1; for(p=st[last].fa;p \u0026amp;\u0026amp; !st[p].next[ch];p=st[p].fa) st[p].next[ch] = cur; int q = st[p].next[ch]; if(q==0){ st[cur].fa = 1; } else if(st[p].len+1==st[q].len){ st[cur].fa = q; } else{ int r = ++cnt; st[r].fa = st[q].fa; for(int i=0;i\u0026lt;26;i++) if(st[st[q].next[i]].len) st[r].next[i] = st[q].next[i]; st[r].len = st[p].len+1; for(;p \u0026amp;\u0026amp; st[p].next[ch]==q;p=st[p].fa) st[p].next[ch] = r; st[cur].fa = st[q].fa = r; } return cur; //返回插入节点编号 } void build(){ std::queue\u0026lt;pii\u0026gt; qu; for(int i=0;i\u0026lt;26;i++){ if(st[1].next[i]) qu.push({1,i}); } while(!qu.empty()){ int fa = qu.front().first; int ch = qu.front().second; qu.pop(); int p = insert(fa,ch); for(int i=0;i\u0026lt;26;i++){ if(st[p].next[i]) qu.push({p,i}); } } } void insertTrie(std::string const \u0026amp; str){ int cur = 1; for(auto c:str){ if(!st[cur].next[c-\u0026#39;a\u0026#39;]){ st[cur].next[c-\u0026#39;a\u0026#39;]=++cnt; } cur = st[cur].next[c-\u0026#39;a\u0026#39;]; } } }; GSA gsa; int main(){ int n; std::cin\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ std::string str; std::cin\u0026gt;\u0026gt;str; gsa.insertTrie(str); } gsa.build(); return 0; } 回文字动机 //回文字动机，复杂度：线性 //luogu p5496 struct State{ int len, fail, next[26]; }; //PAM的每一个状态代表原字符串的一个回文子串，每一个转移代表从当前状态字符串的前后同时加一个相同字符后的状态。可以接受其所有回文子串。除了奇根都是可行状态（当然不能为空时偶根不可行） //fail指针指向该状态的最长回文真后缀。例如ayawaya就指向aya。总体和AC自动机的fail转移很像，都是没有ch的转移，则看fail有没有ch的转移，若fail没有则看fail[fail]的，以此类推。 //回文串分为奇长度和偶长度的，所以PAM有奇根和偶根，偶根的fail指向奇根，奇根不可能失配。 //PAM和SAM一样是动态构建的。 class PAM{ public: int last,cnt,pos; //last代表上个前缀的最长回文后缀的状态 State st[MAXN];//最多有n+2个状态和n个转移 std::string str; void init(std::string const \u0026amp; s){ last = 1,pos = -1; cnt = 2;//起始两个根为1奇根，2偶根，len分别为-1和0 st[1].len = -1, st[2].len = 0, st[2].fail = 1; str = s; } int up(int p){ while(str[pos-1-st[p].len]!=str[pos]) p = st[p].fail; return p; } void insert(int ch){ pos++; ch = ch-\u0026#39;a\u0026#39;; int p = up(last); int \u0026amp; q = st[p].next[ch]; if(!q){ q=++cnt; st[q].len = st[p].len+2; st[q].fail = p==1 ? 2 : st[up(st[p].fail)].next[ch]; } last = q; } }; PAM pam; int main(){ std::string str std::cin\u0026gt;\u0026gt;str; pam.init(str); for(auto c:str){ pam.insert(c); } return 0; } 序列自动机 //序列自动机，复杂度 O(n|S|) //luogu p5826 //字符集很大时需要用可持久化线段树维护next struct State{ int next[26]; }; //SQA接受字符串的所有子序列（不需要连续，可以为空） class SQA{ public: State st[MAXN]; void build(std::string const \u0026amp; str){ int nxt[26]; std::fill(nxt,nxt+26,0); int n = str.size(); for(int i=n-1;i\u0026gt;=0;i--){ nxt[str[i]-\u0026#39;a\u0026#39;] = i+2;//1号节点是起始空节点 for(int ch=0;ch\u0026lt;26;ch++){ st[i+1].next[ch] = nxt[ch]; } } } bool query(std::string const \u0026amp; str){ //查询str是否是子序列（可以不连续） int p = 1, n=str.size(); for(int i=0;i\u0026lt;n;i++){ p = st[p].next[str[i]-\u0026#39;a\u0026#39;]; if(p==0) return false; } return true; } }; SQA sqa; 数论 欧几里得算法 //复杂度 logn //luogu B3736 //gcd是可重复贡献的，gcd(x,x)=x，可以用st表维护区间gcd //x*y=gcd(x,y)*lcm(x,y)，lcm是最小公倍数 #include \u0026lt;iostream\u0026gt; inline int gcd(int a,int b){ return b==0 ? a : gcd(b, a%b); } int main(){ int x,y,z; std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y\u0026gt;\u0026gt;z; std::cout\u0026lt;\u0026lt;gcd(gcd(x,y),z)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 扩展欧几里得 //复杂度 logn //求解ax+by=c的一组解，c不是gcd(a,b)的倍数则无解 //扩展欧几里得 //luogu P5656 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cmath\u0026gt; using LL = long long; LL exgcd(LL a,LL b,LL\u0026amp; x,LL\u0026amp; y){ //求出的是ax+by=gcd(a,b)的一组解，等于c的需要转换一下 if(b==0){ x = 1; y = 0;//此时ax+by=gcd(a,b)中b=0，任何数与0的最大公约数是他本身，所以ax+0y=a，x=1 y=0 return a; } LL d = exgcd(b,a%b,y,x); y -= (a/b)*x; return d; } int main(){ int T; std::cin\u0026gt;\u0026gt;T; while(T--){ LL a,b,c; std::cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b\u0026gt;\u0026gt;c; LL x0=0, y0=0; LL d = exgcd(a,b,x0,y0);//d=gcd(a,b) if(c%d!=0){//c不是gcd(a,b)的倍数则无解 std::cout\u0026lt;\u0026lt;\u0026#34;-1\\n\u0026#34;; continue; } LL x1 = x0*c/d, y1 = y0*c/d;//ax+by=gcd(a,b)的一组解转化为ax+by=c的一组解 //通解的形式为x=x1+s*dx, y=y1-s*dy //其中s为任意整数，dx=b/d, dy = a/d; LL dx = b/d, dy = a/d; LL l = std::ceil((-x1+1.0)/dx); LL r = std::floor((y1-1.0)/dy); //x\u0026gt;0,y\u0026gt;0时，s的取值为[l,r]中的整数，若l\u0026gt;r，则说明不存在正整数解 if(l\u0026gt;r){ std::cout\u0026lt;\u0026lt;x1+l*dx\u0026lt;\u0026lt;\u0026#34; \u0026#34;;//所有解中x的最小正整数值 std::cout\u0026lt;\u0026lt;y1-r*dy\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;;//所有解中y的最小正整数值 } else{ std::cout\u0026lt;\u0026lt;r-l+1\u0026lt;\u0026lt;\u0026#34; \u0026#34;;//正整数解的个数 std::cout\u0026lt;\u0026lt;x1+l*dx\u0026lt;\u0026lt;\u0026#34; \u0026#34;;//正整数解中x的最小值 std::cout\u0026lt;\u0026lt;y1-r*dy\u0026lt;\u0026lt;\u0026#34; \u0026#34;;//正整数解中y的最小值 std::cout\u0026lt;\u0026lt;x1+r*dx\u0026lt;\u0026lt;\u0026#34; \u0026#34;;//正整数解中x的最大值 std::cout\u0026lt;\u0026lt;y1-l*dy\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;;//正整数解中y的最大值 } } return 0; } 欧拉筛 TODO: 用模板元编程实现编译期算素数\n//复杂度 n //欧拉筛, luogu p3383 int const MAXN = 1e8+5; std::vector\u0026lt;int\u0026gt; prime; bool isnp[MAXN]; void sieve(int n){ for(int i=2;i\u0026lt;=n;i++){ if(!isnp[i]) prime.push_back(i); for(auto p:prime){ if(i*p\u0026gt;n) break; isnp[i*p] = 1; if(i%p==0) break; } } } Miller-Rabin素数测试 //对数 n 进行 k 轮测试的时间复杂度是 klog^3(n) //miller-rabin //loj 143 //通过测试的有可能是素数，不通过的一定不是素数 #include \u0026lt;iostream\u0026gt; #include \u0026lt;ctime\u0026gt; #include \u0026lt;cstdio\u0026gt; #include \u0026lt;cstdint\u0026gt; using LL = __int128;//本题数据范围过大，防止运算中爆掉 LL const test_time = 10; LL qPowMod(LL n, LL p, LL m){ LL res = 1; while(p\u0026gt;0){ if(p\u0026amp;1){ res = (res * n)%m; } n = (n*n)%m; p\u0026gt;\u0026gt;=1; } return res; } bool millerRabin(LL n) { if (n \u0026lt; 3 || n % 2 == 0) return n == 2; LL a = n - 1, b = 0; while (a % 2 == 0) a /= 2, ++b; // test_time 为测试次数,建议设为不小于 8 // 的整数以保证正确率,但也不宜过大,否则会影响效率 for (LL i = 1, j; i \u0026lt;= test_time; ++i) { LL x = rand() % (n - 2) + 2; LL v = qPowMod(x, a, n); if (v == 1) continue; for (j = 0; j \u0026lt; b; ++j) { if (v == n - 1) break; v = v * v % n; } if (j == b) return 0; } return 1; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); srand(time(NULL)); long long n; while(std::cin\u0026gt;\u0026gt;n){ if(millerRabin(n)){ std::cout\u0026lt;\u0026lt;\u0026#34;Y\\n\u0026#34;; } else{ std::cout\u0026lt;\u0026lt;\u0026#34;N\\n\u0026#34;; } } return 0; } 乘法逆元 //复杂度 扩展欧几里得法和费马小定理法都是logn //乘法逆元 //ax≡1(mod b)，x为a在乘法意义上的逆元，记作a^(-1)，或者inv(a) //用扩展欧几里得法的角度看，就是求ax+by=1的整数解 //快速幂法利用费马小定理，需要b为素数，并且疑似比exgcd常数大 //luogu P3811，会TLE，需要线性求逆元 //但loj 110不会TLE int exgcd(int a,int b,int\u0026amp; x,int\u0026amp; y){ if(b==0){ x = 1; y = 0; return a; } int d = exgcd(b,a%b,y,x); y -= (a/b)*x; return d; } int exgcd_inv(int a, int b){ //a在模b意义下的逆元 int x,y; int d = exgcd(a,b,x,y); if(d!=1){//显然a，b要互质才会有逆元 return -1; } else{ return (x+b)%b;//实际上是为了防止出现x为负数的情况 } } int qPowMod(int x, int p, int mod){ //x^p % m int ans = 1; while(p){ if(p\u0026amp;1){ ans = (ans*x)%mod; } x = (x*x)%mod; p\u0026gt;\u0026gt;=1; } return ans; } int fermat_inv(int a, int b){//a在模b意义下的逆元 return qPowMod(a,b-2,b); } 线性求逆元 //线性求逆元，对于1~n这些数，复杂度总共n //luogu p3381, loj 110 #include \u0026lt;iostream\u0026gt; using LL = long long; int const MAXN = 3000005; LL inv[MAXN]; void getinv(LL n, LL m){ //求1~n中，每个数在模m意义下的乘法逆元 inv[1] = 1; for(LL i=2;i\u0026lt;=n;i++){ //inv[i] = -(b/i)*inv[b%i]; //这样写会出现负数 inv[i] = (LL)(m-m/i)*inv[m%i]%m; } } 线性同余方程 //复杂度 logn //ax≡c (mod b)求解x //和ax+by=c等价 //luogu p1082 #include \u0026lt;iostream\u0026gt; using namespace std; int exgcd(int a,int b,int\u0026amp; x,int\u0026amp; y){ if(b==0){ x = 1; y = 0; return a; } int d = exgcd(b,a%b,y,x); y -= (a/b)*x; return d; } int linearEquation(int a, int b, int c, int \u0026amp;x, int \u0026amp;y){ int d = exgcd(a,b,x,y); if(c%d!=0) return -1; x = x*c/d; y = y*c/d; return d; } int main(){ int a,b,c,x,y; cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b; c=1; int d = linearEquation(a,b,c,x,y); //d是a,b的最大公约数，如果无解d==-1 //下面输出的是最小整数解 int t = b/d; x = (x%t+t)%t; cout\u0026lt;\u0026lt;x\u0026lt;\u0026lt;endl; return 0; } 中国剩余定理 求解如下方程中的\\(x\\)\n\\[\\left\\{\\begin{matrix} x \\equiv a_1(mod\\quad r_1) \\\\ x \\equiv a_2(mod\\quad r_2) \\\\ \\vdots \\\\ x \\equiv a_k(mod\\quad r_k) \\end{matrix}\\right. \\]\n其中\\(r_i\\)两两互质，如果不满足则需要扩展CRT。\n设\\(n=r_1r_2\\cdots r_k\\)，计算\\(m_i=n/r_i\\)，计算\\(m_i\\)在模\\(r_i\\)意义下的逆元，计算\\(c_i=m_im_i^{-1}\\)（不要对\\(r_i\\)取模）。方程组在模\\(n\\)意义下有唯一解\\(x=\\sum^k_i a_ic_i\\)（也就意味着\\(x\\)在\\(1\\sim n\\)中必有一解）\n//中国剩余定理 复杂度 klogk //luogu p1495 typedef long long ll; const int MAXN = 10005; ll exgcd(ll a, ll b, ll \u0026amp;x, ll \u0026amp;y){ if(!b){ x=1; y=0; return a; } ll d = exgcd(b,a%b,x,y); ll tmp = x; x = y; y = tmp - (a/b)*y; return d; } ll exgcd_inv(ll a, ll b){ ll x,y; ll d = exgcd(a,b,x,y); return (x+b)%b; } class CRT{ public: ll ax[MAXN],rx[MAXN];//每个方程的形式为x≡ai(mod ri)，要求ri互质 int k=0;//k个方程 void add(ll a, ll r){ ax[++k] = a; rx[k] = r; } ll solve(){ ll n=1, ans=0; for(int i=1;i\u0026lt;=k;i++){ n = n * rx[i]; } for(int i=1;i\u0026lt;=k;i++){ ll m = n/rx[i]; ans = (ans+ax[i]*m*exgcd_inv(m,rx[i]))%n; } return ans; } }; CRT crt; 积性函数 积性函数是数论函数的一种。数论函数则是定义域为正整数的函数。\n若函数\\(f(n)\\)满足\\(f(1)=1\\)且\\(\\forall x,y\\in N^*,gcd(x,y)=1\\)都有\\(f(xy)=f(x)f(y)\\)，则\\(f(n)\\)为积性函数\n如果不要求\\(gcd(x,y)=1\\)也有这个性质的函数叫完全积性函数。同理可知加性函数的定义。\n性质\n若\\(f(x),g(x)\\)均为积性函数，则以下函数也是积性函数 \\(h(x)=f(x^p)\\) \\(h(x)=f^p(x)\\) \\(h(x)=f(x)g(x)\\) \\(h(x)=\\sum_{d|x}f(d)g(x/d)\\)（即狄利克雷卷积） 其逆元 若\\(f\\)是积性函数，且在算术基本定理中\\(n=\\prod^{m}_{i=1}p_i^{c_i}\\)，则\\(f(n)=\\prod^{m}_{i=1}f(p_i^{c_i})\\)。如果\\(f\\)是完全积性函数，则\\(f(n)=\\prod^{m}_{i=1}f(p_i)^{c_i}\\) 例子\n\\(\\varepsilon(n)=[n=1]\\)，单位函数，括号是艾弗森括号，是完全积性。 \\(id_k(n)=n^k\\)，幂函数，是完全积性。\\(k=1\\)是恒等函数\\(id(n)=n\\)，\\(k=0\\)是常数函数\\(1(n)=1\\) \\(\\sigma_k(n)=\\sum_{d/n}d^k\\)，除数函数。当\\(k=1\\)时，为因数和函数\\(\\sigma(n)\\)，当\\(k=0\\)时为因数个数函数\\(\\sigma_0(n)\\) 欧拉函数 莫比乌斯函数 欧拉函数 TODO：习题 \\(1\\sim N\\)中与\\(N\\)互质的数的个数被称为欧拉函数，记为\\(\\varphi(N)\\)\n若在算数基本定理中，\\(N=p_1^{c_1}p_2^{c_2}\\cdots p_m^{c_m}\\)，则\n\\[\\varphi(N)=N\\times\\dfrac{p_1-1}{p_1}\\times\\dfrac{p_2-1}{p_2}\\times\\cdots\\times\\dfrac{p_m-1}{p_m} \\]\n欧拉函数也可以写成艾弗森括号的形式为\n\\[\\sum^n_{i=1}[\\gcd(i,n)=1] \\]\n//复杂度 根号n int phi(int n){ int ans = n; for(int i=2;i*i\u0026lt;=n;i++){ if(n%i==0){ ans = ans/i*(i-1); while(n%i==0) n/=i; } } if(n\u0026gt;1) ans = ans/n*(n-1); return ans; } 欧拉函数有以下性质\n\\(\\forall n\u003e1\\)，\\(1\\sim n\\)中与\\(n\\)互质的数的和为\\(n\\times\\varphi(n)/2\\) 若\\(a,b\\)互质，则\\(\\varphi(ab)=\\varphi(a)\\varphi(b)\\)。也就是说欧拉函数是积性函数 设\\(p\\)为质数，若\\(p|n\\)且\\(p^2|n\\)，则\\(\\varphi(n)=\\varphi(n/p)\\times p\\) 设\\(p\\)为质数，若\\(p|n\\)但不满足\\(p^2|n\\)，则\\(\\varphi(n)=\\varphi(n/p)\\times (p-1)\\) \\(\\sum_{d|n}\\varphi(d)=n\\) 若\\(p\\)是质数，则\\(\\varphi(p^n)=p^{n-1}(p-1)\\) 若\\(a|x\\)，则\\(\\varphi(ax)=a\\varphi(x)\\) //求1-N的所有欧拉函数值，使用筛法，埃氏筛复杂度NloglogN，线性筛复杂度N，这里是线性筛 std::vector\u0026lt;int\u0026gt; prime; bool isnp[MAXN]; int phi[MAXN]; void euler(int n){ phi[1] = 1; for(int i=2;i\u0026lt;=n;i++){ if(!isnp[i]){ prime.push_back(i); phi[i] = i-1; } for(auto p:prime){ if(i*p\u0026gt;n) break; isnp[i*p] = 1; if(i%p==0){ phi[i*p] = phi[i] * p; break; } else{ phi[i*p] = phi[i] * phi[p]; } } } } 狄利克雷卷积 两个数论函数\\(f(n),g(n)\\)的狄利克雷卷积定义为\n\\[(f\\ast g)(n) = \\sum_{xy=n}f(x)g(y) \\]\n也可以写作\n\\[(f\\ast g)(n) = \\sum_{d|n}f(d)g(n/d) \\]\n性质\n两个积性函数的卷积还是积性函数 \\((f\\ast 1)(n) = \\sum_{d|n}f(d)\\) \\((id_k\\ast 1)(n)=\\sum_{d|n}d^k=\\sigma_k\\) \\(\\varphi\\ast 1=id\\) 满足交换率、结合律、对加法的分配律 等式性质，\\(f=g\\)的充要条件是\\(f\\ast h = g\\ast h\\)，其中数论函数\\(h(1)\\neq 0\\) 幺元是\\(\\varepsilon\\)，即\\(f\\ast \\varepsilon=f\\) 逆元，即满足\\(f\\ast g=\\varepsilon\\)的函数\\(g\\)为（显然\\(f(1)\\neq 0\\)才有逆元） \\[g(x)=\\dfrac{\\varepsilon(x)-\\sum_{d|x,d\\neq 1}f(d)g(x/d)}{f(1)} \\]\n积性函数一定有逆元，且逆元也是积性函数。 莫比乌斯反演 TODO：习题 莫比乌斯函数是常数函数\\(1\\)的逆元。即\n\\[\\mu(n) = \\left\\{\\begin{matrix} 1, \u0026 n=1 \\\\ (-1)^m \u0026 n=p_1p_2\\cdots p_m\\\\ 0 \u0026 \\text{otherwise} \\end{matrix}\\right. \\]\n其中第二个条件就是\\(n\\)质因数分解后每个因子的次数是\\(1\\)\n莫比乌斯反演公式即为\n\\[g(n)=\\sum_{d|n}f(d)\\Leftrightarrow f(n) = \\sum_{d|n}\\mu(d)g(n/d) \\]\n用狄利克雷卷积来写就是\n\\[f\\ast 1=g\\Leftrightarrow f=g\\ast \\mu \\]\n还有一种形式（倍数形式，之前的叫因数形式）是\n\\[g(n) = \\sum_{n|N}f(N)\\Leftrightarrow f(n) = \\sum_{n|N}\\mu(N/n)g(N) \\]\n性质\n是积性函数 \\(\\sum_{d|n}\\mu(d)=\\varepsilon(n),\\mu\\ast 1=\\varepsilon\\) \\(\\sum_{d|\\gcd(i,j)}\\mu(d)=[\\gcd(i,j)=1]\\) //线性筛求莫比乌斯函数，复杂度n int mu[MAXN]; std::vector\u0026lt;int\u0026gt; prime; bool isnp[MAXN]; void mobius(int n){ mu[1] = 1; for(int i=2;i\u0026lt;=n;i++){ if(!isnp[i]){ prime.push_back(i); mu[i] = -1; } for(auto p:prime){ if(i*p\u0026gt;n) break; isnp[i*p] = 1; if(i%p==0){ mu[i*p] = 0; break; } else{ mu[i*p] = mu[i] * mu[p]; } } } } 数论分块 在计算形如\n\\[\\sum^n_{i=1}f(i)g(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor ) \\]\n的式子时，注意到\\(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor\\)的取值个数会比\\(n\\)小很多，我们可以将取值相同的合在一起计算。如果可以在\\(O(1)\\)内计算\\(f(l)+\\cdots+f(r)\\)（比如等差数列求和公式）或者有\\(f\\)的前缀和时，数论分块可以在\\(O(\\sqrt{n})\\)计算和式的值。\n定理1\n\\[\\forall a,b,c\\in Z, \\left \\lfloor \\dfrac{a}{bc} \\right \\rfloor=\\left \\lfloor \\dfrac{\\left \\lfloor \\dfrac{a}{b} \\right \\rfloor}{c} \\right \\rfloor \\]\n定理2\n当\\(i\\)取正整数且\\(i\\leq n\\)时，\\(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor\\)的不同取值的数量不超过\\(\\left \\lfloor 2\\sqrt n \\right \\rfloor\\)\n定理3\n使得式子\n\\[\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor = \\left \\lfloor \\dfrac{n}{j} \\right \\rfloor \\]\n成立的最大的满足\\(i\\leq j\\leq n\\)的\\(j\\)值是\\(\\left \\lfloor \\dfrac{n}{\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor} \\right \\rfloor\\)。也就是这个分块的右端点。\n//UVA 11526 //数论分块模板 复杂度sqrt n //要求计算i=1~n, ans = ans+n/i void solve(){ LL n; std::cin\u0026gt;\u0026gt;n; LL ans = 0; LL l = 1, r = 0; while(l\u0026lt;=n){ r = n/(n/l); ans += (r-l+1) * (n/l); l = r+1; } std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } 注意如果不是\\(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor\\)而是某个\\(\\left \\lfloor \\dfrac{k}{i} \\right \\rfloor\\)，要注意特判判\\(k/l\\)等于\\(0\\)，以及\\(r\\)要特判不能超过\\(n\\)。\n当有多个取整\\(\\left \\lfloor \\dfrac{a_1}{i} \\right \\rfloor,\\left \\lfloor \\dfrac{a_2}{i} \\right \\rfloor,\\cdots\\) 时，我们取的右端点就变成每一个块的右端点的最小值。\n杜教筛 杜教筛可以在\\(O(n^{2/3})\\)的时间复杂度下求得一类数论函数（不一定需要积性）\\(f(n)\\)的前缀和。\n我们需要找到一个数论函数\\(g(n)\\)，使得\\(g(n)\\)和\\(f\\ast g(n)\\)的前缀和都很容易求出（最好在\\(O(1)\\)），那我们就能以低于线性复杂度的算法求出\\(f(n)\\)的前缀和\\(S(n)\\)。证明略，结论为：\n\\[g(1)S(n) = \\sum^n_{i=1}(f\\ast g)(i)-\\sum^n_{i=2}g(i)S(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor) \\]\n筛莫比乌斯函数\n之前我们学到\\(\\mu\\ast 1=\\varepsilon\\)，所以我们自然的令\\(g(n)=1\\)，得到\n\\[S(n)=\\sum^n_{i=1}\\varepsilon(i)-\\sum^n_{i=2}S(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor) = 1-\\sum^n_{i=2}S(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor) \\]\n此时如果我们直接用数论分块去算\\(S(n)\\)，我们的算法复杂度是\\(O(n^{3/4})\\)，但是如果我们用线性筛预处理前\\(n^{2/3}\\)的\\(S(n)\\)的值，就可以优化复杂度到\\(O(n^{2/3})\\)，通常我们还会开一个哈希表去维护大于\\(n^{2/3}\\)的值来优化。\n筛欧拉函数\n同样取\\(g(n)=1\\)，有\\(\\varphi(n)\\ast 1=id\\)\n\\[S(n) = \\sum^n_{i=1}id-\\sum^n_{i=2}S(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor) = \\dfrac{n(1+n)}{2}-\\sum^n_{i=2}S(\\left \\lfloor \\dfrac{n}{i} \\right \\rfloor) \\]\n跟之前可以说没什么区别。\n给出求欧拉函数和莫比乌斯函数前缀和的例子代码。这里筛法一次把两个函数都筛了，其他不难理解。注意要用unordered_map以及数论分块的时候\\(l\\)从\\(2\\)开始。以及洛谷上这题数据范围为2^31，要筛出大概前170w个数。我筛了200w也过了，分类讨论，前200w直接返回，大于200w的如果在map里就返回，否则递归计算后放入map里。\n//杜教筛 复杂度n^(2/3) //luogu p4213 int const MAXN = 2000005; int mu[MAXN]; LL phi[MAXN]; std::vector\u0026lt;int\u0026gt; prime; bool isnp[MAXN]; LL sum_mu[MAXN],sum_phi[MAXN]; std::unordered_map\u0026lt;LL,LL\u0026gt; mp_mu,mp_phi; void sieve(int n=MAXN-1){ mu[1] = 1; phi[1] = 1; for(int i=2;i\u0026lt;=n;i++){ if(!isnp[i]){ prime.push_back(i); mu[i] = -1; phi[i] = i-1; } for(auto p:prime){ if(i*p\u0026gt;n) break; isnp[i*p] = 1; if(i%p==0){ mu[i*p] = 0; phi[i*p] = phi[i] * p; break; } else{ mu[i*p] = mu[i] * mu[p]; phi[i*p] = phi[i] * phi[p]; } } } for(int i=1;i\u0026lt;=n;i++){ sum_mu[i] = sum_mu[i-1]+mu[i]; sum_phi[i] = sum_phi[i-1]+phi[i]; } } LL sum1(LL n){ if(n\u0026lt;MAXN){ return sum_phi[n]; } if(mp_phi.count(n)){ return mp_phi[n]; } LL l=2, r=0; LL ret = n*(1+n)/2; while(l\u0026lt;=n){ r = n/(n/l); ret -= (r-l+1)*sum1(n/l); l = r+1; } mp_phi[n] = ret; return ret; } LL sum2(LL n){ if(n\u0026lt;MAXN){ return sum_mu[n]; } if(mp_mu.count(n)){ return mp_mu[n]; } LL l=2, r=0; LL ret = 1; while(l\u0026lt;=n){ r = n/(n/l); ret -= (r-l+1)*sum2(n/l); l = r+1; } mp_mu[n] = ret; return ret; } void solve(){ LL n; std::cin\u0026gt;\u0026gt;n; std::cout\u0026lt;\u0026lt;sum1(n)\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;sum2(n)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); sieve(); int T; std::cin\u0026gt;\u0026gt;T; //T=1; while(T--){ solve(); } return 0; } 图论 存图 邻接矩阵 int graph[MAXN][MAXN]; //加边删边、访问很方便，a-\u0026gt;b，权值为w，则graph[a][b]=w //空间占用大，并且不能存重边 邻接表（vector版） struct Edge{ int v,w;//下一点，权 }; std::vector\u0026lt;Edge\u0026gt; edges[MAXN]; //加边u-\u0026gt;v,权值w edges[u].push_back(w); //访问只能遍历u所连的出边 for(auto x:edges[u]){ std::cout\u0026lt;\u0026lt;x.v\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;x.w\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } //缺点是，删边难，以及清空边复杂度过高。快速清边见链式前向星传统数组版 链式前向星（vector版） struct Edge{ int v;LL w;//指向的点，容量 Edge(int v_, LL w_):v(v_),w(w_){} }; std::vector\u0026lt;Edge\u0026gt; edges; std::vector\u0026lt;std::vector\u0026lt;int\u0026gt; \u0026gt; graph(MAXN); //常用于网络流，例如加u-\u0026gt;v，权值为w，及其反向边v-\u0026gt;w，权值为0 graph[u].push_back(edges.size()); edges.push_back(Edge(v,w)); graph[v].push_back(edges.size()); edges.push_back(Edge(u,0)); //遍历u的边时 for(auto x:graph[u]){ auto e=edges[x]; auto v=e.v, w=e.w; //e的反向边就是edges[x^1] } //清空某个点连出的所有边时，graph[u].clear()，不需要管edges的size //清除整个图时edges.clear()，graph要对每个下标clear //这种清除方式复杂度比传统数组版高很多，需要反复建图时不推荐使用。 //好处是不需要让边编号从2开始，从0开始即可存反向边 链式前向星（传统数组版） struct Edge{ int v,w,next;//指向的点，边权，下一条边 }; Edge edges[MAXM];//存无向图记得开两倍 int head[MAXN],cnt;//如果要存反向边，并且用^1取反向边，应初始化cnt=1 //不应把后面add的逻辑改成最后再cnt++，因为我们遍历边的时候是判断e是否等于0，所以不应该有边的编号等于0 inline void add(int u, int v, int w){ edges[++cnt].w = w; edges[cnt].v = v; edges[cnt].next = head[u];//把下一条边设置为当前起点的第一条边 head[u] = cnt;//该边称为当前起点的第一条边 } //遍历，与vector版不同，vector版按加入先后顺序遍历，而这里是反向顺序遍历。绝大多数情况不影响 //例如遍历1号节点所连的边 for(int e=head[1];e;e=edges[e].next){ std::cout\u0026lt;\u0026lt;edges[e].v\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;edges[e].w\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } //当需要清空某个点的所有连出边时, head[u] = 0，不需要管cnt //清空全图时，cnt = 0, 对于所有点head = 0， 由于还可以用memset，比vector版更是快了不少 最短路 Dijkstra //复杂度 优先队列实现为mlogm //dijkstra，单源最短路 //luogu p4779 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; #define MAXN 500005 #define MAXINT 0x7fffffff struct Edge{ int v,w;//下一点，权 Edge(int v_, int w_):v(v_),w(w_){} }; struct Node { int dis, u;//存储起点到u点的距离 Node(int dis_, int u_):dis(dis_),u(u_){}; bool operator\u0026gt;(Node const \u0026amp; a) const { return dis \u0026gt; a.dis; } }; std::vector\u0026lt;Edge\u0026gt; graph[MAXN]; int dis[MAXN]; bool tag[MAXN]; std::priority_queue\u0026lt;Node, std::vector\u0026lt;Node\u0026gt;, std::greater\u0026lt;Node\u0026gt; \u0026gt; pq; void init(int n){ for(int i=1;i\u0026lt;=n;i++){ dis[i] = MAXINT; //初始化为无限远 tag[i] = 0; graph[i].clear(); } while(!pq.empty()) pq.pop(); } void dijk(int s){ dis[s]=0; pq.push(Node(0,s)); while (!pq.empty()) { int u = pq.top().u; pq.pop(); if(tag[u]) continue; tag[u]=1; for(auto g : graph[u]){ int v = g.v, w = g.w; if(dis[v]\u0026gt;dis[u]+w){ dis[v] = dis[u]+w; pq.push(Node(dis[v],v)); } } } } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m,s; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s; //点数，边数，起点 init(n); for(int i=1;i\u0026lt;=m;i++){ int u,v,w; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w;//起点，终点，边权 graph[u].push_back(Edge(v,w)); } dijk(s); for(int i=1;i\u0026lt;=n;i++){ std::cout\u0026lt;\u0026lt;dis[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } return 0; } Bellman-Ford //复杂度 nm //bellman-ford, 单源最短路 //luogu p4779，有一个点TLE #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;cstring\u0026gt; int const MAXN = 100005; int const INF = 0x6fffffff; struct Edge{ int v,w;//下一点,权 Edge(int v_, int w_):v(v_),w(w_){} }; int dis[MAXN]; std::vector\u0026lt;Edge\u0026gt; graph[MAXN]; void init(int n){ for(int i=1;i\u0026lt;=n;i++){ dis[i]=INF; graph[i].clear(); } } bool BF(int n, int s){ //如果不存在最短路就返回0，否则返回1 dis[s] = 0; bool flag = 1; for (int i=1;i\u0026lt;=n;i++){//松弛n-1轮，若第n轮还能松弛，就说明有负环 flag = 1; for(int u=1;u\u0026lt;=n;u++){//这里看似是两层循环，实际上总数是边数，整个算法的复杂度是mn for (auto e : graph[u]){ int w=e.w,v=e.v; if(dis[v]\u0026gt;dis[u]+w){ dis[v]=dis[u]+w; flag = 0; } } } if(flag){ break; } } return flag; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m,s;//点数，边数，起点 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s; init(n); for(int i=1;i\u0026lt;=m;i++){ int u,v,w; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w; //起点，终点，边权 graph[u].push_back(Edge(v,w)); } BF(n,s); for(int i=1;i\u0026lt;=n;i++){ std::cout\u0026lt;\u0026lt;dis[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } return 0; } SPFA //复杂度 nm /* bellman-ford的优化 只有上一次被松弛的结点，所连接的边， 才有可能引起下一次的松弛操作 */ //spfa 单源最短路 //luogu P3371 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; int const MAXN = 100005; int const INF = 0x5fffffff; struct Edge{ int v,w; Edge(int v_, int w_):v(v_),w(w_){} }; int dis[MAXN];//距离 int cnt[MAXN];//算到达本节点所要经过的边数，若cnt\u0026gt;=n，则说明有负权环 bool tag[MAXN];//用于判断是否为上次松弛过的节点的边所连的点 std::queue\u0026lt;int\u0026gt; qu; std::vector\u0026lt;Edge\u0026gt; graph[MAXN]; void init(int n){ while(!qu.empty()) qu.pop(); for(int i=1;i\u0026lt;=n;i++){ dis[i] = INF; cnt[i] = 0; tag[i] = 0; graph[i].clear(); } } bool SPFA(int n, int s){ //如果不存在最短路就返回0，否则返回1 dis[s] = 0; tag[s] = 1; qu.push(s); bool flag = 1; while(!qu.empty()){ if(!flag) break; int u = qu.front(); qu.pop(); tag[u]=0; for(auto e : graph[u]){ int v = e.v, w = e.w; if(dis[v]\u0026gt;dis[u]+w){ dis[v]=dis[u]+w; cnt[v]=cnt[u]+1; if(cnt[v]\u0026gt;=n) { flag = 0; break; } if(!tag[v]){ qu.push(v); tag[v]=1; } } } } return flag; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m,s; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s; init(n); for(int i=1;i\u0026lt;=m;i++){ int u,v,w; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w; //起点，终点，边权 graph[u].push_back(Edge(v,w)); } SPFA(n,s); for(int i=1;i\u0026lt;=n;i++){ if(dis[i]!=INF){ std::cout\u0026lt;\u0026lt;dis[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } else{ std::cout\u0026lt;\u0026lt;\u0026#34;2147483647 \u0026#34;;//根据luogu P3371要输出这个数 } } return 0; } Floyd //复杂度 n^3 //floyd全源最短路 //luogu p5905，由于不能判断负环和速度慢，会wa和tle一些 //floyd虽然不能处理负环但是可以接受负边 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; using LL = long long; int const MAXN = 3005; LL const INF = 1e17; //不能设置为int的最大值，否则后面加法可能导致溢出 LL graph[MAXN][MAXN]; int main(){ int n,m;//点数，边数 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; for(int i = 1;i\u0026lt;=n;i++){ for(int j = 1;j\u0026lt;=n;j++){ graph[i][j] = INF; } } for(int i=1;i\u0026lt;=m;i++){ int u,v;LL w; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w;//起点，终点，边权 graph[u][v] = std::min(graph[u][v], w);//处理重边 } for(int i = 1;i\u0026lt;=n;i++){ graph[i][i] = 0; } for(int k=1;k\u0026lt;=n;k++){ for(int i=1;i\u0026lt;=n;i++){ for(int j=1;j\u0026lt;=n;j++){ graph[i][j] = std::min(graph[i][j],graph[i][k]+graph[k][j]); } } } for(int i=1;i\u0026lt;=n;i++){ LL res=0; for(LL j=1;j\u0026lt;=n;j++){ if(graph[i][j]\u0026gt;1e9) graph[i][j] = 1e9; res += j*graph[i][j]; } std::cout\u0026lt;\u0026lt;res\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } Johnson TODO 差分约束 给出一组不等式\n\\[\\left\\{\\begin{matrix} x_{c_1}-x_{c_1'}\\leq y_1 \\\\ x_{c_2}-x_{c_2'}\\leq y_2 \\\\ \\vdots \\\\ x_{c_m}-x_{c_m'}\\leq y_m \\end{matrix}\\right. \\]\n其中一共有\\(n\\)个未知数\\(x_1,x_2,\\cdots,x_n\\)，\\(m\\)个不等式，求一组可行解。\n我们连边，连一条\\(x_{c_i'}\\)到\\(x_{c_i}\\)，权值为\\(y_i\\)的边。然后增加\\(n+1\\)号节点，从它到所有点连一条权值为\\(0\\)的边。然后以\\(n+1\\)为源点求到各点的最短路，这个最短距离dis[i]就是\\(x_i\\)的一个解。\n当然，出现负环就无解。\n不难理解，\\(x_1,x_2,\\cdots,x_n\\)全部加上或减去同一个数，仍然是可行解。\n之前我们假设dis[n+1]=0，如果我们设置dis[n+1] = w，那么我们求得的就是\\(x_1,x_2,\\cdots,x_n\\leq w\\)的一组解。实际上，可以证明这个解是满足\\(x_1,x_2,\\cdots,x_n\\leq w\\)的最大解（每个变量能取得的最大值）。\n如果题目上的约束条件全部变为\\(\\geq\\)型，我们要求满足\\(x_1,x_2,\\cdots,x_n\\geq w\\)的最小解，则只需要求最长路即可。对于Bellman-Ford和SPFA来说，初始化dis为-INF，然后颠倒比较符号即可。\n题目中不总是给出\\(x_1-x_2\\leq y\\)，但我们可以转化\n\\(x_1-x_2\\geq y\\Rightarrow x_2-x_1\\leq -y\\) \\(x_1-x_2=y\\Rightarrow x_1-x_2\\leq y \\wedge x_2-x_1\\leq -y\\) \\(x_1-x_2\u003c y\\Rightarrow x_1-x_2\\leq y-1\\)（要求取值只能是整数） \\(x_1-x_2\u003ey\\Rightarrow x_2-x_1\\leq -y-1\\)（要求取值只能是整数） //差分约束，复杂度同SPFA //luogu p5960 //使用介绍见markdown #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; int const MAXN = 5005; int const INF = 0x5fffffff; struct Edge{ int v,w; Edge(int v_, int w_):v(v_),w(w_){} }; int dis[MAXN];//距离 int cnt[MAXN];//算到达本节点所要经过的边数，若cnt\u0026gt;=n，则说明有负权环 bool tag[MAXN];//用于判断是否为上次松弛过的节点的边所连的点 std::queue\u0026lt;int\u0026gt; qu; std::vector\u0026lt;Edge\u0026gt; graph[MAXN]; void init(int n){ while(!qu.empty()) qu.pop(); for(int i=1;i\u0026lt;=n;i++){ dis[i] = INF; cnt[i] = 0; tag[i] = 0; graph[i].clear(); } } bool SPFA(int n, int s){ //如果不存在最短路就返回0，否则返回1 dis[s] = 0; tag[s] = 1; qu.push(s); bool flag = 1; while(!qu.empty()){ if(!flag) break; int u = qu.front(); qu.pop(); tag[u]=0; for(auto e : graph[u]){ int v = e.v, w = e.w; if(dis[v]\u0026gt;dis[u]+w){ dis[v]=dis[u]+w; cnt[v]=cnt[u]+1; if(cnt[v]\u0026gt;=n) { flag = 0; break; } if(!tag[v]){ qu.push(v); tag[v]=1; } } } } return flag; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; init(n+1); for(int i=1;i\u0026lt;=m;i++){ int v,u,w; std::cin\u0026gt;\u0026gt;v\u0026gt;\u0026gt;u\u0026gt;\u0026gt;w; graph[u].push_back(Edge(v,w)); } for(int i=1;i\u0026lt;=n;i++){ graph[n+1].push_back(Edge(i,0)); } n++; if(!SPFA(n,n)){ std::cout\u0026lt;\u0026lt;\u0026#34;NO\\n\u0026#34;; return 0; } for(int i=1;i\u0026lt;=n-1;i++){ std::cout\u0026lt;\u0026lt;dis[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } return 0; } 拓扑排序 //复杂度 n //拓扑排序, luogu B3644 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; int const MAXN = 105; std::vector\u0026lt;int\u0026gt; graph[MAXN]; int in[MAXN]; int main(){ int n; std::cin\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ while(true){ int v; std::cin\u0026gt;\u0026gt;v; if(v==0) break; graph[i].push_back(v); in[v]++; } } std::queue\u0026lt;int\u0026gt; qu; for(int i=1;i\u0026lt;=n;i++){ if(in[i]==0) qu.push(i); } while(!qu.empty()){ int u = qu.front(); qu.pop(); std::cout\u0026lt;\u0026lt;u\u0026lt;\u0026lt;\u0026#34; \u0026#34;; for(auto v:graph[u]){ in[v]--; if(in[v]==0) qu.push(v); } } return 0; } 最小生成树 Kruskal //复杂度 mlogm //最小生成树Kruskal，luogu p3366 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; int const MAXM = 200005; int const MAXN = 5005; struct Edge{ int u,v,w;//最小生成树是在无向图上跑的，由于要排序，所以记录uvw bool operator\u0026lt;(Edge const \u0026amp; x) const { return w\u0026lt;x.w; } }; Edge edges[MAXM]; int find_sets[MAXN];//并查集 int find(int x){return find_sets[x]==x ? x : find_sets[x] = find(find_sets[x]);} int main(){ int n,m;//点数和边数 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; for(int i=1;i\u0026lt;=m;i++){ std::cin\u0026gt;\u0026gt;edges[i].u\u0026gt;\u0026gt;edges[i].v\u0026gt;\u0026gt;edges[i].w; } std::sort(edges+1,edges+1+m); for(int i=1;i\u0026lt;=n;i++){ find_sets[i]=i; } int ans = 0; int cnt=0; for(int i=1;i\u0026lt;=m;i++){ int u = edges[i].u, v = edges[i].v; int x = find(u); int y = find(v); if(x!=y){ ans += edges[i].w; find_sets[x] = y; cnt++; } } //计数，如果小于n-1则不连通 if(cnt\u0026lt;n-1){ std::cout\u0026lt;\u0026lt;\u0026#34;orz\\n\u0026#34;; } else{ std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } Prim算法 //复杂度 (m+n)logn //最小生成树prim，luogu p3366 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; const int MAXN = 5005; const int MAXM = 200005; const int INF = 0x5fffffff; struct edge{ int v,w; edge(){}; edge(int v,int w):v(v),w(w){} bool operator\u0026gt;(const edge\u0026amp; x) const {return w\u0026gt;x.w;} }; std::vector\u0026lt;edge\u0026gt; graph[MAXN]; bool vis[MAXN]; std::priority_queue\u0026lt;edge, std::vector\u0026lt;edge\u0026gt;, std::greater\u0026lt;edge\u0026gt; \u0026gt; pq; int main(){ int n,m;//点数，边数 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; int ans = 0; int cnt = 1; for(int i=1;i\u0026lt;=m;i++){ int u,v,w;//起点，终点，边权 std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w; graph[u].push_back(edge(v,w)); graph[v].push_back(edge(u,w)); //无向图 } for(int i=0;i\u0026lt;graph[1].size();i++){ pq.push(graph[1][i]); } vis[1]=true; while(cnt!=n\u0026amp;\u0026amp;!pq.empty()){ edge minx=pq.top(); pq.pop(); while(vis[minx.v]){ if(pq.empty()){ std::cout\u0026lt;\u0026lt;\u0026#34;orz\\n\u0026#34;;//不连通 return 0; } minx=pq.top(); pq.pop(); } vis[minx.v] = true; ans+=minx.w; cnt++; for(int i=0;i\u0026lt;graph[minx.v].size();i++){ if(!vis[graph[minx.v][i].v]) pq.push(graph[minx.v][i]); } } if(cnt\u0026lt;n){ std::cout\u0026lt;\u0026lt;\u0026#34;orz\\n\u0026#34;; } else{ std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } 最小树形图（朱刘算法） //复杂度 nm //最小树形图，朱刘算法 //从根节点能到达其他所有点 //luogu4716 #include \u0026lt;iostream\u0026gt; const int MAXN = 105; const int MAXM = 10005; const int INF = 0x7fffffff; struct Edge{ int u,v,w; }; Edge edge[MAXM]; int vis[MAXN],id[MAXN]; int in[MAXN],pre[MAXN]; int zhuliu(int n, int m, int root){ //返回最小树形图的边权和，如果不存在则返回-1 int ans = 0; for(;;){ for(int i=1;i\u0026lt;=n;i++) in[i]=INF; for(int i=1;i\u0026lt;=m;i++){ int u = edge[i].u; int v = edge[i].v; if(u!=v \u0026amp;\u0026amp; edge[i].w\u0026lt;in[v]){//遍历所有边，找到对每个点的最短入边 in[v] = edge[i].w; pre[v] = u; } } for(int i=1;i\u0026lt;=n;i++){ if(i!=root \u0026amp;\u0026amp; in[i]==INF){ return -1;//无解 } } int cnt = 0;//记录环数以及下一次循环的点数 for(int i=1;i\u0026lt;=n;i++){ vis[i] = -1; id[i] = -1; } in[root] = 0; for(int i=1;i\u0026lt;=n;i++){ if(i==root) continue; ans += in[i]; int v=i; while(vis[v]!=i\u0026amp;\u0026amp;id[v]==-1\u0026amp;\u0026amp;v!=root){ vis[v] = i; v = pre[v]; } if(v!=root \u0026amp;\u0026amp; id[v]==-1){ id[v] = ++cnt; for(int u=pre[v];u!=v;u=pre[u]) id[u] = cnt; } } if(cnt==0){//无环，得到解 break; } for(int i=1;i\u0026lt;=n;i++){ if(id[i]==-1) id[i]=++cnt; } for(int i=1;i\u0026lt;=m;i++){ int u = edge[i].u; int v = edge[i].v; edge[i].u = id[u]; edge[i].v = id[v]; if(edge[i].u!=edge[i].v) edge[i].w -= in[v]; } n = cnt; root = id[root]; } return ans; } int main(){ int n,m,root; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;root; //点数，边数，根节点序号 for(int i=1;i\u0026lt;=m;i++){ std::cin\u0026gt;\u0026gt;edge[i].u\u0026gt;\u0026gt;edge[i].v\u0026gt;\u0026gt;edge[i].w; //起点，终点，边权 } std::cout\u0026lt;\u0026lt;zhuliu(n,m,root)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 二分图判定 一张无向图是二分图，当且仅当图中不存在长度为奇数的环。\n我们可以用染色法来判定。假设染成两种颜色，一个节点被染色后，所有相连节点都应该染成另一种颜色，如果有冲突，则说明不是二分图。\n二分图匹配 最大匹配（匈牙利算法） //复杂度 nm //luogu p3386 //求二分图最大匹配，根据定理，最大匹配=最小点覆盖，以及最小边覆盖=点数-最大匹配 //二分图是\u0026#34;可以将点集分为两个不相交的部分，所有边连接的两个顶点在不同的部分中\u0026#34;的图 //二分图的匹配：边集的任意子集的任意两条边都没有公共顶点，则这个子集是一个匹配 //二分图的最大匹配：所有匹配中边数最多的 //最小点覆盖：选最少的点，满足每条边至少有一个端点被选 //最大独立集：选最多的点，满足两两之间没有边相连 //这里的二分图是无向图 //如果最大匹配中所有点都被匹配，那么叫做完美匹配 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; const int MAXN = 505; bool graph[MAXN][MAXN]; bool vis[MAXN]; int toLeft[MAXN];//标记右边节点i连到了哪个左边界点，即toLeft[i] bool match(int const \u0026amp; i, int const \u0026amp; rightNum){ for(int j=1;j\u0026lt;=rightNum;j++){ if(graph[i][j]\u0026amp;\u0026amp;!vis[j]){ vis[j] = true; if(toLeft[j]==0 || match(toLeft[j], rightNum)){ toLeft[j] = i; return true; } } } return false; } int hungarian(int const \u0026amp; leftNum, int const \u0026amp; rightNum){ //返回最大的边数 int cnt = 0; for(int i=1;i\u0026lt;=leftNum;i++){ std::memset(vis,0,sizeof(vis)); if(match(i,rightNum)) cnt++; } return cnt; } int main(){ int n,m,e;//左边点数，右边点数，边数 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;e; for(int i=1;i\u0026lt;=e;i++){ int x,y; std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y; graph[x][y] = true; } std::cout\u0026lt;\u0026lt;hungarian(n,m)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 二分图的相关定理 Konig定理：一个二分图中的最大匹配数等于这个图中的最小点覆盖数。\n最大独立集=点数-最小点覆盖。\n最大匹配转换为网络流模型 将源点连上左边所有点，右边所有点连上汇点，容量都为1。原来的每条边从左往右连边（转成了有向有容量图），容量也为1，最大流即最大匹配。用Dinic算法求复杂度为\\(O(\\sqrt nm)\\)\n二分图最大权完美匹配（KM算法） TODO: BFS版 //luogu p6577 //二分图的最大权匹配，必须是完美匹配才能正确运行，即左右各n个点，最大匹配有n条边。虽然KM算法必须是完美匹配才可以运行而转化为费用流则不需要，但是KM算法在稠密图上的效率会高于费用流 //随机数据O(n^3)，最坏O(n^4)，所以luogu p6577上会超时一些数据 //这主要是他卡dfs版的，bfs版的可以通过。但luogu p3967不卡dfs //最大权匹配指二分图中边权和最大的匹配，最大权匹配不一定是最大匹配 //如果要跑多次KM算法记得把toLeft数组初始化 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; typedef long long LL; const int MAXN = 505; const LL INF = 1e17; LL graph[MAXN][MAXN]; LL labelL[MAXN], labelR[MAXN]; bool visL[MAXN],visR[MAXN]; int toLeft[MAXN]; LL upd[MAXN]; bool match(int const \u0026amp; i, int const \u0026amp; pointNum){ visL[i] = true; for(int j=1;j\u0026lt;=pointNum;j++){ if(!visR[j]){ if(labelL[i]+labelR[j]-graph[i][j]==0){ visR[j] = true; if(!toLeft[j]||match(toLeft[j],pointNum)){ toLeft[j] = i; return true; } } else{ upd[j] = std::min(upd[j],labelL[i]+labelR[j]-graph[i][j]); } } } return false; } LL KM(int const \u0026amp; pointNum){ for(int i=1;i\u0026lt;=pointNum;i++){ labelL[i] = -INF; labelR[i] = 0; for(int j=1;j\u0026lt;=pointNum;j++) labelL[i] = std::max(labelL[i], graph[i][j]); } for(int i=1;i\u0026lt;=pointNum;i++){ while(true){ std::memset(visL,0,sizeof(visL)); std::memset(visR,0,sizeof(visR)); for(int j=1;j\u0026lt;=pointNum;j++) upd[j] = INF; if(match(i,pointNum)) break; LL delta = INF; for(int j=1;j\u0026lt;=pointNum;j++) if(!visR[j]) delta = std::min(delta,upd[j]); for(int j=1;j\u0026lt;=pointNum;j++){ if(visL[j]) labelL[j] -= delta; if(visR[j]) labelR[j] += delta; } } } LL ans = 0; for(int i=1;i\u0026lt;=pointNum;i++) ans += graph[toLeft[i]][i]; return ans;//输出最大权匹配的权值和 } int main(){ int n,e;//一边的点数；边数 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;e; for(int i=1;i\u0026lt;=n;i++){ for(int j=1;j\u0026lt;=n;j++){ graph[i][j] = -INF; } } for(int i=1;i\u0026lt;=e;i++){ int x,y; std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y; std::cin\u0026gt;\u0026gt;graph[x][y];//这里是左边有n个点，右边有n个点 //左边第x个点到右边第y个点的边权，并不是双向边 } std::cout\u0026lt;\u0026lt;KM(n)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; for(int i=1;i\u0026lt;=n;i++){ std::cout\u0026lt;\u0026lt;toLeft[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } std::cout\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 最大权匹配转化为费用流 新增一个源点和一个汇点，从源点向二分图的每个左部点连一条流量为1，费用为0的边；从每个右部点向汇点连一条流量为1，费用为0的边；从左部点i向右部点j连一条流量为1，费用为c的边。然后这些边的反向边也要注意连上。然后求这个网络的最大费用最大流即可。\n具体而言，最大费用的求法最好不要去该内部算法实现。把费用取相反数，然后最后答案再取相反数即可。\n如果要输出方案，就遍历右边点到左边点的反向边，如果实际流量w变为1了，则说明走了这条边，也就是这两个点配对。\n目前为止还只能处理完美匹配的情况。因为最大费用最大流是在最大流的前提下采取计算最大费用，也就是说它会去计算最大匹配再去计算其中的最大权。而最大权匹配是只要求权最大而不用一定是最大匹配。\n解决方法是把左部点连一条边到汇点，容量为1，费用为0，再去求最大费用最大流。这样如果这条边有实际流量通过（即w变成0），他是失配的。\n动态维护二分图判定 TODO: 例题 只判定一次可以用涂色法。动态加边可以用扩展域并查集（可撤销）来实现。\nstd::stack\u0026lt;pii\u0026gt; stk; class DSU{ public: int fa[MAXN*2], rk[MAXN*2]; void init(int n){ for(int i=1;i\u0026lt;=n;i++) fa[i] = i, rk[i] = 1; } int find(int x){ return fa[x]==x ? x : find(fa[x]); } void merge(int x, int y){ x = find(x), y = find(y); if(x==y) return; if(rk[x]\u0026gt;rk[y]) std::swap(x,y); fa[x] = y; stk.push({x,rk[x]==rk[y]});//保存操作记录，也可以用stack以外的数据结构 if(rk[x]==rk[y]) rk[y]++; } void erase(pii p){ rk[find(p.first)]-=p.second; fa[p.first] = p.first; } }; bool add(int x, int y){ //设总共n个点，每次添加一条边\u0026lt;x,y\u0026gt;，注意没有边也算二分图 dsu.merge(x,y+n); dsu.merge(y,x+n); if(dsu.find(x)==dsu.find(x+n) || dsu.find(y)==dsu.find(y+n)){ //说明不是二分图 return false; } else{ //说明是二分图 return true; } } //删边的时候，需要注意用一个pii删（调用erase函数），first保存了\u0026lt;x,y\u0026gt;这条边的x（y可以用find函数找出来），second保存了秩的数据，在删边时有用。至于删完是不是二分图，我没有找到办法。我做过的题目都是，添加了这条边后不再是二分图，输出某个结果，然后撤销这条边（之后显然是二分图）。要不就是只有加边的。直接删去任意一条边的题目并没有遇到过。 网络流 最大流 DFS实现的Ford-Fulkerson //luogu 3376 //复杂度O(ef)，边数乘以最大流，所以在luogu上这题超时 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; typedef long long LL; const int MAXN = 205; const LL INF = 0xffffffff; struct Edge{ int v;LL w;//指向的点，容量 Edge(int v_, LL w_):v(v_),w(w_){} }; std::vector\u0026lt;Edge\u0026gt; edges; std::vector\u0026lt;std::vector\u0026lt;int\u0026gt; \u0026gt; graph(MAXN);//vector版的链式前向星 bool vis[MAXN]; LL DFS(int const \u0026amp; p, LL const \u0026amp; flow, int const \u0026amp; s, int const \u0026amp; t){ if(p==t) return flow; vis[p] = true; int size = graph[p].size(); for(int i=0 ; i\u0026lt;size ; i++){ int eg = graph[p][i]; int to = edges[eg].v; LL vol = edges[eg].w, c; if(vol\u0026gt;0 \u0026amp;\u0026amp; !vis[to] \u0026amp;\u0026amp; (c=DFS(to,std::min(flow,vol),s,t))!=-1){ edges[eg].w -= c; edges[eg^1].w += c; return c; } } return -1; } LL FF(int const \u0026amp; p, LL const \u0026amp; flow, int const \u0026amp; s, int const \u0026amp; t){ LL ans = 0, c; while((c=DFS(p,flow,s,t))!=-1){ std::memset(vis,0,sizeof(vis)); ans += c; } return ans; } int main(){ int n,m,s,t;//点数，边数，源点，汇点 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s\u0026gt;\u0026gt;t; for(int i=1;i\u0026lt;=m;i++){ int u,v;LL w; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w;//起点，终点，边容量 graph[u].push_back(edges.size()); edges.push_back(Edge(v,w)); graph[v].push_back(edges.size()); edges.push_back(Edge(u,0)); } std::cout\u0026lt;\u0026lt;FF(s,INF,s,t)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;;//输出最大流 return 0; } EdmondsKarp //luogu P3376 //EK算法的时间复杂度为O(nm^2)，这题不会超时 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; typedef long long LL; const int MAXN = 205; const LL INF = 0xffffffff; struct Edge{ int v;LL w;//指向的点，容量 Edge(int v_, LL w_):v(v_),w(w_){} }; std::vector\u0026lt;Edge\u0026gt; edges; std::vector\u0026lt;std::vector\u0026lt;int\u0026gt; \u0026gt; graph(MAXN);//vector版的链式前向星 int last[MAXN]; LL flow[MAXN]; bool BFS(int const \u0026amp; s, int const \u0026amp; t){ std::memset(last,-1,sizeof(last)); std::queue\u0026lt;int\u0026gt; qu; qu.push(s); flow[s] = INF; while(!qu.empty()){ int p = qu.front(); qu.pop(); if(p == t) break; int size = graph[p].size(); for(int i=0;i\u0026lt;size;i++){ int eg = graph[p][i]; int to = edges[eg].v; LL vol = edges[eg].w; if(vol\u0026gt;0 \u0026amp;\u0026amp; last[to] == -1){ last[to] = eg; flow[to] = std::min(flow[p], vol); qu.push(to); } } } return last[t] != -1; } LL EK(int const \u0026amp; s, int const \u0026amp; t){ LL ans = 0; while(BFS(s,t)){ ans += flow[t]; for(int i=t;i!=s;i=edges[last[i]^1].v){ edges[last[i]].w -= flow[t]; edges[last[i]^1].w += flow[t]; } } return ans; } int main(){ int n,m,s,t;//点数，边数，源点，汇点 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s\u0026gt;\u0026gt;t; for(int i=1;i\u0026lt;=m;i++){ int u,v;LL w; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w; graph[u].push_back(edges.size()); edges.push_back(Edge(v,w)); graph[v].push_back(edges.size()); edges.push_back(Edge(u,0)); } std::cout\u0026lt;\u0026lt;EK(s,t)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } Dinic TODO: 如果可能换成链式前向星 //luogu P3376 //Dinic算法的时间复杂度为O(n^2m)，这题不会超时 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; typedef long long LL; const int MAXN = 205; const LL INF = 0xffffffff; struct Edge{ int v;LL w;//指向的点，容量 Edge(int v_, LL w_):v(v_),w(w_){} }; std::vector\u0026lt;Edge\u0026gt; edges; std::vector\u0026lt;std::vector\u0026lt;int\u0026gt; \u0026gt; graph(MAXN);//vector版的链式前向星 std::vector\u0026lt;int\u0026gt; cur(MAXN); int level[MAXN]; bool BFS(int s, int t){//BFS分层 std::memset(level, -1, sizeof(level)); level[s] = 0; cur.assign(MAXN,0);//初始化当前弧 std::queue\u0026lt;int\u0026gt; qu; qu.push(s); while(!qu.empty()){ int p = qu.front(); qu.pop(); int size = graph[p].size(); for(int i=0;i\u0026lt;size;i++){ int eg = graph[p][i]; int to = edges[eg].v; LL vol = edges[eg].w; if(vol\u0026gt;0 \u0026amp;\u0026amp; level[to] == -1){ level[to] = level[p] + 1; qu.push(to); } } } return level[t] != -1; } LL DFS(int const \u0026amp; p, LL const \u0026amp; flow, int const \u0026amp; s, int const \u0026amp; t){ if(p==t) return flow; LL surplus = flow;//剩余流量 int size = graph[p].size(); for(int i=cur[p];i\u0026lt;size \u0026amp;\u0026amp; surplus;i++){ int eg = graph[p][i]; cur[p] = i;//更新当前弧 int to = edges[eg].v; LL vol = edges[eg].w; if(vol\u0026gt;0 \u0026amp;\u0026amp; level[to]==level[p]+1){ LL c = DFS(to, std::min(vol, surplus), s, t); surplus -= c; edges[eg].w -= c; edges[eg^1].w += c; } } return flow - surplus; } LL Dinic(int const \u0026amp; p, LL const \u0026amp; flow, int const \u0026amp; s, int const \u0026amp; t){ LL ans = 0; while(BFS(s,t)){ ans += DFS(p,flow,s,t); } return ans; } int main(){ int n,m,s,t;//点数，边数，源点，汇点 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s\u0026gt;\u0026gt;t; for(int i=1;i\u0026lt;=m;i++){ int u,v;LL w; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w; graph[u].push_back(edges.size()); edges.push_back(Edge(v,w)); graph[v].push_back(edges.size()); edges.push_back(Edge(u,0)); } std::cout\u0026lt;\u0026lt;Dinic(s,INF,s,t)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } ISAP算法 TODO 最大流最小割定理 网络流的最大流等于其所有割的最小容量。\n割：从网络中选择一些边，去掉这些边后，剩下恰好两个互相不连通的分别包含源点和汇点的点集（当然其他边不去掉）。去掉的这些边就是一个割。\n割的大小就是去掉的这些边的容量之和。\n最小费用最大流 即在使流最大的前提下，最小化费用。费用是一条边的属性，一条边的总费用等于它的单位费用\\(\\times\\)流过的流量。\n建边的时候，反向边的容量为0，费用为相反数。\nEK+SPFA //luogu P3381 //EK+SPFA的实现，复杂度为O(nmf)，即点数、边数、最大流 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; typedef long long LL; typedef std::pair\u0026lt;LL,LL\u0026gt; pll; const int MAXN = 5005; const LL INF = 0xffffffff; struct Edge{ int v;LL w;LL c;//指向的点，容量，费用 Edge(int v_, LL w_, LL c_):v(v_),w(w_),c(c_){} }; std::vector\u0026lt;Edge\u0026gt; edges; std::vector\u0026lt;std::vector\u0026lt;int\u0026gt; \u0026gt; graph(MAXN);//vector版的链式前向星 int last[MAXN]; LL flow[MAXN]; LL dis[MAXN]; bool inq[MAXN]; bool SPFA(int s, int t){ std::queue\u0026lt;int\u0026gt; qu; qu.push(s); std::memset(last,-1,sizeof(last)); std::memset(dis,127,sizeof(dis)); std::memset(inq,0,sizeof(inq)); flow[s] = INF; dis[s] = 0; inq[s] = 1; while(!qu.empty()){ int p = qu.front(); qu.pop(); inq[p] = 0; int size = graph[p].size(); for(int i=0;i\u0026lt;size;i++){ int eg = graph[p][i]; int to = edges[eg].v; LL vol = edges[eg].w; if(vol\u0026gt;0 \u0026amp;\u0026amp; dis[to]\u0026gt;dis[p]+edges[eg].c){ last[to] = eg; flow[to] = std::min(flow[p], vol); dis[to] = dis[p]+edges[eg].c; if(!inq[to]){ qu.push(to); inq[to] = 1; } } } } return last[t] != -1; } pll MCMF(int s, int t){ LL maxflow = 0, mincost = 0; while(SPFA(s,t)){ maxflow += flow[t]; mincost += dis[t] * flow[t]; for(int i=t;i!=s;i=edges[last[i]^1].v){ edges[last[i]].w -= flow[t]; edges[last[i]^1].w += flow[t]; } } return {maxflow,mincost}; } int main(){ int n,m,s,t;//点数，边数，源点，汇点 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s\u0026gt;\u0026gt;t; for(int i=1;i\u0026lt;=m;i++){ int u,v;LL w,c; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w\u0026gt;\u0026gt;c; graph[u].push_back(edges.size()); edges.push_back(Edge(v,w,c)); graph[v].push_back(edges.size()); edges.push_back(Edge(u,0,-c)); } pll ans = MCMF(s,t); std::cout\u0026lt;\u0026lt;ans.first\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;ans.second\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } Dinic+SPFA //luogu P3381 //Dinic+SPFA的实现，复杂度为O(nmf)，即点数、边数、最大流 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;queue\u0026gt; typedef long long LL; typedef std::pair\u0026lt;LL,LL\u0026gt; pll; const int MAXN = 5005; const LL INF = 0xffffffff; struct Edge{ int v;LL w,c;//指向的点，容量，费用 Edge(int v_, LL w_, LL c_):v(v_),w(w_),c(c_){} }; std::vector\u0026lt;Edge\u0026gt; edges; std::vector\u0026lt;std::vector\u0026lt;int\u0026gt; \u0026gt; graph(MAXN);//vector版的链式前向星 std::vector\u0026lt;int\u0026gt; cur(MAXN); LL dis[MAXN]; bool inq[MAXN]; bool SPFA(int s, int t){//BFS分层 std::fill(dis,dis+MAXN,INF); std::memset(inq, 0, sizeof(inq)); dis[s] = 0; inq[s] = 1; cur.assign(MAXN,0);//初始化当前弧 std::queue\u0026lt;int\u0026gt; qu; qu.push(s); while(!qu.empty()){ int p = qu.front(); qu.pop(); inq[p] = 0; int size = graph[p].size(); for(int i=0;i\u0026lt;size;i++){ int eg = graph[p][i]; int to = edges[eg].v; LL vol = edges[eg].w; if(vol\u0026gt;0 \u0026amp;\u0026amp; dis[to] \u0026gt; dis[p]+edges[eg].c){ dis[to] = dis[p]+edges[eg].c; if(!inq[to]){ qu.push(to); inq[to] = 1; } } } } return dis[t] != INF; } LL DFS(int const \u0026amp; p, LL const \u0026amp; flow, int const \u0026amp; s, int const \u0026amp; t){ if(p==t) return flow; LL surplus = flow;//剩余流量 inq[p] = 1;//由于在SPFA中都会清零，可以复用 int size = graph[p].size(); for(int i=cur[p];i\u0026lt;size \u0026amp;\u0026amp; surplus;i++){ int eg = graph[p][i]; cur[p] = i;//更新当前弧 int to = edges[eg].v; LL vol = edges[eg].w; if(!inq[to] \u0026amp;\u0026amp; vol\u0026gt;0 \u0026amp;\u0026amp; dis[to]==dis[p]+edges[eg].c){ LL cx = DFS(to, std::min(vol, surplus), s, t); surplus -= cx; edges[eg].w -= cx; edges[eg^1].w += cx; } } inq[p] = 0; return flow - surplus; } pll MCMF(int const \u0026amp; p, LL const \u0026amp; flow, int const \u0026amp; s, int const \u0026amp; t){ LL maxflow = 0, mincost = 0; while(SPFA(s,t)){ LL ret = DFS(p,flow,s,t); maxflow += ret; mincost += ret * dis[t]; } return {maxflow,mincost}; } int main(){ int n,m,s,t;//点数，边数，源点，汇点 std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s\u0026gt;\u0026gt;t; for(int i=1;i\u0026lt;=m;i++){ int u,v;LL w,c; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w\u0026gt;\u0026gt;c; graph[u].push_back(edges.size()); edges.push_back(Edge(v,w,c)); graph[v].push_back(edges.size()); edges.push_back(Edge(u,0,-c)); } pll ans = MCMF(s,INF,s,t); std::cout\u0026lt;\u0026lt;ans.first\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;ans.second\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 上下界流 无源汇上下界可行流 给定一个没有源点和汇点的网络，每条边的容量都有一个上界和下界，问是否有一个可行流使得流量平衡（即每个点的流入等于流出）。\n//loj 115 //前面的Dinic算法省略 LL in[MAXN]; int main() { int n, m, s, t; //点数，边数，源点，汇点 std::cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; m; s = n + 1;//虚拟源点 t = n + 2;//虚拟汇点 std::vector\u0026lt;LL\u0026gt; ans; for (int i = 1; i \u0026lt;= m; i++) { int u, v; LL w1, w2;//下界，上界 std::cin \u0026gt;\u0026gt; u \u0026gt;\u0026gt; v \u0026gt;\u0026gt; w1 \u0026gt;\u0026gt; w2; ans.push_back(w1); graph[u].push_back(edges.size()); edges.push_back(Edge(v, w2 - w1));//只用建立差网络即可 graph[v].push_back(edges.size()); edges.push_back(Edge(u, 0)); in[u] -= w1; in[v] += w1; } for (int i = 1; i \u0026lt;= n; i++) { if (in[i] \u0026gt; 0) {//在下界网络中，有净流入的节点，要从源点连一条边，大小等于净流入 graph[s].push_back(edges.size()); edges.push_back(Edge(i, in[i])); graph[i].push_back(edges.size()); edges.push_back(Edge(s, 0)); } else {//有净流出的节点，要向汇点连一条边，大小等于净流出 graph[i].push_back(edges.size()); edges.push_back(Edge(t, -in[i])); graph[t].push_back(edges.size()); edges.push_back(Edge(i, 0)); } } Dinic(s, INF, s, t); for (auto x : graph[s]) { if (edges[x].w != 0) { //如果源点的附加边没有满流，说明不存在可行流 //也可以换成判断汇点没有满流，二者等价 std::cout \u0026lt;\u0026lt; \u0026#34;NO\\n\u0026#34;; return 0; } } std::cout \u0026lt;\u0026lt; \u0026#34;YES\\n\u0026#34;; for (int i = 1; i \u0026lt; 2 * m; i += 2) { //反向边就是这条边的流量，再加之前输入的下界得到每条边的流量 ans[i / 2] += edges[i].w; } for (auto x : ans) { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; } return 0; } 有源汇上下界可行流 比起无源汇的情况，我们可以把图中的汇点向源点连一条下界0，上界无限大的边。然后就变成无源汇图了。处理的时候，新建附加源点汇点\\(S',T'\\)，原来的\\(S,T\\)就变成了普通点，思路一致。\n若有解，则\\(S\\)到\\(T\\)的可行流流量等于\\(T\\)到\\(S\\)的附加边的流量。\n有源汇上下界最大流 在有源汇上下界可行流有解的时候，\\(S\\)到\\(T\\)的可行流量就是\\(T\\)到\\(S\\)的附加边的流量。然后我们删去所有添加的附加边，包括\\(S',T'\\)连的以及\\(T-S\\)附加边，再在跑完的网络上再跑一次Dinic，得到的流加上可行流就是最后的答案。\n具体实践上，我们不需要真的把边删了，\\(S',T'\\)所连的边根本不会影响结果，可以不用管，至于\\(T-S\\)这条边，我们获取了流量之后，直接把正向、反向边置零即可。\n//loj 116 //前面的Dinic算法省略 LL in[MAXN]; int main() { int n, m, s, t; //点数，边数，源点，汇点 std::cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; m \u0026gt;\u0026gt; s \u0026gt;\u0026gt; t; for (int i = 1; i \u0026lt;= m; i++) { int u, v; LL w1, w2; std::cin \u0026gt;\u0026gt; u \u0026gt;\u0026gt; v \u0026gt;\u0026gt; w1 \u0026gt;\u0026gt; w2; graph[u].push_back(edges.size()); edges.push_back(Edge(v, w2 - w1)); graph[v].push_back(edges.size()); edges.push_back(Edge(u, 0)); in[u] -= w1; in[v] += w1; } graph[t].push_back(edges.size()); edges.push_back(Edge(s, INF * 4ll)); graph[s].push_back(edges.size()); edges.push_back(Edge(t, 0)); //T-S的边 int s2 = n + 1, t2 = n + 2; for (int i = 1; i \u0026lt;= n; i++) { if (in[i] \u0026gt; 0) { graph[s2].push_back(edges.size()); edges.push_back(Edge(i, in[i])); graph[i].push_back(edges.size()); edges.push_back(Edge(s2, 0)); } else { graph[i].push_back(edges.size()); edges.push_back(Edge(t2, -in[i])); graph[t2].push_back(edges.size()); edges.push_back(Edge(i, 0)); } } Dinic(s2, INF, s2, t2); for (auto x : graph[s2]) { if (edges[x].w != 0) { std::cout \u0026lt;\u0026lt; \u0026#34;please go home to sleep\\n\u0026#34;; return 0; } } LL flow = edges[2 * m + 1].w; edges[2 * m].w = 0, edges[2 * m + 1].w = 0; std::cout \u0026lt;\u0026lt; Dinic(s, INF, s, t) + flow \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; return 0; } 有源汇上下界最小流 和上面几乎一模一样，只需在拆掉附加边后，从汇点到源点跑一次Dinic，然后flow删去这个结果就得到最小流。Loj 117。\n割边（Tarjan算法） //复杂度 n+m //tarjan求割边，可以正确处理重边 //如果无向图中删掉某条边会使无向图的连通分量数增多，那么这条边叫割边 //luogu p1656 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;stack\u0026gt; #include \u0026lt;algorithm\u0026gt; const int MAXN = 20005; const int MAXM = 100005; int dfn[MAXN], low[MAXN], cnt=0; //dfn为对一个图进行dfs时，dfs的顺序序号 //low[x]为以下所有符合要求的节点的dfn中的最小值 //1.以x为根的子树的所有节点 //2.通过非dfs生成树上的边能够到达该子树的所有节点 struct Edge{ int v,next;//指向的点，边权，下一条边 }; Edge edges[MAXM*2];//存无向图记得开两倍 int head[MAXN],ecnt=1;//注意这个ecnt=1，这是用来方便in_edge判断的 bool bridges[MAXM*2];//判断一条边是不是割边 inline void add(int u, int v){ edges[++ecnt].v = v; edges[ecnt].next = head[u]; head[u] = ecnt; } void tarjan(int u, int in_edge){ low[u] = dfn[u] = ++cnt; for(int i=head[u];i;i=edges[i].next){ int v = edges[i].v; if(!dfn[v]){ tarjan(v,i); low[u] = std::min(low[u],low[v]); if(low[v]\u0026gt;dfn[u])//边u-v是割边的充要条件 bridges[i] = bridges[i^1] = true; } else if(i != (in_edge ^ 1)){ low[u] = std::min(low[u], dfn[v]); } } } int main(){ int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; //点数，边数 for(int i=1;i\u0026lt;=m;i++){ int a,b; std::cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b; //起点，终点 add(a,b); add(b,a); //无向图 } for(int i=1;i\u0026lt;=n;i++){ if(!dfn[i]) tarjan(i,0); } std::vector\u0026lt;std::pair\u0026lt;int,int\u0026gt; \u0026gt; ans; for(int i=2;i\u0026lt;ecnt;i+=2){ if(bridges[i]){ int u = edges[i].v; int v = edges[i^1].v; if(u\u0026gt;v) std::swap(u,v); ans.push_back({u,v}); } } std::sort(ans.begin(),ans.end()); for(auto x:ans) std::cout\u0026lt;\u0026lt;x.first\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;x.second\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 割点（Tarjan算法） //复杂度 n+m //tarjan求割点,luogu P3388 //如果无向图中删掉某个点和其所有相连的边边会使无向图的连通分量数增多，那么这个点叫割点 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;stack\u0026gt; #include \u0026lt;algorithm\u0026gt; const int MAXN = 20005; const int MAXM = 100005; int dfn[MAXN], low[MAXN], cnt=0; //含义见割边模板 struct Edge{ int v,next;//指向的点，边权，下一条边 }; Edge edges[MAXM*2];//存无向图记得开两倍 int head[MAXN],ecnt;//这个ecnt和割边那里不一样，但也可以等于1 bool cut[MAXN];//判断割点 inline void add(int u, int v){ edges[++ecnt].v = v; edges[ecnt].next = head[u]; head[u] = ecnt; } void tarjan(int u, int root){ int tot = 0; low[u] = dfn[u] = ++cnt; for(int i=head[u];i;i=edges[i].next){ int v = edges[i].v; if(!dfn[v]){ tarjan(v,root); low[u] = std::min(low[u],low[v]); //一个点x是割点的充要条件是，它至少一个子节点y满足dfn[x]\u0026lt;=low[y]，特别的，对于根节点，需要至少两个这样的子节点 if(low[v]\u0026gt;=dfn[u]){ tot++; if(u!=root || tot\u0026gt;1) cut[u] = true; } } else{ low[u] = std::min(low[u], dfn[v]); } } } int main(){ int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; //点数，边数 for(int i=1;i\u0026lt;=m;i++){ int a,b; std::cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b; //起点，终点 add(a,b); add(b,a); //无向图 } for(int i=1;i\u0026lt;=n;i++){ if(!dfn[i]) tarjan(i,i); } std::vector\u0026lt;int\u0026gt; ans; for(int i=1;i\u0026lt;=n;i++) if(cut[i]) ans.push_back(i); std::sort(ans.begin(),ans.end()); std::cout\u0026lt;\u0026lt;ans.size()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; for(auto x:ans) std::cout\u0026lt;\u0026lt;x\u0026lt;\u0026lt;\u0026#34; \u0026#34;; return 0; } 强连通分量（Tarjan算法） //强连通分量，复杂度 n+m //luogu P2863 //一个有向图是强连通的当且仅当其中任意两个顶点相互可达 //强连通分量是有向图中的极大的强连通子图。极大意味着把一个图分为若干个强连通分量，分量之间互相不可达。或者，不存在包含该子图的更大的子图也是强连通分量。 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;stack\u0026gt; const int MAXN = 10005; const int MAXM = 50005; int dfn[MAXN], low[MAXN], instk[MAXN], scci[MAXN], cnt=0, cscc=0; std::vector\u0026lt;int\u0026gt; edges[MAXN]; std::stack\u0026lt;int\u0026gt; stk; std::vector\u0026lt;int\u0026gt; scc[MAXN]; //dfn是dfs时的顺序的序号 //stk中存入两类点，访问到节点x时 //1.搜索树上x的祖先节点 //2.已经访问过，并且存在一条路径到达x祖先的节点 //low[x]定义为满足以下两个条件的节点的最小dfn //1.该点在stk中 //2.存在一条从subtree(x)出发的有向边，以该点为终点 //scci[x]代表，x这个结点在第几个分量中 //cscc代表有几个分量 //scc[j]中表示，第j个分量的所有节点 void tarjan(int u){ low[u] = dfn[u] = ++cnt; instk[u] = 1; stk.push(u); for(int i=0;i\u0026lt;edges[u].size();i++){ int v = edges[u][i]; if(!dfn[v]){ tarjan(v); low[u] = std::min(low[u],low[v]); } else if(instk[v]){ low[u] = std::min(low[u], dfn[v]); } } if(low[u]==dfn[u]){ int top; cscc++; do{ top = stk.top(); stk.pop(); instk[top] = 0; scci[top] = cscc; scc[cscc].push_back(top); }while(top!=u); } } int main(){ int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; for(int i=1;i\u0026lt;=m;i++){ int a,b; std::cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b; edges[a].push_back(b);//有向边 } for(int i=1;i\u0026lt;=n;i++){ if(!dfn[i]) tarjan(i);//注意遍历所有dfn为零的点 } int ans = 0; for(int i=1;i\u0026lt;=cscc;i++){ if(scc[i].size()\u0026gt;1) ans++; } std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 2-SAT问题 //2-SAT算法，复杂度n+m //luogu P4782 //2-SAT是用来解决一些条件是否能够满足的算法。 //每个条件都能转化为形如\u0026#34;若x赋值为a，则y必须赋值为b\u0026#34;的形式。其中a,b的取值只能有两个，通常是true和false。 //例如总共有m个这样的条件，我们要判断是否存在一种赋值情况满足所有的条件。如果有还要输出一种可行方案 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;stack\u0026gt; const int MAXN = 2e6+5; int dfn[MAXN], low[MAXN], instk[MAXN], scci[MAXN], cnt=0, cscc=0; std::vector\u0026lt;int\u0026gt; edges[MAXN]; std::stack\u0026lt;int\u0026gt; stk; std::vector\u0026lt;int\u0026gt; scc[MAXN]; //含义见强连通分量tarjan算法 bool ans[MAXN]; void tarjan(int u){ low[u] = dfn[u] = ++cnt; instk[u] = 1; stk.push(u); for(int i=0;i\u0026lt;edges[u].size();i++){ int v = edges[u][i]; if(!dfn[v]){ tarjan(v); low[u] = std::min(low[u],low[v]); } else if(instk[v]){ low[u] = std::min(low[u], dfn[v]); } } if(low[u]==dfn[u]){ int top; cscc++; do{ top = stk.top(); stk.pop(); instk[top] = 0; scci[top] = cscc; scc[cscc].push_back(top); }while(top!=u); } } int main(){ int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; //n个点，m个条件 while(m--){ int i,j; bool a,b; std::cin\u0026gt;\u0026gt;i\u0026gt;\u0026gt;a\u0026gt;\u0026gt;j\u0026gt;\u0026gt;b; //本题的条件为，i为a或（不是异或）j为b，其他题按情况处理 //每个点x拆为两个点y和y+n,y代表x为0，y+n代表x为1 //每条边x-\u0026gt;y代表着，如果x，那么一定有y //本题如“i为假或j为真”可以拆为两个条件，这个条件满足（为真）时 //i为真则j一定为真 //j为假则i一定为假 edges[i+(!a)*n].push_back(j+b*n); edges[j+(!b)*n].push_back(i+a*n);//逆否命题 //逆否命题是一定要插入的，不能只插入原命题，但是本题拆出来的两个条件正好互为逆否命题，所以只插入了两条边。其他题并不一定总会给出逆否命题 //这里的逻辑运算可能有些不容易理解，怕错可以写成很长的if else判断a和b的具体取值 } for(int i=1;i\u0026lt;=2*n;i++){ if(!dfn[i]) tarjan(i);//注意遍历所有dfn为零的点 } for(int i=1;i\u0026lt;=n;i++){ if(scci[i]==scci[i+n]){//如果i和i+n在一个强连通分量，则不可满足 std::cout\u0026lt;\u0026lt;\u0026#34;IMPOSSIBLE\\n\u0026#34;; return 0; } else if(scci[i]\u0026gt;scci[i+n]) ans[i] = 1; else ans[i] = 0; } std::cout\u0026lt;\u0026lt;\u0026#34;POSSIBLE\\n\u0026#34;; for(int i=1;i\u0026lt;=n;i++){ std::cout\u0026lt;\u0026lt;ans[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } return 0; } 边双联通分量 //复杂度 n+m //tarjan求边双联通分量 //luogu p8436 //如果一张无向连通图不存在割边，则称之为边双联通图 //双连通分量是图的极大双联通子图 //若u-v边双联通，v-w边双联通，则u-w边双联通 //一张图是边双联通，当且仅当每条边都在至少一个简单环中 //无向连通图中，对于任意两个点，如果无论删去哪条边（只能一条），都不能使它们不连通，则为边双联通 //同时这也意味着，把割边删去后的图，就是若干个双联通分量 /*这一段是求割边的核心代码，省略*/ int dcci[MAXN], cdcc;//记录点i属于双联通分量dcci[i]，以及总的dcc个数 std::vector\u0026lt;std::vector\u0026lt;int\u0026gt; \u0026gt; dcc(MAXN);//存储双联通分量dcc[i]中有哪些点 void getDCC(int u){ dcci[u] = cdcc; dcc[cdcc].push_back(u); for(int i=head[u];i;i=edges[i].next){ int v = edges[i].v; if(dcci[v] || bridges[i]) continue; getDCC(v); } } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; //点数，边数 for(int i=1;i\u0026lt;=m;i++){ int a,b; std::cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b; //起点，终点 add(a,b); add(b,a); //无向图 } for(int i=1;i\u0026lt;=n;i++){ if(!dfn[i]) tarjan(i,0); } //以上求完了割边 for(int i=1;i\u0026lt;=n;i++){ if(!dcci[i]){ cdcc++; getDCC(i); } } std::cout\u0026lt;\u0026lt;cdcc\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; for(int i=1;i\u0026lt;=cdcc;i++){ std::cout\u0026lt;\u0026lt;dcc[i].size()\u0026lt;\u0026lt;\u0026#34; \u0026#34;; for(auto x:dcc[i]){ std::cout\u0026lt;\u0026lt;x\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } std::cout\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } 边双联通缩点TODO 点双联通分量 //复杂度 n+m //tarjan求点双联通分量 //luogu p8435 //如果一张无向连通图不存在割点，则称之为点双联通图 //双连通分量是图的极大双联通子图 //极大指的是，不存在包含这个子图的更大的子图也是边双联通图 //若u-v点双联通，v-w点双联通，则u-w[并不一定]点双联通 //一张图是点双联通，当且仅当以下两个条件之一成立 //1. 图的顶点数不超过2 //2. 图中任意两点都同时包含在至少一个简单环中 //无向连通图中，对于任意两个点，如果无论删去哪个点（只能一个，且不能删除这两个点自己），都不能使它们不连通，则为点双联通 //但是，虽然边双联通中的割边不属于任何连通分量，但割点却可以属于多个点双联通分量 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;stack\u0026gt; #include \u0026lt;algorithm\u0026gt; const int MAXN = 500005; const int MAXM = 2000005; int dfn[MAXN], low[MAXN], cnt=0; //含义见割边模板 struct Edge{ int v,next;//指向的点，边权，下一条边 }; Edge edges[MAXM*2];//存无向图记得开两倍 int head[MAXN],ecnt;//这个ecnt和割边那里不一样，但也可以等于1 bool cut[MAXN];//判断割点 inline void add(int u, int v){ edges[++ecnt].v = v; edges[ecnt].next = head[u]; head[u] = ecnt; } std::stack\u0026lt;int\u0026gt; stk; int cdcc; std::vector\u0026lt;std::vector\u0026lt;int\u0026gt; \u0026gt; dcc(MAXN); void tarjan(int u, int root){ low[u] = dfn[u] = ++cnt; stk.push(u); if(u==root \u0026amp;\u0026amp; head[u]==0){ dcc[++cdcc].push_back(u); return; } int tot=0; for(int i=head[u];i;i=edges[i].next){ int v = edges[i].v; if(!dfn[v]){ tarjan(v,root); low[u] = std::min(low[u],low[v]); if(low[v]\u0026gt;=dfn[u]){ tot++; if(u!=root || tot\u0026gt;1) cut[u] = true; cdcc++; int z; do{ z = stk.top(); stk.pop(); dcc[cdcc].push_back(z); }while(z!=v); dcc[cdcc].push_back(u); } } else{ low[u] = std::min(low[u], dfn[v]); } } } int main(){ int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; //点数，边数 for(int i=1;i\u0026lt;=m;i++){ int a,b; std::cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b; //起点，终点 if(a==b) continue;//点双联通需要注意排除自环才能处理孤立点 add(a,b); add(b,a); //无向图 } for(int i=1;i\u0026lt;=n;i++){ if(!dfn[i]) tarjan(i,i); } std::cout\u0026lt;\u0026lt;cdcc\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; for(int i=1;i\u0026lt;=cdcc;i++){ std::cout\u0026lt;\u0026lt;dcc[i].size()\u0026lt;\u0026lt;\u0026#34; \u0026#34;; for(auto x:dcc[i]) std::cout\u0026lt;\u0026lt;x\u0026lt;\u0026lt;\u0026#34; \u0026#34;; std::cout\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } 点双联通缩点TODO 树的直径 //树的直径，复杂度n //poj1985，输出树上最长路径的长度，即树的直径 //两遍dfs版可以求出路径上的点，但树形dp的可以处理负边权问题 std::vector\u0026lt;pii\u0026gt; edges[MAXN];//first是v，second是w int dis[MAXN]; int far; void dfs(int u, int fa){ int size = edges[u].size(); for(int i=0;i\u0026lt;size;i++){ pii e = edges[u][i]; int v = e.first, w = e.second; if(v==fa) continue; dis[v] = dis[u]+w; if(dis[v]\u0026gt;dis[far]) far=v; dfs(v,u); } } void solve(){ int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; for(int i=1;i\u0026lt;=m;i++){ int u,v,w; char trash;//poj 1985的输入数据问题 std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w\u0026gt;\u0026gt;trash; edges[u].push_back(std::make_pair(v,w)); edges[v].push_back(std::make_pair(u,w)); } dfs(1,0); dis[far] = 0; dfs(far,0); std::cout\u0026lt;\u0026lt;dis[far]\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } //树的直径，复杂度n //poj1985，输出树上最长路径的长度，即树的直径 //两遍dfs版可以求出路径上的点，但树形dp的可以处理负边权问题 std::vector\u0026lt;pii\u0026gt; edges[MAXN];//first是v，second是w int dis[MAXN]; bool vis[MAXN]; int ans; void dp(int u){ vis[u] = 1; int size = edges[u].size(); for(int i=0;i\u0026lt;size;i++){ pii e = edges[u][i]; int v = e.first, w = e.second; if(vis[v]) continue; dp(v); ans = std::max(ans,dis[u]+dis[v]+w); dis[u] = std::max(dis[u],dis[v]+w); } } void solve(){ int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; for(int i=1;i\u0026lt;=m;i++){ int u,v,w; char trash;//poj 1985的输入数据问题 std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w\u0026gt;\u0026gt;trash; edges[u].push_back(std::make_pair(v,w)); edges[v].push_back(std::make_pair(u,w)); } dp(1); std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } 若树上所有边边权均为正，则树的所有直径中点重合。\n树的重心 计算无根树的每一个节点作为根时，其最大子树的大小。最大子树的大小最小的节点叫做树的重心。\n性质如下\n重心如果不唯一，则最多只有两个，且它们相邻。并且此时树有偶数个节点，可以被划分为两个大小相等的连通块，每个块各自包含一个重心。 以树的重心为根时，所有子树的大小都不超过整棵树的一半 树中所有点到某个点的距离之和中，到重心的距离之和是最小的。如果有两个重心，它们是并列最小的。反过来距离之和最小的点一定是重心。 两棵树通过一条边连成一棵树，则新树的重心在连接原来两颗树的重心的路径上。如果两棵树大小一样，那么重心就是两个连接点。 在一棵树上添加或删除一个叶节点，它的重心最多只移动一条边的距离。如果原树有奇数个节点，那么重心可能会增加一个，原重心仍然是重心。如果有偶数个节点，那么重心可能减少一个，另一个重心仍然是重心。 //复杂度 n //poj 1655 std::vector\u0026lt;int\u0026gt; edges[MAXN]; int sz[MAXN], mss[MAXN];//树的大小（含自己），最大子树大小（不含自己） std::vector\u0026lt;int\u0026gt; ctr;//存重心 void dfs(int u, int fa, int const n){//需要传入点的个数 sz[u] = 1, mss[u] = 0; int size = edges[u].size(); for(int e=0;e\u0026lt;size;e++){ int v = edges[u][e]; if(v==fa) continue; dfs(v,u,n); mss[u] = std::max(mss[u],sz[v]); sz[u] += sz[v]; } mss[u] = std::max(mss[u],n-sz[u]); if(mss[u]\u0026lt;=n/2) ctr.push_back(u); } 倍增求最近公共祖先 //复杂度 单次查询 logn 预处理 nlogn，常数小点的可以用重链剖分 //luogu P3379 //倍增求最近公共祖先 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;cstdio\u0026gt; int const MAXN = 500005; int const LOGN = 31; std::vector\u0026lt;int\u0026gt; edge[MAXN];//邻接表 int logn[MAXN]; int fa[MAXN][LOGN],deep[MAXN]; //fa[a][b]代表a的第2^b个祖先，deep是深度，根节点深度为1 void build(int u,int father){ fa[u][0] = father; deep[u] = deep[father]+1; for(int i=1;i\u0026lt;=logn[deep[u]];i++){ fa[u][i] = fa[fa[u][i-1]][i-1]; } for(auto v:edge[u]){ if(v==father) continue; build(v,u); } } int lca(int x,int y){ if(deep[x]\u0026gt;deep[y]) std::swap(x,y); //保证y比x深 while(deep[x]!=deep[y]){ y = fa[y][logn[deep[y]-deep[x]]]; } if(x==y) return x; for(int k=logn[deep[x]];k\u0026gt;=0;k--){ if(fa[x][k]!=fa[y][k]){ x = fa[x][k], y = fa[y][k]; } } return fa[x][0]; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m,s; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;s; //点数，询问数，根节点序号 for(int i=2;i\u0026lt;=n;i++){ logn[i] = logn[i/2] + 1; //必须的初始化 } for(int i=1;i\u0026lt;=n-1;i++){ int a,b; std::cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b; //读入树 edge[a].push_back(b); edge[b].push_back(a); } build(s,0);//必须build才能用 for(int i=1;i\u0026lt;=m;i++){ int x,y; std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y; //查询x,y的最近公共祖先 std::cout\u0026lt;\u0026lt;lca(x,y)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } 虚树 TODO 点分治 //点分治 复杂度nlog^2n //poj 1741 //查询树上长度小于等于k的路径的数量 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cmath\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;map\u0026gt; #include \u0026lt;set\u0026gt; #include \u0026lt;queue\u0026gt; #include \u0026lt;stack\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;cstdio\u0026gt; int const MAXN = 10007; struct Edge{ int v,w,next;//指向的点，边权，下一条边 }; Edge edges[MAXN*2]; int head[MAXN],cnt; inline void add(int u, int v, int w){ edges[++cnt].w = w; edges[cnt].v = v; edges[cnt].next = head[u]; head[u] = cnt; } int sz[MAXN], mss[MAXN];//树的大小（含自己），最大子树大小（不含自己） int ctr=-1;//重心 bool del[MAXN];//这个点是否在分治的时候被删除 void dfsCtr(int u, int fa, int const n){//需要传入树的点的个数 //执行完后ctr为本子树的重心 sz[u] = 1, mss[u] = 0; for(int e=head[u];e;e=edges[e].next){ int v = edges[e].v; if(v==fa || del[v]) continue; dfsCtr(v,u,n); if(ctr!=-1) return; mss[u] = std::max(mss[u],sz[v]); sz[u] += sz[v]; } mss[u] = std::max(mss[u],n-sz[u]); if(mss[u]\u0026lt;=n/2) ctr = u, sz[fa] = n-sz[u];//注意要改编sz以保证复杂度正确 } int dis[MAXN];//dis[x]存储点x到根root的距离 int indexx[MAXN];//要对节点编号按照dis进行排序，indexx[0]代表元素个数 int belong[MAXN];//判断子树节点属于哪一个子子树 int cntsame[MAXN];//查询[l,r]时，维护[l+1,r]中belong与l的belong相同的个数，见calc函数 bool cmp(int x,int y){return dis[x]\u0026lt;dis[y];} void dfsDis(int u, int fa, int from){ //获得子树到根节点的距离，from用于计算belong indexx[++indexx[0]] = u; belong[u] = from; for(int e=head[u];e;e=edges[e].next){ int v = edges[e].v, w = edges[e].w; if(v==fa || del[v]) continue; dis[v] = dis[u] + w; cntsame[from]++; dfsDis(v,u,from); } } int calc(int u,int k){ indexx[0] = 0; indexx[++indexx[0]] = u; belong[u] = u; dis[u] = 0; cntsame[u] = 1; for(int e=head[u];e;e=edges[e].next){ int v = edges[e].v, w =edges[e].w; if(del[v]) continue; dis[v] = dis[u] + w; cntsame[v] = 1; dfsDis(v,u,v); } std::sort(indexx+1,indexx+1+indexx[0],cmp); int l=1, r=indexx[0],ans=0; while(l\u0026lt;r){ int x = indexx[l], y = indexx[r]; if(dis[x]+dis[y]\u0026gt;k){ cntsame[belong[y]]--;//把cntsame由[l,r]转移,r-1] r--; } else{ //显然，如果不考虑两个点在同一个子子树内，则l和l+1~r的每个点都满足dis[x]+dis[y]\u0026lt;=k //减去同子子树的情况，即减去[l+1,r]中和l拥有相同belong的点 cntsame[belong[x]]--;//把cntsame由[l,r]转移到[l+1,r]，一定要注意顺序 ans += r-l-cntsame[belong[x]]; l++; } } return ans; } int res = 0; void divide(int u, int k){ del[u] = 1; res += calc(u,k); for(int e=head[u];e;e=edges[e].next){ int v = edges[e].v, w = edges[e].w; if(del[v]) continue; ctr = -1; dfsCtr(v,0,sz[v]); divide(ctr,k); } } void solve(int n, int k){ for(int i=1;i\u0026lt;n;i++){ int u,v,w; std::cin\u0026gt;\u0026gt;u\u0026gt;\u0026gt;v\u0026gt;\u0026gt;w; add(u,v,w); add(v,u,w); } dfsCtr(1,0,n); divide(ctr,k); std::cout\u0026lt;\u0026lt;res\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; ctr = -1; cnt = 0; res = 0; for(int i=1;i\u0026lt;=n;i++) head[i] = 0,del[i] = 0; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,k; while(std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;k){ if(n==0\u0026amp;\u0026amp;k==0) break; solve(n,k); } return 0; } 重链剖分 //树根节点的子节点中子树最大的为它的重子节点，其他的为轻子节点（整棵树的根节点是轻点，其他子树的根节点可轻可重） //节点连向其轻子节点的边叫轻边，否则叫重边 //节点数为n，则从任意节点向上到根节点，经过的轻边数不超过logn struct Node{ int fa, sz, dep, hson;//父节点、子树大小（包含自己）、深度、重子节点 int top;//链头，即所在的重链中深度最小的那个节点 }node[MAXN]; std::vector\u0026lt;int\u0026gt; edges[MAXN]; void dfs1(int u, int d=1){ //在dfs2之前先用dfs1 int size = 1, ma = 0; node[u].dep = d; for(auto v:edges[u]){ if(!node[v].dep){ dfs1(v,d+1); node[v].fa = u; size += node[v].sz; if(node[v].sz \u0026gt; ma){ node[u].hson = v, ma = node[v].sz; } } } node[u].sz = size; } void dfs2(int u){ //需要先把根节点的top设置为自己 for(auto v:edges[u]){ if(!node[v].top){ if(v==node[u].hson) node[v].top = node[u].top; else node[v].top = v; dfs2(v); } } } void cut(int r=1){ //进行树剖预处理 dfs1(r); node[r].top = r; dfs2(r); } 重链剖分求LCA //树剖求LCA，每次查询复杂度 logn，常数很小 //luogu p3379 int lca(int a, int b){ while(node[a].top!=node[b].top){ if(node[node[a].top].dep\u0026gt;node[node[b].top].dep) a = node[node[a].top].fa; else b = node[node[b].top].fa; } if(node[a].dep \u0026gt; node[b].dep) return b; return a; } 重链剖分+线段树维护树上路径点权和 //树剖维护树上路径的点权和，维护和查询一次复杂度 logn //luogu p3384 //树根节点的子节点中子树最大的为它的重子节点，其他的为轻子节点（整棵树的根节点是轻点，其他子树的根节点可轻可重） //节点连向其轻子节点的边叫轻边，否则叫重边 //节点数为n，则从任意节点向上到根节点，经过的轻边数不超过logn #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cmath\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; #define pb push_back #define mkp std::make_pair #define fi first #define se second using LL = long long; int const MAXN = 100005; int const INF = 0x7fffffff; LL MOD = 998244353; struct Node{ int fa, sz, dep, hson;//父节点、子树大小（包含自己）、深度、重子节点 int top;//链头，即所在的重链中深度最小的那个节点 int dfn, mdfn;//该节点的dfs序，该节点子树的最大dfs序 LL v;//点上的权 }node[MAXN]; int dfnmap[MAXN];//映射dfn对应的点编号 std::vector\u0026lt;int\u0026gt; edges[MAXN]; void dfs1(int u, int d=1){ //在dfs2之前先用dfs1 int size = 1, ma = 0; node[u].dep = d; for(auto v:edges[u]){ if(!node[v].dep){ dfs1(v,d+1); node[v].fa = u; size += node[v].sz; if(node[v].sz \u0026gt; ma){ node[u].hson = v, ma = node[v].sz; } } } node[u].sz = size; } int cnt=0; void dfs2(int u){ //需要先把根节点的top设置为自己 node[u].dfn = ++cnt; dfnmap[cnt] = u; if(node[u].hson!=0){ node[node[u].hson].top = node[u].top; dfs2(node[u].hson); } //采取这个改变的原因是，每棵子树的dfs序是连续的，根节点dfs序最小 //而如果我们强制先遍历重子节点，那么重链上的dfs序是连续的，并且链头dfs序最小。这样就能用线段树维护链上的信息了 for(auto v:edges[u]){ if(!node[v].top){ node[v].top = v; dfs2(v); } } node[u].mdfn = cnt; } void cut(int r){ dfs1(r); node[r].top = r; dfs2(r); } struct Nodest { int s,t;//该端点的起点和终点下标 LL tag, v; }; Nodest st[MAXN*4+2]; void build(int s, int t, int p){ st[p].s = s; st[p].t = t; if(s==t) { st[p].v = node[dfnmap[s]].v%MOD; st[p].tag = 0; return; } int m = s+((t-s)\u0026gt;\u0026gt;1); build(s,m,p*2); build(m+1,t,p*2+1); st[p].v = (st[p*2].v + st[p*2+1].v)%MOD; st[p].tag = 0; } void spreadTag(int p){ if(st[p].tag){ int s = st[p].s, t = st[p].t; int m = s+((t-s)\u0026gt;\u0026gt;1); st[p*2].v = (st[p*2].v + (m-s+1)*st[p].tag)%MOD; st[p*2+1].v = (st[p*2+1].v + (t-m)*st[p].tag)%MOD; st[p*2].tag = (st[p].tag + st[p*2].tag)%MOD; st[p*2+1].tag = (st[p].tag + st[p*2+1].tag)%MOD; st[p].tag=0; } } void update(int l, int r, int p, LL k){ int s = st[p].s, t = st[p].t; if(l\u0026lt;=s \u0026amp;\u0026amp; t\u0026lt;=r){ st[p].v = (st[p].v + (t-s+1) * k)%MOD; st[p].tag = (st[p].tag + k)%MOD; return; } spreadTag(p); int m = s+((t-s)\u0026gt;\u0026gt;1); if(l\u0026lt;=m) update(l, r, p*2, k); if(r\u0026gt;m) update(l, r, p*2+1, k); st[p].v = (st[p*2].v + st[p*2+1].v)%MOD; } LL query(int l, int r, int p){ int s = st[p].s, t = st[p].t; if(l\u0026lt;=s \u0026amp;\u0026amp; t\u0026lt;=r) return st[p].v%MOD; spreadTag(p); int m = s+((t-s)\u0026gt;\u0026gt;1); LL ret = 0; if(l\u0026lt;=m) ret = (ret + query(l,r,p*2))%MOD; if(r\u0026gt;m) ret = (ret + query(l,r,p*2+1))%MOD; return ret; } void update_path(int x, int y, LL k){ while(node[x].top != node[y].top){ if(node[node[x].top].dep \u0026gt; node[node[y].top].dep){ update(node[node[x].top].dfn, node[x].dfn, 1, k); x = node[node[x].top].fa; } else{ update(node[node[y].top].dfn, node[y].dfn, 1, k); y = node[node[y].top].fa; } } if(node[x].dep\u0026gt;node[y].dep){ update(node[y].dfn, node[x].dfn, 1, k); } else{ update(node[x].dfn, node[y].dfn, 1, k); } } LL query_path(int x, int y){ LL ans = 0; while(node[x].top != node[y].top){ if(node[node[x].top].dep \u0026gt; node[node[y].top].dep){ ans += query(node[node[x].top].dfn, node[x].dfn, 1); x = node[node[x].top].fa; } else{ ans += query(node[node[y].top].dfn, node[y].dfn, 1); y = node[node[y].top].fa; } } if(node[x].dep\u0026gt;node[y].dep){ ans += query(node[y].dfn, node[x].dfn, 1); } else{ ans += query(node[x].dfn, node[y].dfn, 1); } return ans%MOD; } void update_subtree(int x, LL k){ update(node[x].dfn, node[x].mdfn, 1, k); } LL query_subtree(int x){ return query(node[x].dfn, node[x].mdfn, 1)%MOD; } void solve(){ int n,m,r; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;r\u0026gt;\u0026gt;MOD;//节点个数，操作个数，根节点序号，取模数 for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;node[i].v; } for(int i=1;i\u0026lt;n;i++){ int x,y; std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y; edges[x].pb(y); edges[y].pb(x); } cut(r); build(1,n,1); while(m--){ int ope,x,y; LL z; std::cin\u0026gt;\u0026gt;ope; if(ope==1){ std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y\u0026gt;\u0026gt;z; update_path(x,y,z); } else if(ope==2){ std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y; std::cout\u0026lt;\u0026lt;query_path(x,y)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } else if(ope==3){ std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;z; update_subtree(x,z); } else if(ope==4){ std::cin\u0026gt;\u0026gt;x; std::cout\u0026lt;\u0026lt;query_subtree(x)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } } } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int T; T=1; while(T--){ solve(); } return 0; } 长链剖分 求K级祖先 //长链剖分定义子树最深深度最深的节点为重子节点 //任意节点p的k级祖先q所在的链长度一定大于k //任意节点p到根节点最多经过sqrt n级别的轻边 //luogu p5903 //求任意节点的第k级祖先，预处理nlogn，查询常数 #define pb push_back using LL = long long; int const MAXN = 500005; struct Node{ int fa, dep, hson;//父节点、深度、重子节点 int top;//链头，即所在的长链中深度最小的那个节点 int len,dfn,mdfn;//部分链长，dfs序，子树最大dfs序 }node[MAXN]; int dfnmap[MAXN];//dfs序对应节点 std::vector\u0026lt;int\u0026gt; edges[MAXN]; void dfs1(int u, int d=1){ node[u].len = 1, node[u].dep = d; for(auto v:edges[u]){ if(!node[v].dep){ dfs1(v,d+1); node[v].fa = u; if(node[v].len+1\u0026gt;node[u].len) node[u].hson = v, node[u].len = node[v].len+1; } } } int cnt = 0; void dfs2(int u, int tp){ node[u].dfn = ++cnt; node[u].top = tp; dfnmap[cnt] = u; if(node[u].hson) dfs2(node[u].hson, tp); for(auto v:edges[u]){ if(!node[v].top) dfs2(v,v); } node[u].mdfn = cnt; } void cut(int r=1){ dfs1(r); dfs2(r,r); } std::vector\u0026lt;int\u0026gt; anc[MAXN], des[MAXN]; //分别存储（链头）节点p的1,2,...,node[p].len-1级祖先节点和子孙节点 int const LOGN = 21; int fa[MAXN][LOGN]; int logn[MAXN]; void init(int r, int n){ cut(r); logn[1] = 0; logn[2] = 1; for(int i=3;i\u0026lt;MAXN;i++){ logn[i] = logn[i/2]+1; //预先计算logn } for(int i=1;i\u0026lt;=n;i++) fa[i][0] = node[i].fa; for(int j=1;j\u0026lt;LOGN;j++){ for(int i=1;i\u0026lt;=n;i++){ fa[i][j] = fa[fa[i][j-1]][j-1]; } } for(int i=1;i\u0026lt;=n;i++){ if(node[i].top==i){ for(int j=0,p=i;j\u0026lt;node[i].len;j++,p=fa[p][0]) anc[i].pb(p); for(int j=0;j\u0026lt;node[i].len;j++) des[i].pb(dfnmap[node[i].dfn+j]); } } } int query(int u, int k){ //查询节点u的k级祖先 if(k==0) return u; int i = logn[k]; int v = fa[u][i]; int tp = node[v].top; int d = k - (1\u0026lt;\u0026lt;i) + node[tp].dep - node[v].dep; if(d\u0026gt;0) return anc[tp][d]; else return des[tp][-d]; } 计算几何 TODO 基础板子 ///////////////////////////////////////////////// //数据类型定义 typedef double db; typedef long double LD; struct Point{db x,y;}; typedef Point Vec; struct Line{Point p; Vec v;};//点向式直线，不保证方向向量为单位向量 struct Seg{Point a,b;};//线段 struct Circle{Point o;db r;};//圆心和半径 ///////////////////////////////////////////////// //常数定义 Point const o{0.0,0.0};//原点 Line const ox{o,{1.0,0.0}}, oy{o,{0.0,1.0}};//横轴纵轴 db const PI = acos(-1); db const EPS = 1e-9; ///////////////////////////////////////////////// //可调整精度的比较 bool eq(db a, db b) {return std::abs(a - b)\u0026lt; EPS;}//等于 bool ge(db a, db b) {return a - b \u0026gt; EPS;}//大于 bool le(db a, db b) {return a - b \u0026lt; -EPS;}//小于 bool geq(db a, db b) {return a - b \u0026gt; -EPS;}//大于等于 bool leq(db a, db b) {return a - b \u0026lt; EPS;}//小于等于 ///////////////////////////////////////////////// //基础运算 Vec r90a(Vec v){return {-v.y, v.x};}//向量逆时针90度 Vec r90c(Vec v){return {v.y, -v.x};}//向量顺时针90度 Vec operator+(Vec a, Vec b){return {a.x+b.x, a.y+b.y};} Vec operator-(Vec a, Vec b){return {a.x-b.x, a.y-b.y};} Vec operator*(db k, Vec v){return {k*v.x, k*v.y};} Vec operator*(Vec v, db k){return {v.x*k, v.y*k};} db operator*(Vec a, Vec b){return a.x*b.x+a.y*b.y;} db operator^(Vec a, Vec b){return a.x*b.y-a.y*b.x;}//叉积 db len2(Vec v){return v.x*v.x+v.y*v.y;}//长度平方 db len(Vec v){return std::sqrt(len2(v));}//向量长度 db slope(Vec v){return v.y/v.x;}//斜率，不存在时，用后面的paral_y函数，不要判断是否是无穷 ///////////////////////////////////////////////// //向量操作 db cos_v(Vec a, Vec b){return a*b/len(a)/len(b);}//向量夹角余弦 Vec norm(Vec v){return {v.x/len(v), v.y/len(v)};}//求其单位向量 Vec pnorm(Vec v){return (v.x\u0026lt;0?-1:1)/len(v)*v;}//与原向量平行且横坐标大于零的单位向量 Vec dvec(Seg l){return l.b-l.a;}//线段转化为向量（没有归一化） ///////////////////////////////////////////////// //直线操作 Line line(Point a, Point b){return {a,b-a};}//两点式直线 Line line(db k, db b){return {{0,b},{1,k}};}//斜截式直线y=kx+b Line line(Point p, db k){return {p,{1,k}};}//点斜式直线 Line line(Seg l){return {l.a, l.b-l.a};}//线段所在直线 db at_x(Line l, db x){return l.p.y+(x-l.p.x)*l.v.y/l.v.x;}//给定直线上的横坐标求纵坐标，要确保直线不与y轴平行 db at_y(Line l, db y){return l.p.x+(y+l.p.y)*l.v.x/l.v.y;}//与上相反 Point pedal(Point p, Line l){return l.p-(l.p-p)*l.v/(l.v*l.v)*l.v;}//求点到直线的垂足 Line perp(Line l, Point p){return {p,r90c(l.v)};}//过某点作直线的垂线 Line bisec(Point p, Vec a, Vec b){return {p,norm(a)+norm(b)};}//角平分线 ///////////////////////////////////////////////// //线段操作 Point midp(Seg l){return {(l.a.x+l.b.x)/2.0,(l.a.y+l.b.y)/2.0};}//线段中点 Line perp(Seg l){return {midp(l), r90c(l.b-l.a)};}//线段中垂线 ///////////////////////////////////////////////// //几何关系 bool verti(Vec a, Vec b){return eq(a*b,0.0);}//向量是否垂直 bool paral(Vec a, Vec b){return eq(a^b,0.0);}//向量是否平行 bool paral_x(Vec v){return eq(v.y,0.0);}//是否平行x轴 bool paral_y(Vec v){return eq(v.x,0.0);}//是否平行y轴 bool on(Point p, Line l){return eq((p.x-l.p.x)*l.v.y, (p.y-l.p.y)*l.v.x);}//点是否在直线上 bool on(Point p, Seg l){return eq(len(p-l.a)+len(p-l.b),len(l.a-l.b));}//点是否在线段上 bool operator==(Point a, Point b){return eq(a.x,b.x)\u0026amp;\u0026amp;eq(a.y,b.y);}//点重合 bool operator==(Line a, Line b){return on(a.p,b)\u0026amp;\u0026amp;on(a.p+a.v,b);}//直线重合 bool operator==(Seg a, Seg b){return ((a.a==b.a\u0026amp;\u0026amp;a.b==b.b)||(a.a==b.b\u0026amp;\u0026amp;a.b==b.a));}//线段（完全）重合 bool operator\u0026lt;(Point a, Point b){return le(a.x,b.x)||(eq(a.x,b.x)\u0026amp;\u0026amp;le(a.y,b.y));}//横坐标第一关键字，纵坐标第二关键字 bool tangency(Line l, Circle c){return eq(std::abs((c.o^l.v)-(l.p^l.v)),c.r*len(l.v));}//直线和圆是否相切 bool tangency(Circle c1, Circle c2){return eq(len(c1.o-c2.o),c1.r+c2.r);}//两个圆是否相切 ///////////////////////////////////////////////// //距离 db dis(Point a, Point b){return len(a-b);}//两点距离 db dis(Point p, Line l){return std::abs((p^l.v)-(l.p^l.v))/len(l.v);}//点到直线的距离 db dis(Line a, Line b){return std::abs((a.p^pnorm(a.v))-(b.p^pnorm(b.v)));}//两直线距离，需要确保平行 ///////////////////////////////////////////////// //平移 Line operator+(Line l, Vec v){return {l.p+v, l.v};}//直线平移 Seg operator+(Seg l, Vec v){return {l.a+v,l.b+v};}//线段平移 ///////////////////////////////////////////////// //旋转 Point rotate(Point p, db rad){return {cos(rad)*p.x-sin(rad)*p.y,sin(rad)*p.x+cos(rad)*p.y};}//绕原点旋转rad弧度 Point rotate(Point p, db rad, Point c){return c+rotate(p-c,rad);}//绕c旋转rad弧度 Line rotate(Line l, db rad, Point c=o){return {rotate(l.p,rad,c),rotate(l.v,rad)};}//直线绕c点旋转rad弧度 Seg rotate(Seg l, db rad, Point c=o){return {rotate(l.a,rad,c), rotate(l.b,rad,c)};}; ///////////////////////////////////////////////// //对称 Point reflect(Point a, Point p){return {p.x*2.0-a.x, p.y*2.0-a.y};}//a关于p的对称点 Line reflect(Line l, Point p){return {reflect(l.p,p),l.v};}//直线l关于p的对称直线 Seg reflect(Seg l, Point p){return {reflect(l.a,p),reflect(l.b,p)};}//线段l关于p的对称线段 Point reflect(Point a, Line ax){return reflect(a, pedal(a,ax));}//点a关于直线ax的对称点 Point reflect_v(Vec v, Line ax){return reflect(v,ax)-reflect(o,ax);}//向量v关于直线ax的对称向量 Line reflect(Line l, Line ax){return {reflect(l.p, ax),reflect_v(l.v, ax)};}//直线l关于直线ax的对称直线 Seg reflect(Seg l, Line ax){return {reflect(l.a, ax), reflect(l.b, ax)};} ///////////////////////////////////////////////// //交点 std::vector\u0026lt;Point\u0026gt; inter(Line a, Line b){ //两直线的交点，没有交点返回空vector，否则返回一个大小为1的vector db c = a.v^b.v; std::vector\u0026lt;Point\u0026gt; ret; if(eq(c,0.0)) return ret; Vec v = 1/c*Vec{a.p^(a.p+a.v), b.p^(b.p+b.v)}; ret.push_back({v*Vec{-b.v.x, a.v.x},v*Vec{-b.v.y, a.v.y}}); return ret; } std::vector\u0026lt;Point\u0026gt; inter(Line l, Circle c){ //直线与圆的交点 Point p = pedal(c.o, l); db h = len(p-c.o); std::vector\u0026lt;Point\u0026gt; ret; if(ge(h,c.r)) return ret; if(eq(h,c.r)) {ret.push_back(p);return ret;}; db d = std::sqrt(c.r*c.r - h*h); Vec v = d/len(l.v)*l.v; ret.push_back(p+v);ret.push_back(p+v); return ret; } std::vector\u0026lt;Point\u0026gt; inter(Circle c1, Circle c2){ //两个圆的交点 Vec v1 = c2.o - c1.o, v2 = r90c(v1); db d = len(v1); std::vector\u0026lt;Point\u0026gt; ret; if(ge(d, c1.r+c2.r)||ge(std::abs(c1.r-c2.r),d)) return ret; if(eq(d, c1.r+c2.r)||eq(std::abs(c1.r-c2.r),d)){ret.push_back(c1.o+c1.r/d*v1);return ret;} db a = ((c1.r*c1.r-c2.r*c2.r)/d+d)/2.0; db h = std::sqrt(c1.r*c1.r-a*a); Vec av = a/len(v1)*v1, hv = h/len(v2)*v2; ret.push_back(c1.o+av+hv);ret.push_back(c1.o+av-hv); return ret; } ///////////////////////////////////////////////// //三角形四心 Point barycenter(Point a, Point b, Point c){ //重心 return {(a.x+b.x+c.x)/3.0, (a.y+b.y+c.y)/3.0}; } Point circumcenter(Point a, Point b, Point c){ //外心 db a2 = a*a, b2 = b*b, c2 = c*c; db d = 2.0*(a.x*(b.y-c.y))+b.x*(c.y-a.y)+c.x*(a.y-b.y); return 1/d * r90c(a2*(b-c)+b2*(c-a)+c2*(a-b)); } Point incenter(Point a, Point b, Point c){ //内心 db a1 = len(b-c), b1 = len(a-c), c1 = len(a-b); db d = a1+b1+c1; return 1/d * (a1*a+b1*b+c1*c); } Point orthocenter(Point a, Point b, Point c){ //垂心 db n = b*(a-c), m = a*(b-c); db d = (b-c)^(a-c); return 1/d * r90c(n*(c-b)-m*(c-a)); } 二维凸包 Andrew扫描法 //复杂度 nlogn #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstdio\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; #define MAXN 50005 using namespace std; struct Point{ double x,y; Point()=default; Point(double x, double y):x(x),y(y){} Point operator + (Point p){ return Point(x+p.x, y+p.y); } Point operator - (Point p){ return Point(x-p.x, y-p.y); } Point operator * (double d){ return Point(x*d, y*d); } double dot(Point p){//点积 return x*p.x+y*p.y; } double det(Point p){//叉积 return x*(p.y)-(p.x)*y; } }; int n; Point po[MAXN*2]; bool cmp(Point\u0026amp; a, Point\u0026amp; b){ if(a.x!=b.x) return a.x\u0026lt;b.x; return a.y\u0026lt;b.y; } vector\u0026lt;Point\u0026gt; convexHull(){ //返回凸包上的点 int k = 0; vector\u0026lt;Point\u0026gt; qs; for(int i=0;i\u0026lt;n;i++){ while(k\u0026gt;1\u0026amp;\u0026amp;(qs[k-1]-qs[k-2]).det(po[i]-qs[k-1])\u0026lt;=0){ qs.erase(qs.end()-1); k--; } qs.push_back(po[i]); k++; } for(int i=n-2,t=k;i\u0026gt;=0;i--){ while(k\u0026gt;t\u0026amp;\u0026amp;(qs[k-1]-qs[k-2]).det(po[i]-qs[k-1])\u0026lt;=0) { qs.erase(qs.end()-1); k--; } qs.push_back(po[i]); k++; } qs.erase(qs.end()-1); return qs; } int main(){ cin\u0026gt;\u0026gt;n; for(int i=0;i\u0026lt;n;i++){ cin\u0026gt;\u0026gt;po[i].x\u0026gt;\u0026gt;po[i].y; //输入点的横纵坐标 } sort(po,po+n,cmp); for(auto p:convexHull()){ cout\u0026lt;\u0026lt;p.x\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;p.y\u0026lt;\u0026lt;endl; } return 0; } 旋转卡壳求最远点对 //复杂度 nlogn，其中求凸包nlogn，旋转卡壳本身为n //Luogu P1452 //旋转卡壳和凸包 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; #define MAXN 50005 using namespace std; struct Point{ int x,y; Point()=default; Point(int x, int y):x(x),y(y){} Point operator - (Point p){ return Point(x-p.x, y-p.y); } Point operator + (Point p){ return Point(x+p.x, y+p.y); } Point operator * (int d){ return Point(x*d, y*d); } int dot(Point p){ return x*p.x+y*p.y; } int det(Point p){ return x*(p.y)-y*(p.x); } }; bool cmp(Point\u0026amp; a, Point\u0026amp; b){ if(a.x!=b.x) return a.x\u0026lt;b.x; return a.y\u0026lt;b.y; } int n; Point po[MAXN]; vector\u0026lt;Point\u0026gt; convexHull(){ //返回凸包上的点 vector\u0026lt;Point\u0026gt; ans; int k = 0; for(int i=0;i\u0026lt;n;i++){ while(k\u0026gt;1\u0026amp;\u0026amp;(ans[k-1]-ans[k-2]).det(po[i]-ans[k-1])\u0026lt;=0){ ans.erase(ans.end()-1); k--; } ans.push_back(po[i]); k++; } for(int i=n-2,t=k;i\u0026gt;=0;i--){ while(k\u0026gt;t\u0026amp;\u0026amp;(ans[k-1]-ans[k-2]).det(po[i]-ans[k-1])\u0026lt;=0){ ans.erase(ans.end()-1); k--; } ans.push_back(po[i]); k++; } ans.erase(ans.end()-1); return ans; } inline long long dist(Point a, Point b){//计算距离的平方 return (a-b).dot(a-b); } void rc(vector\u0026lt;Point\u0026gt; ans){ int tn = ans.size(); int cnt=0; if(tn==2){ cout\u0026lt;\u0026lt;dist(ans[0],ans[1])\u0026lt;\u0026lt;endl; return; } int i=0,j=0; for(int k=0;k\u0026lt;tn;k++){ if(!cmp(ans[i],ans[k])) i=k; if(cmp(ans[j],ans[k])) j=k; } long long res = 0; int si=i,sj=j; while(i!=sj||j!=si){ res = max(res,dist(ans[i],ans[j])); if((ans[(i+1)%tn]-ans[i]).det(ans[(j+1)%tn]-ans[j])\u0026lt;0){ i = (i+1)%tn; }else{ j = (j+1)%tn; } cnt++; } //返回凸包最远点对的距离的平方 cout\u0026lt;\u0026lt;res\u0026lt;\u0026lt;endl; } int main(){ cin\u0026gt;\u0026gt;n; vector\u0026lt;Point\u0026gt; qs; for(int i=0;i\u0026lt;n;i++){ cin\u0026gt;\u0026gt;po[i].x\u0026gt;\u0026gt;po[i].y; //按横纵坐标输入点对 } sort(po,po+n,cmp); qs = convexHull(); rc(qs); return 0; } 平面最近点对 输入\\(n\\)个点的平面坐标，使用分治法计算最近点对，复杂度\\(O(nlogn)\\)\n//复杂度nlogn //Luogu P1257 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cmath\u0026gt; const int MAXN = 200005; struct Node{ int x,y; int id; bool operator\u0026lt;(const Node\u0026amp; a) const { if(x!=a.x) return x\u0026lt;a.x; return y\u0026lt;a.y; } }nodes[MAXN]; bool cmp(const Node\u0026amp; a, const Node\u0026amp; b){ return a.y\u0026lt;b.y; } double minDist; int ansA, ansB; inline void updAns(const Node\u0026amp; a, const Node\u0026amp; b){ double dist = sqrt((a.x-b.x)*(a.x-b.x)+(a.y-b.y)*(a.y-b.y)+0.0); if(dist\u0026lt;minDist){ minDist = dist; //如果要记录节点 ansA = a.id; ansB = b.id; } } void calcMin(int l, int r){ if(r-l\u0026lt;=3){ for(int i=l;i\u0026lt;=r;i++){ for(int j=i+1;j\u0026lt;=r;j++){ updAns(nodes[i],nodes[j]); } } std::sort(nodes+l, nodes+r+1, cmp); return; } int m = (l+r)\u0026gt;\u0026gt;1; int midx = nodes[m].x; calcMin(l,m); calcMin(m+1,r); //归并排序的合并，两个有序数组合并，合并之后仍然有序 std::inplace_merge(nodes+l, nodes+m+1, nodes+r+1, cmp); static Node t[MAXN]; int tsz = 0; for (int i = l; i \u0026lt;= r; ++i){ if (abs(nodes[i].x - midx) \u0026lt; minDist) { for (int j = tsz - 1; j \u0026gt;= 0 \u0026amp;\u0026amp; nodes[i].y - t[j].y \u0026lt; minDist; --j) updAns(nodes[i], t[j]); t[tsz++] = nodes[i]; } } } int main(){ int n; std::cin\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;nodes[i].x\u0026gt;\u0026gt;nodes[i].y; nodes[i].id = i; } std::sort(nodes+1,nodes+1+n); minDist = 1e20; calcMin(1,n); printf(\u0026#34;%.4f\\n\u0026#34;,minDist); return 0; } 扫描线算法 //Luogu P5490 //复杂度 nlogn #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; using ll = long long; int const MAXN = 2000005; struct Line{ ll l,r,h; int tag; Line(){} Line(ll l, ll r, ll h, int tag):l(l),r(r),h(h),tag(tag){} bool operator\u0026lt;(Line const \u0026amp; rhs) const{ return h\u0026lt;rhs.h; } }line[MAXN*2]; ll st[MAXN*4+2];//对于一颗线段树，n个数所组成的树最多有4n-5个节点，开大了一点 ll posX[MAXN*2]; ll len[MAXN*4+2]; void update(int l, int r, int s, int t, int p, ll c){//c表示加减的数值 if(posX[t+1]\u0026lt;=l || r\u0026lt;=posX[s]) return; if(l\u0026lt;=posX[s] \u0026amp;\u0026amp; posX[t+1]\u0026lt;=r){ st[p] += c; if(st[p]){ len[p] = posX[t+1] - posX[s]; } else{ len[p] = len[p*2] + len[p*2+1]; } return; } int m = s + ((t-s)\u0026gt;\u0026gt;1); if(l\u0026lt;=posX[m]) update(l, r, s, m, p*2, c); if(r\u0026gt;posX[m]) update(l, r, m+1, t, p*2+1, c); if(st[p]){ len[p] = posX[t+1] - posX[s]; } else{ len[p] = len[p*2] + len[p*2+1]; } } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n; std::cin\u0026gt;\u0026gt;n;//矩形个数 ll x1,x2,y1,y2; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;x1\u0026gt;\u0026gt;y1\u0026gt;\u0026gt;x2\u0026gt;\u0026gt;y2;//输入每个矩形的左下角和右上角 posX[2*i-1] = x1, posX[2*i] = x2; line[2*i-1] = Line(x1,x2,y1,1), line[2*i] = Line(x1,x2,y2,-1); } n*=2;//方便起见 std::sort(line+1,line+n+1); std::sort(posX+1,posX+n+1); int sumSeg = std::unique(posX+1, posX+1+n) - posX - 1 - 1;//去重求出线段总数 ll ans = 0; for(int i=1;i\u0026lt;n;i++){//最后一条边不用管 update(line[i].l, line[i].r, 1, sumSeg, 1, line[i].tag); ans += len[1] * (line[i+1].h - line[i].h); } std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;;//输出矩形的并集的总面积 return 0; } 二维数点 //Luogu P2163 //时间复杂度 nlogn #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; int const MAXN = 500005; struct Point{ int x,y; int tag;//用于区分实际的点和查询时的虚点 bool operator\u0026lt;(Point const \u0026amp; p){ if(x!=p.x) return x\u0026lt;p.x; if(y!=p.y) return y\u0026lt;p.y; return tag\u0026lt;p.tag; } }pts[MAXN*5];//实点和查询矩阵的点都放在这里面 int b[MAXN*5]; int bit[MAXN]; int ans[MAXN][5]; int tot[MAXN]; inline int lowbit(int n){ return n\u0026amp;(-n); } void update(int p, int k, int n){ for(;p\u0026lt;=n;p+=lowbit(p)){ bit[p]+=k; } } int query(int p){ int ret=0; for(;p;p-=lowbit(p)){ ret+=bit[p]; } return ret; } inline int lsh(int x, int cnt){//离散化函数 return std::lower_bound(b+1,b+cnt+1,x)-b; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m;//点数，查询数 for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;pts[i].x\u0026gt;\u0026gt;pts[i].y;//所有实点的坐标 pts[i].tag = 0; } for(int i=1;i\u0026lt;=m;i++){ int x1,x2,y1,y2; std::cin\u0026gt;\u0026gt;x1\u0026gt;\u0026gt;y1\u0026gt;\u0026gt;x2\u0026gt;\u0026gt;y2;//查询的长方形的左下角和右上角 pts[++n].x = x1-1, pts[n].y = y1-1, pts[n].tag = i; pts[++n].x = x2, pts[n].y = y2, pts[n].tag = i; pts[++n].x = x2, pts[n].y = y1-1, pts[n].tag = i; pts[++n].x = x1-1, pts[n].y = y2, pts[n].tag = i; } std::sort(pts+1,pts+1+n); for(int i=1;i\u0026lt;=n;i++) b[i] = pts[i].y; std::sort(b+1,b+1+n); int cnt = std::unique(b+1,b+1+n) - b - 1;//把所有y离散化 for(int i=1;i\u0026lt;=n;i++){ if(pts[i].tag){ ans[pts[i].tag][++tot[pts[i].tag]] = query(lsh(pts[i].y, cnt)); } else{ update(lsh(pts[i].y, cnt), 1, cnt); } } for(int i=1;i\u0026lt;=m;i++){ std::cout\u0026lt;\u0026lt;ans[i][4]-ans[i][3]-ans[i][2]+ans[i][1]\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } Pick定理 给定顶点均为整点的简单多边形，其面积\\(A\\)和内部格点数目\\(i\\)，边上格点数目\\(b\\)的关系为\n\\[A = i+\\dfrac{b}{2}-1 \\]\n组合数学 用乘法逆元计算组合数 TODO: 用模板元编程实现编译期算阶乘\n根据\n\\[(a/b)\\%p=(a\\times b^{-1})\\%p=[(a\\%p)\\times(b^{-1}\\%p)]\\%p \\]\n（如果加载不全，见取余运算的分配律）\n可以不用除法求出组合数。其中\\(b^{-1}\\)是\\(b\\)在模\\(p\\)意义下的逆元。\n注意阶乘和其逆元的预处理。\n//复杂度 初始化为nlogn 后续查询为O(1) //luogu P3414，只能过50%（因为这道题考的不是这个） using LL = long long; const int MAXN = 200005; const LL MOD = 6662333; LL fac[MAXN]; LL invFac[MAXN]; LL qPowMod(LL x, LL p, LL m){ //x^p % m LL ans = 1; while(p){ if(p\u0026amp;1){ ans = (ans*x)%m; } x = (x*x)%m; p\u0026gt;\u0026gt;=1; } return ans; } LL fermat_inv(LL a, LL b){ return qPowMod(a,b-2,b); } void init(int n){ fac[0] = 1; invFac[0] = 1; for(int i=1;i\u0026lt;=n;i++){ fac[i] = (fac[i-1]*i)%MOD; invFac[i] = fermat_inv(fac[i],MOD); } } LL comb(LL n, LL m){ //n里面选m个 if(n\u0026lt;0||m\u0026lt;0||m\u0026gt;n) return 0; return (((fac[n]*invFac[m])%MOD)*invFac[n-m])%MOD; } 组合数的性质 二项式定理\n\\[(a+b)^n = \\sum^n_{i=0}\\binom{n}{i}a^{n-i}b^i \\]\n对称性\n\\[\\binom{n}{m} = \\binom{n}{n-m} \\]\n递推式1\n\\[\\binom{n}{k}=\\dfrac{n}{k}\\binom{n-1}{k-1} \\]\n递推式2\n\\[\\binom{n}{m} = \\binom{n-1}{m}+\\binom{n-1}{m-1} \\]\n二项式定理的特例1\n\\[\\binom{n}{0}+\\binom{n}{1}+\\cdots+\\binom{n}{n} = 2^n \\]\n二项式定理的特例2\n\\[\\sum^n_{i=0}(-1)^i\\binom{n}{i} = [n=0] \\]\n组合数拆分\n\\[\\sum^m_{i=0}\\binom{n}{i}\\binom{m}{m-i} = \\binom{m+n}{m} (n\\geq m) \\]\n组合数拆分的特例\n\\[\\sum^m_{i=0}\\binom{n}{i}^2= \\binom{2n}{n} \\]\n带权和1\n\\[\\sum^n_{i=0}i\\binom{n}{i} = n2^{n-1} \\]\n带权和2\n\\[\\sum^n_{i=0}i^2\\binom{n}{i} = n(n+1)2^{n-2} \\]\n性质1\n\\[\\sum^n_{l=0}\\binom{l}{k} = \\binom{n+1}{k+1} \\]\n性质2\n\\[\\binom{n}{r}\\binom{r}{k} = \\binom{n}{k}\\binom{n-k}{r-k} \\]\n斐波那契数列性质\n\\[\\sum^n_{i=0}\\binom{n-i}{i} = F_{n+1} \\]\n圆排列 \\(n\\)个人全部来围成一圈，所有的排列数记为\\(Q^n_n\\)。考虑其中已经拍好的一圈，从不同位置断开可以变成不同的队列，则有\n\\[Q^n_n\\times n = A^n_n \\]\n由此可知\n\\[Q^r_n = \\dfrac{A^r_n}{r} \\]\n二项式反演 记\\(f_n\\)表示恰好使用\\(n\\)个不同元素形成特定结构的方案数，\\(g_n\\)表示从\\(n\\)个不同元素中选出\\(i\\geq 0\\)个元素形成特定结构的总方案数。有\n\\[g_n = \\sum^n_{i=0}\\binom{n}{i}f_i \\]\n二项式反演就是已知\\(g_n\\)求\\(f_n\\)\n\\[f_n = \\sum^n_{i=0}\\binom{n}{i}(-1)^{n-i}g_i \\]\n斐波那契数列的性质 通项公式\n\\[F_n = \\dfrac{\\left(\\dfrac{1+\\sqrt{5}}{2}\\right)^n-\\left(\\dfrac{1-\\sqrt{5}}{2}\\right)^n}{\\sqrt{5}} \\]\n\\[F_n = \\left[\\dfrac{\\left(\\dfrac{1+\\sqrt{5}}{2}\\right)^n}{\\sqrt{5}}\\right] \\]\n中括号表示取离他最近的整数。\n性质1\n\\[F_{n-1}F_{n+1}-F_n^2=(-1)^n \\]\n性质2\n\\[F_{n+k}=F_kF_{n+1}+F_{k-1}F_n \\]\n性质3\n\\[F_{2n}=F_{n}(F_{n+1}+F_{n-1}),\\quad F_{2n+1}=F^2_{k+1}+F^2_k \\]\n性质4\n\\[\\forall k\\in N,F_n|F_{nk} \\]\n性质5\n\\[\\forall F_a|F_b,a|b \\]\n性质6\n\\[\\gcd(F_m,F_n)=F_{\\gcd(m,n)} \\]\n性质7\n\\[F_{n+1}=\\sum_{0\\leq i\\leq n}\\binom{n-i}{i} \\]\n和式性质 基本性质 \\[\\sum_{k\\in K}ca_k=c\\sum_{k\\in K}a_k \\]\n\\[\\sum_{k\\in K}(a_k+b_k)=\\sum_{k\\in K}a_k+\\sum_{k\\in K}b_k \\]\n\\[\\sum_{k\\in K}a_k = \\sum_{p(k)\\in K}a_{p(k)} \\]\n此处\\(p(k)\\)是\\(k\\)的任意排列。\n多重和式分配律 \\[\\sum_{j\\in J,k\\in K}a_jb_k = (\\sum_{j\\in J}a_j)(\\sum_{k\\in K}b_k) \\]\n多重和式次序交换 \\[\\sum_{j\\in J}\\sum_{k\\in K}a_{j,k} = \\sum_{j\\in J,k\\in K}a_{j,k} = \\sum_{k\\in K}\\sum_{j\\in J}a_{j,k} \\]\n当\\(J,K\\)相互独立时成立。\n\\[\\sum_{j\\in J}\\sum_{k\\in K(j)}a_{j,k} = \\sum_{k\\in K'}\\sum_{j\\in J'(k)}a_{j,k} \\]\n这里\\(J,K\\)不独立，并且要满足\n\\[[j\\in J][k\\in K(j)]=[k\\in K'][j\\in J'(k)] \\]\n例如\n\\[\\sum_{j=1}^n\\sum_{k=j}^na_{j,k}=\\sum_{i\\leq j\\leq k\\leq n}a_{j,k}=\\sum_{k=1}^n\\sum_{j=1}^ka_{j,k} \\]\n卡特兰数 TODO: 用模板元编程实现编译期算卡特兰数\n第\\(n\\)个记作\\(C_n\\)\n\\(n\\)对括号形成的字符串，合法的情况数是\\(C_n\\)\n\\(n\\)个节点的二叉树，总共有\\(C_n\\)种\n\\(2n+1\\)个节点组成的满二叉树，有\\(C_n\\)种\n\\(n\\times n\\)的格点网中，从左下角格点出发，到达右上角格点，不穿过对角线（但可以碰到）的单调路径个数有\\(C_n\\)个。\n在圆上有\\(2n\\)个点，将这些点成对连接起来使得所得到的\\(n\\)条线段不相交的方法数为\\(C_n\\)种\n一个栈（无穷大）的进栈序列为\\(1,2,3,\\cdots,n\\)，合法的出栈序列有\\(C_n\\)个\n其计算公式为\n\\[C_n = \\frac{1}{n+1}\\binom{2n}{n} \\]\n\\[C_n=\\binom{2n}{n} - \\binom{2n}{n-1} \\]\n\\[C_0=1,C_{n+1}=\\sum^n_{i=0}C_iC_{n-i} \\]\n\\[C_0=1,C_{n+1}=\\frac{2(2n+1)}{n+2}C_n \\]\n//复杂度 n #include \u0026lt;iostream\u0026gt; //前几项：1, 1, 2, 5, 14, 42, 132, 429, 1430, 4862, 16796 //luogu p1044 using namespace std; typedef long long ll; const int MAXN = 3005; ll h[MAXN]; ll comb(ll a,ll b){ ll ans=1; for(ll i=1;i\u0026lt;=b;i++){ ans*=a;//数字太大会爆 a--; } for(ll i=1;i\u0026lt;=b;i++){ ans/=i; } return ans; } int main(){ ll n; cin\u0026gt;\u0026gt;n; for(ll i=1;i\u0026lt;=n;i++){ cout\u0026lt;\u0026lt;comb(2*i,i)/(i+1)\u0026lt;\u0026lt;endl;//n\u0026gt;=15的时候ll都能爆 } cout\u0026lt;\u0026lt;\u0026#34;###\u0026#34;\u0026lt;\u0026lt;endl; //下面是递推求法，不容易爆 h[1]=1; cout\u0026lt;\u0026lt;h[1]\u0026lt;\u0026lt;endl; for(ll i=2;i\u0026lt;=n;i++){ h[i] = h[i-1]*(4*i-2)/(i+1); cout\u0026lt;\u0026lt;h[i]\u0026lt;\u0026lt;endl; } return 0; } 生成函数 生成函数是一种形式幂级数\n\\[F(x) = \\sum_na_nx^n \\]\n\\(\\{a_i\\}\\)序列可以是有限的，也可以是无限的。\\(a_i\\)下标以\\(0\\)为起点。生成函数例如\n\\(a=\u003c1,2,3\u003e\\)的普通生成函数为\\(1+2x+3x^2\\) \\(a=\u003c1,1,1,\\cdots\u003e\\)的普通生成函数为\\(\\sum_{n\\geq 0}x^n\\) \\(a=\u003c2,4,6,8,\\cdots\u003e\\)的普通生成函数为\\(\\sum_{n\\geq 0}(2n+2)x^n\\) 加减运算\n设序列\\(a,b\\)的普通生成函数分别为\\(F(x),G(x)\\)，则\n\\[F(x)\\pm G(x) = \\sum_n(a_n\\pm b_n)x^n \\]\n乘/卷积运算\n\\[F(x)G(x) = \\sum_n x^n\\sum^n_{i=0}a_i b_{n-i} \\]\n给出一些常见封闭形式，这其实和幂级数收敛时的求和公式差不多（目前只会普通生成函数来应对组合问题，之后更新指数生成函数应对排列问题TODO）：\n\\[\\sum_{n\\geq 0}x^n = \\dfrac{1}{1-x} \\]\n\\[\\sum_{n\\geq 0}p^nx^n=\\dfrac{1}{1-px} \\]\n\\[\\sum_{n\\geq 1}x^n = \\dfrac{x}{1-x} \\]\n\\[\\sum_{n\\geq 0}x^{cn} = \\dfrac{1}{1-x^c} \\]\n\\[1+2x+3x^2+\\cdots = \\sum_{n\\geq 0}(n-1)x^n = \\dfrac{1}{(1-x)^2} \\]\n\\[\\sum_{n\\geq 0}\\binom{m}{n}x^n = (1+x)^m \\]\n\\[\\sum_{n\\geq 0}\\binom{m+n-1}{n}x^n = \\dfrac{1}{(1-x)^{m}} \\]\n其他有限项生成函数应该用等比数列求和公式，转化成分式形式。之后再来进行生成函数的计算。\n例题\n在许多不同种类的食物中选出\\(n\\)个，每种食物的限制如下（每种食物选出来的个数必须满足该限制）\n汉堡：偶数个 可乐：0或1个 鸡腿：0或1或2个 蜜桃多：奇数个（注：0个不满足条件） 鸡块：4的倍数个 包子，0、1、2、3个 土豆炒肉：不超过1个 面包：3的倍数个 所有食物选出来的总数加起来等于\\(n\\)就可以算作一种方案。计算方案总数模\\(10007\\)\n我们设\\(a_n\\)表示这种食物选\\(n\\)个的方案数，并求出其生成函数。显然，假设只选两个食品，如果食品1选了\\(i\\)个，那么食品2就只能选\\(n-i\\)个。这和我们之前的卷积形式是一样的。所以我们应该把各种食品的生成函数的封闭形式乘起来得到答案。生成函数构造如下\n\\(\\sum_{n\\geq 0}x^{2n}=\\dfrac{1}{1-x^2}\\) \\(1+x\\) \\(1+x+x^2=\\dfrac{1-x^3}{1-x}\\)（这里食品都是相同的，所以选1个只有1种方案。求法是等比数列求和。有些题的物品是不同的，这里就要变成其他序列） \\(\\dfrac{x}{1-x^2}\\) \\(\\dfrac{1}{1-x^4}\\) \\(\\dfrac{1-x^4}{1-x}\\) \\(1+x\\) \\(\\dfrac{1}{1-x^3}\\) 全部乘起来得到的生成函数为\n\\[F(x) = \\dfrac{(1+x)(1-x^3)x(1-x^4)(1+x)}{(1-x^2)(1-x)(1-x^2)(1-x^4)(1-x)(1-x^3)} = \\dfrac{x}{(1-x)^4} \\]\n再转化为展开形式\n\\[F(x) = \\sum_{n\\geq 0}\\binom{n+3}{n}x^{n+1}=\\sum_{n\\geq 1}\\binom{n+2}{n-1}x^n \\]\n可得答案就是\\(\\binom{n+2}{n-1}=\\binom{n+2}{3}\\)\n稳定婚姻问题(Gale-Shapley算法) TODO //POJ 3487 #include \u0026lt;iostream\u0026gt; #include \u0026lt;queue\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cstring\u0026gt; using namespace std; const int N = 30; const int inf = 1\u0026lt;\u0026lt;29; const int MOD = 2007; typedef long long ll; int couple; int maleLike[N][N], femaleLike[N][N]; int maleChoice[N], femaleChoice[N]; int maleName[N], femaleName[N]; char str[N]; queue\u0026lt;int\u0026gt;freemale;//目前单身的男人 int main(){ int t; scanf(\u0026#34;%d\u0026#34;,\u0026amp;t);//数据组数 while(t--){ scanf(\u0026#34;%d\u0026#34;,\u0026amp;couple);//男女对数 while(!freemale.empty()){ freemale.pop(); } for(int i=0;i\u0026lt;couple;i++){ scanf(\u0026#34;%s\u0026#34;,str); maleName[i]=str[0]-\u0026#39;a\u0026#39;;//题目中是以小写字母给男人名字，转化为数字 freemale.push(maleName[i]); } sort(maleName, maleName+couple);//名字排序，便于字典序 for(int i=0;i\u0026lt;couple;i++){ scanf(\u0026#34;%s\u0026#34;,str); femaleName[i]=str[0]-\u0026#39;A\u0026#39;;//女人名字是大写字母 } for(int i=0;i\u0026lt;couple;i++){ scanf(\u0026#34;%s\u0026#34;,str); for(int j=0;j\u0026lt;couple;j++){ maleLike[i][j]=str[j+2]-\u0026#39;A\u0026#39;;//男人喜好顺序由男人名字:女人名字列表给出;降序排列 } } //女士对男士的打分，添加虚拟人物，编号couple，为女士的初始对象 for(int i=0;i\u0026lt;couple;i++){ scanf(\u0026#34;%s\u0026#34;,str); for(int j=0;j\u0026lt;couple;j++){ femaleLike[i][str[j+2]-\u0026#39;a\u0026#39;]=couple-j;//排名越前打分越高 } femaleLike[i][couple]=0; } memset(maleChoice,0,sizeof(maleChoice)); //一开始男士的期望都是最喜欢的女士 for(int i=0;i\u0026lt;couple;i++){ femaleChoice[i]=couple; } while(!freemale.empty()){ int male=freemale.front(); //找出未配对的男士 int female=maleLike[male][maleChoice[male]]; //找出心意的女士 if(femaleLike[female][male]\u0026gt;femaleLike[female][femaleChoice[female]]){ //比现男友好 freemale.pop(); if(femaleChoice[female]!=couple){ //前男友再次单身，并且不能将虚拟人物加入队列 freemale.push(femaleChoice[female]); maleChoice[femaleChoice[female]]++; } femaleChoice[female]=male; //更换男友 } else maleChoice[male]++; //如果被拒绝，则选择下一位 } for(int i=0;i\u0026lt;couple;i++){ printf(\u0026#34;%c %c\\n\u0026#34;,maleName[i]+\u0026#39;a\u0026#39;, maleLike[maleName[i]][maleChoice[maleName[i]]]+\u0026#39;A\u0026#39;); } if(t) puts(\u0026#34;\u0026#34;); } return 0; } 数据结构 树状数组 //复杂度 单次查询 logn 单次修改 logn //树状数组，维护的是数组的前缀和，有大量的应用 //luogu P3374 //普通的树状数组要维护的信息，其运算要满足结合律和可差分 //结合律不难理解，可差分指的是若已知x op y和x，则可以求出y //这样的运算例如加，乘，异或。乘如果在模意义下可差分，需要保证每个数都有逆元，如果模数为质数则肯定有 //gcd,max这种是不可差分的 #include \u0026lt;iostream\u0026gt; int const MAXN = 1000005; using LL = long long; class Fenwick{ public: LL data[MAXN]; int size = 0; void init(int size_){size=size_;} inline int lowbit(int x){ return x\u0026amp;(-x); } void update(int p, LL k){//位置p的元素加k for(;p\u0026lt;=size;p+=lowbit(p)){ data[p]+=k; } } LL query(int p){//查询[1,p]的和 LL ret=0; for(;p;p-=lowbit(p)){ ret += data[p]; } return ret; } }; Fenwick fenwick; int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; //数组长度，查询数 fenwick.init(n); for(int i=1;i\u0026lt;=n;i++){ LL tmp; std::cin\u0026gt;\u0026gt;tmp; fenwick.update(i,tmp); } for(int i=1;i\u0026lt;=m;i++){ int op; int x,y; LL k; std::cin\u0026gt;\u0026gt;op\u0026gt;\u0026gt;x; if(op==1){ std::cin\u0026gt;\u0026gt;k; //将单点增加k，如果想要改成修改，则可以update(x,k-查询x位置上的数) fenwick.update(x,k); } else{ std::cin\u0026gt;\u0026gt;y; //输出[x,y]的数组和 std::cout\u0026lt;\u0026lt;fenwick.query(y)-fenwick.query(x-1)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } } return 0; } 树状数组求逆序对 //复杂度 nlogn //Luogu P1908 //逆序对\u0026lt;i,j\u0026gt;即，符合i\u0026lt;j且ai\u0026gt;aj的\u0026lt;i,j\u0026gt;的个数 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #define LL long long const int MAXN = 500005; LL arr[MAXN]; struct Par{ LL value,id; }par[MAXN]; bool cmp(const Par\u0026amp; a,const Par\u0026amp; b){ if(a.value!=b.value) return a.value\u0026lt;b.value; return a.id\u0026lt;b.id; } LL bit[MAXN]; inline LL lowbit(LL n){ return n\u0026amp;(-n); } void update(LL p, LL k, LL n){ for(;p\u0026lt;=n;p+=lowbit(p)){ bit[p]+=k; } } long long query(LL p){ LL ans=0; for(;p;p-=lowbit(p)){ ans+=bit[p]; } return ans; } int main(){ LL n; std::cin\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;par[i].value; par[i].id = i; } std::sort(par+1,par+1+n,cmp); for(int i=1;i\u0026lt;=n;i++){ arr[par[i].id] = i; }//这一步其实是离散化，但与stl实现的离散化不同的是， //出现同样的数字时，例如6,-4,3,7,3会离散化为4,1,2,5,3 LL ans = 0; for(int i=1;i\u0026lt;=n;i++){ ans += query(arr[i]); update(arr[i],1,n); } ans = n*(n-1)/2-ans;//本来统计的是等于或顺序对，现在反过来计算逆序对 std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 二维树状数组 //二维树状数组 支持单点修改和区间查询 //loj 133 #include \u0026lt;iostream\u0026gt; int const MAXN = 5005; using LL = long long; class BIT2D{ public: int N,M; LL data[MAXN][MAXN]; void init(int n,int m){ N = n, M = m; } inline int lowbit(int x){ return x\u0026amp;(-x); } void add(int x, int y, LL v){//把(x,y)这个点加上v for(int i=x;i\u0026lt;=N;i+=lowbit(i)){ for(int j=y;j\u0026lt;=M;j+=lowbit(j)){ data[i][j] += v; } } } LL sum(int x, int y){ LL ret = 0; for(int i=x;i\u0026gt;0;i-=lowbit(i)){ for(int j=y;j\u0026gt;0;j-=lowbit(j)){ ret += data[i][j]; } } return ret; } LL query(int x1, int y1, int x2, int y2){//查询(x1,y1)-(x2,y2)这个矩形的区间和 return sum(x2,y2) - sum(x2,y1-1) - sum(x1-1, y2) + sum(x1-1, y1-1); } }; BIT2D bit2d; 并查集 //复杂度 很小 //并查集 Luogu3367 const int MAXN = 10005; class DSU{ public: int fa[MAXN], rk[MAXN]; void init(int n){ for(int i=1;i\u0026lt;=n;i++) fa[i] = i, rk[i] = 1; } int find(int x){ //没有路径压缩的find，在需要删除操作时，不能使用路径压缩，只能按秩合并保证复杂度 return fa[x]==x ? x : find(fa[x]); } int findc(int x){ //带路径压缩的find return fa[x]==x ? x : (fa[x] = findc(fa[x])); } void merge(int x, int y){ //按秩合并，如果不需要则直接 fa[find(x)] = find(y); x = find(x), y = find(y); if(x==y) return; if(rk[x]\u0026gt;rk[y]) std::swap(x,y); fa[x] = y; if(rk[x]==rk[y]) rk[y]++; } void mergec(int x, int y){ //按秩合并+路径压缩，如果不需要则直接 fa[findc(x)] = findc(y); x = findc(x), y = findc(y); if(x==y) return; if(rk[x]\u0026gt;rk[y]) std::swap(x,y); fa[y] = x; if(rk[x]==rk[y]) rk[y]++; } void erase(int x){ --rk[find(x)]; fa[x] = x; } }; 线段树 //复杂度 单次查询 logn 单次修改 logn //luogu p3372 //线段树维护的数据要求满足结合律，比如区间和，区间最大区间最小，区间gcd //区间修改一般支持加、乘、赋值 #include \u0026lt;iostream\u0026gt; int const MAXN = 100005; using LL = long long; struct Node { int s,t;//该端点的起点和终点下标 LL tag, v; }; Node st[MAXN*4+2]; LL arr[MAXN]; void build(int s, int t, int p=1){ st[p].s = s; st[p].t = t; if(s==t) { st[p].v = arr[s]; st[p].tag = 0; return; } int m = s+((t-s)\u0026gt;\u0026gt;1); build(s,m,p*2); build(m+1,t,p*2+1); st[p].v = st[p*2].v + st[p*2+1].v; st[p].tag = 0; } void spreadTag(int p){ if(st[p].tag){ int s = st[p].s, t = st[p].t; int m = s+((t-s)\u0026gt;\u0026gt;1); st[p*2].v += (m-s+1)*st[p].tag; st[p*2+1].v += (t-m)*st[p].tag; st[p*2].tag += st[p].tag; st[p*2+1].tag += st[p].tag; st[p].tag=0; } } void update(int l, int r, LL k, int p=1){ int s = st[p].s, t = st[p].t; if(l\u0026lt;=s \u0026amp;\u0026amp; t\u0026lt;=r){ st[p].v += (t-s+1) * k; st[p].tag += k; return; } spreadTag(p); int m = s+((t-s)\u0026gt;\u0026gt;1); if(l\u0026lt;=m) update(l, r, k, p*2); if(r\u0026gt;m) update(l, r, k, p*2+1); st[p].v = st[p*2].v + st[p*2+1].v; } LL query(int l, int r, int p=1){ int s = st[p].s, t = st[p].t; if(l\u0026lt;=s \u0026amp;\u0026amp; t\u0026lt;=r) return st[p].v; spreadTag(p); int m = s+((t-s)\u0026gt;\u0026gt;1); LL ret = 0; if(l\u0026lt;=m) ret+=query(l,r,p*2); if(r\u0026gt;m) ret+=query(l,r,p*2+1); return ret; } 动态开点线段树 //动态开点线段树 //luogu p3372，由于并没有找到合适的习题，我把题中的查询范围全部加了一个偏移值-5e4 //动态开点线段树并不是动态分配内存，只是在范围很大，但查询不多的时候，可以用 //普通线段树的空间复杂度是O(n)，单次操作的时间复杂度是O(logn) //动态开点，设查询为m次，时间复杂度仍然为O(logn)，但是空间复杂度变成O(mlogn) //动态开点还可以处理查询范围为负数的情况，比如查询[-5,6]这一段上的和 //动态开点假设初始数组全部为0，输入一个数组时直接add修改线段树即可 using LL = long long; int const MAXN = 8e6+5;//能开多大开多大，128M可以开到800万 struct Node{ LL val, tag; int ls, rs; }st[MAXN]; inline int\u0026amp; ls(int x){return st[x].ls;} inline int\u0026amp; rs(int x){return st[x].rs;} inline LL\u0026amp; val(int x){return st[x].val;} inline LL\u0026amp; tag(int x){return st[x].tag;} inline int getMid(int s, int t){ //处理负数边界时，需要强行向下取整，而不是向零取整 if(s+t==0) return 0; if(s+t\u0026gt;0) return (s+t)/2; return -((-s-t+1)/2); } int stcnt = 1; int L = -(1e6+5), R = 1e6+5;//这里根据题目信息选择区间范围 void upd(int \u0026amp;p, LL k, int len){ if(!p) p = ++stcnt; val(p) += k * len; tag(p) += k; } void spreadTag(int p, int len){ if(len\u0026lt;=1) return; upd(ls(p), tag(p), len-len/2); upd(rs(p), tag(p), len/2); tag(p) = 0; } LL query(int l, int r, int p = 1, int s = L, int t = R){ if(s\u0026gt;=l \u0026amp;\u0026amp; t\u0026lt;=r) return val(p); spreadTag(p, t-s+1); int mid = getMid(s,t); LL ret = 0; if(mid \u0026gt;= l) ret += query(l, r, ls(p), s, mid); if(mid \u0026lt; r) ret += query(l, r, rs(p), mid+1, t); return ret; } void add(int l, int r, LL k, int p = 1, int s = L, int t = R){ if(s\u0026gt;=l \u0026amp;\u0026amp; t\u0026lt;=r){ val(p) += k * (t-s+1); tag(p) += k; return; } spreadTag(p, t-s+1); int mid = getMid(s,t); if(mid \u0026gt;= l) add(l, r, k, ls(p), s, mid); if(mid \u0026lt; r) add(l, r, k, rs(p), mid+1, t); val(p) = val(ls(p)) + val(rs(p)); } void solve(){ int n,m; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; int const offset = -5e4; for(int i=1;i\u0026lt;=n;i++){ int a; std::cin\u0026gt;\u0026gt;a; add(i+offset,i+offset,a); } while(m--){ int ope, l, r, x; std::cin\u0026gt;\u0026gt;ope\u0026gt;\u0026gt;l\u0026gt;\u0026gt;r; l += offset; r += offset; if(ope==1){ std::cin\u0026gt;\u0026gt;x; add(l,r,x); } else{ std::cout\u0026lt;\u0026lt;query(l,r)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } } } 权值线段树 //权值线段树 //loj 104 //权值线段树大部分时候是用来代替平衡树使用的 //和树状数组求逆序对很像，他把每一个[x,x]范围上的节点视作一个桶，插入数据时，add(x,x,1)，删除一个时add(x,x,-1)。 //查询复杂度为O(logv)，v为值域 /*这里是动态开点线段树的核心代码*/ void insert(int v){//插入一个数 add(v,v,1); } void remove(int v){//删除一个数，相同的只删一个 add(v,v,-1); } int countL(int v){//计算小于v的数的个数 return query(L, v-1); } int countG(int v){//计算大于v的数的个数 return query(v+1, R); } int rank(int v){//求v的排名，即小于v的数的个数+1 return countL(v)+1; } int kth(int k, int p=1, int s=L, int t=R){//查询排名第k的数 if(s==t) return s; int mid = getMid(s,t); if(val(ls(p)) \u0026gt;= k) return kth(k, ls(p), s, mid); else return kth(k-val(ls(p)), rs(p), mid+1, t); } int pre(int v){//查询v的前驱，即第一个比v小的数，可能需要保证一定存在 int r = countL(v); return kth(r); } int suc(int v){//查询v的后继 int r = val(1) - countG(v) + 1; return kth(r); } 可持久化线段树 单点修改 //可持久化线段树，单点修改、区间查询，操作复杂度logn //luogu p3919 //可持久化线段树是完全可持久化的，意味着可以查询历史修改，以及对每一个历史状态都可以再修改 #include \u0026lt;iostream\u0026gt; using LL = long long; int const MAXV = 3e7+5; int const MAXN = 1e6+5; struct Node{ LL val; int ls, rs; }st[MAXV]; inline int\u0026amp; ls(int x){return st[x].ls;} inline int\u0026amp; rs(int x){return st[x].rs;} inline LL\u0026amp; val(int x){return st[x].val;} inline int getMid(int s, int t){ if(s+t==0) return 0; if(s+t\u0026gt;0) return (s+t)/2; return -((-s-t+1)/2); } int stcnt = 1; int L = 1, R = 1e6+5;//这里根据题目信息选择区间范围 LL arr[MAXN], roots[MAXN];//arr存初始数组，roots[i]表示第i次操作的根节点 void build(int s=L, int t=R, int p=1){ //一般不会完全动态开点，会把初始状态建树 if(s==t) val(p) = arr[s]; else{ ls(p) = ++stcnt, rs(p) = ++stcnt; int mid = getMid(s,t); build(s,mid,ls(p)); build(mid+1,t,rs(p)); val(p) = val(ls(p)) + val(rs(p)); } } void assign(int i, LL k, int p, int q, int s=L, int t=R){ //这里是单点修改操作，如果改成区间加，则下一行改成val(q)=val(p)+k //修改第i位为k，对版本x的根节点p进行修改，修改完为版本y的根节点q if(s==t) val(q) = k; else{ ls(q) = ls(p), rs(q) = rs(p); int mid = getMid(s,t); if(i\u0026lt;=mid) ls(q) = ++stcnt, assign(i,k,ls(p),ls(q),s,mid); else rs(q) = ++stcnt, assign(i,k,rs(p),rs(q),mid+1,t); val(q) = val(ls(q)) + val(rs(q)); } } LL query(int l, int r, int p, int s=L, int t=R){ //查询区间和 //对版本p查询 if(s\u0026gt;r || t\u0026lt;l) return 0; else if(s\u0026gt;=l \u0026amp;\u0026amp; t\u0026lt;=r) return val(p); else{ int mid = getMid(s,t); return query(l,r,ls(p),s,mid) + query(l,r,rs(p),mid+1,t); } } void solve(){ int m; std::cin\u0026gt;\u0026gt;R\u0026gt;\u0026gt;m; for(int i=L;i\u0026lt;=R;i++){ std::cin\u0026gt;\u0026gt;arr[i]; } build(); roots[0] = 1;//别忘了初始化初始区间的根 for(int t=1;t\u0026lt;=m;t++){ int v, o; std::cin\u0026gt;\u0026gt;v\u0026gt;\u0026gt;o;//v是对第v个版本操作 if(o==1){ int i;LL k; std::cin\u0026gt;\u0026gt;i\u0026gt;\u0026gt;k; roots[t] = ++stcnt;//本题的修改和查询都算一个版本 assign(i,k,roots[v],roots[t]); //注意你把第1个版本修改为第5个，不会对2、3、4版本产生影响 } else{ int i; std::cin\u0026gt;\u0026gt;i; roots[t] = roots[v];//虽然修改也算一个版本，但是可以和之前的合并 std::cout\u0026lt;\u0026lt;query(i,i,roots[v])\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } } } 区间修改 //可持久化线段树，区间修改、区间查询，操作复杂度logn //hdu 4348 #include \u0026lt;iostream\u0026gt; using LL = long long; int const MAXV = 3e6+5; int const MAXN = 1e5+5; struct Node{ LL val, tag; int ls, rs; }st[MAXV]; inline int\u0026amp; ls(int x){return st[x].ls;} inline int\u0026amp; rs(int x){return st[x].rs;} inline LL\u0026amp; val(int x){return st[x].val;} inline LL\u0026amp; tag(int x){return st[x].tag;} inline int getMid(int s, int t){ if(s+t==0) return 0; if(s+t\u0026gt;0) return (s+t)/2; return -((-s-t+1)/2); } int stcnt = 1; int L = 1, R = 1e6+5;//这里根据题目信息选择区间范围 LL arr[MAXN], roots[MAXN]; void build(int s=L, int t=R, int p=1){ if(s==t) val(p) = arr[s], tag(p) = 0; else{ ls(p) = ++stcnt, rs(p) = ++stcnt; int mid = getMid(s,t); build(s,mid,ls(p)); build(mid+1,t,rs(p)); val(p) = val(ls(p)) + val(rs(p)); } } void add(int l, int r, LL k, int p, int q, int s=L, int t=R){ //l,r是修改范围，其他同单点修改 ls(q) = ls(p), rs(q) = rs(p), tag(q) = tag(p); if(l\u0026lt;=s \u0026amp;\u0026amp; t\u0026lt;=r){ if(t\u0026gt;s) tag(q) += k; } else{ int mid = getMid(s,t); if(s\u0026lt;=r \u0026amp;\u0026amp; mid\u0026gt;=l) ls(q) = ++stcnt, add(l,r,k,ls(p),ls(q),s,mid); if(mid+1\u0026lt;=r \u0026amp;\u0026amp; t\u0026gt;=l) rs(q) = ++stcnt, add(l,r,k,rs(p),rs(q),mid+1,t); } val(q) = val(p) + (std::min(r,t)-std::max(l,s)+1)*k; } LL query(int l, int r, int p, LL tg=0, int s=L, int t=R){ //l,r是修改范围，tg是一种标记永久化的技术，其他同单点修改 if(s\u0026gt;r || t\u0026lt;l) return 0; else if(s\u0026gt;=l \u0026amp;\u0026amp; t\u0026lt;=r) return val(p) + tg*(t-s+1); else{ int mid = getMid(s,t); return query(l,r,ls(p),tg+tag(p),s,mid) + query(l,r,rs(p),tg+tag(p),mid+1,t); } } void solve(){ int m; std::cin\u0026gt;\u0026gt;m; for(int i=L;i\u0026lt;=R;i++){ std::cin\u0026gt;\u0026gt;arr[i]; } stcnt = 1; build(); roots[0] = 1; int time = 0;//本题只有加数才算进行一次版本修改 while(m--){ char o;int l,r;LL d; std::cin\u0026gt;\u0026gt;o; if(o==\u0026#39;C\u0026#39;){ std::cin\u0026gt;\u0026gt;l\u0026gt;\u0026gt;r\u0026gt;\u0026gt;d;//[l,r]上每个数+d time++; roots[time] = ++stcnt; add(l,r,d,roots[time-1],roots[time]); } else if(o==\u0026#39;Q\u0026#39;){ std::cin\u0026gt;\u0026gt;l\u0026gt;\u0026gt;r;//查询当前版本[l,r]和 std::cout\u0026lt;\u0026lt;query(l,r,roots[time])\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } else if(o==\u0026#39;H\u0026#39;){ std::cin\u0026gt;\u0026gt;l\u0026gt;\u0026gt;r\u0026gt;\u0026gt;d;//查询版本d的[l,r]和 std::cout\u0026lt;\u0026lt;query(l,r,roots[d])\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } else if(o==\u0026#39;B\u0026#39;){ std::cin\u0026gt;\u0026gt;d;//把版本倒回d，中间的版本失效 time = d; } } std::cout\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } signed main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); while(std::cin\u0026gt;\u0026gt;R){//本题多组数据 solve(); } return 0; } 主席树（可持久化权值线段树） //主席树，查询静态区间第k小，复杂度logn //luogu p3834 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; using LL = long long; int const MAXV = 8e6+5; int const MAXN = 2e5+5; struct Node{ LL val; int ls, rs; }st[MAXV]; inline int\u0026amp; ls(int x){return st[x].ls;} inline int\u0026amp; rs(int x){return st[x].rs;} inline LL\u0026amp; val(int x){return st[x].val;} inline int getMid(int s, int t){ //处理负数边界时，需要强行向下取整，而不是向零取整 if(s+t==0) return 0; if(s+t\u0026gt;0) return (s+t)/2; return -((-s-t+1)/2); } int stcnt = 1; int L = 1, R = 2e5+5; void build(int s=L, int t=R, int p=1){ //初始化建成全0的，因为主席树是权值线段树的可持久化版 val(p) = 0; if(s!=t){ ls(p) = ++stcnt, rs(p) = ++stcnt; int mid = getMid(s,t); build(s,mid,ls(p)); build(mid+1,t,rs(p)); } } void add(int i, LL k, int p, int q, int s=L, int t=R){ //参数同单点修改 if(s==t) val(q) = val(p) + k; else{ ls(q) = ls(p), rs(q) = rs(p); int mid = getMid(s,t); if(i\u0026lt;=mid) ls(q) = ++stcnt, add(i,k,ls(p),ls(q),s,mid); else rs(q) = ++stcnt, add(i,k,rs(p),rs(q),mid+1,t); val(q) = val(ls(q)) + val(rs(q)); } } int arr[MAXN], disc[MAXN], assi[MAXN],ori[MAXN]; //arr是输入的原数组，disc是离散化后的，assi是临时的辅助数组 //ori[i]代表着在arr里排名为i的数 int roots[MAXN]; int kth(int k, int p, int q, int s=L, int t=R){ if(s==t) return ori[s]; int mid = getMid(s,t); if(val(ls(q)) - val(ls(p))\u0026gt;=k){ return kth(k, ls(p), ls(q), s, mid); } else{ return kth(k-(val(ls(q))-val(ls(p))), rs(p), rs(q), mid+1, t); } } int lrkth(int l, int r, int k){ //查询数组arr的[l,r]区间中第k小的数 return kth(k,roots[l-1],roots[r]); } void solve(){ int m; std::cin\u0026gt;\u0026gt;R\u0026gt;\u0026gt;m; for(int i=L;i\u0026lt;=R;i++){ std::cin\u0026gt;\u0026gt;arr[i]; disc[i] = assi[i] = arr[i]; } std::sort(assi+L,assi+R+1); int last = std::unique(assi+L,assi+R+1) - (assi+L); for(int i=L;i\u0026lt;=R;i++){ disc[i] = std::lower_bound(assi+L,assi+last,disc[i]) - (assi+L)+1; ori[disc[i]] = arr[i]; } //这上面都是离散化和数据输入 build(); roots[0] = 1; for(int i=L;i\u0026lt;=R;i++){ roots[i] = ++stcnt; add(disc[i],1,roots[i-1],roots[i]); //和权值线段树的思路一致 } while(m--){ int l,r,k; std::cin\u0026gt;\u0026gt;l\u0026gt;\u0026gt;r\u0026gt;\u0026gt;k; std::cout\u0026lt;\u0026lt;lrkth(l,r,k)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } } 线段树合并 //线段树合并，合并复杂度大概是O(klogN)，N是值域，k是若干线段树一共进行过k次插入 //luogu p3224 //动态开点线段树，之前的各种操作中都有p=1这一参数默认值，这其实是根节点的意思。也就是如果我们设置不同的p，可以开多颗线段树。 //线段树合并就是把重合位置的节点的值加起来，对于没有重合位置的节点则原地保留，常常用于权值线段树 int merge(int p, int q, int s=L, int t=R){ //不新开空间的合并方式 //把q为根的树合并到p为根的树上，返回p，即新根节点 //由于各题不一样，所以要在合并后手动把roots[j]指定为p if(!p||!q) return p+q; if(s==t) return val(p)+=val(q), p; int mid = getMid(s,t); ls(p) = merge(ls(p), ls(q), s, mid); rs(p) = merge(rs(p), rs(q), mid+1, t); val(p) = val(ls(p)) + val(rs(p)); return p; } int merge(int p, int q, int s=L, int t=R){ //新开空间的合并方式 //把p,q为根的两棵树合并到r为根的树上，返回r，即新根节点 //由于各题不一样，所以要在合并后手动把roots[i]和[j]指定为r if(!p||!q) return p+q; int r = ++stcnt; if(s==t) return val(r) = val(p)+val(q), r; int mid = getMid(s,t); ls(r) = merge(ls(p), ls(q), s, mid); rs(r) = merge(rs(p), rs(q), mid+1, t); val(r) = val(ls(r)) + val(rs(r)); return r; } 珂朵莉树 //珂朵莉树，区间推平问题 //方便给某个区间赋值，区间加数，维护区间第k大值，区间和等等 //数据随机的情况下，复杂度为nloglogn //珂朵莉树的每一个节点都是一个区间，这个区间内的值相同。 //cf896c struct Node{ int l,r; mutable LL v;//这里修改成自己需要的数据类型，在[l,r]内都等于这个值 Node(int l, int r, LL v):l(l),r(r),v(v){} bool operator\u0026lt;(Node const \u0026amp; x) const {return l\u0026lt;x.l;} }; class ODT{ public: std::set\u0026lt;Node\u0026gt; tree; auto split(int pos){ auto it = tree.lower_bound(Node(pos,0,0)); if(it!=tree.end() \u0026amp;\u0026amp; it-\u0026gt;l==pos) return it; it--; int l = it-\u0026gt;l, r = it-\u0026gt;r; LL v = it-\u0026gt;v; tree.erase(it); tree.insert(Node(l,pos-1,v)); return tree.insert(Node(pos,r,v)).first; } void assign(int l, int r, int v){ //给区间赋值 auto end = split(r+1), begin = split(l);//必须要注意顺序 tree.erase(begin,end); tree.insert(Node(l,r,v)); } void perf(int l, int r){//其他操作的模板函数 auto end = split(r+1), begin = split(l); for(auto it=begin;it!=end;it++){ //这里是操作 //这些操作都很暴力，例如k大值，就把区间全部枚举排序一遍去找 //例如区间和，就枚举区间加起来，注意是加it-\u0026gt;v * (it-\u0026gt;r-it-\u0026gt;l+1) //例如区间加数，就枚举区间给所有的it-\u0026gt;v都加一个数 } } }; //珂朵莉树的初始化不能用assign，设范围为[1,w]，初值全部为0，则 ODT odt; odt.tree.insert(Node(1,w,0)); 分块 分块是根号算法，比线段树略差，但是不需要满足结合律，也不需要传递tag。\n//luogu p3372 和线段树区间加，维护区间和一样 //复杂度n sqrt(n) //在块内时对块操作，跨块时中间对块操作，两边多余部分暴力处理 LL arr[MAXN]; class BA{ public: int st[MAXN],ed[MAXN],size[MAXN],bel[MAXN];//每一段的开始下标、结束下标、段大小；每个元素属于哪个段 int sq; LL sum[MAXN];//保存第i个块的和 LL tag[MAXN]; void init(int n){ sq = std::sqrt(n); for(int i=1;i\u0026lt;=sq;i++){ st[i] = n / sq * (i-1) + 1; ed[i] = n / sq * i; size[i] = ed[i] - st[i] + 1; } ed[sq] = n;//最后一段可能长度不够n/sq size[sq] = ed[sq] - st[sq] + 1; for(int i=1;i\u0026lt;=sq;i++) for(int j=st[i];j\u0026lt;=ed[i];j++) bel[j] = i, sum[i] += arr[j]; } void update(int l, int r, LL k){ if(bel[l]==bel[r]){ for(int i=l;i\u0026lt;=r;i++){ arr[i]+=k; sum[bel[i]] += k; } return; } for(int i=l;i\u0026lt;=ed[bel[l]];i++){ arr[i]+=k; sum[bel[i]]+=k; } for(int i=st[bel[r]];i\u0026lt;=r;i++){ arr[i]+=k; sum[bel[i]]+=k; } for(int i=bel[l]+1;i\u0026lt;bel[r];i++){ tag[i] += k; } } LL query(int l, int r){ LL ret = 0; if(bel[l]==bel[r]){ for(int i=l;i\u0026lt;=r;i++) ret += arr[i] + tag[bel[i]]; return ret; } for(int i=l;i\u0026lt;=ed[bel[l]];i++) ret += arr[i] + tag[bel[i]]; for(int i=st[bel[r]];i\u0026lt;=r;i++) ret += arr[i] + tag[bel[i]]; for(int i=bel[l]+1;i\u0026lt;bel[r];i++) ret += sum[i] + tag[i] * size[i]; return ret; } }; BA ba;//注意，开了大数组，要声明在main函数外面，或者可以去用动态分配内存 平衡树（pbds实现） 平衡树在ACM中用的极少，就不手搓了，大部分情况下都可以用set和pbds搞定。\n#include\u0026lt;ext/pb_ds/assoc_container.hpp\u0026gt; #include\u0026lt;ext/pb_ds/tree_policy.hpp\u0026gt; //仅限g++可以使用 namespace pbds = __gnu_pbds; pbds::tree\u0026lt;LL, pbds::null_type, std::less\u0026lt;LL\u0026gt;, pbds::rb_tree_tag, pbds::tree_order_statistics_node_update\u0026gt; tr; 声明如上，还是挺复杂的，但是ACM可以带资料所以不成问题。需要注意只能在g++上用，ACM赛场大多都有g++所以不是问题。\n模板参数解释\nLL是存储数据的类型；\npbds::null_type是映射规则（低版本g++为pbds::null_mapped_type，如果存入类型为std::map\u0026lt;Key,Value\u0026gt;则要填入Value）；\nstd::less\u0026lt;LL\u0026gt;则是我们选择大根还是小根；可选参数，默认为less\npbds::rb_tree_tag 则是我们选择的树的类型。总共有三种平衡树在pbds里，红黑树、splay、ov，但是后两个容易超时，一般不用。可选参数，默认为红黑树\npbds::tree_order_statistics_node_update是节点更新方法，如果使用order_of_key和find_by_key方法，则要用它。可选参数，但默认是null_node_update。\n方法\ntr.insert(x); //插入一个元素x，返回std::pair\u0026lt;point_iterator, bool\u0026gt; //若成功，则是插入之后的迭代器和true，否则是x的迭代器和false tr.erase(x); //成功返回true，也可以把迭代器作为参数 tr.order_of_key(x); //返回x的排名，0为第一名，x不一定要在树里 tr.find_by_order(k); //返回排名为k的元素的迭代器，0为第一名 tr.lower_bound(x); //返回迭代器，这个函数不用多说了吧，和经常见到的一样 tr.upper_bound(x); //返回迭代器 tr.join(b); //将b树并入当前树，两棵树的类型要一样，不能有重复元素，b树将会被删除 tr.split(x,b); //小于等于x的保留在当前树，其他分给b树 tr.empty(); tr.size(); 以上操作均为O(logn)复杂度，除了最后两个是O(1)\n注意事项\ntree里面的元素是唯一的，有点类似与set。但我们并没有multi-tree去使用，做例如洛谷上的平衡树模板题，他要求元素可重复。此时我们有以下奇技淫巧\nLL n; std::cin\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ int ope; LL x; std::cin\u0026gt;\u0026gt;ope\u0026gt;\u0026gt;x; if(ope==1) tr.insert((x\u0026lt;\u0026lt;20)+i); else if(ope==2) tr.erase(tr.lower_bound(x\u0026lt;\u0026lt;20)); else if(ope==3) std::cout\u0026lt;\u0026lt;tr.order_of_key(x\u0026lt;\u0026lt;20)+1\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; else if(ope==4) std::cout\u0026lt;\u0026lt;((*tr.find_by_order(x-1))\u0026gt;\u0026gt;20)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; else if(ope==5){ auto it = tr.lower_bound(x\u0026lt;\u0026lt;20); it--; std::cout\u0026lt;\u0026lt;((*it)\u0026gt;\u0026gt;20)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } else{ auto it = tr.upper_bound((x\u0026lt;\u0026lt;20)+n); std::cout\u0026lt;\u0026lt;((*it)\u0026gt;\u0026gt;20)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } } 假设有\\(n\\)个操作，共\\(6\\)种\n插入\\(x\\) 删除\\(x\\) 查询\\(x\\)的排名（比\\(x\\)小的数的个数\\(+1\\)） 查询排名为\\(x\\)的数 求小于\\(x\\)的最大的数 求大于\\(x\\)的最小的数 看代码，我们将\\(x\\)左移20位，加上了操作序号，这样我们就可以实现可重复插入。只需要我们再最后把数字右移20位回来即可。erase注意是加入迭代器去erase，因为我们并没有等于x\u0026lt;\u0026lt;20的数字。最后一个操作，要\\(+n\\)，来处理所有的相等的\\(x\\)\n01字典树 //01字典树，复杂度线性 //HDU4825 int const MAXN = 3500005; int const MAXBIT = 35;//注意题目给的数据范围，这里2^32以下可以处理 class Trie{ public: int nxt[MAXN][2]; int cnt; LL num[MAXN]; void init(){ for(int i=0;i\u0026lt;=cnt;i++) for(int j=0;j\u0026lt;2;j++) nxt[i][j] = 0; for(int i=0;i\u0026lt;=cnt;i++) num[i] = 0; cnt = 0; } void insert(LL n){ //插入一个自然数 int cur = 0; for(LL i=MAXBIT;i\u0026gt;=0;i--){ LL bit = (n\u0026gt;\u0026gt;i)\u0026amp;1; if(!nxt[cur][bit]){ nxt[cur][bit] = ++cnt; } cur = nxt[cur][bit]; } num[cur] = n; } LL find_max(LL x){ //查询x与数组内的所有数的异或的最大值 int cur=0; for(int i=MAXBIT;i\u0026gt;=0;i--){ LL bit = (x\u0026gt;\u0026gt;i)\u0026amp;1; if(nxt[cur][bit^1])//尽量走与当前位不同的路径，最小值应改为走相同的 cur = nxt[cur][bit^1]; else cur = nxt[cur][bit]; } return x^num[cur]; } }; Trie trie; 可以通过01Trie来计算连续区间的异或最大值。要用到一个性质：\n\\[a\\oplus b\\oplus b = a \\]\n也就是说，我们可以把异或前缀全部插入到Trie里，然后以第i个数为结尾的区间的最大异或值就是find_max(pre[i])。注意特殊处理长度为1的区间。\nLL ans = 0; arr[0] = 0; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;arr[i]; ans = std::max(ans,arr[i]); arr[i] ^= arr[i-1]; } trie.insert(0);//注意要先插入一个0 for(int i=1;i\u0026lt;=n;i++){ ans = std::max(ans,trie.find_max(arr[i])); trie.insert(arr[i]); } std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; 对顶堆 //动态维护一个集合的第k大数，每次操作logn //spoj RMID2 //维护第k小只要维护第n-k大即可 //另外这个k是可以变化的，不需要固定，复杂度确实是logn #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; #include \u0026lt;vector\u0026gt; template\u0026lt;typename T\u0026gt; class KthLargest{ private: std::priority_queue\u0026lt;T,std::vector\u0026lt;T\u0026gt;,std::less\u0026lt;T\u0026gt; \u0026gt; big{}; std::priority_queue\u0026lt;T,std::vector\u0026lt;T\u0026gt;,std::greater\u0026lt;T\u0026gt; \u0026gt; small{}; size_t kth{}; size_t size{}; void update(){ kth = std::min(kth,size); while(kth\u0026lt;small.size()){ big.push(small.top()); small.pop(); } while(kth\u0026gt;small.size()){ small.push(big.top()); big.pop(); } } public: KthLargest():kth(1),size(0){} T findK(size_t k){ //找到第k大的数字 kth = k; update(); return small.top(); } void eraseK(size_t k){ //移除第k大的数字 kth = k; update(); small.pop(); size--; update(); } void insert(T x){ //插入一个数字 size++; if(small.empty() || x\u0026gt;=small.top()){ small.push(x); } else{ big.push(x); } update(); } size_t getSize(){ return size; } }; KthLargest\u0026lt;int\u0026gt; ddd; 单调栈 //单调栈 luogu p5788 //本题定义f[i]为数列中第i个元素之后第一个大于a[i]的元素的下标（不存在则为0） //很显然我们可以维护一个单调不增的栈 //当push的元素x大于栈顶t时，第一个大于t的元素就是x。反复出栈直到栈顶t小于等于x或栈空，入栈。 //复杂度 n int arr[MAXN]; int ans[MAXN]; int stk[MAXN]; int main(){ int n; std::cin\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;arr[i]; } int top = 0; for(int i=1;i\u0026lt;=n;i++){ while(top\u0026amp;\u0026amp;arr[stk[top]]\u0026lt;arr[i]){ ans[stk[top]] = i;//这一行是具体的操作，因题而异；而其他行在这个for循环里都是固定的 top--; } stk[++top] = i; } for(int i=1;i\u0026lt;=n;i++){ std::cout\u0026lt;\u0026lt;ans[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } return 0; } 单调队列 //单调队列，luogu1886 //本题是滑动窗口，即在长度为n的数组中，给出一个长度为k的连续区间，从左向右滑动，求每个区间中的最大值和最小值 //求最小值时，我们可以维护一个单增的双端队列。x加入队尾时，如果队尾元素b\u0026gt;=x，则把队尾弹出，直到b\u0026lt;x或者栈空时把x入队。 //因为我们的区间长度有限，每次我们的区间左端点向右枚举+1时，判断队首元素的下标，如果小于区间左端点，就出队。 //之后留在队首的元素就是区间最小值 //具体可见代码。最大值维护同理。 //复杂度n int arr[MAXN]; int main(){ int n,k; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;k; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;arr[i]; } std::deque\u0026lt;int\u0026gt; dq; for(int i=1;i\u0026lt;k;i++){ while(!dq.empty()\u0026amp;\u0026amp;arr[dq.back()]\u0026gt;=arr[i]) dq.pop_back(); dq.push_back(i); } for(int i=k;i\u0026lt;=n;i++){ while(!dq.empty()\u0026amp;\u0026amp;arr[dq.back()]\u0026gt;=arr[i]) dq.pop_back(); dq.push_back(i); while(dq.front()\u0026lt;=i-k) dq.pop_front(); std::cout\u0026lt;\u0026lt;arr[dq.front()]\u0026lt;\u0026lt;\u0026#34; \u0026#34;;//输出最小值 } std::cout\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; dq.clear(); for(int i=1;i\u0026lt;k;i++){ while(!dq.empty()\u0026amp;\u0026amp;arr[dq.back()]\u0026lt;=arr[i]) dq.pop_back(); dq.push_back(i); } for(int i=k;i\u0026lt;=n;i++){ while(!dq.empty()\u0026amp;\u0026amp;arr[dq.back()]\u0026lt;=arr[i]) dq.pop_back(); dq.push_back(i); while(dq.front()\u0026lt;=i-k) dq.pop_front(); std::cout\u0026lt;\u0026lt;arr[dq.front()]\u0026lt;\u0026lt;\u0026#34; \u0026#34;;//输出最大值 } return 0; } ST表 对于经典的RMQ（即给定一个数组，求区间内的最大值）问题，有如下代码\n//复杂度 单次查询 logn 预处理 nlogn //luogu P3865 //查询区间最大值 //也可以查询其他可重复贡献问题的信息 //可重复贡献指对于运算op，满足x op x = x。这样的运算有最大最小、gcd等。但显然求和不是。 //另外op还必须满足结合律。 #include \u0026lt;cstdio\u0026gt; #include \u0026lt;iostream\u0026gt; const int MAXN = 100005; const int LOGN = 21; int fmax[MAXN][LOGN+1]; //fmax[a][b]表示[a,a+2^b-1]中的最大值 int logn[MAXN]; //预先计算logn int main(){ int n,m; //数组大小以及查询次数 scanf(\u0026#34;%d%d\u0026#34;,\u0026amp;n,\u0026amp;m); for(int i=1;i\u0026lt;=n;i++){ scanf(\u0026#34;%d\u0026#34;,\u0026amp;fmax[i][0]); } logn[1] = 0; logn[2] = 1; for(int i=3;i\u0026lt;MAXN;i++){ logn[i] = logn[i/2]+1; //预先计算logn } for(int j=1;j\u0026lt;=LOGN;j++){ for(int i=1;i+(1\u0026lt;\u0026lt;j)-1\u0026lt;=n;i++){ fmax[i][j] = std::max(fmax[i][j-1],fmax[i+(1\u0026lt;\u0026lt;(j-1))][j-1]); } } for(int i=1;i\u0026lt;=m;i++){ int a,b; scanf(\u0026#34;%d%d\u0026#34;,\u0026amp;a,\u0026amp;b); //查询[a,b]分为两部分，即[a,a+2^s-1]与[b-2^s+1,b] //完全不用担心这两个范围重叠，因为是求max int s = logn[b-a+1]; printf(\u0026#34;%d\\n\u0026#34;,std::max(fmax[a][s],fmax[b-(1\u0026lt;\u0026lt;s)+1][s])); } return 0; } 二分 二分答案 给出一个通用代码\nint l = 0; int r = MAXR; while(l+1\u0026lt;r){ int mid = (l+r)\u0026gt;\u0026gt;1; if(judge(mid)) l=mid; else r = mid; } if(judge(l)) std::cout\u0026lt;\u0026lt;l\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; else std::cout\u0026lt;\u0026lt;r\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; 当验证一个情况是否能满足题目的复杂度小于等于\\(O(n)\\)，而且这些情况具有单调性（即例如若x\u0026gt;y，x不能满足，则y一定不能满足）时，就可以通过二分去得到最符合题意的答案。二分这些情况的复杂度为\\(O(\\log n)\\)，再乘上验证情况的复杂度得到总的复杂度。\njudge函数应该根据题意写出。\n如果是浮点数的二分，则不推荐使用EPS进行精度判断（有可能会丢精度）。而是使用计数器，一般迭代100次就能保证符合题目要求。\n二分查找 通常是在排好序上的数组中，查找第一个大于（或大于等于）x的元素。见STL用法中的lower_bound和upper_bound。每次查找的复杂度是logn\n二分求单调函数零点 设函数\\(f\\)在\\([l,r]\\)上严格单调，\\(mid=(l+r)/2\\)，显然有\\(f(l)f(r)\u003c0\\)。迭代中，若\\(f(l)f(mid)\u003c0\\)，则\\(r=mid\\)，否则\\(l=mid\\)。直到\\(f(mid)=0\\)或者\\(r-l\u003c EPS\\)或者迭代次数达到要求。收敛速度是线性收敛。\n三分法 三分法求单峰函数的极值点 用二分求函数的导数的零点也可以，但是并不是每次都可以方便的求出导数。三分法可以不用求出导数。\n设函数\\(f\\)在\\([l,r]\\)上单峰，意味着有且只有一个极大值\\(x\\)，\\(f\\)在\\([l,x]\\)上严格单增，在\\([x,r]\\)上严格单减。单谷函数则为极小值\\(x\\)。\n//三分法求单峰函数的极值点 luogu p3382 //收敛速度是线性收敛 //用二分求函数的导数的零点也可以，但是并不是每次都可以方便的求出导数。三分法可以不用求出导数。 //设函数f在[l,r]上单峰，意味着有且只有一个极大值x，f在[l,x]上严格单增，在[x,r]上严格单减。单谷函数则为极小值x。 //在[l,r]上取两个不等的点，设靠近l的是l1，靠近r的是r1。如果f(l1)\u0026lt;f(r1)，说明极大值一定在[l1,r]，令l=l1 //如果f(l1)\u0026gt;f(r1)，极大值一定在[l,r1]，令r=r1 //持续下去直到r-l\u0026lt;EPS或者迭代次数足够 //取l1和r1时，可以直接取三等分点，也可以取黄金分割点(l1=l+(r-l)(1-0.618),r1=r-(r-l)*(1-0.618)) //还可以让l1=mid-EPS, r1=mid-EPS，但是要令l=mid而不是l=l1，防止死循环 using DB = double; DB const EPS = 1e-8; DB l,r; std::cin\u0026gt;\u0026gt;l\u0026gt;\u0026gt;r; while(r-l\u0026gt;EPS){ DB mid = (l+r)/2; DB f1 = func(mid-EPS), f2 = func(mid+EPS);//func根据题目要求定义，是一元函数 if(f1\u0026lt;f2) l = mid; else r = mid; } 三分套三分 例如Luogu P2571，这是一个二元函数要求最小值。我们发现这个函数在固定\\(x\\)的时候\\(y\\)是单谷的，固定\\(y\\)的时候\\(x\\)是单谷的。所以我们可以先三分一个变量，再固定这个变量三分另一个变量，最后得出答案。\n注意，三分套三分是指不能先假设一个\\(y\\)的定值，再三分\\(x\\)，然后拿着计算出的\\(x\\)再去三分\\(y\\)。应当在三分\\(x\\)的过程中，把\\(x\\)当作参数，传入三分\\(y\\)的函数中。它们不是先后关系，而是嵌套关系。\nauto func = [\u0026amp;](DB x, DB y){ //这里是函数定义 }; auto sfy = [\u0026amp;](DB x){//固定x，三分y DB ret = 0.0; DB l = 0.0, r = 1.0; while(r-l\u0026gt;EPS){ DB delta = (r-l)/3.0; DB f1 = func(x,l+delta), f2 = func(x,r-delta); if(f1\u0026gt;f2) l = l+delta; else r = r-delta; } return func(x,l); }; DB l=0.0,r=1.0; while(r-l\u0026gt;EPS){//三分x DB delta = (r-l)/3.0; DB f1 = sfy(l+delta), f2 = sfy(r-delta); if(f1\u0026gt;f2) l = l+delta; else r = r-delta; } //最后的答案是sfy(l) 三分答案 TODO 动态规划 01背包 //复杂度 nW //luogu P1048 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cmath\u0026gt; int const MAXN = 1005; using namespace std; int dp[MAXN]; int w[MAXN]; int v[MAXN]; int main(){ int n,W;//物品数，背包大小 cin\u0026gt;\u0026gt;W\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ cin\u0026gt;\u0026gt;w[i]\u0026gt;\u0026gt;v[i];//物品体积，物品价值 } for(int i=1;i\u0026lt;=n;i++){ for(int j=W;j\u0026gt;=w[i];j--){ dp[j] = std::max(dp[j],dp[j-w[i]]+v[i]); } } cout\u0026lt;\u0026lt;dp[W]\u0026lt;\u0026lt;endl; return 0; } 完全背包 //复杂度 nW //luogu P1616 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cmath\u0026gt; int const MAXN = 10007; int const MAXW = 10000007; typedef long long LL; using namespace std; LL dp[MAXW]; int w[MAXN]; int v[MAXN]; int main(){ int n,W;//物品数，背包大小 cin\u0026gt;\u0026gt;W\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ cin\u0026gt;\u0026gt;w[i]\u0026gt;\u0026gt;v[i];//物品体积，物品价值 } for(int i=1;i\u0026lt;=n;i++){ for(int j=w[i];j\u0026lt;=W;j++){ dp[j] = std::max(dp[j],dp[j-w[i]]+v[i]); } } cout\u0026lt;\u0026lt;dp[W]\u0026lt;\u0026lt;endl; return 0; } 多重背包 //复杂度 Wsum(logk_i) //luogu P1776 //即每种物品有ki个 //我们可以简单转化为01背包，但是复杂度太高；采用二进制分组的思想 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cmath\u0026gt; int const MAXN = 100007; int const MAXW = 40007; typedef long long LL; using namespace std; LL dp[MAXW]; int w[MAXN]; int v[MAXN]; int main(){ int m,W;//物品种类数，背包大小 cin\u0026gt;\u0026gt;m\u0026gt;\u0026gt;W; int n = 0; for(int i=1;i\u0026lt;=m;i++){ int c = 1; int p,h,k;//物品价值，物品体积，物品数量 cin\u0026gt;\u0026gt;p\u0026gt;\u0026gt;h\u0026gt;\u0026gt;k; while(k\u0026gt;c){ k -= c; v[++n] = c*p; w[n] = c*h; c *= 2; } v[++n] = p*k; w[n] = h*k; } for(int i=1;i\u0026lt;=n;i++){ for(int j=W;j\u0026gt;=w[i];j--){ dp[j] = std::max(dp[j],dp[j-w[i]]+v[i]); } } cout\u0026lt;\u0026lt;dp[W]\u0026lt;\u0026lt;endl; return 0; } 分组背包 //分组背包 复杂度=组数*背包容量*组内个数最大值 //luogu p1757 //有g个组，每组物品有group[i].size()个，每个物品有价值v和体积w，总共n个物品，背包体积为m。每个组最多只能拿一个物品出来，求最大价值。 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; int const MAXN = 1005; int dp[MAXN]; std::vector\u0026lt;int\u0026gt; group[MAXN];//存储每一组的物品序号 int v[MAXN],w[MAXN];//物品价值和体积 void solve(){ int n,m; std::cin\u0026gt;\u0026gt;m\u0026gt;\u0026gt;n;//背包容量;n件物品 for(int i=1;i\u0026lt;=n;i++){ int a,b,c; std::cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b\u0026gt;\u0026gt;c; w[i] = a, v[i] = b,group[c].push_back(i); } int const g = 100;//本题中只说了有g个组，没有给出具体有多少个以及是否连续，采取遍历的方法 for(int i=1;i\u0026lt;=g;i++){ if(group[i].size()==0) continue; for(int j=m;j\u0026gt;=0;j--){ for(auto k:group[i]){//注意这三个循环的顺序不能改变 if(j\u0026gt;=w[k]) dp[j] = std::max(dp[j], dp[j-w[k]]+v[k]); } } } std::cout\u0026lt;\u0026lt;dp[m]\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int T; T=1; while(T--){ solve(); } return 0; } 最长上升子序列 //最长上升子序列 复杂度nlogn //luogu B3637 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cstring\u0026gt; const int MAXN = 100005; int arr[MAXN]; int dp[MAXN]; //dp[i]表示长度为i的上升子序列的最后一个元素的最小值 //例如1 2 5 3 4 1。 //最开始dp[1]=1，arr[2]=2\u0026gt;dp[1]，所以插入dp[2]=2;arr[3]同理，得到dp={1,2,5};到arr[4]=3时，我们找到第一个大于等于3的元素，即dp[3]，替换他，得到dp={1,2,3};接下来到arr[5]=4，现在4\u0026gt;3，可以插入末尾得到dp={1,2,3,4}，显然我们刚刚的操作把5换成3，让后面的数更有可能直接加入到数组末尾了。最后arr[6]=1，由于我们求的是最长上升子序列，而不是最长不下降，所以替换不影响。 //注意dp里面的数字并不是最长的序列，例如我们加一个0进去，dp={0,2,3,4}，但是0是在最后的，不存在0,2,3,4这个序列。我们只能计算长度。 int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n; std::cin\u0026gt;\u0026gt;n; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;arr[i]; } std::memset(dp,0x3f,sizeof(dp)); int maxv = dp[0]; for(int i=1;i\u0026lt;=n;i++){ *std::lower_bound(dp,dp+n,arr[i]) = arr[i]; //换成最长不下降子序列时，用upper_bound } int ans = 0; while(dp[ans]!=maxv) ans++; std::cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } Dilworth定理 把一个序列分为若干不上升子序列，其序列总数的最小值等于最长上升子序列的长度\n最长公共子序列 //最长公共子序列，复杂度nm //hdu 1159 //luogu p1439因为是排列，可以转化为LIS问题，复杂度是nlogn。但hdu1159没有这种性质，复杂度到不了nlogn #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;string\u0026gt; #define MAXN 505 int dp[MAXN][MAXN]; int lcs(std::string const \u0026amp; s1, std::string const \u0026amp; s2){ int n1=s1.size(),n2=s2.size(); std::memset(dp,0,sizeof(dp)); for(int i=1;i\u0026lt;=n1;i++){ for(int j=1;j\u0026lt;=n2;j++){ if(s1[i-1]==s2[j-1]) dp[i][j] = dp[i-1][j-1]+1; else dp[i][j] = std::max(dp[i][j-1],dp[i-1][j]); } } return dp[n1][n2]; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); std::string s1,s2; while(std::cin\u0026gt;\u0026gt;s1\u0026gt;\u0026gt;s2){ std::cout\u0026lt;\u0026lt;lcs(s1,s2)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } 最大子段和 //luogu P1115 //复杂度 n //求一个数组里面最大连续子段的和，可以为空，此时和为0 //如果要保证非空，则可以在外部加一条 //ans = std::max(ans, arr[i]); //并且如果每个数都是负数，则直接输出最大的负数。 LL calc(std::vector\u0026lt;LL\u0026gt; const \u0026amp; vec){ LL ret=0; LL cur=0; for(int i=0;i\u0026lt;vec.size();i++){ cur += vec[i]; if(cur\u0026lt;0) cur = 0; ret = std::max(ret, cur); } return ret; } 斜率优化TODO 四边形不等式TODO 悬线法 //luogu p1387 //悬线法求符合条件的最大矩形/正方形，复杂度 nm int grid[MAXN][MAXN]; int l[MAXN][MAXN], r[MAXN][MAXN], u[MAXN][MAXN]; //l,r分别表示从当前格向上的悬线最多能向左向右扩展多少格（含自己） //u表示当前格向上能扩展多少格（含自己），即悬线 void dp(int n, int m){ for(int i=1;i\u0026lt;=n;i++){ for(int j=1;j\u0026lt;=m;j++){ if(grid[i][j]) l[i][j] = l[i][j-1]+1;//若(i,j-1)可选，当然首先要(i,j)可选，(i,j-1)不可选时l[i][j-1]会等于0，l[i][j]就会等于1 //这里的if条件看情况选择，下面同理 } } for(int i=1;i\u0026lt;=n;i++){ for(int j=m;j\u0026gt;=1;j--){ if(grid[i][j]) r[i][j] = r[i][j+1]+1;//若(i,j+1)可选 } } for(int i=1;i\u0026lt;=n;i++){ for(int j=1;j\u0026lt;=m;j++){ if(grid[i][j]){ u[i][j] = u[i-1][j]+1; if(grid[i-1][j]){//若(i-1,j)可选 l[i][j] = std::min(l[i][j], l[i-1][j]); r[i][j] = std::min(r[i][j], r[i-1][j]); } //然后在这里对ans进行该有的操作，因题而异 //对于(i,j)这一格来说，它对应的悬线向左右拓展能得到的最大矩形面积为 //u[i][j]*(l[i][j]+r[i][j]-1) //最大正方形为 //min(u[i][j],l[i][j]+r[i][j]-1)的平方 } } } } 数位DP 数位DP是对有多少数符合特性的计数问题。通常他的题目数据范围会很大，比如\\(10^{18}\\)。题目通常也会要求我们的数字要在某个范围内，还有可能会要求符合题意的一对、一组数。\n我们通常会用记忆化搜索来实现。\n//数位dp模板题，常用记忆化搜索实现 //hdu 2089 //本题要求，[n,m]之间的所有整数，不含4，不含62（连续的）的数字有多少个 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;cmath\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;vector\u0026gt; #define pb push_back std::vector\u0026lt;int\u0026gt; digit;//用于存储getSum中x的每一位，最高位从0下标开始 int dp[8][12][2];//dp[pos][last][limit] //pos代表搜索到第几位，如五位数，pos==0说明搜索到高位第一位，pos==4说明搜索到个位 //last代表上一位搜索的数字是多少，如果last==11，10这样的数字则代表目前在搜索pos==0。设置为11还是10还是别的什么要看题目对只有一位数时的要求 //limit代表本位数字的取值有没有限制，例如上限是12345，现在搜到了12???，要搜第三位，显然第三位只能取0,1,2,3，limit==true。又如搜到了11???，第三位就可以取0-9，limit==false。 //limit==true当且仅当上一位limit也为true且取得最大值（第一位特判） int dfs(int pos, int last, bool limit){ int ret = 0; if(pos==digit.size()) return 1;//搜索终点，由于不是非法状态所以返回1 if(dp[pos][last][limit] != -1) return dp[pos][last][limit]; for(int v=0;v\u0026lt;=(limit ? digit[pos] : 9);v++){ if((last==6 \u0026amp;\u0026amp; v==2) || v==4) continue;//非法状态 ret += dfs(pos+1, v, limit \u0026amp;\u0026amp; v==digit[pos]); } dp[pos][last][limit] = ret; return ret; } int getSum(int x){ digit.clear(); std::memset(dp,-1,sizeof(dp)); while(x){//注意如果某些题0也在范围内要特判 digit.pb(x%10); x/=10; } std::reverse(digit.begin(),digit.end());//高位到低位存 return dfs(0,10,true); } void solve(int n, int m){ std::cout\u0026lt;\u0026lt;getSum(m)-getSum(n-1)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n,m; while(std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m){ if(n==0 \u0026amp;\u0026amp; m==0) break; solve(n,m); } return 0; } 下面再给出一例，求一对数字的、与位运算有关的，拆分成二进制的题。\n//数位dp另一例 //atcoder abc317_f //本题给定n,a1,a2,a3。要求求三元组\u0026lt;x1,x2,x3\u0026gt;的个数，满足 //1. 1\u0026lt;=xi\u0026lt;=n，对所有i //2. xi是ai的任意倍数，对所有i //3. x1^x2^x3=0 //其中n取值[1,1e18] //ai取值[1,10] #define pb push_back using LL = long long; LL const MOD = 998244353; std::vector\u0026lt;int\u0026gt; digit; int dp[80][12][12][12][2][2][2][2][2][2]; int a1,a2,a3; int dfs(int pos, int r1, int r2, int r3, bool l1, bool l2, bool l3, bool z1, bool z2, bool z3){ //分布代表着，pos位数字，上一位搜索到的x1除以a1的余数,...,x1的limit,...,x1是否前面全是前导0 int ret = 0; if(pos==-1){ return !z1 \u0026amp;\u0026amp; !z2 \u0026amp;\u0026amp; !z3 \u0026amp;\u0026amp; !r1 \u0026amp;\u0026amp; !r2 \u0026amp;\u0026amp; !r3; //每个数都没有前导零（即填入了至少一个数字），以及余数都是0（即xi已经是ai的倍数了） } if(dp[pos][r1][r2][r3][l1][l2][l3][z1][z2][z3] != -1) return dp[pos][r1][r2][r3][l1][l2][l3][z1][z2][z3]; int m1 = l1 ? digit[pos] : 1; int m2 = l2 ? digit[pos] : 1; int m3 = l3 ? digit[pos] : 1; for(LL i=0;i\u0026lt;=m1;i++){ for(LL j=0;j\u0026lt;=m2;j++){ for(LL k=0;k\u0026lt;=m3;k++){ if((i^j^k)!=0) continue; int newr1 = ((LL)r1+(i\u0026lt;\u0026lt;pos))%a1;//计算新的余数 int newr2 = ((LL)r2+(j\u0026lt;\u0026lt;pos))%a2; int newr3 = ((LL)r3+(k\u0026lt;\u0026lt;pos))%a3; ret = (ret + dfs(pos-1,newr1,newr2,newr3, l1\u0026amp;\u0026amp;i==digit[pos], l2\u0026amp;\u0026amp;j==digit[pos],l3\u0026amp;\u0026amp;k==digit[pos], z1\u0026amp;\u0026amp;i==0,z2\u0026amp;\u0026amp;j==0,z3\u0026amp;\u0026amp;k==0))%MOD; } } } dp[pos][r1][r2][r3][l1][l2][l3][z1][z2][z3] = ret; return ret; } int getSum(LL x){ digit.clear(); std::memset(dp,-1,sizeof(dp)); while(x){ digit.pb(x%2); x/=2; }//本题低位到高位存更方便，方便移位运算 return dfs(digit.size()-1,0,0,0,1,1,1,1,1,1); } void solve(){ LL n; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;a1\u0026gt;\u0026gt;a2\u0026gt;\u0026gt;a3; std::cout\u0026lt;\u0026lt;getSum(n)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } 选择低位到高位还是高位到低位应该根据题目的不同来选择。\n另外如果满足limit为真的情况出现的概率远低于为假的，那么可以把limit这一维省略掉，dp数组里面只记录limit为假的情况。\n低位到高位存还有一个好处。我们知道高位到低位存时，由于数字长度不一样，比如a有5位，b有10位，把a的dp数组求完后，求b时就必须再次清空成-1。原因是，对于a的pos为1，也就是从高到低第二位，其实对应这b的pos为6，我们就不能用a中求出的dp带进去b里面计算了。\n而低位到高位就没有这个问题，大家的最低位都是平等的从0下标开始的，可以进行复用。清零为-1只需要程序最开始的时候清零一次即可。有时候程序有多个case会避免TLE。\n概率论 处理分数期望、概率 有时候，题目中的期望是一个分数\\(\\frac{P}{Q}\\)，而为了防止精度问题，往往会要求输出一个\\(R\\)，满足\n\\[R\\times Q\\equiv P(mod\\ 998244353) \\]\n此时\n\\[R = (P\\times Q^{-1})\\%998244353 \\]\n\\(Q^{-1}\\)是\\(Q\\)在模\\(998244353\\)意义下的乘法逆元\n杂项 快速幂 //复杂度logn //快速幂 //luogu P1226 using LL = long long; LL qPow(LL x, LL p){ //x^p LL res = 1; while(p){ if(p\u0026amp;1){ res = res * x; } x *= x; p\u0026gt;\u0026gt;=1; } return res; } LL qPowMod(LL x, LL p, LL m){ //x^p % m LL res = 1; while(p){ if(p\u0026amp;1){ res = (res * x)%m; } x = (x*x)%m; p\u0026gt;\u0026gt;=1; } return res; } 离散化 有两种，一种是unique函数版，一种是树状数组求逆序对里使用的，都可以，区别是，那个对于相同的数字根据先后顺序确定大小，这个则是一样大\n//复杂度nlogn //离散化 例如将1,500,40,1000保持相对大小不变，离散化为1,3,2,4 //出现同样的数字时，例如6,-4,3,7,3会离散化为3,1,2,4,2 //luogu B3694 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; std::vector\u0026lt;int\u0026gt; arr,assi; void solve(){ int n; std::cin\u0026gt;\u0026gt;n; arr.clear(); assi.clear(); for(int i=1;i\u0026lt;=n;i++){ int a; std::cin\u0026gt;\u0026gt;a; arr.push_back(a); assi.push_back(a); } std::sort(assi.begin(),assi.end()); assi.erase(std::unique(assi.begin(),assi.end()),assi.end()); for(int i=0;i\u0026lt;n;i++){ arr[i] = std::upper_bound(assi.begin(),assi.end(),arr[i])-assi.begin(); } for(int i=0;i\u0026lt;n;i++){ std::cout\u0026lt;\u0026lt;arr[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } std::cout\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } 莫队算法 //对于序列上的区域离线询问问题，如果[l,r]的答案能够O(1)拓展得到 //[l-1,r],[l+1,r],[l,r-1],[l,r+1]的答案，那么就可以在O(n sqrt(n))中解决所有询问 //SPOJ DQUERY //本题是给定若干个区间[l,r]，查询这个范围内有多少个不同的数 int arr[MAXN]; int sq;//分块数sq = sqrt(n) struct Query{ int l,r,id;//询问区间和询问下标 bool operator\u0026lt;(Query const \u0026amp; x)const{ if(l/sq != x.l/sq)//根据归属于哪个块排序 return l\u0026lt;x.l; if(l/sq \u0026amp; 1) //玄学奇偶排序 return r\u0026lt;x.r; return r\u0026gt;x.r; } }Q[MAXQ]; int ans[MAXQ], cnt[MAXA], cur; int l=1,r=0;//初始化询问区间 inline void add(int p){ if(cnt[arr[p]]==0)//新增一种数 cur++; cnt[arr[p]]++; } inline void del(int p){ cnt[arr[p]]--; if(cnt[arr[p]]==0)//把一种数全部删完 cur--; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); int n; std::cin\u0026gt;\u0026gt;n; sq = std::sqrt(n); for(int i=1;i\u0026lt;=n;i++) std::cin\u0026gt;\u0026gt;arr[i]; int q; std::cin\u0026gt;\u0026gt;q; for(int i=0;i\u0026lt;q;i++){ std::cin\u0026gt;\u0026gt;Q[i].l\u0026gt;\u0026gt;Q[i].r; Q[i].id = i;//把询问离线 } std::sort(Q,Q+q); for(int i=0;i\u0026lt;q;i++){ while(l\u0026gt;Q[i].l) add(--l);//当前区间l大于查询的l，要把左边的数加进来 while(r\u0026lt;Q[i].r) add(++r);//当前区间r小于查询的r，要把右边的数加进来 while(l\u0026lt;Q[i].l) del(l++);//当前区间l小于查询的l，要把左边的数删掉 while(r\u0026gt;Q[i].r) del(r--);//当前区间r大于查询的r，要把右边的数删掉 //注意上述顺序，扩张区间是先移动再更新，缩减区间是先更新再移动 //四个操作的具体实现可能会有不一样，具体题目具体讨论 ans[Q[i].id] = cur; } for(int i=0;i\u0026lt;q;i++){ std::cout\u0026lt;\u0026lt;ans[i]\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } return 0; } 0/1分数规划 0/1分数规划的目的是如下列式子取值最大化\n\\[\\dfrac{\\sum^n_{i=1}a_ix_i}{\\sum^n_{i=1}b_ix_i} \\]\n其中\\(\\{a_i\\}\\)和\\(\\{b_i\\}\\)是给定的数列，而\\(\\{x_i\\}\\)是要求的一组解，其取值只能是\\(0\\)或\\(1\\)。或者说，给定\\(n\\)对数\\(a_i,b_i\\)，从中选出若干对（通常题目要求恰好选\\(k\\)对），使选出的数对的\\(a\\)之和和\\(b\\)之和的商最大。\n我们转化成二分答案，验证一个值\\(m\\)，上式的取值能否大于等于\\(m\\)。转化一下就可以得到，是否存在一组解\\(x_1,\\cdots,x_n\\)，满足\n\\[\\sum^n_{i=1}(a_i-m\\times b_i)\\times x_i\\geq 0 \\]\n如果存在则说明\\(m\\)比最大值要小，否则\\(m\\)比最大值要大，满足二分性。\n我们可以计算每一个\\((a_i-m\\times b_i)\\)，如果题目说可以任意选择若干对，则只要有一个非负数，就能满足条件。如果要求恰好选\\(k\\)对，那么我们全部算出来然后排序，选择最大的\\(k\\)个，其和非负就能满足条件。\n//0/1分数规划，复杂度n log^2 n //nowcoder NC14662 //介绍见markdown LL a[MAXN],b[MAXN]; int n,k; bool judge(DB mid){ std::vector\u0026lt;DB\u0026gt; vec; for(int i=1;i\u0026lt;=n;i++){ vec.pb(a[i]-mid*b[i]); } std::sort(vec.begin(),vec.end()); DB sum = 0; for(int i=n-1;i\u0026gt;=0 \u0026amp;\u0026amp; n-1-i+1\u0026lt;=k;i--) sum+=vec[i]; if(sum\u0026gt;=0) return true; return false; } void solve(){ std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;k; for(int i=1;i\u0026lt;=n;i++){ std::cin\u0026gt;\u0026gt;b[i]\u0026gt;\u0026gt;a[i]; } DB l=0, r=1e13; for(int i=1;i\u0026lt;=100;i++){ DB mid = (l+r)/2; if(judge(mid)) l = mid; else r = mid; } std::cout\u0026lt;\u0026lt;(LL)r\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } 表达式求值 可能需要进一步完善TODO inline bool isOper(char c){ return c==\u0026#39;+\u0026#39;||c==\u0026#39;-\u0026#39;||c==\u0026#39;*\u0026#39;||c==\u0026#39;/\u0026#39;; } inline bool isDigit(char c){ return c\u0026gt;=\u0026#39;0\u0026#39; \u0026amp;\u0026amp; c\u0026lt;=\u0026#39;9\u0026#39;; } inline int priority(char oper){ if(oper==\u0026#39;+\u0026#39; || oper==\u0026#39;-\u0026#39;) return 1; if(oper==\u0026#39;*\u0026#39; || oper==\u0026#39;/\u0026#39;) return 2; return -1; } std::string toRPN(std::string expr){ std::string ret; std::stack\u0026lt;char\u0026gt; oper; int esize = expr.size(); for(int i=0;i\u0026lt;esize;i++){ char\u0026amp; c = expr[i]; if(c==\u0026#39; \u0026#39;) continue; else if(isOper(c)){ if(c==\u0026#39;-\u0026#39; \u0026amp;\u0026amp; (i==0 || expr[i-1]==\u0026#39;(\u0026#39;)){ //判断一元运算符负号，这里采用了加个0-前缀的方法，如果题目要求输出RPN其实是做不到的 //TODO: 把toRPN返回一个vector，实现真正的RPN ret.push_back(\u0026#39;0\u0026#39;); ret.push_back(\u0026#39; \u0026#39;); } while(!oper.empty() \u0026amp;\u0026amp; priority(oper.top())\u0026gt;=priority(c)){ //如果是右结合运算符，则要改成大于，如果只有一部分是右结合运算符，分类讨论 ret.push_back(oper.top()); ret.push_back(\u0026#39; \u0026#39;); oper.pop(); } oper.push(c); } else if(c==\u0026#39;(\u0026#39;){ oper.push(c); } else if(c==\u0026#39;)\u0026#39;){ while(oper.top()!=\u0026#39;(\u0026#39;){ ret.push_back(oper.top()); ret.push_back(\u0026#39; \u0026#39;); oper.pop(); } oper.pop(); } else{ while(i\u0026lt;esize \u0026amp;\u0026amp; isDigit(expr[i])){ ret.push_back(expr[i++]); } ret.push_back(\u0026#39; \u0026#39;); i--; } } while(!oper.empty()){ ret.push_back(oper.top()); ret.push_back(\u0026#39; \u0026#39;); oper.pop(); } return ret; } void processOper(std::stack\u0026lt;int\u0026gt; \u0026amp; st, char oper){ int r = st.top(); st.pop(); int l = st.top(); st.pop(); switch(oper){ case \u0026#39;+\u0026#39;: st.push(l+r); break; case \u0026#39;-\u0026#39;: st.push(l-r); break; case \u0026#39;*\u0026#39;: st.push(l*r); break; case \u0026#39;/\u0026#39;: st.push(l/r); break; } } int RPNCalc(std::string expr){ int ret = 0; std::stack\u0026lt;int\u0026gt; number; int esize = expr.size(); for(int i=0;i\u0026lt;esize;i++){ char\u0026amp; c = expr[i]; if(c==\u0026#39; \u0026#39;) continue; else if(isOper(c)){ processOper(number, c); } else{ int res = 0; while(i\u0026lt;esize \u0026amp;\u0026amp; isDigit(expr[i])){ res = res*10 + expr[i++] - \u0026#39;0\u0026#39;; } i--; number.push(res); } } ret = number.top(); return ret; } int exprCalc(std::string expr){ int ret = RPNCalc(toRPN(expr)); return ret; } int main(){ std::ios::sync_with_stdio(false); std::cin.tie(0); std::string str; std::cin\u0026gt;\u0026gt;str; std::cout\u0026lt;\u0026lt;toRPN(str)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; std::cout\u0026lt;\u0026lt;exprCalc(str)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; return 0; } 艾弗森括号 艾弗森括号常表示为\\([A]\\)，其中\\(A\\)是一个二值表达式。用三元运算符可以等价为\\([A]\\leftrightarrow A?1:0\\)。\n例如\\([\\gcd(a,b)==1]\\)，就意味着，如果\\(a,b\\)互质，式子的值为\\(1\\)，否则为\\(0\\)。\n向上、向下取整 在C++中，如果我们对一个double或者float用强制类型转换\ndouble x = 1.1; std::cout\u0026lt;\u0026lt;(int)x\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; 这其实看起来像是向下取整，实际上却不是。它是省略小数部分，实为向\\(0\\)取整。C++的整数除法也是向零取整的，而Python则是向下取整。具体表现为C++中\\(-7/2\\)为\\(-3\\)，Python中\\(-7//2\\)为\\(-4\\)。\nC++本身也有std::floor()和std::ceil()，但是只能针对浮点数使用。\n我们一般会在结果非负的时候，用以下方式计算向上向下取整\nint x = a/b;//a/b向下取整 int y = (a+b-1)/b;//a/b向上取整 而对于负数结果，我们有一个性质\n\\[-\\lfloor x\\rfloor= \\lceil -x\\rceil \\]\n\\[-\\lceil x\\rceil= \\lfloor -x\\rfloor \\]\n转换即可。\n滚动哈希 （总觉得和之前的字符串哈希其实一模一样）\n滚动哈希用来以线性复杂度求一个序列的哈希，这个序列可以是一个字符串，可以是一个数组。或者也可以退化成单个元素。假设序列是\\(A=(A_1,A_2,\\cdots,A_N)\\)，定义滚动哈希函数为\\(R\\)，为\n\\[R(A) = \\bigg(\\sum^N_{i=1}A_ix^{N-i}\\bigg)\\mod{p} \\]\n其中，\\(P\\)是一个足够大的质数，而\\(x\\)是从\\([0,p)\\)中等可能选出的一个整数。假设\\(A(a,b)\\)为\\(A\\)的下标从\\(a\\)到\\(b\\)的子序列，我们可以立即得到它的递推式：\n\\[R(A(1,1)) = A_1, R(A(1,n))=R(A(1,n-1))\\times x+A_n(n\u003e1) \\]\n并且如果已经与处理过所有的\\(R(A(1, i))\\)，那么我们可以在\\(O(1)\\)内求出\\(R(A(a,b))\\)，即\n\\[R(A(a,b)) = R(A(1,b)) - R(A(1, a-1))\\times x^{b-(a-1)} \\]\n有一个有用的性质，如果记\\(A+B=(A_1+B_1, A_2+B_2, \\cdots, A_N+B_N)\\)，那么有\n\\[R(A+B) = R(A)+R(B) \\]\n对于字符串\\(S\\)和\\(T\\)，它们的拼接，即\\(S+T\\)，可以由之前的递推式得出哈希为\n\\[R(S+T) = R(S)\\times x^{|T|}+R(T) \\]\n这样的序列上的哈希可以方便我们判断任意两个区间的内容是否相等。另外，结合线段树，我们可以实现\\(O(logn)\\)的单点修改和\\(O(logn)\\)的区间哈希查询。只要每个节点存这段区间的哈希即可。两个区间合并的时候相当于拼接。支持区间修改可能有些麻烦，因为lazy tag有些难写。\n另外，对于字符串，滚动哈希还可以用来\\(O(1)\\)地判断一个区间是否是回文串。我们只需要正着求一遍哈希，再倒着求一遍哈希，响应的区间的哈希值相等，那么意味着是回文串。如果要避免下标的转换，则可以换一下哈希函数（注意与之前正着的哈希区分）：\n\\[R'(A) = \\bigg(\\sum^N_{i=1}A_ix^{i-1}\\bigg)\\mod{p} \\]\n此时，\\(R'(S+T)=R'(S)+R'(T)\\times x^{|S|}\\)。\n另外，单哈希可能不能使得碰撞的概率足够低，那么我们就重复使用多个\\(p\\)来算多个哈希即可。\n下面给出一个，支持单点修改，维护字符串子串哈希的线段树代码\n//atcoder abc331_f //滚动哈希+线段树 #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;random\u0026gt; #include \u0026lt;ctime\u0026gt; #include \u0026lt;array\u0026gt; using LL = long long; int const MAXN = 1000005; constexpr int B = 5; LL mod[B] = {998244353, 1000000007, 1000000009, 1000000021, 1000000033}; LL base[B]; struct Hash{ LL h1, h2, pw; Hash():h1(0),h2(0),pw(1){} // 字符串拼接哈希时，拼接操作的幺元 }; using T = std::array\u0026lt;Hash, B\u0026gt;; // 存多个哈希，以减小碰撞概率 T operator+(T lhs, T rhs){ // 区间拼接 T res; for(int i=0;i\u0026lt;B;i++){ res[i].h1 = (lhs[i].h1*rhs[i].pw + rhs[i].h1)%mod[i]; res[i].h2 = (lhs[i].h2 + lhs[i].pw*rhs[i].h2)%mod[i]; res[i].pw = (lhs[i].pw*rhs[i].pw)%mod[i]; // 见字符串拼接的哈希 } return res; } T gen(char c){ // 单个字符的哈希 T res; for(int i=0;i\u0026lt;B;i++){ res[i].h1 = c; res[i].h2 = c; res[i].pw = base[i]; } return res; } struct Node { int s,t;//该端点的起点和终点下标 T v; }; Node st[MAXN*4+2]; std::string arr; void build(int s, int t, int p=1){ st[p].s = s; st[p].t = t; if(s==t) { st[p].v = gen(arr[s]); return; } int m = s+((t-s)\u0026gt;\u0026gt;1); build(s,m,p*2); build(m+1,t,p*2+1); st[p].v = st[p*2].v + st[p*2+1].v; } void update(int i, char ch, int p=1){ int s = st[p].s, t = st[p].t; if(s==t){ st[p].v = gen(ch); return; } int m = s+((t-s)\u0026gt;\u0026gt;1); if(i\u0026lt;=m) update(i, ch, p*2); if(i\u0026gt;m) update(i, ch, p*2+1); st[p].v = st[p*2].v + st[p*2+1].v; } T query(int l, int r, int p=1){ int s = st[p].s, t = st[p].t; if(l\u0026lt;=s \u0026amp;\u0026amp; t\u0026lt;=r) return st[p].v; int m = s+((t-s)\u0026gt;\u0026gt;1); T ret; if(l\u0026lt;=m) ret = ret+query(l,r,p*2); if(r\u0026gt;m) ret = ret+query(l,r,p*2+1); return ret; } void solve(){ std::mt19937_64 rng(time(0)); for(int i=0;i\u0026lt;B;i++){ base[i] = rng() % mod[i]; // 即随机生成的x } int n,q; std::cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;q; std::cin\u0026gt;\u0026gt;arr; arr = \u0026#39;#\u0026#39;+arr; build(1, n); while(q--){ int op; std::cin\u0026gt;\u0026gt;op; if(op==1){ int x; char c; std::cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;c; update(x,c); } else{ // 判断[l,r]是否为回文串 int l, r; std::cin\u0026gt;\u0026gt;l\u0026gt;\u0026gt;r; auto h = query(l, r); bool ans = 1; for(int i=0;i\u0026lt;B;i++){ ans \u0026amp;= (h[i].h1==h[i].h2); } std::cout\u0026lt;\u0026lt;(ans?\u0026#34;Yes\u0026#34;:\u0026#34;No\u0026#34;)\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; } } } C++ STL用法 std::swap 交换两个元素的内容（也可以交换数组，不重要不介绍）。复杂度：常数。\nint a,b; std::swap(a,b); 注意其中的两个参数，类型要相同。不能一个是LL一个是int。\nstd::sort 对数组、vector等进行排序。复杂度nlogn。\nint a[5]; std::vector\u0026lt;int\u0026gt; vec(5); std::sort(a,a+5); std::sort(vec.begin(),vec.end()); 注意排序范围是左闭右开区间。\n通常会按照类型的\u0026lt;操作符来进行比较。如果对结构体进行排序，可以重载运算符或者设定cmp函数。注意这两种方法一定不能是小于等于或者大于等于的运算，必须只使用小于号或者大于号（严格弱序）。\nbool cmp(const Type1\u0026amp; a, const Type2\u0026amp; b); //然后在sort中加入第三个参数 std::sort(a,a+5,cmp); struct node{ bool operator\u0026lt;(const node\u0026amp; a); }; //不用添加cmp参数 std::merge 对两个有序数组进行合并。\nstd::vector\u0026lt;int\u0026gt; a(5), b(6); std::vector\u0026lt;int\u0026gt; c(5+6); std::merge(a.begin(), a.end(), b.begin(), b.end(), c.begin(), std::less\u0026lt;int\u0026gt;()); 如上，假设a和b都是从小到大排好序的数组，把它们合并成同样从小到大排序的c数组。如果是从大到小合并成从大到小，则改成std::greater\n另外，它的操作逻辑是双指针。比如less情况下，指向a数组元素的指针为p1，指向b数组元素的指针为p2。他会判断p1大还是p2大，如果p1大，则把p1指向的数字放进c，然后p1自增。否则p2放进去后自增。他其实不会管你原来的数组是否真的排好序，有时候这可以用在一些数组的合并上。\nstd::greater, std::less 很简单，greater是大于号\u0026gt;，而less是小于号\u0026lt;。在sort函数里的第三个参数可以用这个，例如std::greater\u0026lt;int\u0026gt;()代表从大到小排序，std::less\u0026lt;int\u0026gt;()则是从小到大排序。\n但是在优先队列里不一样，greater是小根堆，而less才是大根堆。\nstd::lower_bound,std::upper_bound 对某个已经排序好的数组，查找第一个大于等于（lower_bound）或者大于(upper_bound)某个给定值的元素。复杂度：logn（对于随机访问的迭代器），n（对于其他迭代器）。\nint a[5]={0,1,3,4,6}; int first = std::lower_bound(a,a+5,3); 同样是左闭右开区间，第三个参数是指定的值。如果找到就会返回所查找元素的迭代器（或者指针）。找不到就会返回末尾元素的后一个指针（或者end迭代器）。\n如果需要自定义比较方法，同sort函数。\nstd::max,std::min 对于两个元素返回最大值和最小值。复杂度：准确一次比较。\nint a=1,b=2; int maxv = std::max(a,b); int minv = std::min(a,b); 同样，两个参数类型相同。自定义比较方法同sort。如果要比较三四个元素，可以使用initializer_list，例如std::max({1,2,3,4,5});\nstd::max_element,std::min_element 返回一个范围内的最大（最小元素）的迭代器（指针）。复杂度，准确比较max(N-1,0)次\nstd::vector\u0026lt;int\u0026gt; v{3,1,-14,9}; std::cout\u0026lt;\u0026lt;*std::max_element(v.begin(),v.end())\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; std::abs 计算绝对值。复杂度：文档没写但应该是常数。\nint a = -1; int b = std::abs(a); 注意，函数只有float,double,long double的返回值类型。使用时如果给予整数参数会自动转换，这是否会导致精度问题有待观察。\nstd::string ::swap 将两个字符串互换。复杂度：常数。\nstd::string str = \u0026#34;123456\u0026#34;; std::string str2 = \u0026#34;456789\u0026#34;; str.swap(str2); ::begin,std::end 返回字符串的起始得带器和结尾迭代器。\nstr.begin();str.end(); ::size 返回字符串的大小。\nstr.size(); ::push_back 向字符串末尾添加一个字符，同时大小加一。复杂度：常数。\nstr.push_back(\u0026#39;a\u0026#39;); ::pop_back 将字符串末尾的字符弹出，同时大小减一。如果字符串为空则未定义。复杂度：常数。\nstr.pop_back(); ::find 在字符串中寻找某个子串是否存在。复杂度：没有规定，编译器不一定都是使用的kmp算法。\nstd::string::size_type n; std::string s = \u0026#34;this is a string\u0026#34;; n = s.find(\u0026#34;is\u0026#34;); 如果找到则返回首个匹配的首字母位置。否则返回std::string::npos。如果是int n作为s.find的接收端，则会在找不到时接收到-1。\n::replace 将字符串的某个片段替换为另一个字符串\nstd::string s = \u0026#34;abcd efgh\u0026#34;; s.replace(1,3,\u0026#34;aaaa\u0026#34;); 第一个参数是开始位置的下标，第二个参数是指从开始位置有几个字符，第三个参数是将要替换进去的字符串，上式结果是\u0026quot;aaaaa efgh\u0026quot;。\n::substr 获取自字符串\nstd::string s = \u0026#34;abcd efgh\u0026#34;; std::string b = s.substr(1,3); 从下标1开始的3个字符，即b=\u0026ldquo;bcd\u0026rdquo;。\nstd::memset 将值复制到dest所指对象的前count个字节中。复杂度：没有规定。\nint a[20]; std::memset(a,0,sizeof(a)); 注意，赋的值不能随便取，这个函数是一个字节一个字节地去赋值的。如果取1并不会得到全部赋值为1的效果，通常只会取0和-1。\nstd::copy 将一个范围的值复制给另一个范围，复杂度：准确赋值 (last - first) 次\nint a[10],b[10]; std::copy(a,a+10,b);//源起点，源终点，目的地起点 需要注意的点是，不要数组越界，包括源不要越界，目标的大小也要足够复制。类型要一致。以及，目标起点的地址不能在源之内，否则行为是未定义的。\nstd::fill 将给定值填写到整个范围中，复杂度：准确赋值 std::distance(first, last) 次。\nstd::vector\u0026lt;int\u0026gt; v{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}; std::fill(v.begin(), v.end(), -1); 之后v变成全-1的vector。\n可以对C数组使用指针，和memset不一样的是，memset是字节赋值，fill并不会把4字节的int每一个字节都赋值一次。\n注意，如果你对结构体数组使用，你不能直接像memset一样全部memset为0。你要创建一个你认为的初始化应该有的值，再fill进去。\nstruct A{ int a,b; }a[100]; std::memset(a,0,sizeof(a)); //std::fill(a,a+100,0);//出错 A tmp = {0,0}; std::fill(a,a+100,tmp); std::map map是有序键值对容器，通常用红黑树实现。元素的键是唯一的。\ntemplate\u0026lt; class Key, class T, class Compare = std::less\u0026lt;Key\u0026gt;, class Allocator = std::allocator\u0026lt;std::pair\u0026lt;const Key, T\u0026gt; \u0026gt; \u0026gt; class map; 可以通过迭代器来遍历\nfor(std::map\u0026lt;int,int\u0026gt;::iterator it = mp.begin();it!=mp.end();it++); //访问元素用it-\u0026gt;first和it-\u0026gt;second //或者 for(auto it:mp); //访问元素用it.first和it.second 自定义比较函数 map通常会按照key的大小关系进行升序排列。如果要自定义比较函数，则\nstruct cmp{ bool operator()(const int\u0026amp; a, const int\u0026amp; b) const{ return a\u0026gt;b; } }; std::map\u0026lt;int,std::string,cmp\u0026gt; mp; ::empty 检测是否为空。\n::size 返回大小。\n::clear 清除所有内容。复杂度：线性。\n::erase 提供迭代器，删除迭代器所指的键值对。复杂度：常数。\nauto it = mp.begin(); mp.erase(it); 当然也可以提供两个迭代器，删除这之间的所有元素（左闭右开区间）\n::find 寻找key等于给定值的元素，返回迭代器。如果没有找到则返回end迭代器。复杂度：对数。\nauto it = mp.find(1); ::lower_bound,::upper_bound 寻找首个大于等于(或大于，对upper_bound)给定值的key。复杂度：对数。\nauto it = mp.lower_bound(1); std::unordered_map 可以看作是无序的map，通常由哈希表实现。这意味着map中和排序有关的函数都不能使用。\n警告\nunordered_map可能不能用auto x:mp或者迭代器遍历。它的遍历可能是遍历bucket，而不是遍历元素。但是只是查找是可以的。\n这里的bucket是指哈希桶，也就是用拉链法实现的hash表。\nstd::set set是关联容器，含有Key类型对象的已排序集，通常用红黑树实现。\ntemplate\u0026lt; class Key, class Compare = std::less\u0026lt;Key\u0026gt;, class Allocator = std::allocator\u0026lt;Key\u0026gt; \u0026gt; class set; 遍历的方式与map相同。\n使用方法 自定义比较函数,empty,size,clear,erase,find,lower_bound,upper_bound都与map相同。\n::insert map可以用[]进行插入，但是set只能用insert函数。\nstd::set\u0026lt;int\u0026gt; st; st.insert(1); 返回值是一个pair，first是迭代器，指向被插入进去的元素（如果插入不成功则指向没插进去的元素），second是bool，插入成功时为true，否则为false。\n修改内部元素 有时候，我们需要修改内部元素。由于例如begin函数返回的迭代器是const的，我们无法直接修改数据。但我们可以给变量添加mutable修饰。这样我们就可以不用拿出来一个元素再插回去。例子可见珂朵莉树。\n注意，如果你修改的数据和排序依据有关，set不会维护内部有序。要维护还得是拿出来再插入进去。\nstd::unordered_set 用哈希实现，没有内部排序。\n警告\n可能跟unordered_map一样不能遍历。\nstd::multiset 与普通的set不同的是，可以插入多个相同的元素。这在一些情况下是有用的，而且它还是满足内部有序。\n可以用::count(x)来统计Key为x的元素的数量，普通的set也有这个方法，但是要么是0要么是1，与find功能可以说是重复。但是multiset可以统计数量。\n注意，用erase方法时，如果给出的是一个值，那么会把等于这个值的元素都删掉，如果给出迭代器，那么之后删一个。所以，只想删一个等于这个值的元素时，用erase(find(\u0026hellip;))\nstd::stack 栈，有先入后出特性。\n::top 访问栈顶元素，复杂度：常数。\n::empty 检查是否为空，复杂度：常数\n::size 返回元素个数，复杂度：常数\n::push 将元素推入栈，复杂度：通常和deque的push_back相同，即常数\n::pop 将栈顶弹出，复杂度：通常和deque的pop_back相同，即常数\n::emplace 在顶部原位构造元素，通常会用在栈的元素是结构体的时候，复杂度：通常和deque的emplace_back相同，即常数\nstd::queue 队列，拥有先入先出特性。\n::front 访问队首元素，复杂度：常数\n::back 访问队尾元素，复杂度：常数\n其他方法 同stack，不过push是推入队尾，pop是弹出队首。\nstd::priority_queue 优先队列，提供常数时间的最大（或最小）元素查找，以及对数时间的插入与删除。\n自定义比较方法 通常我们会重载元素的运算符来自定义\nstruct node { int dis, u; bool operator\u0026gt;(const node\u0026amp; a) const { return dis \u0026gt; a.dis; } }; priority_queue\u0026lt;node, vector\u0026lt;node\u0026gt;, greater\u0026lt;node\u0026gt; \u0026gt; pq; 方法 其方法与stack相同，只不过没有先入后出特性，插入元素或弹出元素后会根据大小关系进行排序，保证栈顶是最大的（或最小的）元素。\nstd::deque 双端队列，允许在队首和队尾进行插入和删除。另外，在 deque 任一端插入或删除不会非法化指向其余元素的指针或引用。通常也会用来实现单调队列。\n方法 size、empty与stack、queue相同。其pop_back、push_back、pop_front、push_front、emplace_front、emplace_back用法也类似。\nstd::vector 通常可以理解为一个可以变化长度的数组。\n声明方法 std::vector\u0026lt;int\u0026gt; vec;//声明一个初始大小为0的vector std::vector\u0026lt;int\u0026gt; vec2(n);//声明一个初始大小为n的vector，每个元素都会初始化为0 std::vector\u0026lt;int\u0026gt; vec3(n,1);//与上一个不同的是，每一个元素都会初始化为1 元素访问 vec[5];//像数组一样访问 vec.at(5);//与上一个方法的差别在会进行越界检查 vec.front();//访问第一个元素 vec.back();//访问最后一个元素 ::size 获取大小，复杂度：常数\n::empty 查看是否为空，复杂度：常数\n::push_back 向末尾添加元素，复杂度：常数\n::pop_back 把末尾元素弹出，复杂度：常数\n::emplace_back 在末尾原位构造元素，复杂度：常数\n::resize 重新指定vector的大小，会改变size()，resize有两个参数(new_size, value)，第一个为要分配的大小，第二个为指定的初始值（可以忽略，此时调用默认构造函数）。注意只有加大size时，新增的元素会被赋值。\n::reserve 给vector预留空间，但不会改变size()的大小。参数只有一个，为预留的元素个数。\n如果dfs中参数引用的vector会导致RE，可以试试预留足够的大小。\nstd::vector\u0026lt;bool\u0026gt; 这是一个特化的vector，它每一个元素所占的空间是一位，而不是sizeof(bool)（通常是一字节）。\n不建议使用，除非非常了解会发生什么。\noperator[]返回的不是bool类型，返回的是一个proxy reference。\nstd::vector\u0026lt;bool\u0026gt; c{false,true,true}; bool a = c[0];//经过了强制类型转换 auto b = c[0];//没有转换，本身b就是引用了 a = true;//c是0 1 1 b = true;//c是1 1 1 std::bitset 表示一串二进制位。\n声明方法 std::bitset\u0026lt;100\u0026gt; bs;//声明一个位数为100位的bitset std::bitset\u0026lt;4\u0026gt; bs2{0xA};//声明一个四位的bitset，其值等于0xA 元素访问 同数组的访问方式。同样也可以用数组的方式进行修改。\n::all,::any,::none 检查是否全部，存在、没有元素被设置为true。\n::count 返回设置为true的数量。\n运算 bitset和bitset之间能用所有的位运算符。也可以用等号和不等号比较。\n::flip 翻转某一位的值。\n如果没有提供位置，就翻转所有。\n::to_string 转化为二进制数的字符串。\n::to_ulong,::to_ullong 转化为unsigned long和unsigned long long。\n::set 设置某一位为1，如果没有提供位置，则将所有位设为1\n::reset 设置某一位为0，如果没有提供位置，则将所有位设置为0\nstd::pair 定义一个二元组，例如std::pair\u0026lt;int,int\u0026gt;, std::pair\u0026lt;int,std::string\u0026gt;等。其定义是在\u0026lt;utility\u0026gt;中，但是也可以#include \u0026lt;algorithm\u0026gt;来使用\n元素访问 std::pair\u0026lt;int,int\u0026gt; p; p-\u0026gt;first;//访问第一个元素 p-\u0026gt;second;//访问第二个元素 ::swap 交换两个元素的内容。复杂度：没有定义。\nstd::make_pair auto p = std::make_pair(1,1);//自动推断类型为std::pair\u0026lt;int,int\u0026gt; std::tuple 定义一个多元组，可以说pair是tuple的特例。其定义是在\u0026lt;utility\u0026gt;中，但是也可以#include \u0026lt;algorithm\u0026gt;来使用\n元素访问 根据下标可以如下访问\nauto t = std::make_tuple(1, \u0026#34;Foo\u0026#34;, 3.14); std::get\u0026lt;0\u0026gt;(t);//1 std::get\u0026lt;1\u0026gt;(t);//Foo std::get\u0026lt;2\u0026gt;(t);//3.14 std::make_tuple 同pair。\n如果一个函数要返回tuple\nstd::tuple\u0026lt;int, int\u0026gt; foo_tuple() { return {1, -1}; // N4387 前错误 return std::tuple\u0026lt;int, int\u0026gt;{1, -1}; // 始终有效 return std::make_tuple(1, -1); // 始终有效 } 需要注意兼容性，有些编译器不支持第一种返回方式。\nstd::tie 将tuple解包。\nauto t = std::make_tuple(1,2,\u0026#34;Foo\u0026#34;); int a,b; std::string str; std::tie(a,b,str) = t; 当然也可以用auto，都不需要指定变量类型。\nauto[c,d,str2] = t; std::list 声明方法 std::list\u0026lt;int\u0026gt; l;//如果有初值可以l = {1,2,3}; 元素访问 链表的特性让我们无法随机访问，只能用front()和end()访问开始和结束元素。\n::empty() 返回是否为空\n::size() 返回元素个数\n::clear() 清空\n::begin(), ::end(), ::rbegin(), ::rend() 返回开始、结束迭代器。返回反向开始、结束迭代器。所以list是双向链表。\n::insert(pos, value) pos是一个迭代器，会在pos前面插入值为value的元素，不会使任何迭代器失效。\n::erase(pos) pos是一个迭代器，移除pos所指的元素。只有指向该元素的迭代器会失效，其他的不会。\n::push_back(v), ::pop_back(), ::push_front(v), ::pop_front() 和双向队列一样，不再介绍\n::merge(list\u0026amp; other) 将两个有序的链表合并，得到的新链表保持有序。另外新列表是调用这个方法的链表，other则会清空（如果两个链表相等则不会做任何事）。\n迭代器和引用不会失效。指向other元素的迭代器之后会指向新链表里的对应元素。\n::reverse() 翻转链表，迭代器不会失效。\n::sort() 排序，复杂度为nlogn\n::unique() 删除连续的重复的元素，只保留第一个，被删除元素的迭代器失效。\nstd::next_permutation, std::prev_permutation bool next_permutation (Iterator first, Iterator last); bool prev_permutation(Iterator first, Iterator last); 这两个算法都是“原地”算法，也就是说会直接更改原数组，而不会返回一个新数组。这两个函数的作用是，获取按字典序比当前排列小1号的排列，以及大1号的排列。\n例如123是一个排列，比它正好大1号的排列是132，再大1号的是213。比321小1号的是312。\n用法如下\nstring number = \u0026#34;213\u0026#34;; next_permutation(number.begin(), number.end()); cout \u0026lt;\u0026lt; number; 输出231。\n如果当前已经是最小的还要得到更小的，则返回false。已经是最大的还要得到更大的，则返回false。其他情况返回true。\n复杂度：线性。\nstd::unique 对一个已经排好序的数组去除重复元素。或者说是，移除一个一般数组中相邻的、相同的元素。复杂度：线性。\nIterator unique(Iterator first, Iterator last); 给出一个范围来进行这个操作。具体用例可以见离散化一节。\n返回值是新数组的末尾的迭代器。\nstd::mt19937_64 本功能在C++11后可以使用。\n#include\u0026lt;random\u0026gt; #include\u0026lt;ctime\u0026gt; std::mt19937_64 rng(time(0)); for(int i=0;i\u0026lt;B;i++){ base[i] = rng() % mod[i]; // 即随机生成[0,mod[i])之间的整数 } 使用梅森缠绕算法，给出\\([0,2^{64})\\)之间的随机数，如果想要32位的，用mt19937即可。其比cstdlib中的srand和rand生成的随机数性质要好得多，并且rand()的范围不那么好设置。推荐在涉及随机的算法中优先使用这个生成器。\nstd::cin 输入十六进制、八进制、二进制 int a; std::cin\u0026gt;\u0026gt;std::hex\u0026gt;\u0026gt;a;//16进制 std::cin\u0026gt;\u0026gt;std::dec\u0026gt;\u0026gt;a;//10进制 std::cin\u0026gt;\u0026gt;std::oct\u0026gt;\u0026gt;a;//8进制 注意，使用一次std::hex之后所有的输入都会是十六进制，需要用std::dec输入一次十进制才会转换回来。\n输入二进制可以考虑用bitset\nstd::bitset\u0026lt;32\u0026gt; bs; std::cin\u0026gt;\u0026gt;bs; std::cout\u0026lt;\u0026lt;bs.to_ulong(); 输入不忽略空格、回车 虽然可以用cin.get()和cin.getline()来实现，但是我们还是考虑用getchar比较好，当getchar返回EOF时代表输入结束。类似于逗号表达式返回最后一个的值，等号表达式返回等号左边的值，所以我们可以写(c=getchar())!=EOF。\nstd::cout 输出十六进制、八进制、二进制 int a = 16; std::cout\u0026lt;\u0026lt;std::hex\u0026lt;\u0026lt;a;//16进制 std::cout\u0026lt;\u0026lt;std::oct\u0026lt;\u0026lt;a;//8进制 std::cout\u0026lt;\u0026lt;std::dec\u0026lt;\u0026lt;a;//10进制 使用注意事项同前。\n输出二进制也是考虑用bitset\nstd::bitset\u0026lt;32\u0026gt; bs{64}; std::string ans = bs.to_string(); std::cout\u0026lt;\u0026lt;ans.substr(ans.find(\u0026#39;1\u0026#39;),int(ans.end()-ans.begin()))\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; 需要去除前导0，如果直接输出bs或者其to_string的话会带有前导0\n浮点数精度 std::cout\u0026lt;\u0026lt;std::fixed;//如果不用这个，则为有效数字四位。 std::cout.precision(4); std::cout\u0026lt;\u0026lt;a;//这里输出小数点后4位。 scanf TODO 输入十六进制、八进制、二进制 printf TODO 输出十六进制、八进制、二进制 atoi TODO 正则表达式 正则表达式语法 符号 功能 例子 literal 匹配字符串的值 foo \\|转义符，将一些正则表达式需要的符号进行转义 \\. () 括选一些字符，方便星号、加号等当作一个整体处理 a(abc)* re1|re2 匹配re1或匹配re2的值 foo|bar . 匹配换行符以外的单字符 a.b ^ 在字符串开头匹配（在方括号里除外） ^Dear $ 在字符串的结尾匹配 \\.sh$ * 匹配星号前面的零次、一次或多次 a(abc)* + 匹配加号前面的一次或多次 a(abc)+ ? 匹配问号前面的零次或一次 a(abc)? {N} 指定匹配次数 a(abc){5} {M,N} 匹配出现次数在M,N之间的，如果左边留空代表0次，右边留空代表任意次 a(abc){2,8} [\u0026hellip;] 匹配其中的任意字符 [aeiou],[0-9A-Za-z] [^\u0026hellip;] 匹配除了其中字符的任意字符 [^aeiou] \\n 匹配回车符 \\s 匹配任何空白字符 \\S 匹配任何非空字符 贪婪匹配\n*，+都是贪婪匹配的，也就是说，如果用\u0026quot;\u0026lt;.*\u0026gt;\u0026ldquo;匹配\u0026rdquo;\u0026lt;h1\u0026gt;测试\u0026lt;/h1\u0026gt;\u0026ldquo;会匹配到全文，而不是只匹配到\u0026rdquo;\u0026lt;h1\u0026gt;\u0026ldquo;这叫做贪婪匹配。如果遇到第一个满足的就停下，要用\u0026rdquo;\u0026lt;.*?\u0026gt;\u0026quot;\u0026quot;\nC++正则表达式库 std::regex 一个类型，可以设定匹配的模式串。\nstd::regex pattern(\u0026#34;.*\u0026lt;.*?\u0026gt;.*\u0026#34;); 后续如果要更换pattern的内容，可以使用pattern.assign(\u0026ldquo;sth.\u0026quot;)或者直接pattern = \u0026ldquo;sth.\u0026rdquo;\nstd::smatch 一个类型，可以用于接收匹配的结果。\nstd::regex_match 用于测试字符串是否匹配模式串\nbool regex_match(string s,regex pattern); bool regex_match(string s,smatch res,regex pattern); bool regex_match(s.cbegin(),s.cend(),smatch res,regex pattern); 如果匹配到，就会返回1，否则返回0。\ns代表被匹配的字符串，pattern代表模式串。res代表，如果这个字符串被匹配了，就会返回这个字符串。注意这里是完全匹配，后面介绍的search函数是子串匹配。\nres是smatch类型，不能直接cout，要输出res[0]。\n如果要传入一个字符串的范围，需要传入const_iterator，也就是s.cbegin()和s.cend()返回的版本（这其实是因为smatch的模板是const_iterator，如果是c风格字符数组，传入的是头尾指针，则要用cmatch）。此时如果匹配上，返回res是这个范围的字符串，而不是整个。\nconst_iterator不是指迭代器指的位置不能变，而是指你不能通过这个迭代器去修改元素。\nstd::regex_search bool regex_search(string s,regex pattern); bool regex_search(string s,smatch res,regex pattern); bool regex_search(s.cbegin(),s.cend(),smatch res,regex pattern); 参数、返回值同前。\n只不过，这个东西不是完全匹配，只要有任意子串匹配，就会返回1。而且只要匹配到一个就会返回（当然这里要注意贪婪和非贪婪），不会再往后搜索，所以如果你使用res[1]是不会输出第二个结果的。res[0]返回的是匹配到的子串的结果，res[1]以后的东西也有含义，但是我暂时觉得没什么用。\nres[0]的类型是sub_match，可以使用.second方法得到res[0]在s中的匹配结果位置的末尾的迭代器，所以要遍历所有匹配的子序列，可以这么写：\nwhile(std::regex_search(it_begin,it_end,res,pattern)){ std::cout\u0026lt;\u0026lt;res[0]\u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt;res.position()\u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; it_begin = res[0].second; } 其中你还可以用.position返回子串开头的位置（相对于it_begin而言）。\nstd::regex_replace string regex_replace(string s,regex p,string rs) s为源字符串，p为模式串，rs为匹配到的子串将会被替换成的字符串。\n返回替换后的字符串。\n这里会替换一切匹配到的子串，不像search一样麻烦。\n如果我们只替换被匹配的子串的一部分，我们可以用如下方法\nstring s = \u0026#34;abcd123abcd\u0026#34;; regex p(\u0026#34;(abcd)([0-9]+)\u0026#34;); string ss = regex_replace(s,p,\u0026#34;a$2\u0026#34;); 则我们的ss会变成a123abcd。$2代表的是第二个捕捉组的意思（这里下标又是从1开始的，而不是0）。捕捉组是括号括起来的算一组。\n转义符 含义 $n 表示第n个捕捉组捕捉到的字符串 $\u0026amp; 表示匹配到的整个子串，相当于$0 $` 在源字符串中，在匹配到的子串左边的部分 $' 在源字符串中，在匹配到的子串右边的部分 $$ 美元符号 ","date":"2021-12-18T15:57:37+08:00","permalink":"https://kegalas.top/p/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E5%B8%B8%E7%94%A8%E6%A8%A1%E6%9D%BF%E6%95%B4%E7%90%86/","title":"算法竞赛常用模板整理"},{"content":"网络设备管理 题目描述 ​\t叮叮叮！网络设备管理员欢欢在行动\n​\t欢欢就职于一家庞大的数据管理分析公司\n​\t公司有一个存储数据的庞大网络，把每个数据存储器看做一个节点，这个存储网络可以看做是一个树型结构，每天有庞大的数据流在节点之间穿梭\n​\t随着公司的发展，这个网络越来越庞大，数据的传输速度也越来越慢，通过研究，欢欢发现，每个节点的传输速度，只与与这个节点连接的节点数量有关，比如仅和一个节点连接的节点传输数据会很快，而和 100 个节点连接的节点传输数据会很慢\n​\t欢欢准备提交一份研究报告，报告将会指出，若对于网络中的所有节点，与该节点相连的节点数量不超过 d，那么网络的整体传输速度将会大幅提高。\n​\t欢欢准备通过添加新的网络设备来降低与某节点相连的节点的数量\n​\t简而言之，对于网络设备a，我们可以添加新的设备b，使得原来与a相连的若干节点断开与a的连接并与b连接，并且使a,b连接，显然，添加新的网络设备后，这个网络仍旧是一个树形结构这样通过添加若干新的网络设备，我们可以把所有网络设备的相连网络设备数量降低到不超过d台 (包括与新添加的网络设备相接的网络设备数量不超过 d)\n​\t欢欢发现，有很多种解决方案\n​\t聪明的你知道欢欢最少添加多少台网络设备吗？\n​\t注意: 欢欢添加新的设备后，网络的结构仍保持为树形结构\n输入 ​\t单组输入 ​\t第一行两个正整数 \\(n\\), \\(d$ \\)(1\\le n\\le 10^5,3\\le d\\le n)\\(​\t接下来\\)n-1\\(行，每行两个正整数$a\\)，\\(b$ \\)(1\\le a, b\\le n)\\(，说明设备$a\\)与设备\\(b\\)相连接，数据保证设备网络为树形结构。\n输出 ​\t一个正整数，最小添加的网络设备数量，注意欢欢可以添加0台设备。\n样例 样例输入 样例输出 10 32 13 14 15 26 17 68 59 710 6 1 AC代码 #include \u0026lt;iostream\u0026gt; #define MAXN 100005 using namespace std; int arr[MAXN]; int main(){ int n,d; cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;d; for(int i=1;i\u0026lt;n;i++){ int a,b; scanf(\u0026#34;%d%d\u0026#34;,\u0026amp;a,\u0026amp;b); arr[a]+=1; arr[b]+=1; } int ans=0; for(int i=1;i\u0026lt;=n;i++){ if(arr[i]\u0026gt;d){ int tmp = (d-1)*2; if(arr[i]-tmp\u0026lt;=0){ ans+=1; } else if((arr[i]-tmp)%(d-2)==0) ans += 1 + (arr[i]-tmp)/(d-2); else ans += 1 + (arr[i]-tmp)/(d-2)+1; } } cout\u0026lt;\u0026lt;ans; return 0; } 正确性证明 先给出样例的示意图\n样例图\r其中红色数字表示与这个节点直接相连的节点的个数。显然只有1号节点连了大于3个节点，我们可以新增一个节点A，将2、3号与A相连，4、6号不变，然后将1与A相连，现在1与A连了三个节点，符合要求。不过这不是唯一的连法。\n这种有最大连接节点的结构，很容易让人回想起烷烃。显然的，饱和烷烃的碳链无论怎么排布，所连的氢原子的数目不会改变。每个碳原子也都会连四个原子。\n类比到这道题，我们要做的，就是将形如下图的点（假设上限为连3个）\n2\r变为如下的一些点，当然这里的点怎么排布都不影响，只要他最大的利用了链接上限，就是答案。\n3\r解释一下核心代码\nfor(int i=1;i\u0026lt;=n;i++){ if(arr[i]\u0026gt;d){//枚举超过链接上限的节点 int tmp = (d-1)*2; //点链两端，能“向外”链接d-1个点，必须要向“内部”链接一个点，才能构成点链，这个arr[i]-tmp得到的是还需要“向外”链接的数量。 if(arr[i]-tmp\u0026lt;=0){//特判一下，如果只用新增一个节点，并且有一个节点没有占满上限 ans+=1; } else if((arr[i]-tmp)%(d-2)==0)//内部每个节点都只能“向外”链接d-2个节点，如果能全部占满每个内部节点的上限，ans如下 ans += 1 + (arr[i]-tmp)/(d-2); else//不能占满则ans如下 ans += 1 + (arr[i]-tmp)/(d-2)+1; } ","date":"2021-11-21T14:53:54+08:00","image":"https://kegalas.top/p/%E7%AE%97%E6%B3%95%E9%A2%98-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E7%AE%A1%E7%90%86/1_hue13a31d22502e6414becf06d466eec8f_119570_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/%E7%AE%97%E6%B3%95%E9%A2%98-%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E7%AE%A1%E7%90%86/","title":"算法题-网络设备管理"},{"content":"向量 题目描述 ​ 给你n个向量，请问是否可以通过旋转异或伸缩任意一个向量，使得这n个向量相加等于0向量。 ​\n​ 注意，在本题中，我们认为0向量只能伸缩为0向量，非0向量可以伸缩为0向量、方向相同长度任意的向量、方向相反长度任意的向量。\n输入 ​ 单组输入\n​ 第一行一个正整数 \\(n(1\\le n\\le 10^5)\\)，即向量的个数。\n​ 接下来\\(n\\)行，每行两个整数\\(x_i\\), \\(y_i$ \\)(0\\le |x_i|,|y_i|\\le 10^9)\\(，分别代表第$i\\)个向量\\(x\\)轴与\\(y\\)轴的大小方向。\n数据保证\n\\[\\sum_{i=1}^{n}(|x_i|+|y_i|)\\le 10^9 \\]\n输出 ​ 若存在满足要求的操作输出 “yes”，反之输出 “no”。\n样例 样例输入 样例输出 3\n0 0\n1 2\n4 2 no AC代码 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstdio\u0026gt; typedef long long ll; #define MAXN 100005 using namespace std; struct Vec { ll x; ll y; }; Vec vec[MAXN]; int main(){ int n; cin\u0026gt;\u0026gt;n; Vec allSum; allSum.x=0;allSum.y=0; for(int i=1;i\u0026lt;=n;i++){ cin\u0026gt;\u0026gt;vec[i].x\u0026gt;\u0026gt;vec[i].y; allSum.x+=vec[i].x; allSum.y+=vec[i].y; } ll ans = 0; for(int i=1;i\u0026lt;=n;i++){ if(vec[i].x==0\u0026amp;\u0026amp;vec[i].y==0) continue; Vec tmpSum = allSum; tmpSum.x-=vec[i].x; tmpSum.y-=vec[i].y; ll dis1 = tmpSum.x*tmpSum.x+tmpSum.y*tmpSum.y; ll dis2 = vec[i].x*vec[i].x+vec[i].y*vec[i].y; if(dis1==dis2) { ans=1; break; } if(vec[i].y*tmpSum.x-tmpSum.y*vec[i].x==0) { ans=1; break; } } if(ans) cout\u0026lt;\u0026lt;\u0026#34;yes\u0026#34;; else cout\u0026lt;\u0026lt;\u0026#34;no\u0026#34;; return 0; } 正确性证明 首先分析题目，出题人的表达和数据结果并不一致。“是否可以通过旋转异或伸缩任意一个向量”实际上应该是“是否可以通过旋转异或伸缩某一个向量”，从而“使得这n个向量相加等于0向量”。\n数据也就\\(10^5\\)，直接枚举就行。先将所有向量加到一起记为allSum，然后建立一个tmpSum = allSum-我们当前枚举的向量，记为v。\n然后判断这个tmpSum向量是否和v长度平方相等，是则可以通过旋转v，再相加得到0向量。判断tmpSum向量终点是否和\\((0,0)\\)和v的终点在同一直线上,是则可以通过伸缩v来达到目的。这里判断三点共线的方法是求外积。若都为否，则不可以只对v伸缩或者旋转达到目的，枚举下一个。这里注意，我上述写的代码要将0向量略过，否则0向量总是可以通过三点共线的判断，达不到目的。\n如果枚举出一个向量可以达到目的，就输出yes。如果所有向量都达不到目的，就输出no。\n","date":"2021-11-15T22:30:41+08:00","permalink":"https://kegalas.top/p/%E7%AE%97%E6%B3%95%E9%A2%98-%E5%90%91%E9%87%8F/","title":"算法题-向量"},{"content":"有限小数 题目描述 ​\t现在有一个正整数n,可以证明存在若干个正整数d使得1/n在d进制下为有限小数，输出最小的d。\n输入 ​\t单组输入 ​\t第一行一个正整数\\(n(2\\le n\\le 10^{12})\\)\n输出 ​\t一个正整数d\n样例 输入 输出 9 3 999 111 AC代码 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;cmath\u0026gt; using namespace std; int main(){ long long n; cin\u0026gt;\u0026gt;n; long long ans=1; long long tmp=n; //求n的质因数的乘积 for(long long i=2;i*i\u0026lt;=tmp;i++){ if(tmp%i==0){ ans*=i; while(tmp%i==0){ tmp/=i; } } } if(tmp\u0026gt;1) ans*=tmp; cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;endl; return 0; } 正确性证明 ​若\\(1/n\\)可以在d进制表达为有限小数，那么一定有：\n\\[\\frac{1}{n}=\\frac{a_1}{d}+\\frac{a_2}{d^2}+\\dots+\\frac{a_m}{d^m} \\]\n其中\\(a_i\u003c d(1\\le i\\le m)\\)，且\\(a\\)为正整数，\\(m\\)是一个正整数。将两边同乘\\(nd^m\\)得：\n​$$ d^m=n(a_1d^{m-1}+\\dots+a_md^0)\n\\[ 故只要$d^m$是n的倍数，$1/n$在d进制下就为有限小数。 将n进行质因数分解，由唯一分解定理知只能分解为一种形式，设d为n的质因数的乘积，易知此时总存在m使得n|$d^m$，并且显然，这个d是最小的。 \\]\n","date":"2021-11-15T16:26:01+08:00","permalink":"https://kegalas.top/p/%E7%AE%97%E6%B3%95%E9%A2%98-%E6%9C%89%E9%99%90%E5%B0%8F%E6%95%B0/","title":"算法题-有限小数"},{"content":"各种主义整理 哲学、政治、社会 绝对主义 绝对主义认为在任何一种学说里，某种观点必定是绝对正确或者绝对错误的。\n荒诞主义 “荒诞主义”是对人生的极端反叛，认为人生的意义并不存在，所以可以活得很无厘头都无所谓。\n唯美主义 唯美主义者的人生目的就是去创造和享受一切美的东西。\n利他主义 利他主义者是一种随时都在无私地为他人福利着想的人，在道德判断上，认为别人的幸福快乐比自己的来得重要。利他主义在许多思想和文化中是一种美德。\n无政府主义（安那其主义） “无政府”一词并不代表混乱、虚无或道德沦丧的状态，而是一种由自由的个体自愿结合，以建立互助、自治、反独裁主义的和谐社会。庄子被认为是最早的无政府主义者。\n人类中心主义（以人为本） 人类中心主义认为人类是地球上最核心或者最重要的物种，评价现实的真实与否依靠人类的视角。人类中心主义是环境伦理学和环境哲学的主要概念，被认为是人类为何与自然环境发生冲突的根本原因，但这种理念已经根植在大多数人类的心中。\n无神论 无神论并没有统一的哲学思想，一些无神论者可能完全否定超自然事物，但另一些无神论者可能相信诸如占星术等伪科学。无神论经常同不可知论、反神论或反有神论相混淆。无神论者是认为没有神，不可知论者是认为神的存在是不可知，而反神论者是直接明确反对有神论。\n资本主义 资本主义的特色是私人拥有生产资料，且投资活动是由个人决策左右，而非由国家所控制，经济行为则以追求利润为目标。资本主义的主要经济模式包括了自由的资本和雇佣流动、市场竞争以及价格机制的运行。\n集体主义 集体主义是主张个人从属于社会，个人利益应当服从集体、民族、阶级和国家利益的一种思想理论。\n建构主义 建构主义者认为，任何一个社会人的行为都被约定俗成的社会传统、社会习惯和个人身份来制约或改变，因此现实和我们理解现实的方式都是人造的、主观的。\n犬儒主义 犬儒主义本意是指人不应被一切世俗的事物，包括宗教、礼节、惯常的衣食住行等习俗束缚，提倡对道德的无限追求，同时过着极简朴而非物质的生活。\n现代社会中“犬儒主义”一词常被误用作比喻一些否定利他主义、自私而且毫无道德的人。\n演绎主义 科学知识的产生是通过提出假设，然后通过实验和观察到的现象和数据来证明这样一个过程。\n决定论（determinism） 决定论是哲学的一种命题，认为每个事件的发生，包括人类的认知、举止、决定和行动，都是因为先前的事而有原因地发生。\n教条主义 指那些我们所相信的、不容质疑的观念。宗教上指那些具有权威性的团体所确立的教理，信徒以此作为应该学习的真理课程。\n二元论 二元论认为世界由两种力量统治：善与恶。善是精神，是灵魂，是善的力量创造的一切东西;而恶是物质，是肉体，是恶的力量创造的一切。这两种力量对抗着，共同支配世界。\n折衷主义 折衷主义是指操作运用不同的理论、方法、风格，拣选其中最佳要素，应用在新的创作中。在艺术或建筑批评等特定领域，指挪借多种视觉资源来创作新作品。\n平均主义 平均主义要求平均分享一切社会财富，对人人应该予以同样、平等对待。\n情感主义 情感主义是 20 世纪 30 年代，英美等国最流行的一种元伦理学，它否认伦理学的科学地位，主张道德是个人情感的表达，否认道德的客观性，认为道德判断没有合理的或有效的根据，没有真假之别，不过是表示某种情感、某种愿望。\n经验主义 经验主义指相信现代科学方法，认为理论应建立于对于事物的观察，通过实验研究而后进行理论归纳，优于单纯的逻辑推理、直觉或者先入为主的概念。\n副现象论（epiphenomenalism） 副现象论认为物理世界可以影响内心世界，但是反过来却不行。\n永恒论 永恒论认为时间不过是另外一个维度，明天已经存在了，只是你还没到那里而已。过去、现在、未来都一样真实。\n幸福主义 以幸福作为人生目的和理想的人生哲学。认为幸福包括物质生活和精神生活两个方面，人有追求幸福的权利，这是人的天性，人生的意义即在对于幸福的追求。\n存在主义 存在主义认为人存在的意义无法经由理性思考而得到答案，强调个人的主观经验。\n有序主义（extropy） 有序主义是相信科技进步可以解决人类问题的超人类主义思想之一。它认为随着科技的进步，总有一天人类可以得到永生。有序主义者愿意为了这个目的而努力，比如进行调查研究，志愿测试新技术等。\n女性主义 女性主义是指主要以女性经验为来源与动机的社会理论与政治运动。在对社会关系进行批判之外，许多女性主义的支持者也着重于性别不平等的分析以及推动妇女的权利、利益与议题。\n因果论（finalism） 因果论认为任何事物的发展都由预设好的既定结果来决定。\n自由意志 自由意志是指在社会、道德、政治的限制下，人们依照其拥有的条件去自主决定是否做一件事的能力。\n快乐主义 又称享乐主义。它倾向于用纯粹生物学的或心理学的观点来解释人的行为与需要，认为人们以求得快乐为生活目的，包括肉体与心灵的快乐。\n历史论 历史论认为去理解一个历史事件，我们必须考虑到当时的大环境和历史的上下文，而不是抽象地用概念去解释。\n唯心主义 唯心主义反对现实主义的哲学观，认为在人类的认知中，我们对物体的理解与感知，独立于物体的实际存在。\n个人主义 个人主义是一种道德的、政治的和社会的哲学，认为个人利益应是决定行为的最主要因素，强调个人自由和个人权利的重要性，超越集体如国家、种族、社会组织之上。\n神秘主义 也译作密契主义，包含人类与神明或某种超自然力量结合为一的各种形式、经验、体验，并且强调这是一切宗教共有的现象。神秘主义者的基本信条是世界上存在超自然的力量或隐藏的自然力量，这种力量可以通过特殊教育或者宗教仪式获得。\n自然主义 自然主义者认为自然的和超自然的都是一回事，可以用同一套方法来研究和解释。\n虚无主义 虚无主义作为哲学主义，为怀疑主义的极致形式，认为世界、生命(特别是人类)的存在是没有客观意义、目的以及可以理解的真相的。\n客观主义 在伦理学中，客观主义认为有些事情的对错是客观存在的。\n乐观主义 乐观主义是指一种对一切事物采与正面看法的观念。乐观的人不会想到一件事的缺点与瑕疵，永远以正面的想法对待身边的一切。\n泛神论 泛神论是一种将自然界与神等同起来，以强调自然界的至高无上的哲学观点。泛神论认为神就存在于自然界一切事物之中，并没有另外的超自然的主宰或精神力量。\n观点主义 观点主义认为人思想和价值判断来自不同的内心驱动和个人视角，并没有绝对的真理，只能去融合不同的观点。\n厌世主义 厌世主义，亦即悲观主义和虚无主义，是特定人群中所形成的一种无可奈何的悲观心理的反映。\n理性主义 理性主义是建立在承认人的理性可以作为知识来源的理论基础上的一种哲学方法，认为理性高于并独立于感官感知。\n相对主义 相对主义不是一个单一的学说，而是一系列观点，其共同的主题是，经验、思想、价值总是相对于其他东西而成立的，没有什么绝对的真理或评判标准。\n怀疑论 怀疑论是一种认识论，是认识问题的一种态度，它拒绝对问题作随意的不够严格的定论，对事物的看法采取一种类于“中立”的立场，既怀疑“是”也怀疑“不是”。怀疑论的反面是迷信，或更确切地说是独断论。\n斯多葛主义 斯多葛主义认为，重要的是在任何情况下都必须保持沉着，学会情感和生理的自我控制，以求得内心的平和与力量，获得更好的生活。斯多葛主义认为它的对立面激情是“背离理性和违反自然的精神冲动”。\n结构主义 结构主义认为任何一个现象都必须在知道了语境和上下文和他们之间的相互关系后才能被真正理解。\n融合主义 融合主义倡导不同宗教信仰或哲学主张之间的融合。\n有神论 广义上的有神论认为至少存在一个神明。狭义上特指一神论信仰，认为世界有一位至高的神明，关注于宇宙与这位神明之间的关系。\n功利主义 功利主义提倡追求大多数人的最大幸福，如果需要牺牲少部分人的利益也没办法。\n生命力论（活力论） 生命力论在人类历史上存在长久的历史，现代版本是19世纪初由瑞典化学家贝采利乌斯提出的，认为生命的运作，不只依循物理及化学定律。生命有自我决定的能力。\n新柏拉图主义 新柏拉图主义认为，世界有两极，一端是被称为“上帝”的神圣之光，另一端则是完全的黑暗。但新柏拉图主义也相信，完全的黑暗并不存在，只是缺乏亮光而已。\n柏拉图主义 尤指宣称理念形式是绝对的和永恒的实在，而世界中实在的现象却是不完美的和暂时的反映。\n伊壁鸠鲁学派 伊壁鸠鲁派认为并宣扬人死魂灭，这是人类思想史上的一大进步，同时提倡寻求快乐和幸福。但他们所主张的快乐决非肉欲物质享受之乐，而是排除情感困扰后的心灵宁静之乐。伊壁鸠鲁派生活简朴而又节制，目的就是要抵制奢侈生活对一个人身心的侵袭。\n斯多亚主义 斯多葛派认为世界理性决定事物的发展变化。所谓\u0026quot;世界理性\u0026quot;，就是神性，它是世界的主宰，个人只不过是神的整体中的一分子。在社会生活中斯多葛派强调顺从天命,要安于自己在社会中所处的地位，要恬淡寡欲，只有这样才能得到幸福。\n工具主义 工具主义的实践理性观可以表达为：理性指导人们的实践，是并且只是通过告诉人们采用何种必要的手段以达到既定目的来完成的，但是这些既定目的是否合适则不受理性的批判。\n世界主义 世界主义相信所有的人类都属于一个基于同样道德观念的社群，。世界主义的社群包括一个包容性的道德规范，共享的经济体制，和一个包含所有国家的政治结构。社群之中来自世界各地的人通过彼此的敬意来建立关系。\n加速主义 指一种政治与社会理论，认为资本主义制度或历史上某种技术相关的社会进程应该被加速以产生巨大社会变革。\n国际主义 国际主义是指各国无产阶级在反对剥削制度，争取自身解放斗争中，在政治、经济、道义等方面互相支持，互相援助，坚持国际团结的思想和政治原则。国际主义体现了无产阶级的民族观，是无产阶级处理民族问题的基本原则，也是无产阶级认识和处理各国无产阶级之间、各国无产阶级政党之间以及社会主义国家之间相互关系的行为准则。资本压迫和统治的国际性，决定了无产阶级反对资产阶级的斗争，从形式上看，首先是在一国范围内进行，但从内容上看，从来就是国际性的:无产阶级只有解放全人类，才能最后解放自己。\n沙文主义 沙文主义是资产阶级侵略性的民族主义。18世纪末、19世纪初产生于法国，因法国士兵沙文（Nicolas Chauvin）狂热拥护拿破仑一世的侵略扩张政策，主张用暴力建立法兰西帝国而得名。它鼓吹法兰西民族是世界上最优秀的民族，宣扬本民族利益高于一切，煽动民族之间的仇恨，主张征服和奴役其他民族。在帝国主义时代，沙文主义是帝国主义侵略和压迫其他国家和民族的舆论工具。\n民族主义 民族主义，即指以自我民族的利益为基础而进行的思想或运动。在近代以来，民族主义推动了民族解放与平等，是现代国际社会的源泉。美国学者汉斯·科恩认为：“民族主义首先而且最重要的是应该被看作是一种思想状态。”英国学者爱德华·卡尔认为：“民族主义通常被用来表示个人、群体和一个民族内部成员的一种意识，或者是增进自我民族的力量、自由或财富的一种愿望”。民族主义通常是指以维护本民族利益和尊严为出发点的思想与行为\n民粹主义 民粹主义（populism），又译平民主义，是在19世纪的俄国兴起的一股社会思潮。民粹主义的基本理论包括：强调平民群众的价值和理想，把平民化和大众化作为政治运动和政治制度合法性的最终来源；依靠平民大众对社会进行改革，并把普通群众当作政治改革的决定性力量；通过强调诸如平民的统一、全民公决、人民的创制权等民粹主义价值，对平民大众从整体上实施有效的控制和操纵。\n法西斯主义 法西斯主义（英语：Fascism；俄语：фашизм；意大利语：Fascismo；德语：Faschismus；西班牙语：Fascismo）是一种结合了社团主义、工团主义、独裁主义、极端民族主义、中央集权形式的军国主义、反无政府主义、反自由放任的资本主义、和反共产主义政治哲学；《大英百科全书》对法西斯主义的定义：“个人的地位被压制于集体—例如：某个国家、民族、种族、或社会阶级之下的社会组织。”\n纳粹主义 纳粹主义，是德文“Nationalsozialismus”缩写“Nazismus”的音译，意译为“民族社会主义”。\n纳粹主义意识形态的精神是“属于一个民族”，纳粹主义的基本理论包括：种族优秀论，“优等种族”至上；一切领域的“领袖”原则，“领袖”是国家整体意志的代表；反对英法资本主义体系以及共产主义思想体系，抵制共产主义理论。\n种族主义 种族主义是一种自我为中心的态度，认为种族差异决定人类社会历史和文化发展，认为自己所属的团体，例如人种、民族或国家，优越于其他的团体。\n修正主义 修正主义是在共产主义运动之中歪曲、篡改、否定马克思主义的一类资产阶级思潮和政治势力，是国际工人运动中打着马克思主义旗号反对马克思主义的机会主义思潮。“修正“一词来源于拉丁文reisio，意思是“修改、重新审查”。 修正主义产生于十九世纪九十年代。其社会基础是资本主义“和平”发展时期逐步形成起来的工人贵族阶层以及补充到工人阶级队伍中的小资产阶级。\n改良主义 改良主义是一种试图以非革命手段解决资本主义社会矛盾的资产阶级和小资产阶级思潮。这种思潮宣扬阶级合作，主张在保存资本主义制度的前提下，实行局部的微小的社会改良; 反对暴力革命和无产阶级专政，主张通过法令和立法途径实行社会改革，变资本主义为“普遍福利”社会。\n社会民主主义 社会民主主义是社会思潮和社会运动。它反映和代表了各国社会党 (包括社会民主党、工党) 及其国际联合组织“社会党国际” 解决社会矛盾问题、处理政治问题的共同的基本主张、基本观点、基本理论和方法，是各国社会党思想体系的统称。\n社会民主主义思潮最初于19世纪中叶诞生于欧洲，作为对资本剥削和侮辱劳动阶级的反抗运动，迄今已存在了一个半世纪之久。在一百五十余年的风风雨雨中，社会民主主义已经历了由理论到实践，由欧洲到世界的发展过程，愈益发展壮大。\n孤立主义 孤立主义，是一种外交政策。它通常由防务和经济上的两方面政策组成。在防务上，孤立主义采取不干涉原则，即除自卫战争外不主动卷入任何外部军事冲突；在经济文化上，通过立法最大程度限制与国外的贸易和文化交流。\n单边主义 所谓单边主义是指举足轻重的特定大国，不考虑大多数国家和民众的愿望，单独或带头退出或挑战已制订或商议好了的维护国际性、地区性、集体性和平、发展、进步的规则和制度，并对全局或局部的和平、发展、进步有破坏性的影响和后果的行为与倾向。\n多边主义 多边主义原是指不完全依赖俄罗斯或者独联体内部来解决问题而是谋求多边发展利用外部世界一切可能利用的因素和机会既为自己吸收更多的发展动力又可避免单方面依赖而受制于俄罗斯。现指三个或三个以上国家之间发生联系的方式。\n实用主义 冯友兰总结的实用主义主要观点最为简洁明了。在《三松堂自序》中冯说：“实用主义的特点在于它的真理论。它的真理论实际是一种不可知论。认识来源于经验，人们所能认识的，只限于经验，至于经验的背后还有什么东西，那是不可知的，也不必问这个问题。这个问题是没有意义的，因为无论怎么说，人们总是不能走出经验范围之外而有什么认识。要解决这个问题，还得靠经验。所谓真理，无非就是对于经验的一种解释，对于复杂的经验解释得通。如果解释得通，它就是真理，对于我们有用，即有用就是真理，忽略所谓客观的真理。”如此说得之，实用二字昭然若揭。\n计算机科学 符号主义 符号主义（Symbolism）是一种基于逻辑推理的智能模拟方法，又称为逻辑主义(Logicism)、心理学派(Psychlogism)或计算机学派(Computerism)，其原理主要为物理符号系统（即符号操作系统）假设和有限合理性原理，长期以来，一直在人工智能中处于主导地位，其代表人物是纽威尔、肖、西蒙和尼尔森。\n连接主义 连接主义(connectionism)，又称为仿生学派或生理学派，其主要原理为神经网络及神经网络间的连接机制与学习算法。\n行为主义 行为主义(actionism)，又称为进化主义或控制论学派，其原理为控制论及感知-动作型控制系统。\n文艺 文学 都合主义 剧情、人物、设定等为主角服务而无视因果、设定，这就是都合主义。\n魔幻现实主义 魔幻现实主义作为拉丁美洲所特有的文学样式，它具有与众不同的鲜明而独特的特征。将新闻报道般的写实与神奇的幻想结合起来，采用模糊化技巧和神话模式，表现拉丁美洲的历史文化和现实生活。这是魔幻现实主义突出的艺术特征。\n美术 浪漫主义 这一画派摆脱了当时学院派和古典主义的羁绊，偏重于发挥艺术家自己的想象和创造，创作题材取自现实生活，中世纪传说和文学名著（如莎士比亚、但丁、歌德、拜伦的作品）等，有一定的进步性。\n印象派 不依据可靠的知识，以瞬间的印象作画。画家们是抓住一个具有特点的侧面去作画，所以他们必须疾飞画笔把颜色直接涂在画布上，他们只能多考虑画的总体效果，较少的顾及枝节细部。印象主义的以粗放的笔法作画，作品缺乏修饰，是一种对笔法较草率的画法。\n印象主义采取在户外阳光下直接描绘景物，追求以思维来揣摩光与色的变化，并将瞬间的光感依据自己脑海中的处理附之于画布之上，这种对光线和色彩的揣摩也是达到了色彩和光感美的极致。\n画家：莫奈、马奈、毕沙罗、雷诺阿、 西斯莱、德加、科罗、莫里索、巴齐约\n点彩派（新印象派） 他们不用轮廓线划分形象，而用点状的小笔触，通过合乎科学的光色规律的并置，让无数小色点在观者视觉中混合，从而构成色点组成的形象，被一些艺术评论家称作“点彩派”。\n画家：乔治·修拉、保罗·西涅克、卡米尔·毕沙罗、M. 吕斯、H.-E.克罗斯\n新艺术派 简单讲就是喜欢画些清新脱俗的花草纹样，而且喜欢勾线，还经常画得扁扁平平的。女人头上长花是常有的事，当然，驴头上也可以长。\n画家：慕夏\n野兽派 顾名思义，就是像野兽一样狂放，这一派画家基本是不调色的，颜料挤出来就直接用，而且形状也是粗矿得很。国内的幼儿园墙画深得这种风格的真传。\n画家：马蒂斯\n风格派 风格派完全拒绝使用任何的具象元素，主张用纯粹几何形的抽象来表现纯粹的精神。认为抛开具体描绘,抛开细节，才能避免个别性和特殊性，获得人类共通的纯粹精神表现。\n画家：蒙德里安\n构成主义 简单讲，这个派别特备喜欢画立体块块和几何图形，而且喜欢乱摆。\n画家：里茨斯基\n超现实主义 简单讲就是觉得现实不重要，专门画现实里没有的东西。比如，为什么驴就不能长得像鱼呢？\n画家：达利\n表现主义 表现主义是艺术家通过作品着重表现内心的情感，而忽视对描写对象形式的摹写，因此往往表现为对现实的扭曲和抽象化，这个做法尤其用来表达恐惧的情感，因此，主题欢快的表现主义作品很少见。\n画家：席勒\n抽象表现主义 抽象表现主义是指一种结合了抽象形式和表现主义画家情感价值取向的非写实性绘画风格。\n该运动存在着多样的绘画风格，画风多半大胆粗犷、尖锐且尺幅巨大。画作色彩强烈，并经常出现偶然效果，例如让油彩自然流淌而不加以限制。\n画家：波洛克\n立体派 主要目的是追求一种几何形体的美，在形式的排列组合所产生的美感。 它否定了从一个视点观察事物和表现事物的传统方法，把三度空间的画面归结成平面。因为把不同视点所观察和理解的形诉诸于画面，从而表现出时间的持续性。\n画家：毕加索\n未来派 未来派全盘否定传统文艺的价值，认为人类的文化遗产和现存的文化都是腐朽、僵死，与现时代的精神不相容的。他们的口号是“摒弃一切博物馆、图书馆和学院”，反对一切模仿的形式，反抗和谐和趣味高雅，否定艺术批评的作用。未来派的美学主张与表现主义、立体主义有相同的地方，只是他们特别强调表现运动和力量，口号更激烈，纲领更明确，虚无主义的色彩更浓郁。\n他们觉得不能只表现静态的东西，画什么都要动起来、嗨起来，所以一个驴子可能带着七八个形状各异的残影。\n画家：波丘尼\n达达主义 达达主义是20世纪初期在欧洲兴起的虚无主义运动，是一种无政府主义的艺术运动，其艺术特点如下:\n1.反传统观念，公开蔑视文学艺术的一切现有形式，反秩序，反系统化\n2.运用理性的方法抨击人类，将人性化的内容与机械原理结合起来，并使用现成品作为艺术创作\n3.艺术手法抽象怪异，完全突破了已有的艺术观念和形式的束缚，被认为是后现代主义的创作者\n4.代表画家 杜尚，法国艺术家，被誉为\u0026quot;现代艺术的守护神\u0026quot;，其代表作是《下楼梯的裸女二号》，《泉》\n波普艺术 波普艺术，一种主要源于商业美术形式的艺术风格，其特点是将大众文化的一些细节，如连环画、快餐及印有商标的包装进行放大复制。\n画家：安迪·沃霍尔\n极简主义 顾名思义就是能省就省，企图以最少的东西表达最多的含义，能用一双眼睛搞定何必要画一整头驴呢？\n画家：纽曼\n概念艺术 概念艺术就是在20世纪60年代中后期出现，其基本概念源于马塞尔·杜尚的思想：一件艺术品从根本上说是艺术家的思想，而不是有形的实物，即绘画和雕塑；有形的实物出自那种思想。这种艺术导致以观念取代实物、是艺术摆脱物质的艺术品。\n画家：杜尚\n后现代主义 是一种对现代表达方式甚至思维方式以及价值观的颠覆和反叛。\n音乐 巴洛克时期 音乐领域中的巴洛克时期，如同其他艺术领域一样，也体现了各种不同的风格。 这段时期的音乐中没有太多的思想，讲究韵律的优美。歌剧、清唱剧和大合唱是声乐方面最重要的一些新形式，而奏鸣曲、协奏曲和前奏曲则是为器乐而创作的。\n古典主义时期 其特点是：理智和情感的高度统一，深刻的思想内容与完美的艺术形式的高度统一。创作技法上，继承欧洲传统的复调与主调音乐的成就，并确立了近代奏鸣曲曲式的结构以及交响曲、协奏曲、各类室内乐的体裁和形式，对西洋音乐的发展有深远影响。\n浪漫主义时期 这个时期艺术家的创作上则表现为对主观感情的崇尚，对自然的热爱和对未来的幻想。艺术表现形式也较以前有了新的变化，出现了浪漫主义思潮与风格的形成与发展。\n注：本文有许多内容搜集自互联网，若有侵权请联系删除。\n","date":"2021-01-17T23:25:28Z","permalink":"https://kegalas.top/p/%E5%90%84%E7%A7%8D%E4%B8%BB%E4%B9%89%E6%95%B4%E7%90%86/","title":"各种主义整理"},{"content":"系统：Ubuntu 20.10\n今天使用Ubuntu，想安装一下deepin的qq，在网上找到以下方法：\nwget -O- https://deepin-wine.i-m.dev/setup.sh | sh 正常执行\nsudo apt-get install com.qq.im.deepin 报错：\n下列软件包有未满足的依赖关系： libgirepository-1.0-1 : 破坏: python-gi (\u0026lt; 3.34.0-4~) 但是 3.30.4-1 正要被安装 E: 无法修正错误，因为您要求某些软件包保持现状，就是它们破坏了软件包间的依赖关系。 我试着安装python-gi，同样报错，我又试着删了libgirepository-1.0-1，但是他是很多包的依赖，不敢删。\n百度搜索无果，bing搜索外国也没找到解决办法，倒是有人遇到了同样的问题。\n在ubuntu搜集信息后，发现libgirepository-1.0-1依赖于libffi7，但是apt下载不到他，只能去https://packages.ubuntu.com/zh-cn/focal/libffi7手动下载。安装完后又去https://packages.ubuntu.com/zh-cn/focal/python-gi手动下载python-gi，先后安装成功。\n再次安装qq，重启，安装成功。\n但是发现字体显示不全。找了个网站下载了simsun.ttc，放到~/.deepinwine/Deepin-QQ/drive_c/windows/Fonts/\n问题解决。\n图片 1\r后记：现在linux下qq有官方支持的新版本了，应该没人再用这个了吧。\n","date":"2021-01-03T12:16:26Z","image":"https://kegalas.top/p/ubuntu%E5%AE%89%E8%A3%85deepin-qq%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E4%B8%8E%E8%A7%A3%E5%86%B3/cover_huadd5fdafa4a185a8686ebe054dd413b9_24301_120x120_fill_q75_box_smart1.jpg","permalink":"https://kegalas.top/p/ubuntu%E5%AE%89%E8%A3%85deepin-qq%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E4%B8%8E%E8%A7%A3%E5%86%B3/","title":"ubuntu安装deepin-qq时遇到的问题与解决"},{"content":"[TOC]\n不等式 均值不等式 \\(H_n\\) 为调和平均数、 ​\\(G_n\\) 为几何平均数、 ​\\(A_n\\) 为算数平均数、 ​\\(Q_n\\) 为平方平均数。 ​任意\\(x_i\u003e 0\\)都成立时，有 ​\n\\[H_n=\\frac{n}{\\sum\\limits_{i=1}^n\\frac{1}{x_i}}=\\frac{n}{\\frac{1}{x_1}+\\frac{1}{x_2}+\\dots+\\frac{1}{x_n}} \\]\n​\n\\[G_n=\\sqrt[n]{\\prod_{i=1}^{n}x_i}=\\sqrt[n]{x_1 x_2 \\dots x_n} \\]\n​\n\\[A_n=\\frac{\\sum\\limits_{i=1}^{n}x_i}{n}=\\frac{x_1+x_2+\\dots+x_n}{n} \\]\n​\n\\[Q_n=\\sqrt{\\frac{\\sum\\limits_{i=1}^{n}x_i^{2}}{n}}=\\sqrt{\\frac{x_1^{2}+x_2^{2}+\\dots+x_n^{2}}{n}} \\]\n​\n\\[H_n\\leq G_n\\leq A_n\\leq Q_n \\]\n当且仅 当\\(x_1=x_2=\\dots =x_n\\)时取等号\n对数平均不等式 \\(a\\neq b\\)时，有 ​\n\\[\\sqrt{ab}\u003c\\frac{a-b}{lna-lnb}\u003c\\frac{a+b}{2} \\]\n柯西不等式 \\[\\sum\\limits_{i=1}^{n}a_i^{2}\\sum\\limits_{i=1}^{n}b_i^{2}\\geq (\\sum\\limits_{i=1}^{n}a_i b_i)^2 \\]\n​当且仅当\\(\\frac{a_1}{b_1}=\\frac{a_2}{b_2}=\\dots =\\frac{a_n}{b_n}\\)时取等号 ​其中二维形式如下 ​\n\\[(a^2+b^2)(c^2+d^2)\\geq (ac+bd)^2 \\]\n​当且仅当\\(ad=bc\\)即\\(\\frac{a}{c}=\\frac{b}{d}\\)时取等\n排序不等式 ​排序不等式表示如下 ​\n设有两组数\\(a_1,a_2,\\dots,a_n\\)和\\(b_1,b_2,\\dots,b_n\\)，满足\\(a_1\\leq a_2\\leq \\dots \\leq a_n\\)且\\(b_1\\leq b_2\\leq \\dots \\leq b_n\\)，\\(c_1,c_2,\\dots,c_n\\)是\\(b_1,b_2,\\dots,b_n\\)的乱序排列，则有： ​ ​\n\\[a_1 b_n+a_2 b_{n-1}+\\dots+a_n b_1\\leq a_1 c_1+a_2 c_2+\\dots+a_n c_n\\leq a_1 b_1+a_2 b_2+\\dots+a_n b_n \\]\n​ ​当且仅当\\(a_1=a_2=\\dots=a_n\\)或\\(b_1=b_2=\\dots=b_n\\)时取等号。便于记忆，常记为：反序和\\(\\leq\\)乱序和\\(\\leq\\)顺序和\n权方和不等式 ​若\\(a_i\u003e0\\)，\\(b_i\u003e0\\)，\\(m\u003e0\\)，则有 ​\n\\[\\sum\\limits_{i=1}^{n}\\frac{a_i^{m+1}}{b_i^{m}}\\geq \\frac{\\left (\\sum\\limits_{i=1}^{n}a_i\\right) ^{m+1}}{\\left (\\sum\\limits_{i=1}^{n}b_i\\right) ^m} \\]\n即为 ​\n\\[\\frac{a_1^{m+1}}{b_1^{m}}+\\frac{a_2^{m+1}}{b_2^{m}}+\\dots+\\frac{a_n^{m+1}}{b_n^{m}}\\geq \\frac{(a_1+a_2+\\dots+a_n)^{m+1}}{(b_1+b_2+\\dots+b_n)^{m}} \\]\n​当且仅当\\(a_i=\\lambda b_i\\)时取等号其中二维形式如下对于正数\\(a\\)，\\(b\\)，\\(x\\)，\\(y\\)，有 ​\n\\[\\frac{a^2}{x}+\\frac{b^2}{y}\\geq \\frac{(a+b)^2}{x+y} \\]\n​当且仅当\\(a:b=x:y\\)时取等号也有 ​\n\\[\\frac{a^2}{ax}+\\frac{b^2}{by}=\\frac{a}{x}+\\frac{b}{y}\\geq \\frac{(a+b)^2}{ax+by} \\]\n​当且仅当\\(x=y\\)时取等号\n舒尔不等式 ​\\(a,b,c\\geq 0\\quad t\\in R\\)时，有 ​\n\\[a^t (a-b)(a-c)+b^t (b-a)(b-c)+c^t (c-a)(c-b)\\geq 0 \\]\n​当且仅当\\(a=b=c\\)，或其中两个数相等且另一个等于零时，取等号。特别的，当\\(t\\)为非负偶数时，此不等式对任意实数\\(a,b,c\\)成立。\n琴生不等式 设\\(f(x)\\)在区间\\(I\\)上是下凸函数，则对任意\\(x_i\\in I\\)及\\(p_i\u003e0\\quad (i=1,2,\\dots,n)\\)，有 ​\n\\[\\frac{\\sum\\limits_{i=1}^{n}p_i\\cdot f(x_i)}{\\sum\\limits_{i=1}^{n}p_i}\\geq f \\left (\\frac{\\sum\\limits_{i=1}^{n}p_i\\cdot x_i}{\\sum\\limits_{i=1}^{n}p_i} \\right ) \\]\n​其中等号当且仅当\\(x_1=x_2=\\dots=x_n\\)时成立，若\\(f(x)\\)在区间\\(I\\)上是上凸函数，则不等号反向。\n绝对值不等式 ​\n\\[||a|-|b|| \\leq |a\\pm b| \\leq |a|+|b| \\]\n糖水不等式 \\[\\frac{b+c}{a+c}\u003e\\frac{b}{a}(a\u003eb\u003e0,c\u003e0) \\]\n\\[\\frac{b+c}{a+c}\u003c\\frac{b}{a}(b\u003ea\u003e0,c\u003e0) \\]\n函数 拉格朗日中值定理 ​设\\(y=f(x)\\)在\\([a,b]\\)上连续，在\\((a,b)\\)上可导，则存在\\(\\xi \\in (a,b)\\)使得 ​\n\\[f^{'}(\\xi)=\\frac{f(b)-f(a)}{b-a} \\]\n拉格朗日乘数法 ​【例题】若正数\\(a,b\\)满足\\(2a+b=1\\)，则\\(\\frac{a}{2-2a}+\\frac{b}{2-b}\\)的最小值为? ​\n解：构造拉格朗日函数 ​\n\\[L(a,b,\\lambda)=\\frac{a}{2-2a}+\\frac{b}{2-b}-\\lambda(2a+b-1) \\]\n令 ​\n\\[\\frac{\\partial L}{\\partial a}=L_a=\\frac{1}{2(1-a)^2}-2\\lambda=0 \\]\n\\[\\frac{\\partial L}{\\partial b}=L_b=\\frac{2}{(2-b)^2}-\\lambda=0 \\]\n​\n\\[\\frac{\\partial L}{\\partial \\lambda}=L_\\lambda=-(2a+b-1)=0 \\]\n联立解得 ​\n\\[a=\\frac{5-3\\sqrt{2}}{2},b=3\\sqrt{2}-4,\\lambda=\\frac{1}{27-18\\sqrt{2}} \\]\n​从而 ​\n\\[\\frac{a}{2-2a}+\\frac{b}{2-b}=\\frac{2\\sqrt{2}}{3}-\\frac{1}{2} \\]\n​此即为所求的最小值。\n高次韦达定理 ​设\\(x_1,x_2,\\dots,x_n\\)为如下方程的根 ​\n\\[a_n x^n+a_{n-1} x^{n-1}+\\dots+a_1 x+a_0=0 \\]\n​则有 ​\n\\[x_1+x_2+\\dots+x_n=-\\frac{a_{n-1}}{a_n} \\]\n\\[x_1 x_2+x_1 x_3+\\dots+x_n x_{n-1}=\\frac{a_{n-2}}{a_n} \\]\n​\n\\[\\dots \\]\n​\n\\[x_1 x_2\\dots x_n=(-1)^n \\frac{a_0}{a_n} \\]\n​其中三次的形式如下若\\(ax^3+bx^2+cx+d=0\\ (a\\neq 0)\\)的3个根分别为\\(x_1,x_2,x_3\\)则有 ​\n\\[x_1+x_2+x_3=-\\frac{b}{a} \\]\n​\n\\[x_1 x_2+x_1 x_3+x_2 x_3=\\frac{c}{a} \\]\n​\n\\[x_1\\cdot x_2\\cdot x_3=-\\frac{d}{a} \\]\n泰勒展开 ​若函数\\(f(x)\\)在\\(x_0\\)存在\\(n\\)阶导数，则有 ​\n\\[f(x)=f(x_0)+\\frac{f'(x_0)}{1!}(x-x_0)+\\frac{f''(x_0)}{2!}(x-x_0)^2+\\dots+\\frac{f^{(n)} (x_0)}{n!}(x-x_0)^n+R_{n+1} \\]\n​上式即为函数\\(f(x)\\)在\\(x_0\\)处的泰勒展开式，其中\\(R_{n+1}=\\frac{f^{(n+1)} (\\xi)}{(n+1)!}(x-x_0)^{n+1}\\)（其中\\(\\xi\\)介于\\(x\\)和\\(x_0\\)间）叫做拉格朗日余项。\n​拉格朗日余项可用于证明不等式。如：\\(-1\u003c x\u003c1\\)时 ​\n\\[\\ln(1+x)=x-\\frac{x^2}{2}+\\frac{x^3}{3}-\\frac{x^4}{4(1+\\xi)^4} (-1\u003c\\xi\u003c1) \\]\n​因为\\(-\\frac{x^4}{4(1+\\xi)^4}\\leq 0\\)，所以\\(\\ln(1+x)\\leq x-\\frac{x^2}{2}+\\frac{x^3}{3}\\)\n极值点偏移 ​【例题】已知函数\\(f(x)=e^x-ax\\)有两个零点\\(x_1\\)和\\(x_2\\)，证明：\\(x_1 +x_2 \u003e2\\) ​\n\\[f(x)=e^x-ax=0\\Leftrightarrow \\frac{e^x}{x}=a \\]\n​令\n\\[\\varphi(x)=\\frac{e^x}{x} \\]\n​则\n\\[f(x_1)=f(x_2)\\Leftrightarrow\\varphi(x_1)=\\varphi(x_2),\\quad \\varphi'(x)=\\frac{(x-1)e^x}{x^2} \\]\n因此\\(\\varphi(x)\\)在\\((0,1)\\)单减，\\((1,+\\infty)\\)单增，不妨设\\(0\u003c x_1\u003c1\u003c x_2\\)，则\\(x_1+x_2\u003e2\\Leftrightarrow x_2\u003e2-x_1\\)，注意到\\(2-x_1\u003e1\\Leftrightarrow\\varphi(x_2)\u003e\\varphi(2-x_1)\\)，注意到\\(\\varphi(x_1)=\\varphi(x_2)\\)，则\\(\\varphi(x_1)\u003e\\varphi(2-x_1)\\)，其中\\(0\u003c x_1\u003c1\\)\n令\n\\[g(x)=\\varphi(x)-\\varphi(2-x), \\quad 0\u003c x\u003c1 \\]\n​ 易知 ​\n\\[g'(x)\u003c0 \\]\n​所以\\(g(x)\\)在\\((0,1)\\)上单减，\\(g(x)\u003eg(1)=\\varphi(1)-\\varphi(1)=0\\)，即\\(\\varphi(x)-\\varphi(2-x)\u003e0\\)，令\\(x=x_1\\)，Q.E.D.\n最值函数基本定理 定理一: ​\n\\[min\\{a,b \\} \\leq \\frac{a+b}{2} \\leq max\\{a,b \\} \\]\n​\n\\[min\\{a,b\\}\\leq\\sqrt{ab}\\leq max\\{a,b\\}.(a\u003e0,b\u003e0) \\]\n定理二： ​\n\\[max\\{\\left|a+b\\right|,\\left|a-b\\right| \\}=|a|+|b| \\]\n​\n\\[min\\{\\left|a+b\\right|,\\left|a-b\\right| \\}=||a|-|b|| \\]\n​定理三： ​\n\\[max\\{|a|,|b|\\}=\\frac{|a+b|}{2}+\\frac{|a-b|}{2} \\]\n​\n\\[min\\{|a|,|b|\\}=\\left|\\frac{|a+b|}{2}-\\frac{|a-b|}{2}\\right| \\]\n数列 不动点原理 ​【例题】求\\(a_1 = 1 , a_{n+1}=2a_n +1\\)的通项公式，其特征函数为\\(f(x)=2x+1\\)，令\\(f(x)=x\\),解得\\(x=-1\\)，带入得\\(a_{n+1}-(-1)=2(a_n-(-1))\\)，即\\(a_{n+1}+1=2(a_n+1)\\)，之后根据等比数列可得\\(a_n=2^n -1\\)\n组合数学 容斥原理 ​建议根据韦恩图解题\n伯努利装错信封问题 ​n封信与n个信封全部错位的组合数为 ​\n\\[f(n)=n!\\left[ \\frac{1}{2!}-\\frac{1}{3!}+\\frac{1}{4!}-\\dots +(-1)^n \\frac{1}{n!} \\right] \\]\n向量 极化恒等式 ​重要恒等式:\\(4ab=(a+b)^2-(a-b)^2\\) ​\n极化恒等式:\\(4\\boldsymbol{a}\\cdot \\boldsymbol{b}=(\\boldsymbol{a}+\\boldsymbol{b})^2-(\\boldsymbol{a}-\\boldsymbol{b})^2\\)\n分点恒等式 ​在\\(\\triangle ABC\\)中，M为BC上一等分点，当\\(\\overrightarrow{BM}=\\lambda \\overrightarrow{MC}时\\)，有 ​\n\\[\\overrightarrow{AM}=\\frac{1}{1+\\lambda}\\overrightarrow{AB}+\\frac{\\lambda}{1+\\lambda}\\overrightarrow{AC} \\]\n三点共线定理 在平面中A、B、P三点共线的充要条件是：对于该平面内任意一点O，存在唯一的实数\\(x,y\\)使得： ​\n\\[\\overrightarrow{OP}=x\\overrightarrow{OA}+y\\overrightarrow{OB} \\]\n且 ​\n\\[x+y=1 \\]\n​特别的有：当P在线段AB上时，\\(x\u003e0,y\u003e0\\)，P在线段AB之外时,\\(xy\u003c0\\)\n向量中值定理 在\\(\\triangle ABC\\)中，M为BC的中点，则 ​\n\\[AB^2+AC^2=2(AM^2+BM^2) \\]\n对应的向量公式有: ​\n\\[\\boldsymbol{a}^2+\\boldsymbol{b}^2=2\\left[\\left(\\frac{\\boldsymbol{a}+\\boldsymbol{b}}{2}\\right)^2 + \\left(\\frac{\\boldsymbol{a}-\\boldsymbol{b}}{2}\\right)^2 \\right] \\]\n向量数乘余弦定理 在\\(\\triangle ABC\\)中,有 ​\n\\[\\overrightarrow{AB}\\cdot \\overrightarrow{AC}=\\frac{AB^2+AC^2-BC^2}{2} \\]\n三角 和差化积 ​\n\\[sin\\alpha+sin\\beta=2sin\\frac{\\alpha+\\beta}{2}\\cdot cos\\frac{\\alpha-\\beta}{2} \\]\n​\n\\[sin\\alpha-sin\\beta=2cos\\frac{\\alpha+\\beta}{2}\\cdot sin\\frac{\\alpha-\\beta}{2} \\]\n​\n\\[cos\\alpha+cos\\beta=2cos\\frac{\\alpha+\\beta}{2}\\cdot cos\\frac{\\alpha-\\beta}{2} \\]\n​\n\\[cos\\alpha-cos\\beta=-2sin\\frac{\\alpha+\\beta}{2}\\cdot sin\\frac{\\alpha-\\beta}{2} \\]\n积化和差 ​\n\\[sin\\alpha cos\\beta=\\frac{1}{2}\\left[sin(\\alpha+\\beta)+sin(\\alpha-\\beta)\\right] \\]\n​\n\\[os\\alpha sin\\beta=\\frac{1}{2}\\left[sin(\\alpha+\\beta)-sin(\\alpha-\\beta)\\right] \\]\n​\n\\[cos\\alpha cos\\beta=\\frac{1}{2}\\left[cos(\\alpha+\\beta)+cos(\\alpha-\\beta)\\right] \\]\n​\n\\[sin\\alpha sin\\beta=-\\frac{1}{2}\\left[cos(\\alpha+\\beta)-cos(\\alpha-\\beta)\\right] \\]\n半角公式 \\[sin\\frac{\\theta}{2}=\\pm \\sqrt{\\frac{1-cos\\alpha}{2}} \\]\n​\n\\[sin\\frac{\\theta}{2}=\\pm \\sqrt{\\frac{1+cos\\alpha}{2}} \\]\n​\n\\[tan\\frac{\\theta}{2}=\\pm \\sqrt{\\frac{1-cos\\alpha}{1+cos\\alpha}}=\\frac{sin\\alpha}{1+cos\\alpha}=\\frac{1-cos\\alpha}{sin\\alpha} \\]\n辅助角公式 ​\n\\[asin\\theta\\pm bcos\\theta=\\sqrt{a^2+b^2}sin(\\theta\\pm\\varphi),\\quad tan\\varphi=\\frac{b}{a} \\]\n统计、概率、分布 期望、方差、标准差 数学期望：我们称\\(E\\xi = x_1 p_1+x_2 p_2+\\dots+x_n p_n\\)为离散型随机变量\\(\\xi\\)的数学期望 ​\n方差和标准差：我们称\\(D\\xi = \\sum_{i=1}^{n}(x_i-E\\xi)^2 p_i\\)为离散型随机变量\\(\\xi\\)的方差，其算数平方根\\(\\sqrt{D\\xi}=\\sigma\\xi\\)叫做离散型随机变量\\(\\xi\\)的标准差 ​\n​定理一： ​\n\\[E(a\\xi+b)=aE\\xi+b \\]\n​\n\\[D(a\\xi+b)=a^2 D\\xi \\]\n​ 定理二： ​\n\\[E(a\\xi _1+b\\xi _2)=aE\\xi _1+bE\\xi _2 \\]\n二项分布 n次试验中事件A恰好发生k次 ​\n\\[P(E) ={n \\choose k}p^k (1-p)^{n-k}\\quad k=1,2,3,\\dots \\]\n​我们称\\(\\xi\\)服从二项分布，记作\\(\\xi \\sim B(n,p)\\) ​\n定理：\\(E\\xi = np\\), \\(D\\xi = np(1-p)\\)\n正态分布 ​\n\\[f_\\xi (x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\sigma ^2}} \\quad x\\in R,\\sigma\u003e0 \\]\n​记作\\(\\xi \\sim N(\\mu,\\sigma ^2)\\) ​\n性质：\n其正态曲线关于\\(x=\\mu\\)对称，最高点为\\(\\frac{1}{\\sigma\\sqrt{2\\pi}}\\) \\(E\\xi=\\mu,D\\xi=\\sigma ^2\\) \\(\\sigma\\)越大，正态曲线越“矮胖”，表示分布越分散，\\(\\sigma\\)越小，正态曲线越“瘦高”，表示分布越集中 几何分布 ​在n次伯努利试验中，试验k次才得到第一次成功的机率。记为\\(P(\\xi=k)=g(k,p)=q^{k-1}p\\),其中\\(q=1-p\\)，也记为\\(\\xi \\sim GE(p)\\)\n定理：\\(E\\xi=\\frac{1}{p},D\\xi=\\frac{q}{p^2}\\)\n超几何分布 它描述了从有限N个物件（其中包含M个指定种类的物件）中抽出n个物件，成功抽出该指定种类的物件的次数（不放回），记为\\(\\eta \\sim H(n,M,N)\\) ​\n\\[P ( \\eta=m ) = \\frac{\\binom{M}{m}\\cdot \\binom{N-M}{n-m}}{\\binom{N}{n}}\\quad m=0,1,2,\\dots,min \\{ n,M \\} \\]\n其中有：\n\\[E(X)=\\frac{nM}{N} \\]\n\\[D(X)=\\frac{nM}{N}\\left(1-\\frac{M}{N}\\right)\\frac{N-n}{N-1} \\]\n方程 立方和分解 ​\n\\[a^3+b^3=(a+b)(a^2-ab+b^2) \\]\n立方差分解 \\[a^3-b^3=(a-b)(a^2+ab+b^2) \\]\n比例性质 ​若\\(\\frac{a}{b}=\\frac{c}{d}\\)则有：\n​合比性质\n\\[\\frac{a+b}{b}=\\frac{c+d}{d} \\]\n​分比性质\n\\[\\frac{a-b}{b}=\\frac{c-d}{d} \\]\n​合分比性质\n\\[\\frac{a+b}{a-b}=\\frac{c+d}{c-d} \\]\n​等比性质\n\\[\\frac{a}{b}=\\frac{c}{d}=\\frac{a+c}{b+d}=\\frac{ma+nc}{mb+nd} \\]\n几何 射影定理 ​射影定理，又称“欧几里德定理”：在直角三角形中，斜边上的高是两条直角边在斜边射影的比例中项，每一条直角边又是这条直角边在斜边上的射影和斜边的比例中项。 ​ ​在\\(Rt\\bigtriangleup ABC\\)中,\\(\\angle ABC=90^\\circ\\)，\\(BD\\)为斜边\\(AC\\)上的高，则有射影定理如下： ​\n\\[BD^2=AD\\cdot CD \\]\n\\[AB^2=AC\\cdot AD \\]\n\\[BC^2=CD\\cdot AC \\]\n阿波罗尼斯圆 ​平面内到两个定点的距离之比为常数\\(k(k\\neq1)\\)的点的轨迹是圆\n角平分线定理 在\\(\\bigtriangleup ABC\\)中，\\(AM\\)为\\(\\angle BAC\\)的角平分线，\\(M\\)在\\(BC\\)上，则有： ​\n\\[\\frac{AB}{AC}=\\frac{MB}{MC} \\]\n三角形五心 重心 ​三角形的三条边的中线交于一点，该点叫三角形的重心 ​\n重心的性质： ​\n重心到顶点的距离与重心到对边中点的距离之比为2:1。 重心和三角形任意两个顶点组成的3个三角形面积相等。即重心到三条边的距离与三条边的长成反比。 重心到三角形3个顶点距离的平方和最小。 在平面直角坐标系中，重心的坐标是顶点坐标的算术平均数，即其重心坐标为 ​ \\[P_1= ​ \\begin{bmatrix} ​ x_1\\\\ ​ y_1 ​ \\end{bmatrix} ​ P_2= ​ \\begin{bmatrix} ​ x_2\\\\ ​ y_2 ​ \\end{bmatrix} ​ p_3= ​ \\begin{bmatrix} ​ x_3\\\\ ​ y_3 ​ \\end{bmatrix} \\]\n\\[​ \\begin{bmatrix} ​ x\\\\ ​ y ​ \\end{bmatrix} ​ =\\frac{1}{3}(P_1+P_2+P_3)=\\frac{1}{3} ​ \\begin{bmatrix} ​ x_1+x_2+x_3\\\\ ​ y_1+y_2+y_3 ​ \\end{bmatrix} \\]\n以重心为起点，以三角形三顶点为终点的三条向量之和等于零向量。 外心 ​三角形外接圆的圆心，叫做三角形的外心。 ​\n外心的性质： ​\n三角形的三条边的垂直平分线交于一点，该点即为该三角形的外心。 若O是\\(\\bigtriangleup\\)ABC的外心，则\\(\\angle\\)BOC=2\\(\\angle\\)A（\\(\\angle\\)A为锐角或直角）或\\(\\angle\\)BOC=360°-2\\(\\angle\\)A（\\(\\angle\\)A为钝角）。 当三角形为锐角三角形时，外心在三角形内部；当三角形为钝角三角形时，外心在三角形外部；当三角形为直角三角形时，外心在斜边上，与斜边的中点重合。 外心到三顶点的距离相等 垂心 ​三角形的三条高（所在直线）交于一点，该点叫做三角形的垂心。 ​\n垂心的性质： ​\n三角形三个顶点，三个垂足，垂心这7个点可以得到6个四点圆。 三角形外心O、重心G和垂心H三点共线，且OG:GH=1:2。（此直线称为三角形的欧拉线（Euler line））（除正三角形） 垂心到三角形一顶点距离为此三角形外心到此顶点对边距离的2倍。 垂心分每条高线的两部分乘积相等 内心 ​三角形内切圆的圆心，叫做三角形的内心。 ​\n内心的性质： ​\n三角形的三条内角平分线交于一点。该点即为三角形的内心。 直角三角形的内心到边的距离等于两直角边的和与斜边的差的二分之一。 P为\\(\\bigtriangleup\\)ABC所在空间中任意一点，点O是ΔABC内心的充要条件是：\\(\\overrightarrow{PO}=(a×\\overrightarrow{PA} +b×\\overrightarrow{PB} +c×\\overrightarrow{PC} )/(a+b+c)\\). O为三角形的内心，A、B、C分别为三角形的三个顶点，延长AO交BC边于N，则有AO:ON=AB:BN=AC:CN=(AB+AC):BC (欧拉定理)⊿ABC中，R和r分别为外接圆为和内切圆的半径，O和I分别为其外心和内心，则\\(OI^2=R^2-2Rr\\)． （内角平分线分三边长度关系）△ABC中，0为内心，∠A 、∠B、 ∠C的内角平分线分别交BC、AC、AB于Q、P、R，则BQ/QC=c/b, CP/PA=a/c, BR/RA=a/b. 内心到三角形三边距离相等。 旁心 三角形的旁切圆（与三角形的一边和其他两边的延长线相切的圆）的圆心，叫做三角形的旁心。 ​\n旁心的性质： ​\n三角形一内角平分线和另外两顶点处的外角平分线交于一点，该点即为三角形的旁心。 每个三角形都有三个旁心。 旁心到三边的距离相等。 法向量叉乘求法 ​已知不共线的两个向量\\(\\boldsymbol{a}=(x_1,y_1,z_1)\\)，\\(\\boldsymbol{b}=(x_2,y_2,z_2)\\)\n​则它们所确定的平面的法向量为：\n​\n\\[\\bm{n}=(y_1 z_2-z_1 y_2,z_1 x_2-x_1 z_2,x_1 y_2-y_1 x_2) \\]\n方法 主元法 ​【例题】对任意\\(m\\in [-1,1]\\),函数\\(f(x)=x^2+(m-4)x+4-2m\\)的值恒大于零，求\\(x\\)的取值范围。 ​\n\\[f(x)=x^2+(m-4)x+4-2m=(x-2)m+x^2-4x+4 \\]\n​ 令 ​\n\\[g(m)=(x-2)m+x^2-4x+4 \\]\n​\n所以有 ​\n\\[\\begin{cases} ​ g(-1)=(x-2)(-1)+x^2-4x+4\u003e0 ​ \\\\ ​ g(1)=(x-2)\\cdot 1+x^2-4x+4\u003e0 ​ \\end{cases} \\]\n​解得\\(x\u003c1 \\)或 \\(x\u003e3\\)\n裂项 \\[\\frac{1}{n(n+1)}=\\frac{1}{n}-\\frac{1}{n+1} \\]\n​\n\\[\\frac{1}{n(n+1)(n+2)}=\\frac{1}{2}\\left[\\frac{1}{n(n+1)}-\\frac{1}{(n+1)(n+2)}\\right] \\]\n​\n\\[\\frac{1}{\\sqrt{n+1}+\\sqrt{n}}=\\sqrt{n+1}-\\sqrt{n} \\]\n​\n\\[a_n=(a_n-a_{n-1})+(a_{n-1}-a_{n-2})+\\dots+(a_2-a_1)+a_1 \\]\n​\n\\[a_n=\\frac{a_n}{a_{n-1}}\\bullet\\frac{a_{n-1}}{a_{n-2}}\\bullet\\dots\\bullet\\frac{a_2}{a_1}\\bullet a_1 \\]\n​\n\\[n\\cdot n!=(n+1)!-n! \\]\n​\n\\[C^{m}_{n}=C^{m}_{n+1}-C^{m-1}_{n} \\]\n​\n\\[n(n+1)=\\frac{1}{3}\\left[n(n+1)(n+2)-(n-1)n(n+1)\\right] \\]\n​\n\\[\\frac{1}{C^{1}_{n+1}C^{2}_{n}}=\\frac{2}{(n+1)n(n-1)}=\\frac{1}{n(n-1)}-\\frac{1}{(n+1)n} \\]\n​\n\\[\\frac{1}{2^n(2^n-1)}=\\frac{1}{2^n-1}-\\frac{1}{2^n} \\]\n​\n\\[\\frac{n}{(n+1)!}=\\frac{1}{n!}-\\frac{1}{(n+1)!} \\]\n放缩 ​\n\\[\\frac{1}{n^2}=\\frac{4}{4n^2}\u003c\\frac{4}{4n^2 -1}=2\\left(\\frac{1}{2n-1}-\\frac{1}{2n+1}\\right) \\]\n​\n\\[\\left(1+\\frac{1}{n}\\right)^n\u003c1+1+\\frac{1}{2\\times 1}+\\frac{1}{3\\times 2}+\\dots+\\frac{1}{n(n-1)}\u003c\\frac{5}{2} \\]\n​\n\\[\\frac{1}{\\sqrt{n+2}}\u003c\\frac{1}{\\sqrt{n+2}}-\\frac{1}{\\sqrt{n}} \\]\n​\n\\[2(\\sqrt{n+1}-\\sqrt{n})\u003c\\frac{1}{\\sqrt{n}}\u003c2(\\sqrt{n}-\\sqrt{n-1}) \\]\n​\n\\[\\frac{2^n}{(2^n-1)^2}\u003c\\frac{2^n}{(2^n-1)(2^n-2)}=\\frac{2^{n-1}}{(2^n-1)(2^{n-1}-1)}=\\frac{1}{2^{n-1}-1}-\\frac{1}{2^n-1} \\]\n​\n\\[\\frac{1}{\\sqrt{n^3}}=\\frac{1}{\\sqrt{n\\cdot n^2}}\u003c\\frac{1}{\\sqrt{n(n-1)(n+1)}}=\\left(\\frac{1}{\\sqrt{n(n-1)}}\\ -\\frac{1}{\\sqrt{n(n+1)}}\\right)\\frac{1}{\\sqrt{n+1}-\\sqrt{n-1}} \\]\n​\n\\[=\\left(\\frac{1}{\\sqrt{n-1}}-\\frac{1}{\\sqrt{n+1}}\\ ​ \\right)\\frac{\\sqrt{n+1}+\\sqrt{n-1}}{2\\sqrt{n}}\u003c\\frac{1}{\\sqrt{n-1}}-\\frac{1}{\\sqrt{n+1}} \\]\n​\n\\[\\frac{1}{\\sqrt{n(n+1)}}\u003c\\sqrt{n}-\\sqrt{n-1} \\]\n\\[e^x\\geq x+1 \\]\n​\n\\[e^x\\leq \\frac{1}{1-x} \\]\n​\n\\[ln(x+1)\\leq x \\]\n​\n\\[ln(x+1)\\geq \\frac{x}{x+1} \\]\n​\n\\[ln(x+1)\\geq x-\\frac{x^2}{2} \\]\n​\n\\[e^x\\geq 1+x+\\frac{x^2}{2} \\]\n​\n\\[tanx\\geq x+\\frac{x^2}{3} \\]\n​\n\\[sinx\\geq x-\\frac{x^3}{6} \\]\n​\n\\[sinx\\leq x \\]\n​\n\\[cosx\\geq 1-\\frac{x^2}{2} \\]\n","date":"2020-12-13T13:10:39Z","permalink":"https://kegalas.top/p/%E6%88%91%E7%9A%84%E9%AB%98%E4%B8%AD%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/","title":"我的高中资料整理"},{"content":"这是一个测试文档\n","date":"2020-12-13T12:30:53Z","permalink":"https://kegalas.top/p/%E6%B5%8B%E8%AF%95/","title":"测试"}]