<!DOCTYPE html>
<html lang="en-us">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='前言 这篇文章是接在相机PSF标定之后的，我们也说过，PSF表征着光学系统的所有像差（除了畸变），也就描述了相机拍摄出来的照片是如何变得模糊的'><title>像差矫正简述</title>

<link rel='canonical' href='https://kegalas.uk/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/'>

<link rel="stylesheet" href="/scss/style.min.css"><meta property='og:title' content='像差矫正简述'>
<meta property='og:description' content='前言 这篇文章是接在相机PSF标定之后的，我们也说过，PSF表征着光学系统的所有像差（除了畸变），也就描述了相机拍摄出来的照片是如何变得模糊的'>
<meta property='og:url' content='https://kegalas.uk/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/'>
<meta property='og:site_name' content='KegalaS的个人博客'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='大学' /><meta property='article:tag' content='计算机视觉' /><meta property='article:tag' content='计算摄影' /><meta property='article:tag' content='计算机图形学' /><meta property='article:published_time' content='2025-07-14T19:48:36&#43;08:00'/><meta property='article:modified_time' content='2025-07-14T19:48:36&#43;08:00'/><meta property='og:image' content='https://kegalas.uk/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/cover.jpg' />
<meta name="twitter:title" content="像差矫正简述">
<meta name="twitter:description" content="前言 这篇文章是接在相机PSF标定之后的，我们也说过，PSF表征着光学系统的所有像差（除了畸变），也就描述了相机拍摄出来的照片是如何变得模糊的"><meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content='https://kegalas.uk/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/cover.jpg' />
    <link rel="shortcut icon" href="/images/favicon.ico" />

    </head>
    <body class="
    article-page has-toc
">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex 
    
        extended
    
">
    
        <div id="article-toolbar">
            <a href="/" class="back-home">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="15 6 9 12 15 18" />
</svg>



                <span>返回</span>
            </a>
        </div>
    
<main class="main full-width">
    <article class="has-image main-article">
    <header class="article-header">
        <div class="article-image">
            <a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/">
                <img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/cover_huc45965efbb78f489d2942b8e48485bda_47013_800x0_resize_q75_box.jpg"
                        srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/cover_huc45965efbb78f489d2942b8e48485bda_47013_800x0_resize_q75_box.jpg 800w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/cover_huc45965efbb78f489d2942b8e48485bda_47013_1600x0_resize_q75_box.jpg 1600w"
                        width="800" 
                        height="424" 
                        loading="lazy"
                        alt="Featured image of post 像差矫正简述" />
                
            </a>
        </div>
    

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/" >
                图形学
            </a>
        
    </header>
    

    <h2 class="article-title">
        <a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/">像差矫正简述</a>
    </h2>

    

    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Jul 14, 2025</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    阅读时长: 16 分钟
                </time>
            </div>
        
    </footer>
    
</div>
</header>

    <section class="article-content">
    <h1 id="前言">前言</h1>
<p>这篇文章是接在相机PSF标定之后的，我们也说过，PSF表征着光学系统的所有像差（除了畸变），也就描述了相机拍摄出来的照片是如何变得模糊的。我们获得PSF的目的实际上就是去校正这个相差，将图片中模糊的地方变得清晰。理论上来说，任何一种PSF标定方法得出的PSF都可以无缝接在这里面的所有像差矫正方法之前。</p>
<h1 id="extreme-quality-computational-imaging-via-degradation-framework">Extreme-Quality Computational Imaging via Degradation Framework</h1>
<p>之前的部分见上一篇博客，在预估完PSF后，就介绍了本文的校正模型。</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 217; 
			flex-basis: 522px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/21.jpg" data-size="1138x523">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/21.jpg"
			width="1138"
			height="523"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/21_hu57955e7d46c7d853eaf4ee407e3741b1_100168_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/21_hu57955e7d46c7d853eaf4ee407e3741b1_100168_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="21.jpg">
	</a>
	
	<figcaption>21.jpg</figcaption>
	
</figure></p>
<p>这是一个端到端的网络，输入一个退化的sRGB图像<span class="math inline">\(I_{DE}\)</span>，输出重建后的图像<span class="math inline">\(I_{PRED}\)</span>，大体上可以分为三个模块。</p>
<p>首先是FOV编码器。因为空间信息和退化有强相关性，本文提出了FOV模块来利用空间特征。这个网络的细节在上图的下方，可以看到它被用于计算一个mask，然后影响到<span class="math inline">\(I_{DE}\)</span>的输出。</p>
<p>第二部分是一个可变形解码器。由于PSF的不规则形状和大小，传统的卷积层不是很适合来处理退化，因为传统卷积层只会获取到固定位置的特征。</p>
<p>最后一部分是KPN模块。按照前人的研究结果，预测卷积核来间接预测结果要比直接预测结果要更稳定一些，但是这会增加模型的开销，尤其是卷积核很大的时候。于是本文提出了一种扩大卷积的方式，来让卷积核影响更广的范围。可以看图像来理解。</p>
<p>我们预估的PSF到底用在哪里了呢？实际上在预估完PSF后，我们将ground truth与其进行卷积，合成退化图像。后面的恢复网络在这个配对数据上进行训练。</p>
<h1 id="large-depth-of-field-ultra-compact-microscope-by-progressive-optimization-and-deep-learning">Large depth-of-field ultra-compact microscope by progressive optimization and deep learning</h1>
<p><a class="link" href="https://www.nature.com/articles/s41467-023-39860-0"  target="_blank" rel="noopener"
    >https://www.nature.com/articles/s41467-023-39860-0</a></p>
<p>本文主要是针对手机相机进行优化，让它能够较好的实现显微任务。作者指出过往的端到端方法计算开销太大，所以本文提出了一种渐进式的优化方法。</p>
<p>首先第一个需要优化的是镜头设计。首先考虑传统的镜头设计方法，例如光线追踪等等，来手动设计一系列镜头，后续的优化算法在每个镜头上都进行一次，选出最好的那一个。使用这种方法减小了参数量，从而减小开销。</p>
<p>关于镜头是如何设计的笔者不懂，也不是PSF估计的重点，就跳过。但是我们需要记得一些概念。在设计镜头的时候要考虑一个两难问题：景深和横向分辨率的关系，横向分辨率越大，景深越小。而对于一个显微镜来说景深是比较重要的。传统的增加景深的做法是减小数字孔径（NA），也就通常意味着减小物理孔径（光圈）或者增大焦距。但是减小光圈会导致进光量减小，从而减小信噪比；而增长焦距则会增大体积，对手机这种设备来说是不行的。</p>
<p>为了解决这个问题，本文开发了一种叫diffractive optical element (DOE)的物理元件，放在光圈之前。这个DOE在这里是一个三次曲面，表示为<span class="math inline">\(\alpha(x^3,y^3)\)</span>。这里的<span class="math inline">\(\alpha\)</span>是唯一一个参数，用于控制在不同的defocus（离焦）下PSF的扩散，从而控制景深大小。</p>
<p>针对这个<span class="math inline">\(\alpha\)</span>，本文均匀选择了<span class="math inline">\([0.005,0.075]\)</span>上的15个值，每一个都做成一套系统（顺带一提材料便宜、工艺简单、成本很低），然后在神经网络上训练，选出最好的。最后选出来的是<span class="math inline">\(\alpha=0.03\)</span>，使得景深增加了10倍。</p>
<p>网络架构基于pix2pix，可以很好的适应细节丰富的图像复原任务。本文获取训练数据的方式是，使用商用的显微镜，上下调节物镜高度，获得一系列图像</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 93; 
			flex-basis: 225px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/17.jpg" data-size="770x821">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/17.jpg"
			width="770"
			height="821"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/17_hu572ef19402fee0b4aea32341ed0791a0_96912_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/17_hu572ef19402fee0b4aea32341ed0791a0_96912_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="17.jpg">
	</a>
	
	<figcaption>17.jpg</figcaption>
	
</figure></p>
<p>其中使用算法将每张图片中最清晰的部分提取出来，合并成一个all-in-focus图像，作为Ground-Truth。然后对每一张图片，使用本文设计的镜头在对应高度下的PSF进行卷积，最后再合并起来，得到近似的本文镜头拍摄的退化图象。二者作为配对数据送入pix2pix中进行训练。</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 131; 
			flex-basis: 315px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/18.jpg" data-size="845x643">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/18.jpg"
			width="845"
			height="643"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/18_hua181b31e773e09ec8e5199f3caf4a337_121386_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/18_hua181b31e773e09ec8e5199f3caf4a337_121386_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="18.jpg">
	</a>
	
	<figcaption>18.jpg</figcaption>
	
</figure></p>
<p>在PSF的标定方面很简单，用光刻技术直接在一块1mm厚的玻璃板子上刻了一系列1um的小孔，然后直接用镜头拍摄。</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 147; 
			flex-basis: 353px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/15.jpg" data-size="671x455">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/15.jpg"
			width="671"
			height="455"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/15_hu04736ce613643b983e5f4cba5f75b7af_37586_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/15_hu04736ce613643b983e5f4cba5f75b7af_37586_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="15.jpg">
	</a>
	
	<figcaption>15.jpg</figcaption>
	
</figure></p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 95; 
			flex-basis: 229px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/16.jpg" data-size="780x814">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/16.jpg"
			width="780"
			height="814"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/16_hu824c97503e8943fbb62da1f91aea52eb_47719_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/16_hu824c97503e8943fbb62da1f91aea52eb_47719_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="16.jpg">
	</a>
	
	<figcaption>16.jpg</figcaption>
	
</figure></p>
<p>在如何对图片使用PSF卷积得到退化图像，本文建立了一个更细致的模型</p>
<p>由于相机系统拥有大FOV和大NA，导致PSF就更不像一个冲激函数了。为了解决这个问题，提出了一个考虑到PSF平移可变性的前向模型，并且优化了计算开销。假设具有平移可变性PSF的光学模型如下</p>
<p><span class="math display">\[i(x,y)=\sum_{u,v,z}s(u,v)p(u,v,x-u,y-v,z)
\]</span></p>
<p>其中<span class="math inline">\((u,v)\)</span>和<span class="math inline">\((x,y)\)</span>分别是物平面和像平面的坐标，而<span class="math inline">\(z\)</span>代表不同的深度，每个像<span class="math inline">\(s(u,v)\)</span>都对应一个PSF矩阵，表示为<span class="math inline">\(p(u,v,x,y,z)\)</span>。由上式也看得出来计算他要迭代所有PSF，复杂度很高，需要对其进行降维。作者这里的想法是进行矩阵分解，将PSF分成一系列基<span class="math inline">\(h_i(x,y)\)</span>的加权和</p>
<p><span class="math display">\[p(u,v,x,y,z) = \sum^N_{i} w_i(u,v,z)h_i(x,y,z)
\]</span></p>
<p>其中<span class="math inline">\(N\)</span>是具有平移不变性的基<span class="math inline">\(h_i\)</span>的个数。在实践上，对每个深度<span class="math inline">\(z\)</span>，都只标定一共<span class="math inline">\(M\)</span>个PSF，最后得到一个PSF集合<span class="math inline">\(\{p(u,v,x_i,y_i,z)\},1\leq i\leq M\)</span>。这些PSF经过下采样、剪裁、向量化，最后合并成一个矩阵<span class="math inline">\(\mathbf{P}\)</span>，同样的也有基矩阵<span class="math inline">\(\mathbf{H}\)</span>和权重矩阵<span class="math inline">\(\mathbf{W}\)</span>，于是我们就可以通过数值方法估计<span class="math inline">\(\mathbf{H,W}\)</span></p>
<p><span class="math display">\[\mathbf{\hat H},\mathbf{\hat W}=\underset{\mathbf{H},\mathbf{W}}{\arg\min}||\mathbf{H}\times\mathbf{W}-\mathbf{P}||^2_2
\]</span></p>
<p>估计完成后，就可以将成像系统表示为</p>
<p><span class="math display">\[i(x,y,z)=\sum^N_{i=1}\sum_{u,v}s(u,v)w_i(u,v)h_i(x-u,y-v,z)
\]</span></p>
<p>使用卷积表示则更简单</p>
<p><span class="math display">\[i(x,y)=\sum^N_{i=1}\{(s(u,v)\times w_i(u,v))\ast h_i(u,v)\}[x,y]
\]</span></p>
<p>作者使用一个电动控制台和一个显微镜来获取训练数据。首先用显微镜在正好对上焦的位置拍摄一张图片（文中称作一个sample），然后在<span class="math inline">\([-150\mu m,150\mu m]\)</span>的范围上以<span class="math inline">\(10\mu m\)</span>为步长移动显微镜来拍摄，从而得到一系列配对的训练数据。</p>
<p>似乎本文提出的镜头在PSF标定和使用方面就只有上面这些内容。下面的部分似乎是用于效果对比，将本文的神经网络方法和传统的PSF去卷积方法对比。</p>
<p>TODO：有待补完，Deconvolution部分本文说的很模糊，并且疑似有公式错误。</p>
<h1 id="a-physics-informed-low-rank-deep-neural-network-for-blind-and-universal-lens-aberration-correction">A Physics-informed Low-rank Deep Neural Network for Blind and Universal Lens Aberration Correction</h1>
<p><a class="link" href="https://openaccess.thecvf.com/content/CVPR2024/html/Gong_A_Physics-informed_Low-rank_Deep_Neural_Network_for_Blind_and_Universal_CVPR_2024_paper.html"  target="_blank" rel="noopener"
    >https://openaccess.thecvf.com/content/CVPR2024/html/Gong_A_Physics-informed_Low-rank_Deep_Neural_Network_for_Blind_and_Universal_CVPR_2024_paper.html</a></p>
<p>本文介绍了一种使用一组典型PSF来提取特征基，从而为畸变建模的方法。</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 113; 
			flex-basis: 272px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/19.jpg" data-size="682x601">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/19.jpg"
			width="682"
			height="601"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/19_hu67dd6c6cd69fbbec7df3746feb09524a_58713_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/19_hu67dd6c6cd69fbbec7df3746feb09524a_58713_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="19.jpg">
	</a>
	
	<figcaption>19.jpg</figcaption>
	
</figure></p>
<p>这里从Zemax里选出了20个PSF数据，因为PSF是具有旋转对称性的，于是又将一个平面上的PSF拆成多个同心圆环，然后再将圆环展开成长方形，将长方形前后拼合。最后将20个镜头的PSF长方形拼合起来得到一个矩阵，对其进行ONMF（正交非负矩阵分解）分解，得到一组基<span class="math inline">\(\{B_i\}\)</span>，之后所有的PSF都可以由下式表述</p>
<p><span class="math display">\[k=\sum_i\alpha_i\cdot B_i
\]</span></p>
<p>图像退化过程就可以由下式表述</p>
<p><span class="math display">\[Y=X\ast(\sum_i\alpha_i\cdot B_i) + n = \sum_i(\alpha_i\cdot X)\ast B_i + n
\]</span></p>
<p>其中<span class="math inline">\(X\)</span>是锐利图像，<span class="math inline">\(Y\)</span>是退化图象，而<span class="math inline">\(n\)</span>是噪声。</p>
<p>我们同样可以将退化图象进行分解，分解出模糊成分<span class="math inline">\(\{Y_i=(\alpha_i\cdot X)\ast B_i\}\)</span>。之后，我们就可以通过预训练的方式，训练一个去卷积模型，通过预测参数<span class="math inline">\(\alpha_i\)</span>的值来消除像差。</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 207; 
			flex-basis: 499px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/20.jpg" data-size="1329x639">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/20.jpg"
			width="1329"
			height="639"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/20_hu224a1faa10b8aea2f649aae73c2b532d_149481_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/20_hu224a1faa10b8aea2f649aae73c2b532d_149481_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="20.jpg">
	</a>
	
	<figcaption>20.jpg</figcaption>
	
</figure></p>
<p>本文提出的方法主要分为三块。第一块负责将原图的模糊成分（特征）提取出来。</p>
<p>在训练过程中，使用Zemax及其中的PSF，来将一个锐利图像<span class="math inline">\(X\)</span>合成出一个退化图象<span class="math inline">\(\tilde{Y_i}=X\ast(\alpha_i\cdot B_i)\)</span>，然后将退化图像<span class="math inline">\(\tilde{Y}\)</span>和基<span class="math inline">\(B\)</span>一起送进基于U-net的网络中，输出模糊成分<span class="math inline">\(Y_i\)</span>，使用的损失函数如下</p>
<p><span class="math display">\[\mathcal{L}_{decom} = ||Y-\sum_iY_i||_2+\sum_i(Y_i-\tilde{Y}_i)
\]</span></p>
<p>其中第一项是为了让<span class="math inline">\(Y_i\)</span>的加和和输入一样（我怀疑是不是符号有误），第二项是为了让每一项<span class="math inline">\(Y_i\)</span>和合成的<span class="math inline">\(\tilde{Y}_i\)</span>一样。</p>
<p>然后是第二部分，进行去卷积。本文提取出来的模糊成分和普通照片的特征区别挺大的，所以不能按常规的思路在空间域上进行去卷积，作者这里使用了在特征域上去卷积的方式。</p>
<p><span class="math display">\[X^*_i=\arg\min||Y_i-X_i\ast B_i||
\]</span></p>
<p>在实现上，作者使用了一个基于特征的自适应维纳滤波网络，设<span class="math inline">\(f_i\)</span>是可学习的线性滤波器集合，和<span class="math inline">\(Y_i\)</span>进行卷积来获得有用的特征，于是</p>
<p><span class="math display">\[F_iY_i=F_i(X_i\ast B_i)+F_in
\]</span></p>
<p>这里的<span class="math inline">\(F_i\)</span>是<span class="math inline">\(f_i\)</span>的傅立叶变换（作者能不能统一一下大小写，其他的大写都是空间域的，只有<span class="math inline">\(F\)</span>是频域的）。于是，我们的优化目标也就等价于寻找一个维纳滤波操作<span class="math inline">\(G_i\)</span>来进行像差矫正</p>
<p><span class="math display">\[X_i^*=\arg\min||G_iF_iY_i-F_iX_i||
\]</span></p>
<p>最后误差函数是</p>
<p><span class="math display">\[\mathcal{L}_{deconv} = ||F_iX_i-G_iF_iY_i||_2
\]</span></p>
<p>这里我个人觉得作者说的很乱，作者的意思看图可能更容易理解。首先将模糊成分<span class="math inline">\(Y_i\)</span>送进特征提取器，提取特征得到<span class="math inline">\(F_iY_i\)</span>，这个<span class="math inline">\(F_i\)</span>似乎是可学习的，然后将其送入预训练的维纳滤波<span class="math inline">\(G_i\)</span>中，这一部分是不可训练的。然后得到的<span class="math inline">\(G_iF_iY_i\)</span>再经过一系列网络，输出了一个预测的<span class="math inline">\(\hat X_i\)</span>。网络的目标是期望这个<span class="math inline">\(F_i\hat X_i\)</span>和真实标注<span class="math inline">\(F_iX_i\)</span>更接近。</p>
<p>目前来说将预估出来的<span class="math inline">\(X_i\)</span>组合起来就得到了锐利图片，但事实上由于分解的不精确性和去卷积的伪影，最终会影响到图像质量。为此作者又提出了第三部分，基于注意力的混合模块。这个模块是一个可训练的网络，输入所有的锐利patch，输出一张完整的锐利的图。</p>
<h1 id="image-restoration-for-optical-zooming-system-based-on-alvarez-lenses">Image restoration for optical zooming system based on Alvarez lenses</h1>
<p><a class="link" href="https://opg.optica.org/oe/fulltext.cfm?uri=oe-31-22-35765&amp;id=540720"  target="_blank" rel="noopener"
    >https://opg.optica.org/oe/fulltext.cfm?uri=oe-31-22-35765&amp;id=540720</a></p>
<p>本篇解决了基于Alvarez镜头组的光学变焦系统的图像恢复问题，有很多光学设计的内容，不过我不懂，除去这一部分的话本文内容不多。</p>
<p>首先是获取配对数据，仍然是使用锐利图像，然后卷积上PSF得到退化图象。对于图像恢复部分，本文基于MIMO-UNet进行了修改</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 179; 
			flex-basis: 430px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/22.jpg" data-size="1011x564">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/22.jpg"
			width="1011"
			height="564"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/22_hu54372c1f78364c33e23797e331df4a23_64653_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/22_hu54372c1f78364c33e23797e331df4a23_64653_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="22.jpg">
	</a>
	
	<figcaption>22.jpg</figcaption>
	
</figure></p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 259; 
			flex-basis: 622px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/23.jpg" data-size="1051x405">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/23.jpg"
			width="1051"
			height="405"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/23_hu9ac246440863c6bc974cd58c095e92d7_50041_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/23_hu9ac246440863c6bc974cd58c095e92d7_50041_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="23.jpg">
	</a>
	
	<figcaption>23.jpg</figcaption>
	
</figure></p>
<p>损失函数使用CharbonnierLoss</p>
<p><span class="math display">\[Loss=\sqrt{(output-input)^2+\epsilon^2}
\]</span></p>
<h1 id="neural-nano-optics-for-high-quality-thin-lens-imaging">Neural nano-optics for high-quality thin lens imaging</h1>
<p><a class="link" href="https://www.nature.com/articles/s41467-021-26443-0"  target="_blank" rel="noopener"
    >https://www.nature.com/articles/s41467-021-26443-0</a></p>
<p>本文针对超透镜进行校正。</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 141; 
			flex-basis: 338px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/24.jpg" data-size="1030x730">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/24.jpg"
			width="1030"
			height="730"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/24_hu0524fa783bc0f03a75882446cd97e7b7_102578_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/24_hu0524fa783bc0f03a75882446cd97e7b7_102578_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="24.jpg">
	</a>
	
	<figcaption>24.jpg</figcaption>
	
</figure></p>
<p>本文将超透镜的设计融入到了训练过程中，超透镜的参数可由下式表述</p>
<p><span class="math display">\[\phi(r)=\sum^n_{i=0}a_i\left(\dfrac{r}{R}\right)^{2i}
\]</span></p>
<p>由于笔者不是很清楚光学设计，所以就把这里简单当做一个函数，参数可调，场景用其获取能产生一些数值。</p>
<p>上图描述的是整个端到端的流程，其可以用下式表述</p>
<p><span class="math display">\[O=f_{\text{DECONV}}(P_{\text{DECONV}}, f_{\text{SENSOR}}(I\ast f_{\text{META}}(P_{\text{META}})), f_{\text{META}}(P_{\text{META}}))
\]</span></p>
<p>其中<span class="math inline">\(P_{\text{META}}\)</span>就是超透镜的参数，使用函数<span class="math inline">\(f_{\text{META}}\)</span>计算出理论PSF，和输入信号进行卷积（在训练过程中是数据集的gt图像）。<span class="math inline">\(f_{\text{SENSOR}}\)</span>模拟传感器的行为，其中包含了传感器的噪声。然后就是去卷积的神经网络<span class="math inline">\(f_{\text{DECONV}}\)</span>，其参数为<span class="math inline">\(P_{\text{DECONV}}\)</span>，接受传感器产生的图像，并且由于是非盲，也接受PSF，最终生成一张预测的清晰图像。损失函数就是gt和预测之间的L1损失。</p>
<p>在联合优化过后，就使用最优的超透镜参数去制造超透镜物理实体。</p>
<h1 id="realistic-image-degradation-with-measured-psf">Realistic Image Degradation with Measured PSF</h1>
<p><a class="link" href="https://arxiv.org/abs/1801.02197"  target="_blank" rel="noopener"
    >https://arxiv.org/abs/1801.02197</a></p>
<p>这篇文章虽然是反过来模拟像差的，但很多文章是用合成数据的，这篇文章也可以进行一定了解。</p>
<p>本文采集的PSF是用高精度仪器采集的，不是用我们之前说到的各种数值和深度学习方法，用的是单色滤镜，所以只有单通道的PSF。一共测试了27个镜头，有三个参数：离焦<span class="math inline">\(\Delta z\)</span>、图像高度<span class="math inline">\(R\)</span>、
方位角<span class="math inline">\(\phi\)</span>。</p>
<p>由于这个测量的精度很高(0.3um)，比传感器的像素尺寸(3um)小的多，所以可以进行下采样来提升效率。在本文中，下采样至大约6um的像素大小，得到一个13x13的PSF。</p>
<p>作者这里是想对每一个像素都卷积一个专属于它的PSF，从而达到比较好的结果。为此，作者将之前测量到的PSF作为gt，将<span class="math inline">\(\Delta z\)</span>、<span class="math inline">\(R\)</span>、<span class="math inline">\(\phi\)</span>作为数据输入，让神经网络拟合出PSF。然后对每一个像素都预测一个PSF。但作者认为这又太麻烦了，PSF在短距离内变化不大，不如直接用插值的方法去弄。</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 143; 
			flex-basis: 344px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/27.jpg" data-size="709x494">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/27.jpg"
			width="709"
			height="494"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/27_hu1c8af06c60a367fd87f6947eadadd1bd_48430_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/27_hu1c8af06c60a367fd87f6947eadadd1bd_48430_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="27.jpg">
	</a>
	
	<figcaption>27.jpg</figcaption>
	
</figure></p>
<p>上面的红点是有测量过PSF的位置，其他位置通过双线性插值得到。</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 294; 
			flex-basis: 706px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/28.jpg" data-size="692x235">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/28.jpg"
			width="692"
			height="235"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/28_hu43a77b870ca9b8d8ec2cb216a059748d_30159_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/28_hu43a77b870ca9b8d8ec2cb216a059748d_30159_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="28.jpg">
	</a>
	
	<figcaption>28.jpg</figcaption>
	
</figure></p>
<p>之后使用插值的或真实的PSF对图像卷积就得到了退化图像，同时为了减小拍摄图像自带的退化，还对数据提前使用了盲去卷积。</p>
<p>但是在模拟退化的这个过程中，没有考虑到离焦距离<span class="math inline">\(\Delta z\)</span>，作者后面说了一大堆提出的PSF模型有<span class="math inline">\(\Delta z\)</span>的好处，但我并没有看到和计算退化有什么关系，整篇文章都很乱。</p>
<h1 id="end-to-end-hybrid-refractive-diffractive-lens-design-with-differentiable-ray-wave-model">End-to-end hybrid refractive-diffractive lens design with differentiable ray-wave model</h1>
<p><a class="link" href="https://dl.acm.org/doi/full/10.1145/3680528.3687640"  target="_blank" rel="noopener"
    >https://dl.acm.org/doi/full/10.1145/3680528.3687640</a></p>
<p>这篇文章首次提出一个可微分的、精度高的折射-衍射混合成像模型，来让镜头设计和神经网络结合在一起，从而能够端到端的进行训练。</p>
<p>同前，光学部分不是很懂，简要介绍一下提到的公式。</p>
<p>本文的镜头组如下图</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 363; 
			flex-basis: 871px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/25.jpg" data-size="930x256">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/25.jpg"
			width="930"
			height="256"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/25_hub0b3e4142dca85df2597f5af7773a201_47678_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/25_hub0b3e4142dca85df2597f5af7773a201_47678_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="25.jpg">
	</a>
	
	<figcaption>25.jpg</figcaption>
	
</figure></p>
<p>他首先是一连串折射镜片，最后接上一个衍射镜片（衍射光学元件，DOE），然后再接到传感器上。在模拟这个镜头的物理性质时，使用了一种光线-光波结合的方法，在前面的折射镜片上使用光线追踪，而在后面的DOE上使用相位调制等方法去分析。</p>
<p>蒙特卡洛光线追踪的过程可以表示如下</p>
<p><span class="math display">\[\left\{\begin{matrix}
\mathcal{I}_n(\mathcal S_n):(o^{n-1}, d^{n-1},\phi^{n-1},\lambda)\to (o^{n}, d^{n-1},\phi^{n},\lambda)\\
\mathcal{R}_n(\mathcal S_n):(o^{n}, d^{n-1},\phi^{n},\lambda)\to (o^{n}, d^{n},\phi^{n},\lambda) \\
(o,d,\phi,\lambda)=(\mathcal{R}_N\mathcal{I}_N\dots\mathcal{R}_1\mathcal{I}_1)(o^0, d^0, \phi^0, \lambda)
\end{matrix}\right.
\]</span></p>
<p>其中<span class="math inline">\(\mathcal{I}\)</span>指的是光线与平面<span class="math inline">\(\mathcal{S}\)</span>的相交，<span class="math inline">\(\mathcal{R}\)</span>指的是光线在平面<span class="math inline">\(\mathcal{S}\)</span>上的折射，<span class="math inline">\(o,d,\phi,\lambda\)</span>分别是位置、角度、相位、波长。当计算完所有折射后，光线就抵达DOE前表面，此时可以计算光场为</p>
<p><span class="math display">\[U_{DOE^-}=\sum^{spp}_{i=1}u_i\exp(j\phi_i)\cos<d_i, n>
\]</span></p>
<p>其中<span class="math inline">\(u_i\)</span>是振幅，<span class="math inline">\(\phi_i\)</span>是光线<span class="math inline">\(i\)</span>的相位，<span class="math inline">\(spp\)</span>是蒙特卡洛采样的光线数，<span class="math inline">\(n\)</span>是DOE表面的法向量。在DOE的调制过后，光场可以写为</p>
<p><span class="math display">\[U_{DOE^+}=U_{DOE^-}\exp\left(j\dfrac{n_\lambda-1}{n_0-1}\dfrac{\lambda_0}{\lambda}\phi_0\right)
\]</span></p>
<p>计算完之后，我们就可以算出传感器表面的光场</p>
<p><span class="math display">\[U_{Sensor}=\mathcal{F}^{-1}(\mathcal{F}(U_{DOE^+})H)
\]</span></p>
<p>其中<span class="math inline">\(H\)</span>是传递函数，之后PSF计算如下</p>
<p><span class="math display">\[PSF=|U_{Sensor}|^2
\]</span></p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 200; 
			flex-basis: 482px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/26.jpg" data-size="1089x542">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/26.jpg"
			width="1089"
			height="542"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/26_hubee10749488b94a86bb5175b4edc98ba_100737_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/26_hubee10749488b94a86bb5175b4edc98ba_100737_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="26.jpg">
	</a>
	
	<figcaption>26.jpg</figcaption>
	
</figure></p>
<p>在实验中，作者计算了10x10个RGB PSF。同样，使用PSF来和图像卷积，构造出退化图像。之后使用NAFNet作为图像恢复模型，损失函数如下</p>
<p><span class="math display">\[\mathcal{L}=\mathcal{L}_{pixel}(\mathcal{N}(PSF\ast I), I) + \alpha\mathcal{L}_{percep}(\mathcal{N}(PSF\ast I), I)
\]</span></p>
<p>其中<span class="math inline">\(I\)</span>是输入图像，也被当做ground truth使用，<span class="math inline">\(\mathcal{N}\)</span>代表着NAFNet，<span class="math inline">\(\mathcal{L}_{pixel}\)</span>代表均方误差，<span class="math inline">\(\mathcal{L}_{percep}\)</span>代表着VGG loss。</p>
<h1 id="grayscale-to-hyperspectral-at-any-resolution-using-a-phase-only-lens">Grayscale to Hyperspectral at Any Resolution Using a Phase-Only Lens</h1>
<p><a class="link" href="https://arxiv.org/abs/2412.02798"  target="_blank" rel="noopener"
    >https://arxiv.org/abs/2412.02798</a></p>
<p>这篇文章主要面向metalens的像差矫正。本文使用的相机由一个衍射元件和一个无滤镜的传感器组成，获取到多个波长的光线，输出的是一个加和的灰度图。本文的目标是从这个灰度图中恢复出31个通道的图像。使用的是一个conditional denoising diffusion model</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 109; 
			flex-basis: 262px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/30.jpg" data-size="559x512">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/30.jpg"
			width="559"
			height="512"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/30_hu33e12c4142afa5cfb9c62a9b2cb1558d_71330_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/30_hu33e12c4142afa5cfb9c62a9b2cb1558d_71330_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="30.jpg">
	</a>
	
	<figcaption>30.jpg</figcaption>
	
</figure></p>
<p>一个高光谱图像（HSI），记作<span class="math inline">\(\mathbf{x}\in\mathcal{R}^{H\times W\times C}_{\geq 0}\)</span>，被传感器测量后变成单通道的<span class="math inline">\(\mathbf{y}\in\mathcal{R}^{H\times W}_{\geq 0}\)</span>，成像的过程为</p>
<p><span class="math display">\[\mathbf{y}(u,v)=\mathcal{M}(x)=\sum_\lambda o(\lambda)\cdot f(u,v,\lambda) \underset{(u, v)}{\ast} \mathbf{x}(u,v,\lambda)
\]</span></p>
<p>其中<span class="math inline">\(f(u,v,\lambda)\)</span>是PSF，<span class="math inline">\(\lambda\)</span>是波长。<span class="math inline">\(o(\lambda)\)</span>是传感器的光谱响应。于是对于高光谱图像的测量就变成了一个线性的编码过程，将3D的高光谱“体”编码成2D“图”。这里的PSF测量似乎不是本文的重点，根据附录来说PSF似乎是理论计算值，整个实验是在合成数据上进行的。</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 148; 
			flex-basis: 356px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/29.jpg" data-size="539x363">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/29.jpg"
			width="539"
			height="363"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/29_hub5d1a0450ea0081f6b29c5b5923c60b5_50694_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/29_hub5d1a0450ea0081f6b29c5b5923c60b5_50694_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="29.jpg">
	</a>
	
	<figcaption>29.jpg</figcaption>
	
</figure></p>
<p>在本文的实验中使用了8个PSF，目的是为了测试哪种光学编码器（指的应该是衍射元件而非神经网络中的编码器）是最好的。左边的PSF较为稀疏，能够产生更锐利的图像，但是编码光谱信息的能力比右边的PSF弱。因为重建任务需要同时保持空间和光谱的高准确性，所以哪种PSF较好并不是很显然。</p>
<p>这上面的每一种PSF都可以通过设计合适的metalens来在物理上实现。我认为作者的逻辑应该是先用这八种PSF去测试，看哪种效果最好，然后依照最好的这个PSF来生产metalens。</p>
<p>本文使用扩散模型来解决图像恢复问题，但并不是整张图上进行，而是分patch进行，作者说从实验结果上来看这样是更好的。</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 264; 
			flex-basis: 635px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/31.jpg" data-size="1107x418">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/31.jpg"
			width="1107"
			height="418"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/31_hud0154917283db05c888dd615fd885e62_124012_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/31_hud0154917283db05c888dd615fd885e62_124012_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="31.jpg">
	</a>
	
	<figcaption>31.jpg</figcaption>
	
</figure></p>
<p>训练数据是从ARAD1K中获取的HSI，然后使用我们前面介绍的成像模型来合成退化图像，然后就得到了配对数据<span class="math inline">\((x_0^{(i)}, y^{(i)})\)</span>。看起来作者意识到它的合成过程中，卷积计算涉及到了patch以外的信号，但是结果上来说影响不大。</p>
<p>同上图介绍的，往扩散模型中添加condition是通过将<span class="math inline">\(x,y\)</span>拼在一起实现的，然后让模型在每一步的中间都输出一个预测的HSI<span class="math inline">\((\hat{\mathbf{x}}^p_0)\)</span>，再将他们拼成一张大图，使用前述成像过程进行一次退化，让它的结果和真实标签<span class="math inline">\(y\)</span>一致，作者说用这个方法引道全局的去噪过程。如下</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 141; 
			flex-basis: 340px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/32.jpg" data-size="553x390">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/32.jpg"
			width="553"
			height="390"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/32_huaa5a130c2a463f2ca51088ebe5e121b0_50745_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/32_huaa5a130c2a463f2ca51088ebe5e121b0_50745_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="32.jpg">
	</a>
	
	<figcaption>32.jpg</figcaption>
	
</figure></p>
<p>其中上标<span class="math inline">\(p\)</span>代表patch，<span class="math inline">\(Stitch\)</span>代表这个拼图的过程，<span class="math inline">\(\mathcal{M}\)</span>就是前面的成像过程。由于<span class="math inline">\(y\)</span>和<span class="math inline">\(x_0\)</span>是max-normalized的，所以模型预测出来的HSI是带有一个未知的比例因子的，为了校正这个比例因子，多了一步过程，也就是这个cross-patch guidance。</p>
<p>（上图有误，应该是<span class="math inline">\(\arg\min\)</span>）将<span class="math inline">\(\hat x\)</span>乘以一个因子再拼起来，然后经过成像模型退化，尽量和标签<span class="math inline">\(y\)</span>一致，取这个最好的因子<span class="math inline">\(c\)</span>，再取和标签的误差，作为优化<span class="math inline">\(x_t\)</span>的误差。将<span class="math inline">\(x_t\)</span>优化后再放入扩散模型的去噪过程中。</p>
<p>最后按照这个模型走<span class="math inline">\(T\)</span>步去噪过程，就得到了最终预测的HSI。作者将光谱的不确定性量化如下</p>
<p><span class="math display">\[\text{Uncertainty} = \sum_{\lambda}\text{Var}(\{\mathbf{x}_0\}^N_{i=0})
\]</span></p>
<p>一共预测了<span class="math inline">\(N\)</span>次。</p>
<h1 id="achromatic-single-metalens-imaging-viadeepneural-network">Achromatic Single Metalens Imaging viaDeepNeural Network</h1>
<p>本文也是针对metalens进行像差矫正，但是没有引入PSF数据。模型没什么特别的，主要关注一下成像模型和数据获取方式。</p>
<p>首先介绍一下本文使用的成像模型</p>
<p><span class="math display">\[I_{sensor} = C(\mathbf{w}\cdot\mathbf{v}\cdot e\mathbf{D}(T(I_{gt}(\lambda))_{H^{-1}}\ast PSF(\lambda))+n)
\]</span></p>
<p>其中<span class="math inline">\(I_{sensor}\)</span>是相机获取到的图像，<span class="math inline">\(I_{gt}(\lambda)\)</span>是真实图像的该波长下的分量，<span class="math inline">\(T\)</span>指的是一个转换函数，将gt图像转化成显示屏上的图像。相机获取的一部分数据实际上是对着显示屏拍。</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 164; 
			flex-basis: 394px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/33.jpg" data-size="875x532">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/33.jpg"
			width="875"
			height="532"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/33_huca1c278ff67e8bc9f8cb83166bbd9c8d_67791_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/33_huca1c278ff67e8bc9f8cb83166bbd9c8d_67791_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="33.jpg">
	</a>
	
	<figcaption>33.jpg</figcaption>
	
</figure></p>
<p><span class="math inline">\(PSF(\lambda)\)</span>是在该波长下的PSF，<span class="math inline">\(\ast\)</span>是卷积，<span class="math inline">\(\mathbf{W}\)</span>是色彩平衡矩阵，<span class="math inline">\(\mathbf{V}\)</span>代表晕影，<span class="math inline">\(H\)</span>代表透视投影矩阵，<span class="math inline">\(D\)</span>代表镜头畸变，<span class="math inline">\(e\)</span>是曝光参数，<span class="math inline">\(n\)</span>是噪声，<span class="math inline">\(C\)</span>是剪裁函数，剪裁最大最小信号值。</p>
<p>本文是盲去卷积，没有使用测量的PSF。作者认为是metalens的测量比较困难，而且和波长相关，并且PSF通常还不是uniform的。</p>
<p><figure 
	
		class="gallery-image" 
		style="
			flex-grow: 197; 
			flex-basis: 474px"
	>
	<a href="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/34.jpg" data-size="1413x715">
		<img src="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/34.jpg"
			width="1413"
			height="715"
			srcset="/p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/34_hu09b76942ab43c3971270ef7ef8d71ea5_204225_480x0_resize_q75_box.jpg 480w, /p/%E5%83%8F%E5%B7%AE%E7%9F%AB%E6%AD%A3%E7%AE%80%E8%BF%B0/34_hu09b76942ab43c3971270ef7ef8d71ea5_204225_1024x0_resize_q75_box.jpg 1024w"
			loading="lazy"
			alt="34.jpg">
	</a>
	
	<figcaption>34.jpg</figcaption>
	
</figure></p>
<p>上面的成像模型很全面，但是本文主要只关注彩色图像的质量增强，于是就只保留了<span class="math inline">\(\mathbf{w},\mathbf{v},PSF\)</span>这三项，其他的项在数据采集的过程中去除。其中，曝光参数的去除是通过手动设定相机曝光实现的。镜头畸变和透视投影是通过拍摄test charts来去除的。去除过程见上图h部分。gt到显示器的转移矩阵是通过校正显示器去除的。</p>
<p>可以从上图的g部分看到有效性，矫正过的图片在几何上和gt高度相似，在雾状退化、分辨率降低等方面就证实了我们只剩下前述的3项需要矫正。</p>
<p>矫正就没什么好说的，UNet一把抓。损失函数是</p>
<p><span class="math display">\[\mathcal{L}=\alpha L_{Perceptual}+\beta L_{PSNR}
\]</span></p>
<p><span class="math display">\[L_{Perceptual}=\sum^n_{i=m}\beta_il_{p_i}(I_{gt}, I_{restored})
\]</span></p>
<p><span class="math display">\[l_p(I_{gt}, I_{restored}) = ||P(I_{gt})-P(I_{restored})||^2
\]</span></p>
<p><span class="math inline">\(P(\cdot)\)</span>指的是预训练的VGG19，<span class="math inline">\(i\)</span>是指模型的第<span class="math inline">\(i\)</span>个卷积层。</p>
<p><span class="math display">\[L_{PSNR} = \dfrac{1}{(10\log 10((I_{max}^2)/MSE(I_{gt}, I_{restored})))}
\]</span></p>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/%E5%A4%A7%E5%AD%A6/">大学</a>
        
            <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a>
        
            <a href="/tags/%E8%AE%A1%E7%AE%97%E6%91%84%E5%BD%B1/">计算摄影</a>
        
            <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/">计算机图形学</a>
        
    </section>


    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css"integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js"integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8"crossorigin="anonymous"
                defer="true"
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js"integrity="sha384-vZTG03m&#43;2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl"crossorigin="anonymous"
                defer="true"
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.querySelector(`.article-content`), {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ]
        });})
</script>
    
</article>

    <aside class="related-contents--wrapper">
    
    
        <h2 class="section-title">相关文章</h2>
        <div class="related-contents">
            <div class="flex article-list--tile">
                
                    
<article class="has-image">
    <a href="/p/%E7%9B%B8%E6%9C%BApsf%E6%A0%87%E5%AE%9A%E7%AE%80%E8%BF%B0/">
        
        
            <div class="article-image">
                <img src="/p/%E7%9B%B8%E6%9C%BApsf%E6%A0%87%E5%AE%9A%E7%AE%80%E8%BF%B0/cover.323e8fc2f31139a7790886588b4d5590_hu33a64856d379455576d0eb000fa3eb5e_11271_250x150_fill_q75_box_smart1.jpg" 
                        width="250" 
                        height="150" 
                        loading="lazy" 
                        data-key="" 
                        data-hash="md5-Mj6PwvMROad5CIZYi01VkA==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">相机PSF标定简述</h2>
        </div>
    </a>
</article>
                
                    
<article class="has-image">
    <a href="/p/%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E7%9A%84tone-mapping%E7%AE%80%E8%BF%B0/">
        
        
            <div class="article-image">
                <img src="/p/%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E7%9A%84tone-mapping%E7%AE%80%E8%BF%B0/cover.0d1f710c6f0ca8af1c1e9fb6dd83630f_hud564e3059b92e0982aa63ebb5c38fa59_49577_250x150_fill_q75_box_smart1.jpg" 
                        width="250" 
                        height="150" 
                        loading="lazy" 
                        data-key="" 
                        data-hash="md5-DR9xDG8MqK8cHp&#43;23YNjDw==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">基于图像分割的Tone Mapping简述</h2>
        </div>
    </a>
</article>
                
                    
<article class="has-image">
    <a href="/p/hdr%E8%89%B2%E8%B0%83%E6%98%A0%E5%B0%84%E5%9B%BE%E5%83%8F%E8%B4%A8%E9%87%8F%E8%AF%84%E4%BB%B7%E7%AE%80%E8%BF%B0/">
        
        
            <div class="article-image">
                <img src="/p/hdr%E8%89%B2%E8%B0%83%E6%98%A0%E5%B0%84%E5%9B%BE%E5%83%8F%E8%B4%A8%E9%87%8F%E8%AF%84%E4%BB%B7%E7%AE%80%E8%BF%B0/cover.180758a5ee73b6597684d5908958cd17_hubce6d89c2fc230acc2296e007ead6ecd_28081_250x150_fill_q75_box_smart1.jpg" 
                        width="250" 
                        height="150" 
                        loading="lazy" 
                        data-key="" 
                        data-hash="md5-GAdYpe5ztll2hNWQiVjNFw==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">HDR色调映射图像质量评价简述</h2>
        </div>
    </a>
</article>
                
                    
<article class="has-image">
    <a href="/p/tone-mapping%E7%AE%80%E8%BF%B0/">
        
        
            <div class="article-image">
                <img src="/p/tone-mapping%E7%AE%80%E8%BF%B0/cover.5aa682735da6aa1619a10f7cb3c36e37_hue2557a0ca715ca3bab4b5f5b903f073d_123247_250x150_fill_q75_box_smart1.jpg" 
                        width="250" 
                        height="150" 
                        loading="lazy" 
                        data-key="" 
                        data-hash="md5-WqaCc12mqhYZoQ98s8NuNw==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">Tone Mapping简述</h2>
        </div>
    </a>
</article>
                
                    
<article class="has-image">
    <a href="/p/grabcut-interactive-foreground-extraction-using-iterated-graph-cuts%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%E4%B8%8E%E5%A4%8D%E7%8E%B0/">
        
        
            <div class="article-image">
                <img src="/p/grabcut-interactive-foreground-extraction-using-iterated-graph-cuts%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB%E4%B8%8E%E5%A4%8D%E7%8E%B0/cover.719f06f8145a0ec2fc378d5f11233592_huf62d2c95a51769be2a7aa0d894297a77_82581_250x150_fill_q75_box_smart1.jpg" 
                        width="250" 
                        height="150" 
                        loading="lazy" 
                        data-key="" 
                        data-hash="md5-cZ8G&#43;BRaDsL8N41fESM1kg==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">GrabCut— Interactive Foreground Extraction Using Iterated Graph Cuts论文精读与复现</h2>
        </div>
    </a>
</article>
                
            </div>
        </div>
    
</aside>

     
    
        
    <script src="https://utteranc.es/client.js" 
        repo="kegalas/blogComments"
        issue-term="pathname"
        
        crossorigin="anonymous"
        async
        >
</script>

<style>
    .utterances {
        max-width: unset;
    }
</style>

<script>
    function setUtterancesTheme(theme) {
        let utterances = document.querySelector('.utterances iframe');
        if (utterances) {
            utterances.contentWindow.postMessage(
                {
                    type: 'set-theme',
                    theme: `github-${theme}`
                },
                'https://utteranc.es'
            );
        }
    }

    addEventListener('message', event => {
        if (event.origin !== 'https://utteranc.es') return;
        setUtterancesTheme(document.documentElement.dataset.scheme)
    });

    window.addEventListener('onColorSchemeChange', (e) => {
        setUtterancesTheme(e.detail)
    })
</script>


    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2025 KegalaS的个人博客
    </section>
    
    <section class="powerby">
         <br />
        
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer="true"
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer="true"
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css"integrity="sha256-c0uckgykQ9v5k&#43;IqViZOZKc47Jn7KQil4/MP3ySA3F8="crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css"integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE="crossorigin="anonymous"
            >

            </main>
    
        <aside class="sidebar right-sidebar sticky">
            <section class="widget archives">
                <div class="widget-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



                </div>
                <h2 class="widget-title section-title">目录</h2>
                
                <div class="widget--toc">
                    <nav id="TableOfContents">
  <ol>
    <li><a href="#前言">前言</a></li>
    <li><a href="#extreme-quality-computational-imaging-via-degradation-framework">Extreme-Quality Computational Imaging via Degradation Framework</a></li>
    <li><a href="#large-depth-of-field-ultra-compact-microscope-by-progressive-optimization-and-deep-learning">Large depth-of-field ultra-compact microscope by progressive optimization and deep learning</a></li>
    <li><a href="#a-physics-informed-low-rank-deep-neural-network-for-blind-and-universal-lens-aberration-correction">A Physics-informed Low-rank Deep Neural Network for Blind and Universal Lens Aberration Correction</a></li>
    <li><a href="#image-restoration-for-optical-zooming-system-based-on-alvarez-lenses">Image restoration for optical zooming system based on Alvarez lenses</a></li>
    <li><a href="#neural-nano-optics-for-high-quality-thin-lens-imaging">Neural nano-optics for high-quality thin lens imaging</a></li>
    <li><a href="#realistic-image-degradation-with-measured-psf">Realistic Image Degradation with Measured PSF</a></li>
    <li><a href="#end-to-end-hybrid-refractive-diffractive-lens-design-with-differentiable-ray-wave-model">End-to-end hybrid refractive-diffractive lens design with differentiable ray-wave model</a></li>
    <li><a href="#grayscale-to-hyperspectral-at-any-resolution-using-a-phase-only-lens">Grayscale to Hyperspectral at Any Resolution Using a Phase-Only Lens</a></li>
    <li><a href="#achromatic-single-metalens-imaging-viadeepneural-network">Achromatic Single Metalens Imaging viaDeepNeural Network</a></li>
  </ol>
</nav>
                </div>
            </section>
        </aside>
    

        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js"integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g="crossorigin="anonymous"
                defer="false"
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
