<!DOCTYPE html>
<html lang="en-us">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='人工智能概论的学习笔记'><title>人工智能概论笔记</title>

<link rel='canonical' href='https://kegalas.top/p/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E7%AC%94%E8%AE%B0/'>

<link rel="stylesheet" href="/scss/style.min.css"><meta property='og:title' content='人工智能概论笔记'>
<meta property='og:description' content='人工智能概论的学习笔记'>
<meta property='og:url' content='https://kegalas.top/p/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E7%AC%94%E8%AE%B0/'>
<meta property='og:site_name' content='KegalaS的个人博客'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='人工智能' /><meta property='article:tag' content='大学' /><meta property='article:published_time' content='2022-10-31T09:56:28&#43;08:00'/><meta property='article:modified_time' content='2022-10-31T09:56:28&#43;08:00'/><meta property='og:image' content='https://kegalas.top/p/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E7%AC%94%E8%AE%B0/cover.jpg' />
<meta name="twitter:title" content="人工智能概论笔记">
<meta name="twitter:description" content="人工智能概论的学习笔记"><meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content='https://kegalas.top/p/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E7%AC%94%E8%AE%B0/cover.jpg' />
    <link rel="shortcut icon" href="favicon-16x16.png" />

    </head>
    <body class="
    article-page has-toc
">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex 
    
        extended
    
">
    
        <div id="article-toolbar">
            <a href="/" class="back-home">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="15 6 9 12 15 18" />
</svg>



                <span>返回</span>
            </a>
        </div>
    
<main class="main full-width">
    <article class="has-image main-article">
    <header class="article-header">
        <div class="article-image">
            <a href="/p/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E7%AC%94%E8%AE%B0/">
                <img src="/p/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E7%AC%94%E8%AE%B0/cover_hu729735102c3c060f4a29b2f0df39e169_86954_800x0_resize_q75_box.jpg"
                        srcset="/p/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E7%AC%94%E8%AE%B0/cover_hu729735102c3c060f4a29b2f0df39e169_86954_800x0_resize_q75_box.jpg 800w, /p/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E7%AC%94%E8%AE%B0/cover_hu729735102c3c060f4a29b2f0df39e169_86954_1600x0_resize_q75_box.jpg 1600w"
                        width="800" 
                        height="454" 
                        loading="lazy"
                        alt="Featured image of post 人工智能概论笔记" />
                
            </a>
        </div>
    

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" >
                人工智能
            </a>
        
    </header>
    

    <h2 class="article-title">
        <a href="/p/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E7%AC%94%E8%AE%B0/">人工智能概论笔记</a>
    </h2>

    
    <h3 class="article-subtitle">
        人工智能概论的学习笔记
    </h3>
    

    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Oct 31, 2022</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    阅读时长: 30 分钟
                </time>
            </div>
        
    </footer>
    
</div>
</header>

    <section class="article-content">
    

<h1 id="一些概念解释">一些概念解释</h1>
<h2 id="弱人工智能与强人工智能">弱人工智能与强人工智能</h2>
<p>弱人工智能是指不能真正实现推理和解决问题的智能机器，这些机器表面看像是智能的，但是并不真正拥有智能，也不会有自主意识。</p>
<p>强人工智能是指真正能思维的智能机器，并且认为这样的机器是有知觉的和自我意识的，这类机器可分为类人（机器的思考和推理类似人的思维）与非类人（机器产生了和人完全不一样的知觉和意识，使用和人完全不一样的推理方式）两大类。</p>
<h2 id="符号处理系统">符号处理系统</h2>
<h3 id="六种功能">六种功能</h3>
<ol type="1">
<li>输入符号</li>
<li>输出符号</li>
<li>存储符号</li>
<li>复制符号</li>
<li>建立符号结构：在符号系统中形成符号结构</li>
<li>条件性迁移：根据已有符号，继续完成活动的过程</li>
</ol>
<p>可以把人看作是一个物理符号系统。如果一个物理符号系统具有上述全部6种功能，能够完成这个全过程，那么它就是一个完整的物理符号系统。人具有上述6种功能；现代计算机也具备物理符号系统的这6种功能。</p>
<p>有一个假设：任何一个系统，如果它能表现出智能，那么它就必定能够执行上述6种功能。反之，任何系统如果具有这6种功能，那么它就能够表现出智能；这种智能指的是人类所具有的那种智能。把这个假设称为物理符号系统的假设。</p>
<p>这个假设有很多局限性，许多乐观预言都成了泡影。90年代之后人工智能领域形成了很多新的研究模式</p>
<h2 id="人工智能的学派">人工智能的学派</h2>
<h3 id="符号主义">符号主义</h3>
<p>又称：逻辑主义、心理学派或计算机学派</p>
<p>原理：物理符号系统（即符号操作系统）假设和有限合理性原理</p>
<p>符号主义认为人的认知基元是符号，认知过程即符号操作过程。认为人是一个物理符号系统，计算机也是一个物理符号系统，因此能够用计算机来模拟人的智能行为。人工智能的核心问题是知识表示、知识推理和知识运用。</p>
<h3 id="连接主义">连接主义</h3>
<p>又称：仿生学派或生理学派</p>
<p>原理：神经网络及神经网络间的连接机制与学习算法。</p>
<p>连接主义认为思维基元是神经元，而不是符号处理过程。认为人脑不同于电脑，并提出连接主义的大脑工作模式，用于取代符号操作的电脑工作模式。</p>
<h3 id="行为主义">行为主义</h3>
<p>又称：进化主义或控制论学派</p>
<p>原理：控制论及感知—动作型控制系统</p>
<p>行为主义认为智能取决于感知和行动（所以被称为行为主义），提出智能行为的“感知—动作”模式。认为智能不需要知识、不需要表示、不需要推理；人工智能可以象人类智能一样逐步进化(所以称为进化主义)；智能行为只能在现实世界中与周围环境交互作用而表现出来。</p>
<h2 id="研究领域">研究领域</h2>
<h3 id="自然语言理解">自然语言理解</h3>
<p>是计算机对人类的书面和口头形式的自然语言信息进行处理加工的技术,涉及语言学,数学和计算机科学等多学科知识领域.其主要任务是建立各种自然语言处理系统,如:文字(语音)自动识别系统,电子词典,机器翻译,自动索引系统等.</p>
<h3 id="模式识别">模式识别</h3>
<p>模式识别是指用计算机代替人类或帮助人类感知模式，是对人类感知外界功能的模拟，研究的是计算机模式识别系统，也就是使一个计算机系统具有模拟人类通过感官接受外界信息、识别和理解周围环境的感知能力。</p>
<p>其已在医学图象,指纹识别,天气预报,汽车牌照识别中广泛应用。</p>
<h3 id="计算机视觉">计算机视觉</h3>
<p>机器视觉或计算机视觉是一种用计算机实现(或模拟)人的视觉功能，对客观外界进行感知和理解的技术。它是在图像处理和模式识别技术基础上发展起来的一门新兴的学科分支，其主要目的就是用机器识别客观外界景物，即从外界获得二维图像，抽取其特征(如形状、位置、大小、灰度、颜色、纹理等)构成本征描述，然后与已知物体的描述相匹配，从而辨认出所描述的物体。</p>
<h3 id="专家系统">专家系统</h3>
<p>专家系统是一个具有大量专门知识和经验的程序系统，它应用于人工智能技术，根据某个领域中一个或多个人类专家提供的知识和经验进行推理和判断，模拟人类专家的决策过程，以解决那些需要专家决定的复杂问题。</p>
<h3 id="机器学习">机器学习</h3>
<p>所谓机器学习，就是要使计算机能模拟人的学习行为，自动地通过学习获取知识和技能，不断改善性能，实现自我完善。机器学习就是计算机自动获取知识，它是知识工程的三个分支（使用知识、知识表示、获取知识）之一
。</p>
<h3 id="神经网络">神经网络</h3>
<p>也称神经计算,是指一类计算模型,其工作原理模仿了人类大脑的某些工作机制,其利用大量人工神经元组成一个大网络,来实现大规模并行运算。</p>
<h1 id="状态空间知识表示及其搜索技术">状态空间知识表示及其搜索技术</h1>
<h2 id="知识">知识</h2>
<p><strong>知识</strong>是人们在改造客观世界的实践中积累起来的认识和经验。</p>
<p>一般来说，我们把有关信息关联在一起所形成的信息结构称为知识。</p>
<p><strong>知识表示</strong>就是对知识的一种描述，一种计算机可以
接受的用于描述知识的数据结构。</p>
<p><strong>知识的要素</strong>，一般而言，人工智能系统的知识包含事实、规则、控制和元知识。</p>
<p><strong>事实</strong>：事物的分类、属性、事物间关系、科学事实、客观事实等。</p>
<p><strong>规则</strong>：事物的行动、动作和联系的因果关系知识。</p>
<p><strong>控制</strong>：是有关问题的求解步骤、规划、求解策略等技巧性知识，告诉怎么做一件事。</p>
<p><strong>元知识</strong>：怎样使用规则、解释规则、校验规则、解释程序结构等知识。是有关知识的知识，是知识库中的高层知识。</p>
<h2 id="知识表示的一般方法">知识表示的一般方法</h2>
<p>一般有：状态空间法、问题归约法、谓词逻辑法、语义网络、框架表示、剧本表示、过程表示等。</p>
<h3 id="状态空间法">状态空间法</h3>
<p>问题求解(problem
solving)是个大课题，它涉及归约、推断、决策、规划、常识推理、定理证明和相关过程的核心概念。在分析了人工智能研究中运用的问题求解方法之后，就会发现许多问题求解方法是采用试探搜索方法的。也就是说，这些方法是通过在某个可能的解空间内寻找一个解来求解问题的。这种基于解答空间的问题表示和求解方法就是状态空间法，它是以状态和算符(operator)为基础来表示和求解问题的。</p>
<p><strong>状态</strong></p>
<p>为描述某类不同事物间的差别而引入的一组最少变量<span class="math inline">\(q_0,q_1,\cdots,q_n\)</span>的有序集合</p>
<p>可用矢量来表示：<span class="math inline">\(Q=[q_0,q_1,\cdots,q_n]^T\)</span></p>
<p>其中的每一个元素为集合的分量，称为状态变量。</p>
<p>给定每个分量的一组值就得到一个具体的状态。</p>
<p><strong>算符</strong></p>
<p>把问题从一种状态变换为另一种状态的手段。</p>
<p><strong>问题的状态空间</strong></p>
<p>是一个表示该问题全部可能状态及其关系的图。</p>
<p>它包含三种说明的集合,即三元状态（S，F，G），S-初始状态集合，F-操作符集合，G-目标状态集合。</p>
<p><strong>状态图示法</strong></p>
<p>用有向带权图来表示，图上的节点代表状态，边代表状态转移的路径以及转移的代价。这个路径通常也和算符有关。</p>
<h2 id="搜索推理技术">搜索推理技术</h2>
<p>知识表示是问题求解所必须的，从问题表示到问题的解决，有一个求解过程，也就是搜索推理过程。</p>
<h3 id="搜索">搜索</h3>
<p>根据问题的实际情况不断寻找可利用的知识,构造出一条代价较少的推理路线,使问题得到圆满解决的过程称为搜索</p>
<p>要求，找到一条从初始事实到问题的最终答案的一条推理路径、找到的这条路在时间和空间复杂度上最优。</p>
<p>在状态空间中搜索时，我们通常会用：图搜索策略、盲目搜索、启发式搜索等方法。</p>
<h3 id="图搜索策略">图搜索策略</h3>
<p>这是一种在图中寻找路径的方法。</p>
<p>图中每个节点对应一个状态，每条连线对应一个操作符。</p>
<p>搜索方法有很多，例如深度优先搜索等，可以看算法竞赛整理。</p>
<p>在这里我们通常需要</p>
<ol type="1">
<li>必须记住下一步可以走哪些点。OPEN表，记录还没有扩展的节点，用于存放刚生成的节点。</li>
<li>必须记住哪些点走过了。CLOSED表，记录已经扩展过的节点，用于存放已经扩展或将要扩展的节点</li>
<li>必须记住从目标返回的路径</li>
</ol>
<p>其基本思想是，先把问题的初始状态作为当前扩展节点对其进行扩展，生成一组子节点，然后检查问题的目标状态是否出现在这些子节点中。</p>
<p>若出现，则找到问题的解。</p>
<p>若没有出现，则按照某种策略继续扩展。</p>
<p>重复上述过程，直到找到解或者没有可以操作的节点为止。</p>
<p>总结如下</p>
<figure>
<img src="1.jpg" alt="1.jpg"/>
<figcaption aria-hidden="true">1.jpg</figcaption>
</figure>
<p>其中第七步的排序可以是任意的即盲目的（属于盲目搜索），也可以用之后讨论的各种启发性思想或其他准则为依据（属于启发式搜索）。</p>
<h3 id="盲目搜索">盲目搜索</h3>
<p>这是没有启发信息的一种搜索形式，搜索过程中获得的信息不会用来改进策略。</p>
<p>一般只适用于求解比较简单的问题。</p>
<p>不需要重排OPEN表。</p>
<p>种类主要分为：宽度优先、深度优先、等代价搜索。</p>
<p>DFS和BFS不再介绍，介绍一个有界深度优先搜索。</p>
<p><strong>有界深度优先搜索</strong></p>
<p>对深度优先搜索引入搜索深度的界限（设为<span class="math inline">\(d_m\)</span>），当搜索深度达到了深度界限，而仍未出现目标节点时，就换一个分支进行搜索。</p>
<p><strong>等代价搜索</strong></p>
<p>它宽度优先搜索的一种推广。不是沿着等长度路径断层进行扩展，而是沿着等代价路径断层进行扩展。</p>
<p><strong>代价树的广度优先搜索</strong></p>
<p>每次从OPEN表中选择节点往CLOSED表传送时，总是选择其中代价最小的节点。</p>
<p>换句话说就是用二叉堆去维护OPEN表的节点。</p>
<h3 id="启发式搜索">启发式搜索</h3>
<p>特点是重排OPEN表,选择最有希望的节点加以扩展。种类有：有序搜索、<span class="math inline">\(A^*\)</span>算法等等。</p>
<p><strong>启发式搜索的估价函数</strong></p>
<p>估价函数(evaluation function)，是估算节点希望程度的量度，用<span class="math inline">\(f(n)\)</span>表示节点<span class="math inline">\(n\)</span>的估价函数值。</p>
<p>建立估价函数的一般方法是：提出任意节点与目标集之间的距离量度或差别量度</p>
<p><strong>有序搜索</strong></p>
<p>有序搜索，也称最好优先搜索，选择OPEN表上具有最小<span class="math inline">\(f\)</span>值的节点作为下一个要扩展的节点。</p>
<p><strong><span class="math inline">\(A^*\)</span>算法</strong></p>
<p>它是有序搜索的一种，其特点在于对估价函数的定义上。</p>
<p>用<span class="math inline">\(k(n_i,n_j)\)</span>表示任意两个节点<span class="math inline">\(n_i\)</span>和<span class="math inline">\(n_j\)</span>之间最小代价路径的实际代价。</p>
<p>如果两个节点没有通路，则<span class="math inline">\(k\)</span>没有定义。</p>
<p>对于一个具体的目标节点<span class="math inline">\(t_i\)</span>，用<span class="math inline">\(h^*(n)\)</span>表示整个目标节点集合<span class="math inline">\(\{t_i\}\)</span>上所有<span class="math inline">\(k(n,t_i)\)</span>中最小的一个，此时<span class="math inline">\(h^*(n)\)</span>就是从<span class="math inline">\(n\)</span>到目标节点最小代价路径的代价，从<span class="math inline">\(n\)</span>到目标节点的代价为<span class="math inline">\(h^*(n)\)</span>的任一路径就是一条最佳路径。</p>
<p>估价函数设计如下(S是初始状态)</p>
<p><span class="math display">\[
g^*(n) = k(S,n)
\]</span></p>
<p><span class="math display">\[
f^*(n) = g^*(n)+h^*(n)
\]</span></p>
<p><span class="math inline">\(f^*(n)\)</span>就是从<span class="math inline">\(S\)</span>开始约束通过节点<span class="math inline">\(n\)</span>的一条最佳路径的代价。</p>
<p>希望估价函数<span class="math inline">\(f\)</span>是<span class="math inline">\(f^*\)</span>的一个估计，<span class="math inline">\(g\)</span>是<span class="math inline">\(g^*\)</span>的一个估计，<span class="math inline">\(h\)</span>是<span class="math inline">\(h^*\)</span>的一个估计，<span class="math inline">\(h\)</span>叫做启发函数</p>
<p><span class="math display">\[
f(n) = g(n)+h(n)
\]</span></p>
<p>在图搜索中，如果OPEN表的重排是根据<span class="math inline">\(f(n) =
g(n)+h(n)\)</span>来进行的，那么称为<span class="math inline">\(A\)</span>算法。</p>
<p>在<span class="math inline">\(A\)</span>算法中,如果对所有的<span class="math inline">\(n\)</span>存在<span class="math inline">\(h(n)\leq
h^*(n)\)</span> ,则称<span class="math inline">\(h(n)\)</span>为<span class="math inline">\(h^*(n)\)</span>的下界,它表示某种偏于保守的估计;</p>
<p>采用<span class="math inline">\(h^*(n)\)</span>的下界<span class="math inline">\(h(n)\)</span>为启发函数的<span class="math inline">\(A\)</span>算法，称为<span class="math inline">\(A^*\)</span>算法。</p>
<h1 id="问题归约知识表示及其搜索技术">问题归约知识表示及其搜索技术</h1>
<p>已知问题的描述，通过一系列变换把此问题最终变为一个子问题集合；这些子问题的解可以直接得到，从而解决了初始问题。</p>
<p>该方法也就是从目标(要解决的问题)出发逆向推理，建立子问题以及子问题的子问题，直至最后把初始问题归约为一个平凡的本原问题集合。这就是问题归约的实质。</p>
<p>问题归约法的组成部分：</p>
<ol type="1">
<li>一个初始问题描述</li>
<li>一套把问题变为子问题的操作符</li>
<li>一套本原问题描述</li>
</ol>
<p>举个例子</p>
<figure>
<img src="2.jpg" alt="2.jpg"/>
<figcaption aria-hidden="true">2.jpg</figcaption>
</figure>
<h2 id="与或图表示">与或图表示</h2>
<figure>
<img src="3.jpg" alt="3.jpg"/>
<figcaption aria-hidden="true">3.jpg</figcaption>
</figure>
<p><strong>或节点</strong>：只要解决某个问题就可以解决其父节点的问题</p>
<p><strong>与节点</strong>：只有解决所有子问题才可以解决其父节点的问题</p>
<p><strong>终叶节点</strong>：对应本原问题的节点</p>
<p><strong>可解节点</strong>：如下定义</p>
<ol type="1">
<li>终叶节点是可解节点</li>
<li>如果某个非终叶节点含有<strong>或</strong>后继节点，那么只有当其后继节点至少有一个是可解的时，此非终叶节点才是可解的。</li>
<li>如果某个非终叶节点含有<strong>与</strong>后继节点，那么只要当其后继节点全部为可解时，此非终叶节点才是可解的</li>
</ol>
<p><strong>不可解节点</strong>：如下定义</p>
<ol type="1">
<li>没有后裔的非终叶节点为不可解节点</li>
<li>如果某个非终叶节点含有<strong>或</strong>后继节点，那么只有当其全部后裔为不可解时，此非终叶节点才是不可解的。</li>
<li>如果某个非终叶节点含有<strong>与</strong>后继节点，那么只要当其后裔至少有一个为不可解时，此非终叶节点才是不可解的。</li>
</ol>
<h2 id="与或图搜索">与或图搜索</h2>
<p>整体与之前提到的图搜索基础没有差别，只是要去记录节点的可解性。如果最终初始节点可解，原问题就有解，否则就无解。</p>
<h2 id="max-min搜索">Max-Min搜索</h2>
<ul>
<li>目的是为博弈的双方中的一方寻找一个最优行动方案</li>
<li>要寻找这个最优方案，就要通过计算当前所有可能的方案来进行比较；</li>
<li>方案的比较是根据问题的特征来定义一个估价函数，用来估算当前博弈树端节点的得分；</li>
<li>当计算出端节点的估值后，再推算出父节点的得分（即计算倒推值）；</li>
<li><ul>
<li>对或节点，选其子节点中一个最大得分作为父节点的得分</li>
</ul></li>
<li><ul>
<li>对与节点，选其子节点中一个最小得分作为父节点的得分</li>
</ul></li>
<li>如果一个行动方案能获得较大的倒推值，则它就是当前最好的行动方案。</li>
</ul>
<p>假设Max是机器人下棋，Min是人类对手下棋，搜索的步骤是</p>
<ol type="1">
<li>以<span class="math inline">\(c(o)\)</span>为根，生成<span class="math inline">\(k\)</span>-步博弈树；</li>
<li>评估博弈树叶节点对应的博弈状态(棋局)；</li>
<li>进行极大极小运算 (Max-Min 运算)；</li>
<li>等待 Min 行棋，产生新的 c(o)，返回 step1.</li>
</ol>
<p>其实和人类思考差不多，往下多想<span class="math inline">\(k\)</span>步可能的局面，选择自己最优，对方最差的局面。但是机器暴力地枚举了所有可能。</p>
<h2 id="alpha-beta剪枝"><span class="math inline">\(\alpha-\beta\)</span>剪枝</h2>
<p>之前说的暴力算法，先生成一棵博弈树，然后再计算其倒推值，效率非常低。</p>
<p>而<span class="math inline">\(\alpha-\beta\)</span>剪枝技术的基本思想是，边生成博弈树边计算评估各节点的倒推值并且根据评估出的倒推值范围，及时停止扩展那些已无必要再扩展的子节点，即相当于剪去了博弈树上的一些分枝，从而节约了机器开销，提高了搜索效率。</p>
<h1 id="谓词逻辑表示与推理技术">谓词逻辑表示与推理技术</h1>
<p>谓词逻辑的概念和离散数学中讲授的一样，不再重复。具体可见<u><strong><a href="../离散数学整理">离散数学整理</a></strong></u></p>
<h2 id="谓词逻辑法">谓词逻辑法</h2>
<p>谓词逻辑法采用谓词合式公式和一阶谓词演算把要解决的问题变为一个有待证明的问题,然后采用消解原理和消解反演来证明一个新语句是从已知的正确语句导出的,从而证明新语句也是正确的.</p>
<h2 id="利用谓词公式进行知识表示的步骤">利用谓词公式进行知识表示的步骤</h2>
<ol type="1">
<li>定义谓词及个体，确定其含义</li>
<li>根据要表达的事物或概念,为每个谓词中的变元赋值</li>
<li>根据表达的知识的含义,用适当的连接符号将各个谓词连接起来,形成谓词公式。</li>
</ol>
<h2 id="置换与合一">置换与合一</h2>
<h3 id="置换">置换</h3>
<p>介绍一下在离散数学中不是很详细的部分。</p>
<p>一个表达式的置换就是在该表达式中用置换项置换变量。</p>
<p>置换是形如</p>
<p><span class="math display">\[
\{t_1/x_1,t_2/x_2,\cdots,t_n/x_n\}
\]</span></p>
<p>的有限集合。其中，<span class="math inline">\(t_i\)</span>是不同于<span class="math inline">\(x_i\)</span>的项（常量、变量、函数）；<span class="math inline">\(x_1,x_2,\cdots,x_n\)</span>是互不相同的变量；<span class="math inline">\(t_i/x_i\)</span>表示用<span class="math inline">\(t_i\)</span>代换<span class="math inline">\(x_i\)</span></p>
<p>令置换<span class="math inline">\(s=\{t_1/x_1,t_2/x_2,\cdots,t_n/x_n\}\)</span>，而<span class="math inline">\(E\)</span>是一个谓词公式，那么<span class="math inline">\(s\)</span>作用于<span class="math inline">\(E\)</span>，就是将<span class="math inline">\(E\)</span>中出现的<span class="math inline">\(x_i\)</span>都以<span class="math inline">\(t_i\)</span>代入。结果以<span class="math inline">\(Es\)</span>表示，并称为<span class="math inline">\(E\)</span>的一个例</p>
<p>而合成，也称为置换乘法，是置换之间的一种运算，若</p>
<p><span class="math display">\[
\theta = \{t_1/x_1,\cdots,t_n/x_n\}
\]</span></p>
<p><span class="math display">\[
\lambda = \{u_1/y_1,\cdots,u_m/y_m\}
\]</span></p>
<p>置换的乘积<span class="math inline">\(\theta\cdot\lambda\)</span>是个新的置换，作用于<span class="math inline">\(E\)</span>相当于先<span class="math inline">\(\theta\)</span>后<span class="math inline">\(\lambda\)</span>对<span class="math inline">\(E\)</span>的作用。</p>
<p>先作置换</p>
<p><span class="math display">\[
\{t_1\cdot\lambda/x_1,\cdots,t_n\cdot\lambda/x_n,u_1/y_1,\cdots,u_m/y_m\}
\]</span></p>
<p>若<span class="math inline">\(y_i\in\{x_1,\cdots,x_n\}\)</span>时，先从中删除<span class="math inline">\(u_i/y_i\)</span>；<span class="math inline">\(t_i\cdot\lambda=x_i\)</span>时，再从中删除<span class="math inline">\(t_i\cdot\lambda/x_i\)</span></p>
<p>所得的置换称为<span class="math inline">\(\theta\)</span>与<span class="math inline">\(\lambda\)</span>的乘积，记作<span class="math inline">\(\theta\cdot\lambda\)</span></p>
<p>置换的乘法是有结合律的，但没有交换率。</p>
<h3 id="合一">合一</h3>
<p>合一是寻找项对变量的置换，以使两表达式一致。</p>
<p>如果一个置换<span class="math inline">\(s\)</span>作用于表达式集<span class="math inline">\(\{E_i\}\)</span>的每个元素，则我们用<span class="math inline">\(\{E_i\}s\)</span>来表示置换例的集。</p>
<p>称表达式集<span class="math inline">\(\{E_i\}\)</span>是可合一的。如果存在一个置换<span class="math inline">\(s\)</span>，使得：</p>
<p><span class="math display">\[
E_1s=E_2s=E_3s=\cdots
\]</span></p>
<p>那么我们称此<span class="math inline">\(s\)</span>为<span class="math inline">\(\{E_i\}\)</span>的合一者，因为<span class="math inline">\(s\)</span>的作用是使 集合<span class="math inline">\(\{E_i\}\)</span>成为单一形式。</p>
<p>通过置换最少的变量以使表达式一致，这个置换就叫最一般合一者,记为mgu。</p>
<h2 id="消解原理">消解原理</h2>
<p>消解原理又称为归结原理。该原理是Robinson提出的一种基于逻辑的、采用反证法的推理方法。</p>
<p>消解法的基本原理是采用反证法或者称为反演推理方法，将待证明的表达式（定理）转换成为逻辑公式（谓词公式），然后再进行归结，归结能够顺利完成，则证明原公式(定理）是正确性的。</p>
<h2 id="子句集的求解">子句集的求解</h2>
<p>先给出一些定义</p>
<p><strong>文字</strong></p>
<p>一个原子公式和原子公式的否定都叫做文字</p>
<p><strong>子句</strong></p>
<p>由文字的析取组成的公式</p>
<p><strong>空子句</strong></p>
<p>不包含任何文字的子句</p>
<p><strong>子句集</strong></p>
<p>由子句构成的集合</p>
<p>任一谓词演算公式可以化成一个子句集。由九个步骤组成</p>
<ol type="1">
<li><p>消去蕴涵符号（使用蕴含律）</p></li>
<li><p>减少否定符号的辖域，应用德摩根定律等使得每个否定符号都只结合一个谓词符号</p></li>
<li><p>对变量标准化。在任一量词辖域内，受该量词约束的变量为一哑元(虚构变量)，它可以在该辖域内处处统一地被另一个没有出现过的任意变量所代替，而不改变公式的真值。</p></li>
<li><p>消去存在量词</p>
<ol type="1">
<li>如果要消去的存在量词在某些全称量词的辖域内，例如<span class="math inline">\((\forall y)[(\exists
x)P(x,y)]\)</span>中，中，存在量词是在全称量词的辖域内，我们允许所存在的<span class="math inline">\(x\)</span>可能依赖于<span class="math inline">\(y\)</span>值。令这种依赖关系明显地由函数<span class="math inline">\(g(y)\)</span>所定义，它把每个<span class="math inline">\(y\)</span>值映射到存在的那个<span class="math inline">\(x\)</span>。这种函数叫做Skolem函数。如果用Skolem函数代替存在的<span class="math inline">\(x\)</span>,我们就可以消去全部存在量词，并写成：<span class="math inline">\((\forall y)P(g(y),y)\)</span></li>
<li>如果不再全称量词的辖域内，直接用一个新的常量符号来替代即可。</li>
</ol></li>
<li><p>化为前束形。把所有全称量词移到公式的左边，并使每个量词的辖域包括这个量词后面公式的整个部分。所得公式称为前束形。前束形公式由前缀和母式组成，前缀由全称量词串组成，母式由没有量词的公式组成。</p></li>
<li><p>把母式化为合取范式</p></li>
<li><p>消去全称量词</p></li>
<li><p>消去连词符号<span class="math inline">\(\wedge\)</span>。用<span class="math inline">\(\{(A\vee B),(A\vee C)\}\)</span>替代<span class="math inline">\((A\vee B)\wedge(A\vee C)\)</span></p></li>
<li><p>更换变量名称，把每个子句中重复变量的名称换成不同的。</p></li>
</ol>
<h2 id="消解反演">消解反演</h2>
<p>一般过程</p>
<ol type="1">
<li>建立子句集<span class="math inline">\(S\)</span></li>
<li>从子句集<span class="math inline">\(S\)</span>出发,仅对<span class="math inline">\(S\)</span>的子句间使用归结推理规则（也即反证法）</li>
<li>如果得出空子句, 则结束;否则转下一步</li>
<li>将所得归结式仍放入<span class="math inline">\(S\)</span>中</li>
<li>对新的子句集使用归结推理规则</li>
<li>转3.</li>
</ol>
<p>空子句不含有文字,它不能被任何解释满足,所以空子句是永假的,不可满足的。</p>
<p>归结过程出现空子句,说明出现互补文字,说明S中有矛盾,因此S是不可满足的。</p>
<h2 id="语义网络法">语义网络法</h2>
<p>语义网络是知识的一种结构化图解表示，它由节点和弧线组成。节点用于表示实体、概念和情况等，节点之间的弧线用于表示节点间的关系。</p>
<h2 id="框架表示">框架表示</h2>
<p>框架是一种结构化表示法，通常采用语义网络中的节点-槽-值表示结构。</p>
<h1 id="规则演绎系统">规则演绎系统</h1>
<p>基于规则的演绎推理是一种直接的推理方法，它不像消解反演把知识转化为子句集，而是把有关问题的知识和信息划分为规则和事实两种类型。</p>
<p>规则由包含蕴含形式的表达式表示，事实由无蕴含形式的表达式表示，并画出相应的与或图，然后通过规则进行演绎推理。</p>
<p>规则演绎系统可以分为规则正向演绎推理、规则逆向演绎系统和规则双向演绎系统。</p>
<p>基于规则的问题求解系统运用下述规则来建立：</p>
<p><span class="math display">\[
If\to Then
\]</span></p>
<p>其中，If部分可能由几个if组成，而Then部分可能由一个或一个以上的then组成。</p>
<p>在这种系统中，通常称每个if部分为前项，称每个then部分为后项。</p>
<h2 id="规则正向演绎系统">规则正向演绎系统</h2>
<p>规则正向演绎系统是从事实到目标进行操作的，即从状况条件到动作进行推理的，也就是从if到then的方向进行推理的。</p>
<p>过程</p>
<ol type="1">
<li>事实表达式的与或形变换。把事实表示为非蕴涵形式的与或形，作为系统的总数据库。具体变换步骤与前述化为子句形类似。</li>
<li>事实表达式的与或图表示，即用与或图来表达事实表达式。</li>
<li>与或图的F规则变换</li>
</ol>
<blockquote>
<p>这些规则是建立在某个问题辖域中普通陈述性知识的蕴涵公式基础上的。我们把允许用作规则的公式类型限制为下列形式：</p>
</blockquote>
<p><span class="math display">\[
L\Rightarrow W
\]</span></p>
<blockquote>
<p>式中：<span class="math inline">\(L\)</span>是单文字；<span class="math inline">\(W\)</span>为与或形的公式。</p>
</blockquote>
<ol start="4" type="1">
<li>作为终止条件的目标公式</li>
</ol>
<blockquote>
<p>基于规则的正向演绎推理的基本原理是：应用F规则作
用于表示事实的与或图，改变与或图的结构，从而产生
新的事实，直到推出目标公式，则推理成功结束。</p>
</blockquote>
<blockquote>
<p>其推理过程为</p>
</blockquote>
<blockquote>
<ol type="1">
<li>首先用与或图把已知事实表示出来。</li>
<li>用F规则的左部和与或图的叶节点进行匹配，并将匹配成功的F规则加入到与或图中，即利用F规则转换与或图。</li>
<li>重复第（2）步，直到产生一个含有以目标节点作为终止节点的解图为止。</li>
</ol>
</blockquote>
<h2 id="规则逆向演绎系统">规则逆向演绎系统</h2>
<p>规则逆向演绎系统是从then向if进行推理的，即从目标或动作向事实或状况条件进行推理的。</p>
<p>逆向演绎系统能够处理任意形式的目标表达式。采用和变换事实表达式类似的过程，把目标公式化成与或形。</p>
<p><strong>与或图的B规则变换</strong></p>
<p>这个B规则是建立在确定的蕴涵式基础上的，正如正向系统的F规则一样。不过，我们现在把这些B规则限制为:
<span class="math inline">\(W\Rightarrow L\)</span>形式的表达式。</p>
<p>其中，W为任一与或形公式，L为文字，而且蕴涵式中任何变量的量词辖域为整个蕴涵式。其次，把B规则限制为这种形式的蕴涵式还可以简化匹配，使之不会引起重大的实际困难。</p>
<p>此外，可以把像<span class="math inline">\(W\Rightarrow(L1\wedge
L2)\)</span>这样的蕴涵式化为两个规则<span class="math inline">\(W\Rightarrow L1\)</span>和<span class="math inline">\(W\Rightarrow L2\)</span>。</p>
<p><strong>作为终止条件的事实节点的一致解图</strong></p>
<p>逆向系统中的事实表达式均限制为文字合取形，它可以表示为一个文字集。当一个事实文字和标在该图文字节点上的文字相匹配时，就可把相应的后裔事实节点添加到该与或图中去。这个事实节点通过标有mgu的匹配弧与匹配的子目标文字节点连接起来。同一个事实文字可以多次重复使用(每次用不同变量)，以便建立多重事实节点。逆向系统成功的终止条件是与或图包含有某个终止在事实节点上的一致解图。</p>
<h2 id="规则双向演绎系统">规则双向演绎系统</h2>
<p>正向和逆向组合系统是建立在两个系统相结合的基础上的。此组合系统的总数据库由表示目标和表示事实的两个与或图结构组成，并分别用F规则和B规则来修正。</p>
<p>双向演绎系统的主要复杂之处在于其终止条件，终止涉及两个图结构之间的适当交接处。这些结构可由标有合一文字的节点上的匹配棱线来连接。</p>
<h2 id="产生式系统">产生式系统</h2>
<p>用来描述若干个不同的以一个基本概念为基础的系统。这个基本概念就是产生式规则或产生式条件和操作对的概念。</p>
<p>在产生式系统中，论域的知识分为两部分：用事实表示静态知识，如事物、事件和它们之间的关系；用产生式规则表示推理过程和行为。由于这类系统的知识库主要用于存储规则，因此又把此类系统称为基于规则的系统。</p>
<h1 id="不确定性推理">不确定性推理</h1>
<h2 id="模糊计算和模糊推理">模糊计算和模糊推理</h2>
<p>与二值逻辑这样的非真即假的概念不同，模糊概念中，从属于该概念到不属于该概念之间无明显分界线。</p>
<p>比如快慢、大小、软硬、强弱等。</p>
<p>其基本思想是，用属于程度替代属于或不属于。</p>
<h3 id="经典集合">经典集合</h3>
<p>设<span class="math inline">\(A\)</span>是论域<span class="math inline">\(U\)</span>上的一个集合，对任意<span class="math inline">\(u\in U\)</span>，令</p>
<p><span class="math display">\[
C_A(u) = \left\{\begin{matrix}
1,u\in A\\
0,u\notin A
\end{matrix}\right.
\]</span></p>
<p>则称<span class="math inline">\(C_A(u)\)</span>为集合<span class="math inline">\(A\)</span>的特征函数。</p>
<h3 id="模糊理论基本概念">模糊理论基本概念</h3>
<p><strong>模糊集合</strong></p>
<p>论域<span class="math inline">\(U\)</span>中的模糊集<span class="math inline">\(F\)</span>用一个在区间<span class="math inline">\([0,1]\)</span>的取值的隶属函数<span class="math inline">\(\mu_F\)</span>来表示，即：</p>
<p><span class="math display">\[
\mu_F:U\to[0,1]
\]</span></p>
<p><span class="math inline">\(\mu_F\)</span>称为<span class="math inline">\(F\)</span>的隶属函数，<span class="math inline">\(\mu_F(u)\)</span>称为<span class="math inline">\(u\)</span>对<span class="math inline">\(A\)</span>的隶属度。</p>
<p>直观上来说，就是将一些元素属于某个集合的程度映射到连续的<span class="math inline">\([0,1]\)</span>上。</p>
<h3 id="模糊集的表示方法">模糊集的表示方法</h3>
<p>若<span class="math inline">\(U\)</span>为离散域且为有限集合时，模糊集合可以表示为：</p>
<p><strong>扎德表示法</strong></p>
<p><span class="math display">\[
F = \sum^n_{i=1}\mu_F(u_i)/u_i
\]</span></p>
<p>其中“<span class="math inline">\(/\)</span>”符号表示的意思是，分母是论域中的元素，分子是该元素对模糊子集<span class="math inline">\(F\)</span>的隶属度。<span class="math inline">\(\sum\)</span>也不是表示相加，只是一个记号。</p>
<p>比如我们写出来的可能是<span class="math inline">\(A =
1/u_1+0.7/u_2+0/u_3+0.5/u_4\)</span>这样的形式。如果隶属度为<span class="math inline">\(0\)</span>可以省略不写。</p>
<p><strong>序偶表示法</strong></p>
<p><span class="math display">\[
F=\{(u_1,\mu(u_1)),(u_2,\mu(u_2)),\cdots,(u_n,\mu(u_n))\}
\]</span></p>
<p><strong>向量表示法</strong></p>
<p><span class="math display">\[
F = \{\mu(u_1),\mu(u_2),\cdots,\mu(u_n)\}
\]</span></p>
<p>无论论域是有限的还是无限的，连续的还是离散的，扎德都用如下记号作为模糊子集的一般表示形式：</p>
<p><span class="math display">\[
F = \int_U\frac{\mu_F}{u}
\]</span></p>
<p>这里的积分号不是数学中的积分，也不是求和，只是表示论域中各元素与其隶属度对应关系的总括，是一个记号。</p>
<h3 id="集合运算">集合运算</h3>
<p><strong>定义1</strong></p>
<p>设<span class="math inline">\(A,B\)</span>是论域<span class="math inline">\(U\)</span>的模糊集，即<span class="math inline">\(A,B\in F(U)\)</span>，若对于任一<span class="math inline">\(u\in U\)</span>都有<span class="math inline">\(\mu_B(u)\leq\mu_A(A)\)</span>，则称<span class="math inline">\(B\)</span>包含于<span class="math inline">\(A\)</span>，或者说<span class="math inline">\(B\)</span>是<span class="math inline">\(A\)</span>的一个子集，记作<span class="math inline">\(B\subseteq A\)</span>。若对于任一<span class="math inline">\(u\in U\)</span>都有<span class="math inline">\(\mu_B(u)=\mu_A(A)\)</span>，则称<span class="math inline">\(B\)</span>等于<span class="math inline">\(A\)</span>，记作<span class="math inline">\(B=A\)</span></p>
<p><strong>定义2</strong></p>
<p>并运算（<span class="math inline">\(A\bigcup
B\)</span>）的隶属度函数<span class="math inline">\(\mu_{A\bigcup
B}\)</span>对所有的<span class="math inline">\(u\in
U\)</span>被逐点定义为取大运算，即</p>
<p><span class="math display">\[
\mu_{A\bigcup B} = \mu_A(u)\vee\mu_B(u)
\]</span></p>
<p>式中，<span class="math inline">\(\vee\)</span>符号取极大值运算。</p>
<p><strong>定义3</strong></p>
<p>交运算（<span class="math inline">\(A\bigcap
B\)</span>）的隶属度函数<span class="math inline">\(\mu_{A\bigcap
B}\)</span>对所有的<span class="math inline">\(u\in
U\)</span>被逐点定义为取小运算，即</p>
<p><span class="math display">\[
\mu_{A\bigcap B} = \mu_A(u)\wedge\mu_B(u)
\]</span></p>
<p>式中，<span class="math inline">\(\wedge\)</span>符号取极小值运算。</p>
<p><strong>定义4</strong></p>
<p>补，隶属度函数<span class="math inline">\(\mu_{\bar
A}\)</span>，对所有的<span class="math inline">\(u\in
U\)</span>，被逐点定义为<span class="math inline">\(\mu_{\bar A}(u) =
1-\mu_{A}(u)\)</span></p>
<p>模糊集合中有时会用<span class="math inline">\(\neg
A\)</span>表示<span class="math inline">\(A\)</span>的补集。</p>
<p><strong>定理</strong></p>
<p>集合运算的定理和经典的集合没有区别，例如结合、分配律，德摩根律等等。</p>
<h3 id="模糊集的截集">模糊集的截集</h3>
<p><strong>定义1</strong></p>
<p>设<span class="math inline">\(A\in
F(u),\lambda\in[0,1]\)</span>，则</p>
<ol type="1">
<li><span class="math inline">\(A_\lambda=\{u|u\in
U,\mu_A(u)\geq\lambda\}\)</span>，称<span class="math inline">\(A_\lambda\)</span>为<span class="math inline">\(A\)</span>的一个<span class="math inline">\(\lambda\)</span>截集，称<span class="math inline">\(\lambda\)</span>为阈值（置信水平）</li>
<li><span class="math inline">\(A_\lambda=\{u|u\in
U,\mu_A(u)&gt;\lambda\}\)</span>，称<span class="math inline">\(A_\lambda\)</span>为<span class="math inline">\(A\)</span>的一个<span class="math inline">\(\lambda\)</span>强截集</li>
<li><span class="math inline">\(SuppA=\{u|u\in
U,\mu_A(u)&gt;0\}\)</span>为<span class="math inline">\(A\)</span>的支集</li>
<li><span class="math inline">\(KerA=\{u|u\in
U,\mu_A(u)=1\}\)</span>为<span class="math inline">\(A\)</span>的核</li>
</ol>
<p>当<span class="math inline">\(A\)</span>的核不为空，则称<span class="math inline">\(A\)</span>为正规<span class="math inline">\(F\)</span>集。</p>
<h3 id="模糊集合的模糊度">模糊集合的模糊度</h3>
<p>模糊度是模糊集模糊程度的一种度量</p>
<p><strong>定义</strong></p>
<p>设<span class="math inline">\(A\in F(U)\)</span>，<span class="math inline">\(d\)</span>是定义在<span class="math inline">\(F(U)\)</span>上的一个实函数，如果它满足以下条件：</p>
<ol type="1">
<li>对任意<span class="math inline">\(A\in F(U)\)</span>，有<span class="math inline">\(d(A)\in[0,1]\)</span></li>
<li>当且仅当<span class="math inline">\(A\)</span>是一个普通集合时，<span class="math inline">\(d(A) = 0\)</span></li>
<li>若<span class="math inline">\(A\)</span>的隶属函数<span class="math inline">\(\mu_A(U)\equiv0.5\)</span>，则<span class="math inline">\(d(A)=1\)</span></li>
<li>若<span class="math inline">\(A,B\in F(U)\)</span>，且对任意<span class="math inline">\(u\in U\)</span>，满足</li>
</ol>
<p><span class="math display">\[
\mu_B(u)\leq\mu_A(u)\leq0.5或者\mu_B(u)\geq\mu_A(u)\geq0.5
\]</span></p>
<p>则有<span class="math inline">\(d(B)\leq d(A)\)</span></p>
<ol start="5" type="1">
<li>对任意<span class="math inline">\(A\in F(U)\)</span>，有<span class="math inline">\(d(A)=d(\neg A)\)</span></li>
</ol>
<p>则称<span class="math inline">\(d\)</span>为定义在<span class="math inline">\(F(U)\)</span>上的一个模糊度，<span class="math inline">\(d(A)\)</span>称为<span class="math inline">\(A\)</span>的模糊度。</p>
<p>直观地理解</p>
<ul>
<li>模糊度是<span class="math inline">\([0,1]\)</span>上的一个数</li>
<li>普通集合的模糊度是<span class="math inline">\(0\)</span>，也就代表其不模糊</li>
<li>越靠近<span class="math inline">\(0.5\)</span>就越模糊，<span class="math inline">\(\mu_A(u)=0.5\)</span>时最模糊</li>
<li>模糊集<span class="math inline">\(A\)</span>与其补集<span class="math inline">\(\neg A\)</span>具有相同的模糊度</li>
</ul>
<p><strong>模糊度的计算方法</strong></p>
<p><em>Haming（海明）模糊度</em></p>
<p><span class="math display">\[
d_1(A) = \frac{2}{n}\sum^n_{i=1}|\mu_A(u_i)-\mu_{A_{0.5}}(u_i)|
\]</span></p>
<p>其中，<span class="math inline">\(\mu_{A_{0.5}}(u_i)\)</span>是<span class="math inline">\(A\)</span>的<span class="math inline">\(\lambda=0.5\)</span>截集的隶属函数。由于<span class="math inline">\(A_{0.5}\)</span>是一个普通集合，所以<span class="math inline">\(\mu_{A_{0.5}}(u_i)\)</span>实际上是特征函数</p>
<p><em>Euclid（欧几里得）模糊度</em></p>
<p><span class="math display">\[
d_2(A) = \frac{2}{\sqrt n
}(\sum^n_{i=1}|\mu_A(u_i)-\mu_{A_{0.5}}(u_i)|^2)^{1/2}
\]</span></p>
<p><em>Minkowski（明可夫斯基）模糊度</em></p>
<p><span class="math display">\[
d_p(A) =
\frac{2}{n^{1/p}}(\sum^n_{i=1}|\mu_A(u_i)-\mu_{A_{0.5}}(u_i)|^p)^{1/p}
\]</span></p>
<p><em>Shannon（香农）模糊度</em></p>
<p><span class="math display">\[
d(A) = \frac{1}{n\ln 2}\sum^n_{i=1}S(\mu_A(u_i))
\]</span></p>
<p>其中<span class="math inline">\(S(x)\)</span>是定义在<span class="math inline">\([0,1]\)</span>上的香农函数，即</p>
<p><span class="math display">\[
S(x) = \left\{\begin{matrix}
-x\ln x-(1-x)ln(1-x),\quad &amp;x\in(0,1) \\
0,\quad &amp;x=1\ or\ x = 0
\end{matrix}\right.
\]</span></p>
<h3 id="模糊数">模糊数</h3>
<p>模糊的数量，例如：500人左右，大约0.6等</p>
<p><strong>定义</strong></p>
<p>如果实数域<span class="math inline">\(R\)</span>上的模糊集<span class="math inline">\(A\)</span>的隶属函数<span class="math inline">\(\mu_A(u)\)</span>在<span class="math inline">\(R\)</span>上连续且具有如下性质</p>
<ol type="1">
<li><span class="math inline">\(A\)</span>是凸模糊集，即对任意<span class="math inline">\(\lambda\in[0,1]\)</span>，<span class="math inline">\(A_\lambda\)</span>是闭区间</li>
<li><span class="math inline">\(A\)</span>是正规模糊集，即存在<span class="math inline">\(u\in R\)</span>，使得<span class="math inline">\(\mu_A(u)=1\)</span></li>
</ol>
<p>则称<span class="math inline">\(A\)</span>为一个模糊数</p>
<p>直观上模糊数的隶属函数图形是单峰的，且在峰顶使隶属度达到<span class="math inline">\(1\)</span></p>
<h3 id="模糊关系">模糊关系</h3>
<p>在普通集合上定义的关系已经在离散数学中介绍过了。这种关系是一种确定性的关系，要么有，要么没有。</p>
<p>而模糊关系就不是非常明确的。</p>
<p><strong>定义</strong></p>
<p>设论域<span class="math inline">\(U,V\)</span>，则<span class="math inline">\(U\times V\)</span>（笛卡尔积）的一个子集<span class="math inline">\(R\)</span>就是从<span class="math inline">\(U\)</span>到<span class="math inline">\(V\)</span>的模糊关系，记作</p>
<p><span class="math display">\[
U\overset{R}{\rightarrow} V
\]</span></p>
<p>这里的模糊关系<span class="math inline">\(R\)</span>是属于模糊二元关系。</p>
<p>其隶属函数为映射<span class="math inline">\(\mu_R:U\times
V\to[0,1]\)</span></p>
<p>隶属度<span class="math inline">\(\mu_R(u_0,v_0)\)</span>，表示<span class="math inline">\(u_0\)</span>与<span class="math inline">\(v_0\)</span>具有关系<span class="math inline">\(R\)</span>的程度。</p>
<p>对于有限论域<span class="math inline">\(U = \{u_1,u_2,\cdots,u_m\},V
= \{v_1,v_2,\cdots,v_n\}\)</span>，则<span class="math inline">\(U\)</span>对<span class="math inline">\(V\)</span>的模糊关系的隶属函数可以用$mn <span class="math inline">\(阶模糊矩阵\)</span>R$来表示，即</p>
<p><span class="math display">\[
R = (r_{ij})_{m\times n}
\]</span></p>
<p><strong>模糊集的笛卡尔乘积</strong></p>
<p>模糊集<span class="math inline">\(A,B\)</span>的笛卡尔乘积为</p>
<p><span class="math display">\[
A\times B = \int_{U\times V}\min(\mu_A(u),\mu_B(v))/(u,v)
\]</span></p>
<p><strong>模糊关系的合成</strong></p>
<p>设<span class="math inline">\(R_1\)</span>与<span class="math inline">\(R_2\)</span>分别是<span class="math inline">\(u\times v\)</span>及<span class="math inline">\(v\times w\)</span>上的两个模糊关系，则<span class="math inline">\(R_1\)</span>与<span class="math inline">\(R_2\)</span>的合成是指从<span class="math inline">\(u\)</span>到<span class="math inline">\(w\)</span>的一个模糊关系，记为<span class="math inline">\(R_1\circ R_2\)</span>，其隶属度为</p>
<p><span class="math display">\[
\mu_{R_1\circ R_2}(u,w) =
\{\bigvee^{v}\mu_{R_1}(u,v)\wedge\mu_{R_2}(v,w) \}
\]</span></p>
<h3 id="模糊推理">模糊推理</h3>
<p><strong>模糊命题</strong></p>
<p>含有模糊概念、模糊数据的语句称为模糊命题。</p>
<p>它的一般表示形式为</p>
<p><span class="math display">\[
x\quad is \quad A
\]</span></p>
<p>或者</p>
<p><span class="math display">\[
x\quad is \quad A(CF)
\]</span></p>
<p>其中<span class="math inline">\(A\)</span>是模糊概念或模糊数，用相应的模糊集及隶属函数刻画；<span class="math inline">\(x\)</span>是论域上的变量，用以代表所论述对象的属性；
<span class="math inline">\(CF\)</span>是该模糊命题的可信度，它既可以是一个确定的数，也可以是一个模糊数或者模糊语言值。</p>
<p>模糊语言值是指表示大小、长短、多少等程度的一些词汇。如：极大、很大、相当大、比较大。模糊语言值同样可用模糊集描述。</p>
<h2 id="模糊的知识表示">模糊的知识表示</h2>
<ol type="1">
<li>模糊产生式规则的一般形式是</li>
</ol>
<p><span class="math display">\[
IF\quad E\quad THEN\quad H\quad (CF,\lambda)
\]</span></p>
<p>其中<span class="math inline">\(E\)</span>是用模糊命题表示的模糊条件；<span class="math inline">\(H\)</span>是用模糊命题表示的模糊结论；<span class="math inline">\(CF\)</span>是知识的可信度因子，它既可以是一个确定的数，也可以是一个模糊数或模糊语言值。<span class="math inline">\(\lambda\)</span>是匹配度的阈值，用以指出知识被运用的条件。</p>
<ol start="2" type="1">
<li>推理中所用的证据也用模糊命题表示，一般形式为</li>
</ol>
<p><span class="math display">\[
x\quad is \quad A&#39;
\]</span></p>
<p>或者</p>
<p><span class="math display">\[
x\quad is \quad A&#39;(CF)
\]</span></p>
<ol start="3" type="1">
<li>模糊推理要解决的问题：证据与知识的条件是否匹配；如果匹配，如何利用知识及证据推出结论。</li>
</ol>
<h2 id="模糊匹配与冲突消解">模糊匹配与冲突消解</h2>
<h3 id="贴近度">贴近度</h3>
<p>设<span class="math inline">\(A,B\)</span>分别是论域<span class="math inline">\(U=\{u_1,u_2,\cdots,u_n\}\)</span>上的两个模糊集，则它们的贴近度定义为：</p>
<p><span class="math display">\[
(A,B) = [A\cdot B+(1-A\odot B)]/2
\]</span></p>
<p>其中</p>
<p><span class="math display">\[
A\cdot B = \bigvee_U(\mu_A(u_i)\wedge\mu_B(u_i))
\]</span></p>
<p>是内积</p>
<p><span class="math display">\[
A\odot B = \bigwedge_U(\mu_A(u_i)\vee\mu_B(u_i))
\]</span></p>
<p>是外积。</p>
<h3 id="语义距离">语义距离</h3>
<p><strong>海明距离</strong></p>
<p><span class="math display">\[
d(A,B) = \frac{1}{n}\sum^n_{i=1}|\mu_A(u_i)-\mu_B(u_i)|
\]</span></p>
<p><span class="math display">\[
d(A,B) = \frac{1}{b-a}\int^b_a|\mu_A(u)-\mu_B(u)|du
\]</span></p>
<p><strong>欧几里得距离</strong></p>
<p><span class="math display">\[
d(A,B) = \frac{1}{\sqrt n}\sqrt{\sum^n_{i=1}(\mu_A(u_i)-\mu_B(u_i))^2}
\]</span></p>
<p><strong>明可夫斯基距离</strong></p>
<p><span class="math display">\[
d(A,B) =
[\frac{1}{n}\sum^n_{i=1}|\mu_A(u_i)-\mu_{A_{0.5}}(u_i)|^p]^{1/p},\quad
p\geq1
\]</span></p>
<p><strong>切比雪夫距离</strong></p>
<p><span class="math display">\[
d(A,B) = \underset{1\leq i\leq n}{\max}|\mu_A(u_i)-\mu_B(u_i)|
\]</span></p>
<p>匹配度为<span class="math inline">\(1-d(A,B)\)</span></p>
<h3 id="相似度">相似度</h3>
<ol type="1">
<li>最大最小法</li>
</ol>
<p><span class="math display">\[
r(A,B) =
\frac{\sum\min\{\mu_A(u_i),\mu_B(u_i)\}}{\sum\max\{\mu_A(u_i),\mu_B(u_i)\}}
\]</span></p>
<ol start="2" type="1">
<li>算术平均法</li>
</ol>
<p><span class="math display">\[
r(A,B) =
\frac{\sum\min\{\mu_A(u_i),\mu_B(u_i)\}}{\frac{1}{2}\sum(\mu_A(u_i)+\mu_B(u_i))}
\]</span></p>
<ol start="3" type="1">
<li>几何平均最小法</li>
</ol>
<p><span class="math display">\[
r(A,B) = \frac{\sum\min\{\mu_A(u_i),\mu_B(u_i)\}}{\sum\sqrt
{(\mu_A(u_i)\times\mu_B(u_i))}}
\]</span></p>
<ol start="4" type="1">
<li>相关系数法</li>
</ol>
<p><span class="math display">\[
r(A,B) =
\frac{\sum(\mu_A(u_i)-\bar\mu_A)\times(\mu_B(u_i)-\bar\mu_B)}{\sqrt{[\sum(\mu_A(u_i)-\bar\mu_A)^2]\times[\sum(\mu_B(u_i)-\bar\mu_B)^2]}}
\]</span></p>
<p><span class="math display">\[
\bar\mu_A = \frac{1}{n}\sum\mu_A(u_i),\quad\bar\mu_B =
\frac{1}{n}\sum\mu_B(u_i)
\]</span></p>
<ol start="5" type="1">
<li>指数法</li>
</ol>
<p><span class="math display">\[
r(A,B) = \exp\bigg(-\sum|\mu_A(u_i)-\mu_B(u_i)|\bigg)
\]</span></p>
<h3 id="复合条件的模糊匹配">复合条件的模糊匹配</h3>
<ol type="1">
<li>分别计算出每一个子条件与其证据的匹配度</li>
<li>求出整个前提条件与证据的总匹配度。目前常用的方法有“取极小”和“相乘”等。</li>
<li>检查总匹配度是否满足阈值条件，如果满足就可以匹配，否则为不可匹配。</li>
</ol>
<h3 id="冲突消解">冲突消解</h3>
<ol type="1">
<li>按匹配度大小排序</li>
<li>按加权平均值排序</li>
<li>按广义顺序关系排序</li>
</ol>
<h2 id="模糊推理的基本形式">模糊推理的基本形式</h2>
<ol type="1">
<li>模糊假言推理</li>
</ol>
<p>知识：<span class="math inline">\(IF\quad x\ is\ A\quad THEN\quad y\
is\ B\)</span></p>
<p>证据：<span class="math inline">\(x\ is\ A&#39;\)</span></p>
<p>结论：<span class="math inline">\(y\ is\ B&#39;\)</span></p>
<ol start="2" type="1">
<li>模糊拒取式推理</li>
</ol>
<p>知识：<span class="math inline">\(IF\quad x\ is\ A\quad THEN\quad y\
is\ B\)</span></p>
<p>证据：<span class="math inline">\(y\ is\ B&#39;\)</span></p>
<p>结论：<span class="math inline">\(x\ is\ A&#39;\)</span></p>
<p>知识中只含有简单条件，且不带可信度因子的模糊推理称为简单模糊推理。</p>
<p><strong>合成推理知识</strong></p>
<p>对于知识<span class="math inline">\(IF\quad x\ is\ A\quad THEN\quad
y\ is\ B\)</span></p>
<p>首先构造出<span class="math inline">\(A,B\)</span>之间的模糊关系<span class="math inline">\(R\)</span>，</p>
<ul>
<li><p>如果已知证据是<span class="math inline">\(x\ is\
A&#39;\)</span>，且<span class="math inline">\(A,A&#39;\)</span>之间可以进行模糊匹配，则<span class="math inline">\(B&#39; = A&#39;\circ R\)</span></p></li>
<li><p>如果已知证据是<span class="math inline">\(y\ is\
B&#39;\)</span>，且<span class="math inline">\(B,B&#39;\)</span>之间可以进行模糊匹配，则<span class="math inline">\(A&#39; = R\circ B&#39;\)</span></p></li>
</ul>
<h2 id="构造模糊关系r的方法">构造模糊关系R的方法</h2>
<h3 id="扎德方法">扎德方法</h3>
<p>扎德提出了两种方法：一种称为条件命题的极大极小规则。另一种称为条件命题的算术规则，由它们获得的模糊关系分别记为<span class="math inline">\(R_m\)</span>和<span class="math inline">\(R_a\)</span></p>
<p>设<span class="math inline">\(A\in F(U), B\in
F(V)\)</span>，其分别表示为</p>
<p><span class="math display">\[
A = \int_U \mu_A(u)/u, B = \int_V \mu_B(u)/u
\]</span></p>
<p>则</p>
<p><span class="math display">\[
R_m = (A\times B)\cup(\neg A\times V) = \int_{U\times
V}(\mu_A(u)\wedge\mu_B(v))\vee(1-\mu_A(u))/(u,v)
\]</span></p>
<p><span class="math display">\[
R_m = (\neg A\times V)\oplus(U\times B) = \int_{U\times
V}1\wedge(1-\mu_A(u)+\mu_B(v))/(u,v)
\]</span></p>
<p>其中<span class="math inline">\(\times\)</span>是笛卡尔积；有界和<span class="math inline">\(x\oplus y=\min\{1,x+y\}\)</span></p>
<h3 id="mamdani方法">Mamdani方法</h3>
<p>对于知识<span class="math inline">\(IF\quad x\ is\ A\quad THEN\quad
y\ is\ B\)</span></p>
<p><span class="math display">\[
R_C = A\times B = \int_{U\times V}\mu_A(u)\wedge\mu_B(v)/(u,v)
\]</span></p>
<h3 id="mizumoto方法">Mizumoto方法</h3>
<p>米祖莫托等人根据多值逻辑中计算<span class="math inline">\(T(AB)\)</span>的定义，提出了一组构造模糊关系的方法，分别记为<span class="math inline">\(R_s,R_g,R_{sg},R_{gs},R_{gg},R_{ss}\)</span>等等。</p>
<p><span class="math display">\[
R_s = A\times V \underset{s}{\Rightarrow} U\times B = \int_{U\times
V}[\mu_A(u)\underset{s}{\to}\mu_B(v)]/(u,v)
\]</span></p>
<p>其中</p>
<p><span class="math display">\[
\mu_A(u)\underset{s}{\to}\mu_B(v) = \left\{\begin{matrix}
1,\mu_A(u)\leq\mu_B(v) \\
0,\mu_A(u)&gt;\mu_B(v)
\end{matrix}\right.
\]</span></p>
<p><span class="math display">\[
R_s = A\times V \underset{g}{\Rightarrow} U\times B = \int_{U\times
V}[\mu_A(u)\underset{g}{\to}\mu_B(v)]/(u,v)
\]</span></p>
<p>其中</p>
<p><span class="math display">\[
\mu_A(u)\underset{g}{\to}\mu_B(v) = \left\{\begin{matrix}
1,&amp;\mu_A(u)\leq\mu_B(v) \\
\mu_B(v),&amp;\mu_A(u)&gt;\mu_B(v)
\end{matrix}\right.
\]</span></p>
<h2 id="模糊判决方法">模糊判决方法</h2>
<p>在推理得到的模糊集合中取一个相对最能代表这个模糊集合的单值的过程就称作解模糊（去模糊）或模糊判决(Defuzzification)。</p>
<p>方法有：重心法、最大隶属度方法、加权平均法、隶属度限幅元素平均法等等。</p>
<h3 id="重心法">重心法</h3>
<p>所谓重心法就是取模糊隶属函数曲线与横坐标轴围成面积的重心作为代表点。理论上应该计算输出范围内一系列连续点的重心，即</p>
<p><span class="math display">\[
u = \frac{\int_x x\mu_N(x)dx}{\int_x \mu_N(x)dx}
\]</span></p>
<h3 id="最大隶属度法">最大隶属度法</h3>
<p>这种方法最简单，只要在推理结论的模糊集合中取隶属度最大的那个元素作为输出量即可。不过，要求这种情况下的隶属函数曲线一定是单峰曲线。如果该曲线是梯形平顶，那么具有最大隶属度的元素就可能不只一个，这时就要对所有取最大隶属度的元素求其平均值。</p>
<h3 id="系数加权平均法">系数加权平均法</h3>
<p><span class="math display">\[
u = \sum k_i\cdot x_i/\sum k_i
\]</span></p>
<p>其中系数<span class="math inline">\(k_i\)</span>的选择要根据实际情况而定。</p>
<h3 id="隶属度限幅元素平均法">隶属度限幅元素平均法</h3>
<p>用所确定的隶属度值
a对隶属度函数曲线进行切割，再对切割后大于等于该隶属度的所有元素进行平均，用这个平均值作为输出执行量，这种方法就称为隶属度限幅元素平均法。</p>
<h2 id="不确定性推理的基本概念">不确定性推理的基本概念</h2>
<p>不确定性推理是建立在非经典逻辑基础上的一种推理，它是对不确定性知识的运用与处理。</p>
<p>具体地说，所谓不确定性推理就是从不确定性的初始证据（即事实）出发，通过运用不确定性的知识，最终推出具有一定程度不确定性的结论。</p>
<h2 id="不确定性推理中的基本问题">不确定性推理中的基本问题</h2>
<ol type="1">
<li>不确定性的表示与度量</li>
</ol>
<p>不确定性一般分为两类，一类是知识的不确定性，一类是证据的不确定性。</p>
<p>知识不确定性的表示：目前在专家系统中知识的不确定性一般是由领域专家给出的，通常用一个数值表示，它表示相应知识的不确定性程度，称为知识的静态强度。</p>
<p>证据不确定性的表示：证据不确定性的表示方法与知识不确定性的表示方法一致，通常也用一个数值表示，代表相应证据的不确定性程度，称之为动态强度。</p>
<ol start="2" type="1">
<li>不确定性匹配算法及阈值的选择</li>
</ol>
<p>推理是不断运用知识的过程,为了找到所需的知
识,需要在这一过程中用知识的前提与已知证据进
行匹配.只有匹配成功的知识才有可能被应用.</p>
<ol start="3" type="1">
<li>组合证据不确定性的计算方法</li>
</ol>
<p>即已知证据<span class="math inline">\(E_1\)</span>和<span class="math inline">\(E_2\)</span>的不确定性度量，求证据<span class="math inline">\(E_1\)</span>和<span class="math inline">\(E_2\)</span>的析取和合取的不确定性，常用的方法有：</p>
<ul>
<li>最大最小法</li>
</ul>
<p><span class="math display">\[
T(E_1\ AND\ E_2) = \min\{T(E_1),T(E_2)\}
\]</span></p>
<p><span class="math display">\[
T(E_1\ OR\ E_2) = \max\{T(E_1),T(E_2)\}
\]</span></p>
<ul>
<li>概率法</li>
</ul>
<p><span class="math display">\[
T(E_1\ AND\ E_2) = T(E_1)\times T(E_2)
\]</span></p>
<p><span class="math display">\[
T(E_1\ OR\ E_2) = T(E_1)+T(E_2) - T(E_1)\times T(E_2)
\]</span></p>
<ul>
<li>有界法</li>
</ul>
<p><span class="math display">\[
T(E_1\ AND\ E_2) = \max\{0,T(E_1)+T(E_2)-1\}
\]</span></p>
<p><span class="math display">\[
T(E_1\ OR\ E_2) = \min\{1,T(E_1)+T(E_2)\}
\]</span></p>
<p>其中，<span class="math inline">\(T(E)\)</span>表示证据<span class="math inline">\(E\)</span>为真的程度（动态强度），如可信度、概率等。</p>
<ol start="4" type="1">
<li>不确定性的传递算法</li>
</ol>
<ul>
<li>在每一步推理中，如何把证据及知识的不确定性传递给结论</li>
<li>在多步推理中，如何把初始证据的不确定性传递给最终结论</li>
</ul>
<ol start="5" type="1">
<li>结论不确定性的合成</li>
</ol>
<p>用不同知识进行推理得到了相同结论，但所得结论的
不确定性却不同。此时，需要用合适的算法对结论的 不确定性进行合成。</p>
<h2 id="不确定性推理方法的分类">不确定性推理方法的分类</h2>
<p>不确定性推理方法主要可分为模型法与控制法。</p>
<p>模型法：在推理一级对确定性推理进行扩展，引入证据的不确定性及知识的不确定性。</p>
<p>模型方法又分为数值方法和非数值方法两类。数值方法对不确定性进行定量的描述，按其所依据的理论又可分为基于概率的方法和基于模糊理论的方法。</p>
<p>本节主要针对模型方法中相关的典型算法展开.</p>
<h3 id="逆概率法">逆概率法</h3>
<p>TODO</p>
<h1 id="遗传算法">遗传算法</h1>
<h2 id="基本思想">基本思想</h2>
<p>遗传算法把问题的解表示成“染色体”，在算法中即是以一定方式编码的串。并且，在执行遗传算法之前，给出一群“染色体”，也即假设解（候选解）。然后，把这些假设解置于问题的“环境”中，并按适者生存的原则，从中选择出较适应环境的“染色体”进行复制，再通过交叉，变异过程产生更适应环境的新一代“染色体”群。这样，一代一代地进化，最后就会收敛到最适应环境的一个“染色体”上，它就是问题的最优解。</p>
<p>其算法框图为</p>
<figure>
<img src="4.jpg" alt="4.jpg"/>
<figcaption aria-hidden="true">4.jpg</figcaption>
</figure>



</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a>
        
            <a href="/tags/%E5%A4%A7%E5%AD%A6/">大学</a>
        
    </section>


    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css"integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js"integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8"crossorigin="anonymous"
                defer="true"
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js"integrity="sha384-vZTG03m&#43;2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl"crossorigin="anonymous"
                defer="true"
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.querySelector(`.article-content`), {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ]
        });})
</script>
    
</article>

    <aside class="related-contents--wrapper">
    
    
</aside>

     
    
        
    <script src="https://utteranc.es/client.js" 
        repo="kegalas/blogComments"
        issue-term="pathname"
        
        crossorigin="anonymous"
        async
        >
</script>

<style>
    .utterances {
        max-width: unset;
    }
</style>

<script>
    function setUtterancesTheme(theme) {
        let utterances = document.querySelector('.utterances iframe');
        if (utterances) {
            utterances.contentWindow.postMessage(
                {
                    type: 'set-theme',
                    theme: `github-${theme}`
                },
                'https://utteranc.es'
            );
        }
    }

    addEventListener('message', event => {
        if (event.origin !== 'https://utteranc.es') return;
        setUtterancesTheme(document.documentElement.dataset.scheme)
    });

    window.addEventListener('onColorSchemeChange', (e) => {
        setUtterancesTheme(e.detail)
    })
</script>


    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2022 KegalaS的个人博客
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.4.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer="true"
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer="true"
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css"integrity="sha256-c0uckgykQ9v5k&#43;IqViZOZKc47Jn7KQil4/MP3ySA3F8="crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css"integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE="crossorigin="anonymous"
            >

            </main>
    
        <aside class="sidebar right-sidebar sticky">
            <section class="widget archives">
                <div class="widget-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



                </div>
                <h2 class="widget-title section-title">目录</h2>
                
                <div class="widget--toc">
                    <nav id="TableOfContents">
  <ol>
    <li><a href="#一些概念解释">一些概念解释</a>
      <ol>
        <li><a href="#弱人工智能与强人工智能">弱人工智能与强人工智能</a></li>
        <li><a href="#符号处理系统">符号处理系统</a>
          <ol>
            <li><a href="#六种功能">六种功能</a></li>
          </ol>
        </li>
        <li><a href="#人工智能的学派">人工智能的学派</a>
          <ol>
            <li><a href="#符号主义">符号主义</a></li>
            <li><a href="#连接主义">连接主义</a></li>
            <li><a href="#行为主义">行为主义</a></li>
          </ol>
        </li>
        <li><a href="#研究领域">研究领域</a>
          <ol>
            <li><a href="#自然语言理解">自然语言理解</a></li>
            <li><a href="#模式识别">模式识别</a></li>
            <li><a href="#计算机视觉">计算机视觉</a></li>
            <li><a href="#专家系统">专家系统</a></li>
            <li><a href="#机器学习">机器学习</a></li>
            <li><a href="#神经网络">神经网络</a></li>
          </ol>
        </li>
      </ol>
    </li>
    <li><a href="#状态空间知识表示及其搜索技术">状态空间知识表示及其搜索技术</a>
      <ol>
        <li><a href="#知识">知识</a></li>
        <li><a href="#知识表示的一般方法">知识表示的一般方法</a>
          <ol>
            <li><a href="#状态空间法">状态空间法</a></li>
          </ol>
        </li>
        <li><a href="#搜索推理技术">搜索推理技术</a>
          <ol>
            <li><a href="#搜索">搜索</a></li>
            <li><a href="#图搜索策略">图搜索策略</a></li>
            <li><a href="#盲目搜索">盲目搜索</a></li>
            <li><a href="#启发式搜索">启发式搜索</a></li>
          </ol>
        </li>
      </ol>
    </li>
    <li><a href="#问题归约知识表示及其搜索技术">问题归约知识表示及其搜索技术</a>
      <ol>
        <li><a href="#与或图表示">与或图表示</a></li>
        <li><a href="#与或图搜索">与或图搜索</a></li>
        <li><a href="#max-min搜索">Max-Min搜索</a></li>
        <li><a href="#alpha-beta剪枝"><span class="math inline">\(\alpha-\beta\)</span>剪枝</a></li>
      </ol>
    </li>
    <li><a href="#谓词逻辑表示与推理技术">谓词逻辑表示与推理技术</a>
      <ol>
        <li><a href="#谓词逻辑法">谓词逻辑法</a></li>
        <li><a href="#利用谓词公式进行知识表示的步骤">利用谓词公式进行知识表示的步骤</a></li>
        <li><a href="#置换与合一">置换与合一</a>
          <ol>
            <li><a href="#置换">置换</a></li>
            <li><a href="#合一">合一</a></li>
          </ol>
        </li>
        <li><a href="#消解原理">消解原理</a></li>
        <li><a href="#子句集的求解">子句集的求解</a></li>
        <li><a href="#消解反演">消解反演</a></li>
        <li><a href="#语义网络法">语义网络法</a></li>
        <li><a href="#框架表示">框架表示</a></li>
      </ol>
    </li>
    <li><a href="#规则演绎系统">规则演绎系统</a>
      <ol>
        <li><a href="#规则正向演绎系统">规则正向演绎系统</a></li>
        <li><a href="#规则逆向演绎系统">规则逆向演绎系统</a></li>
        <li><a href="#规则双向演绎系统">规则双向演绎系统</a></li>
        <li><a href="#产生式系统">产生式系统</a></li>
      </ol>
    </li>
    <li><a href="#不确定性推理">不确定性推理</a>
      <ol>
        <li><a href="#模糊计算和模糊推理">模糊计算和模糊推理</a>
          <ol>
            <li><a href="#经典集合">经典集合</a></li>
            <li><a href="#模糊理论基本概念">模糊理论基本概念</a></li>
            <li><a href="#模糊集的表示方法">模糊集的表示方法</a></li>
            <li><a href="#集合运算">集合运算</a></li>
            <li><a href="#模糊集的截集">模糊集的截集</a></li>
            <li><a href="#模糊集合的模糊度">模糊集合的模糊度</a></li>
            <li><a href="#模糊数">模糊数</a></li>
            <li><a href="#模糊关系">模糊关系</a></li>
            <li><a href="#模糊推理">模糊推理</a></li>
          </ol>
        </li>
        <li><a href="#模糊的知识表示">模糊的知识表示</a></li>
        <li><a href="#模糊匹配与冲突消解">模糊匹配与冲突消解</a>
          <ol>
            <li><a href="#贴近度">贴近度</a></li>
            <li><a href="#语义距离">语义距离</a></li>
            <li><a href="#相似度">相似度</a></li>
            <li><a href="#复合条件的模糊匹配">复合条件的模糊匹配</a></li>
            <li><a href="#冲突消解">冲突消解</a></li>
          </ol>
        </li>
        <li><a href="#模糊推理的基本形式">模糊推理的基本形式</a></li>
        <li><a href="#构造模糊关系r的方法">构造模糊关系R的方法</a>
          <ol>
            <li><a href="#扎德方法">扎德方法</a></li>
            <li><a href="#mamdani方法">Mamdani方法</a></li>
            <li><a href="#mizumoto方法">Mizumoto方法</a></li>
          </ol>
        </li>
        <li><a href="#模糊判决方法">模糊判决方法</a>
          <ol>
            <li><a href="#重心法">重心法</a></li>
            <li><a href="#最大隶属度法">最大隶属度法</a></li>
            <li><a href="#系数加权平均法">系数加权平均法</a></li>
            <li><a href="#隶属度限幅元素平均法">隶属度限幅元素平均法</a></li>
          </ol>
        </li>
        <li><a href="#不确定性推理的基本概念">不确定性推理的基本概念</a></li>
        <li><a href="#不确定性推理中的基本问题">不确定性推理中的基本问题</a></li>
        <li><a href="#不确定性推理方法的分类">不确定性推理方法的分类</a>
          <ol>
            <li><a href="#逆概率法">逆概率法</a></li>
          </ol>
        </li>
      </ol>
    </li>
    <li><a href="#遗传算法">遗传算法</a>
      <ol>
        <li><a href="#基本思想">基本思想</a></li>
      </ol>
    </li>
  </ol>
</nav>
                </div>
            </section>
        </aside>
    

        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js"integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g="crossorigin="anonymous"
                defer="false"
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
