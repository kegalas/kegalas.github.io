---
title: Deep Bilateral Learning for Real Time Image Enhancement论文速读
date: 2024-12-12T13:06:47+08:00
draft: true
tags:
  - 大学
  - 人工智能
  - 计算机视觉
  - 图形学
categories: 人工智能
mathjax: true
markup: goldmark
image: cover.jpg
---

原论文[https://groups.csail.mit.edu/graphics/hdrnet/](https://groups.csail.mit.edu/graphics/hdrnet/)

# 摘要

在移动设备中进行图像处理，优秀的性能是关键的挑战。给出一个作为参考的图像处理管线，或者甚至只给出原图和人工ps过的图，本文希望可以以实时的速度去对这些图像增强进行再现。为此，本文提出了一种神经网络结构，其受到了bilateral grid处理和区域仿射颜色变换（local affine color transform）的启发。

使用一对输入输出图像（即原图和ps过后的图），本文的CNN可以在bilateral空间中预测出局部仿射模型的系数。本文的模型可以生成局部、全局、内容相关的决策，来近似得到期望的图像变换。在运行时，本模型输入一个图像的低分辨率版本，生成一组在bilateral空间中的仿射变换，再对变换进行上采样（同时使用一种新的slicing节点，保证edge-preserving），最后将上采样后的变换应用在原图分辨率上。

本文提出的模型速度很快，在智能手机上，对1080p也有实时性能，并且保持SOTA效果。与前人工作不同，本文的模型进行离线训练，所以在运行时不需要访问原始的operator（算子？）。这允许模型学习到复杂的、依赖场景的变换，通常这样的场景没有参考的实现（应该是前文提到的管线），例如人工ps。

# 简介

本文提出的模型可以学习到多种多样的图像增强处理过程，并且可以高速地应用在高分辨率图上。为此，本文使用了3个关键策略：

1. 本文的预测环节都是在低分辨率的bilateral grid上进行的。grid中，每个像素的坐标$x,y$都增加了一个第三维，即该像素的颜色的函数。为了实现这点，本文引入了一个新的node，来执行数据依赖的查询。这也就是一种slicing（切片）操作，其可以使用像素的颜色信息和位置信息，从3D bilateral grid中将期望图像在高分辨率上重建出来。
2. 本文参照前人工作，注意到预测输入-输出之间的变换，通常比起直接预测输出要更简单。所以，本文架构只是学习到了一个中间的转换关系的表示，使用这个转换关系就能将输入转化到期望的输出。
3. 虽然学习和推理是在低分辨率上的，但是训练过程中的损失函数是在高分辨率上进行的。这使得模型学习到的低分辨率的变换函数是直接为高分辨率图像而优化的。

综上，这三条允许本模型大量的计算在低分辨率，但输出仍然是高分辨率。

# 架构

![1.jpg](1.jpg)

大部分推理都是在低分辨率的$\tilde{I}$上进行，即上图中的上半部分，最终预测出一个局部仿射变换。根据作者的经验，图像增强不仅取决于局部图像特征，还取决于全局的信息，例如直方图、平均亮度，甚至是场景的类型。所以，low-res的部分在后面进一步分成两条路，即local和global。最终又把这两种特征混合起来并生成最终的参数。

下面的high-res部分就在原图分辨率上进行，它会应用最少的计算，并且主要集中于应用影响最大的操作，并且还会保持边缘不变。为此，本文提出了一个切片节点，其受到了bilateral grid的启发。这种节点对低分辨率的grid执行依赖于数据的（data-dependent）查找，该节点基于一个可学习的guidance map。给出从guidance map得出的高分辨率的仿射变换因子，再对图片中的每个像素应用局部的颜色变换，就得到了最终的输出$O$。在训练时，损失函数是在原分辨率上最小化的。

本架构有三点超越了前人：

1. 下采样到bilateral grid的过程是可学习的
2. guidance image也是可学习的，并且不受亮度限制
3. 损失函数不是在仿射因子上评估的，而是在原分辨率的最终图像上。

## bilateral因子在低分辨率下的预测

$\tilde{I}$被固定为$256\times 256$的大小。首先经过一连串卷积层（含stride）$(S^i)_{i=1,\cdots,n_S}$，来提取底层特征并降低分辨率。然后，数据分为两条道路。第一条路是$(L^i)_{i=1,\cdots,n_L}$，全都是卷积层，其主要学习局部特征并保留空间信息。第二条路是$(G^i)_{i=1,\cdots,n_G}$，包含了卷积层和全连接层，来学习一个固定大小的向量，表示$\tilde{I}$全局特征（例如场景类型）。这两套路的最后输出$G^{n^G}$和$L^{n_L}$进行混合，得到一个特征集$F$，在模型最后使用一个pointwise的线性层输出一个最终的数组$A$。可以将这个$A$解释为仿射因子的bilateral grid。因为使用2D图像以内容依赖的方式造出了3D的bilateral grid，可以将low-res部分视为一种可学习的splatting的实现。
